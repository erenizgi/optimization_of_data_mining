{
    "author": "cyyever",
    "message": "Use | for Optional and Union typing  (#41675)\n\nUse | for Optional and Union typing\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>",
    "sha": "def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
    "files": [
        {
            "sha": "97292bf36dc037de17e414feec270ae5c7e3c595",
            "filename": "src/transformers/distributed/configuration_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fdistributed%2Fconfiguration_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fdistributed%2Fconfiguration_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdistributed%2Fconfiguration_utils.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -16,7 +16,7 @@\n import json\n import os\n from dataclasses import dataclass\n-from typing import Any, Union\n+from typing import Any\n \n \n @dataclass\n@@ -49,7 +49,7 @@ def from_dict(cls, config_dict, **kwargs):\n         return config\n \n     # Copied from transformers.utils.quantization_config.QuantizationConfigMixin.to_json_file\n-    def to_json_file(self, json_file_path: Union[str, os.PathLike]):\n+    def to_json_file(self, json_file_path: str | os.PathLike):\n         \"\"\"\n         Save this instance to a JSON file.\n         Args:"
        },
        {
            "sha": "2aa942a55b4a9b304fcca9ad30fced0bc5d9f102",
            "filename": "src/transformers/pipelines/audio_classification.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Faudio_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Faudio_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Faudio_classification.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n import subprocess\n-from typing import Any, Union\n+from typing import Any\n \n import httpx\n import numpy as np\n@@ -105,7 +105,7 @@ def __init__(self, *args, **kwargs):\n \n         self.check_model_type(MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES)\n \n-    def __call__(self, inputs: Union[np.ndarray, bytes, str, dict], **kwargs: Any) -> list[dict[str, Any]]:\n+    def __call__(self, inputs: np.ndarray | bytes | str | dict, **kwargs: Any) -> list[dict[str, Any]]:\n         \"\"\"\n         Classify the sequence(s) given as inputs. See the [`AutomaticSpeechRecognitionPipeline`] documentation for more\n         information."
        },
        {
            "sha": "75869b86ae0e5649673d68d889a90b42113f9651",
            "filename": "src/transformers/pipelines/audio_utils.py",
            "status": "modified",
            "additions": 6,
            "deletions": 7,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Faudio_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Faudio_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Faudio_utils.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -2,7 +2,6 @@\n import datetime\n import platform\n import subprocess\n-from typing import Optional, Union\n \n import numpy as np\n \n@@ -50,8 +49,8 @@ def ffmpeg_microphone(\n     sampling_rate: int,\n     chunk_length_s: float,\n     format_for_conversion: str = \"f32le\",\n-    ffmpeg_input_device: Optional[str] = None,\n-    ffmpeg_additional_args: Optional[list[str]] = None,\n+    ffmpeg_input_device: str | None = None,\n+    ffmpeg_additional_args: list[str] | None = None,\n ):\n     \"\"\"\n     Helper function to read audio from a microphone using ffmpeg. The default input device will be used unless another\n@@ -134,11 +133,11 @@ def ffmpeg_microphone(\n def ffmpeg_microphone_live(\n     sampling_rate: int,\n     chunk_length_s: float,\n-    stream_chunk_s: Optional[int] = None,\n-    stride_length_s: Optional[Union[tuple[float, float], float]] = None,\n+    stream_chunk_s: int | None = None,\n+    stride_length_s: tuple[float, float] | float | None = None,\n     format_for_conversion: str = \"f32le\",\n-    ffmpeg_input_device: Optional[str] = None,\n-    ffmpeg_additional_args: Optional[list[str]] = None,\n+    ffmpeg_input_device: str | None = None,\n+    ffmpeg_additional_args: list[str] | None = None,\n ):\n     \"\"\"\n     Helper function to read audio from a microphone using ffmpeg. This will output `partial` overlapping chunks starting"
        },
        {
            "sha": "37034ad94f94728e57258a664a53bdec8e2baa35",
            "filename": "src/transformers/pipelines/automatic_speech_recognition.py",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fautomatic_speech_recognition.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fautomatic_speech_recognition.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fautomatic_speech_recognition.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n from collections import defaultdict\n-from typing import TYPE_CHECKING, Any, Optional, Union\n+from typing import TYPE_CHECKING, Any, Union\n \n import httpx\n import numpy as np\n@@ -187,10 +187,10 @@ class AutomaticSpeechRecognitionPipeline(ChunkPipeline):\n     def __init__(\n         self,\n         model: \"PreTrainedModel\",\n-        feature_extractor: Optional[Union[\"SequenceFeatureExtractor\", str]] = None,\n-        tokenizer: Optional[PreTrainedTokenizer] = None,\n-        decoder: Optional[Union[\"BeamSearchDecoderCTC\", str]] = None,\n-        device: Optional[Union[int, \"torch.device\"]] = None,\n+        feature_extractor: Union[\"SequenceFeatureExtractor\", str] | None = None,\n+        tokenizer: PreTrainedTokenizer | None = None,\n+        decoder: Union[\"BeamSearchDecoderCTC\", str] | None = None,\n+        device: Union[int, \"torch.device\"] | None = None,\n         **kwargs,\n     ):\n         # set the model type so we can check we have the right pre- and post-processing parameters\n@@ -210,7 +210,7 @@ def __init__(\n \n         super().__init__(model, tokenizer, feature_extractor, device=device, **kwargs)\n \n-    def __call__(self, inputs: Union[np.ndarray, bytes, str, dict], **kwargs: Any) -> list[dict[str, Any]]:\n+    def __call__(self, inputs: np.ndarray | bytes | str | dict, **kwargs: Any) -> list[dict[str, Any]]:\n         \"\"\"\n         Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\n         documentation for more information.\n@@ -577,7 +577,7 @@ def _forward(self, model_inputs, return_timestamps=False, **generate_kwargs):\n         return {\"is_last\": is_last, **out, **extra}\n \n     def postprocess(\n-        self, model_outputs, decoder_kwargs: Optional[dict] = None, return_timestamps=None, return_language=None\n+        self, model_outputs, decoder_kwargs: dict | None = None, return_timestamps=None, return_language=None\n     ):\n         # Optional return types\n         optional = {}"
        },
        {
            "sha": "03ee70673d6cecf8a0e710bf66db8d7cfc06727e",
            "filename": "src/transformers/pipelines/depth_estimation.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fdepth_estimation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fdepth_estimation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fdepth_estimation.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -65,7 +65,7 @@ def __call__(self, inputs: list[Union[str, \"Image.Image\"]], **kwargs: Any) -> li\n \n     def __call__(\n         self, inputs: Union[str, list[str], \"Image.Image\", list[\"Image.Image\"]], **kwargs: Any\n-    ) -> Union[dict[str, Any], list[dict[str, Any]]]:\n+    ) -> dict[str, Any] | list[dict[str, Any]]:\n         \"\"\"\n         Predict the depth(s) of the image(s) passed as inputs.\n "
        },
        {
            "sha": "6feb678b1f98335a6af32437892919b898eaaf9a",
            "filename": "src/transformers/pipelines/document_question_answering.py",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fdocument_question_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fdocument_question_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fdocument_question_answering.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -13,7 +13,7 @@\n # limitations under the License.\n \n import re\n-from typing import Any, Optional, Union, overload\n+from typing import Any, Union, overload\n \n import numpy as np\n \n@@ -60,7 +60,7 @@ def normalize_box(box, width, height):\n     ]\n \n \n-def apply_tesseract(image: \"Image.Image\", lang: Optional[str], tesseract_config: Optional[str]):\n+def apply_tesseract(image: \"Image.Image\", lang: str | None, tesseract_config: str | None):\n     \"\"\"Applies Tesseract OCR on a document image, and returns recognized words + normalized bounding boxes.\"\"\"\n     # apply OCR\n     data = pytesseract.image_to_data(image, lang=lang, output_type=\"dict\", config=tesseract_config)\n@@ -168,8 +168,8 @@ def _sanitize_parameters(\n         padding=None,\n         doc_stride=None,\n         max_question_len=None,\n-        lang: Optional[str] = None,\n-        tesseract_config: Optional[str] = None,\n+        lang: str | None = None,\n+        tesseract_config: str | None = None,\n         max_answer_len=None,\n         max_seq_len=None,\n         top_k=None,\n@@ -218,7 +218,7 @@ def __call__(\n         self,\n         image: Union[\"Image.Image\", str],\n         question: str,\n-        word_boxes: Optional[tuple[str, list[float]]] = None,\n+        word_boxes: tuple[str, list[float]] | None = None,\n         **kwargs: Any,\n     ) -> list[dict[str, Any]]: ...\n \n@@ -231,10 +231,10 @@ def __call__(self, image: list[dict[str, Any]], **kwargs: Any) -> list[list[dict\n     def __call__(\n         self,\n         image: Union[\"Image.Image\", str, list[dict[str, Any]]],\n-        question: Optional[str] = None,\n-        word_boxes: Optional[tuple[str, list[float]]] = None,\n+        question: str | None = None,\n+        word_boxes: tuple[str, list[float]] | None = None,\n         **kwargs: Any,\n-    ) -> Union[dict[str, Any], list[dict[str, Any]]]:\n+    ) -> dict[str, Any] | list[dict[str, Any]]:\n         \"\"\"\n         Answer the question(s) given as inputs by using the document(s). A document is defined as an image and an\n         optional list of (word, box) tuples which represent the text in the document. If the `word_boxes` are not\n@@ -313,7 +313,7 @@ def preprocess(\n         padding=\"do_not_pad\",\n         doc_stride=None,\n         max_seq_len=None,\n-        word_boxes: Optional[tuple[str, list[float]]] = None,\n+        word_boxes: tuple[str, list[float]] | None = None,\n         lang=None,\n         tesseract_config=\"\",\n         timeout=None,"
        },
        {
            "sha": "a37f147605f04347efa34f587d7fdebe8074f3b5",
            "filename": "src/transformers/pipelines/feature_extraction.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Ffeature_extraction.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Ffeature_extraction.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ffeature_extraction.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -1,4 +1,4 @@\n-from typing import Any, Union\n+from typing import Any\n \n from ..utils import add_end_docstrings\n from .base import GenericTensor, Pipeline, build_pipeline_init_args\n@@ -75,7 +75,7 @@ def postprocess(self, model_outputs, return_tensors=False):\n             return model_outputs[0]\n         return model_outputs[0].tolist()\n \n-    def __call__(self, *args: Union[str, list[str]], **kwargs: Any) -> Union[Any, list[Any]]:\n+    def __call__(self, *args: str | list[str], **kwargs: Any) -> Any | list[Any]:\n         \"\"\"\n         Extract the features of the input(s) text.\n "
        },
        {
            "sha": "1ea7c487be76458ff66508a6506bc11437937cb1",
            "filename": "src/transformers/pipelines/fill_mask.py",
            "status": "modified",
            "additions": 2,
            "deletions": 4,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Ffill_mask.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Ffill_mask.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ffill_mask.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -1,4 +1,4 @@\n-from typing import Any, Union, overload\n+from typing import Any, overload\n \n import numpy as np\n \n@@ -231,9 +231,7 @@ def __call__(self, inputs: str, **kwargs: Any) -> list[dict[str, Any]]: ...\n     @overload\n     def __call__(self, inputs: list[str], **kwargs: Any) -> list[list[dict[str, Any]]]: ...\n \n-    def __call__(\n-        self, inputs: Union[str, list[str]], **kwargs: Any\n-    ) -> Union[list[dict[str, Any]], list[list[dict[str, Any]]]]:\n+    def __call__(self, inputs: str | list[str], **kwargs: Any) -> list[dict[str, Any]] | list[list[dict[str, Any]]]:\n         \"\"\"\n         Fill the masked token in the text(s) given as inputs.\n "
        },
        {
            "sha": "18a570df6e21f8e7ebd15d7771408cf324e306de",
            "filename": "src/transformers/pipelines/image_classification.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fimage_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fimage_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fimage_classification.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -122,11 +122,11 @@ def _sanitize_parameters(self, top_k=None, function_to_apply=None, timeout=None)\n     def __call__(self, inputs: Union[str, \"Image.Image\"], **kwargs: Any) -> list[dict[str, Any]]: ...\n \n     @overload\n-    def __call__(self, inputs: Union[list[str], list[\"Image.Image\"]], **kwargs: Any) -> list[list[dict[str, Any]]]: ...\n+    def __call__(self, inputs: list[str] | list[\"Image.Image\"], **kwargs: Any) -> list[list[dict[str, Any]]]: ...\n \n     def __call__(\n         self, inputs: Union[str, list[str], \"Image.Image\", list[\"Image.Image\"]], **kwargs: Any\n-    ) -> Union[list[dict[str, Any]], list[list[dict[str, Any]]]]:\n+    ) -> list[dict[str, Any]] | list[list[dict[str, Any]]]:\n         \"\"\"\n         Assign labels to the image(s) passed as inputs.\n "
        },
        {
            "sha": "49854beb5a40b1c3017febba20b72678e81b9374",
            "filename": "src/transformers/pipelines/image_segmentation.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fimage_segmentation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fimage_segmentation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fimage_segmentation.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -96,11 +96,11 @@ def _sanitize_parameters(self, **kwargs):\n     def __call__(self, inputs: Union[str, \"Image.Image\"], **kwargs: Any) -> list[dict[str, Any]]: ...\n \n     @overload\n-    def __call__(self, inputs: Union[list[str], list[\"Image.Image\"]], **kwargs: Any) -> list[list[dict[str, Any]]]: ...\n+    def __call__(self, inputs: list[str] | list[\"Image.Image\"], **kwargs: Any) -> list[list[dict[str, Any]]]: ...\n \n     def __call__(\n         self, inputs: Union[str, \"Image.Image\", list[str], list[\"Image.Image\"]], **kwargs: Any\n-    ) -> Union[list[dict[str, Any]], list[list[dict[str, Any]]]]:\n+    ) -> list[dict[str, Any]] | list[list[dict[str, Any]]]:\n         \"\"\"\n         Perform segmentation (detect masks & classes) in the image(s) passed as inputs.\n "
        },
        {
            "sha": "7e795d9c91b3ffd93f9c2296ed1f18d4604c11d5",
            "filename": "src/transformers/pipelines/image_text_to_text.py",
            "status": "modified",
            "additions": 13,
            "deletions": 22,
            "changes": 35,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fimage_text_to_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fimage_text_to_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fimage_text_to_text.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -15,7 +15,7 @@\n \n import enum\n from collections.abc import Iterable\n-from typing import Any, Optional, Union, overload\n+from typing import Any, Union, overload\n \n from ..generation import GenerationConfig\n from ..processing_utils import ProcessingKwargs, Unpack\n@@ -56,7 +56,7 @@ class Chat:\n     actually a batch of samples rather than messages in the same conversation.\"\"\"\n \n     def __init__(\n-        self, messages: dict, images: Optional[Union[str, list[str], \"Image.Image\", list[\"Image.Image\"]]] = None\n+        self, messages: dict, images: Union[str, list[str], \"Image.Image\", list[\"Image.Image\"]] | None = None\n     ):\n         for message in messages:\n             if not (\"role\" in message and \"content\" in message):\n@@ -66,9 +66,7 @@ def __init__(\n         self.messages = messages\n \n \n-def add_images_to_messages(\n-    messages: dict, images: Optional[Union[str, list[str], \"Image.Image\", list[\"Image.Image\"]]]\n-):\n+def add_images_to_messages(messages: dict, images: Union[str, list[str], \"Image.Image\", list[\"Image.Image\"]] | None):\n     \"\"\"\n     Retrieve and combine images from the chat and the images passed as input.\n     \"\"\"\n@@ -261,35 +259,28 @@ def _sanitize_parameters(\n     @overload\n     def __call__(\n         self,\n-        image: Optional[Union[str, \"Image.Image\"]] = None,\n-        text: Optional[str] = None,\n+        image: Union[str, \"Image.Image\"] | None = None,\n+        text: str | None = None,\n         **kwargs: Any,\n     ) -> list[dict[str, Any]]: ...\n \n     @overload\n     def __call__(\n         self,\n-        image: Optional[Union[list[str], list[\"Image.Image\"]]] = None,\n-        text: Optional[list[str]] = None,\n+        image: list[str] | list[\"Image.Image\"] | None = None,\n+        text: list[str] | None = None,\n         **kwargs: Any,\n     ) -> list[list[dict[str, Any]]]: ...\n \n     def __call__(\n         self,\n-        images: Optional[\n-            Union[\n-                str,\n-                list[str],\n-                list[list[str]],\n-                \"Image.Image\",\n-                list[\"Image.Image\"],\n-                list[list[\"Image.Image\"]],\n-                list[dict],\n-            ]\n-        ] = None,\n-        text: Optional[Union[str, list[str], list[dict]]] = None,\n+        images: Union[\n+            str, list[str], list[list[str]], \"Image.Image\", list[\"Image.Image\"], list[list[\"Image.Image\"]], list[dict]\n+        ]\n+        | None = None,\n+        text: str | list[str] | list[dict] | None = None,\n         **kwargs,\n-    ) -> Union[list[dict[str, Any]], list[list[dict[str, Any]]]]:\n+    ) -> list[dict[str, Any]] | list[list[dict[str, Any]]]:\n         \"\"\"\n         Generate a text given text and the image(s) passed as inputs.\n "
        },
        {
            "sha": "d48321b8028016cd9acb0de6796792c50cd60ab2",
            "filename": "src/transformers/pipelines/image_to_image.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fimage_to_image.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fimage_to_image.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fimage_to_image.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -92,7 +92,7 @@ def _sanitize_parameters(self, **kwargs):\n     def __call__(self, images: Union[str, \"Image.Image\"], **kwargs: Any) -> \"Image.Image\": ...\n \n     @overload\n-    def __call__(self, images: Union[list[str], list[\"Image.Image\"]], **kwargs: Any) -> list[\"Image.Image\"]: ...\n+    def __call__(self, images: list[str] | list[\"Image.Image\"], **kwargs: Any) -> list[\"Image.Image\"]: ...\n \n     def __call__(\n         self, images: Union[str, list[str], \"Image.Image\", list[\"Image.Image\"]], **kwargs: Any"
        },
        {
            "sha": "53f92e7c0de67883564e81318be817817e78046c",
            "filename": "src/transformers/pipelines/image_to_text.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fimage_to_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fimage_to_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fimage_to_text.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -113,7 +113,7 @@ def _sanitize_parameters(self, max_new_tokens=None, generate_kwargs=None, prompt\n     def __call__(self, inputs: Union[str, \"Image.Image\"], **kwargs: Any) -> list[dict[str, Any]]: ...\n \n     @overload\n-    def __call__(self, inputs: Union[list[str], list[\"Image.Image\"]], **kwargs: Any) -> list[list[dict[str, Any]]]: ...\n+    def __call__(self, inputs: list[str] | list[\"Image.Image\"], **kwargs: Any) -> list[list[dict[str, Any]]]: ...\n \n     def __call__(self, inputs: Union[str, list[str], \"Image.Image\", list[\"Image.Image\"]], **kwargs):\n         \"\"\""
        },
        {
            "sha": "d75656a7db3b301476faf02401c0a5df5d2c5691",
            "filename": "src/transformers/pipelines/keypoint_matching.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fkeypoint_matching.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fkeypoint_matching.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fkeypoint_matching.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -97,10 +97,10 @@ def __call__(self, inputs: list[ImagePair], threshold: float = 0.0, **kwargs: An\n \n     def __call__(\n         self,\n-        inputs: Union[list[ImagePair], ImagePair],\n+        inputs: list[ImagePair] | ImagePair,\n         threshold: float = 0.0,\n         **kwargs: Any,\n-    ) -> Union[list[Match], list[list[Match]]]:\n+    ) -> list[Match] | list[list[Match]]:\n         \"\"\"\n         Find matches between keypoints in two images.\n "
        },
        {
            "sha": "0f520536473b44326d5014a3a1eb74677fd41316",
            "filename": "src/transformers/pipelines/mask_generation.py",
            "status": "modified",
            "additions": 4,
            "deletions": 6,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fmask_generation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fmask_generation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fmask_generation.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -1,5 +1,5 @@\n from collections import defaultdict\n-from typing import TYPE_CHECKING, Any, Optional, Union, overload\n+from typing import TYPE_CHECKING, Any, Union, overload\n \n from ..image_utils import load_image\n from ..utils import (\n@@ -138,13 +138,11 @@ def _sanitize_parameters(self, **kwargs):\n     def __call__(self, image: Union[str, \"Image.Image\"], *args: Any, **kwargs: Any) -> dict[str, Any]: ...\n \n     @overload\n-    def __call__(\n-        self, image: Union[list[str], list[\"Image.Image\"]], *args: Any, **kwargs: Any\n-    ) -> list[dict[str, Any]]: ...\n+    def __call__(self, image: list[str] | list[\"Image.Image\"], *args: Any, **kwargs: Any) -> list[dict[str, Any]]: ...\n \n     def __call__(\n         self, image: Union[str, \"Image.Image\", list[str], list[\"Image.Image\"]], *args: Any, **kwargs: Any\n-    ) -> Union[dict[str, Any], list[dict[str, Any]]]:\n+    ) -> dict[str, Any] | list[dict[str, Any]]:\n         \"\"\"\n         Generates binary segmentation masks\n \n@@ -194,7 +192,7 @@ def preprocess(\n         crop_overlap_ratio: float = 512 / 1500,\n         points_per_crop: int = 32,\n         crop_n_points_downscale_factor: int = 1,\n-        timeout: Optional[float] = None,\n+        timeout: float | None = None,\n     ):\n         image = load_image(image, timeout=timeout)\n         target_size = self.image_processor.size.get(\"longest_edge\", self.image_processor.size.get(\"height\"))"
        },
        {
            "sha": "0a4fba996d7d364283371c17e9cf6adbc43d0c23",
            "filename": "src/transformers/pipelines/object_detection.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fobject_detection.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fobject_detection.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fobject_detection.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -75,10 +75,10 @@ def __call__(self, image: Union[str, \"Image.Image\"], *args: Any, **kwargs: Any)\n \n     @overload\n     def __call__(\n-        self, image: Union[list[str], list[\"Image.Image\"]], *args: Any, **kwargs: Any\n+        self, image: list[str] | list[\"Image.Image\"], *args: Any, **kwargs: Any\n     ) -> list[list[dict[str, Any]]]: ...\n \n-    def __call__(self, *args, **kwargs) -> Union[list[dict[str, Any]], list[list[dict[str, Any]]]]:\n+    def __call__(self, *args, **kwargs) -> list[dict[str, Any]] | list[list[dict[str, Any]]]:\n         \"\"\"\n         Detect objects (bounding boxes & classes) in the image(s) passed as inputs.\n "
        },
        {
            "sha": "e94604b6469fafe6448afa4cd2bc690e89ae05ee",
            "filename": "src/transformers/pipelines/question_answering.py",
            "status": "modified",
            "additions": 5,
            "deletions": 7,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fquestion_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fquestion_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fquestion_answering.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -2,7 +2,7 @@\n import types\n import warnings\n from collections.abc import Iterable\n-from typing import TYPE_CHECKING, Optional, Union\n+from typing import TYPE_CHECKING\n \n import numpy as np\n \n@@ -259,7 +259,7 @@ def __init__(\n         self,\n         model: \"PreTrainedModel\",\n         tokenizer: PreTrainedTokenizer,\n-        modelcard: Optional[ModelCard] = None,\n+        modelcard: ModelCard | None = None,\n         task: str = \"\",\n         **kwargs,\n     ):\n@@ -275,9 +275,7 @@ def __init__(\n         self.check_model_type(MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES)\n \n     @staticmethod\n-    def create_sample(\n-        question: Union[str, list[str]], context: Union[str, list[str]]\n-    ) -> Union[SquadExample, list[SquadExample]]:\n+    def create_sample(question: str | list[str], context: str | list[str]) -> SquadExample | list[SquadExample]:\n         \"\"\"\n         QuestionAnsweringPipeline leverages the [`SquadExample`] internally. This helper method encapsulate all the\n         logic for converting question(s) and context(s) to [`SquadExample`].\n@@ -619,7 +617,7 @@ def postprocess(\n             return answers[0]\n         return answers\n \n-    def get_answer(self, answers: list[dict], target: str) -> Optional[dict]:\n+    def get_answer(self, answers: list[dict], target: str) -> dict | None:\n         for answer in answers:\n             if answer[\"answer\"].lower() == target.lower():\n                 return answer\n@@ -643,7 +641,7 @@ def get_indices(\n             end_index = enc.offsets[e][1]\n         return start_index, end_index\n \n-    def span_to_answer(self, text: str, start: int, end: int) -> dict[str, Union[str, int]]:\n+    def span_to_answer(self, text: str, start: int, end: int) -> dict[str, str | int]:\n         \"\"\"\n         When decoding from token probabilities, this method maps token indexes to actual word in the initial context.\n "
        },
        {
            "sha": "2e9e616914427b30cf74a51a1e42207be2b43a6a",
            "filename": "src/transformers/pipelines/text2text_generation.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Ftext2text_generation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Ftext2text_generation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftext2text_generation.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -1,6 +1,6 @@\n import enum\n import warnings\n-from typing import Any, Union\n+from typing import Any\n \n from ..generation import GenerationConfig\n from ..tokenization_utils import TruncationStrategy\n@@ -150,7 +150,7 @@ def _parse_and_tokenize(self, *args, truncation):\n             del inputs[\"token_type_ids\"]\n         return inputs\n \n-    def __call__(self, *args: Union[str, list[str]], **kwargs: Any) -> list[dict[str, str]]:\n+    def __call__(self, *args: str | list[str], **kwargs: Any) -> list[dict[str, str]]:\n         r\"\"\"\n         Generate the output text(s) using text(s) given as inputs.\n "
        },
        {
            "sha": "1dc720154e8474c5015b128fb22a842c26b15494",
            "filename": "src/transformers/pipelines/text_classification.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Ftext_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Ftext_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftext_classification.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -1,6 +1,6 @@\n import inspect\n import warnings\n-from typing import Any, Union\n+from typing import Any\n \n import numpy as np\n \n@@ -120,7 +120,7 @@ def _sanitize_parameters(self, return_all_scores=None, function_to_apply=None, t\n \n     def __call__(\n         self,\n-        inputs: Union[str, list[str], dict[str, str], list[dict[str, str]]],\n+        inputs: str | list[str] | dict[str, str] | list[dict[str, str]],\n         **kwargs: Any,\n     ) -> list[dict[str, Any]]:\n         \"\"\""
        },
        {
            "sha": "99334eff468a81b4dbd810ffb2465c81886fa429",
            "filename": "src/transformers/pipelines/text_to_audio.py",
            "status": "modified",
            "additions": 2,
            "deletions": 4,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -11,7 +11,7 @@\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.from typing import List, Union\n-from typing import Any, Union, overload\n+from typing import Any, overload\n \n from ..generation import GenerationConfig\n from ..utils import is_torch_available\n@@ -193,9 +193,7 @@ def __call__(self, text_inputs: str, **forward_params: Any) -> dict[str, Any]: .\n     @overload\n     def __call__(self, text_inputs: list[str], **forward_params: Any) -> list[dict[str, Any]]: ...\n \n-    def __call__(\n-        self, text_inputs: Union[str, list[str]], **forward_params\n-    ) -> Union[dict[str, Any], list[dict[str, Any]]]:\n+    def __call__(self, text_inputs: str | list[str], **forward_params) -> dict[str, Any] | list[dict[str, Any]]:\n         \"\"\"\n         Generates speech/audio from the inputs. See the [`TextToAudioPipeline`] documentation for more information.\n "
        },
        {
            "sha": "412c11c875b30a69db574c1820128609d53aeedf",
            "filename": "src/transformers/pipelines/token_classification.py",
            "status": "modified",
            "additions": 12,
            "deletions": 14,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Ftoken_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Ftoken_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftoken_classification.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -1,6 +1,6 @@\n import types\n import warnings\n-from typing import Any, Optional, Union, overload\n+from typing import Any, overload\n \n import numpy as np\n \n@@ -24,7 +24,7 @@ class TokenClassificationArgumentHandler(ArgumentHandler):\n     Handles arguments for token classification.\n     \"\"\"\n \n-    def __call__(self, inputs: Union[str, list[str]], **kwargs):\n+    def __call__(self, inputs: str | list[str], **kwargs):\n         is_split_into_words = kwargs.get(\"is_split_into_words\", False)\n         delimiter = kwargs.get(\"delimiter\")\n \n@@ -147,13 +147,13 @@ def __init__(self, args_parser=TokenClassificationArgumentHandler(), **kwargs):\n     def _sanitize_parameters(\n         self,\n         ignore_labels=None,\n-        grouped_entities: Optional[bool] = None,\n-        ignore_subwords: Optional[bool] = None,\n-        aggregation_strategy: Optional[AggregationStrategy] = None,\n-        offset_mapping: Optional[list[tuple[int, int]]] = None,\n+        grouped_entities: bool | None = None,\n+        ignore_subwords: bool | None = None,\n+        aggregation_strategy: AggregationStrategy | None = None,\n+        offset_mapping: list[tuple[int, int]] | None = None,\n         is_split_into_words: bool = False,\n-        stride: Optional[int] = None,\n-        delimiter: Optional[str] = None,\n+        stride: int | None = None,\n+        delimiter: str | None = None,\n     ):\n         preprocess_params = {}\n         preprocess_params[\"is_split_into_words\"] = is_split_into_words\n@@ -230,9 +230,7 @@ def __call__(self, inputs: str, **kwargs: Any) -> list[dict[str, str]]: ...\n     @overload\n     def __call__(self, inputs: list[str], **kwargs: Any) -> list[list[dict[str, str]]]: ...\n \n-    def __call__(\n-        self, inputs: Union[str, list[str]], **kwargs: Any\n-    ) -> Union[list[dict[str, str]], list[list[dict[str, str]]]]:\n+    def __call__(self, inputs: str | list[str], **kwargs: Any) -> list[dict[str, str]] | list[list[dict[str, str]]]:\n         \"\"\"\n         Classify each token of the text(s) given as inputs.\n \n@@ -425,11 +423,11 @@ def gather_pre_entities(\n         sentence: str,\n         input_ids: np.ndarray,\n         scores: np.ndarray,\n-        offset_mapping: Optional[list[tuple[int, int]]],\n+        offset_mapping: list[tuple[int, int]] | None,\n         special_tokens_mask: np.ndarray,\n         aggregation_strategy: AggregationStrategy,\n-        word_ids: Optional[list[Optional[int]]] = None,\n-        word_to_chars_map: Optional[list[tuple[int, int]]] = None,\n+        word_ids: list[int | None] | None = None,\n+        word_to_chars_map: list[tuple[int, int]] | None = None,\n     ) -> list[dict]:\n         \"\"\"Fuse various numpy arrays into dicts with all the information needed for aggregation\"\"\"\n         pre_entities = []"
        },
        {
            "sha": "9d8266b0ac05ba62b281304ab0c2cc52d3cda58c",
            "filename": "src/transformers/pipelines/video_classification.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fvideo_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fvideo_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fvideo_classification.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -13,7 +13,7 @@\n # limitations under the License.\n import warnings\n from io import BytesIO\n-from typing import Any, Optional, Union, overload\n+from typing import Any, overload\n \n import httpx\n \n@@ -88,7 +88,7 @@ def __call__(self, inputs: str, **kwargs: Any) -> list[dict[str, Any]]: ...\n     @overload\n     def __call__(self, inputs: list[str], **kwargs: Any) -> list[list[dict[str, Any]]]: ...\n \n-    def __call__(self, inputs: Optional[Union[str, list[str]]] = None, **kwargs):\n+    def __call__(self, inputs: str | list[str] | None = None, **kwargs):\n         \"\"\"\n         Assign labels to the video(s) passed as inputs.\n "
        },
        {
            "sha": "721b0b60e8d897d9240f75a17da2f99e8cac7865",
            "filename": "src/transformers/pipelines/visual_question_answering.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fvisual_question_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fvisual_question_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fvisual_question_answering.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -1,4 +1,4 @@\n-from typing import Optional, Union\n+from typing import Union\n \n from ..generation import GenerationConfig\n from ..utils import add_end_docstrings, is_torch_available, is_vision_available, logging\n@@ -95,7 +95,7 @@ def _sanitize_parameters(self, top_k=None, padding=None, truncation=None, timeou\n     def __call__(\n         self,\n         image: Union[\"Image.Image\", str, list[\"Image.Image\"], list[str], \"KeyDataset\"],\n-        question: Optional[Union[str, list[str]]] = None,\n+        question: str | list[str] | None = None,\n         **kwargs,\n     ):\n         r\"\"\""
        },
        {
            "sha": "fe674f024987d0d8d7b6d3336ddc484942da1925",
            "filename": "src/transformers/pipelines/zero_shot_audio_classification.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fzero_shot_audio_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fzero_shot_audio_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fzero_shot_audio_classification.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -13,7 +13,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n from collections import UserDict\n-from typing import Any, Union\n+from typing import Any\n \n import httpx\n import numpy as np\n@@ -68,7 +68,7 @@ class ZeroShotAudioClassificationPipeline(Pipeline):\n     def __init__(self, **kwargs):\n         super().__init__(**kwargs)\n \n-    def __call__(self, audios: Union[np.ndarray, bytes, str, dict], **kwargs: Any) -> list[dict[str, Any]]:\n+    def __call__(self, audios: np.ndarray | bytes | str | dict, **kwargs: Any) -> list[dict[str, Any]]:\n         \"\"\"\n         Assign labels to the audio(s) passed as inputs.\n "
        },
        {
            "sha": "3eca4ea4eb9c651a5a31019fb782937097ae5d8a",
            "filename": "src/transformers/pipelines/zero_shot_classification.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fzero_shot_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fzero_shot_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fzero_shot_classification.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -1,5 +1,4 @@\n import inspect\n-from typing import Union\n \n import numpy as np\n \n@@ -165,7 +164,7 @@ def _sanitize_parameters(self, **kwargs):\n \n     def __call__(\n         self,\n-        sequences: Union[str, list[str]],\n+        sequences: str | list[str],\n         *args,\n         **kwargs,\n     ):"
        },
        {
            "sha": "fa26ec4f2d03561d52c13b3116656035137fe1d8",
            "filename": "src/transformers/pipelines/zero_shot_image_classification.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fzero_shot_image_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fzero_shot_image_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fzero_shot_image_classification.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -78,15 +78,15 @@ def __call__(\n \n     @overload\n     def __call__(\n-        self, image: Union[list[str], list[\"Image.Image\"]], candidate_labels: list[str], **kwargs: Any\n+        self, image: list[str] | list[\"Image.Image\"], candidate_labels: list[str], **kwargs: Any\n     ) -> list[list[dict[str, Any]]]: ...\n \n     def __call__(\n         self,\n         image: Union[str, list[str], \"Image.Image\", list[\"Image.Image\"]],\n         candidate_labels: list[str],\n         **kwargs: Any,\n-    ) -> Union[list[dict[str, Any]], list[list[dict[str, Any]]]]:\n+    ) -> list[dict[str, Any]] | list[list[dict[str, Any]]]:\n         \"\"\"\n         Assign labels to the image(s) passed as inputs.\n "
        },
        {
            "sha": "7f353afd7499e100353bd450293fd174183a0e13",
            "filename": "src/transformers/pipelines/zero_shot_object_detection.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fzero_shot_object_detection.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Fpipelines%2Fzero_shot_object_detection.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fzero_shot_object_detection.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -1,4 +1,4 @@\n-from typing import Any, Optional, Union, overload\n+from typing import Any, Union, overload\n \n from ..utils import add_end_docstrings, is_torch_available, is_vision_available, logging, requires_backends\n from .base import ChunkPipeline, build_pipeline_init_args\n@@ -66,7 +66,7 @@ def __init__(self, **kwargs):\n \n     @overload\n     def __call__(\n-        self, image: Union[str, \"Image.Image\"], candidate_labels: Union[str, list[str]], **kwargs: Any\n+        self, image: Union[str, \"Image.Image\"], candidate_labels: str | list[str], **kwargs: Any\n     ) -> list[dict[str, Any]]: ...\n \n     @overload\n@@ -75,9 +75,9 @@ def __call__(self, image: list[dict[str, Any]], **kwargs: Any) -> list[list[dict\n     def __call__(\n         self,\n         image: Union[str, \"Image.Image\", list[dict[str, Any]]],\n-        candidate_labels: Optional[Union[str, list[str]]] = None,\n+        candidate_labels: str | list[str] | None = None,\n         **kwargs: Any,\n-    ) -> Union[list[dict[str, Any]], list[list[dict[str, Any]]]]:\n+    ) -> list[dict[str, Any]] | list[list[dict[str, Any]]]:\n         \"\"\"\n         Detect objects (bounding boxes & classes) in the image(s) passed as inputs.\n "
        },
        {
            "sha": "d68317e6c903e1ff4f614f1c093629b622ad47d5",
            "filename": "src/transformers/utils/auto_docstring.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fauto_docstring.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fauto_docstring.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fauto_docstring.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -17,7 +17,7 @@\n import os\n import textwrap\n from pathlib import Path\n-from typing import Optional, Union, get_args\n+from typing import get_args\n \n import regex as re\n \n@@ -1084,7 +1084,7 @@ def parse_docstring(docstring, max_indent_level=0, return_intro=False):\n     return params, remainder_docstring\n \n \n-def contains_type(type_hint, target_type) -> tuple[bool, Optional[object]]:\n+def contains_type(type_hint, target_type) -> tuple[bool, object | None]:\n     \"\"\"\n     Check if a \"nested\" type hint contains a specific target type,\n     return the first-level type containing the target_type if found.\n@@ -1173,7 +1173,7 @@ def format_args_docstring(docstring, model_name):\n     return docstring\n \n \n-def get_args_doc_from_source(args_classes: Union[object, list[object]]) -> dict:\n+def get_args_doc_from_source(args_classes: object | list[object]) -> dict:\n     if isinstance(args_classes, (list, tuple)):\n         args_classes_dict = {}\n         for args_class in args_classes:"
        },
        {
            "sha": "8580aecf7a2bab993e8566c063a04a3276f97a4d",
            "filename": "src/transformers/utils/backbone_utils.py",
            "status": "modified",
            "additions": 15,
            "deletions": 15,
            "changes": 30,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fbackbone_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fbackbone_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fbackbone_utils.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -17,7 +17,7 @@\n import enum\n import inspect\n from collections.abc import Iterable\n-from typing import TYPE_CHECKING, Optional, Union\n+from typing import TYPE_CHECKING, Union\n \n \n if TYPE_CHECKING:\n@@ -30,7 +30,7 @@ class BackboneType(enum.Enum):\n \n \n def verify_out_features_out_indices(\n-    out_features: Optional[Iterable[str]], out_indices: Optional[Iterable[int]], stage_names: Optional[Iterable[str]]\n+    out_features: Iterable[str] | None, out_indices: Iterable[int] | None, stage_names: Iterable[str] | None\n ):\n     \"\"\"\n     Verify that out_indices and out_features are valid for the given stage_names.\n@@ -75,8 +75,8 @@ def verify_out_features_out_indices(\n \n \n def _align_output_features_output_indices(\n-    out_features: Optional[list[str]],\n-    out_indices: Optional[Union[list[int], tuple[int, ...]]],\n+    out_features: list[str] | None,\n+    out_indices: list[int] | tuple[int, ...] | None,\n     stage_names: list[str],\n ):\n     \"\"\"\n@@ -106,8 +106,8 @@ def _align_output_features_output_indices(\n \n \n def get_aligned_output_features_output_indices(\n-    out_features: Optional[list[str]],\n-    out_indices: Optional[Union[list[int], tuple[int]]],\n+    out_features: list[str] | None,\n+    out_indices: list[int] | tuple[int] | None,\n     stage_names: list[str],\n ) -> tuple[list[str], list[int]]:\n     \"\"\"\n@@ -138,7 +138,7 @@ def get_aligned_output_features_output_indices(\n \n \n class BackboneMixin:\n-    backbone_type: Optional[BackboneType] = None\n+    backbone_type: BackboneType | None = None\n \n     # Attribute to indicate if the backbone has attention and can return attention outputs.\n     # Should be set to `False` for conv-based models to be able to run `forward_with_filtered_kwargs`\n@@ -215,7 +215,7 @@ def out_indices(self):\n         return self._out_indices\n \n     @out_indices.setter\n-    def out_indices(self, out_indices: Union[tuple[int], list[int]]):\n+    def out_indices(self, out_indices: tuple[int] | list[int]):\n         \"\"\"\n         Set the out_indices attribute. This will also update the out_features attribute to match the new out_indices.\n         \"\"\"\n@@ -244,9 +244,9 @@ def forward_with_filtered_kwargs(self, *args, **kwargs):\n     def forward(\n         self,\n         pixel_values,\n-        output_hidden_states: Optional[bool] = None,\n-        output_attentions: Optional[bool] = None,\n-        return_dict: Optional[bool] = None,\n+        output_hidden_states: bool | None = None,\n+        output_attentions: bool | None = None,\n+        return_dict: bool | None = None,\n     ):\n         raise NotImplementedError(\"This method should be implemented by the derived class.\")\n \n@@ -284,7 +284,7 @@ def out_indices(self):\n         return self._out_indices\n \n     @out_indices.setter\n-    def out_indices(self, out_indices: Union[tuple[int, ...], list[int]]):\n+    def out_indices(self, out_indices: tuple[int, ...] | list[int]):\n         \"\"\"\n         Set the out_indices attribute. This will also update the out_features attribute to match the new out_indices.\n         \"\"\"\n@@ -362,9 +362,9 @@ def load_backbone(config):\n def verify_backbone_config_arguments(\n     use_timm_backbone: bool,\n     use_pretrained_backbone: bool,\n-    backbone: Optional[str],\n-    backbone_config: Optional[Union[dict, \"PreTrainedConfig\"]],\n-    backbone_kwargs: Optional[dict],\n+    backbone: str | None,\n+    backbone_config: Union[dict, \"PreTrainedConfig\"] | None,\n+    backbone_kwargs: dict | None,\n ):\n     \"\"\"\n     Verify that the config arguments to be passed to load_backbone are valid"
        },
        {
            "sha": "5df252344d23568b557481645583c4ba2de35e15",
            "filename": "src/transformers/utils/chat_template_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 5,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fchat_template_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fchat_template_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fchat_template_utils.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -25,7 +25,6 @@\n from typing import (\n     Any,\n     Literal,\n-    Optional,\n     Union,\n     get_args,\n     get_origin,\n@@ -201,7 +200,7 @@ def _convert_type_hints_to_json_schema(func: Callable) -> dict:\n     return schema\n \n \n-def parse_google_format_docstring(docstring: str) -> tuple[Optional[str], Optional[dict], Optional[str]]:\n+def parse_google_format_docstring(docstring: str) -> tuple[str | None, dict | None, str | None]:\n     \"\"\"\n     Parses a Google-style docstring to extract the function description,\n     argument descriptions, and return description.\n@@ -465,9 +464,9 @@ def strftime_now(format):\n \n def render_jinja_template(\n     conversations: list[list[dict[str, str]]],\n-    tools: Optional[list[Union[dict, Callable]]] = None,\n-    documents: Optional[list[dict[str, str]]] = None,\n-    chat_template: Optional[str] = None,\n+    tools: list[dict | Callable] | None = None,\n+    documents: list[dict[str, str]] | None = None,\n+    chat_template: str | None = None,\n     return_assistant_tokens_mask: bool = False,\n     continue_final_message: bool = False,\n     add_generation_prompt: bool = False,"
        },
        {
            "sha": "db0e67325d7811d41d1ca90f49813ed0fb803f0f",
            "filename": "src/transformers/utils/deprecation.py",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fdeprecation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fdeprecation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fdeprecation.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -14,7 +14,6 @@\n import inspect\n import warnings\n from functools import wraps\n-from typing import Optional\n \n import packaging.version\n \n@@ -37,11 +36,11 @@ class Action(ExplicitEnum):\n def deprecate_kwarg(\n     old_name: str,\n     version: str,\n-    new_name: Optional[str] = None,\n+    new_name: str | None = None,\n     warn_if_greater_or_equal_version: bool = False,\n     raise_if_greater_or_equal_version: bool = False,\n     raise_if_both_names: bool = False,\n-    additional_message: Optional[str] = None,\n+    additional_message: str | None = None,\n ):\n     \"\"\"\n     Function or method decorator to notify users about deprecated keyword arguments, replacing them with a new name if specified."
        },
        {
            "sha": "011930f72f4802aa0e6e70eed8f97436bb54710b",
            "filename": "src/transformers/utils/fx.py",
            "status": "modified",
            "additions": 11,
            "deletions": 11,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Ffx.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Ffx.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Ffx.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -24,7 +24,7 @@\n import sys\n import warnings\n from collections.abc import Callable\n-from typing import Any, Literal, Optional, Union\n+from typing import Any, Literal\n \n import torch\n import torch.utils._pytree as pytree\n@@ -77,7 +77,7 @@\n \n def _generate_supported_model_class_names(\n     model_name: type[PreTrainedConfig],\n-    supported_tasks: Optional[Union[str, list[str]]] = None,\n+    supported_tasks: str | list[str] | None = None,\n ) -> list[str]:\n     task_mapping = {\n         \"default\": MODEL_MAPPING_NAMES,\n@@ -733,8 +733,8 @@ def __class__(self):\n \n def create_wrapper(\n     function: Callable,\n-    op_type: Union[Literal[\"call_function\"], Literal[\"call_method\"], Literal[\"get_attr\"]],\n-    proxy_factory_fn: Optional[Callable[[Node], Proxy]] = None,\n+    op_type: Literal[\"call_function\"] | Literal[\"call_method\"] | Literal[\"get_attr\"],\n+    proxy_factory_fn: Callable[[Node], Proxy] | None = None,\n ) -> Callable:\n     @functools.wraps(function)\n     def wrapper(*args, **kwargs):\n@@ -775,7 +775,7 @@ def __new__(\n         name: str,\n         bases: tuple[type, ...],\n         attrs: dict[str, Any],\n-        proxy_factory_fn: Optional[Callable[[Node], Proxy]] = None,\n+        proxy_factory_fn: Callable[[Node], Proxy] | None = None,\n     ):\n         instance = super().__new__(cls, name, bases, attrs)\n         for attr_name in dir(instance):\n@@ -845,7 +845,7 @@ def cache_proxy_factory_fn(n: Node) -> HFCacheProxy:\n )\n \n \n-def _generate_random_int(low: int = 10, high: int = 20, forbidden_values: Optional[list[int]] = None):\n+def _generate_random_int(low: int = 10, high: int = 20, forbidden_values: list[int] | None = None):\n     if forbidden_values is None:\n         forbidden_values = []\n     value = random.randint(low, high)\n@@ -1184,7 +1184,7 @@ def proxy(self, node):\n         return HFProxy(node, self)\n \n     @contextlib.contextmanager\n-    def patch_for_tracing(self, root: Union[torch.nn.Module, Callable[..., Any]]):\n+    def patch_for_tracing(self, root: torch.nn.Module | Callable[..., Any]):\n         # Patching torch functions\n         self.patched_torch_methods = {\n             target: gen_constructor_wrapper(getattr(torch, target)) for target in self._TORCH_METHODS_TO_PATCH\n@@ -1222,9 +1222,9 @@ def patch_for_tracing(self, root: Union[torch.nn.Module, Callable[..., Any]]):\n \n     def trace(\n         self,\n-        root: Union[torch.nn.Module, Callable[..., Any]],\n-        concrete_args: Optional[dict[str, Any]] = None,\n-        dummy_inputs: Optional[dict[str, Any]] = None,\n+        root: torch.nn.Module | Callable[..., Any],\n+        concrete_args: dict[str, Any] | None = None,\n+        dummy_inputs: dict[str, Any] | None = None,\n         complete_concrete_args_with_inputs_not_in_dummy_inputs: bool = True,\n     ) -> Graph:\n         \"\"\"\n@@ -1440,7 +1440,7 @@ def check_if_model_is_supported(model: \"PreTrainedModel\"):\n \n def symbolic_trace(\n     model: \"PreTrainedModel\",\n-    input_names: Optional[list[str]] = None,\n+    input_names: list[str] | None = None,\n     disable_check: bool = False,\n     tracer_cls: type[HFTracer] = HFTracer,\n ) -> GraphModule:"
        },
        {
            "sha": "9bc51f1bac650fbe8b715570a78d7a8aec0b254e",
            "filename": "src/transformers/utils/generic.py",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fgeneric.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fgeneric.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fgeneric.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -573,7 +573,7 @@ def torch_float(x):\n     return x.to(torch.float32) if torch.jit.is_tracing() and isinstance(x, torch.Tensor) else int(x)\n \n \n-def filter_out_non_signature_kwargs(extra: Optional[list] = None):\n+def filter_out_non_signature_kwargs(extra: list | None = None):\n     \"\"\"\n     Decorator to filter out named arguments that are not in the function signature.\n \n@@ -676,13 +676,13 @@ class TransformersKwargs(TypedDict, total=False):\n     \"\"\"\n \n     num_items_in_batch: Optional[\"torch.Tensor\"]\n-    output_hidden_states: Optional[bool]\n-    output_attentions: Optional[bool]\n-    output_router_logits: Optional[bool]\n+    output_hidden_states: bool | None\n+    output_attentions: bool | None\n+    output_router_logits: bool | None\n     cu_seq_lens_q: Optional[\"torch.LongTensor\"]\n     cu_seq_lens_k: Optional[\"torch.LongTensor\"]\n-    max_length_q: Optional[int]\n-    max_length_k: Optional[int]\n+    max_length_q: int | None\n+    max_length_k: int | None\n \n \n def is_timm_config_dict(config_dict: dict[str, Any]) -> bool:\n@@ -777,8 +777,8 @@ class OutputRecorder:\n \n     target_class: \"type[torch.nn.Module]\"\n     index: int = 0\n-    layer_name: Optional[str] = None\n-    class_name: Optional[str] = None\n+    layer_name: str | None = None\n+    class_name: str | None = None\n \n \n def check_model_inputs(tie_last_hidden_states=True):"
        },
        {
            "sha": "dfbfa0eed5202f2d2e578ab5249a1a8f7f47917d",
            "filename": "src/transformers/utils/hub.py",
            "status": "modified",
            "additions": 53,
            "deletions": 53,
            "changes": 106,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fhub.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fhub.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fhub.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -23,7 +23,7 @@\n import warnings\n from concurrent import futures\n from pathlib import Path\n-from typing import Optional, TypedDict, Union\n+from typing import TypedDict\n from urllib.parse import urlparse\n from uuid import uuid4\n \n@@ -77,14 +77,14 @@\n \n \n class DownloadKwargs(TypedDict, total=False):\n-    cache_dir: Optional[Union[str, os.PathLike]]\n+    cache_dir: str | os.PathLike | None\n     force_download: bool\n-    proxies: Optional[dict[str, str]]\n+    proxies: dict[str, str] | None\n     local_files_only: bool\n-    token: Optional[Union[str, bool]]\n-    revision: Optional[str]\n+    token: str | bool | None\n+    revision: str | None\n     subfolder: str\n-    commit_hash: Optional[str]\n+    commit_hash: str | None\n \n \n _is_offline_mode = huggingface_hub.constants.HF_HUB_OFFLINE\n@@ -144,9 +144,9 @@ def is_offline_mode():\n def _get_cache_file_to_return(\n     path_or_repo_id: str,\n     full_filename: str,\n-    cache_dir: Union[str, Path, None] = None,\n-    revision: Optional[str] = None,\n-    repo_type: Optional[str] = None,\n+    cache_dir: str | Path | None = None,\n+    revision: str | None = None,\n+    repo_type: str | None = None,\n ):\n     # We try to see if we have a cached version (not up to date):\n     resolved_file = try_to_load_from_cache(\n@@ -161,9 +161,9 @@ def list_repo_templates(\n     repo_id: str,\n     *,\n     local_files_only: bool,\n-    revision: Optional[str] = None,\n-    cache_dir: Optional[str] = None,\n-    token: Optional[Union[str, bool]] = None,\n+    revision: str | None = None,\n+    cache_dir: str | None = None,\n+    token: str | bool | None = None,\n ) -> list[str]:\n     \"\"\"List template files from a repo.\n \n@@ -233,7 +233,7 @@ def define_sagemaker_information():\n     return sagemaker_object\n \n \n-def http_user_agent(user_agent: Union[dict, str, None] = None) -> str:\n+def http_user_agent(user_agent: dict | str | None = None) -> str:\n     \"\"\"\n     Formats a user-agent string with basic info about a request.\n     \"\"\"\n@@ -254,7 +254,7 @@ def http_user_agent(user_agent: Union[dict, str, None] = None) -> str:\n     return ua\n \n \n-def extract_commit_hash(resolved_file: Optional[str], commit_hash: Optional[str]) -> Optional[str]:\n+def extract_commit_hash(resolved_file: str | None, commit_hash: str | None) -> str | None:\n     \"\"\"\n     Extracts the commit hash from a resolved filename toward a cache file.\n     \"\"\"\n@@ -269,10 +269,10 @@ def extract_commit_hash(resolved_file: Optional[str], commit_hash: Optional[str]\n \n \n def cached_file(\n-    path_or_repo_id: Union[str, os.PathLike],\n+    path_or_repo_id: str | os.PathLike,\n     filename: str,\n     **kwargs,\n-) -> Optional[str]:\n+) -> str | None:\n     \"\"\"\n     Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\n \n@@ -329,23 +329,23 @@ def cached_file(\n \n \n def cached_files(\n-    path_or_repo_id: Union[str, os.PathLike],\n+    path_or_repo_id: str | os.PathLike,\n     filenames: list[str],\n-    cache_dir: Optional[Union[str, os.PathLike]] = None,\n+    cache_dir: str | os.PathLike | None = None,\n     force_download: bool = False,\n-    proxies: Optional[dict[str, str]] = None,\n-    token: Optional[Union[bool, str]] = None,\n-    revision: Optional[str] = None,\n+    proxies: dict[str, str] | None = None,\n+    token: bool | str | None = None,\n+    revision: str | None = None,\n     local_files_only: bool = False,\n     subfolder: str = \"\",\n-    repo_type: Optional[str] = None,\n-    user_agent: Optional[Union[str, dict[str, str]]] = None,\n+    repo_type: str | None = None,\n+    user_agent: str | dict[str, str] | None = None,\n     _raise_exceptions_for_gated_repo: bool = True,\n     _raise_exceptions_for_missing_entries: bool = True,\n     _raise_exceptions_for_connection_errors: bool = True,\n-    _commit_hash: Optional[str] = None,\n+    _commit_hash: str | None = None,\n     **deprecated_kwargs,\n-) -> Optional[str]:\n+) -> str | None:\n     \"\"\"\n     Tries to locate several files in a local folder and repo, downloads and cache them if necessary.\n \n@@ -609,15 +609,15 @@ def download_url(url, proxies=None):\n \n \n def has_file(\n-    path_or_repo: Union[str, os.PathLike],\n+    path_or_repo: str | os.PathLike,\n     filename: str,\n-    revision: Optional[str] = None,\n-    proxies: Optional[dict[str, str]] = None,\n-    token: Optional[Union[bool, str]] = None,\n+    revision: str | None = None,\n+    proxies: dict[str, str] | None = None,\n+    token: bool | str | None = None,\n     *,\n     local_files_only: bool = False,\n-    cache_dir: Union[str, Path, None] = None,\n-    repo_type: Optional[str] = None,\n+    cache_dir: str | Path | None = None,\n+    repo_type: str | None = None,\n     **deprecated_kwargs,\n ):\n     \"\"\"\n@@ -701,10 +701,10 @@ class PushToHubMixin:\n     def _create_repo(\n         self,\n         repo_id: str,\n-        private: Optional[bool] = None,\n-        token: Optional[Union[bool, str]] = None,\n-        repo_url: Optional[str] = None,\n-        organization: Optional[str] = None,\n+        private: bool | None = None,\n+        token: bool | str | None = None,\n+        repo_url: str | None = None,\n+        organization: str | None = None,\n     ) -> str:\n         \"\"\"\n         Create the repo if needed, cleans up repo_id with deprecated kwargs `repo_url` and `organization`, retrieves\n@@ -733,22 +733,22 @@ def _create_repo(\n         url = create_repo(repo_id=repo_id, token=token, private=private, exist_ok=True)\n         return url.repo_id\n \n-    def _get_files_timestamps(self, working_dir: Union[str, os.PathLike]):\n+    def _get_files_timestamps(self, working_dir: str | os.PathLike):\n         \"\"\"\n         Returns the list of files with their last modification timestamp.\n         \"\"\"\n         return {f: os.path.getmtime(os.path.join(working_dir, f)) for f in os.listdir(working_dir)}\n \n     def _upload_modified_files(\n         self,\n-        working_dir: Union[str, os.PathLike],\n+        working_dir: str | os.PathLike,\n         repo_id: str,\n         files_timestamps: dict[str, float],\n-        commit_message: Optional[str] = None,\n-        token: Optional[Union[bool, str]] = None,\n+        commit_message: str | None = None,\n+        token: bool | str | None = None,\n         create_pr: bool = False,\n-        revision: Optional[str] = None,\n-        commit_description: Optional[str] = None,\n+        revision: str | None = None,\n+        commit_description: str | None = None,\n     ):\n         \"\"\"\n         Uploads all modified files in `working_dir` to `repo_id`, based on `files_timestamps`.\n@@ -821,16 +821,16 @@ def _upload_modified_files(\n     def push_to_hub(\n         self,\n         repo_id: str,\n-        use_temp_dir: Optional[bool] = None,\n-        commit_message: Optional[str] = None,\n-        private: Optional[bool] = None,\n-        token: Optional[Union[bool, str]] = None,\n-        max_shard_size: Optional[Union[int, str]] = \"5GB\",\n+        use_temp_dir: bool | None = None,\n+        commit_message: str | None = None,\n+        private: bool | None = None,\n+        token: bool | str | None = None,\n+        max_shard_size: int | str | None = \"5GB\",\n         create_pr: bool = False,\n         safe_serialization: bool = True,\n-        revision: Optional[str] = None,\n-        commit_description: Optional[str] = None,\n-        tags: Optional[list[str]] = None,\n+        revision: str | None = None,\n+        commit_description: str | None = None,\n+        tags: list[str] | None = None,\n         **deprecated_kwargs,\n     ) -> str:\n         \"\"\"\n@@ -956,7 +956,7 @@ def push_to_hub(\n             )\n \n \n-def convert_file_size_to_int(size: Union[int, str]):\n+def convert_file_size_to_int(size: int | str):\n     \"\"\"\n     Converts a size expressed as a string with digits an unit (like `\"5MB\"`) to an integer (in bytes).\n \n@@ -1050,8 +1050,8 @@ def get_checkpoint_shard_files(\n \n def create_and_tag_model_card(\n     repo_id: str,\n-    tags: Optional[list[str]] = None,\n-    token: Optional[str] = None,\n+    tags: list[str] | None = None,\n+    token: str | None = None,\n     ignore_metadata_errors: bool = False,\n ):\n     \"\"\"\n@@ -1093,7 +1093,7 @@ class PushInProgress:\n     Internal class to keep track of a push in progress (which might contain multiple `Future` jobs).\n     \"\"\"\n \n-    def __init__(self, jobs: Optional[futures.Future] = None) -> None:\n+    def __init__(self, jobs: futures.Future | None = None) -> None:\n         self.jobs = [] if jobs is None else jobs\n \n     def is_done(self):"
        },
        {
            "sha": "06ff0e5cac75b68e529aa3e579e1bf256668f5c2",
            "filename": "src/transformers/utils/import_utils.py",
            "status": "modified",
            "additions": 8,
            "deletions": 10,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fimport_utils.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -31,7 +31,7 @@\n from functools import lru_cache\n from itertools import chain\n from types import ModuleType\n-from typing import Any, Optional, Union\n+from typing import Any\n \n from packaging import version\n \n@@ -44,7 +44,7 @@\n PACKAGE_DISTRIBUTION_MAPPING = importlib.metadata.packages_distributions()\n \n \n-def _is_package_available(pkg_name: str, return_version: bool = False) -> Union[tuple[bool, str], bool]:\n+def _is_package_available(pkg_name: str, return_version: bool = False) -> tuple[bool, str] | bool:\n     \"\"\"Check if `pkg_name` exist, and optionally try to get its version\"\"\"\n     package_exists = importlib.util.find_spec(pkg_name) is not None\n     package_version = \"N/A\"\n@@ -183,7 +183,7 @@ def is_habana_gaudi1() -> bool:\n \n \n @lru_cache\n-def is_torch_mps_available(min_version: Optional[str] = None) -> bool:\n+def is_torch_mps_available(min_version: str | None = None) -> bool:\n     if is_torch_available():\n         import torch\n \n@@ -355,9 +355,7 @@ def patched_gather(input: torch.Tensor, dim: int, index: torch.LongTensor) -> to\n \n     original_take_along_dim = torch.take_along_dim\n \n-    def patched_take_along_dim(\n-        input: torch.Tensor, indices: torch.LongTensor, dim: Optional[int] = None\n-    ) -> torch.Tensor:\n+    def patched_take_along_dim(input: torch.Tensor, indices: torch.LongTensor, dim: int | None = None) -> torch.Tensor:\n         if input.dtype == torch.int64 and input.device.type == \"hpu\":\n             return original_take_along_dim(input.to(torch.int32), indices, dim).to(torch.int64)\n         else:\n@@ -1773,9 +1771,9 @@ def __init__(\n         name: str,\n         module_file: str,\n         import_structure: IMPORT_STRUCTURE_T,\n-        module_spec: Optional[importlib.machinery.ModuleSpec] = None,\n-        extra_objects: Optional[dict[str, object]] = None,\n-        explicit_import_shortcut: Optional[dict[str, list[str]]] = None,\n+        module_spec: importlib.machinery.ModuleSpec | None = None,\n+        extra_objects: dict[str, object] | None = None,\n+        explicit_import_shortcut: dict[str, list[str]] | None = None,\n     ):\n         super().__init__(name)\n \n@@ -2435,7 +2433,7 @@ def flatten_dict(_dict, previous_key=None):\n \n \n @lru_cache\n-def define_import_structure(module_path: str, prefix: Optional[str] = None) -> IMPORT_STRUCTURE_T:\n+def define_import_structure(module_path: str, prefix: str | None = None) -> IMPORT_STRUCTURE_T:\n     \"\"\"\n     This method takes a module_path as input and creates an import structure digestible by a _LazyModule.\n "
        },
        {
            "sha": "c9fc19f26dd70e945754ba0274daf9022368e974",
            "filename": "src/transformers/utils/logging.py",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Flogging.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Flogging.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Flogging.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -29,14 +29,13 @@\n     WARNING,\n )\n from logging import captureWarnings as _captureWarnings\n-from typing import Optional\n \n import huggingface_hub.utils as hf_hub_utils\n from tqdm import auto as tqdm_lib\n \n \n _lock = threading.Lock()\n-_default_handler: Optional[logging.Handler] = None\n+_default_handler: logging.Handler | None = None\n \n log_levels = {\n     \"detail\": logging.DEBUG,  # will also print filename and line number\n@@ -144,7 +143,7 @@ def captureWarnings(capture):\n     _captureWarnings(capture)\n \n \n-def get_logger(name: Optional[str] = None) -> logging.Logger:\n+def get_logger(name: str | None = None) -> logging.Logger:\n     \"\"\"\n     Return a logger with the specified name.\n "
        },
        {
            "sha": "998595dd94bae6053921c5f83b46d0975b090639",
            "filename": "src/transformers/utils/metrics.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fmetrics.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fmetrics.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fmetrics.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -3,7 +3,7 @@\n import time\n from collections.abc import Callable\n from enum import Enum\n-from typing import Any, Optional, Union\n+from typing import Any\n \n from .import_utils import is_opentelemetry_available\n \n@@ -81,7 +81,7 @@ def traced(\n     *,\n     span_name=None,\n     standalone=False,\n-    additional_attributes: Optional[list[tuple[str, str, Union[Any, Callable[[Any], Any]]]]] = None,\n+    additional_attributes: list[tuple[str, str, Any | Callable[[Any], Any]]] | None = None,\n ):\n     \"\"\"\n     Decorator to trace function calls with OpenTelemetry."
        },
        {
            "sha": "1660d546ed1e387734c32cdbbc2b161ce1d48a08",
            "filename": "src/transformers/utils/notebook.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fnotebook.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fnotebook.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fnotebook.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -101,7 +101,7 @@ class NotebookProgressBar:\n     def __init__(\n         self,\n         total: int,\n-        prefix: Optional[str] = None,\n+        prefix: str | None = None,\n         leave: bool = True,\n         parent: Optional[\"NotebookTrainingTracker\"] = None,\n         width: int = 300,\n@@ -120,7 +120,7 @@ def __init__(\n             self.update_every = 0.5  # Adjusted for smooth updated as html rending is slow on VS Code\n             # This is the only adjustment required to optimize training html rending\n \n-    def update(self, value: int, force_update: bool = False, comment: Optional[str] = None):\n+    def update(self, value: int, force_update: bool = False, comment: str | None = None):\n         \"\"\"\n         The main method to update the progress bar to `value`.\n "
        },
        {
            "sha": "0b59faae94bd700c22c55d56c50f93e6b45ebcc9",
            "filename": "src/transformers/utils/peft_utils.py",
            "status": "modified",
            "additions": 6,
            "deletions": 7,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fpeft_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fpeft_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fpeft_utils.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -13,7 +13,6 @@\n # limitations under the License.\n import importlib\n import os\n-from typing import Optional, Union\n \n from packaging import version\n \n@@ -28,15 +27,15 @@\n \n def find_adapter_config_file(\n     model_id: str,\n-    cache_dir: Optional[Union[str, os.PathLike]] = None,\n+    cache_dir: str | os.PathLike | None = None,\n     force_download: bool = False,\n-    proxies: Optional[dict[str, str]] = None,\n-    token: Optional[Union[bool, str]] = None,\n-    revision: Optional[str] = None,\n+    proxies: dict[str, str] | None = None,\n+    token: bool | str | None = None,\n+    revision: str | None = None,\n     local_files_only: bool = False,\n     subfolder: str = \"\",\n-    _commit_hash: Optional[str] = None,\n-) -> Optional[str]:\n+    _commit_hash: str | None = None,\n+) -> str | None:\n     r\"\"\"\n     Simply checks if the model stored on the Hub or locally is an adapter model or not, return the path of the adapter\n     config file if it is, None otherwise."
        },
        {
            "sha": "09f31e7712baa0a9046a568e77b014c964ea128d",
            "filename": "src/transformers/utils/quantization_config.py",
            "status": "modified",
            "additions": 40,
            "deletions": 40,
            "changes": 80,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fquantization_config.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fquantization_config.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fquantization_config.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -134,7 +134,7 @@ def from_dict(cls, config_dict, return_unused_kwargs=False, **kwargs):\n         else:\n             return config\n \n-    def to_json_file(self, json_file_path: Union[str, os.PathLike]):\n+    def to_json_file(self, json_file_path: str | os.PathLike):\n         \"\"\"\n         Save this instance to a JSON file.\n \n@@ -304,8 +304,8 @@ def __init__(\n         nbits: int = 4,\n         group_size: int = 64,\n         view_as_float: bool = False,\n-        axis: Optional[int] = None,\n-        dynamic_config: Optional[dict] = None,\n+        axis: int | None = None,\n+        dynamic_config: dict | None = None,\n         skip_modules: list[str] = [\"lm_head\"],\n         **kwargs,\n     ):\n@@ -696,26 +696,26 @@ def __init__(\n         self,\n         bits: int,\n         tokenizer: Any = None,\n-        dataset: Optional[Union[list[str], str]] = None,\n+        dataset: list[str] | str | None = None,\n         group_size: int = 128,\n         damp_percent: float = 0.1,\n         desc_act: bool = False,\n         sym: bool = True,\n         true_sequential: bool = True,\n         checkpoint_format: str = \"gptq\",\n-        meta: Optional[dict[str, Any]] = None,\n-        backend: Optional[str] = None,\n+        meta: dict[str, Any] | None = None,\n+        backend: str | None = None,\n         use_cuda_fp16: bool = False,\n-        model_seqlen: Optional[int] = None,\n-        block_name_to_quantize: Optional[str] = None,\n-        module_name_preceding_first_block: Optional[list[str]] = None,\n+        model_seqlen: int | None = None,\n+        block_name_to_quantize: str | None = None,\n+        module_name_preceding_first_block: list[str] | None = None,\n         batch_size: int = 1,\n-        pad_token_id: Optional[int] = None,\n-        use_exllama: Optional[bool] = None,\n-        max_input_length: Optional[int] = None,\n-        exllama_config: Optional[dict[str, Any]] = None,\n+        pad_token_id: int | None = None,\n+        use_exllama: bool | None = None,\n+        max_input_length: int | None = None,\n+        exllama_config: dict[str, Any] | None = None,\n         cache_block_outputs: bool = True,\n-        modules_in_block_to_quantize: Optional[list[list[str]]] = None,\n+        modules_in_block_to_quantize: list[list[str]] | None = None,\n         **kwargs,\n     ):\n         self.quant_method = QuantizationMethod.GPTQ\n@@ -896,11 +896,11 @@ def __init__(\n         zero_point: bool = True,\n         version: AWQLinearVersion = AWQLinearVersion.GEMM,\n         backend: AwqBackendPackingMethod = AwqBackendPackingMethod.AUTOAWQ,\n-        do_fuse: Optional[bool] = None,\n-        fuse_max_seq_len: Optional[int] = None,\n-        modules_to_fuse: Optional[dict] = None,\n-        modules_to_not_convert: Optional[list] = None,\n-        exllama_config: Optional[dict[str, int]] = None,\n+        do_fuse: bool | None = None,\n+        fuse_max_seq_len: int | None = None,\n+        modules_to_fuse: dict | None = None,\n+        modules_to_not_convert: list | None = None,\n+        exllama_config: dict[str, int] | None = None,\n         **kwargs,\n     ):\n         self.quant_method = QuantizationMethod.AWQ\n@@ -1057,7 +1057,7 @@ def __init__(\n         out_group_size: int = 1,\n         num_codebooks: int = 1,\n         nbits_per_codebook: int = 16,\n-        linear_weights_not_to_quantize: Optional[list[str]] = None,\n+        linear_weights_not_to_quantize: list[str] | None = None,\n         **kwargs,\n     ):\n         self.quant_method = QuantizationMethod.AQLM\n@@ -1167,7 +1167,7 @@ def __init__(\n         enable_proxy_error: bool = False,\n         config_for_layers: dict[str, Any] = {},\n         shared_layer_config: dict[str, Any] = {},\n-        modules_to_not_convert: Optional[list] = None,\n+        modules_to_not_convert: list | None = None,\n         **kwargs,\n     ):\n         self.quant_method = QuantizationMethod.VPTQ\n@@ -1207,7 +1207,7 @@ def __init__(\n         self,\n         weights=\"int8\",\n         activations=None,\n-        modules_to_not_convert: Optional[list] = None,\n+        modules_to_not_convert: list | None = None,\n         **kwargs,\n     ):\n         self.quant_method = QuantizationMethod.QUANTO\n@@ -1245,7 +1245,7 @@ class EetqConfig(QuantizationConfigMixin):\n     def __init__(\n         self,\n         weights: str = \"int8\",\n-        modules_to_not_convert: Optional[list] = None,\n+        modules_to_not_convert: list | None = None,\n         **kwargs,\n     ):\n         self.quant_method = QuantizationMethod.EETQ\n@@ -1290,13 +1290,13 @@ class CompressedTensorsConfig(QuantizationConfigMixin):\n \n     def __init__(\n         self,\n-        config_groups: Optional[dict[str, Union[\"QuantizationScheme\", list[str]]]] = None,  # noqa: F821\n+        config_groups: dict[str, Union[\"QuantizationScheme\", list[str]]] | None = None,  # noqa: F821\n         format: str = \"dense\",\n         quantization_status: \"QuantizationStatus\" = \"initialized\",  # noqa: F821\n         kv_cache_scheme: Optional[\"QuantizationArgs\"] = None,  # noqa: F821\n-        global_compression_ratio: Optional[float] = None,\n-        ignore: Optional[list[str]] = None,\n-        sparsity_config: Optional[dict[str, Any]] = None,\n+        global_compression_ratio: float | None = None,\n+        ignore: list[str] | None = None,\n+        sparsity_config: dict[str, Any] | None = None,\n         quant_method: str = \"compressed-tensors\",\n         run_compressed: bool = True,\n         **kwargs,\n@@ -1461,7 +1461,7 @@ class FbgemmFp8Config(QuantizationConfigMixin):\n     def __init__(\n         self,\n         activation_scale_ub: float = 1200.0,\n-        modules_to_not_convert: Optional[list] = None,\n+        modules_to_not_convert: list | None = None,\n         **kwargs,\n     ):\n         self.quant_method = QuantizationMethod.FBGEMM_FP8\n@@ -1499,10 +1499,10 @@ def __init__(\n         self,\n         bits: int = 4,\n         p: int = 2,\n-        modules_to_not_convert: Optional[list[str]] = None,\n+        modules_to_not_convert: list[str] | None = None,\n         hadamard_size: int = 512,\n         group_size: int = 256,\n-        tune_metadata: Optional[dict[str, Any]] = None,\n+        tune_metadata: dict[str, Any] | None = None,\n         **kwargs,\n     ):\n         if tune_metadata is None:\n@@ -1561,10 +1561,10 @@ def __init__(\n         forward_method: str = \"abs_max\",\n         backward_dtype: str = \"bf16\",\n         store_master_weights: bool = False,\n-        hadamard_group_size: Optional[int] = None,\n+        hadamard_group_size: int | None = None,\n         pseudoquantization: bool = False,\n         transform_init: str = \"hadamard\",\n-        modules_to_not_convert: Optional[list[str]] = None,\n+        modules_to_not_convert: list[str] | None = None,\n         **kwargs,\n     ):\n         self.forward_dtype = forward_dtype\n@@ -1620,7 +1620,7 @@ def post_init(self):\n class TorchAoConfig(QuantizationConfigMixin):\n     quant_method: QuantizationMethod\n     quant_type: Union[str, \"AOBaseConfig\"]  # noqa: F821\n-    modules_to_not_convert: Optional[list]\n+    modules_to_not_convert: list | None\n     quant_type_kwargs: dict[str, Any]\n     include_input_output_embeddings: bool\n     untie_embedding_weights: bool\n@@ -1684,7 +1684,7 @@ class TorchAoConfig(QuantizationConfigMixin):\n     def __init__(\n         self,\n         quant_type: Union[str, \"AOBaseConfig\"],  # noqa: F821\n-        modules_to_not_convert: Optional[list] = None,\n+        modules_to_not_convert: list | None = None,\n         include_input_output_embeddings: bool = False,\n         untie_embedding_weights: bool = False,\n         **kwargs,\n@@ -1885,11 +1885,11 @@ class BitNetQuantConfig(QuantizationConfigMixin):\n \n     def __init__(\n         self,\n-        modules_to_not_convert: Optional[list] = None,\n+        modules_to_not_convert: list | None = None,\n         linear_class: str = \"bitlinear\",\n         quantization_mode: str = \"offline\",\n         use_rms_norm: bool = False,\n-        rms_norm_eps: Optional[float] = 1e-6,\n+        rms_norm_eps: float | None = 1e-6,\n         **kwargs,\n     ):\n         if linear_class not in [\"bitlinear\", \"autobitlinear\"]:\n@@ -1939,8 +1939,8 @@ def __init__(\n         bits: int = 3,\n         beta1: int = 16,\n         beta2: int = 16,\n-        shapes: Optional[dict[str, int]] = None,\n-        modules_to_not_convert: Optional[list[str]] = None,\n+        shapes: dict[str, int] | None = None,\n+        modules_to_not_convert: list[str] | None = None,\n         **kwargs,\n     ):\n         if shapes is None:\n@@ -1992,7 +1992,7 @@ def __init__(\n         self,\n         activation_scheme: str = \"dynamic\",\n         weight_block_size: tuple[int, int] = (128, 128),\n-        modules_to_not_convert: Optional[list] = None,\n+        modules_to_not_convert: list | None = None,\n         **kwargs,\n     ):\n         self.quant_method = QuantizationMethod.FP8\n@@ -2071,7 +2071,7 @@ class Mxfp4Config(QuantizationConfigMixin):\n \n     def __init__(\n         self,\n-        modules_to_not_convert: Optional[list] = None,\n+        modules_to_not_convert: list | None = None,\n         dequantize: bool = False,\n         **kwargs,\n     ):"
        },
        {
            "sha": "b6fdbcac948fd551fb70ae889a4b0c28a284c7dd",
            "filename": "src/transformers/utils/type_validators.py",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Ftype_validators.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Ftype_validators.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Ftype_validators.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -1,5 +1,5 @@\n from collections.abc import Sequence\n-from typing import Optional, Union\n+from typing import Union\n \n from ..tokenization_utils_base import PaddingStrategy, TruncationStrategy\n from ..video_utils import VideoMetadataType\n@@ -11,17 +11,17 @@\n     from ..image_utils import PILImageResampling\n \n \n-def positive_any_number(value: Optional[Union[int, float]] = None):\n+def positive_any_number(value: int | float | None = None):\n     if value is not None and (not isinstance(value, (int, float)) or not value >= 0):\n         raise ValueError(f\"Value must be a positive integer or floating number, got {value}\")\n \n \n-def positive_int(value: Optional[int] = None):\n+def positive_int(value: int | None = None):\n     if value is not None and (not isinstance(value, int) or not value >= 0):\n         raise ValueError(f\"Value must be a positive integer, got {value}\")\n \n \n-def padding_validator(value: Optional[Union[bool, str, PaddingStrategy]] = None):\n+def padding_validator(value: bool | str | PaddingStrategy | None = None):\n     possible_names = [\"longest\", \"max_length\", \"do_not_pad\"]\n     if value is None:\n         pass\n@@ -31,7 +31,7 @@ def padding_validator(value: Optional[Union[bool, str, PaddingStrategy]] = None)\n         raise ValueError(f\"If padding is a string, the value must be one of {possible_names}\")\n \n \n-def truncation_validator(value: Optional[Union[bool, str, TruncationStrategy]] = None):\n+def truncation_validator(value: bool | str | TruncationStrategy | None = None):\n     possible_names = [\"only_first\", \"only_second\", \"longest_first\", \"do_not_truncate\"]\n     if value is None:\n         pass\n@@ -41,15 +41,15 @@ def truncation_validator(value: Optional[Union[bool, str, TruncationStrategy]] =\n         raise ValueError(f\"If truncation is a string, value must be one of {possible_names}\")\n \n \n-def image_size_validator(value: Optional[Union[int, Sequence[int], dict[str, int]]] = None):\n+def image_size_validator(value: int | Sequence[int] | dict[str, int] | None = None):\n     possible_keys = [\"height\", \"width\", \"longest_edge\", \"shortest_edge\", \"max_height\", \"max_width\"]\n     if value is None:\n         pass\n     elif isinstance(value, dict) and any(k not in possible_keys for k in value.keys()):\n         raise ValueError(f\"Value for size must be a dict with keys {possible_keys} but got size={value}\")\n \n \n-def device_validator(value: Optional[Union[str, int]] = None):\n+def device_validator(value: str | int | None = None):\n     possible_names = [\"cpu\", \"cuda\", \"xla\", \"xpu\", \"mps\", \"meta\"]\n     if value is None:\n         pass\n@@ -65,7 +65,7 @@ def device_validator(value: Optional[Union[str, int]] = None):\n         )\n \n \n-def resampling_validator(value: Optional[Union[int, \"PILImageResampling\"]] = None):\n+def resampling_validator(value: Union[int, \"PILImageResampling\"] | None = None):\n     if value is None:\n         pass\n     elif isinstance(value, int) and value not in list(range(6)):\n@@ -76,7 +76,7 @@ def resampling_validator(value: Optional[Union[int, \"PILImageResampling\"]] = Non\n         raise ValueError(f\"The resampling should an integer or `PIL.Image.Resampling`, but got resampling={value}\")\n \n \n-def video_metadata_validator(value: Optional[VideoMetadataType] = None):\n+def video_metadata_validator(value: VideoMetadataType | None = None):\n     if value is None:\n         return\n \n@@ -107,7 +107,7 @@ def check_dict_keys(d: dict) -> bool:\n             )\n \n \n-def tensor_type_validator(value: Optional[Union[str, TensorType]] = None):\n+def tensor_type_validator(value: str | TensorType | None = None):\n     possible_names = [\"pt\", \"np\", \"mlx\"]\n     if value is None:\n         pass"
        },
        {
            "sha": "452f0d48a8e279c6e16fba74d9d565b59da1cfc5",
            "filename": "src/transformers/utils/versions.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fversions.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/def9a7ef057b13d04aeeaa150e3ce63afa151d4e/src%2Ftransformers%2Futils%2Fversions.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fversions.py?ref=def9a7ef057b13d04aeeaa150e3ce63afa151d4e",
            "patch": "@@ -19,7 +19,6 @@\n import operator\n import re\n import sys\n-from typing import Optional\n \n from packaging import version\n \n@@ -46,7 +45,7 @@ def _compare_versions(op, got_ver, want_ver, requirement, pkg, hint):\n         )\n \n \n-def require_version(requirement: str, hint: Optional[str] = None) -> None:\n+def require_version(requirement: str, hint: str | None = None) -> None:\n     \"\"\"\n     Perform a runtime check of the dependency versions, using the exact same syntax used by pip.\n "
        }
    ],
    "stats": {
        "total": 550,
        "additions": 261,
        "deletions": 289
    }
}