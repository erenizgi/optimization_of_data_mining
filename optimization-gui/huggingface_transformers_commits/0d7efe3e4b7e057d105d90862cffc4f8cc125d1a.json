{
    "author": "Xiang-cd",
    "message": "fix gpt2 usage doc (#39351)\n\nfix typo of gpt2 doc usage",
    "sha": "0d7efe3e4b7e057d105d90862cffc4f8cc125d1a",
    "files": [
        {
            "sha": "edc32747bdd90082f52fba4802070af9a48bbf5e",
            "filename": "docs/source/en/model_doc/gpt2.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0d7efe3e4b7e057d105d90862cffc4f8cc125d1a/docs%2Fsource%2Fen%2Fmodel_doc%2Fgpt2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/0d7efe3e4b7e057d105d90862cffc4f8cc125d1a/docs%2Fsource%2Fen%2Fmodel_doc%2Fgpt2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fgpt2.md?ref=0d7efe3e4b7e057d105d90862cffc4f8cc125d1a",
            "patch": "@@ -57,7 +57,7 @@ from transformers import AutoModelForCausalLM, AutoTokenizer\n model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\", torch_dtype=torch.float16, device_map=\"auto\", attn_implementation=\"sdpa\")\n tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n \n-input_ids = tokenzier(\"Hello, I'm a language model\". return_tensors=\"pt\").to(\"cuda\")\n+input_ids = tokenizer(\"Hello, I'm a language model\", return_tensors=\"pt\").to(\"cuda\")\n \n output = model.generate(**input_ids, cache_implementation=\"static\")\n print(tokenizer.decode(output[0], skip_special_tokens=True))"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}