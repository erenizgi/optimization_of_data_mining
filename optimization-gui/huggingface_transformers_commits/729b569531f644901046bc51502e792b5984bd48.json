{
    "author": "jiqing-feng",
    "message": "fix document qa bf16 pipeline (#35456)\n\n* fix document qa bf16 pipeline\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\r\n\r\n* add test\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\r\n\r\n* fix test\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\r\n\r\n---------\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>",
    "sha": "729b569531f644901046bc51502e792b5984bd48",
    "files": [
        {
            "sha": "41cd5d5d851b98ee22d98450c8ae36c2f550344d",
            "filename": "src/transformers/pipelines/document_question_answering.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/729b569531f644901046bc51502e792b5984bd48/src%2Ftransformers%2Fpipelines%2Fdocument_question_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/729b569531f644901046bc51502e792b5984bd48/src%2Ftransformers%2Fpipelines%2Fdocument_question_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fdocument_question_answering.py?ref=729b569531f644901046bc51502e792b5984bd48",
            "patch": "@@ -485,6 +485,11 @@ def postprocess_extractive_qa(\n         for output in model_outputs:\n             words = output[\"words\"]\n \n+            if self.framework == \"pt\" and output[\"start_logits\"].dtype in (torch.bfloat16, torch.float16):\n+                output[\"start_logits\"] = output[\"start_logits\"].float()\n+            if self.framework == \"pt\" and output[\"end_logits\"].dtype in (torch.bfloat16, torch.float16):\n+                output[\"end_logits\"] = output[\"end_logits\"].float()\n+\n             starts, ends, scores, min_null_score = select_starts_ends(\n                 start=output[\"start_logits\"],\n                 end=output[\"end_logits\"],"
        },
        {
            "sha": "85d528ce91045897bcfb401f93e201fef1213363",
            "filename": "tests/pipelines/test_pipelines_document_question_answering.py",
            "status": "modified",
            "additions": 46,
            "deletions": 1,
            "changes": 47,
            "blob_url": "https://github.com/huggingface/transformers/blob/729b569531f644901046bc51502e792b5984bd48/tests%2Fpipelines%2Ftest_pipelines_document_question_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/729b569531f644901046bc51502e792b5984bd48/tests%2Fpipelines%2Ftest_pipelines_document_question_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_document_question_answering.py?ref=729b569531f644901046bc51502e792b5984bd48",
            "patch": "@@ -14,7 +14,12 @@\n \n import unittest\n \n-from transformers import MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING, AutoTokenizer, is_vision_available\n+from transformers import (\n+    MODEL_FOR_DOCUMENT_QUESTION_ANSWERING_MAPPING,\n+    AutoTokenizer,\n+    is_torch_available,\n+    is_vision_available,\n+)\n from transformers.pipelines import DocumentQuestionAnsweringPipeline, pipeline\n from transformers.pipelines.document_question_answering import apply_tesseract\n from transformers.testing_utils import (\n@@ -24,13 +29,17 @@\n     require_pytesseract,\n     require_tf,\n     require_torch,\n+    require_torch_bf16,\n     require_vision,\n     slow,\n )\n \n from .test_pipelines_common import ANY\n \n \n+if is_torch_available():\n+    import torch\n+\n if is_vision_available():\n     from PIL import Image\n \n@@ -145,6 +154,42 @@ def test_small_model_pt(self):\n         outputs = dqa_pipeline(image=image, question=question, words=words, boxes=boxes, top_k=2)\n         self.assertEqual(outputs, [])\n \n+    @require_torch\n+    @require_torch_bf16\n+    @require_detectron2\n+    @require_pytesseract\n+    def test_small_model_pt_bf16(self):\n+        dqa_pipeline = pipeline(\n+            \"document-question-answering\",\n+            model=\"hf-internal-testing/tiny-random-layoutlmv2-for-dqa-test\",\n+            torch_dtype=torch.bfloat16,\n+        )\n+        image = INVOICE_URL\n+        question = \"How many cats are there?\"\n+\n+        expected_output = [\n+            {\"score\": 0.0001, \"answer\": \"oy 2312/2019\", \"start\": 38, \"end\": 39},\n+            {\"score\": 0.0001, \"answer\": \"oy 2312/2019 DUE\", \"start\": 38, \"end\": 40},\n+        ]\n+        outputs = dqa_pipeline(image=image, question=question, top_k=2)\n+        self.assertEqual(nested_simplify(outputs, decimals=4), expected_output)\n+\n+        outputs = dqa_pipeline({\"image\": image, \"question\": question}, top_k=2)\n+        self.assertEqual(nested_simplify(outputs, decimals=4), expected_output)\n+\n+        # This image does not detect ANY text in it, meaning layoutlmv2 should fail.\n+        # Empty answer probably\n+        image = \"./tests/fixtures/tests_samples/COCO/000000039769.png\"\n+        outputs = dqa_pipeline(image=image, question=question, top_k=2)\n+        self.assertEqual(outputs, [])\n+\n+        # We can optionnally pass directly the words and bounding boxes\n+        image = \"./tests/fixtures/tests_samples/COCO/000000039769.png\"\n+        words = []\n+        boxes = []\n+        outputs = dqa_pipeline(image=image, question=question, words=words, boxes=boxes, top_k=2)\n+        self.assertEqual(outputs, [])\n+\n     # \t TODO: Enable this once hf-internal-testing/tiny-random-donut is implemented\n     #    @require_torch\n     #    def test_small_model_pt_donut(self):"
        }
    ],
    "stats": {
        "total": 52,
        "additions": 51,
        "deletions": 1
    }
}