{
    "author": "Cyrilvallez",
    "message": "Remove `test_initialization` (#41261)\n\nremove it",
    "sha": "9d02602f0f597493257f5a738f3df149c1f93cbf",
    "files": [
        {
            "sha": "0fab7ce3db27f06707e839b67b70732698a39993",
            "filename": "conftest.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/conftest.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/conftest.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/conftest.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -54,7 +54,6 @@\n     \"test_gradient_checkpointing_backward_compatibility\",\n     \"test_gradient_checkpointing_enable_disable\",\n     \"test_torch_save_load\",\n-    \"test_initialization\",\n     \"test_forward_signature\",\n     \"test_model_get_set_embeddings\",\n     \"test_model_main_input_name\","
        },
        {
            "sha": "4f0f98f359e7f8e7b52b4f2a24cbb1dcbb724fc3",
            "filename": "tests/models/aimv2/test_modeling_aimv2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 25,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Faimv2%2Ftest_modeling_aimv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Faimv2%2Ftest_modeling_aimv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faimv2%2Ftest_modeling_aimv2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -39,7 +39,6 @@\n from ...test_modeling_common import (\n     TEST_EAGER_MATCHES_SDPA_INFERENCE_PARAMETERIZATION,\n     ModelTesterMixin,\n-    _config_zero_init,\n     _test_eager_matches_sdpa_inference,\n     floats_tensor,\n     ids_tensor,\n@@ -427,30 +426,6 @@ def test_model_get_set_embeddings(self):\n     def test_multi_gpu_data_parallel_forward(self):\n         pass\n \n-    # Override as the `logit_scale` parameter initialization is different for Aimv2\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def test_load_vision_text_config(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n "
        },
        {
            "sha": "e64ced9131a527948406c8814004921bdd6eb0bc",
            "filename": "tests/models/align/test_modeling_align.py",
            "status": "modified",
            "additions": 1,
            "deletions": 30,
            "changes": 31,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Falign%2Ftest_modeling_align.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Falign%2Ftest_modeling_align.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Falign%2Ftest_modeling_align.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -466,7 +466,7 @@ def test_batching_equivalence(self, atol=3e-4, rtol=3e-4):\n \n     @unittest.skip(reason=\"Start to fail after using torch `cu118`.\")\n     def test_multi_gpu_data_parallel_forward(self):\n-        super().test_multi_gpu_data_parallel_forward()\n+        pass\n \n     @unittest.skip(reason=\"Hidden_states is tested in individual model tests\")\n     def test_hidden_states_output(self):\n@@ -488,35 +488,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    # override as the `temperature` parameter initialization is different for ALIGN\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `temperature` is initialized as per the original implementation\n-                    if name == \"temperature\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            1.0,\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    elif name == \"text_projection.weight\":\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")"
        },
        {
            "sha": "86ea1e6da431e8fdaf017f10c2a1a79f80dff4ad",
            "filename": "tests/models/altclip/test_modeling_altclip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 23,
            "changes": 23,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Faltclip%2Ftest_modeling_altclip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Faltclip%2Ftest_modeling_altclip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faltclip%2Ftest_modeling_altclip.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -464,29 +464,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    # override as the `logit_scale` parameter initialization is different for AltCLIP\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")"
        },
        {
            "sha": "42186970e459d0e2fbd358b7fec4d23ac2c48a1e",
            "filename": "tests/models/aria/test_modeling_aria.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Faria%2Ftest_modeling_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Faria%2Ftest_modeling_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faria%2Ftest_modeling_aria.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -198,10 +198,6 @@ def setUp(self):\n         self.model_tester = AriaVisionText2TextModelTester(self)\n         self.config_tester = ConfigTester(self, config_class=AriaConfig, has_text_modality=False)\n \n-    @unittest.skip(reason=\"Unstable test\")\n-    def test_initialization(self):\n-        pass\n-\n \n SKIP = False\n torch_accelerator_module = getattr(torch, torch_device)"
        },
        {
            "sha": "aa71b32d54471ef73956fff3ab68eee0539e7a62",
            "filename": "tests/models/aya_vision/test_modeling_aya_vision.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Faya_vision%2Ftest_modeling_aya_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Faya_vision%2Ftest_modeling_aya_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faya_vision%2Ftest_modeling_aya_vision.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -197,10 +197,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"Siglip uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(reason=\"Compile not yet supported because in LLava models\")\n     @pytest.mark.torch_compile_test\n     def test_sdpa_can_compile_dynamic(self):"
        },
        {
            "sha": "0092218bc6095d81245da64c85c020cf5b7ec101",
            "filename": "tests/models/bamba/test_modeling_bamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 25,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fbamba%2Ftest_modeling_bamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fbamba%2Ftest_modeling_bamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbamba%2Ftest_modeling_bamba.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -41,7 +41,7 @@\n \n from ...generation.test_utils import GenerationTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -335,30 +335,6 @@ def test_decoder_model_past_with_large_inputs(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_decoder_model_past_large_inputs(*config_and_inputs)\n \n-    def test_initialization(self):\n-        r\"\"\"\n-        Overriding the test_initialization test as the A_log and D params of the Bamba mixer are initialized differently\n-        \"\"\"\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if \"A_log\" in name:\n-                        A = torch.arange(1, config.mamba_n_heads + 1, dtype=torch.float32)\n-                        torch.testing.assert_close(param.data, torch.log(A), rtol=1e-5, atol=1e-5)\n-                    elif \"D\" in name:\n-                        D = torch.ones(config.mamba_n_heads, dtype=torch.float32)\n-                        torch.testing.assert_close(param.data, D, rtol=1e-5, atol=1e-5)\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def test_attention_outputs(self):\n         r\"\"\"\n         Overriding the test_attention_outputs test as the Bamba model outputs attention only for its attention layers"
        },
        {
            "sha": "ab6c28dd4b2f04822f5ba5e02a07f41904a6aa3e",
            "filename": "tests/models/beit/test_modeling_beit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 19,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fbeit%2Ftest_modeling_beit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fbeit%2Ftest_modeling_beit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbeit%2Ftest_modeling_beit.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -34,7 +34,7 @@\n \n from ...test_backbone_common import BackboneTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -382,24 +382,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                # we skip lambda parameters as these require special initial values\n-                # determined by config.layer_scale_init_value\n-                if \"lambda\" in name:\n-                    continue\n-                if param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"microsoft/beit-base-patch16-224\""
        },
        {
            "sha": "3f9269ca17a2fe6e5e4c9d4998d011c1229a6ea5",
            "filename": "tests/models/bit/test_modeling_bit.py",
            "status": "modified",
            "additions": 0,
            "deletions": 17,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fbit%2Ftest_modeling_bit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fbit%2Ftest_modeling_bit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbit%2Ftest_modeling_bit.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -28,7 +28,6 @@\n \n if is_torch_available():\n     import torch\n-    from torch import nn\n \n     from transformers import BitBackbone, BitForImageClassification, BitImageProcessor, BitModel\n \n@@ -200,22 +199,6 @@ def test_backbone(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_backbone(*config_and_inputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=config)\n-            for name, module in model.named_modules():\n-                if isinstance(module, (nn.BatchNorm2d, nn.GroupNorm)):\n-                    self.assertTrue(\n-                        torch.all(module.weight == 1),\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-                    self.assertTrue(\n-                        torch.all(module.bias == 0),\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_hidden_states_output(self):\n         def check_hidden_states_output(inputs_dict, config, model_class):\n             model = model_class(config)"
        },
        {
            "sha": "cfe2d7dd069659dc7cbb36173f7188c05ae1c2d2",
            "filename": "tests/models/blip/test_modeling_blip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 83,
            "changes": 83,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fblip%2Ftest_modeling_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fblip%2Ftest_modeling_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fblip%2Ftest_modeling_blip.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -456,41 +456,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    # override as the `logit_scale` parameter initialization is different for Blip\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        # See PR #38607 (to avoid flakiness)\n-                        data = torch.flatten(param.data)\n-                        n_elements = torch.numel(data)\n-                        # skip 2.5% of elements on each side to avoid issues caused by `nn.init.trunc_normal_` described in\n-                        # https://github.com/huggingface/transformers/pull/27906#issuecomment-1846951332\n-                        n_elements_to_skip_on_each_side = int(n_elements * 0.025)\n-                        data_to_check = torch.sort(data).values\n-                        if n_elements_to_skip_on_each_side > 0:\n-                            data_to_check = data_to_check[\n-                                n_elements_to_skip_on_each_side:-n_elements_to_skip_on_each_side\n-                            ]\n-                        self.assertIn(\n-                            ((data_to_check.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")\n@@ -981,30 +946,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    # override as the `logit_scale` parameter initialization is different for Blip\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")\n@@ -1194,30 +1135,6 @@ def test_training_gradient_checkpointing(self):\n             loss = model(**inputs).loss\n             loss.backward()\n \n-    # override as the `logit_scale` parameter initialization is different for Blip\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")"
        },
        {
            "sha": "f2efb12a4a3979e3caffd0b876a4a99b2386fe31",
            "filename": "tests/models/blip_2/test_modeling_blip_2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 49,
            "changes": 49,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fblip_2%2Ftest_modeling_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fblip_2%2Ftest_modeling_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fblip_2%2Ftest_modeling_blip_2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -13,7 +13,6 @@\n # limitations under the License.\n \"\"\"Testing suite for the PyTorch BLIP-2 model.\"\"\"\n \n-import copy\n import inspect\n import tempfile\n import unittest\n@@ -42,7 +41,6 @@\n from ...test_modeling_common import (\n     TEST_EAGER_MATCHES_SDPA_INFERENCE_PARAMETERIZATION,\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n@@ -988,23 +986,6 @@ def test_get_qformer_features(self):\n             (self.model_tester.vision_model_tester.batch_size, 10, config.vision_config.hidden_size),\n         )\n \n-    # override from common to deal with nested configurations (`vision_config`, `text_config` and `qformer_config`)\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for key in [\"vision_config\", \"qformer_config\", \"text_config\"]:\n-            setattr(configs_no_init, key, _config_zero_init(getattr(configs_no_init, key)))\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=copy.deepcopy(configs_no_init))\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     @unittest.skip(\"T5 backbone deepcopies the configs, and fixing it would be more involved\")\n     def test_internal_model_config_and_subconfig_are_same(self):\n         pass\n@@ -1511,36 +1492,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    elif name == \"temp\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            0.07,\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n \n # We will verify our results on an image of cute cats\n def prepare_img():"
        },
        {
            "sha": "ba9bf5aca93f84ce12c0bb4aae89f8d05c391e2f",
            "filename": "tests/models/bridgetower/test_modeling_bridgetower.py",
            "status": "modified",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fbridgetower%2Ftest_modeling_bridgetower.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fbridgetower%2Ftest_modeling_bridgetower.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbridgetower%2Ftest_modeling_bridgetower.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -28,7 +28,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n@@ -437,29 +436,6 @@ def test_retain_grad_hidden_states_attentions(self):\n         if self.has_attentions:\n             self.assertIsNotNone(attentions.grad)\n \n-    # override as the `logit_scale` parameter initialization is different for BRIDGE TOWER\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            config.logit_scale_init_value,\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     @unittest.skip(reason=\"\"\"Bridge Tower does not have input/output embeddings. So this test is not applicable.\"\"\")\n     def test_model_get_set_embeddings(self):\n         pass"
        },
        {
            "sha": "140823b076d71c9fcb7f6f35b11044edf6b34aa9",
            "filename": "tests/models/chinese_clip/test_modeling_chinese_clip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fchinese_clip%2Ftest_modeling_chinese_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fchinese_clip%2Ftest_modeling_chinese_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fchinese_clip%2Ftest_modeling_chinese_clip.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -18,7 +18,6 @@\n import tempfile\n import unittest\n \n-import numpy as np\n import requests\n \n from transformers import ChineseCLIPConfig, ChineseCLIPTextConfig, ChineseCLIPVisionConfig\n@@ -578,33 +577,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    # override as the `logit_scale` parameter initialization is different for CHINESE_CLIP\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for sub_config_key in (\"vision_config\", \"text_config\"):\n-            sub_config = getattr(configs_no_init, sub_config_key, {})\n-            setattr(configs_no_init, sub_config_key, _config_zero_init(sub_config))\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")"
        },
        {
            "sha": "5790c880e7a634768db7dbdc4ddaee9d51dabdaa",
            "filename": "tests/models/clap/test_modeling_clap.py",
            "status": "modified",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fclap%2Ftest_modeling_clap.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fclap%2Ftest_modeling_clap.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fclap%2Ftest_modeling_clap.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -525,30 +525,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    # override as the `logit_scale` parameter initialization is different for CLAP\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if \"logit_scale\" in name:\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")"
        },
        {
            "sha": "e0721c531b2b9fe8f1a3cdedbc6a77e623dc7241",
            "filename": "tests/models/clip/test_modeling_clip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fclip%2Ftest_modeling_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fclip%2Ftest_modeling_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fclip%2Ftest_modeling_clip.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -562,30 +562,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    # override as the `logit_scale` parameter initialization is different for CLIP\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")\n@@ -750,10 +726,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"CLIP uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n     @parameterized.expand(TEST_EAGER_MATCHES_SDPA_INFERENCE_PARAMETERIZATION)\n     @slow\n     @is_flaky()"
        },
        {
            "sha": "0410fc91fd345730844f2d941295a4c4072eeb2c",
            "filename": "tests/models/clipseg/test_modeling_clipseg.py",
            "status": "modified",
            "additions": 0,
            "deletions": 27,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fclipseg%2Ftest_modeling_clipseg.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fclipseg%2Ftest_modeling_clipseg.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fclipseg%2Ftest_modeling_clipseg.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -490,33 +490,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    # override as the some parameters require custom initialization\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if \"logit_scale\" in name:\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    elif \"film\" in name or \"transposed_conv\" in name or \"reduce\" in name:\n-                        # those parameters use PyTorch' default nn.Linear initialization scheme\n-                        pass\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")"
        },
        {
            "sha": "e1c756df82c58459ff2e1949efd05af51627cc75",
            "filename": "tests/models/clvp/test_modeling_clvp.py",
            "status": "modified",
            "additions": 0,
            "deletions": 31,
            "changes": 31,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fclvp%2Ftest_modeling_clvp.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fclvp%2Ftest_modeling_clvp.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fclvp%2Ftest_modeling_clvp.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -32,7 +32,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     ids_tensor,\n     random_attention_mask,\n )\n@@ -499,36 +498,6 @@ def test_inputs_embeds(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    # override as the `logit_scale` parameter initialization is different for Clvp\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        expected_value = np.log(1 / 0.07)\n-                        returned_value = param.data.item()\n-\n-                        self.assertAlmostEqual(\n-                            returned_value,\n-                            expected_value,\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        expected_range = [0.0, 1.0]\n-                        returned_range = ((param.data.mean() * 1e9).round() / 1e9).item()\n-\n-                        self.assertIn(\n-                            returned_range,\n-                            expected_range,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def test_load_speech_text_decoder_config(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n "
        },
        {
            "sha": "53bded107a3b49ae2c3cbb8eef0a30e3433f11fc",
            "filename": "tests/models/cohere2_vision/test_modeling_cohere2_vision.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fcohere2_vision%2Ftest_modeling_cohere2_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fcohere2_vision%2Ftest_modeling_cohere2_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fcohere2_vision%2Ftest_modeling_cohere2_vision.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -169,10 +169,6 @@ def setUp(self):\n     def test_config(self):\n         self.config_tester.run_common_tests()\n \n-    @unittest.skip(reason=\"Siglip backbone uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n \n @require_read_token\n @require_torch"
        },
        {
            "sha": "761946891ead2c3c710fbf1cef4ad3b606bd6bb3",
            "filename": "tests/models/colpali/test_modeling_colpali.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fcolpali%2Ftest_modeling_colpali.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fcolpali%2Ftest_modeling_colpali.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fcolpali%2Ftest_modeling_colpali.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -273,10 +273,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_model_parallelism(self):\n         pass\n \n-    @unittest.skip(reason=\"PaliGemma's SigLip encoder uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n     # TODO extend valid outputs to include this test @Molbap\n     @unittest.skip(reason=\"PaliGemma has currently one output format.\")\n     def test_model_outputs_equivalence(self):"
        },
        {
            "sha": "d186ce1d9a47317e7a1d92f33ca022f515cfba37",
            "filename": "tests/models/conditional_detr/test_modeling_conditional_detr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 24,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fconditional_detr%2Ftest_modeling_conditional_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fconditional_detr%2Ftest_modeling_conditional_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fconditional_detr%2Ftest_modeling_conditional_detr.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -22,7 +22,7 @@\n from transformers.testing_utils import require_timm, require_torch, require_vision, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -506,29 +506,6 @@ def test_hf_backbone(self):\n \n             self.assertTrue(outputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        configs_no_init.init_xavier_std = 1e9\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if \"bbox_attention\" in name and \"bias\" not in name:\n-                        self.assertLess(\n-                            100000,\n-                            abs(param.data.max().item()),\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n \n TOLERANCE = 1e-4\n "
        },
        {
            "sha": "cc09a9fe646aa5b222cfa58a58d662fab0bed6a6",
            "filename": "tests/models/csm/test_modeling_csm.py",
            "status": "modified",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fcsm%2Ftest_modeling_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fcsm%2Ftest_modeling_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fcsm%2Ftest_modeling_csm.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -39,7 +39,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     ids_tensor,\n )\n \n@@ -189,25 +188,6 @@ def _get_logits_processor_kwargs(self, do_sample=False, config=None):\n \n         return logits_processor_kwargs\n \n-    def test_initialization(self):\n-        \"\"\"\n-        Overrides [ModelTesterMixin.test_initialization] because of specificities of Mimi codec model.\n-        See https://github.com/huggingface/transformers/blob/1077603410cd73ba71d64a522033574d66d64b55/tests/models/mimi/test_modeling_mimi.py#L384-L397\n-        \"\"\"\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\"conv\", \"input_proj\", \"output_proj\"]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _check_similar_generate_outputs(self, output_1, output_2, atol=1e-5, rtol=1e-5):\n         \"\"\"\n         Overrides [GenerationTesterMixin._check_similar_generate_outputs] to handle third input_ids dimension."
        },
        {
            "sha": "7b6eddcfaca383f4fb35ceeebe0c4df271dd0a13",
            "filename": "tests/models/d_fine/test_modeling_d_fine.py",
            "status": "modified",
            "additions": 1,
            "deletions": 53,
            "changes": 54,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fd_fine%2Ftest_modeling_d_fine.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fd_fine%2Ftest_modeling_d_fine.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fd_fine%2Ftest_modeling_d_fine.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -48,7 +48,7 @@\n from transformers import RTDetrImageProcessor\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -628,58 +628,6 @@ def test_hf_backbone(self):\n \n             self.assertTrue(outputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        configs_no_init.initializer_bias_prior_prob = 0.2\n-        bias_value = -1.3863  # log_e ((1 - 0.2) / 0.2)\n-\n-        failed_cases = []\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            # Skip the check for the backbone\n-            for name, module in model.named_modules():\n-                if module.__class__.__name__ == \"DFineConvEncoder\":\n-                    backbone_params = [f\"{name}.{key}\" for key in module.state_dict()]\n-                    break\n-\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if (\"class_embed\" in name and \"bias\" in name) or \"enc_score_head.bias\" in name:\n-                        bias_tensor = torch.full_like(param.data, bias_value)\n-                        try:\n-                            torch.testing.assert_close(param.data, bias_tensor, atol=1e-4, rtol=1e-4)\n-                        except AssertionError:\n-                            failed_cases.append(\n-                                f\"Parameter {name} of model {model_class} seems not properly initialized. \"\n-                                f\"Biases should be initialized to {bias_value}, got {param.data}\"\n-                            )\n-                    elif (\n-                        \"level_embed\" in name\n-                        or \"sampling_offsets.bias\" in name\n-                        or \"value_proj\" in name\n-                        or \"output_proj\" in name\n-                        or \"reference_points\" in name\n-                        or \"enc_score_head.weight\" in name\n-                        or (\"class_embed\" in name and \"weight\" in name)\n-                        or name in backbone_params\n-                    ):\n-                        continue\n-                    else:\n-                        mean = param.data.mean()\n-                        round_mean = (mean * 1e9).round() / 1e9\n-                        round_mean = round_mean.item()\n-                        if round_mean not in [0.0, 1.0]:\n-                            failed_cases.append(\n-                                f\"Parameter {name} of model {model_class} seems not properly initialized. \"\n-                                f\"Mean is {round_mean}, but should be in [0, 1]\"\n-                            )\n-\n-        message = \"\\n\" + \"\\n\".join(failed_cases)\n-        self.assertTrue(not failed_cases, message)\n-\n     @parameterized.expand([\"float32\", \"float16\", \"bfloat16\"])\n     @require_torch_accelerator\n     @slow"
        },
        {
            "sha": "9df7038fdccccfff896b620fa3a8f64d65d915d9",
            "filename": "tests/models/dab_detr/test_modeling_dab_detr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 50,
            "changes": 51,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdab_detr%2Ftest_modeling_dab_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdab_detr%2Ftest_modeling_dab_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdab_detr%2Ftest_modeling_dab_detr.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -22,7 +22,7 @@\n from transformers.testing_utils import require_timm, require_torch, require_vision, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -700,55 +700,6 @@ def test_different_timm_backbone(self):\n \n             self.assertTrue(outputs)\n \n-    def test_initialization(self):\n-        config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        configs_no_init.init_xavier_std = 1e9\n-        # Copied from RT-DETR\n-        configs_no_init.initializer_bias_prior_prob = 0.2\n-        bias_value = -1.3863  # log_e ((1 - 0.2) / 0.2)\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if \"bbox_attention\" in name and \"bias\" not in name:\n-                        self.assertLess(\n-                            100000,\n-                            abs(param.data.max().item()),\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    # Modified from RT-DETR\n-                    elif \"class_embed\" in name and \"bias\" in name:\n-                        bias_tensor = torch.full_like(param.data, bias_value)\n-                        torch.testing.assert_close(\n-                            param.data,\n-                            bias_tensor,\n-                            atol=1e-4,\n-                            rtol=1e-4,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    elif \"activation_fn\" in name and config.activation_function == \"prelu\":\n-                        self.assertTrue(\n-                            param.data.mean() == 0.25,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    elif \"backbone.conv_encoder.model\" in name:\n-                        continue\n-                    elif \"self_attn.in_proj_weight\" in name:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e2).round() / 1e2).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n \n TOLERANCE = 1e-4\n CHECKPOINT = \"IDEA-Research/dab-detr-resnet-50\""
        },
        {
            "sha": "cb286a14e9658888174d44846b9a79cae7859079",
            "filename": "tests/models/dac/test_modeling_dac.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdac%2Ftest_modeling_dac.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdac%2Ftest_modeling_dac.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdac%2Ftest_modeling_dac.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -353,22 +353,6 @@ def recursive_check(tuple_object, dict_object):\n             dict_inputs = self._prepare_for_class(inputs_dict, model_class)\n             check_equivalence(model, tuple_inputs, dict_inputs)\n \n-    # Ignore copy\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\"conv\", \"in_proj\", \"out_proj\", \"codebook\"]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def test_identity_shortcut(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs()\n         config.use_conv_shortcut = False"
        },
        {
            "sha": "34785ccd3a747904e022ec6ace54f0b4aaa87685",
            "filename": "tests/models/data2vec/test_modeling_data2vec_audio.py",
            "status": "modified",
            "additions": 1,
            "deletions": 34,
            "changes": 35,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdata2vec%2Ftest_modeling_data2vec_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdata2vec%2Ftest_modeling_data2vec_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdata2vec%2Ftest_modeling_data2vec_audio.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -24,7 +24,7 @@\n from transformers.testing_utils import require_torch, require_torchcodec, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init\n+from ...test_modeling_common import ModelTesterMixin\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -457,39 +457,6 @@ def test_retain_grad_hidden_states_attentions(self):\n         self.assertIsNotNone(hidden_states.grad)\n         self.assertIsNotNone(attentions.grad)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"masked_spec_embed\",\n-                    \"codevectors\",\n-                    \"quantizer.weight_proj.weight\",\n-                    \"project_hid.weight\",\n-                    \"project_hid.bias\",\n-                    \"project_q.weight\",\n-                    \"project_q.bias\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                    \"objective.weight\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # overwrite from test_modeling_common\n     def _mock_init_weights(self, module):\n         if hasattr(module, \"weight\") and module.weight is not None:"
        },
        {
            "sha": "b540caecafe5529bcf986f2448bd4175e6825c49",
            "filename": "tests/models/data2vec/test_modeling_data2vec_vision.py",
            "status": "modified",
            "additions": 1,
            "deletions": 19,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdata2vec%2Ftest_modeling_data2vec_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdata2vec%2Ftest_modeling_data2vec_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdata2vec%2Ftest_modeling_data2vec_vision.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -32,7 +32,7 @@\n )\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -291,24 +291,6 @@ def test_training_gradient_checkpointing(self):\n             loss = model(**inputs).loss\n             loss.backward()\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                # we skip lambda parameters as these require special initial values\n-                # determined by config.layer_scale_init_value\n-                if \"lambda\" in name:\n-                    continue\n-                if param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_for_image_classification(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_for_image_classification(*config_and_inputs)"
        },
        {
            "sha": "33c5e0c4a46565315625fec01e2dd93ebba549fd",
            "filename": "tests/models/deepseek_vl/test_modeling_deepseek_vl.py",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdeepseek_vl%2Ftest_modeling_deepseek_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdeepseek_vl%2Ftest_modeling_deepseek_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdeepseek_vl%2Ftest_modeling_deepseek_vl.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -186,11 +186,6 @@ def test_inputs_embeds_matches_input_ids(self):\n                 out_embeds = model(inputs_embeds=inputs_embeds, **inputs)[0]\n             torch.testing.assert_close(out_embeds, out_ids)\n \n-    @unittest.skip(reason=\"Siglip uses a non-standard initialization scheme\")\n-    # Copied from tests.models.siglip.test_modeling_siglip.SiglipVisionModelTest.test_initialization\n-    def test_initialization(self):\n-        pass\n-\n     # Copied from tests.models.janus.test_modeling_janus.JanusVisionText2TextModelTest.test_sdpa_can_dispatch_composite_models\n     def test_sdpa_can_dispatch_composite_models(self):\n         for model_class in self.all_model_classes:"
        },
        {
            "sha": "99dba2542ea314621ece0c8222705dd75a6e0976",
            "filename": "tests/models/deepseek_vl_hybrid/test_modeling_deepseek_vl_hybrid.py",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdeepseek_vl_hybrid%2Ftest_modeling_deepseek_vl_hybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdeepseek_vl_hybrid%2Ftest_modeling_deepseek_vl_hybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdeepseek_vl_hybrid%2Ftest_modeling_deepseek_vl_hybrid.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -217,11 +217,6 @@ def test_inputs_embeds_matches_input_ids(self):\n                 out_embeds = model(inputs_embeds=inputs_embeds, **inputs)[0]\n             torch.testing.assert_close(out_embeds, out_ids)\n \n-    @unittest.skip(reason=\"Siglip uses a non-standard initialization scheme\")\n-    # Copied from tests.models.siglip.test_modeling_siglip.SiglipVisionModelTest.test_initialization\n-    def test_initialization(self):\n-        pass\n-\n     def test_sdpa_can_dispatch_composite_models(self):\n         for model_class in self.all_model_classes:\n             config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()"
        },
        {
            "sha": "130c04df10ac7bd515ef04fca6487611d2e97308",
            "filename": "tests/models/deformable_detr/test_modeling_deformable_detr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 24,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdeformable_detr%2Ftest_modeling_deformable_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdeformable_detr%2Ftest_modeling_deformable_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdeformable_detr%2Ftest_modeling_deformable_detr.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -30,7 +30,7 @@\n )\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -575,29 +575,6 @@ def test_hf_backbone(self):\n \n             self.assertTrue(outputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            print(\"Model class:\", model_class)\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if (\n-                        \"level_embed\" in name\n-                        or \"sampling_offsets.bias\" in name\n-                        or \"value_proj\" in name\n-                        or \"output_proj\" in name\n-                        or \"reference_points\" in name\n-                    ):\n-                        continue\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_two_stage_training(self):\n         model_class = DeformableDetrForObjectDetection\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()"
        },
        {
            "sha": "7cb57b843b7a86b558bc39aa4a02ccb5c512207a",
            "filename": "tests/models/depth_pro/test_modeling_depth_pro.py",
            "status": "modified",
            "additions": 1,
            "deletions": 40,
            "changes": 41,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdepth_pro%2Ftest_modeling_depth_pro.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdepth_pro%2Ftest_modeling_depth_pro.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdepth_pro%2Ftest_modeling_depth_pro.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -22,7 +22,7 @@\n from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -300,45 +300,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                non_uniform_init_parms = [\n-                    # these encoders are vision transformers\n-                    # any layer outside these encoders is either Conv2d or ConvTranspose2d\n-                    # which use kaiming initialization\n-                    \"patch_encoder\",\n-                    \"image_encoder\",\n-                    \"fov_model.encoder\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in non_uniform_init_parms):\n-                        # See PR #38607 (to avoid flakiness)\n-                        data = torch.flatten(param.data)\n-                        n_elements = torch.numel(data)\n-                        # skip 2.5% of elements on each side to avoid issues caused by `nn.init.trunc_normal_` described in\n-                        # https://github.com/huggingface/transformers/pull/27906#issuecomment-1846951332\n-                        n_elements_to_skip_on_each_side = int(n_elements * 0.025)\n-                        data_to_check = torch.sort(data).values\n-                        if n_elements_to_skip_on_each_side > 0:\n-                            data_to_check = data_to_check[\n-                                n_elements_to_skip_on_each_side:-n_elements_to_skip_on_each_side\n-                            ]\n-                        self.assertIn(\n-                            ((data_to_check.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # this started when switched from normal initialization to kaiming_normal initialization\n     # maybe because the magnitude of offset values from ViT-encoders increases when followed by many convolution layers\n     def test_batching_equivalence(self, atol=1e-4, rtol=1e-4):"
        },
        {
            "sha": "e6f8e07f8d16af66357d8f0d2108b195c48acdd2",
            "filename": "tests/models/detr/test_modeling_detr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 24,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdetr%2Ftest_modeling_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdetr%2Ftest_modeling_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdetr%2Ftest_modeling_detr.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -22,7 +22,7 @@\n from transformers.testing_utils import Expectations, require_timm, require_torch, require_vision, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -526,29 +526,6 @@ def test_greyscale_images(self):\n \n             self.assertTrue(outputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        configs_no_init.init_xavier_std = 1e9\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if \"bbox_attention\" in name and \"bias\" not in name:\n-                        self.assertLess(\n-                            100000,\n-                            abs(param.data.max().item()),\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n \n TOLERANCE = 1e-4\n "
        },
        {
            "sha": "099b285581cb225eb589fbc65dde9c5752750515",
            "filename": "tests/models/dinat/test_modeling_dinat.py",
            "status": "modified",
            "additions": 1,
            "deletions": 15,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdinat%2Ftest_modeling_dinat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdinat%2Ftest_modeling_dinat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdinat%2Ftest_modeling_dinat.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -23,7 +23,7 @@\n \n from ...test_backbone_common import BackboneTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -326,20 +326,6 @@ def test_model_from_pretrained(self):\n         model = DinatModel.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if \"embeddings\" not in name and param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n \n @require_natten\n @require_vision"
        },
        {
            "sha": "85e70f99fca628be5811ad25dea0acc8c11e4452",
            "filename": "tests/models/dinov2/test_modeling_dinov2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdinov2%2Ftest_modeling_dinov2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdinov2%2Ftest_modeling_dinov2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdinov2%2Ftest_modeling_dinov2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -18,7 +18,6 @@\n \n from transformers import Dinov2Config\n from transformers.testing_utils import (\n-    is_flaky,\n     require_torch,\n     require_vision,\n     slow,\n@@ -237,10 +236,6 @@ def setUp(self):\n         self.model_tester = Dinov2ModelTester(self)\n         self.config_tester = ConfigTester(self, config_class=Dinov2Config, has_text_modality=False, hidden_size=37)\n \n-    @is_flaky(max_attempts=3, description=\"`torch.nn.init.trunc_normal_` is flaky.\")\n-    def test_initialization(self):\n-        super().test_initialization()\n-\n     def test_config(self):\n         self.config_tester.run_common_tests()\n "
        },
        {
            "sha": "bbeae1888a51c9cd6dcf2732ddcfd51d791202a3",
            "filename": "tests/models/dinov2_with_registers/test_modeling_dinov2_with_registers.py",
            "status": "modified",
            "additions": 1,
            "deletions": 24,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdinov2_with_registers%2Ftest_modeling_dinov2_with_registers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdinov2_with_registers%2Ftest_modeling_dinov2_with_registers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdinov2_with_registers%2Ftest_modeling_dinov2_with_registers.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -27,7 +27,7 @@\n \n from ...test_backbone_common import BackboneTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -244,29 +244,6 @@ def setUp(self):\n             self, config_class=Dinov2WithRegistersConfig, has_text_modality=False, hidden_size=37\n         )\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad and \"register_tokens\" not in name:\n-                    # See PR #38607 (to avoid flakiness)\n-                    data = torch.flatten(param.data)\n-                    n_elements = torch.numel(data)\n-                    # skip 2.5% of elements on each side to avoid issues caused by `nn.init.trunc_normal_` described in\n-                    # https://github.com/huggingface/transformers/pull/27906#issuecomment-1846951332\n-                    n_elements_to_skip_on_each_side = int(n_elements * 0.025)\n-                    data_to_check = torch.sort(data).values\n-                    if n_elements_to_skip_on_each_side > 0:\n-                        data_to_check = data_to_check[n_elements_to_skip_on_each_side:-n_elements_to_skip_on_each_side]\n-                    self.assertIn(\n-                        ((data_to_check.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_config(self):\n         self.config_tester.run_common_tests()\n "
        },
        {
            "sha": "1de2e6ec5cebf310026c9abdf09327be9a298322",
            "filename": "tests/models/dinov3_vit/test_modeling_dinov3_vit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 24,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdinov3_vit%2Ftest_modeling_dinov3_vit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdinov3_vit%2Ftest_modeling_dinov3_vit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdinov3_vit%2Ftest_modeling_dinov3_vit.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -21,7 +21,7 @@\n from transformers.utils import is_torch_available, is_vision_available\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -160,29 +160,6 @@ def setUp(self):\n         self.model_tester = DINOv3ViTModelTester(self)\n         self.config_tester = ConfigTester(self, config_class=DINOv3ViTConfig, has_text_modality=False, hidden_size=37)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad and \"register_tokens\" not in name:\n-                    # See PR #38607 (to avoid flakiness)\n-                    data = torch.flatten(param.data)\n-                    n_elements = torch.numel(data)\n-                    # skip 2.5% of elements on each side to avoid issues caused by `nn.init.trunc_normal_` described in\n-                    # https://github.com/huggingface/transformers/pull/27906#issuecomment-1846951332\n-                    n_elements_to_skip_on_each_side = int(n_elements * 0.025)\n-                    data_to_check = torch.sort(data).values\n-                    if n_elements_to_skip_on_each_side > 0:\n-                        data_to_check = data_to_check[n_elements_to_skip_on_each_side:-n_elements_to_skip_on_each_side]\n-                    self.assertIn(\n-                        ((data_to_check.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_config(self):\n         self.config_tester.run_common_tests()\n "
        },
        {
            "sha": "720a11ca85f0ab181ce096322938f8517b2d4c73",
            "filename": "tests/models/donut/test_modeling_donut_swin.py",
            "status": "modified",
            "additions": 1,
            "deletions": 15,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdonut%2Ftest_modeling_donut_swin.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdonut%2Ftest_modeling_donut_swin.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdonut%2Ftest_modeling_donut_swin.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -21,7 +21,7 @@\n from transformers.utils import is_torch_available\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -358,17 +358,3 @@ def test_model_from_pretrained(self):\n         model_name = \"naver-clova-ix/donut-base\"\n         model = DonutSwinModel.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n-\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if \"embeddings\" not in name and param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )"
        },
        {
            "sha": "501139310b30fca30ce41da408f682a714b2ebf4",
            "filename": "tests/models/dpt/test_modeling_dpt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 24,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -23,7 +23,7 @@\n from transformers.testing_utils import Expectations, require_torch, require_vision, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -260,29 +260,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_sdpa_can_compile_dynamic(self):\n         pass\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            # Skip the check for the backbone\n-            backbone_params = []\n-            for name, module in model.named_modules():\n-                if module.__class__.__name__ == \"DPTViTHybridEmbeddings\":\n-                    backbone_params = [f\"{name}.{key}\" for key in module.state_dict()]\n-                    break\n-\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if name in backbone_params:\n-                        continue\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_backbone_selection(self):\n         def _validate_backbone_init():\n             for model_class in self.all_model_classes:"
        },
        {
            "sha": "237045464a875a98a0ef3119cdd56a6945d3795a",
            "filename": "tests/models/dpt/test_modeling_dpt_auto_backbone.py",
            "status": "modified",
            "additions": 1,
            "deletions": 24,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_auto_backbone.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_auto_backbone.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_auto_backbone.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -21,7 +21,7 @@\n from transformers.utils.import_utils import get_torch_major_and_minor_version\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -194,29 +194,6 @@ def test_training_gradient_checkpointing(self):\n             loss = model(**inputs).loss\n             loss.backward()\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            # Skip the check for the backbone\n-            backbone_params = []\n-            for name, module in model.named_modules():\n-                if module.__class__.__name__ == \"DPTViTHybridEmbeddings\":\n-                    backbone_params = [f\"{name}.{key}\" for key in module.state_dict()]\n-                    break\n-\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if name in backbone_params:\n-                        continue\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     @unittest.skip(reason=\"DPT with AutoBackbone does not have a base model and hence no input_embeddings\")\n     def test_model_get_set_embeddings(self):\n         pass"
        },
        {
            "sha": "c28260320bf1975f0d52d843fac4924d41b9a32d",
            "filename": "tests/models/dpt/test_modeling_dpt_hybrid.py",
            "status": "modified",
            "additions": 1,
            "deletions": 24,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_hybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_hybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_hybrid.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -20,7 +20,7 @@\n from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -270,29 +270,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            # Skip the check for the backbone\n-            backbone_params = []\n-            for name, module in model.named_modules():\n-                if module.__class__.__name__ == \"DPTViTHybridEmbeddings\":\n-                    backbone_params = [f\"{name}.{key}\" for key in module.state_dict()]\n-                    break\n-\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if name in backbone_params:\n-                        continue\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"Intel/dpt-hybrid-midas\""
        },
        {
            "sha": "3bbc350a08414feb40d41ebf3f24a502c87d5104",
            "filename": "tests/models/edgetam/test_modeling_edgetam.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fedgetam%2Ftest_modeling_edgetam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fedgetam%2Ftest_modeling_edgetam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fedgetam%2Ftest_modeling_edgetam.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -367,10 +367,6 @@ def test_hidden_states_output(self):\n     def test_can_init_all_missing_weights(self):\n         pass\n \n-    @unittest.skip(reason=\"Timm weights cannot be fully constructed in _init_weights\")\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(\n         reason=\"TIMM's attention implementation is self configured and won't raise ValueError on global attention implementation.\"\n     )"
        },
        {
            "sha": "71d3c9f48b524d7a1d3b5b6d2fa555f1331c2e52",
            "filename": "tests/models/emu3/test_modeling_emu3.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Femu3%2Ftest_modeling_emu3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Femu3%2Ftest_modeling_emu3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Femu3%2Ftest_modeling_emu3.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -348,10 +348,6 @@ def test_disk_offload_bin(self):\n     def test_cpu_offload(self):\n         pass\n \n-    @unittest.skip(\"VQ-VAE module doesn't initialize weights properly\")\n-    def test_initialization(self):\n-        pass\n-\n     @pytest.mark.generate\n     @unittest.skip(\"Emu3 has dynamic control flow in vision backbone\")\n     def test_generate_with_static_cache(self):"
        },
        {
            "sha": "2dfbbcaee41e69695e4a44fef95b38f291237e7f",
            "filename": "tests/models/encodec/test_modeling_encodec.py",
            "status": "modified",
            "additions": 0,
            "deletions": 22,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fencodec%2Ftest_modeling_encodec.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fencodec%2Ftest_modeling_encodec.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fencodec%2Ftest_modeling_encodec.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -410,28 +410,6 @@ def check_equivalence(model, tuple_inputs, dict_inputs, additional_kwargs={}):\n             dict_inputs = self._prepare_for_class(inputs_dict, model_class)\n             check_equivalence(model, tuple_inputs, dict_inputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\"conv\"]\n-                ignore_init = [\"lstm\"]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    elif not any(x in name for x in ignore_init):\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def test_identity_shortcut(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs()\n         config.use_conv_shortcut = False"
        },
        {
            "sha": "7c8163266479722dc28329f9b000f02f2bcfd53e",
            "filename": "tests/models/eomt/test_modeling_eomt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 35,
            "changes": 36,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Feomt%2Ftest_modeling_eomt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Feomt%2Ftest_modeling_eomt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Feomt%2Ftest_modeling_eomt.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -22,7 +22,7 @@\n from transformers.utils import is_torch_available, is_vision_available\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -232,40 +232,6 @@ def test_training(self):\n             loss = model(**inputs).loss\n             loss.backward()\n \n-    def test_initialization(self):\n-        # Apart from the below params, all other parameters are initialized using kaiming uniform.\n-        non_uniform_init_parms = [\n-            \"layernorm.bias\",\n-            \"layernorm.weight\",\n-            \"norm1.bias\",\n-            \"norm1.weight\",\n-            \"norm2.bias\",\n-            \"norm2.weight\",\n-            \"layer_scale1.lambda1\",\n-            \"layer_scale2.lambda1\",\n-            \"register_tokens\",\n-            \"cls_token\",\n-        ]\n-\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if any(x in name for x in non_uniform_init_parms):\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n \n @require_torch\n class EomtForUniversalSegmentationIntegrationTest(unittest.TestCase):"
        },
        {
            "sha": "ff28ad50baecbf78b0d7163ab0126431c81c8dac",
            "filename": "tests/models/esm/test_modeling_esmfold.py",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fesm%2Ftest_modeling_esmfold.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fesm%2Ftest_modeling_esmfold.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fesm%2Ftest_modeling_esmfold.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -240,12 +240,6 @@ def test_model_outputs_equivalence(self):\n     def test_feed_forward_chunking(self):\n         pass\n \n-    @unittest.skip(\n-        reason=\"ESMFold doesn't respect you and it certainly doesn't respect your initialization arguments.\"\n-    )\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(reason=\"ESMFold doesn't support torchscript compilation.\")\n     def test_torchscript_output_attentions(self):\n         pass"
        },
        {
            "sha": "6e399ef0ffde0dd6e12c285b54b859db23840625",
            "filename": "tests/models/evolla/test_modeling_evolla.py",
            "status": "modified",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fevolla%2Ftest_modeling_evolla.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fevolla%2Ftest_modeling_evolla.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fevolla%2Ftest_modeling_evolla.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -32,7 +32,6 @@\n from ...test_modeling_common import (\n     TEST_EAGER_MATCHES_SDPA_INFERENCE_PARAMETERIZATION,\n     ModelTesterMixin,\n-    _config_zero_init,\n     ids_tensor,\n     random_attention_mask,\n )\n@@ -300,25 +299,6 @@ def test_single_forward(self):\n                 outputs = model(**self._prepare_for_class(inputs_dict, model_class))\n             print(outputs)\n \n-    def test_initialization(self):\n-        # we skip the latents initialization test\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # skip latents\n-                    if name.endswith(\"latents\"):\n-                        print(f\"Skipping latents {name}\")\n-                        continue\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     @parameterized.expand(TEST_EAGER_MATCHES_SDPA_INFERENCE_PARAMETERIZATION)\n     @unittest.skip(\"Evolla requires both text and protein inputs which is currently not done in this test.\")\n     def test_eager_matches_sdpa_inference(self):"
        },
        {
            "sha": "919130175b7e66329bb36fc051b424e431e905a1",
            "filename": "tests/models/falcon_mamba/test_modeling_falcon_mamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 41,
            "changes": 42,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ffalcon_mamba%2Ftest_modeling_falcon_mamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ffalcon_mamba%2Ftest_modeling_falcon_mamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ffalcon_mamba%2Ftest_modeling_falcon_mamba.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -13,7 +13,6 @@\n # limitations under the License.\n \n \n-import math\n import unittest\n from unittest.util import safe_repr\n \n@@ -34,7 +33,7 @@\n \n from ...generation.test_utils import GenerationTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -331,45 +330,6 @@ def test_falcon_mamba_lm_head_forward_and_backwards(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_falcon_mamba_lm_head_forward_and_backwards(*config_and_inputs)\n \n-    def test_initialization(self):\n-        config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n-        config.rescale_prenorm_residual = True\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if \"dt_proj.bias\" in name:\n-                    dt = torch.exp(\n-                        torch.tensor([0, 1]) * (math.log(config.time_step_max) - math.log(config.time_step_min))\n-                        + math.log(config.time_step_min)\n-                    ).clamp(min=config.time_step_floor)\n-                    inv_dt = dt + torch.log(-torch.expm1(-dt))\n-                    if param.requires_grad:\n-                        self.assertTrue(param.data.max().item() <= inv_dt[1])\n-                        self.assertTrue(param.data.min().item() >= inv_dt[0])\n-                elif \"A_log\" in name:\n-                    A = torch.arange(1, config.state_size + 1, dtype=torch.float32)[None, :]\n-                    A = A.expand(config.intermediate_size, -1).contiguous()\n-                    torch.testing.assert_close(param.data, torch.log(A), rtol=1e-5, atol=1e-5)\n-                elif \"D\" in name:\n-                    if param.requires_grad:\n-                        # check if it's a ones like\n-                        torch.testing.assert_close(param.data, torch.ones_like(param.data), rtol=1e-5, atol=1e-5)\n-                else:\n-                    if param.requires_grad:\n-                        if (\n-                            \"mixer.conv1d.weight\" in name\n-                            or \"mixer.dt_proj.weight\" in name\n-                            or \"mixer.out_proj.weight\" in name\n-                        ):\n-                            continue\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     @slow\n     # Ignore copy\n     def test_model_from_pretrained(self):"
        },
        {
            "sha": "33889a7a9404a86766c184962c7c6d2dd6fa3a33",
            "filename": "tests/models/fastspeech2_conformer/test_modeling_fastspeech2_conformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 33,
            "changes": 34,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ffastspeech2_conformer%2Ftest_modeling_fastspeech2_conformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ffastspeech2_conformer%2Ftest_modeling_fastspeech2_conformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ffastspeech2_conformer%2Ftest_modeling_fastspeech2_conformer.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -33,7 +33,7 @@\n )\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, ids_tensor\n \n \n if is_torch_available():\n@@ -141,22 +141,6 @@ def test_model(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    def test_initialization(self):\n-        config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    msg = f\"Parameter {name} of model {model_class} seems not properly initialized\"\n-                    if \"norm\" in name:\n-                        if \"bias\" in name:\n-                            self.assertEqual(param.data.mean().item(), 0.0, msg=msg)\n-                        if \"weight\" in name:\n-                            self.assertEqual(param.data.mean().item(), 1.0, msg=msg)\n-                    elif \"conv\" in name or \"embed\" in name:\n-                        self.assertTrue(-1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0, msg=msg)\n-\n     def test_duration_energy_pitch_output(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n         config.return_dict = True\n@@ -573,22 +557,6 @@ def test_model(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    def test_initialization(self):\n-        config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    msg = f\"Parameter {name} of model {model_class} seems not properly initialized\"\n-                    if \"norm\" in name:\n-                        if \"bias\" in name:\n-                            self.assertEqual(param.data.mean().item(), 0.0, msg=msg)\n-                        if \"weight\" in name:\n-                            self.assertEqual(param.data.mean().item(), 1.0, msg=msg)\n-                    elif \"conv\" in name or \"embed\" in name:\n-                        self.assertTrue(-1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0, msg=msg)\n-\n     def _prepare_for_class(self, inputs_dict, model_class, return_labels=False):\n         return inputs_dict\n "
        },
        {
            "sha": "5333e6ef9242af168483418f5d26b15acaacb65a",
            "filename": "tests/models/flava/test_modeling_flava.py",
            "status": "modified",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fflava%2Ftest_modeling_flava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fflava%2Ftest_modeling_flava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fflava%2Ftest_modeling_flava.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -920,30 +920,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    # override as the `logit_scale` parameter initialization is different for FLAVA\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\" or name == \"flava.logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")"
        },
        {
            "sha": "f09d8e8a8e5152afa3090957a108c81df335c0d6",
            "filename": "tests/models/focalnet/test_modeling_focalnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 15,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ffocalnet%2Ftest_modeling_focalnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ffocalnet%2Ftest_modeling_focalnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ffocalnet%2Ftest_modeling_focalnet.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -23,7 +23,7 @@\n \n from ...test_backbone_common import BackboneTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -387,20 +387,6 @@ def test_model_from_pretrained(self):\n         model = FocalNetModel.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if \"embeddings\" not in name and param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n \n @require_vision\n @require_torch"
        },
        {
            "sha": "bcceea0e73790a3d00e3e937d040354546ca97a9",
            "filename": "tests/models/gemma3/test_modeling_gemma3.py",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fgemma3%2Ftest_modeling_gemma3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fgemma3%2Ftest_modeling_gemma3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgemma3%2Ftest_modeling_gemma3.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -335,12 +335,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(\n-        reason=\"Siglip (vision backbone) uses the same initialization scheme as the Flax original implementation\"\n-    )\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(\"Loading nested configs with overwritten `kwargs` isn't supported yet, FIXME @raushan.\")\n     def test_load_with_mismatched_shapes(self):\n         pass"
        },
        {
            "sha": "06c118955aff71c28d8b65a965fab84b3722fd29",
            "filename": "tests/models/gemma3n/test_modeling_gemma3n.py",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fgemma3n%2Ftest_modeling_gemma3n.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fgemma3n%2Ftest_modeling_gemma3n.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgemma3n%2Ftest_modeling_gemma3n.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -147,7 +147,6 @@ class Gemma3nAudioModelTest(ModelTesterMixin, unittest.TestCase):\n     is_generative = False\n     _is_stateful = True\n     main_input_name = \"audio_mel\"\n-    test_initialization = False\n \n     def setUp(self):\n         self.model_tester = Gemma3nAudioModelTester(self)\n@@ -700,10 +699,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"Siglip (vision backbone) uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(\n         reason=\"Siglip has no FLEX attention, and we don't have a proper way to set/test attn in VLMs. TODO @raushan\"\n     )"
        },
        {
            "sha": "db9f9f97d41758982600166b187e5594d2500745",
            "filename": "tests/models/got_ocr2/test_modeling_got_ocr2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 15,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fgot_ocr2%2Ftest_modeling_got_ocr2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fgot_ocr2%2Ftest_modeling_got_ocr2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgot_ocr2%2Ftest_modeling_got_ocr2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -25,7 +25,7 @@\n \n from ...generation.test_utils import GenerationTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -162,20 +162,6 @@ def setUp(self):\n     def test_config(self):\n         self.config_tester.run_common_tests()\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n \n @require_torch\n class GotOcr2IntegrationTest(unittest.TestCase):"
        },
        {
            "sha": "516d44896c2ede127d41ffbc6b4cfad8fb2b5872",
            "filename": "tests/models/granite_speech/test_modeling_granite_speech.py",
            "status": "modified",
            "additions": 0,
            "deletions": 17,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fgranite_speech%2Ftest_modeling_granite_speech.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fgranite_speech%2Ftest_modeling_granite_speech.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgranite_speech%2Ftest_modeling_granite_speech.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -40,7 +40,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n )\n@@ -251,22 +250,6 @@ def test_inputs_embeds(self):\n             with torch.no_grad():\n                 model(**inputs)\n \n-    def test_initialization(self):\n-        config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if name == \"projector.query\":\n-                    continue\n-                elif param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_sdpa_can_dispatch_composite_models(self):\n         # overwrite because Granite Speech is audio+text model (not vision+text)\n         if not self.has_attentions:"
        },
        {
            "sha": "6de95751f16526024a2d5f603ea998a5f7c3dd46",
            "filename": "tests/models/grounding_dino/test_modeling_grounding_dino.py",
            "status": "modified",
            "additions": 1,
            "deletions": 27,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fgrounding_dino%2Ftest_modeling_grounding_dino.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fgrounding_dino%2Ftest_modeling_grounding_dino.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgrounding_dino%2Ftest_modeling_grounding_dino.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -40,7 +40,7 @@\n )\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -569,32 +569,6 @@ def test_hf_backbone(self):\n \n             self.assertTrue(outputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if (\n-                        \"level_embed\" in name\n-                        or \"sampling_offsets.bias\" in name\n-                        or \"text_param\" in name\n-                        or \"vision_param\" in name\n-                        or \"value_proj\" in name\n-                        or \"output_proj\" in name\n-                        or \"reference_points\" in name\n-                        or \"vision_proj\" in name\n-                        or \"text_proj\" in name\n-                    ):\n-                        continue\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     # Copied from tests.models.deformable_detr.test_modeling_deformable_detr.DeformableDetrModelTest.test_two_stage_training with DeformableDetr->GroundingDino\n     def test_two_stage_training(self):\n         model_class = GroundingDinoForObjectDetection"
        },
        {
            "sha": "7dcc17070a108988b1ccb8520e7d021f6644292c",
            "filename": "tests/models/groupvit/test_modeling_groupvit.py",
            "status": "modified",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fgroupvit%2Ftest_modeling_groupvit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fgroupvit%2Ftest_modeling_groupvit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgroupvit%2Ftest_modeling_groupvit.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -566,30 +566,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    # override as the `logit_scale` parameter initialization is different for GROUPVIT\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")"
        },
        {
            "sha": "1900f94657a848670d4f0bf9abf7e2d5c22913cf",
            "filename": "tests/models/hgnet_v2/test_modeling_hgnet_v2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 17,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fhgnet_v2%2Ftest_modeling_hgnet_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fhgnet_v2%2Ftest_modeling_hgnet_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fhgnet_v2%2Ftest_modeling_hgnet_v2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -16,7 +16,6 @@\n import unittest\n \n import torch\n-from torch import nn\n \n from transformers import HGNetV2Config\n from transformers.testing_utils import require_torch, torch_device\n@@ -208,22 +207,6 @@ def test_backbone(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_backbone(*config_and_inputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=config)\n-            for name, module in model.named_modules():\n-                if isinstance(module, (nn.BatchNorm2d, nn.GroupNorm)):\n-                    self.assertTrue(\n-                        torch.all(module.weight == 1),\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-                    self.assertTrue(\n-                        torch.all(module.bias == 0),\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_hidden_states_output(self):\n         def check_hidden_states_output(inputs_dict, config, model_class):\n             model = model_class(config)"
        },
        {
            "sha": "dfa75fbb89c6d0647f345a654377ccb78b703878",
            "filename": "tests/models/hubert/test_modeling_hubert.py",
            "status": "modified",
            "additions": 0,
            "deletions": 52,
            "changes": 52,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fhubert%2Ftest_modeling_hubert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fhubert%2Ftest_modeling_hubert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fhubert%2Ftest_modeling_hubert.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -407,32 +407,6 @@ def test_retain_grad_hidden_states_attentions(self):\n         self.assertIsNotNone(hidden_states.grad)\n         self.assertIsNotNone(attentions.grad)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"conv.parametrizations.weight\",\n-                    \"masked_spec_embed\",\n-                    \"quantizer.weight_proj.weight\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # Hubert cannot be TorchScripted because of torch.nn.utils.weight_norm\n     def _create_and_check_torch_fx_tracing(self, config, inputs_dict, output_loss=False):\n         # TODO: fix it\n@@ -671,32 +645,6 @@ def test_retain_grad_hidden_states_attentions(self):\n         self.assertIsNotNone(hidden_states.grad)\n         self.assertIsNotNone(attentions.grad)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"conv.parametrizations.weight\",\n-                    \"masked_spec_embed\",\n-                    \"quantizer.weight_proj.weight\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # overwrite from test_modeling_common\n     def _mock_init_weights(self, module):\n         if hasattr(module, \"weight\") and module.weight is not None:"
        },
        {
            "sha": "584680d57d588ec1f349345c416a56c1125c3dfe",
            "filename": "tests/models/internvl/test_modeling_internvl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 15,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -41,7 +41,7 @@\n \n from ...generation.test_utils import GenerationTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -207,20 +207,6 @@ def test_flex_attention_with_grads(self):\n     def test_config(self):\n         self.config_tester.run_common_tests()\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     @unittest.skip(reason=\"Compile not yet supported because in LLava models\")\n     @pytest.mark.torch_compile_test\n     def test_sdpa_can_compile_dynamic(self):"
        },
        {
            "sha": "bcf1a3b491f594289e5e788cc9996a212f52bbc0",
            "filename": "tests/models/jamba/test_modeling_jamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 26,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fjamba%2Ftest_modeling_jamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fjamba%2Ftest_modeling_jamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fjamba%2Ftest_modeling_jamba.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -34,7 +34,7 @@\n )\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, ids_tensor, random_attention_mask\n+from ...test_modeling_common import ModelTesterMixin, ids_tensor, random_attention_mask\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -427,31 +427,6 @@ def test_load_balancing_loss(self):\n         # After #40617, we still have 0.003 % of failure rate here.\n         self.assertNotAlmostEqual(include_padding_result.aux_loss.item(), result.aux_loss.item())\n \n-    def test_initialization(self):\n-        r\"\"\"\n-        Overriding the test_initialization test as the A_log and D params of the Mamba block are initialized differently\n-        \"\"\"\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if \"A_log\" in name:\n-                        A = torch.arange(1, config.mamba_d_state + 1, dtype=torch.float32)[None, :]\n-                        A = A.expand(config.mamba_expand * config.hidden_size, -1).contiguous()\n-                        torch.testing.assert_close(param.data, torch.log(A), rtol=1e-5, atol=1e-5)\n-                    elif \"D\" in name:\n-                        # check if it's a ones like\n-                        torch.testing.assert_close(param.data, torch.ones_like(param.data), rtol=1e-5, atol=1e-5)\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def test_attention_outputs(self):\n         r\"\"\"\n         Overriding the test_attention_outputs test as the Jamba model outputs attention only for its attention layers"
        },
        {
            "sha": "d578337df8866bd2ee81dbae35bdd91aeb47d6e8",
            "filename": "tests/models/kosmos2/test_modeling_kosmos2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fkosmos2%2Ftest_modeling_kosmos2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fkosmos2%2Ftest_modeling_kosmos2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fkosmos2%2Ftest_modeling_kosmos2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -315,24 +315,6 @@ def setUp(self):\n     def test_config(self):\n         self.config_tester.run_common_tests()\n \n-    # overwrite from common to skip `image_to_text_projection.latent_query`\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if name == \"image_to_text_projection.latent_query\":\n-                        # The original code use ` nn.Parameter(torch.randn(...))` for which this test won't pass.\n-                        continue\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_model(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_model(*config_and_inputs)"
        },
        {
            "sha": "fc7dac8f02b5d32da7b1b3815993e13aacd58e77",
            "filename": "tests/models/kosmos2_5/test_modeling_kosmos2_5.py",
            "status": "modified",
            "additions": 0,
            "deletions": 19,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fkosmos2_5%2Ftest_modeling_kosmos2_5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fkosmos2_5%2Ftest_modeling_kosmos2_5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fkosmos2_5%2Ftest_modeling_kosmos2_5.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -43,7 +43,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n@@ -378,24 +377,6 @@ def test_assisted_decoding_sample(self):\n     def test_prompt_lookup_decoding_matches_greedy_search(self):\n         pass\n \n-    # overwrite from common to skip `image_to_text_projection.latent_query`\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if name == \"image_to_text_projection.latent_query\":\n-                        # The original code use ` nn.Parameter(torch.randn(...))` for which this test won't pass.\n-                        continue\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_model(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_model(*config_and_inputs)"
        },
        {
            "sha": "c0ea557a33dad5caa30ef13a6ac730aa32122e3c",
            "filename": "tests/models/kyutai_speech_to_text/test_modeling_kyutai_speech_to_text.py",
            "status": "modified",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fkyutai_speech_to_text%2Ftest_modeling_kyutai_speech_to_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fkyutai_speech_to_text%2Ftest_modeling_kyutai_speech_to_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fkyutai_speech_to_text%2Ftest_modeling_kyutai_speech_to_text.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -41,7 +41,6 @@\n from ...test_modeling_common import (\n     TEST_EAGER_MATCHES_SDPA_INFERENCE_PARAMETERIZATION,\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n )\n@@ -317,25 +316,6 @@ def test_tied_weights_keys(self):\n     def test_generate_without_input_ids(self):\n         pass\n \n-    def test_initialization(self):\n-        \"\"\"\n-        Overrides [ModelTesterMixin.test_initialization] because of specificities of Mimi codec model.\n-        See https://github.com/huggingface/transformers/blob/1077603410cd73ba71d64a522033574d66d64b55/tests/models/mimi/test_modeling_mimi.py#L384-L397\n-        \"\"\"\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\"conv\", \"input_proj\", \"output_proj\"]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     @parameterized.expand(TEST_EAGER_MATCHES_SDPA_INFERENCE_PARAMETERIZATION)\n     def test_eager_matches_sdpa_inference(\n         self, name, dtype, padding_side, use_attention_mask, output_attentions, enable_kernels"
        },
        {
            "sha": "4faf6aa61b4a1fd68a665f81a9c1bb0abf43e91c",
            "filename": "tests/models/layoutlmv2/test_modeling_layoutlmv2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 18,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Flayoutlmv2%2Ftest_modeling_layoutlmv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Flayoutlmv2%2Ftest_modeling_layoutlmv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flayoutlmv2%2Ftest_modeling_layoutlmv2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -26,7 +26,7 @@\n from transformers.utils import is_detectron2_available, is_torch_available\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, ids_tensor, random_attention_mask\n+from ...test_modeling_common import ModelTesterMixin, ids_tensor, random_attention_mask\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -432,23 +432,6 @@ def test_model_from_pretrained(self):\n         model = LayoutLMv2Model.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if \"backbone\" in name or \"visual_segment_embedding\" in name:\n-                    continue\n-\n-                if param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_batching_equivalence(self):\n         def equivalence(tensor1, tensor2):\n             return 1.0 - F.cosine_similarity(tensor1.float().flatten(), tensor2.float().flatten(), dim=0, eps=0)"
        },
        {
            "sha": "d097d7e9e6290dcd97336e0afdd56af65771a0fe",
            "filename": "tests/models/lfm2_vl/test_modeling_lfm2_vl.py",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Flfm2_vl%2Ftest_modeling_lfm2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Flfm2_vl%2Ftest_modeling_lfm2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flfm2_vl%2Ftest_modeling_lfm2_vl.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -204,12 +204,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(\n-        reason=\"Siglip2 backbone has a non-standard initialization scheme, that this test cannot handle easily\"\n-    )\n-    def test_initialization(self):\n-        pass\n-\n \n @require_torch_accelerator\n @require_read_token"
        },
        {
            "sha": "ef2b1609ba99ce452d61e5080778c9604fbeb3c1",
            "filename": "tests/models/llava_next/test_modeling_llava_next.py",
            "status": "modified",
            "additions": 0,
            "deletions": 17,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fllava_next%2Ftest_modeling_llava_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fllava_next%2Ftest_modeling_llava_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fllava_next%2Ftest_modeling_llava_next.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -41,7 +41,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n )\n@@ -205,22 +204,6 @@ def setUp(self):\n     def test_config(self):\n         self.config_tester.run_common_tests()\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if \"image_newline\" in name:\n-                    continue\n-                elif param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_mismatching_num_image_tokens(self):\n         \"\"\"\n         Tests that VLMs through an error with explicit message saying what is wrong"
        },
        {
            "sha": "d8980f35fdcfef7be5ac3bf43d8a3ecea1c7aaac",
            "filename": "tests/models/llava_next_video/test_modeling_llava_next_video.py",
            "status": "modified",
            "additions": 0,
            "deletions": 17,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fllava_next_video%2Ftest_modeling_llava_next_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fllava_next_video%2Ftest_modeling_llava_next_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fllava_next_video%2Ftest_modeling_llava_next_video.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -41,7 +41,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n )\n@@ -218,22 +217,6 @@ def setUp(self):\n     def test_config(self):\n         self.config_tester.run_common_tests()\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if \"image_newline\" in name:\n-                    continue\n-                elif param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_mismatching_num_image_tokens(self):\n         \"\"\"\n         Tests that VLMs through an error with explicit message saying what is wrong"
        },
        {
            "sha": "c2280478a35b36f69c06ca71602c347f03175066",
            "filename": "tests/models/llava_onevision/test_modeling_llava_onevision.py",
            "status": "modified",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fllava_onevision%2Ftest_modeling_llava_onevision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fllava_onevision%2Ftest_modeling_llava_onevision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fllava_onevision%2Ftest_modeling_llava_onevision.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -41,7 +41,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n )\n@@ -215,23 +214,6 @@ def setUp(self):\n     def test_config(self):\n         self.config_tester.run_common_tests()\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                # LLaVa Onevision has SigLIP backbone which init weights differently from CLIP\n-                if \"image_newline\" in name or \"vision_tower\" in name:\n-                    continue\n-                elif param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_odd_sized_image(self):\n         # prepare model configuration\n         config = self.model_tester.get_config()"
        },
        {
            "sha": "f63b3cf012a07e991fab29a38550d4ad6595daf0",
            "filename": "tests/models/mamba/test_modeling_mamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 41,
            "changes": 42,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmamba%2Ftest_modeling_mamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmamba%2Ftest_modeling_mamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmamba%2Ftest_modeling_mamba.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -13,7 +13,6 @@\n # limitations under the License.\n \n \n-import math\n import unittest\n from unittest.util import safe_repr\n \n@@ -25,7 +24,7 @@\n \n from ...generation.test_utils import GenerationTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -298,45 +297,6 @@ def test_mamba_lm_head_forward_and_backwards(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_mamba_lm_head_forward_and_backwards(*config_and_inputs)\n \n-    def test_initialization(self):\n-        config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n-        config.rescale_prenorm_residual = True\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if \"dt_proj.bias\" in name:\n-                    dt = torch.exp(\n-                        torch.tensor([0, 1]) * (math.log(config.time_step_max) - math.log(config.time_step_min))\n-                        + math.log(config.time_step_min)\n-                    ).clamp(min=config.time_step_floor)\n-                    inv_dt = dt + torch.log(-torch.expm1(-dt))\n-                    if param.requires_grad:\n-                        self.assertTrue(param.data.max().item() <= inv_dt[1])\n-                        self.assertTrue(param.data.min().item() >= inv_dt[0])\n-                elif \"A_log\" in name:\n-                    A = torch.arange(1, config.state_size + 1, dtype=torch.float32)[None, :]\n-                    A = A.expand(config.intermediate_size, -1).contiguous()\n-                    torch.testing.assert_close(param.data, torch.log(A), rtol=1e-5, atol=1e-5)\n-                elif \"D\" in name:\n-                    if param.requires_grad:\n-                        # check if it's a ones like\n-                        torch.testing.assert_close(param.data, torch.ones_like(param.data), rtol=1e-5, atol=1e-5)\n-                else:\n-                    if param.requires_grad:\n-                        if (\n-                            \"mixer.conv1d.weight\" in name\n-                            or \"mixer.dt_proj.weight\" in name\n-                            or \"mixer.out_proj.weight\" in name\n-                        ):\n-                            continue\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model = MambaModel.from_pretrained(\"hf-internal-testing/mamba-130m\")"
        },
        {
            "sha": "0589b4778b8d8888e166145c0e8808ccbce1c810",
            "filename": "tests/models/mamba2/test_modeling_mamba2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 36,
            "changes": 37,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmamba2%2Ftest_modeling_mamba2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmamba2%2Ftest_modeling_mamba2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmamba2%2Ftest_modeling_mamba2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -13,7 +13,6 @@\n # limitations under the License.\n \n \n-import math\n import unittest\n \n from transformers import AutoTokenizer, Mamba2Config, is_torch_available\n@@ -29,7 +28,7 @@\n \n from ...generation.test_utils import GenerationTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -273,40 +272,6 @@ def test_mamba2_slow_vs_fast_forward_grouped(self):\n         config_and_inputs[0].n_groups //= 2\n         self.model_tester.create_and_check_mamba2_slow_vs_fast_forward(*config_and_inputs)\n \n-    def test_initialization(self):\n-        config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n-        config.rescale_prenorm_residual = True\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if \"dt_proj.bias\" in name:\n-                    dt = torch.exp(\n-                        torch.tensor([0, 1]) * (math.log(config.time_step_max) - math.log(config.time_step_min))\n-                        + math.log(config.time_step_min)\n-                    ).clamp(min=config.time_step_floor)\n-                    inv_dt = dt + torch.log(-torch.expm1(-dt))\n-                    if param.requires_grad:\n-                        self.assertTrue(param.data.max().item() <= inv_dt[1])\n-                        self.assertTrue(param.data.min().item() >= inv_dt[0])\n-                elif \"A_log\" in name:\n-                    A = torch.arange(1, config.num_heads + 1)\n-                    torch.testing.assert_close(param.data, torch.log(A), rtol=1e-5, atol=1e-5)\n-                elif \"D\" in name:\n-                    if param.requires_grad:\n-                        # check if it's a ones like\n-                        torch.testing.assert_close(param.data, torch.ones_like(param.data), rtol=1e-5, atol=1e-5)\n-                else:\n-                    if param.requires_grad:\n-                        if \"mixer.conv1d.weight\" in name or \"mixer.dt_bias\" in name or \"mixer.out_proj.weight\" in name:\n-                            continue\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     @unittest.skip(reason=\"A large mamba2 would be necessary (and costly) for that\")\n     def test_multi_gpu_data_parallel_forward(self):\n         pass"
        },
        {
            "sha": "2b28936a0dc1b883d1115e0e2685788baddb311a",
            "filename": "tests/models/mask2former/test_modeling_mask2former.py",
            "status": "modified",
            "additions": 1,
            "deletions": 21,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmask2former%2Ftest_modeling_mask2former.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmask2former%2Ftest_modeling_mask2former.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmask2former%2Ftest_modeling_mask2former.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -35,7 +35,7 @@\n )\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init\n+from ...test_modeling_common import ModelTesterMixin\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -351,26 +351,6 @@ def test_backbone_selection(self):\n             elif model.__class__.__name__ == \"Mask2FormerForUniversalSegmentation\":\n                 self.assertEqual(model.model.pixel_level_module.encoder.out_indices, [1, 2, 3])\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if (\n-                        \"self_attn.sampling_offsets.bias\" in name\n-                        or \"self_attn.value_proj.weight\" in name\n-                        or \"self_attn.output_proj.weight\" in name\n-                    ):\n-                        continue\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_initialization_pretrained_backbone(self):\n         backbone_name = \"microsoft/resnet-18\"\n "
        },
        {
            "sha": "0a944c49d9c9abda97ac8150c07565d4ec13f447",
            "filename": "tests/models/maskformer/test_modeling_maskformer_swin.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmaskformer%2Ftest_modeling_maskformer_swin.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmaskformer%2Ftest_modeling_maskformer_swin.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmaskformer%2Ftest_modeling_maskformer_swin.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -311,10 +311,6 @@ def test_hidden_states_output_with_padding(self):\n     def test_model_from_pretrained(self):\n         pass\n \n-    @unittest.skip(reason=\"This will be fixed once MaskFormerSwin is replaced by native Swin\")\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(reason=\"This will be fixed once MaskFormerSwin is replaced by native Swin\")\n     def test_gradient_checkpointing_backward_compatibility(self):\n         pass"
        },
        {
            "sha": "b13cb0855923a2fdee688fed092f239c08082fd7",
            "filename": "tests/models/metaclip_2/test_modeling_metaclip_2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmetaclip_2%2Ftest_modeling_metaclip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmetaclip_2%2Ftest_modeling_metaclip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmetaclip_2%2Ftest_modeling_metaclip_2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -572,30 +572,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    # override as the `logit_scale` parameter initialization is different for MetaClip2\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")\n@@ -761,10 +737,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"MetaClip2 uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n     @parameterized.expand(TEST_EAGER_MATCHES_SDPA_INFERENCE_PARAMETERIZATION)\n     @slow\n     @is_flaky()"
        },
        {
            "sha": "865705481e3aae295abdc43b9c1c2a1d53dd98e0",
            "filename": "tests/models/mgp_str/test_modeling_mgp_str.py",
            "status": "modified",
            "additions": 1,
            "deletions": 17,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmgp_str%2Ftest_modeling_mgp_str.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmgp_str%2Ftest_modeling_mgp_str.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmgp_str%2Ftest_modeling_mgp_str.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -22,7 +22,7 @@\n from transformers.utils import is_torch_available, is_vision_available\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -203,22 +203,6 @@ def check_hidden_states_output(inputs_dict, config, model_class):\n \n             check_hidden_states_output(inputs_dict, config, model_class)\n \n-    # override as the `logit_scale` parameter initialization is different for MgpstrModel\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if isinstance(param, (nn.Linear, nn.Conv2d, nn.LayerNorm)):\n-                    if param.requires_grad:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     @unittest.skip(reason=\"Retain_grad is tested in individual model tests\")\n     def test_retain_grad_hidden_states_attentions(self):\n         pass"
        },
        {
            "sha": "9b49c903baf548b6cadfba0e952fa1cf50477bf3",
            "filename": "tests/models/mimi/test_modeling_mimi.py",
            "status": "modified",
            "additions": 0,
            "deletions": 15,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmimi%2Ftest_modeling_mimi.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmimi%2Ftest_modeling_mimi.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmimi%2Ftest_modeling_mimi.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -385,21 +385,6 @@ def check_equivalence(model, tuple_inputs, dict_inputs, additional_kwargs={}):\n             dict_inputs = self._prepare_for_class(inputs_dict, model_class)\n             check_equivalence(model, tuple_inputs, dict_inputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\"conv\", \"input_proj\", \"output_proj\"]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # Copied from transformers.tests.encodec.test_modeling_encodec.MimiModelTest.test_identity_shortcut\n     def test_identity_shortcut(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs()"
        },
        {
            "sha": "694cf3a267bb88ed93d3ec503e6457571bf02591",
            "filename": "tests/models/mistral3/test_modeling_mistral3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 15,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmistral3%2Ftest_modeling_mistral3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmistral3%2Ftest_modeling_mistral3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmistral3%2Ftest_modeling_mistral3.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -36,7 +36,7 @@\n \n from ...generation.test_utils import GenerationTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -192,20 +192,6 @@ def check_config_can_be_init_without_params():\n         self.config_tester.check_config_can_be_init_without_params = check_config_can_be_init_without_params\n         self.config_tester.run_common_tests()\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     @unittest.skip(reason=\"Compile not yet supported because in LLava models\")\n     @pytest.mark.torch_compile_test\n     def test_sdpa_can_compile_dynamic(self):"
        },
        {
            "sha": "bca94e9bf67917be1be7944f366cf1f1d52b5369",
            "filename": "tests/models/mlcd/test_modeling_mlcd.py",
            "status": "modified",
            "additions": 1,
            "deletions": 15,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmlcd%2Ftest_modeling_mlcd.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmlcd%2Ftest_modeling_mlcd.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmlcd%2Ftest_modeling_mlcd.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -32,7 +32,7 @@\n )\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor\n \n \n if is_torch_available():\n@@ -141,20 +141,6 @@ def test_model_get_set_embeddings(self):\n             x = model.get_output_embeddings()\n             self.assertTrue(x is None or isinstance(x, torch.nn.Linear))\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad and \"class_pos_emb\" not in name:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n \n @require_torch\n class MLCDVisionModelIntegrationTest(unittest.TestCase):"
        },
        {
            "sha": "f1e63787fc571d856d06866ce6cd747d6c00ba9a",
            "filename": "tests/models/mm_grounding_dino/test_modeling_mm_grounding_dino.py",
            "status": "modified",
            "additions": 1,
            "deletions": 29,
            "changes": 30,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmm_grounding_dino%2Ftest_modeling_mm_grounding_dino.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmm_grounding_dino%2Ftest_modeling_mm_grounding_dino.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmm_grounding_dino%2Ftest_modeling_mm_grounding_dino.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -39,7 +39,7 @@\n )\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -574,34 +574,6 @@ def test_hf_backbone(self):\n \n             self.assertTrue(outputs)\n \n-    # Ignore copy\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if (\n-                        \"level_embed\" in name\n-                        or \"sampling_offsets.bias\" in name\n-                        or \"text_param\" in name\n-                        or \"vision_param\" in name\n-                        or \"value_proj\" in name\n-                        or \"output_proj\" in name\n-                        or \"reference_points\" in name\n-                        or \"vision_proj\" in name\n-                        or \"text_proj\" in name\n-                        or (\"class_embed\" in name and \"bias\" in name)\n-                    ):\n-                        continue\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     # Copied from tests.models.deformable_detr.test_modeling_deformable_detr.DeformableDetrModelTest.test_two_stage_training with DeformableDetr->MMGroundingDino\n     def test_two_stage_training(self):\n         model_class = MMGroundingDinoForObjectDetection"
        },
        {
            "sha": "db4180d6d97c21db3a50d11b79327171a4f79c14",
            "filename": "tests/models/modernbert/test_modeling_modernbert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 26,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmodernbert%2Ftest_modeling_modernbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmodernbert%2Ftest_modeling_modernbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmodernbert%2Ftest_modeling_modernbert.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -32,7 +32,7 @@\n )\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, ids_tensor, random_attention_mask\n+from ...test_modeling_common import ModelTesterMixin, ids_tensor, random_attention_mask\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -300,31 +300,6 @@ def test_model_various_embeddings(self):\n             config_and_inputs[0].position_embedding_type = type\n             self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                # The classifier.weight from ModernBertForSequenceClassification and ModernBertForTokenClassification\n-                # are initialized without `initializer_range`, so they're not set to ~0 via the _config_zero_init\n-                if param.requires_grad and not (\n-                    name == \"classifier.weight\"\n-                    and model_class\n-                    in [\n-                        ModernBertForSequenceClassification,\n-                        ModernBertForTokenClassification,\n-                        ModernBertForQuestionAnswering,\n-                        ModernBertForMultipleChoice,\n-                    ]\n-                ):\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_for_masked_lm(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_for_masked_lm(*config_and_inputs)"
        },
        {
            "sha": "d6b1a13105d27f22bf84692d38436c91e9fb6e79",
            "filename": "tests/models/modernbert_decoder/test_modeling_modernbert_decoder.py",
            "status": "modified",
            "additions": 0,
            "deletions": 27,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmodernbert_decoder%2Ftest_modeling_modernbert_decoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmodernbert_decoder%2Ftest_modeling_modernbert_decoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmodernbert_decoder%2Ftest_modeling_modernbert_decoder.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -22,7 +22,6 @@\n )\n \n from ...causal_lm_tester import CausalLMModelTest, CausalLMModelTester\n-from ...test_modeling_common import _config_zero_init\n \n \n if is_torch_available():\n@@ -53,32 +52,6 @@ class ModernBertDecoderModelTest(CausalLMModelTest, unittest.TestCase):\n     )\n     model_tester_class = ModernBertDecoderModelTester\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                # The classifier.weight from ModernBertDecoderForSequenceClassification\n-                # is initialized without `initializer_range`, so it's not set to ~0 via the _config_zero_init\n-                if param.requires_grad and not (\n-                    name == \"classifier.weight\" and model_class == ModernBertDecoderForSequenceClassification\n-                ):\n-                    data = torch.flatten(param.data)\n-                    n_elements = torch.numel(data)\n-                    # skip 2.5% of elements on each side to avoid issues caused by `nn.init.trunc_normal_` described in\n-                    # https://github.com/huggingface/transformers/pull/27906#issuecomment-1846951332\n-                    n_elements_to_skip_on_each_side = int(n_elements * 0.025)\n-                    data_to_check = torch.sort(data).values\n-                    if n_elements_to_skip_on_each_side > 0:\n-                        data_to_check = data_to_check[n_elements_to_skip_on_each_side:-n_elements_to_skip_on_each_side]\n-                    self.assertIn(\n-                        ((data_to_check.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n \n @slow\n @require_torch"
        },
        {
            "sha": "06f81f3ef79c01cc3102b2bf91ab04a4d1358ae9",
            "filename": "tests/models/moshi/test_modeling_moshi.py",
            "status": "modified",
            "additions": 0,
            "deletions": 15,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmoshi%2Ftest_modeling_moshi.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmoshi%2Ftest_modeling_moshi.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmoshi%2Ftest_modeling_moshi.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -582,21 +582,6 @@ def _check_generate_outputs(self, output, config, use_cache=False, num_return_se\n             output, config, use_cache=True, num_return_sequences=num_return_sequences, num_beams=num_beams\n         )\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\"conv\", \"input_proj\", \"output_proj\"]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     @unittest.skip(reason=\"Continuing from past key values is not straightforward as we're dealing with 3 inputs\")\n     def test_generate_continue_from_past_key_values(self):\n         pass"
        },
        {
            "sha": "e5f41ca358d30a7c05dde70880a410a063b81a40",
            "filename": "tests/models/musicgen/test_modeling_musicgen.py",
            "status": "modified",
            "additions": 0,
            "deletions": 23,
            "changes": 23,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmusicgen%2Ftest_modeling_musicgen.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmusicgen%2Ftest_modeling_musicgen.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmusicgen%2Ftest_modeling_musicgen.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -874,29 +874,6 @@ def check_hidden_states_output(inputs_dict, config, model_class):\n \n             check_hidden_states_output(inputs_dict, config, model_class)\n \n-    # override since the conv layers and lstm's in encodec are exceptions\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\"conv\"]\n-                ignore_init = [\"lstm\"]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    elif not any(x in name for x in ignore_init):\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # override since we have embeddings / LM heads over multiple codebooks\n     def test_model_get_set_embeddings(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()"
        },
        {
            "sha": "6f5f8728dbabecddd4dc2e1a85ba6abf3c1109d5",
            "filename": "tests/models/musicgen_melody/test_modeling_musicgen_melody.py",
            "status": "modified",
            "additions": 0,
            "deletions": 23,
            "changes": 23,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmusicgen_melody%2Ftest_modeling_musicgen_melody.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fmusicgen_melody%2Ftest_modeling_musicgen_melody.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmusicgen_melody%2Ftest_modeling_musicgen_melody.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -877,29 +877,6 @@ def check_hidden_states_output(inputs_dict, config, model_class):\n \n             check_hidden_states_output(inputs_dict, config, model_class)\n \n-    # override since the conv layers and lstm's in encodec are exceptions\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\"conv\"]\n-                ignore_init = [\"lstm\"]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    elif not any(x in name for x in ignore_init):\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # override since we have embeddings / LM heads over multiple codebooks\n     def test_model_get_set_embeddings(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()"
        },
        {
            "sha": "bdb6a7477b6616a1c3f86e4b482e96d988b8c6d1",
            "filename": "tests/models/omdet_turbo/test_modeling_omdet_turbo.py",
            "status": "modified",
            "additions": 1,
            "deletions": 24,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fomdet_turbo%2Ftest_modeling_omdet_turbo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fomdet_turbo%2Ftest_modeling_omdet_turbo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fomdet_turbo%2Ftest_modeling_omdet_turbo.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -32,7 +32,7 @@\n )\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -614,29 +614,6 @@ def test_retain_grad_hidden_states_attentions(self):\n         self.assertIsNotNone(encoder_attentions.grad)\n         self.assertIsNotNone(cross_attentions.grad)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if (\n-                        \"embeddings\" in name\n-                        or \".fc\" in name\n-                        or \"decoder.channel_projection_layers\" in name\n-                        or \"query_position_head\" in name\n-                        or \"decoder.encoder_vision_features\" in name\n-                        or \"language_backbone.text_projection\" in name\n-                    ):\n-                        continue\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} seems not properly initialized\",\n-                    )\n-\n \n # We will verify our results on an image of cute cats\n def prepare_img():"
        },
        {
            "sha": "0fc2ae46952c1ef6293afe27196df605bf66adc9",
            "filename": "tests/models/oneformer/test_modeling_oneformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 29,
            "changes": 30,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Foneformer%2Ftest_modeling_oneformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Foneformer%2Ftest_modeling_oneformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Foneformer%2Ftest_modeling_oneformer.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -35,7 +35,7 @@\n )\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init\n+from ...test_modeling_common import ModelTesterMixin\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -364,34 +364,6 @@ def test_attention_outputs(self):\n             outputs = model(**inputs, output_attentions=True)\n             self.assertTrue(outputs.attentions is not None)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-        config.is_training = True\n-        config.contrastive_temperature = 1\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if (\n-                        \"self_attn.sampling_offsets.bias\" in name\n-                        or \"self_attn.value_proj.weight\" in name\n-                        or \"self_attn.output_proj.weight\" in name\n-                        or \"self_attn.in_proj_weight\" in name\n-                        or \"self_attn.out_proj.weight\" in name\n-                        or \"mlp.fc1.weight\" in name\n-                        or \"mlp.fc2.weight\" in name\n-                        or \"text_mapper.text_encoder.positional_embedding\" in name\n-                        or \"text_mapper.text_encoder.token_embedding.weight\" in name\n-                    ):\n-                        continue\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_initialization_pretrained_backbone(self):\n         backbone_name = \"microsoft/resnet-18\"\n "
        },
        {
            "sha": "d8afcbb45836608a50f18614ab0b7770e314a308",
            "filename": "tests/models/owlv2/test_modeling_owlv2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fowlv2%2Ftest_modeling_owlv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fowlv2%2Ftest_modeling_owlv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fowlv2%2Ftest_modeling_owlv2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -459,30 +459,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    # override as the `logit_scale` parameter initialization is different for OWLV2\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")\n@@ -668,10 +644,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    @unittest.skip(reason=\"Test_initialization is tested in individual model tests\")\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(reason=\"Test_forward_signature is tested in individual model tests\")\n     def test_forward_signature(self):\n         pass"
        },
        {
            "sha": "185d952447599ccfe99d6f605bdc5e41750a88e7",
            "filename": "tests/models/owlvit/test_modeling_owlvit.py",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fowlvit%2Ftest_modeling_owlvit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fowlvit%2Ftest_modeling_owlvit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fowlvit%2Ftest_modeling_owlvit.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -454,30 +454,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    # override as the `logit_scale` parameter initialization is different for OWLVIT\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")\n@@ -661,10 +637,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    @unittest.skip(reason=\"Test_initialization is tested in individual model tests\")\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(reason=\"Test_forward_signature is tested in individual model tests\")\n     def test_forward_signature(self):\n         pass"
        },
        {
            "sha": "5797f75b2fb5ecf4eb438abd4aff1e1b2bbf1468",
            "filename": "tests/models/paligemma/test_modeling_paligemma.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fpaligemma%2Ftest_modeling_paligemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fpaligemma%2Ftest_modeling_paligemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpaligemma%2Ftest_modeling_paligemma.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -265,10 +265,6 @@ def test_disk_offload_safetensors(self):\n     def test_model_parallelism(self):\n         pass\n \n-    @unittest.skip(reason=\"PaliGemma's SigLip encoder uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n     # TODO extend valid outputs to include this test @Molbap\n     @unittest.skip(reason=\"PaliGemma has currently one output format.\")\n     def test_model_outputs_equivalence(self):"
        },
        {
            "sha": "8cb7feabe8a1872aebacc5df47d84a3e42cfb173",
            "filename": "tests/models/paligemma2/test_modeling_paligemma2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fpaligemma2%2Ftest_modeling_paligemma2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fpaligemma2%2Ftest_modeling_paligemma2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpaligemma2%2Ftest_modeling_paligemma2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -244,10 +244,6 @@ def test_disk_offload_safetensors(self):\n     def test_model_parallelism(self):\n         pass\n \n-    @unittest.skip(reason=\"PaliGemma's SigLip encoder uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n     # TODO extend valid outputs to include this test @Molbap\n     @unittest.skip(reason=\"PaliGemma has currently one output format.\")\n     def test_model_outputs_equivalence(self):"
        },
        {
            "sha": "ba2bf1c582c37ab5cef21ffe4415d635eb9af16f",
            "filename": "tests/models/perception_lm/test_modeling_perception_lm.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fperception_lm%2Ftest_modeling_perception_lm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fperception_lm%2Ftest_modeling_perception_lm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fperception_lm%2Ftest_modeling_perception_lm.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -293,10 +293,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_can_init_all_missing_weights(self):\n         pass\n \n-    @unittest.skip(reason=\"Timm Eva (PE) weights cannot be fully constructed in _init_weights\")\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(\n         reason=\"PE/TIMM's attention implementation is self configured and won't raise ValueError on global attention implementation.\"\n     )"
        },
        {
            "sha": "61c72fe857c13d8107ced5cca2cfb65a0e3eb46d",
            "filename": "tests/models/phi4_multimodal/test_modeling_phi4_multimodal.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fphi4_multimodal%2Ftest_modeling_phi4_multimodal.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fphi4_multimodal%2Ftest_modeling_phi4_multimodal.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fphi4_multimodal%2Ftest_modeling_phi4_multimodal.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -208,10 +208,6 @@ def setUp(self):\n         self.model_tester = Phi4MultimodalModelTester(self)\n         self.config_tester = ConfigTester(self, config_class=Phi4MultimodalConfig)\n \n-    @unittest.skip(reason=\"Unstable test\")\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(reason=\"Depending on input modalities, some params may not have gradients\")\n     def test_training_gradient_checkpointing(self):\n         pass"
        },
        {
            "sha": "813334106ee4b03cb766a7b167ff9aa3cb34bc00",
            "filename": "tests/models/pix2struct/test_modeling_pix2struct.py",
            "status": "modified",
            "additions": 0,
            "deletions": 35,
            "changes": 35,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fpix2struct%2Ftest_modeling_pix2struct.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fpix2struct%2Ftest_modeling_pix2struct.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpix2struct%2Ftest_modeling_pix2struct.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -524,41 +524,6 @@ def test_training_gradient_checkpointing(self):\n             loss = model(**inputs).loss\n             loss.backward()\n \n-    # override as the `logit_scale` parameter initialization is different for Pix2Struct\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        # See PR #38607 (to avoid flakiness)\n-                        data = torch.flatten(param.data)\n-                        n_elements = torch.numel(data)\n-                        # skip 2.5% of elements on each side to avoid issues caused by `nn.init.trunc_normal_` described in\n-                        # https://github.com/huggingface/transformers/pull/27906#issuecomment-1846951332\n-                        n_elements_to_skip_on_each_side = int(n_elements * 0.025)\n-                        data_to_check = torch.sort(data).values\n-                        if n_elements_to_skip_on_each_side > 0:\n-                            data_to_check = data_to_check[\n-                                n_elements_to_skip_on_each_side:-n_elements_to_skip_on_each_side\n-                            ]\n-                        self.assertIn(\n-                            ((data_to_check.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # overwrite because `vocab_size` is not an attribute of `Pix2StructConfig` but rather `Pix2StructTextConfig`\n     def test_resize_tokens_embeddings(self):\n         original_config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()"
        },
        {
            "sha": "ff1264e7988826e8f283a1824c6dd084e1505e93",
            "filename": "tests/models/pvt/test_modeling_pvt.py",
            "status": "modified",
            "additions": 0,
            "deletions": 11,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fpvt%2Ftest_modeling_pvt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fpvt%2Ftest_modeling_pvt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpvt%2Ftest_modeling_pvt.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -171,17 +171,6 @@ def test_inputs_embeds(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=config)\n-            for name, param in model.named_parameters():\n-                self.assertTrue(\n-                    -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                    msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                )\n-\n     def test_hidden_states_output(self):\n         def check_hidden_states_output(inputs_dict, config, model_class):\n             model = model_class(config)"
        },
        {
            "sha": "cfeef2d4d8d695003608656e5c1825a737517fd2",
            "filename": "tests/models/pvt_v2/test_modeling_pvt_v2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 11,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fpvt_v2%2Ftest_modeling_pvt_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fpvt_v2%2Ftest_modeling_pvt_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpvt_v2%2Ftest_modeling_pvt_v2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -188,17 +188,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n         # torch.utils.checkpoint.checkpoint\n         self.check_training_gradient_checkpointing(gradient_checkpointing_kwargs={\"use_reentrant\": True})\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=config)\n-            for name, param in model.named_parameters():\n-                self.assertTrue(\n-                    -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                    msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                )\n-\n     def test_hidden_states_output(self):\n         def check_hidden_states_output(inputs_dict, config, model_class):\n             model = model_class(config)"
        },
        {
            "sha": "1ef2da1af3cfdc0f0de2bf8757e860c2840e6907",
            "filename": "tests/models/qwen2_5_vl/test_modeling_qwen2_5_vl.py",
            "status": "modified",
            "additions": 0,
            "deletions": 15,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -44,7 +44,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n )\n@@ -236,20 +235,6 @@ def test_text_config(self):\n         self.assertEqual(base_config.patch_size, 8)\n         self.assertNotEqual(base_config.vision_config.patch_size, 8)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_mismatching_num_image_tokens(self):\n         \"\"\"\n         Tests that VLMs through an error with explicit message saying what is wrong"
        },
        {
            "sha": "e455c092ba0b02f9c87fbd7d5c7296f6fe6e3720",
            "filename": "tests/models/qwen2_vl/test_modeling_qwen2_vl.py",
            "status": "modified",
            "additions": 0,
            "deletions": 15,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fqwen2_vl%2Ftest_modeling_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fqwen2_vl%2Ftest_modeling_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_vl%2Ftest_modeling_qwen2_vl.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -42,7 +42,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n )\n@@ -216,20 +215,6 @@ def test_text_config(self):\n         self.assertEqual(base_config.patch_size, 8)\n         self.assertNotEqual(base_config.vision_config.patch_size, 8)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_mismatching_num_image_tokens(self):\n         \"\"\"\n         Tests that VLMs through an error with explicit message saying what is wrong"
        },
        {
            "sha": "f0dcdf5ddd4a503526705cb5cbf9339efcb0357c",
            "filename": "tests/models/qwen3_next/test_modeling_qwen3_next.py",
            "status": "modified",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fqwen3_next%2Ftest_modeling_qwen3_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fqwen3_next%2Ftest_modeling_qwen3_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen3_next%2Ftest_modeling_qwen3_next.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -13,7 +13,6 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-import copy\n import tempfile\n import unittest\n \n@@ -40,7 +39,6 @@\n from ...generation.test_utils import has_similar_generate_outputs\n from ...test_modeling_common import (\n     TEST_EAGER_MATCHES_SDPA_INFERENCE_PARAMETERIZATION,\n-    _config_zero_init,\n     _test_eager_matches_sdpa_inference,\n )\n \n@@ -279,24 +277,6 @@ def test_attention_outputs(self):\n             self.assertEqual(len(self_attentions), sum(layer == \"full_attention\" for layer in config.layer_types))\n             self.assertListEqual(list(self_attentions[0].shape[-3:]), [config.num_attention_heads, seq_len, seq_len])\n \n-    def test_initialization(self):\n-        \"Some parameters need to be skipped.\"\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=copy.deepcopy(configs_no_init))\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # this one need to be skipped, it's initialized as log(uniform(0, 16))\n-                    if \"A_log\" in name:\n-                        continue\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     @parameterized.expand(TEST_EAGER_MATCHES_SDPA_INFERENCE_PARAMETERIZATION)\n     def test_eager_matches_sdpa_inference(\n         self,"
        },
        {
            "sha": "db9d2cf4265562b53d263bda85305ea78e4212d9",
            "filename": "tests/models/recurrent_gemma/test_modeling_recurrent_gemma.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Frecurrent_gemma%2Ftest_modeling_recurrent_gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Frecurrent_gemma%2Ftest_modeling_recurrent_gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Frecurrent_gemma%2Ftest_modeling_recurrent_gemma.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -91,10 +91,6 @@ def test_left_padding_compatibility(self):\n     def test_assisted_decoding_sample(self):\n         pass\n \n-    @unittest.skip(reason=\"TODO @arthurzucker not super important and failing.\")\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(reason=\"RecurrentGemma is unusual and fails a lot of generation tests\")\n     @pytest.mark.generate\n     def test_beam_sample_generate_dict_output(self):"
        },
        {
            "sha": "73579fa7d9e83441cf0409997ecfc30fa2d9ceea",
            "filename": "tests/models/regnet/test_modeling_regnet.py",
            "status": "modified",
            "additions": 0,
            "deletions": 17,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fregnet%2Ftest_modeling_regnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fregnet%2Ftest_modeling_regnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fregnet%2Ftest_modeling_regnet.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -27,7 +27,6 @@\n \n if is_torch_available():\n     import torch\n-    from torch import nn\n \n     from transformers import RegNetForImageClassification, RegNetModel\n \n@@ -162,22 +161,6 @@ def test_model(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=config)\n-            for name, module in model.named_modules():\n-                if isinstance(module, (nn.BatchNorm2d, nn.GroupNorm)):\n-                    self.assertTrue(\n-                        torch.all(module.weight == 1),\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-                    self.assertTrue(\n-                        torch.all(module.bias == 0),\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_hidden_states_output(self):\n         def check_hidden_states_output(inputs_dict, config, model_class):\n             model = model_class(config)"
        },
        {
            "sha": "48f250f9ec62dd9dc539175b43c00552e38c1ec7",
            "filename": "tests/models/resnet/test_modeling_resnet.py",
            "status": "modified",
            "additions": 0,
            "deletions": 17,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fresnet%2Ftest_modeling_resnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fresnet%2Ftest_modeling_resnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fresnet%2Ftest_modeling_resnet.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -28,7 +28,6 @@\n \n if is_torch_available():\n     import torch\n-    from torch import nn\n \n     from transformers import ResNetBackbone, ResNetForImageClassification, ResNetModel\n \n@@ -207,22 +206,6 @@ def test_backbone(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_backbone(*config_and_inputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=config)\n-            for name, module in model.named_modules():\n-                if isinstance(module, (nn.BatchNorm2d, nn.GroupNorm)):\n-                    self.assertTrue(\n-                        torch.all(module.weight == 1),\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-                    self.assertTrue(\n-                        torch.all(module.bias == 0),\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_hidden_states_output(self):\n         def check_hidden_states_output(inputs_dict, config, model_class):\n             model = model_class(config)"
        },
        {
            "sha": "eddf6d9a6f919a46be4f45b35f1512483bf055dc",
            "filename": "tests/models/rt_detr/test_modeling_rt_detr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 51,
            "changes": 52,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Frt_detr%2Ftest_modeling_rt_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Frt_detr%2Ftest_modeling_rt_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Frt_detr%2Ftest_modeling_rt_detr.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -39,7 +39,7 @@\n )\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -588,56 +588,6 @@ def test_hf_backbone(self):\n \n             self.assertTrue(outputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        configs_no_init.initializer_bias_prior_prob = 0.2\n-        bias_value = -1.3863  # log_e ((1 - 0.2) / 0.2)\n-\n-        failed_cases = []\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            # Skip the check for the backbone\n-            for name, module in model.named_modules():\n-                if module.__class__.__name__ == \"RTDetrConvEncoder\":\n-                    backbone_params = [f\"{name}.{key}\" for key in module.state_dict()]\n-                    break\n-\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if (\"class_embed\" in name and \"bias\" in name) or \"enc_score_head.bias\" in name:\n-                        bias_tensor = torch.full_like(param.data, bias_value)\n-                        if not torch.allclose(param.data, bias_tensor, atol=1e-4):\n-                            failed_cases.append(\n-                                f\"Parameter {name} of model {model_class} seems not properly initialized. \"\n-                                f\"Biases should be initialized to {bias_value}, got {param.data}\"\n-                            )\n-                    elif (\n-                        \"level_embed\" in name\n-                        or \"sampling_offsets.bias\" in name\n-                        or \"value_proj\" in name\n-                        or \"output_proj\" in name\n-                        or \"reference_points\" in name\n-                        or \"enc_score_head.weight\" in name\n-                        or (\"class_embed\" in name and \"weight\" in name)\n-                        or name in backbone_params\n-                    ):\n-                        continue\n-                    else:\n-                        mean = param.data.mean()\n-                        round_mean = (mean * 1e9).round() / 1e9\n-                        round_mean = round_mean.item()\n-                        if round_mean not in [0.0, 1.0]:\n-                            failed_cases.append(\n-                                f\"Parameter {name} of model {model_class} seems not properly initialized. \"\n-                                f\"Mean is {round_mean}, but should be in [0, 1]\"\n-                            )\n-\n-        message = \"\\n\" + \"\\n\".join(failed_cases)\n-        self.assertTrue(not failed_cases, message)\n-\n     @parameterized.expand([\"float32\", \"float16\", \"bfloat16\"])\n     @require_torch_accelerator\n     @slow"
        },
        {
            "sha": "2b7713af6e84c875aa044890f388b57c2e1c196e",
            "filename": "tests/models/rt_detr_v2/test_modeling_rt_detr_v2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 51,
            "changes": 52,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Frt_detr_v2%2Ftest_modeling_rt_detr_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Frt_detr_v2%2Ftest_modeling_rt_detr_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Frt_detr_v2%2Ftest_modeling_rt_detr_v2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -38,7 +38,7 @@\n )\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -592,56 +592,6 @@ def test_hf_backbone(self):\n \n             self.assertTrue(outputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        configs_no_init.initializer_bias_prior_prob = 0.2\n-        bias_value = -1.3863  # log_e ((1 - 0.2) / 0.2)\n-\n-        failed_cases = []\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            # Skip the check for the backbone\n-            for name, module in model.named_modules():\n-                if module.__class__.__name__ == \"RTDetrV2ConvEncoder\":\n-                    backbone_params = [f\"{name}.{key}\" for key in module.state_dict()]\n-                    break\n-\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if (\"class_embed\" in name and \"bias\" in name) or \"enc_score_head.bias\" in name:\n-                        bias_tensor = torch.full_like(param.data, bias_value)\n-                        if not torch.allclose(param.data, bias_tensor, atol=1e-4):\n-                            failed_cases.append(\n-                                f\"Parameter {name} of model {model_class} seems not properly initialized. \"\n-                                f\"Biases should be initialized to {bias_value}, got {param.data}\"\n-                            )\n-                    elif (\n-                        \"level_embed\" in name\n-                        or \"sampling_offsets.bias\" in name\n-                        or \"value_proj\" in name\n-                        or \"output_proj\" in name\n-                        or \"reference_points\" in name\n-                        or \"enc_score_head.weight\" in name\n-                        or (\"class_embed\" in name and \"weight\" in name)\n-                        or name in backbone_params\n-                    ):\n-                        continue\n-                    else:\n-                        mean = param.data.mean()\n-                        round_mean = (mean * 1e9).round() / 1e9\n-                        round_mean = round_mean.item()\n-                        if round_mean not in [0.0, 1.0]:\n-                            failed_cases.append(\n-                                f\"Parameter {name} of model {model_class} seems not properly initialized. \"\n-                                f\"Mean is {round_mean}, but should be in [0, 1]\"\n-                            )\n-\n-        message = \"\\n\" + \"\\n\".join(failed_cases)\n-        self.assertTrue(not failed_cases, message)\n-\n     @parameterized.expand([\"float32\", \"float16\", \"bfloat16\"])\n     @require_torch_accelerator\n     @slow"
        },
        {
            "sha": "692b5ab5d9bd1c18b1759be829c135155ba5dd81",
            "filename": "tests/models/rwkv/test_modeling_rwkv.py",
            "status": "modified",
            "additions": 0,
            "deletions": 29,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Frwkv%2Ftest_modeling_rwkv.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Frwkv%2Ftest_modeling_rwkv.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Frwkv%2Ftest_modeling_rwkv.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -265,35 +265,6 @@ def test_state_equivalency(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_state_equivalency(*config_and_inputs)\n \n-    def test_initialization(self):\n-        config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=config)\n-            for name, param in model.named_parameters():\n-                if \"time_decay\" in name:\n-                    if param.requires_grad:\n-                        self.assertTrue(param.data.max().item() == 3.0)\n-                        self.assertTrue(param.data.min().item() == -5.0)\n-                elif \"time_first\" in name:\n-                    if param.requires_grad:\n-                        # check if it's a ones like\n-                        torch.testing.assert_close(param.data, torch.ones_like(param.data), rtol=1e-5, atol=1e-5)\n-                elif any(x in name for x in [\"time_mix_key\", \"time_mix_receptance\"]):\n-                    if param.requires_grad:\n-                        self.assertInterval(\n-                            param.data,\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                elif \"time_mix_value\" in name:\n-                    if param.requires_grad:\n-                        self.assertInterval(\n-                            param.data,\n-                            [0.0, 1.3],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def test_attention_outputs(self):\n         r\"\"\"\n         Overriding the test_attention_outputs test as the attention outputs of Rwkv are different from other models"
        },
        {
            "sha": "ab026334c099c59b37eca3a87da48504bf66137a",
            "filename": "tests/models/seamless_m4t/test_modeling_seamless_m4t.py",
            "status": "modified",
            "additions": 0,
            "deletions": 77,
            "changes": 77,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fseamless_m4t%2Ftest_modeling_seamless_m4t.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fseamless_m4t%2Ftest_modeling_seamless_m4t.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fseamless_m4t%2Ftest_modeling_seamless_m4t.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -25,7 +25,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n@@ -374,44 +373,6 @@ def test_model_from_pretrained(self):\n         model = SeamlessM4TModel.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"masked_spec_embed\",\n-                    \"codevectors\",\n-                    \"quantizer.weight_proj.weight\",\n-                    \"project_hid.weight\",\n-                    \"project_hid.bias\",\n-                    \"project_q.weight\",\n-                    \"project_q.bias\",\n-                    \"pos_bias_v\",\n-                    \"pos_bias_u\",\n-                    \"pointwise_conv1\",\n-                    \"pointwise_conv2\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                    \"objective.weight\",\n-                    \"adapter\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     @unittest.skip(reason=\"SeamlessM4TSpeechEncoder doesn't have an embedding layer\")\n     def test_inputs_embeds(self):\n         pass\n@@ -618,44 +579,6 @@ def test_model_from_pretrained(self):\n         model = SeamlessM4TModel.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"masked_spec_embed\",\n-                    \"codevectors\",\n-                    \"quantizer.weight_proj.weight\",\n-                    \"project_hid.weight\",\n-                    \"project_hid.bias\",\n-                    \"project_q.weight\",\n-                    \"project_q.bias\",\n-                    \"pos_bias_v\",\n-                    \"pos_bias_u\",\n-                    \"pointwise_conv1\",\n-                    \"pointwise_conv2\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                    \"objective.weight\",\n-                    \"adapter\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     @unittest.skip(\n         reason=\"Expected missing keys serve when using SeamlessM4TForXXX.from_pretrained from a checkpoint saved by SeamlessM4TModel.save_pretrained.\"\n     )"
        },
        {
            "sha": "66f3353d7482d5c798d0894933ac74a3e73dfa62",
            "filename": "tests/models/seamless_m4t_v2/test_modeling_seamless_m4t_v2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 77,
            "changes": 77,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fseamless_m4t_v2%2Ftest_modeling_seamless_m4t_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fseamless_m4t_v2%2Ftest_modeling_seamless_m4t_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fseamless_m4t_v2%2Ftest_modeling_seamless_m4t_v2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -25,7 +25,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n@@ -400,44 +399,6 @@ def test_model_from_pretrained(self):\n         model = SeamlessM4Tv2Model.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv\",\n-                    \"masked_spec_embed\",\n-                    \"codevectors\",\n-                    \"quantizer.weight_proj.weight\",\n-                    \"project_hid.weight\",\n-                    \"project_hid.bias\",\n-                    \"project_q.weight\",\n-                    \"project_q.bias\",\n-                    \"pos_bias_v\",\n-                    \"pos_bias_u\",\n-                    \"pointwise_conv1\",\n-                    \"pointwise_conv2\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                    \"objective.weight\",\n-                    \"adapter\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     @unittest.skip(reason=\"SeamlessM4Tv2SpeechEncoder doesn't have an embedding layer\")\n     def test_inputs_embeds(self):\n         pass\n@@ -631,44 +592,6 @@ def test_model_from_pretrained(self):\n         model = SeamlessM4Tv2Model.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv\",\n-                    \"masked_spec_embed\",\n-                    \"codevectors\",\n-                    \"quantizer.weight_proj.weight\",\n-                    \"project_hid.weight\",\n-                    \"project_hid.bias\",\n-                    \"project_q.weight\",\n-                    \"project_q.bias\",\n-                    \"pos_bias_v\",\n-                    \"pos_bias_u\",\n-                    \"pointwise_conv1\",\n-                    \"pointwise_conv2\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                    \"objective.weight\",\n-                    \"adapter\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     @unittest.skip(\n         reason=\"Expected missing keys serve when using SeamlessM4Tv2ForXXX.from_pretrained from a checkpoint saved by SeamlessM4Tv2Model.save_pretrained.\"\n     )"
        },
        {
            "sha": "be8b27c17712feffdbd02410bcf6d3cd41ab0d2f",
            "filename": "tests/models/sew/test_modeling_sew.py",
            "status": "modified",
            "additions": 0,
            "deletions": 27,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fsew%2Ftest_modeling_sew.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fsew%2Ftest_modeling_sew.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsew%2Ftest_modeling_sew.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -24,7 +24,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n@@ -375,32 +374,6 @@ def test_seq_classifier_train(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.check_seq_classifier_training(*config_and_inputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.parametrizations.weight\",\n-                    \"conv.weight\",\n-                    \"masked_spec_embed\",\n-                    \"quantizer.weight_proj.weight\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # overwrite from test_modeling_common\n     def _mock_init_weights(self, module):\n         if hasattr(module, \"weight\") and module.weight is not None:"
        },
        {
            "sha": "84c0cc3c56ff2f0745f7d455fcbf6fa9d556d56f",
            "filename": "tests/models/sew_d/test_modeling_sew_d.py",
            "status": "modified",
            "additions": 0,
            "deletions": 27,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fsew_d%2Ftest_modeling_sew_d.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fsew_d%2Ftest_modeling_sew_d.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsew_d%2Ftest_modeling_sew_d.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -24,7 +24,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n@@ -386,32 +385,6 @@ def test_retain_grad_hidden_states_attentions(self):\n         self.assertIsNotNone(hidden_states.grad)\n         self.assertIsNotNone(attentions.grad)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.parametrizations.weight\",\n-                    \"conv.weight\",\n-                    \"masked_spec_embed\",\n-                    \"quantizer.weight_proj.weight\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # overwrite from test_modeling_common\n     def _mock_init_weights(self, module):\n         if hasattr(module, \"weight\") and module.weight is not None:"
        },
        {
            "sha": "95a88f28c2e854182d6a84771a66bd407b4b2528",
            "filename": "tests/models/siglip/test_modeling_siglip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fsiglip%2Ftest_modeling_siglip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fsiglip%2Ftest_modeling_siglip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsiglip%2Ftest_modeling_siglip.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -239,10 +239,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"Siglip uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"google/siglip-base-patch16-224\"\n@@ -384,10 +380,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"Siglip uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"google/siglip-base-patch16-224\"\n@@ -495,10 +487,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    @unittest.skip(reason=\"Siglip uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n     # Copied from tests.models.clip.test_modeling_clip.CLIPModelTest._create_and_check_torchscript with CLIP->Siglip\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n@@ -654,10 +642,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"Siglip uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n \n # We will verify our results on an image of cute cats\n def prepare_img():"
        },
        {
            "sha": "f417b512004b59d4774f6f64d2c91a96fb53f42a",
            "filename": "tests/models/siglip2/test_modeling_siglip2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fsiglip2%2Ftest_modeling_siglip2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fsiglip2%2Ftest_modeling_siglip2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsiglip2%2Ftest_modeling_siglip2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -331,10 +331,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"Siglip2 uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"google/siglip2-base-patch16-naflex\"\n@@ -472,10 +468,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"Siglip2 uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"google/siglip2-base-patch16-naflex\"\n@@ -588,10 +580,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    @unittest.skip(reason=\"Siglip2 uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n     def test_load_vision_text_config(self):\n         config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n \n@@ -685,10 +673,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"Siglip2 uses a non-standard initialization scheme\")\n-    def test_initialization(self):\n-        pass\n-\n \n # Draw a circle on an images with different aspect ratios\n def prepare_images():"
        },
        {
            "sha": "103cc29e92d3b2b3bd6015377dd32c4b2a5a996a",
            "filename": "tests/models/speecht5/test_modeling_speecht5.py",
            "status": "modified",
            "additions": 0,
            "deletions": 82,
            "changes": 82,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fspeecht5%2Ftest_modeling_speecht5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fspeecht5%2Ftest_modeling_speecht5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fspeecht5%2Ftest_modeling_speecht5.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -35,7 +35,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n@@ -556,33 +555,6 @@ def check_hidden_states_output(inputs_dict, config, model_class):\n \n             check_hidden_states_output(inputs_dict, config, model_class)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"conv.parametrizations.weight\",\n-                    \"masked_spec_embed\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # this model has no inputs_embeds\n     @unittest.skip(reason=\"Model has no input_embeds\")\n     def test_inputs_embeds(self):\n@@ -957,29 +929,6 @@ def test_forward_signature(self):\n             expected_arg_names.extend([\"encoder_outputs\"])\n             self.assertListEqual(arg_names[: len(expected_arg_names)], expected_arg_names)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     @unittest.skip(reason=\"Model has no inputs_embeds\")\n     def test_inputs_embeds(self):\n         pass\n@@ -1649,33 +1598,6 @@ def check_hidden_states_output(inputs_dict, config, model_class):\n \n             check_hidden_states_output(inputs_dict, config, model_class)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"conv.parametrizations.weight\",\n-                    \"masked_spec_embed\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     @unittest.skip(reason=\"Model has no input_embeds\")\n     def test_inputs_embeds(self):\n         pass\n@@ -1863,10 +1785,6 @@ def test_forward_signature(self):\n     def test_hidden_states_output(self):\n         pass\n \n-    @unittest.skip\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(reason=\"Model has no input_embeds\")\n     def test_inputs_embeds(self):\n         pass"
        },
        {
            "sha": "6e84a3a5c42ffe522d1e6e5d9b58c34fb02a51c6",
            "filename": "tests/models/swiftformer/test_modeling_swiftformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 17,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fswiftformer%2Ftest_modeling_swiftformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fswiftformer%2Ftest_modeling_swiftformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fswiftformer%2Ftest_modeling_swiftformer.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -26,7 +26,7 @@\n from transformers.utils import is_torch_available, is_vision_available\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -232,22 +232,6 @@ def check_hidden_states_output(inputs_dict, config, model_class):\n \n             check_hidden_states_output(inputs_dict, config, model_class)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if name.endswith(\".w_g\"):\n-                    continue\n-                if param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9) / 1e9).round().item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n \n # We will verify our results on an image of cute cats\n def prepare_img():"
        },
        {
            "sha": "e6d23a8019c49fe91071f86474afba05fbdd511a",
            "filename": "tests/models/swin/test_modeling_swin.py",
            "status": "modified",
            "additions": 1,
            "deletions": 15,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fswin%2Ftest_modeling_swin.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fswin%2Ftest_modeling_swin.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fswin%2Ftest_modeling_swin.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -23,7 +23,7 @@\n \n from ...test_backbone_common import BackboneTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -447,20 +447,6 @@ def test_model_from_pretrained(self):\n         model = SwinModel.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if \"embeddings\" not in name and param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n \n @require_vision\n @require_torch"
        },
        {
            "sha": "e4bf84c682831f136900b1a03d79742a836966cd",
            "filename": "tests/models/swin2sr/test_modeling_swin2sr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 27,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fswin2sr%2Ftest_modeling_swin2sr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fswin2sr%2Ftest_modeling_swin2sr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fswin2sr%2Ftest_modeling_swin2sr.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -20,7 +20,7 @@\n from transformers.utils import is_torch_available, is_vision_available\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -237,32 +237,6 @@ def test_model_from_pretrained(self):\n         model = Swin2SRModel.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    # overwriting because of `logit_scale` parameter\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if \"logit_scale\" in name:\n-                    continue\n-                if param.requires_grad:\n-                    # See PR #38607 (to avoid flakiness)\n-                    data = torch.flatten(param.data)\n-                    n_elements = torch.numel(data)\n-                    # skip 2.5% of elements on each side to avoid issues caused by `nn.init.trunc_normal_` described in\n-                    # https://github.com/huggingface/transformers/pull/27906#issuecomment-1846951332\n-                    n_elements_to_skip_on_each_side = int(n_elements * 0.025)\n-                    data_to_check = torch.sort(data).values\n-                    if n_elements_to_skip_on_each_side > 0:\n-                        data_to_check = data_to_check[n_elements_to_skip_on_each_side:-n_elements_to_skip_on_each_side]\n-                    self.assertIn(\n-                        ((data_to_check.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_attention_outputs(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n         config.return_dict = True"
        },
        {
            "sha": "28c1f8671f0c914e70e3c5f5eae5cb7161e44536",
            "filename": "tests/models/swinv2/test_modeling_swinv2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 15,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fswinv2%2Ftest_modeling_swinv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fswinv2%2Ftest_modeling_swinv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fswinv2%2Ftest_modeling_swinv2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -24,7 +24,7 @@\n \n from ...test_backbone_common import BackboneTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -442,20 +442,6 @@ def test_model_from_pretrained(self):\n     def test_feed_forward_chunking(self):\n         pass\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if \"embeddings\" not in name and \"logit_scale\" not in name and param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n \n @require_vision\n @require_torch"
        },
        {
            "sha": "10985988920e39115853e763f61a8135550c8fcb",
            "filename": "tests/models/table_transformer/test_modeling_table_transformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 24,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ftable_transformer%2Ftest_modeling_table_transformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ftable_transformer%2Ftest_modeling_table_transformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ftable_transformer%2Ftest_modeling_table_transformer.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -23,7 +23,7 @@\n from transformers.testing_utils import Expectations, require_timm, require_torch, require_vision, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -532,29 +532,6 @@ def test_greyscale_images(self):\n \n             self.assertTrue(outputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        configs_no_init.init_xavier_std = 1e9\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if \"bbox_attention\" in name and \"bias\" not in name:\n-                        self.assertLess(\n-                            100000,\n-                            abs(param.data.max().item()),\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n \n TOLERANCE = 1e-4\n "
        },
        {
            "sha": "b839e583b990253cce31407d2db5f212ab471e00",
            "filename": "tests/models/textnet/test_modeling_textnet.py",
            "status": "modified",
            "additions": 0,
            "deletions": 17,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ftextnet%2Ftest_modeling_textnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ftextnet%2Ftest_modeling_textnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ftextnet%2Ftest_modeling_textnet.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -36,7 +36,6 @@\n \n if is_torch_available():\n     import torch\n-    from torch import nn\n \n     from transformers import TextNetBackbone, TextNetForImageClassification, TextNetModel\n \n@@ -246,22 +245,6 @@ def test_backbone(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_backbone(*config_and_inputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=config)\n-            for name, module in model.named_modules():\n-                if isinstance(module, (nn.BatchNorm2d, nn.GroupNorm)):\n-                    self.assertTrue(\n-                        torch.all(module.weight == 1),\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-                    self.assertTrue(\n-                        torch.all(module.bias == 0),\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_hidden_states_output(self):\n         def check_hidden_states_output(inputs_dict, config, model_class):\n             model = model_class(config)"
        },
        {
            "sha": "aafcb141db7c44993a0eed04ac8d8562184f9695",
            "filename": "tests/models/timm_backbone/test_modeling_timm_backbone.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ftimm_backbone%2Ftest_modeling_timm_backbone.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ftimm_backbone%2Ftest_modeling_timm_backbone.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ftimm_backbone%2Ftest_modeling_timm_backbone.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -139,10 +139,6 @@ def test_hidden_states_output(self):\n     def test_can_init_all_missing_weights(self):\n         pass\n \n-    @unittest.skip(reason=\"TimmBackbone initialization is managed on the timm side\")\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(reason=\"TimmBackbone models doesn't have inputs_embeds\")\n     def test_inputs_embeds(self):\n         pass"
        },
        {
            "sha": "69e2f5a134dbb4f89e6eab14c857d0ba5341326b",
            "filename": "tests/models/timm_wrapper/test_modeling_timm_wrapper.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ftimm_wrapper%2Ftest_modeling_timm_wrapper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ftimm_wrapper%2Ftest_modeling_timm_wrapper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ftimm_wrapper%2Ftest_modeling_timm_wrapper.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -157,10 +157,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_can_init_all_missing_weights(self):\n         pass\n \n-    @unittest.skip(reason=\"TimmWrapper initialization is managed on the timm side\")\n-    def test_initialization(self):\n-        pass\n-\n     def test_gradient_checkpointing(self):\n         config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n         model = TimmWrapperModel._from_config(config)"
        },
        {
            "sha": "9672f74d4eee9eb7e0a7c265afb7d94d58b4e737",
            "filename": "tests/models/tvp/test_modeling_tvp.py",
            "status": "modified",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ftvp%2Ftest_modeling_tvp.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Ftvp%2Ftest_modeling_tvp.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ftvp%2Ftest_modeling_tvp.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -22,7 +22,6 @@\n \n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n@@ -194,23 +193,6 @@ def test_inputs_embeds(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    # override as the `logit_scale` parameter initialization is different for TVP\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # params are randomly initialized.\n-                    self.assertAlmostEqual(\n-                        param.data.mean().item(),\n-                        0.0,\n-                        delta=1.0,\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     @require_timm\n     def test_backbone_selection(self):\n         def _validate_backbone_init():"
        },
        {
            "sha": "7aa4cdf1c1f4613053ec008f667cd6f7957f02f9",
            "filename": "tests/models/unispeech/test_modeling_unispeech.py",
            "status": "modified",
            "additions": 0,
            "deletions": 34,
            "changes": 34,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Funispeech%2Ftest_modeling_unispeech.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Funispeech%2Ftest_modeling_unispeech.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Funispeech%2Ftest_modeling_unispeech.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -26,7 +26,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n@@ -420,39 +419,6 @@ def test_retain_grad_hidden_states_attentions(self):\n         self.assertIsNotNone(hidden_states.grad)\n         self.assertIsNotNone(attentions.grad)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"conv.parametrizations.weight\",\n-                    \"masked_spec_embed\",\n-                    \"codevectors\",\n-                    \"quantizer.weight_proj.weight\",\n-                    \"project_hid.weight\",\n-                    \"project_hid.bias\",\n-                    \"project_q.weight\",\n-                    \"project_q.bias\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # overwrite from test_modeling_common\n     def _mock_init_weights(self, module):\n         if hasattr(module, \"weight\") and module.weight is not None:"
        },
        {
            "sha": "02564dea72f815675f2677dfc43f257009c7d425",
            "filename": "tests/models/unispeech_sat/test_modeling_unispeech_sat.py",
            "status": "modified",
            "additions": 0,
            "deletions": 71,
            "changes": 71,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Funispeech_sat%2Ftest_modeling_unispeech_sat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Funispeech_sat%2Ftest_modeling_unispeech_sat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Funispeech_sat%2Ftest_modeling_unispeech_sat.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -26,7 +26,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n@@ -460,41 +459,6 @@ def test_retain_grad_hidden_states_attentions(self):\n         self.assertIsNotNone(hidden_states.grad)\n         self.assertIsNotNone(attentions.grad)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"conv.parametrizations.weight\",\n-                    \"masked_spec_embed\",\n-                    \"codevectors\",\n-                    \"quantizer.weight_proj.weight\",\n-                    \"project_hid.weight\",\n-                    \"project_hid.bias\",\n-                    \"project_q.weight\",\n-                    \"project_q.bias\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                    \"label_embeddings_concat\",\n-                    \"objective.weight\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # overwrite from test_modeling_common\n     def _mock_init_weights(self, module):\n         if hasattr(module, \"weight\") and module.weight is not None:\n@@ -671,41 +635,6 @@ def test_retain_grad_hidden_states_attentions(self):\n         self.assertIsNotNone(hidden_states.grad)\n         self.assertIsNotNone(attentions.grad)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"conv.parametrizations.weight\",\n-                    \"masked_spec_embed\",\n-                    \"codevectors\",\n-                    \"quantizer.weight_proj.weight\",\n-                    \"project_hid.weight\",\n-                    \"project_hid.bias\",\n-                    \"project_q.weight\",\n-                    \"project_q.bias\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                    \"label_embeddings_concat\",\n-                    \"objective.weight\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # overwrite from test_modeling_common\n     def _mock_init_weights(self, module):\n         if hasattr(module, \"weight\") and module.weight is not None:"
        },
        {
            "sha": "f816341a3abe4630816b9287e47a4567c38c8dfd",
            "filename": "tests/models/upernet/test_modeling_upernet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 16,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fupernet%2Ftest_modeling_upernet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fupernet%2Ftest_modeling_upernet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fupernet%2Ftest_modeling_upernet.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -30,7 +30,7 @@\n from transformers.utils.import_utils import get_torch_major_and_minor_version\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -219,21 +219,6 @@ def check_hidden_states_output(inputs_dict, config, model_class):\n \n             check_hidden_states_output(inputs_dict, config, model_class)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        configs_no_init.backbone_config = _config_zero_init(configs_no_init.backbone_config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     @require_timm\n     def test_backbone_selection(self):\n         config, inputs = self.model_tester.prepare_config_and_inputs_for_common()"
        },
        {
            "sha": "d0571e4a0299923629d2dd3c7958134a65522fb5",
            "filename": "tests/models/vit_mae/test_modeling_vit_mae.py",
            "status": "modified",
            "additions": 1,
            "deletions": 18,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fvit_mae%2Ftest_modeling_vit_mae.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fvit_mae%2Ftest_modeling_vit_mae.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvit_mae%2Ftest_modeling_vit_mae.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -34,7 +34,7 @@\n from transformers.utils import is_torch_available, is_vision_available\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -320,23 +320,6 @@ def test_flash_attn_2_inference_equivalence(self):\n     def test_flash_attn_2_inference_equivalence_right_padding(self):\n         pass\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                # This is an exception in the module, it's initialized with xavier_uniform without using initializer_range\n-                if name.endswith(\"patch_embeddings.projection.weight\"):\n-                    continue\n-                if param.requires_grad:\n-                    self.assertIn(\n-                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n \n # We will verify our results on an image of cute cats\n def prepare_img():"
        },
        {
            "sha": "e099f44d074ca356c4d291130fb2b781fb9d8d0d",
            "filename": "tests/models/vitdet/test_modeling_vitdet.py",
            "status": "modified",
            "additions": 5,
            "deletions": 9,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fvitdet%2Ftest_modeling_vitdet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fvitdet%2Ftest_modeling_vitdet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvitdet%2Ftest_modeling_vitdet.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -16,7 +16,7 @@\n import unittest\n \n from transformers import VitDetConfig\n-from transformers.testing_utils import is_flaky, require_torch, torch_device\n+from transformers.testing_utils import require_torch, torch_device\n from transformers.utils import is_torch_available\n \n from ...test_backbone_common import BackboneTesterMixin\n@@ -173,28 +173,24 @@ def setUp(self):\n         self.model_tester = VitDetModelTester(self)\n         self.config_tester = ConfigTester(self, config_class=VitDetConfig, has_text_modality=False, hidden_size=37)\n \n-    @is_flaky(max_attempts=3, description=\"`torch.nn.init.trunc_normal_` is flaky.\")\n-    def test_initialization(self):\n-        super().test_initialization()\n-\n     # TODO: Fix me (once this model gets more usage)\n     @unittest.skip(reason=\"Does not work on the tiny model as we keep hitting edge cases.\")\n     def test_cpu_offload(self):\n-        super().test_cpu_offload()\n+        pass\n \n     # TODO: Fix me (once this model gets more usage)\n     @unittest.skip(reason=\"Does not work on the tiny model as we keep hitting edge cases.\")\n     def test_disk_offload_bin(self):\n-        super().test_disk_offload()\n+        pass\n \n     @unittest.skip(reason=\"Does not work on the tiny model as we keep hitting edge cases.\")\n     def test_disk_offload_safetensors(self):\n-        super().test_disk_offload()\n+        pass\n \n     # TODO: Fix me (once this model gets more usage)\n     @unittest.skip(reason=\"Does not work on the tiny model as we keep hitting edge cases.\")\n     def test_model_parallelism(self):\n-        super().test_model_parallelism()\n+        pass\n \n     def test_config(self):\n         self.config_tester.run_common_tests()"
        },
        {
            "sha": "654503c0bac0b38ebb2641ef282e58598b18aa1f",
            "filename": "tests/models/vitpose_backbone/test_modeling_vitpose_backbone.py",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fvitpose_backbone%2Ftest_modeling_vitpose_backbone.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fvitpose_backbone%2Ftest_modeling_vitpose_backbone.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvitpose_backbone%2Ftest_modeling_vitpose_backbone.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -141,11 +141,6 @@ def test_config(self):\n     def test_batching_equivalence(self, atol=3e-4, rtol=3e-4):\n         super().test_batching_equivalence(atol=atol, rtol=rtol)\n \n-    # TODO: @Pavel\n-    @unittest.skip(reason=\"currently failing\")\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(reason=\"VitPoseBackbone does not support input and output embeddings\")\n     def test_model_common_attributes(self):\n         pass"
        },
        {
            "sha": "f45382e7ce958b3522d9859414c7a1e82ac79ca1",
            "filename": "tests/models/vits/test_modeling_vits.py",
            "status": "modified",
            "additions": 0,
            "deletions": 40,
            "changes": 40,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fvits%2Ftest_modeling_vits.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fvits%2Ftest_modeling_vits.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvits%2Ftest_modeling_vits.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -220,46 +220,6 @@ def test_determinism(self):\n     def test_batching_equivalence(self):\n         pass\n \n-    @is_flaky(\n-        max_attempts=3,\n-        description=\"Weight initialisation for the VITS conv layers sometimes exceeds the kaiming normal range\",\n-    )\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        uniform_init_parms = [\n-            \"emb_rel_k\",\n-            \"emb_rel_v\",\n-            \"conv_1\",\n-            \"conv_2\",\n-            \"conv_pre\",\n-            \"conv_post\",\n-            \"conv_proj\",\n-            \"conv_dds\",\n-            \"project\",\n-            \"wavenet.in_layers\",\n-            \"wavenet.res_skip_layers\",\n-            \"upsampler\",\n-            \"resblocks\",\n-        ]\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     @unittest.skip(reason=\"VITS has no inputs_embeds\")\n     def test_inputs_embeds(self):\n         pass"
        },
        {
            "sha": "3a2a24c5490144b68fb7ea6167963dd4cdad48ec",
            "filename": "tests/models/vjepa2/test_modeling_vjepa2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fvjepa2%2Ftest_modeling_vjepa2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fvjepa2%2Ftest_modeling_vjepa2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvjepa2%2Ftest_modeling_vjepa2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -21,7 +21,6 @@\n \n from transformers import VJEPA2Config\n from transformers.testing_utils import (\n-    is_flaky,\n     require_torch,\n     require_vision,\n     slow,\n@@ -167,10 +166,6 @@ def setUp(self):\n         self.model_tester = VJEPA2ModelTester(self)\n         self.config_tester = ConfigTester(self, config_class=VJEPA2Config, has_text_modality=False, hidden_size=37)\n \n-    @is_flaky(max_attempts=3, description=\"`torch.nn.init.trunc_normal_` is flaky.\")\n-    def test_initialization(self):\n-        super().test_initialization()\n-\n     def test_config(self):\n         self.config_tester.run_common_tests()\n "
        },
        {
            "sha": "204eb797ee41f7fcf8ad7edd20ecf1a0013b8e5a",
            "filename": "tests/models/wav2vec2/test_modeling_wav2vec2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 68,
            "changes": 68,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fwav2vec2%2Ftest_modeling_wav2vec2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fwav2vec2%2Ftest_modeling_wav2vec2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwav2vec2%2Ftest_modeling_wav2vec2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -606,40 +606,6 @@ def test_retain_grad_hidden_states_attentions(self):\n         self.assertIsNotNone(hidden_states.grad)\n         self.assertIsNotNone(attentions.grad)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"conv.parametrizations.weight\",\n-                    \"masked_spec_embed\",\n-                    \"codevectors\",\n-                    \"quantizer.weight_proj.weight\",\n-                    \"project_hid.weight\",\n-                    \"project_hid.bias\",\n-                    \"project_q.weight\",\n-                    \"project_q.bias\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                    \"objective.weight\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # overwrite from test_modeling_common\n     def _mock_init_weights(self, module):\n         if hasattr(module, \"weight\") and module.weight is not None:\n@@ -949,40 +915,6 @@ def test_retain_grad_hidden_states_attentions(self):\n         self.assertIsNotNone(hidden_states.grad)\n         self.assertIsNotNone(attentions.grad)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"conv.parametrizations.weight\",\n-                    \"masked_spec_embed\",\n-                    \"codevectors\",\n-                    \"quantizer.weight_proj.weight\",\n-                    \"project_hid.weight\",\n-                    \"project_hid.bias\",\n-                    \"project_q.weight\",\n-                    \"project_q.bias\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                    \"objective.weight\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # overwrite from test_modeling_common\n     def _mock_init_weights(self, module):\n         if hasattr(module, \"weight\") and module.weight is not None:"
        },
        {
            "sha": "7388f177d60266e7e5e3dd45d208ef0ef45fe00c",
            "filename": "tests/models/wav2vec2_bert/test_modeling_wav2vec2_bert.py",
            "status": "modified",
            "additions": 0,
            "deletions": 39,
            "changes": 39,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fwav2vec2_bert%2Ftest_modeling_wav2vec2_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fwav2vec2_bert%2Ftest_modeling_wav2vec2_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwav2vec2_bert%2Ftest_modeling_wav2vec2_bert.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -31,7 +31,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n@@ -575,44 +574,6 @@ def test_retain_grad_hidden_states_attentions(self):\n         self.assertIsNotNone(hidden_states.grad)\n         self.assertIsNotNone(attentions.grad)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"conv.parametrizations.weight\",\n-                    \"masked_spec_embed\",\n-                    \"codevectors\",\n-                    \"quantizer.weight_proj.weight\",\n-                    \"project_hid.weight\",\n-                    \"project_hid.bias\",\n-                    \"project_q.weight\",\n-                    \"project_q.bias\",\n-                    \"pos_bias_v\",\n-                    \"pos_bias_u\",\n-                    \"pointwise_conv1\",\n-                    \"pointwise_conv2\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                    \"objective.weight\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # overwrite from test_modeling_common\n     def _mock_init_weights(self, module):\n         if hasattr(module, \"weight\") and module.weight is not None:"
        },
        {
            "sha": "0304faaad3f745f377938c0884c222ef7d34e156",
            "filename": "tests/models/wav2vec2_conformer/test_modeling_wav2vec2_conformer.py",
            "status": "modified",
            "additions": 0,
            "deletions": 39,
            "changes": 39,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fwav2vec2_conformer%2Ftest_modeling_wav2vec2_conformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fwav2vec2_conformer%2Ftest_modeling_wav2vec2_conformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwav2vec2_conformer%2Ftest_modeling_wav2vec2_conformer.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -33,7 +33,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n@@ -546,44 +545,6 @@ def test_retain_grad_hidden_states_attentions(self):\n         self.assertIsNotNone(hidden_states.grad)\n         self.assertIsNotNone(attentions.grad)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"conv.parametrizations.weight\",\n-                    \"masked_spec_embed\",\n-                    \"codevectors\",\n-                    \"quantizer.weight_proj.weight\",\n-                    \"project_hid.weight\",\n-                    \"project_hid.bias\",\n-                    \"project_q.weight\",\n-                    \"project_q.bias\",\n-                    \"pos_bias_v\",\n-                    \"pos_bias_u\",\n-                    \"pointwise_conv1\",\n-                    \"pointwise_conv2\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                    \"objective.weight\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # overwrite from test_modeling_common\n     def _mock_init_weights(self, module):\n         if hasattr(module, \"weight\") and module.weight is not None:"
        },
        {
            "sha": "787d3b738669b57cde269d7e8e2c42ccd4dbd03b",
            "filename": "tests/models/wavlm/test_modeling_wavlm.py",
            "status": "modified",
            "additions": 0,
            "deletions": 37,
            "changes": 37,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fwavlm%2Ftest_modeling_wavlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fwavlm%2Ftest_modeling_wavlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwavlm%2Ftest_modeling_wavlm.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -25,7 +25,6 @@\n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import (\n     ModelTesterMixin,\n-    _config_zero_init,\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n@@ -397,42 +396,6 @@ def test_retain_grad_hidden_states_attentions(self):\n \n         self.assertIsNotNone(hidden_states.grad)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                uniform_init_parms = [\n-                    \"conv.weight\",\n-                    \"conv.parametrizations.weight\",\n-                    \"masked_spec_embed\",\n-                    \"codevectors\",\n-                    \"quantizer.weight_proj.weight\",\n-                    \"project_hid.weight\",\n-                    \"project_hid.bias\",\n-                    \"project_q.weight\",\n-                    \"project_q.bias\",\n-                    \"feature_projection.projection.weight\",\n-                    \"feature_projection.projection.bias\",\n-                    \"label_embeddings_concat\",\n-                    \"rel_attn_embed\",\n-                    \"objective.weight\",\n-                ]\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     # overwrite from test_modeling_common\n     def _mock_init_weights(self, module):\n         if hasattr(module, \"weight\") and module.weight is not None:"
        },
        {
            "sha": "6d1827b9073b43d5a53a66a11f0cbf73f313b818",
            "filename": "tests/models/x_clip/test_modeling_x_clip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 26,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fx_clip%2Ftest_modeling_x_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fx_clip%2Ftest_modeling_x_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fx_clip%2Ftest_modeling_x_clip.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -561,32 +561,6 @@ def test_model_get_set_embeddings(self):\n     def test_feed_forward_chunking(self):\n         pass\n \n-    # override as the `logit_scale`, `prompts_generator.alpha` parameters require special treatment\n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n-                        self.assertAlmostEqual(\n-                            param.data.item(),\n-                            np.log(1 / 0.07),\n-                            delta=1e-3,\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-                    elif name == \"prompts_generator.alpha\":\n-                        self.assertAlmostEqual(param.data.mean().item(), model.config.prompt_alpha)\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def _create_and_check_torchscript(self, config, inputs_dict):\n         if not self.test_torchscript:\n             self.skipTest(reason=\"test_torchscript is set to False\")"
        },
        {
            "sha": "41f71c409ba6a41cf1c531d87a004359b8af9aba",
            "filename": "tests/models/xcodec/test_modeling_xcodec.py",
            "status": "modified",
            "additions": 0,
            "deletions": 19,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fxcodec%2Ftest_modeling_xcodec.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fxcodec%2Ftest_modeling_xcodec.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fxcodec%2Ftest_modeling_xcodec.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -345,25 +345,6 @@ def check_equivalence(model, tuple_inputs, dict_inputs, additional_kwargs={}):\n             dict_inputs = self._prepare_for_class(inputs_dict, model_class)\n             check_equivalence(model, tuple_inputs, dict_inputs)\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                # skipping the parametrizations original0 tensor\n-                if name == \"semantic_model.encoder.pos_conv_embed.conv.parametrizations.weight.original0\":\n-                    continue\n-\n-                uniform_init_parms = [\"conv\"]\n-\n-                if param.requires_grad:\n-                    if any(x in name for x in uniform_init_parms):\n-                        self.assertTrue(\n-                            -1.0 <= ((param.data.mean() * 1e9).round() / 1e9).item() <= 1.0,\n-                            msg=f\"Parameter {name} of {model_class.__name__} seems not properly initialized\",\n-                        )\n-\n     @unittest.skip(reason=\"The XcodecModel does not have support dynamic compile yet\")\n     def test_sdpa_can_compile_dynamic(self):\n         pass"
        },
        {
            "sha": "f1fb652e8b93396a6eecbb90a8d9d398129a0534",
            "filename": "tests/models/xlstm/test_modeling_xlstm.py",
            "status": "modified",
            "additions": 0,
            "deletions": 11,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fxlstm%2Ftest_modeling_xlstm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fxlstm%2Ftest_modeling_xlstm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fxlstm%2Ftest_modeling_xlstm.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -168,17 +168,6 @@ def setUp(self):\n             self, config_class=xLSTMConfig, n_embd=37, common_properties=[\"hidden_size\", \"num_hidden_layers\"]\n         )\n \n-    def test_initialization(self):\n-        config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=config)\n-            for name, param in model.named_parameters():\n-                if \"D\" in name:\n-                    if param.requires_grad:\n-                        # check if it's a ones like\n-                        self.assertTrue(torch.allclose(param.data, torch.ones_like(param.data), atol=1e-5, rtol=1e-5))\n-\n     @unittest.skip(reason=\"xLSTM cache slicing test case is an edge case\")\n     def test_generate_without_input_ids(self):\n         pass"
        },
        {
            "sha": "74ca658b9e09e1d59ea3829d78a4e357a6af6b6b",
            "filename": "tests/models/zamba/test_modeling_zamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 46,
            "changes": 47,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fzamba%2Ftest_modeling_zamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fzamba%2Ftest_modeling_zamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fzamba%2Ftest_modeling_zamba.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -21,7 +21,6 @@\n \n from transformers import AutoTokenizer, ZambaConfig, is_torch_available\n from transformers.testing_utils import (\n-    is_flaky,\n     require_bitsandbytes,\n     require_flash_attn,\n     require_torch,\n@@ -32,7 +31,7 @@\n \n from ...generation.test_utils import GenerationTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, ids_tensor, random_attention_mask\n+from ...test_modeling_common import ModelTesterMixin, ids_tensor, random_attention_mask\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -346,50 +345,6 @@ def test_decoder_model_past_with_large_inputs(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs_for_decoder()\n         self.model_tester.create_and_check_decoder_model_past_large_inputs(*config_and_inputs)\n \n-    @is_flaky(description=\"TODO: ydshieh\")\n-    def test_initialization(self):\n-        r\"\"\"\n-        Overriding the test_initialization test as the A_log and D params of the Mamba block are initialized differently\n-        \"\"\"\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if \"A_log\" in name:\n-                        A = torch.arange(1, config.mamba_d_state + 1, dtype=torch.float32)[None, :]\n-                        intermediate_dim = config.mamba_expand * config.hidden_size\n-                        A = A.expand(intermediate_dim, -1).reshape(\n-                            config.n_mamba_heads, intermediate_dim // config.n_mamba_heads, -1\n-                        )\n-                        torch.testing.assert_close(param.data, torch.log(A), rtol=1e-5, atol=1e-5)\n-                    elif \"D\" in name:\n-                        # check if it's a ones like\n-                        torch.testing.assert_close(param.data, torch.ones_like(param.data), rtol=1e-5, atol=1e-5)\n-                    elif \"x_proj\" in name or \"dt_proj_weight\" in name:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e2).round() / 1e2).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized (raw value {param.data.mean()})\",\n-                        )\n-                    elif \"dt_proj_bias\" in name:\n-                        dt = torch.exp(\n-                            torch.tensor([0, 1]) * (math.log(config.time_step_max) - math.log(config.time_step_min))\n-                            + math.log(config.time_step_min)\n-                        ).clamp(min=config.time_step_floor)\n-                        inv_dt = dt + torch.log(-torch.expm1(-dt))\n-                        if param.requires_grad:\n-                            self.assertTrue(param.data.max().item() <= inv_dt[1])\n-                            self.assertTrue(param.data.min().item() >= inv_dt[0])\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def test_attention_outputs(self):\n         r\"\"\"\n         Overriding the test_attention_outputs test as the Zamba model outputs attention only for its attention layers"
        },
        {
            "sha": "665c03b8383775d516fdf636d6d02f033bde4a65",
            "filename": "tests/models/zamba2/test_modeling_zamba2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 35,
            "changes": 36,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fzamba2%2Ftest_modeling_zamba2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Fmodels%2Fzamba2%2Ftest_modeling_zamba2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fzamba2%2Ftest_modeling_zamba2.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -13,7 +13,6 @@\n # limitations under the License.\n \"\"\"Testing suite for the PyTorch Zamba model.\"\"\"\n \n-import math\n import tempfile\n import unittest\n \n@@ -34,7 +33,7 @@\n \n from ...generation.test_utils import GenerationTesterMixin\n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, _config_zero_init, ids_tensor, random_attention_mask\n+from ...test_modeling_common import ModelTesterMixin, ids_tensor, random_attention_mask\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -387,39 +386,6 @@ def test_decoder_model_past_with_large_inputs(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs_for_decoder()\n         self.model_tester.create_and_check_decoder_model_past_large_inputs(*config_and_inputs)\n \n-    def test_initialization(self):\n-        r\"\"\"\n-        Overriding the test_initialization test as the A_log and D params of the Mamba block are initialized differently\n-        \"\"\"\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=configs_no_init)\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    if \"A_log\" in name:\n-                        A = torch.arange(1, config.n_mamba_heads + 1, dtype=torch.float32)[None, :]\n-                        self.assertTrue(torch.allclose(param.data, torch.log(A), atol=1e-5, rtol=1e-5))\n-                    elif \"D\" in name:\n-                        # check if it's a ones like\n-                        self.assertTrue(torch.allclose(param.data, torch.ones_like(param.data), atol=1e-5, rtol=1e-5))\n-                    elif \"dt_bias\" in name:\n-                        dt = torch.exp(\n-                            torch.tensor([0, 1]) * (math.log(config.time_step_max) - math.log(config.time_step_min))\n-                            + math.log(config.time_step_min)\n-                        ).clamp(min=config.time_step_floor)\n-                        inv_dt = dt + torch.log(-torch.expm1(-dt))\n-                        if param.requires_grad:\n-                            self.assertTrue(param.data.max().item() <= inv_dt[1])\n-                            self.assertTrue(param.data.min().item() >= inv_dt[0])\n-                    else:\n-                        self.assertIn(\n-                            ((param.data.mean() * 1e9).round() / 1e9).item(),\n-                            [0.0, 1.0],\n-                            msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                        )\n-\n     def test_attention_outputs(self):\n         r\"\"\"\n         Overriding the test_attention_outputs test as the Zamba2 model outputs attention only for its attention layers"
        },
        {
            "sha": "0896c189932999c0ca888d2f1b23616f32448a6d",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 0,
            "deletions": 22,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d02602f0f597493257f5a738f3df149c1f93cbf/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=9d02602f0f597493257f5a738f3df149c1f93cbf",
            "patch": "@@ -1021,28 +1021,6 @@ def check_equal(loaded):\n                 torch.save(state_dict, pt_checkpoint_path, _use_new_zipfile_serialization=False)\n                 check_equal(load_state_dict(pt_checkpoint_path))\n \n-    def test_initialization(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-\n-        configs_no_init = _config_zero_init(config)\n-        for model_class in self.all_model_classes:\n-            model = model_class(config=copy.deepcopy(configs_no_init))\n-            for name, param in model.named_parameters():\n-                if param.requires_grad:\n-                    data = torch.flatten(param.data)\n-                    n_elements = torch.numel(data)\n-                    # skip 2.5% of elements on each side to avoid issues caused by `nn.init.trunc_normal_` described in\n-                    # https://github.com/huggingface/transformers/pull/27906#issuecomment-1846951332\n-                    n_elements_to_skip_on_each_side = int(n_elements * 0.025)\n-                    data_to_check = torch.sort(data).values\n-                    if n_elements_to_skip_on_each_side > 0:\n-                        data_to_check = data_to_check[n_elements_to_skip_on_each_side:-n_elements_to_skip_on_each_side]\n-                    self.assertIn(\n-                        ((data_to_check.mean() * 1e9).round() / 1e9).item(),\n-                        [0.0, 1.0],\n-                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n-                    )\n-\n     def test_determinism(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n "
        }
    ],
    "stats": {
        "total": 3252,
        "additions": 53,
        "deletions": 3199
    }
}