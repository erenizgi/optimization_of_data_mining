{
    "author": "julian-st",
    "message": "Fixed typos and formatting (#34215)\n\n#hacktoberfest",
    "sha": "66d8d7a07759c1a3138272244ca5f81834de9aa5",
    "files": [
        {
            "sha": "ee213cb25da8920cf159ab4ca3cdd29e17d45592",
            "filename": "i18n/README_fr.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/66d8d7a07759c1a3138272244ca5f81834de9aa5/i18n%2FREADME_fr.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/66d8d7a07759c1a3138272244ca5f81834de9aa5/i18n%2FREADME_fr.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_fr.md?ref=66d8d7a07759c1a3138272244ca5f81834de9aa5",
            "patch": "@@ -227,7 +227,7 @@ Le modèle lui-même est un module [`nn.Module` PyTorch](https://pytorch.org/doc\n \n 1. Choisissez le bon framework pour chaque partie de la vie d'un modèle :\n     - Entraînez des modèles de pointe en 3 lignes de code.\n-    - Transférer un seul modèle entre les frameworks TF2.0/PyTorch/JAX à volonté.\n+    - Transférez un seul modèle entre les frameworks TF2.0/PyTorch/JAX à volonté.\n     - Choisissez facilement le bon framework pour l'entraînement, l'évaluation et la production.\n \n 1. Personnalisez facilement un modèle ou un exemple selon vos besoins :\n@@ -237,7 +237,7 @@ Le modèle lui-même est un module [`nn.Module` PyTorch](https://pytorch.org/doc\n \n ## Pourquoi ne devrais-je pas utiliser transformers ?\n \n-- Cette bibliothèque n'est pas une boîte à outils modulaire de blocs de construction pour les réseaux neuronaux. Le code dans les fichiers de modèle n'est pas refactored avec des abstractions supplémentaires à dessein, afin que les chercheurs puissent itérer rapidement sur chacun des modèles sans plonger dans des abstractions/fichiers supplémentaires.\n+- Cette bibliothèque n'est pas une boîte à outils modulaire de blocs de construction pour les réseaux neuronaux. Le code dans les fichiers de modèle n'est pas refactorisé avec des abstractions supplémentaires à dessein, afin que les chercheurs puissent itérer rapidement sur chacun des modèles sans plonger dans des abstractions/fichiers supplémentaires.\n - L'API d'entraînement n'est pas destinée à fonctionner avec n'importe quel modèle, mais elle est optimisée pour fonctionner avec les modèles fournis par la bibliothèque. Pour des boucles génériques d'apprentissage automatique, vous devriez utiliser une autre bibliothèque (éventuellement, [Accelerate](https://huggingface.co/docs/accelerate)).\n - Bien que nous nous efforcions de présenter autant de cas d'utilisation que possible, les scripts de notre [dossier d'exemples](https://github.com/huggingface/transformers/tree/main/examples) ne sont que cela : des exemples. Il est prévu qu'ils ne fonctionnent pas immédiatement sur votre problème spécifique et que vous devrez probablement modifier quelques lignes de code pour les adapter à vos besoins.\n "
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}