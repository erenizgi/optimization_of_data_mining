{
    "author": "Craigacp",
    "message": "Updating `char_to_token` documentation to note behaviour when `trim_offsets` is True (#33919)\n\nUpdating char_to_token documentation.",
    "sha": "a7e4e1a77ccd8396ab2326f2f4805de5b60a3b4b",
    "files": [
        {
            "sha": "796316b85eb91eb184c340e5787ce9f3eb58fa40",
            "filename": "src/transformers/tokenization_utils_base.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/a7e4e1a77ccd8396ab2326f2f4805de5b60a3b4b/src%2Ftransformers%2Ftokenization_utils_base.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a7e4e1a77ccd8396ab2326f2f4805de5b60a3b4b/src%2Ftransformers%2Ftokenization_utils_base.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_utils_base.py?ref=a7e4e1a77ccd8396ab2326f2f4805de5b60a3b4b",
            "patch": "@@ -598,7 +598,8 @@ def char_to_token(\n \n \n         Returns:\n-            `int`: Index of the token.\n+            `int`: Index of the token, or None if the char index refers to a whitespace only token and whitespace is\n+                   trimmed with `trim_offsets=True`.\n         \"\"\"\n \n         if not self._encodings:"
        }
    ],
    "stats": {
        "total": 3,
        "additions": 2,
        "deletions": 1
    }
}