{
    "author": "lukepayyapilli",
    "message": "ðŸš¨Fix MobileViT image processor default interpolation to BICUBIC (#43024)\n\n* Fix MobileViT image processor default interpolation to BICUBIC\n\nThe original MobileViT implementation (Apple's ml-cvnets) and timm both\nuse BICUBIC interpolation for image preprocessing. Updates both slow and\nfast image processors to match.\n\nContributes to #28180\n\n* Remove copy substitution - code now matches source\n\n---------\n\nCo-authored-by: Yoni Gozlan <74535834+yonigozlan@users.noreply.github.com>",
    "sha": "a34922d6dc777a5ea769308d265dbdbd47c04772",
    "files": [
        {
            "sha": "ea8f4c9314ffc412d24284dafbcc6745be78b988",
            "filename": "src/transformers/models/mobilevit/image_processing_mobilevit.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/a34922d6dc777a5ea769308d265dbdbd47c04772/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fimage_processing_mobilevit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a34922d6dc777a5ea769308d265dbdbd47c04772/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fimage_processing_mobilevit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fimage_processing_mobilevit.py?ref=a34922d6dc777a5ea769308d265dbdbd47c04772",
            "patch": "@@ -79,7 +79,7 @@ class MobileViTImageProcessor(BaseImageProcessor):\n         size (`dict[str, int]` *optional*, defaults to `{\"shortest_edge\": 224}`):\n             Controls the size of the output image after resizing. Can be overridden by the `size` parameter in the\n             `preprocess` method.\n-        resample (`PILImageResampling`, *optional*, defaults to `Resampling.BILINEAR`):\n+        resample (`PILImageResampling`, *optional*, defaults to `Resampling.BICUBIC`):\n             Defines the resampling filter to use if resizing the image. Can be overridden by the `resample` parameter\n             in the `preprocess` method.\n         do_rescale (`bool`, *optional*, defaults to `True`):\n@@ -112,7 +112,7 @@ def __init__(\n         self,\n         do_resize: bool = True,\n         size: Optional[dict[str, int]] = None,\n-        resample: PILImageResampling = PILImageResampling.BILINEAR,\n+        resample: PILImageResampling = PILImageResampling.BICUBIC,\n         do_rescale: bool = True,\n         rescale_factor: Union[int, float] = 1 / 255,\n         do_center_crop: bool = True,\n@@ -137,12 +137,12 @@ def __init__(\n         self.do_flip_channel_order = do_flip_channel_order\n         self.do_reduce_labels = do_reduce_labels\n \n-    # Copied from transformers.models.mobilenet_v1.image_processing_mobilenet_v1.MobileNetV1ImageProcessor.resize with PILImageResampling.BICUBIC->PILImageResampling.BILINEAR\n+    # Copied from transformers.models.mobilenet_v1.image_processing_mobilenet_v1.MobileNetV1ImageProcessor.resize\n     def resize(\n         self,\n         image: np.ndarray,\n         size: dict[str, int],\n-        resample: PILImageResampling = PILImageResampling.BILINEAR,\n+        resample: PILImageResampling = PILImageResampling.BICUBIC,\n         data_format: Optional[Union[str, ChannelDimension]] = None,\n         input_data_format: Optional[Union[str, ChannelDimension]] = None,\n         **kwargs,\n@@ -156,7 +156,7 @@ def resize(\n                 Image to resize.\n             size (`dict[str, int]`):\n                 Size of the output image.\n-            resample (`PILImageResampling`, *optional*, defaults to `PILImageResampling.BILINEAR`):\n+            resample (`PILImageResampling`, *optional*, defaults to `PILImageResampling.BICUBIC`):\n                 Resampling filter to use when resiizing the image.\n             data_format (`str` or `ChannelDimension`, *optional*):\n                 The channel dimension format of the image. If not provided, it will be the same as the input image."
        },
        {
            "sha": "2141177058c2c5f3a47e5fcfb5a0b90883d48937",
            "filename": "src/transformers/models/mobilevit/image_processing_mobilevit_fast.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/a34922d6dc777a5ea769308d265dbdbd47c04772/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fimage_processing_mobilevit_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a34922d6dc777a5ea769308d265dbdbd47c04772/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fimage_processing_mobilevit_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fimage_processing_mobilevit_fast.py?ref=a34922d6dc777a5ea769308d265dbdbd47c04772",
            "patch": "@@ -42,7 +42,7 @@\n \n @auto_docstring\n class MobileViTImageProcessorFast(BaseImageProcessorFast):\n-    resample = PILImageResampling.BILINEAR\n+    resample = PILImageResampling.BICUBIC\n     size = {\"shortest_edge\": 224}\n     default_to_square = False\n     crop_size = {\"height\": 256, \"width\": 256}"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 6,
        "deletions": 6
    }
}