{
    "author": "fabxoe",
    "message": "ğŸŒ [i18n-KO] Translated `model_doc/cohere.md` to Korean (#33885)\n\n* docs: ko: model_doc/cohere.md\r\n\r\n* feat: nmt draft\r\n\r\n* fix: resolve suggestions\r\n\r\nCo-authored-by: HyeokJun SHIN <96534680+jun048098@users.noreply.github.com>\r\nCo-authored-by: SeongWooChoi <46990061+nuatmochoi@users.noreply.github.com>\r\n\r\n* fix: resolve suggestions\r\n\r\n---------\r\n\r\nCo-authored-by: HyeokJun SHIN <96534680+jun048098@users.noreply.github.com>\r\nCo-authored-by: SeongWooChoi <46990061+nuatmochoi@users.noreply.github.com>",
    "sha": "d6d07f9c777a63015033c3d8794d7c107621ec52",
    "files": [
        {
            "sha": "0bd56a288bda09f6681a1c6d9aa06620fad71e74",
            "filename": "docs/source/ko/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d6d07f9c777a63015033c3d8794d7c107621ec52/docs%2Fsource%2Fko%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/d6d07f9c777a63015033c3d8794d7c107621ec52/docs%2Fsource%2Fko%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2F_toctree.yml?ref=d6d07f9c777a63015033c3d8794d7c107621ec52",
            "patch": "@@ -352,6 +352,8 @@\n         title: (ë²ˆì—­ì¤‘) CANINE\n       - local: in_translation\n         title: (ë²ˆì—­ì¤‘) CodeGen\n+      - local: model_doc/cohere\n+        title: Cohere\n       - local: in_translation\n         title: (ë²ˆì—­ì¤‘) ConvBERT\n       - local: in_translation"
        },
        {
            "sha": "c577764623f49672a27b78f850828cc21fa7a37b",
            "filename": "docs/source/ko/model_doc/cohere.md",
            "status": "added",
            "additions": 139,
            "deletions": 0,
            "changes": 139,
            "blob_url": "https://github.com/huggingface/transformers/blob/d6d07f9c777a63015033c3d8794d7c107621ec52/docs%2Fsource%2Fko%2Fmodel_doc%2Fcohere.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/d6d07f9c777a63015033c3d8794d7c107621ec52/docs%2Fsource%2Fko%2Fmodel_doc%2Fcohere.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fcohere.md?ref=d6d07f9c777a63015033c3d8794d7c107621ec52",
            "patch": "@@ -0,0 +1,139 @@\n+# Cohere[[cohere]]\n+\n+## ê°œìš”[[overview]]\n+\n+The Cohere Command-R ëª¨ë¸ì€ CohereíŒ€ì´ [Command-R: í”„ë¡œë•ì…˜ ê·œëª¨ì˜ ê²€ìƒ‰ ì¦ê°• ìƒì„±](https://txt.cohere.com/command-r/)ë¼ëŠ” ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì—ì„œ ì†Œê°œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n+\n+ë…¼ë¬¸ ì´ˆë¡:\n+\n+*Command-Rì€ ê¸°ì—…ì˜ í”„ë¡œë•ì…˜ ê·œëª¨ AIë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ê¸° ìœ„í•´ RAG(ê²€ìƒ‰ ì¦ê°• ìƒì„±)ì™€ ë„êµ¬ ì‚¬ìš©ì„ ëª©í‘œë¡œ í•˜ëŠ” í™•ì¥ ê°€ëŠ¥í•œ ìƒì„± ëª¨ë¸ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ìš°ë¦¬ëŠ” ëŒ€ê·œëª¨ í”„ë¡œë•ì…˜ ì›Œí¬ë¡œë“œë¥¼ ëª©í‘œë¡œ í•˜ëŠ” ìƒˆë¡œìš´ LLMì¸ Command-Rì„ ì†Œê°œí•©ë‹ˆë‹¤. Command-Rì€ ë†’ì€ íš¨ìœ¨ì„±ê³¼ ê°•ë ¥í•œ ì •í™•ì„±ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” 'í™•ì¥ ê°€ëŠ¥í•œ' ëª¨ë¸ ì¹´í…Œê³ ë¦¬ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ì—¬, ê¸°ì—…ë“¤ì´ ê°œë… ì¦ëª…ì„ ë„˜ì–´ í”„ë¡œë•ì…˜ ë‹¨ê³„ë¡œ ë‚˜ì•„ê°ˆ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.*\n+\n+*Command-Rì€ ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG)ì´ë‚˜ ì™¸ë¶€ API ë° ë„êµ¬ ì‚¬ìš©ê³¼ ê°™ì€ ê¸´ ë¬¸ë§¥ ì‘ì—…ì— ìµœì í™”ëœ ìƒì„± ëª¨ë¸ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ RAG ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ìµœê³  ìˆ˜ì¤€ì˜ í†µí•©ì„ ì œê³µí•˜ê³  ê¸°ì—… ì‚¬ìš© ì‚¬ë¡€ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ê¸° ìœ„í•´ ìš°ë¦¬ì˜ ì—…ê³„ ì„ ë„ì ì¸ Embed ë° Rerank ëª¨ë¸ê³¼ ì¡°í™”ë¡­ê²Œ ì‘ë™í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ê¸°ì—…ì´ ëŒ€ê·œëª¨ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ì§„ ëª¨ë¸ë¡œì„œ, Command-Rì€ ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ìë‘í•©ë‹ˆë‹¤:\n+- RAG ë° ë„êµ¬ ì‚¬ìš©ì— ëŒ€í•œ ê°•ë ¥í•œ ì •í™•ì„±\n+- ë‚®ì€ ì§€ì—° ì‹œê°„ê³¼ ë†’ì€ ì²˜ë¦¬ëŸ‰\n+- ë” ê¸´ 128k ì»¨í…ìŠ¤íŠ¸ì™€ ë‚®ì€ ê°€ê²©\n+- 10ê°œì˜ ì£¼ìš” ì–¸ì–´ì— ê±¸ì¹œ ê°•ë ¥í•œ ê¸°ëŠ¥\n+- ì—°êµ¬ ë° í‰ê°€ë¥¼ ìœ„í•´ HuggingFaceì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ê°€ì¤‘ì¹˜\n+\n+ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ëŠ” [ì´ê³³](https://huggingface.co/CohereForAI/c4ai-command-r-v01)ì—ì„œ í™•ì¸í•˜ì„¸ìš”.\n+ì´ ëª¨ë¸ì€ [Saurabh Dash](https://huggingface.co/saurabhdash)ê³¼ [Ahmet ÃœstÃ¼n](https://huggingface.co/ahmetustun)ì— ì˜í•´ ê¸°ì—¬ ë˜ì—ˆìŠµë‹ˆë‹¤. Hugging Faceì—ì„œ ì´ ì½”ë“œì˜ êµ¬í˜„ì€ [GPT-NeoX](https://github.com/EleutherAI/gpt-neox)ì— ê¸°ë°˜í•˜ì˜€ìŠµë‹ˆë‹¤.\n+\n+## ì‚¬ìš© íŒ[[usage-tips]]\n+\n+<Tip warning={true}>\n+\n+Hubì— ì—…ë¡œë“œëœ ì²´í¬í¬ì¸íŠ¸ë“¤ì€ `torch_dtype = 'float16'`ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. \n+ì´ëŠ” `AutoModel` APIê°€ ì²´í¬í¬ì¸íŠ¸ë¥¼ `torch.float32`ì—ì„œ `torch.float16`ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. \n+\n+ì˜¨ë¼ì¸ ê°€ì¤‘ì¹˜ì˜ `dtype`ì€ `model = AutoModelForCausalLM.from_pretrained(\"path\", torch_dtype = \"auto\")`ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì´ˆê¸°í™”í•  ë•Œ `torch_dtype=\"auto\"`ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” í•œ ëŒ€ë¶€ë¶„ ë¬´ê´€í•©ë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ” ëª¨ë¸ì´ ë¨¼ì € ë‹¤ìš´ë¡œë“œë˜ê³ (ì˜¨ë¼ì¸ ì²´í¬í¬ì¸íŠ¸ì˜ `dtype` ì‚¬ìš©), ê·¸ ë‹¤ìŒ `torch`ì˜ ê¸°ë³¸ `dtype`ìœ¼ë¡œ ë³€í™˜ë˜ë©°(ì´ë•Œ `torch.float32`ê°€ ë¨), ë§ˆì§€ë§‰ìœ¼ë¡œ configì— `torch_dtype`ì´ ì œê³µëœ ê²½ìš° ì´ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n+\n+ëª¨ë¸ì„ `float16`ìœ¼ë¡œ í›ˆë ¨í•˜ëŠ” ê²ƒì€ ê¶Œì¥ë˜ì§€ ì•Šìœ¼ë©° `nan`ì„ ìƒì„±í•˜ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ëª¨ë¸ì€ `bfloat16`ìœ¼ë¡œ í›ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤.\n+</Tip>\n+ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n+\n+```python\n+# pip install transformers\n+from transformers import AutoTokenizer, AutoModelForCausalLM\n+\n+model_id = \"CohereForAI/c4ai-command-r-v01\"\n+tokenizer = AutoTokenizer.from_pretrained(model_id)\n+model = AutoModelForCausalLM.from_pretrained(model_id)\n+\n+# Format message with the command-r chat template\n+messages = [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]\n+input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n+## <BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Hello, how are you?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>\n+\n+gen_tokens = model.generate(\n+    input_ids, \n+    max_new_tokens=100, \n+    do_sample=True, \n+    temperature=0.3,\n+    )\n+\n+gen_text = tokenizer.decode(gen_tokens[0])\n+print(gen_text)\n+```\n+\n+- Flash Attention 2ë¥¼ `attn_implementation=\"flash_attention_2\"`ë¥¼ í†µí•´ ì‚¬ìš©í•  ë•ŒëŠ”, `from_pretrained` í´ë˜ìŠ¤ ë©”ì„œë“œì— `torch_dtype`ì„ ì „ë‹¬í•˜ì§€ ë§ê³  ìë™ í˜¼í•© ì •ë°€ë„ í›ˆë ¨(Automatic Mixed-Precision training)ì„ ì‚¬ìš©í•˜ì„¸ìš”. `Trainer`ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” ë‹¨ìˆœíˆ `fp16` ë˜ëŠ” `bf16`ì„ `True`ë¡œ ì§€ì •í•˜ë©´ ë©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°ì—ëŠ” `torch.autocast`ë¥¼ ì‚¬ìš©í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ì´ëŠ” Flash Attentionì´ `fp16`ì™€ `bf16` ë°ì´í„° íƒ€ì…ë§Œ ì§€ì›í•˜ê¸° ë•Œë¬¸ì— í•„ìš”í•©ë‹ˆë‹¤.\n+\n+## ë¦¬ì†ŒìŠ¤[[resources]]\n+\n+Command-Rì„ ì‹œì‘í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” Hugging Faceì™€ community ìë£Œ ëª©ë¡(ğŸŒë¡œ í‘œì‹œë¨) ì…ë‹ˆë‹¤. ì—¬ê¸°ì— í¬í•¨ë  ìë£Œë¥¼ ì œì¶œí•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´ PR(Pull Request)ë¥¼ ì—´ì–´ì£¼ì„¸ìš”. ë¦¬ë·° í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ìë£ŒëŠ” ê¸°ì¡´ ìë£Œë¥¼ ë³µì œí•˜ëŠ” ëŒ€ì‹  ìƒˆë¡œìš´ ë‚´ìš©ì„ ë‹´ê³  ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n+\n+\n+<PipelineTag pipeline=\"text-generation\"/>\n+\n+FP16 ëª¨ë¸ ë¡œë”©\n+```python\n+# pip install transformers\n+from transformers import AutoTokenizer, AutoModelForCausalLM\n+\n+model_id = \"CohereForAI/c4ai-command-r-v01\"\n+tokenizer = AutoTokenizer.from_pretrained(model_id)\n+model = AutoModelForCausalLM.from_pretrained(model_id)\n+\n+# command-r ì±— í…œí”Œë¦¿ìœ¼ë¡œ ë©”ì„¸ì§€ í˜•ì‹ì„ ì •í•˜ì„¸ìš”\n+messages = [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]\n+input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n+## <BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Hello, how are you?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>\n+\n+gen_tokens = model.generate(\n+    input_ids, \n+    max_new_tokens=100, \n+    do_sample=True, \n+    temperature=0.3,\n+    )\n+\n+gen_text = tokenizer.decode(gen_tokens[0])\n+print(gen_text)\n+```\n+\n+bitsandbytes ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ì„œ 4bit ì–‘ìí™”ëœ ëª¨ë¸ ë¡œë”©\n+```python\n+# pip install transformers bitsandbytes accelerate\n+from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n+\n+bnb_config = BitsAndBytesConfig(load_in_4bit=True)\n+\n+model_id = \"CohereForAI/c4ai-command-r-v01\"\n+tokenizer = AutoTokenizer.from_pretrained(model_id)\n+model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config)\n+\n+gen_tokens = model.generate(\n+    input_ids, \n+    max_new_tokens=100, \n+    do_sample=True, \n+    temperature=0.3,\n+    )\n+\n+gen_text = tokenizer.decode(gen_tokens[0])\n+print(gen_text)\n+```\n+\n+\n+## CohereConfig[[transformers.CohereConfig]]\n+\n+[[autodoc]] CohereConfig\n+\n+## CohereTokenizerFast[[transformers.CohereTokenizerFast]]\n+\n+[[autodoc]] CohereTokenizerFast\n+    - build_inputs_with_special_tokens\n+    - get_special_tokens_mask\n+    - create_token_type_ids_from_sequences\n+    - update_post_processor\n+    - save_vocabulary\n+\n+## CohereModel[[transformers.CohereModel]]\n+\n+[[autodoc]] CohereModel\n+    - forward\n+\n+\n+## CohereForCausalLM[[transformers.CohereForCausalLM]]\n+\n+[[autodoc]] CohereForCausalLM\n+    - forward\n+\n+"
        }
    ],
    "stats": {
        "total": 141,
        "additions": 141,
        "deletions": 0
    }
}