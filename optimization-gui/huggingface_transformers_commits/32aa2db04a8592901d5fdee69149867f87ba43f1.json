{
    "author": "Isotr0py",
    "message": " Fix Llava conversion for models that use safetensors to store weights (#35406)\n\n* fix llava-med-v1.5-mistral-7b conversion\r\n\r\nSigned-off-by: Isotr0py <2037008807@qq.com>\r\n\r\n* add weights_only=True\r\n\r\nSigned-off-by: Isotr0py <2037008807@qq.com>\r\n\r\n---------\r\n\r\nSigned-off-by: Isotr0py <2037008807@qq.com>",
    "sha": "32aa2db04a8592901d5fdee69149867f87ba43f1",
    "files": [
        {
            "sha": "3582b9772c9c448907aabe58929b5352fd83ca2b",
            "filename": "src/transformers/models/llava/convert_llava_weights_to_hf.py",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/32aa2db04a8592901d5fdee69149867f87ba43f1/src%2Ftransformers%2Fmodels%2Fllava%2Fconvert_llava_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/32aa2db04a8592901d5fdee69149867f87ba43f1/src%2Ftransformers%2Fmodels%2Fllava%2Fconvert_llava_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava%2Fconvert_llava_weights_to_hf.py?ref=32aa2db04a8592901d5fdee69149867f87ba43f1",
            "patch": "@@ -15,7 +15,7 @@\n import glob\n \n import torch\n-from huggingface_hub import hf_hub_download, snapshot_download\n+from huggingface_hub import file_exists, hf_hub_download, snapshot_download\n from safetensors import safe_open\n \n from transformers import (\n@@ -140,11 +140,12 @@ def convert_llava_llama_to_hf(text_model_id, vision_model_id, output_hub_path, o\n     with torch.device(\"meta\"):\n         model = LlavaForConditionalGeneration(config)\n \n-    if \"Qwen\" in text_model_id:\n-        state_dict = load_original_state_dict(old_state_dict_id)\n-    else:\n+    # Some llava variants like microsoft/llava-med-v1.5-mistral-7b use safetensors to store weights\n+    if file_exists(old_state_dict_id, \"model_state_dict.bin\"):\n         state_dict_path = hf_hub_download(old_state_dict_id, \"model_state_dict.bin\")\n-        state_dict = torch.load(state_dict_path, map_location=\"cpu\")\n+        state_dict = torch.load(state_dict_path, map_location=\"cpu\", weights_only=True)\n+    else:\n+        state_dict = load_original_state_dict(old_state_dict_id)\n \n     state_dict = convert_state_dict_to_hf(state_dict)\n     model.load_state_dict(state_dict, strict=True, assign=True)"
        }
    ],
    "stats": {
        "total": 11,
        "additions": 6,
        "deletions": 5
    }
}