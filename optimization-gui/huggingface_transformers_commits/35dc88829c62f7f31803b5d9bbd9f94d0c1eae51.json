{
    "author": "qgallouedec",
    "message": "Replace `logger.warning` with `logger.warning_once` in `GradientCheckpointingLayer` (#40091)",
    "sha": "35dc88829c62f7f31803b5d9bbd9f94d0c1eae51",
    "files": [
        {
            "sha": "259e626c218e38a93155e6bafacbf8b0f382d5bd",
            "filename": "src/transformers/modeling_layers.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/35dc88829c62f7f31803b5d9bbd9f94d0c1eae51/src%2Ftransformers%2Fmodeling_layers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/35dc88829c62f7f31803b5d9bbd9f94d0c1eae51/src%2Ftransformers%2Fmodeling_layers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_layers.py?ref=35dc88829c62f7f31803b5d9bbd9f94d0c1eae51",
            "patch": "@@ -89,7 +89,7 @@ def __call__(self, *args, **kwargs):\n             # warn if anything was changed\n             if do_warn:\n                 message = message.rstrip(\",\") + \".\"\n-                logger.warning(message)\n+                logger.warning_once(message)\n \n             return self._gradient_checkpointing_func(partial(super().__call__, **kwargs), *args)\n         return super().__call__(*args, **kwargs)"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}