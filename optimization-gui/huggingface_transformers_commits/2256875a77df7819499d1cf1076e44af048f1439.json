{
    "author": "jiqing-feng",
    "message": "fix can_generate (#36570)\n\n* fix can_generate\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\n\n* fix can generate for speecht5 and blip\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\n\n* fix speecht5 tests\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\n\n* fix\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\n\n---------\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\nCo-authored-by: Ilyas Moutawwakil <57442720+IlyasMoutawwakil@users.noreply.github.com>",
    "sha": "2256875a77df7819499d1cf1076e44af048f1439",
    "files": [
        {
            "sha": "2a7430b937abb56da48d2232ce50811a21a4f270",
            "filename": "src/transformers/models/blip/modeling_blip.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2256875a77df7819499d1cf1076e44af048f1439/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2256875a77df7819499d1cf1076e44af048f1439/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py?ref=2256875a77df7819499d1cf1076e44af048f1439",
            "patch": "@@ -1233,7 +1233,7 @@ def generate(\n     \"\"\",\n     BLIP_START_DOCSTRING,\n )\n-class BlipForQuestionAnswering(BlipPreTrainedModel):\n+class BlipForQuestionAnswering(BlipPreTrainedModel, GenerationMixin):\n     config_class = BlipConfig\n     _tied_weights_keys = [\"text_decoder.cls.predictions.decoder.bias\"]\n "
        },
        {
            "sha": "39422cd495a05bc8933cc645ff222ab168880a9a",
            "filename": "src/transformers/models/speecht5/modeling_speecht5.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/2256875a77df7819499d1cf1076e44af048f1439/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fmodeling_speecht5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2256875a77df7819499d1cf1076e44af048f1439/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fmodeling_speecht5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fmodeling_speecht5.py?ref=2256875a77df7819499d1cf1076e44af048f1439",
            "patch": "@@ -2631,6 +2631,13 @@ def __init__(self, config: SpeechT5Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n+    @classmethod\n+    def can_generate(cls) -> bool:\n+        # Speecht5 has a unique model structure, where the external class (`SpeechT5ForTextToSpeech`) doesn't need to inherit from\n+        # `GenerationMixin` (it has a non-standard generation method). This means that the base `can_generate()` will return `False`,\n+        # but we need to override it so as to do `GenerationConfig` handling in multiple parts of the codebase.\n+        return True\n+\n     def get_encoder(self):\n         return self.speecht5.get_encoder()\n "
        },
        {
            "sha": "b44c3d3f048430ecbcc5b1002a20207c0419b828",
            "filename": "tests/models/bark/test_modeling_bark.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2256875a77df7819499d1cf1076e44af048f1439/tests%2Fmodels%2Fbark%2Ftest_modeling_bark.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2256875a77df7819499d1cf1076e44af048f1439/tests%2Fmodels%2Fbark%2Ftest_modeling_bark.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbark%2Ftest_modeling_bark.py?ref=2256875a77df7819499d1cf1076e44af048f1439",
            "patch": "@@ -1076,6 +1076,10 @@ def fine_generation_config(self):\n         fine_generation_config = BarkFineGenerationConfig(**self.model.generation_config.fine_acoustics_config)\n         return fine_generation_config\n \n+    def test_model_can_generate(self):\n+        # Bark has custom generate without inheriting GenerationMixin. This test could prevent regression.\n+        self.assertTrue(self.model.can_generate())\n+\n     @slow\n     def test_generate_semantic(self):\n         input_ids = self.inputs"
        },
        {
            "sha": "126edf62816eee8efcf156d15fe2e3106c61a597",
            "filename": "tests/models/speecht5/test_modeling_speecht5.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/2256875a77df7819499d1cf1076e44af048f1439/tests%2Fmodels%2Fspeecht5%2Ftest_modeling_speecht5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2256875a77df7819499d1cf1076e44af048f1439/tests%2Fmodels%2Fspeecht5%2Ftest_modeling_speecht5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fspeecht5%2Ftest_modeling_speecht5.py?ref=2256875a77df7819499d1cf1076e44af048f1439",
            "patch": "@@ -881,6 +881,7 @@ def create_and_check_model_forward(self, config, inputs_dict):\n @require_torch\n class SpeechT5ForTextToSpeechTest(ModelTesterMixin, unittest.TestCase):\n     all_model_classes = (SpeechT5ForTextToSpeech,) if is_torch_available() else ()\n+    all_generative_model_classes = ()\n     is_encoder_decoder = True\n     test_pruning = False\n     test_headmasking = False\n@@ -892,6 +893,12 @@ def setUp(self):\n     def test_config(self):\n         self.config_tester.run_common_tests()\n \n+    def test_model_can_generate(self):\n+        config, inputs_dict = self.model_tester.prepare_config_and_inputs()\n+        for model_class in self.all_model_classes:\n+            model = model_class(config)\n+            self.assertTrue(model.can_generate())\n+\n     def test_save_load_strict(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs()\n         for model_class in self.all_model_classes:"
        }
    ],
    "stats": {
        "total": 20,
        "additions": 19,
        "deletions": 1
    }
}