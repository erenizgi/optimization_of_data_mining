{
    "author": "MekkCyber",
    "message": "Fix torchao doc examples (#37697)\n\nfix\n\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>",
    "sha": "9b3bf4a2065811c3845cd8d456f5b6f10b9906fa",
    "files": [
        {
            "sha": "42fed458f758f802b6b2d6dda38ac49bf31eb28f",
            "filename": "docs/source/en/quantization/torchao.md",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/9b3bf4a2065811c3845cd8d456f5b6f10b9906fa/docs%2Fsource%2Fen%2Fquantization%2Ftorchao.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/9b3bf4a2065811c3845cd8d456f5b6f10b9906fa/docs%2Fsource%2Fen%2Fquantization%2Ftorchao.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fquantization%2Ftorchao.md?ref=9b3bf4a2065811c3845cd8d456f5b6f10b9906fa",
            "patch": "@@ -149,7 +149,7 @@ print(tokenizer.decode(output[0], skip_special_tokens=True))\n ```py\n import torch\n from transformers import TorchAoConfig, AutoModelForCausalLM, AutoTokenizer\n-from torchao.quantization import Int8WeightOnlyConfig\n+from torchao.quantization import Int8DynamicActivationInt8WeightConfig\n \n quant_config = Int8DynamicActivationInt8WeightConfig()\n # or int8 weight only quantization\n@@ -179,7 +179,7 @@ print(tokenizer.decode(output[0], skip_special_tokens=True))\n ```py\n import torch\n from transformers import TorchAoConfig, AutoModelForCausalLM, AutoTokenizer\n-from torchao.quantization import Int4WeightOnlyConfig\n+from torchao.quantization import GemliteUIntXWeightOnlyConfig\n \n # For batch size N, we recommend gemlite, which may require autotuning\n # default is 4 bit, 8 bit is also supported by passing `bit_width=8`\n@@ -216,7 +216,7 @@ print(tokenizer.decode(output[0], skip_special_tokens=True))\n ```py\n import torch\n from transformers import TorchAoConfig, AutoModelForCausalLM, AutoTokenizer\n-from torchao.quantization import Int8WeightOnlyConfig\n+from torchao.quantization import Int8DynamicActivationInt8WeightConfig\n \n quant_config = Int8DynamicActivationInt8WeightConfig()\n # quant_config = Int8WeightOnlyConfig()"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 3,
        "deletions": 3
    }
}