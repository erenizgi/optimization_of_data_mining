{
    "author": "abuelnasr0",
    "message": "use torch constraints to check if covariance is positive definite during mean resizing. (#35693)\n\n* use torch constraints to check for psd\r\n\r\n* small nit\r\n\r\n* Small change\r\n\r\n* Small change for the ci\r\n\r\n* nit",
    "sha": "ec7afad60909dd97d998c1f14681812d69a15728",
    "files": [
        {
            "sha": "b31368c606253c52fd8734da69573d8cf9f9a547",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 5,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/ec7afad60909dd97d998c1f14681812d69a15728/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ec7afad60909dd97d998c1f14681812d69a15728/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=ec7afad60909dd97d998c1f14681812d69a15728",
            "patch": "@@ -37,6 +37,7 @@\n from huggingface_hub import split_torch_state_dict_into_shards\n from packaging import version\n from torch import Tensor, nn\n+from torch.distributions import constraints\n from torch.nn import CrossEntropyLoss, Identity\n from torch.utils.checkpoint import checkpoint\n \n@@ -2425,14 +2426,12 @@ def _init_added_embeddings_weights_with_mean(\n         covariance = old_centered_embeddings.T @ old_centered_embeddings / old_num_tokens\n \n         # Check if the covariance is positive definite.\n-        eigenvalues = torch.linalg.eigvals(covariance)\n-        is_covariance_psd = bool(\n-            (covariance == covariance.T).all() and not torch.is_complex(eigenvalues) and (eigenvalues > 0).all()\n-        )\n+        epsilon = 1e-9\n+        is_covariance_psd = constraints.positive_definite.check(epsilon * covariance).all()\n         if is_covariance_psd:\n             # If covariances is positive definite, a distribution can be created. and we can sample new weights from it.\n             distribution = torch.distributions.multivariate_normal.MultivariateNormal(\n-                mean_embeddings, covariance_matrix=1e-9 * covariance\n+                mean_embeddings, covariance_matrix=epsilon * covariance\n             )\n             new_embeddings.weight.data[-1 * added_num_tokens :, :] = distribution.sample(\n                 sample_shape=(added_num_tokens,)"
        }
    ],
    "stats": {
        "total": 9,
        "additions": 4,
        "deletions": 5
    }
}