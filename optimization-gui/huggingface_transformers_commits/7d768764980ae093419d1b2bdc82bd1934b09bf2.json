{
    "author": "kmehant",
    "message": "(Part 2) feat: allow for tp_size attr for tplizing the model (#37054)\n\n* feat: custom tp_size, new transformers tp interface\n\nSigned-off-by: Mehant Kammakomati <mehant.kammakomati2@ibm.com>\n\n* fix: review cmt - error when tp_plan not set for tp_size\n\nSigned-off-by: Mehant Kammakomati <mehant.kammakomati2@ibm.com>\n\n* fix: nit in docs\n\nSigned-off-by: Mehant Kammakomati <mehant.kammakomati2@ibm.com>\n\n---------\n\nSigned-off-by: Mehant Kammakomati <mehant.kammakomati2@ibm.com>\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\nCo-authored-by: Matej Sirovatka <54212263+S1ro1@users.noreply.github.com>",
    "sha": "7d768764980ae093419d1b2bdc82bd1934b09bf2",
    "files": [
        {
            "sha": "b6bc21974430320811e34699be9400124fe9e41b",
            "filename": "docs/source/ar/trainer.md",
            "status": "modified",
            "additions": 0,
            "deletions": 22,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d768764980ae093419d1b2bdc82bd1934b09bf2/docs%2Fsource%2Far%2Ftrainer.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d768764980ae093419d1b2bdc82bd1934b09bf2/docs%2Fsource%2Far%2Ftrainer.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Ftrainer.md?ref=7d768764980ae093419d1b2bdc82bd1934b09bf2",
            "patch": "@@ -674,29 +674,7 @@ use_cpu: false\n ```\n \n </hfoption>\n-<hfoption id=\"Tensor Parallelism with PyTorch 2\">\n \n-```yml\n-compute_environment: LOCAL_MACHINE\n-tp_config:\n-  tp_size: 4\n-distributed_type: TP\n-downcast_bf16: 'no'\n-machine_rank: 0\n-main_training_function: main\n-mixed_precision: 'no'\n-num_machines: 1\n-num_processes: 4\n-rdzv_backend: static\n-same_network: true\n-tpu_env: []\n-tpu_use_cluster: false\n-tpu_use_sudo: false\n-use_cpu: false\n-\n-```\n-\n-</hfoption>\n </hfoptions>\n يُعد أمر  [`accelerate_launch`](https://huggingface.co/docs/accelerate/package_reference/cli#accelerate-launch) هو الطريقة المُوصى بها لتشغيل نص البرمجى للتدريب على نظام موزع باستخدام Accelerate و [`Trainer`] مع المعلمات المحددة في `config_file.yaml`. يتم حفظ هذا الملف في مجلد ذاكرة التخزين المؤقت لـ Accelerate ويتم تحميله تلقائيًا عند تشغيل `accelerate_launch`.\n "
        },
        {
            "sha": "892594a1bc1aa1efb6cfc1e055d2fe02f626dfca",
            "filename": "docs/source/en/trainer.md",
            "status": "modified",
            "additions": 1,
            "deletions": 21,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d768764980ae093419d1b2bdc82bd1934b09bf2/docs%2Fsource%2Fen%2Ftrainer.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d768764980ae093419d1b2bdc82bd1934b09bf2/docs%2Fsource%2Fen%2Ftrainer.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftrainer.md?ref=7d768764980ae093419d1b2bdc82bd1934b09bf2",
            "patch": "@@ -341,29 +341,9 @@ use_cpu: false\n ```\n \n </hfoption>\n-<hfoption id=\"Tensor parallelism with PyTorch 2\">\n-\n-```yaml\n-compute_environment: LOCAL_MACHINE\n-tp_config:\n-  tp_size: 4\n-distributed_type: TP\n-downcast_bf16: 'no'\n-machine_rank: 0\n-main_training_function: main\n-mixed_precision: 'no'\n-num_machines: 1\n-num_processes: 4\n-rdzv_backend: static\n-same_network: true\n-tpu_env: []\n-tpu_use_cluster: false\n-tpu_use_sudo: false\n-use_cpu: false\n-```\n-\n </hfoptions>\n \n+\n Run [accelerate_launch](https://hf.co/docs/accelerate/package_reference/cli#accelerate-launch) to start training with the configurations set in `config_file.yaml`. This file is saved to the Accelerate cache folder and automatically loaded when you run `accelerate_launch`.\n \n The example below launches the [run_glue.py](../../../examples/pytorch/text-classification/run_glue) script with the FSDP configuration shown earlier. Parameters from the `config_file.yaml` file can also be directly set in the command line."
        },
        {
            "sha": "4455521f5317c1f1d4feb1e48170edd311996d71",
            "filename": "docs/source/es/trainer.md",
            "status": "modified",
            "additions": 0,
            "deletions": 23,
            "changes": 23,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d768764980ae093419d1b2bdc82bd1934b09bf2/docs%2Fsource%2Fes%2Ftrainer.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d768764980ae093419d1b2bdc82bd1934b09bf2/docs%2Fsource%2Fes%2Ftrainer.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Ftrainer.md?ref=7d768764980ae093419d1b2bdc82bd1934b09bf2",
            "patch": "@@ -363,29 +363,6 @@ use_cpu: false\n \n </hfoption>\n \n-<hfoption id=\"Tensor Parallelism with PyTorch 2\">\n-\n-```yml\n-compute_environment: LOCAL_MACHINE\n-tp_config:\n-  tp_size: 4\n-distributed_type: TP\n-downcast_bf16: 'no'\n-machine_rank: 0\n-main_training_function: main\n-mixed_precision: 'no'\n-num_machines: 1\n-num_processes: 4\n-rdzv_backend: static\n-same_network: true\n-tpu_env: []\n-tpu_use_cluster: false\n-tpu_use_sudo: false\n-use_cpu: false\n-\n-```\n-\n-</hfoption>\n </hfoptions>\n \n El comando [`accelerate_launch`](https://huggingface.co/docs/accelerate/package_reference/cli#accelerate-launch) es la forma recomendada de lanzar tu script de entrenamiento en un sistema distribuido con Accelerate y [`Trainer`] con los parámetros especificados en `config_file.yaml`. Este archivo se guarda en la carpeta de caché de Accelerate y se carga automáticamente cuando ejecutas `accelerate_launch`."
        },
        {
            "sha": "0e6f1d7ed59c04ecf03d6280f4cb2d6f28a19528",
            "filename": "docs/source/ko/trainer.md",
            "status": "modified",
            "additions": 0,
            "deletions": 22,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d768764980ae093419d1b2bdc82bd1934b09bf2/docs%2Fsource%2Fko%2Ftrainer.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d768764980ae093419d1b2bdc82bd1934b09bf2/docs%2Fsource%2Fko%2Ftrainer.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftrainer.md?ref=7d768764980ae093419d1b2bdc82bd1934b09bf2",
            "patch": "@@ -549,29 +549,7 @@ use_cpu: false\n ```\n \n </hfoption>\n-<hfoption id=\"Tensor Parallelism with PyTorch 2\">\n \n-```yml\n-compute_environment: LOCAL_MACHINE\n-tp_config:\n-  tp_size: 4\n-distributed_type: TP\n-downcast_bf16: 'no'\n-machine_rank: 0\n-main_training_function: main\n-mixed_precision: 'no'\n-num_machines: 1\n-num_processes: 4\n-rdzv_backend: static\n-same_network: true\n-tpu_env: []\n-tpu_use_cluster: false\n-tpu_use_sudo: false\n-use_cpu: false\n-\n-```\n-\n-</hfoption>\n </hfoptions>\n \n [`accelerate_launch`](https://huggingface.co/docs/accelerate/package_reference/cli#accelerate-launch) 명령은 Accelerate와 [`Trainer`]를 사용하여 분산 시스템에서 훈련 스크립트를 실행하는 권장 방법이며, `config_file.yaml`에 지정된 매개변수를 사용합니다. 이 파일은 Accelerate 캐시 폴더에 저장되며 `accelerate_launch`를 실행할 때 자동으로 로드됩니다."
        },
        {
            "sha": "bd27041a403c7cd096add1bd1af0dd2dfc93b43c",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 23,
            "deletions": 5,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d768764980ae093419d1b2bdc82bd1934b09bf2/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d768764980ae093419d1b2bdc82bd1934b09bf2/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=7d768764980ae093419d1b2bdc82bd1934b09bf2",
            "patch": "@@ -1788,6 +1788,9 @@ class PreTrainedModel(nn.Module, ModuleUtilsMixin, PushToHubMixin, PeftAdapterMi\n     # for example.\n     _tp_plan = None\n \n+    # tensor parallel degree to which model is sharded to.\n+    _tp_size = None\n+\n     # A pipeline parallel plan specifying the layers which may not be present\n     # on all ranks when PP is enabled. For top-level models, this attribute is\n     # currently defined in respective model code. For base models, this\n@@ -3878,6 +3881,8 @@ def from_pretrained(\n                 A torch tensor parallel plan, see [here](https://pytorch.org/tutorials/intermediate/TP_tutorial.html). Currently, it only accepts\n                 `tp_plan=\"auto\"` to use predefined plan based on the model. Note that if you use it, you should launch your script accordingly with\n                 `torchrun [args] script.py`. This will be much faster than using a `device_map`, but has limitations.\n+            tp_size (`str`, *optional*):\n+                A torch tensor parallel degree. If not provided would default to world size.\n             offload_folder (`str` or `os.PathLike`, *optional*):\n                 If the `device_map` contains any value `\"disk\"`, the folder where we will offload weights.\n             offload_state_dict (`bool`, *optional*):\n@@ -3974,6 +3979,7 @@ def from_pretrained(\n         generation_config = kwargs.pop(\"generation_config\", None)\n         gguf_file = kwargs.pop(\"gguf_file\", None)\n         tp_plan = kwargs.pop(\"tp_plan\", None)\n+        tp_size = kwargs.pop(\"tp_size\", None)\n         key_mapping = kwargs.pop(\"key_mapping\", None)\n         # Not used anymore -- remove them from the kwargs\n         _ = kwargs.pop(\"resume_download\", None)\n@@ -3986,7 +3992,8 @@ def from_pretrained(\n             raise ValueError(\n                 \"`state_dict` cannot be passed together with a model name or a `gguf_file`. Use one of the two loading strategies.\"\n             )\n-\n+        if tp_size is not None and tp_plan is None:\n+            raise ValueError(\"tp_plan has to be set when tp_size is passed.\")\n         if tp_plan is not None and tp_plan != \"auto\":\n             # TODO: we can relax this check when we support taking tp_plan from a json file, for example.\n             raise ValueError(f\"tp_plan supports 'auto' only for now but got {tp_plan}.\")\n@@ -4046,9 +4053,10 @@ def from_pretrained(\n                 sys.stderr = open(os.devnull, \"w\")\n             # This is the easiest way to dispatch to the current process device\n             device_map = tp_device\n-            # Assuming sharding the model onto the world\n-            world_size = torch.distributed.get_world_size()\n-            device_mesh = torch.distributed.init_device_mesh(tp_device.type, (world_size,))\n+\n+            # Assuming sharding the model onto the world when tp_size not provided\n+            tp_size = tp_size if tp_size is not None else torch.distributed.get_world_size()\n+            device_mesh = torch.distributed.init_device_mesh(tp_device.type, (tp_size,))\n \n         if use_auth_token is not None:\n             warnings.warn(\n@@ -4415,6 +4423,9 @@ def from_pretrained(\n                 weights_only=weights_only,\n             )\n \n+        # record tp degree the model sharded to\n+        model._tp_size = tp_size\n+\n         # make sure token embedding weights are still tied if needed\n         model.tie_weights()\n \n@@ -4498,7 +4509,6 @@ def from_pretrained(\n             elif from_flax:\n                 loading_info = None\n             return model, loading_info\n-\n         return model\n \n     @staticmethod\n@@ -5142,6 +5152,14 @@ def supports_tp_plan(self):\n             return True\n         return False\n \n+    @property\n+    def tp_size(self):\n+        \"\"\"\n+        Returns the model's tensor parallelism degree.\n+        \"\"\"\n+        # if None, the model didn't undergo tensor parallel sharding\n+        return self._tp_size\n+\n     @property\n     def supports_pp_plan(self):\n         if self._pp_plan is not None:"
        },
        {
            "sha": "20e8d3389bfc89ab8e47e5d96826e9056828e660",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d768764980ae093419d1b2bdc82bd1934b09bf2/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d768764980ae093419d1b2bdc82bd1934b09bf2/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=7d768764980ae093419d1b2bdc82bd1934b09bf2",
            "patch": "@@ -459,7 +459,7 @@ def __init__(\n         self.hp_name = None\n         self.deepspeed = None\n         self.is_in_train = False\n-\n+        self.model = model\n         self.create_accelerator_and_postprocess()\n \n         # memory metrics - must set up as early as possible\n@@ -5146,10 +5146,10 @@ def create_accelerator_and_postprocess(self):\n             args.update(accelerator_config)\n         # tp is initialized at Accelerator init phase so\n         # args should be prepared here\n-        if self.args.tp_size > 1:\n+        if hasattr(self.model, \"tp_size\") and self.model.tp_size is not None and self.model.tp_size > 1:\n             self.is_tp_enabled = True\n             if version.parse(accelerate_version) > version.parse(\"1.3.0\"):\n-                args[\"torch_tp_plugin\"] = TorchTensorParallelPlugin(tp_size=self.args.tp_size)\n+                args[\"torch_tp_plugin\"] = TorchTensorParallelPlugin(tp_size=self.model.tp_size)\n             else:\n                 raise ValueError(\"Requires accelerate>1.3.0 to use Tensor Parallelism.\")\n "
        },
        {
            "sha": "bd3426614c80f63832f3fe3b4bcbd3f1634f31bb",
            "filename": "src/transformers/training_args.py",
            "status": "modified",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d768764980ae093419d1b2bdc82bd1934b09bf2/src%2Ftransformers%2Ftraining_args.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d768764980ae093419d1b2bdc82bd1934b09bf2/src%2Ftransformers%2Ftraining_args.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftraining_args.py?ref=7d768764980ae093419d1b2bdc82bd1934b09bf2",
            "patch": "@@ -554,10 +554,6 @@ class TrainingArguments:\n                     Will use gradient checkpointing over each nested XLA FSDP wrapped layer. This setting can only be\n                     used when the xla flag is set to true, and an auto wrapping policy is specified through\n                     fsdp_min_num_params or fsdp_transformer_layer_cls_to_wrap.\n-        tp_size (`int`, *optional*):\n-            Use tp_size to enable PyTorch tensor parallelism. Tensor parallelism support is only available to models having `base_tp_plan`\n-            in their respective config classes.\n-            Set a value greater than 1 to activate TP. The same is used to prepare device mesh internally. Requires accelerate>1.3.0.\n         deepspeed (`str` or `dict`, *optional*):\n             Use [Deepspeed](https://github.com/deepspeedai/DeepSpeed). This is an experimental feature and its API may\n             evolve in the future. The value is either the location of DeepSpeed json config file (e.g.,\n@@ -1244,18 +1240,6 @@ class TrainingArguments:\n             )\n         },\n     )\n-    tp_size: Optional[int] = field(\n-        default=0,\n-        metadata={\n-            \"help\": (\n-                \"Use tp_size to enable pytorch tensor parallelism.\"\n-                \"Tensor parallelism support is only available to models having `base_tp_plan` in their respective config classes.\"\n-                \"Set a value greater than 1 to activate TP.\"\n-                \"The same is used to prepare device mesh internally.\"\n-                \"Requires accelerate>1.3.0.\"\n-            )\n-        },\n-    )\n     fsdp_transformer_layer_cls_to_wrap: Optional[str] = field(\n         default=None,\n         metadata={\n@@ -1941,14 +1925,6 @@ def __post_init__(self):\n             if self.fsdp_config[\"xla_fsdp_grad_ckpt\"]:\n                 warnings.warn(\"`--xla_fsdp_grad_ckpt` is useful only when `--xla` is set to true.\")\n \n-        if self.tp_size > 1:\n-            if not is_accelerate_available(\"1.3.1\"):\n-                raise NotImplementedError(\n-                    \"TP using PyTorch requires Accelerate version `accelerate` >= 1.3.1. \"\n-                    \"This is not supported and we recommend you to update your version.\"\n-                )\n-            os.environ[\"ACCELERATE_USE_TP\"] = \"true\"\n-            os.environ[\"TP_SIZE\"] = str(self.tp_size)\n         # accelerate integration for FSDP\n         if len(self.fsdp) > 0 and not self.fsdp_config[\"xla\"]:\n             os.environ[\"ACCELERATE_USE_FSDP\"] = \"true\""
        }
    ],
    "stats": {
        "total": 147,
        "additions": 27,
        "deletions": 120
    }
}