{
    "author": "HuiyingLi",
    "message": "Fix Qwen3OmniMoe Talker weight loading and config initialization (#43084)\n\n* fix modular_qwen3_omni_moe\n\nSigned-off-by: HuiyingLi <willwin.lee@gmail.com>\n\n* update generated configuration and modeling file\n\nSigned-off-by: HuiyingLi <willwin.lee@gmail.com>\n\n* fix tie weight keys\n\nSigned-off-by: HuiyingLi <willwin.lee@gmail.com>\n\n---------\n\nSigned-off-by: HuiyingLi <willwin.lee@gmail.com>",
    "sha": "64a476b718728c76aea8a847aeabbf8074fe3202",
    "files": [
        {
            "sha": "cad8b089a25026cf7ab4ab2617cf25b7da4315ab",
            "filename": "src/transformers/models/qwen3_omni_moe/configuration_qwen3_omni_moe.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/64a476b718728c76aea8a847aeabbf8074fe3202/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fconfiguration_qwen3_omni_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/64a476b718728c76aea8a847aeabbf8074fe3202/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fconfiguration_qwen3_omni_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fconfiguration_qwen3_omni_moe.py?ref=64a476b718728c76aea8a847aeabbf8074fe3202",
            "patch": "@@ -907,6 +907,7 @@ def __init__(\n         self.audio_start_token_id = audio_start_token_id\n         self.vision_start_token_id = vision_start_token_id\n         self.speaker_id = speaker_id\n+        self.initializer_range = self.text_config.initializer_range\n         super().__init__(**kwargs)\n \n \n@@ -997,6 +998,7 @@ def __init__(\n         upsampling_ratios=(2, 2),\n         decoder_dim=1536,\n         attention_dropout=0.0,\n+        initializer_range=0.02,\n         **kwargs,\n     ):\n         self.codebook_size = codebook_size\n@@ -1016,6 +1018,7 @@ def __init__(\n         self.upsampling_ratios = upsampling_ratios\n         self.decoder_dim = decoder_dim\n         self.attention_dropout = attention_dropout\n+        self.initializer_range = initializer_range\n         self.rope_parameters = rope_parameters\n \n         super().__init__(**kwargs)\n@@ -1104,6 +1107,7 @@ def __init__(\n         self.thinker_config = Qwen3OmniMoeThinkerConfig(**thinker_config)\n         self.talker_config = Qwen3OmniMoeTalkerConfig(**talker_config)\n         self.code2wav_config = Qwen3OmniMoeCode2WavConfig(**code2wav_config)\n+        self.initializer_range = self.thinker_config.initializer_range\n         self.enable_audio_output = enable_audio_output\n         self.im_start_token_id = im_start_token_id\n         self.im_end_token_id = im_end_token_id"
        },
        {
            "sha": "e5009acb67ca822f75fab89d81c4b2d37cad59a4",
            "filename": "src/transformers/models/qwen3_omni_moe/modeling_qwen3_omni_moe.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/64a476b718728c76aea8a847aeabbf8074fe3202/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/64a476b718728c76aea8a847aeabbf8074fe3202/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py?ref=64a476b718728c76aea8a847aeabbf8074fe3202",
            "patch": "@@ -3051,9 +3051,9 @@ def get_input_embeddings(self):\n \n @auto_docstring\n class Qwen3OmniMoeTalkerForConditionalGeneration(Qwen3OmniMoeThinkerTextPreTrainedModel, GenerationMixin):\n-    _tied_weights_keys = {\"lm_head.weight\": \"model.embed_tokens.weight\"}\n-    _tp_plan = {\"lm_head\": \"colwise_rep\"}\n-    _pp_plan = {\"lm_head\": ([\"hidden_states\"], [\"logits\"])}\n+    _tied_weights_keys = {\"codec_head\": \"model.codec_embedding.weight\"}\n+    _tp_plan = {\"codec_head\": \"colwise_rep\"}\n+    _pp_plan = {\"codec_head\": ([\"hidden_states\"], [\"logits\"])}\n     config_class = Qwen3OmniMoeTalkerConfig\n     base_model_prefix = \"talker\"\n     _no_split_modules = [\"Qwen3OmniMoeTalkerCodePredictorModelForConditionalGeneration\"]"
        },
        {
            "sha": "ce53bc9e6e8f8d248dbabd743253e72aecbda9d8",
            "filename": "src/transformers/models/qwen3_omni_moe/modular_qwen3_omni_moe.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/64a476b718728c76aea8a847aeabbf8074fe3202/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodular_qwen3_omni_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/64a476b718728c76aea8a847aeabbf8074fe3202/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodular_qwen3_omni_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodular_qwen3_omni_moe.py?ref=64a476b718728c76aea8a847aeabbf8074fe3202",
            "patch": "@@ -673,6 +673,7 @@ def __init__(\n         self.audio_start_token_id = audio_start_token_id\n         self.vision_start_token_id = vision_start_token_id\n         self.speaker_id = speaker_id\n+        self.initializer_range = self.text_config.initializer_range\n         super().__init__(**kwargs)\n \n \n@@ -763,6 +764,7 @@ def __init__(\n         upsampling_ratios=(2, 2),\n         decoder_dim=1536,\n         attention_dropout=0.0,\n+        initializer_range=0.02,\n         **kwargs,\n     ):\n         self.codebook_size = codebook_size\n@@ -782,6 +784,7 @@ def __init__(\n         self.upsampling_ratios = upsampling_ratios\n         self.decoder_dim = decoder_dim\n         self.attention_dropout = attention_dropout\n+        self.initializer_range = initializer_range\n         self.rope_parameters = rope_parameters\n \n         super().__init__(**kwargs)\n@@ -870,6 +873,7 @@ def __init__(\n         self.thinker_config = Qwen3OmniMoeThinkerConfig(**thinker_config)\n         self.talker_config = Qwen3OmniMoeTalkerConfig(**talker_config)\n         self.code2wav_config = Qwen3OmniMoeCode2WavConfig(**code2wav_config)\n+        self.initializer_range = self.thinker_config.initializer_range\n         self.enable_audio_output = enable_audio_output\n         self.im_start_token_id = im_start_token_id\n         self.im_end_token_id = im_end_token_id\n@@ -1869,6 +1873,9 @@ def get_input_embeddings(self):\n \n \n class Qwen3OmniMoeTalkerForConditionalGeneration(Qwen3MoeForCausalLM):\n+    _tied_weights_keys = {\"codec_head\": \"model.codec_embedding.weight\"}\n+    _tp_plan = {\"codec_head\": \"colwise_rep\"}\n+    _pp_plan = {\"codec_head\": ([\"hidden_states\"], [\"logits\"])}\n     config_class = Qwen3OmniMoeTalkerConfig\n     base_model_prefix = \"talker\"\n     _no_split_modules = [\"Qwen3OmniMoeTalkerCodePredictorModelForConditionalGeneration\"]"
        }
    ],
    "stats": {
        "total": 17,
        "additions": 14,
        "deletions": 3
    }
}