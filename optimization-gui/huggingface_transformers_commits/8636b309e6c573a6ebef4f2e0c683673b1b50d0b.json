{
    "author": "robin-ede",
    "message": "Fix chat CLI GPU loading and request_id validation issues (#40230) (#40232)\n\n* Fix chat CLI GPU loading and request_id validation issues (#40230)\n\nThis commit addresses two critical bugs in the transformers chat CLI:\n\n1. **GPU Loading Issue**: Changed default device from \"cpu\" to \"auto\" in ChatArguments\n   - Chat CLI now automatically uses GPU when available instead of defaulting to CPU\n   - Matches the behavior of the underlying serving infrastructure\n\n2. **Request ID Validation Error**: Added request_id field to TransformersCompletionCreateParamsStreaming schema\n   - Fixes \"Unexpected keys in the request: {'request_id'}\" error on second message\n   - Allows request_id to be properly sent and validated by the server\n\nBoth fixes target the exact root causes identified in issue #40230:\n- Users will now get GPU acceleration by default when available\n- Chat sessions will no longer break after the second message\n\n* Remove unrelated request_id field from TransformersCompletionCreateParamsStreaming",
    "sha": "8636b309e6c573a6ebef4f2e0c683673b1b50d0b",
    "files": [
        {
            "sha": "c7fb7c2c7aeb227786d67fe414098bc13e7bd644",
            "filename": "src/transformers/commands/chat.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8636b309e6c573a6ebef4f2e0c683673b1b50d0b/src%2Ftransformers%2Fcommands%2Fchat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8636b309e6c573a6ebef4f2e0c683673b1b50d0b/src%2Ftransformers%2Fcommands%2Fchat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fchat.py?ref=8636b309e6c573a6ebef4f2e0c683673b1b50d0b",
            "patch": "@@ -246,7 +246,7 @@ class ChatArguments:\n         default=\"main\",\n         metadata={\"help\": \"Specific model version to use (can be a branch name, tag name or commit id).\"},\n     )\n-    device: str = field(default=\"cpu\", metadata={\"help\": \"Device to use for inference.\"})\n+    device: str = field(default=\"auto\", metadata={\"help\": \"Device to use for inference.\"})\n     torch_dtype: Optional[str] = field(\n         default=\"auto\",\n         metadata={"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}