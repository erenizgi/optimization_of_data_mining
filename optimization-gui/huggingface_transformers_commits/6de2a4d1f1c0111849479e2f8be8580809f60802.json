{
    "author": "AhmedAlmaghz",
    "message": "[i18n-ar] Translated file : `docs/source/ar/torchscript.md` into Arabic (#33079)\n\n* Add docs/source/ar/torchscript.md to Add_docs_source_ar_torchscript.md\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/torchscript.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Merge troubleshooting.md with this Branch\r\n\r\n* Update _toctree.yml\r\n\r\n* Update torchscript.md\r\n\r\n* Update troubleshooting.md\r\n\r\n---------\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>",
    "sha": "6de2a4d1f1c0111849479e2f8be8580809f60802",
    "files": [
        {
            "sha": "d9523eaf5da535277e1457cbbdba0925a5c3e2bb",
            "filename": "docs/source/ar/_toctree.yml",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/6de2a4d1f1c0111849479e2f8be8580809f60802/docs%2Fsource%2Far%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/6de2a4d1f1c0111849479e2f8be8580809f60802/docs%2Fsource%2Far%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2F_toctree.yml?ref=6de2a4d1f1c0111849479e2f8be8580809f60802",
            "patch": "@@ -127,16 +127,16 @@\n     title: Ø§Ù„ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ ONNX\n   - local: tflite\n     title: Ø§Ù„ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ TFLite\n-#   - local: torchscript\n-#     title: Ø§Ù„ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ TorchScript\n+  - local: torchscript\n+    title: Ø§Ù„ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ TorchScript\n #   - local: benchmarks\n #     title: Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±\n #   - local: notebooks\n #     title: Ø¯ÙØ§ØªØ± Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ø¹ Ø§Ù„Ø£Ù…Ø«Ù„Ø©\n #   - local: community\n #     title: Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹\n-#   - local: troubleshooting\n-#     title: Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ¥ØµÙ„Ø§Ø­Ù‡Ø§\n+  - local: troubleshooting\n+    title: Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ¥ØµÙ„Ø§Ø­Ù‡Ø§\n   - local: gguf\n     title: Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ù…Ù„ÙØ§Øª GGUF\n   title: Ø£Ø¯Ù„Ø© Ø§Ù„Ù…Ø·ÙˆØ±ÙŠÙ†"
        },
        {
            "sha": "bf0bc0dde04b629932d32f85e15529a6c0128305",
            "filename": "docs/source/ar/torchscript.md",
            "status": "added",
            "additions": 154,
            "deletions": 0,
            "changes": 154,
            "blob_url": "https://github.com/huggingface/transformers/blob/6de2a4d1f1c0111849479e2f8be8580809f60802/docs%2Fsource%2Far%2Ftorchscript.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/6de2a4d1f1c0111849479e2f8be8580809f60802/docs%2Fsource%2Far%2Ftorchscript.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Ftorchscript.md?ref=6de2a4d1f1c0111849479e2f8be8580809f60802",
            "patch": "@@ -0,0 +1,154 @@\n+# Ø§Ù„ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ TorchScript\n+\n+<Tip>\n+\n+Ù‡Ø°Ù‡ Ù‡ÙŠ Ø¨Ø¯Ø§ÙŠØ© ØªØ¬Ø§Ø±Ø¨Ù†Ø§ Ù…Ø¹ TorchScript ÙˆÙ„Ø§ Ø²Ù„Ù†Ø§ Ù†Ø³ØªÙƒØ´Ù Ù‚Ø¯Ø±Ø§ØªÙ‡ Ù…Ø¹ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù…ØªØºÙŠØ±Ø© Ø§Ù„Ø­Ø¬Ù…. Ø¥Ù†Ù‡ Ù…Ø¬Ø§Ù„ Ø§Ù‡ØªÙ…Ø§Ù…Ù†Ø§ ÙˆØ³Ù†Ø¹Ù…Ù‚ ØªØ­Ù„ÙŠÙ„Ù†Ø§ ÙÙŠ Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©ØŒ Ù…Ø¹ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©ØŒ ÙˆØªÙ†ÙÙŠØ° Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø©ØŒ ÙˆÙ…Ù‚Ø§ÙŠÙŠØ³ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ†  Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¹Ù„Ù‰ Python Ù…Ø¹ Ø£ÙƒÙˆØ§Ø¯ TorchScript Ø§Ù„Ù…ÙØ¬Ù…Ù‘Ø¹Ø©.\n+\n+</Tip>\n+\n+ÙˆÙÙ‚Ù‹Ø§ Ù„Ù€ [ÙˆØ«Ø§Ø¦Ù‚ TorchScript](https://pytorch.org/docs/stable/jit.html):\n+\n+> TorchScript Ù‡ÙŠ Ø·Ø±ÙŠÙ‚Ø© Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…Ø§Ø°Ø¬ Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ³Ù„Ø³Ù„ ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ† Ù…Ù† ØªØ¹Ù„ÙŠÙ…Ø§Øª PyTorch Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©.\n+\n+Ù‡Ù†Ø§Ùƒ ÙˆØ­Ø¯ØªØ§Ù† Ù…Ù† PyTorchØŒ [JIT and TRACE](https://pytorch.org/docs/stable/jit.html)ØŒ ØªØªÙŠØ­Ø§Ù† Ù„Ù„Ù…Ø·ÙˆØ±ÙŠÙ† ØªØµØ¯ÙŠØ± Ù†Ù…Ø§Ø°Ø¬Ù‡Ù… Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ Ø¨Ø±Ø§Ù…Ø¬ Ø£Ø®Ø±Ù‰ Ù…Ø«Ù„ Ø¨Ø±Ø§Ù…Ø¬ C++ Ø§Ù„Ù…ÙØ­Ø³Ù‘Ù†Ø© Ù„Ù„Ø£Ø¯Ø§Ø¡.\n+\n+Ù†Ù‚Ø¯Ù… ÙˆØ§Ø¬Ù‡Ø© ØªØªÙŠØ­ Ù„Ùƒ ØªØµØ¯ÙŠØ± Ù†Ù…Ø§Ø°Ø¬ ğŸ¤— Transformers Ø¥Ù„Ù‰ TorchScript Ø¨Ø­ÙŠØ« ÙŠÙ…ÙƒÙ† Ø¥Ø¹Ø§Ø¯Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ Ø¨ÙŠØ¦Ø© Ù…Ø®ØªÙ„ÙØ© Ø¹Ù† Ø¨Ø±Ø§Ù…Ø¬ Python Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¥Ù„Ù‰ PyTorch. Ù‡Ù†Ø§ Ù†Ø´Ø±Ø­ ÙƒÙŠÙÙŠØ© ØªØµØ¯ÙŠØ± Ù†Ù…Ø§Ø°Ø¬Ù†Ø§ ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… TorchScript.\n+\n+ÙŠØªØ·Ù„Ø¨ ØªØµØ¯ÙŠØ± Ù†Ù…ÙˆØ°Ø¬ Ø£Ù…Ø±ÙŠÙ†:\n+\n+- ØªÙ‡ÙŠØ¦Ø© Ù…Ø«ÙŠÙ„ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ù„Ø§Ù…Ø© `torchscript`\n+- ØªÙ…Ø±ÙŠØ± Ù…ÙØ¯Ø®Ù„Ø§Øª ÙˆÙ‡Ù…ÙŠØ© (dummy inputs) Ø®Ù„Ø§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n+\n+ØªÙ†Ø·ÙˆÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¶Ø±ÙˆØ±Ø§Øª Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ø£Ù…ÙˆØ± ÙŠØ¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø·ÙˆØ±ÙŠÙ† ØªÙˆØ®ÙŠ Ø§Ù„Ø­Ø°Ø± Ø¨Ø´Ø£Ù†Ù‡Ø§ ÙƒÙ…Ø§ Ù‡Ùˆ Ù…ÙØµÙ„ Ø£Ø¯Ù†Ø§Ù‡.\n+\n+## Ø¹Ù„Ø§Ù…Ø© TorchScript ÙˆØ§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©\n+\n+Ø¹Ù„Ø§Ù…Ø© `torchscript` Ø¶Ø±ÙˆØ±ÙŠØ© Ù„Ø£Ù† Ù…Ø¹Ø¸Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ© ğŸ¤— Transformers Ù„Ù‡Ø§ Ø£ÙˆØ²Ø§Ù† Ù…Ø±ØªØ¨Ø·Ø© Ø¨ÙŠÙ† Ø·Ø¨Ù‚Ø© `Embedding` ÙˆØ·Ø¨Ù‚Ø© `Decoding`. Ù„Ø§ ÙŠØ³Ù…Ø­ Ù„Ùƒ TorchScript Ø¨ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø°Ø§Øª Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©ØŒ Ù„Ø°Ù„Ùƒ Ù…Ù† Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠ ÙØµÙ„ Ø§Ù„Ø£ÙˆØ²Ø§Ù† ÙˆÙ†Ø³Ø®Ù‡Ø§ Ù…Ø³Ø¨Ù‚Ù‹Ø§.\n+\n+Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙÙ‡ÙŠØ£Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ù„Ø§Ù…Ø© `torchscript` Ù„Ù‡Ø§ Ø·Ø¨Ù‚Ø© `Embedding` ÙˆØ·Ø¨Ù‚Ø©`Decoding` Ù…Ù†ÙØµÙ„ØªÙŠÙ†ØŒ Ù…Ù…Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ Ù„Ø§ ÙŠÙ†Ø¨ØºÙŠ ØªØ¯Ø±ÙŠØ¨Ù‡Ø§ Ù„Ø§Ø­Ù‚Ù‹Ø§. Ø³ÙŠØ¤Ø¯ÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¥Ù„Ù‰ Ø¹Ø¯Ù… ØªØ²Ø§Ù…Ù† Ø§Ù„Ø·Ø¨Ù‚ØªÙŠÙ†ØŒ Ù…Ù…Ø§ ÙŠØ¤Ø¯ÙŠ Ø¥Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹Ø©.\n+\n+Ù‡Ø°Ø§ Ù„Ø§ ÙŠÙ†Ø·Ø¨Ù‚ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø±Ø£Ø³ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºØ©ØŒ Ø­ÙŠØ« Ù„Ø§ ØªÙ…Ù„Ùƒ Ø£ÙˆØ²Ø§Ù†Ù‹Ø§ Ù…Ø±ØªØ¨Ø·Ø©. ÙŠÙ…ÙƒÙ† ØªØµØ¯ÙŠØ± Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø£Ù…Ø§Ù† Ø¯ÙˆÙ† Ø¹Ù„Ø§Ù…Ø© `torchscript`.\n+\n+## Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„ÙˆÙ‡Ù…ÙŠØ© ÙˆØ§Ù„Ø£Ø·ÙˆØ§Ù„ Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ©\n+\n+ØªÙØ³ØªØ®Ø¯Ù… Ø§Ù„Ù…ÙØ¯Ø®Ù„Ø§Øª Ø§Ù„ÙˆÙ‡Ù…ÙŠØ© Ù„ØªÙ…Ø±ÙŠØ± Ø£Ù…Ø§Ù…ÙŠ Ø®Ù„Ø§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ø£Ø«Ù†Ø§Ø¡ Ø§Ù†ØªØ´Ø§Ø± Ù‚ÙŠÙ… Ø§Ù„Ù…ÙØ¯Ø®Ù„Ø§Øª Ø¹Ø¨Ø± Ø§Ù„Ø·Ø¨Ù‚Ø§ØªØŒ ÙŠØªØªØ¨Ø¹ PyTorch Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ø§Ù„ØªÙŠ ÙŠØªÙ… ØªÙ†ÙÙŠØ°Ù‡Ø§ Ø¹Ù„Ù‰ ÙƒÙ„ Ù…ØµÙÙˆÙØ©(tensor). Ø«Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙØ³Ø¬Ù„Ø© Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ Ù„Ø¥Ù†Ø´Ø§Ø¡ *Ø£Ø«Ø±* Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n+\n+ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØªØ¨Ø¹ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù…ÙØ¯Ø®Ù„Ø§Øª. ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠØŒ ÙÙ‡Ùˆ Ù…ÙÙ‚ÙŠÙ‘Ø¯ Ø¨Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù…ÙØ¯Ø®Ù„Ø§Øª Ø§Ù„ÙˆÙ‡Ù…ÙŠØ©ØŒ ÙˆÙ„Ù† ÙŠØ¹Ù…Ù„ Ù„Ø£ÙŠ Ø·ÙˆÙ„ ØªØ³Ù„Ø³Ù„ Ø£Ùˆ Ø­Ø¬Ù… Ø¯ÙØ¹Ø© Ù…Ø®ØªÙ„Ù. Ø¹Ù†Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø­Ø¬Ù… Ù…Ø®ØªÙ„ÙØŒ ÙŠØªÙ… Ø±ÙØ¹ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„ØªØ§Ù„ÙŠ:\n+\n+```\n+`The expanded size of the tensor (3) must match the existing size (7) at non-singleton dimension 2`\n+```\n+\n+Ù†ÙˆØµÙŠ Ø¨ØªØªØ¨Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø­Ø¬Ù… Ù…ÙØ¯Ø®Ù„Ø§Øª ÙˆÙ‡Ù…ÙŠØ© Ù„Ø§ ÙŠÙ‚Ù„ Ø¹Ù† Ø£ÙƒØ¨Ø± Ù…ÙØ¯Ø®Ù„ Ø³ÙŠØªÙ… ØªÙ‚Ø¯ÙŠÙ…Ù‡ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„. ÙŠÙ…ÙƒÙ† Ø£Ù† ØªØ³Ø§Ø¹Ø¯ Ø§Ù„Ø­Ø´ÙˆØ©(padding) ÙÙŠ Ù…Ù„Ø¡ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©. ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ Ù†Ø¸Ø±Ù‹Ø§ Ù„ØªØªØ¨Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø­Ø¬Ù… Ù…ÙØ¯Ø®Ù„ Ø£ÙƒØ¨Ø±ØŒ Ø³ØªÙƒÙˆÙ† Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù…ØµÙÙˆÙØ© Ø³ØªÙƒÙˆÙ† ÙƒØ¨ÙŠØ±Ø© Ø£ÙŠØ¶Ù‹Ø§ØŒ Ù…Ù…Ø§ ÙŠØ¤Ø¯ÙŠ Ø¹Ù†Ù‡ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª.\n+\n+Ø§Ù†ØªØ¨Ù‡ Ø¥Ù„Ù‰ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙÙ†ÙØ°Ø© Ø¹Ù„Ù‰ ÙƒÙ„ Ù…ÙØ¯Ø®Ù„ ÙˆØªØ§Ø¨Ø¹ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¹Ù† ÙƒØ«Ø¨ Ø¹Ù†Ø¯ ØªØµØ¯ÙŠØ± Ù†Ù…Ø§Ø°Ø¬ Ù…ØªØºÙŠØ±Ø© Ø·ÙˆÙ„ Ø§Ù„ØªØ³Ù„Ø³Ù„.\n+\n+## Ø§Ø³ØªØ®Ø¯Ø§Ù… TorchScript ÙÙŠ Python\n+\n+ÙŠÙˆØ¶Ø­ Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù… ÙƒÙŠÙÙŠØ© Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØªØ­Ù…ÙŠÙ„Ù‡Ø§ØŒ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØªØ¨Ø¹ Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„.\n+\n+### Ø­ÙØ¸ Ù†Ù…ÙˆØ°Ø¬\n+\n+Ù„ØªØµØ¯ÙŠØ± `BertModel` Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… TorchScriptØŒ Ù‚Ù… Ø¨ØªÙ‡ÙŠØ¦Ø© Ù€ `BertModel` Ù…Ù† ÙØ¦Ø© `BertConfig` Ø«Ù… Ø§Ø­ÙØ¸Ù‡ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø±Øµ ØªØ­Øª Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù `traced_bert.pt`:\n+\n+```python\n+from transformers import BertModel, BertTokenizer, BertConfig\n+import torch\n+\n+enc = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n+\n+# Tokenizing input text\n+text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n+tokenized_text = enc.tokenize(text)\n+\n+# Masking one of the input tokens\n+masked_index = 8\n+tokenized_text[masked_index] = \"[MASK]\"\n+indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n+segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n+\n+# Creating a dummy input\n+tokens_tensor = torch.tensor([indexed_tokens])\n+segments_tensors = torch.tensor([segments_ids])\n+dummy_input = [tokens_tensor, segments_tensors]\n+\n+# Initializing the model with the torchscript flag\n+# Flag set to True even though it is not necessary as this model does not have an LM Head.\n+config = BertConfig(\n+    vocab_size_or_config_json_file=32000,\n+    hidden_size=768,\n+    num_hidden_layers=12,\n+    num_attention_heads=12,\n+    intermediate_size=3072,\n+    torchscript=True,\n+)\n+\n+# Instantiating the model\n+model = BertModel(config)\n+\n+# The model needs to be in evaluation mode\n+model.eval()\n+\n+# If you are instantiating the model with *from_pretrained* you can also easily set the TorchScript flag\n+model = BertModel.from_pretrained(\"google-bert/bert-base-uncased\", torchscript=True)\n+\n+# Creating the trace\n+traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])\n+torch.jit.save(traced_model, \"traced_bert.pt\")\n+```\n+\n+### ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† ØªØ­Ù…ÙŠÙ„ `BertModel` Ø§Ù„Ù…ÙØ­ÙØ¸ Ø³Ø§Ø¨Ù‚Ù‹Ø§ØŒ `traced_bert.pt`ØŒ Ù…Ù† Ø§Ù„Ù‚Ø±Øµ ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ø¹Ù„Ù‰ `dummy_input` Ø§Ù„Ù…ÙÙ‡ÙŠØ£ Ø³Ø§Ø¨Ù‚Ù‹Ø§:\n+\n+```python\n+loaded_model = torch.jit.load(\"traced_bert.pt\")\n+loaded_model.eval()\n+\n+all_encoder_layers, pooled_output = loaded_model(*dummy_input)\n+```\n+\n+### Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØªØªØ¨Ø¹ Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„\n+\n+Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØªØªØ¨Ø¹ Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø³Ù„ÙˆØ¨ `__call__` Ø§Ù„Ø®Ø§Øµ Ø¨Ù‡:\n+\n+```python\n+traced_model(tokens_tensor, segments_tensors)\n+```\n+\n+## Ù†Ø´Ø± Ù†Ù…Ø§Ø°Ø¬ Hugging Face TorchScript Ø¹Ù„Ù‰ AWS Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Neuron SDK\n+\n+Ù‚Ø¯Ù…Øª AWS Ø¹Ø§Ø¦Ù„Ø© [Amazon EC2 Inf1](https://aws.amazon.com/ec2/instance-types/inf1/) Ù…Ù† Ø§ï»·Ø¬Ù‡Ø²Ø© Ù„Ø®ÙØ¶ Ø§Ù„ØªÙƒÙ„ÙØ© ÙˆØ£Ø¯Ø§Ø¡ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙŠ Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠØ©. ØªØ¹Ù…Ù„ Ø£Ø¬Ù‡Ø²Ø© Inf1 Ø¨ÙˆØ§Ø³Ø·Ø© Ø´Ø±ÙŠØ­Ø© Inferentia Ù…Ù† AWSØŒ ÙˆÙ‡ÙŠ Ù…ÙØ³Ø±Ù‘Ø¹ Ø£Ø¬Ù‡Ø²Ø© Ù…ÙØ®ØµØµØŒ Ù…ØªØ®ØµØµ ÙÙŠ Ø£Ø¹Ø¨Ø§Ø¡ Ø¹Ù…Ù„ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚. [AWS Neuron](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/#) Ù‡ÙŠ SDK Ù„Ù€ Inferentia Ø§Ù„ØªÙŠ ØªØ¯Ø¹Ù… ØªØªØ¨Ø¹ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª ÙˆØªØ­Ø³ÙŠÙ†Ù‡Ø§ Ù„Ù„Ù†Ø´Ø± Ø¹Ù„Ù‰ Inf1. ØªÙˆÙØ± Neuron SDK Ù…Ø§ ÙŠÙ„ÙŠ:\n+\n+1. ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø³Ù‡Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹ ØªØºÙŠÙŠØ± Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ù„ØªØªØ¨Ø¹ Ù†Ù…ÙˆØ°Ø¬ TorchScript ÙˆØªØ­Ø³ÙŠÙ†Ù‡ Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ ÙÙŠ Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠØ©.\n+2. ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… [ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙƒÙ„ÙØ© ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/benchmark/>).\n+3. Ø¯Ø¹Ù… Ù†Ù…Ø§Ø°Ø¬ Hugging Face Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª Ø§Ù„Ù…Ø¨Ù†ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥Ù…Ø§ [PyTorch](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/src/examples/pytorch/bert_tutorial/tutorial_pretrained_bert.html) Ø£Ùˆ [TensorFlow](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/src/examples/tensorflow/huggingface_bert/huggingface_bert.html).\n+\n+### Ø§Ù„Ø¢Ø«Ø§Ø± Ø§Ù„Ù…ØªØ±ØªØ¨Ø©\n+\n+ØªØ¹Ù…Ù„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø© Ø¥Ù„Ù‰ Ø¨Ù†ÙŠØ© [BERT (ØªÙ…Ø«ÙŠÙ„Ø§Øª Ø§Ù„ØªØ±Ù…ÙŠØ² Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ù…Ù† Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª)](https://huggingface.co/docs/transformers/main/model_doc/bert) Ø£Ùˆ Ù…ØªØºÙŠØ±Ø§ØªÙ‡Ø§ Ù…Ø«Ù„ [distilBERT](https://huggingface.co/docs/transformers/main/model_doc/distilbert) Ùˆ [roBERTa](https://huggingface.co/docs/transformers/main/model_doc/roberta) Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„ Ø¹Ù„Ù‰ Inf1 Ù„Ù„Ù…Ù‡Ø§Ù… ØºÙŠØ± Ø§Ù„ØªÙˆÙ„ÙŠØ¯ÙŠØ© Ù…Ø«Ù„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ÙŠØ©ØŒ ÙˆØªØµÙ†ÙŠÙ Ø§Ù„ØªØ³Ù„Ø³Ù„Ø§ØªØŒ ÙˆØªØµÙ†ÙŠÙ Ø§Ù„Ø±Ù…ÙˆØ² (tokens). ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ ÙŠÙ…ÙƒÙ† ØªÙƒÙŠÙŠÙ Ù…Ù‡Ø§Ù… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ Ù„Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Inf1 ÙˆÙÙ‚Ù‹Ø§ Ù„Ù‡Ø°Ø§ [Ø¨Ø±Ù†Ø§Ù…Ø¬ ØªØ¹Ù„ÙŠÙ…ÙŠ AWS Neuron MarianMT](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/src/examples/pytorch/transformers-marianmt.html). ÙŠÙ…ÙƒÙ† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¬Ø§Ù‡Ø²Ø© Ø¹Ù„Ù‰ Inferentia ÙÙŠ Ù‚Ø³Ù… [Ù…Ù„Ø§Ø¡Ù…Ø© Ø¨Ù†ÙŠØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/models/models-inferentia.html#models-inferentia) Ù…Ù† ÙˆØ«Ø§Ø¦Ù‚ Neuron.\n+\n+### Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª (Dependencies)\n+\n+ÙŠØªØ·Ù„Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… AWS Neuron Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ [Ø¨ÙŠØ¦Ø© SDK Neuron](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/neuron-frameworks/pytorch-neuron/index.html#installation-guide) ÙˆØ§Ù„ØªÙŠ ØªØ£ØªÙŠ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¹Ù„Ù‰ [AMI Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ù…Ù† AWS](https://docs.aws.amazon.com/dlami/latest/devguide/tutorial-inferentia-launching.html).\n+\n+### ØªØ­ÙˆÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ AWS Neuron\n+\n+Ù‚Ù… Ø¨ØªØ­ÙˆÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ AWS NEURON Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ù…Ù† [Ø§Ø³ØªØ®Ø¯Ø§Ù… TorchScript ÙÙŠ Python](torchscript#using-torchscript-in-python) Ù„ØªØªØ¨Ø¹ `BertModel`. Ù‚Ù… Ø¨Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù…ØªØ¯Ø§Ø¯ Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ `torch.neuron` Ù„Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ù…ÙƒÙˆÙ†Ø§Øª Neuron SDK Ù…Ù† Ø®Ù„Ø§Ù„ ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Python:\n+\n+```python\n+from transformers import BertModel, BertTokenizer, BertConfig\n+import torch\n+import torch.neuron\n+```\n+\n+ÙƒÙ„ Ù…Ø§ Ø¹Ù„ÙŠÙƒ ÙØ¹Ù„Ù‡ Ù‡Ùˆ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø·Ø± Ø§Ù„ØªØ§Ù„ÙŠ:\n+\n+```diff\n+- torch.jit.trace(model, [tokens_tensor, segments_tensors])\n++ torch.neuron.trace(model, [token_tensor, segments_tensors])\n+```\n+\n+ÙŠØªÙŠØ­ Ø°Ù„Ùƒ Ù„Ù€ Neuron SDK ØªØªØ¨Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªØ­Ø³ÙŠÙ†Ù‡ Ù„Ù…Ø«ÙŠÙ„Ø§Øª Inf1.\n+\n+Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ø­ÙˆÙ„ Ù…ÙŠØ²Ø§Øª AWS Neuron SDK ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª ÙˆØ¯Ø±ÙˆØ³ Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø©ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ø·Ù„Ø§Ø¹ Ø¹Ù„Ù‰ [ÙˆØ«Ø§Ø¦Ù‚ AWS NeuronSDK](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/index.html)."
        },
        {
            "sha": "7874a9fad13304a859967b79d9117da8dc34a545",
            "filename": "docs/source/ar/troubleshooting.md",
            "status": "added",
            "additions": 171,
            "deletions": 0,
            "changes": 171,
            "blob_url": "https://github.com/huggingface/transformers/blob/6de2a4d1f1c0111849479e2f8be8580809f60802/docs%2Fsource%2Far%2Ftroubleshooting.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/6de2a4d1f1c0111849479e2f8be8580809f60802/docs%2Fsource%2Far%2Ftroubleshooting.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Ftroubleshooting.md?ref=6de2a4d1f1c0111849479e2f8be8580809f60802",
            "patch": "@@ -0,0 +1,171 @@\n+# Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ¥ØµÙ„Ø§Ø­Ù‡Ø§\n+\n+ØªØ­Ø¯Ø« Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø£Ø­ÙŠØ§Ù†Ù‹Ø§ØŒ Ù„ÙƒÙ†Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©! ÙŠØºØ·ÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø´ÙƒÙ„Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ù‹Ø§ Ø§Ù„ØªÙŠ ÙˆØ§Ø¬Ù‡Ù†Ø§Ù‡Ø§ ÙˆÙƒÙŠÙÙŠØ© Ø­Ù„Ù‡Ø§. Ù…Ø¹ Ø°Ù„ÙƒØŒ Ù„Ø§ ÙŠÙÙ‚ØµØ¯ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø´Ø§Ù…Ù„Ø© Ù„ÙƒÙ„ Ù…Ø´ÙƒÙ„Ø§Øª ğŸ¤— Transformers. Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø§Ø³ØªÙƒØ´Ø§Ù Ù…Ø´ÙƒÙ„ØªÙƒ ÙˆØ¥ØµÙ„Ø§Ø­Ù‡Ø§ØŒ Ø¬Ø±Ø¨ Ù…Ø§ ÙŠÙ„ÙŠ:\n+<Youtube id=\"S2EEG3JIt2A\"/>\n+\n+\n+1. Ø§Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¹Ù„Ù‰ [Ø§Ù„Ù…Ù†ØªØ¯ÙŠØ§Øª](https://discuss.huggingface.co/). Ù‡Ù†Ø§Ùƒ ÙØ¦Ø§Øª Ù…Ø­Ø¯Ø¯Ø© ÙŠÙ…ÙƒÙ†Ùƒ Ù†Ø´Ø± Ø³Ø¤Ø§Ù„Ùƒ ÙÙŠÙ‡Ø§ØŒ Ù…Ø«Ù„ [Ø§Ù„Ù…Ø¨ØªØ¯Ø¦ÙŠÙ†](https://discuss.huggingface.co/c/beginners/5) Ø£Ùˆ [ğŸ¤— Transformers](https://discuss.huggingface.co/c/transformers/9). ØªØ£ÙƒØ¯ Ù…Ù† ÙƒØªØ§Ø¨Ø© Ù…Ù†Ø´ÙˆØ± Ø¬ÙŠØ¯ ÙˆÙˆØ§Ø¶Ø­ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ØªØ¯Ù‰ Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙƒØ±Ø§Ø± Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø­Ù„ Ù…Ø´ÙƒÙ„ØªÙƒ!\n+<Youtube id=\"_PAli-V4wj0\"/>\n+\n+2. Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ [Ù…Ø´ÙƒÙ„Ø©](https://github.com/huggingface/transformers/issues/new/choose) ÙÙŠ Ù…Ø³ØªÙˆØ¯Ø¹ ğŸ¤— Transformers Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ù…Ø´ÙƒÙ„Ø© Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„Ù…ÙƒØªØ¨Ø©. Ø­Ø§ÙˆÙ„ ØªØ¶Ù…ÙŠÙ† Ø£ÙƒØ¨Ø± Ù‚Ø¯Ø± Ù…Ù…ÙƒÙ† Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙŠ ØªØµÙ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙ†Ø§ ÙÙŠ Ù…Ø¹Ø±ÙØ© Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø®Ø·Ø£ ÙˆÙƒÙŠÙÙŠØ© Ø¥ØµÙ„Ø§Ø­Ù‡.\n+\n+3. ØªØ­Ù‚Ù‚ Ù…Ù† Ø¯Ù„ÙŠÙ„ [Ø§Ù„ØªØ±Ø­ÙŠÙ„](migration) Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… Ø¥ØµØ¯Ø§Ø±Ù‹Ø§ Ø£Ù‚Ø¯Ù… Ù…Ù† Ù…ÙƒØªØ¨Ø© ğŸ¤— Transformers Ø­ÙŠØ« ØªÙ… Ø¥Ø¯Ø®Ø§Ù„ Ø¨Ø¹Ø¶ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨ÙŠÙ† Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª.\n+\n+\n+Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ¥ØµÙ„Ø§Ø­Ù‡Ø§ ÙˆØ§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©ØŒ Ø±Ø§Ø¬Ø¹ [Ø§Ù„ÙØµÙ„ 8](https://huggingface.co/course/chapter8/1?fw=pt) Ù…Ù† Ø¯ÙˆØ±Ø© Hugging Face.\n+\n+## Ø¨ÙŠØ¦Ø§Øª Ø¬Ø¯Ø§Ø± Ø§Ù„Ø­Ù…Ø§ÙŠØ©\n+\n+Ø¨Ø¹Ø¶ ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU) Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø­Ø§Ø¨Ø© ÙˆØ¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ù…Ø­Ù…ÙŠØ© Ø¨Ø¬Ø¯Ø§Ø± Ø­Ù…Ø§ÙŠØ© Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©ØŒ Ù…Ù…Ø§ ÙŠØ¤Ø¯ÙŠ Ø¥Ù„Ù‰ Ø­Ø¯ÙˆØ« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„. Ø¹Ù†Ø¯Ù…Ø§ ØªØ­Ø§ÙˆÙ„ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ù†ØµÙŠ ØªÙ†Ø²ÙŠÙ„ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ùˆ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø³ÙŠØªÙˆÙ‚Ù Ø§Ù„ØªÙ†Ø²ÙŠÙ„ Ø«Ù… ÙŠÙ†ØªÙ‡ÙŠ Ø¨Ø®Ø·Ø£ Ù…Ø«Ù„:\n+\n+```\n+ValueError: Connection error, and we cannot find the requested files in the cached path.\n+Please try again or make sure your Internet connection is on.\n+```\n+\n+ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø©ØŒ ÙŠØ¬Ø¨ Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ´ØºÙŠÙ„ ğŸ¤— Transformers ÙÙŠ [ÙˆØ¶Ø¹ Ø¹Ø¯Ù… Ø§Ù„Ø§ØªØµØ§Ù„](installation#offline-mode) Ù„ØªØ¬Ù†Ø¨ Ø®Ø·Ø£ Ø§Ù„Ø§ØªØµØ§Ù„.\n+\n+## CUDA Ù†ÙØ§Ø¯ Ø§Ù„Ø°Ø§ÙƒØ±Ø©\n+\n+ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ù„Ø§ÙŠÙŠÙ† Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø£Ù…Ø±Ù‹Ø§ ØµØ¹Ø¨Ù‹Ø§ Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©. Ø£Ø­Ø¯ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ø§Ù„ØªÙŠ Ù‚Ø¯ ØªÙˆØ§Ø¬Ù‡Ù‡Ø§ Ø¹Ù†Ø¯ Ù†ÙØ§Ø¯ Ø°Ø§ÙƒØ±Ø© GPU Ù‡Ùˆ:\n+\n+```\n+CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 11.17 GiB total capacity; 9.70 GiB already allocated; 179.81 MiB free; 9.85 GiB reserved in total by PyTorch)\n+```\n+\n+ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¬Ø±Ø¨ØªÙ‡Ø§ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©:\n+\n+- Ù‚Ù„Ù„ Ù…Ù† Ù‚ÙŠÙ…Ø© [`per_device_train_batch_size`](main_classes/trainer#transformers.TrainingArguments.per_device_train_batch_size) ÙÙŠ [`TrainingArguments`].\n+\n+- Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… [`gradient_accumulation_steps`](main_classes/trainer#transformers.TrainingArguments.gradient_accumulation_steps) ÙÙŠ [`TrainingArguments`] Ù„Ø²ÙŠØ§Ø¯Ø© Ø­Ø¬Ù… Ø§Ù„Ø¯ÙÙØ¹Ø© Ø¨Ø´ÙƒÙ„ ÙØ¹Ø§Ù„.\n+\n+<Tip>\n+Ø±Ø§Ø¬Ø¹ Ø¯Ù„ÙŠÙ„ [Ø§Ù„Ø£Ø¯Ø§Ø¡](performance) Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ ØªÙ‚Ù†ÙŠØ§Øª ØªÙˆÙÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø©.\n+</Tip>\n+\n+## Ø¹Ø¯Ù… Ø§Ù„Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ TensorFlow Ù…Ø­ÙÙˆØ¸\n+\n+ØªÙ‚ÙˆÙ… Ø·Ø±ÙŠÙ‚Ø© TensorFlow [model.save](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model) Ø¨Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ - Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©ØŒ Ø§Ù„Ø£ÙˆØ²Ø§Ù†ØŒ ØªÙƒÙˆÙŠÙ† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ - ÙÙŠ Ù…Ù„Ù ÙˆØ§Ø­Ø¯. ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ Ø¹Ù†Ø¯ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ØŒ Ù‚Ø¯ ØªÙˆØ§Ø¬Ù‡ Ø®Ø·Ø£ Ù„Ø£Ù† Ù…ÙƒØªØ¨Ø© ğŸ¤— Transformers Ù‚Ø¯ Ù„Ø§ ØªÙ‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ù€ TensorFlow ÙÙŠ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ù…Ø´ÙƒÙ„Ø§Øª  Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø­ÙØ¸ ÙˆØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ TensorFlowØŒ Ù†ÙˆØµÙŠ Ø¨Ù…Ø§ ÙŠÙ„ÙŠ:\n+\n+- Ø§Ø­ÙØ¸ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙƒÙ…Ù„Ù `h5` Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`model.save_weights`](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model) Ø«Ù… Ø£Ø¹Ø¯ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`~TFPreTrainedModel.from_pretrained`]:\n+\n+```python\n+>>> from transformers import TFPreTrainedModel\n+>>> from tensorflow import keras\n+\n+>>> model.save_weights(\"some_folder/tf_model.h5\")\n+>>> model = TFPreTrainedModel.from_pretrained(\"some_folder\")\n+```\n+\n+- Ø§Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`~TFPretrainedModel.save_pretrained`] ÙˆÙ‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„Ù‡ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`~TFPreTrainedModel.from_pretrained`]:\n+\n+```python\n+>>> from transformers import TFPreTrainedModel\n+\n+>>> model.save_pretrained(\"path_to/model\")\n+>>> model = TFPreTrainedModel.from_pretrained(\"path_to/model\")\n+```\n+\n+## ImportError\n+\n+Ø®Ø·Ø£ Ø´Ø§Ø¦Ø¹ Ø¢Ø®Ø± Ù‚Ø¯ ØªÙˆØ§Ø¬Ù‡Ù‡ØŒ Ø®Ø§ØµØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ ØªÙ… Ø¥ØµØ¯Ø§Ø±Ù‡ Ø­Ø¯ÙŠØ«Ù‹Ø§ØŒ Ù‡Ùˆ `ImportError`:\n+\n+```\n+ImportError: cannot import name 'ImageGPTImageProcessor' from 'transformers' (unknown location)\n+```\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ù‡Ø°Ù‡ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ù„Ø¯ÙŠÙƒ Ø£Ø­Ø¯Ø« Ø¥ØµØ¯Ø§Ø± Ù…Ù† Ù…ÙƒØªØ¨Ø© Hugging Face Transformers Ù…Ø«Ø¨ØªÙ‹Ø§ Ù„Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø£Ø­Ø¯Ø« Ø§Ù„Ù†Ù…Ø§Ø°Ø¬:\n+\n+```bash\n+pip install transformers --upgrade\n+```\n+\n+## Ø®Ø·Ø£ CUDA: ØªÙ… ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ£ÙƒÙŠØ¯ Ø¹Ù„Ù‰ Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø¬Ù‡Ø§Ø²\n+\n+ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø­ÙŠØ§Ù†ØŒ Ù‚Ø¯ ØªÙˆØ§Ø¬Ù‡ Ø®Ø·Ø£ CUDA Ø¹Ø§Ù…Ù‹Ø§ Ø­ÙˆÙ„ Ø®Ø·Ø£ ÙÙŠ ÙƒÙˆØ¯ Ø§Ù„Ø¬Ù‡Ø§Ø².\n+\n+```\n+RuntimeError: CUDA error: device-side assert triggered\n+```\n+\n+ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© (CPU) Ø£ÙˆÙ„Ø§Ù‹ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£ Ø£ÙƒØ«Ø± Ø¯Ù‚Ø©. Ø£Ø¶Ù Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ§Ù„ÙŠ ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© ÙƒÙˆØ¯Ùƒ Ù„Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©:\n+\n+```python\n+>>> import os\n+\n+>>> os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n+```\n+\n+Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø¢Ø®Ø± Ù‡Ùˆ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØªØ¨Ø¹ Ù…ÙƒØ¯Ø³ Ø£ÙØ¶Ù„ Ù…Ù† GPU. Ø£Ø¶Ù Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ§Ù„ÙŠ ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© ÙƒÙˆØ¯Ùƒ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØªØ¨Ø¹ Ø§Ù„Ù…ÙƒØ¯Ø³ Ù„Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ù…ØµØ¯Ø± Ø§Ù„Ø®Ø·Ø£:\n+\n+```python\n+>>> import os\n+\n+>>> os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n+```\n+\n+## Ø¥Ø®Ø±Ø§Ø¬ ØºÙŠØ± ØµØ­ÙŠØ­ Ø¹Ù†Ø¯ Ø¹Ø¯Ù… Ø¥Ø®ÙØ§Ø¡ Ø±Ù…ÙˆØ² Ø§Ù„Ø­Ø´Ùˆ\n+\n+ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø­Ø§Ù„Ø§ØªØŒ Ù‚Ø¯ ÙŠÙƒÙˆÙ† `hidden_state` ØºÙŠØ± ØµØ­ÙŠØ­Ø© Ø¥Ø°Ø§ ØªØ¶Ù…Ù†Øª `input_ids` Ø±Ù…ÙˆØ² Ø­Ø´Ùˆ. ÙˆÙ„Ø¥Ø«Ø¨Ø§Øª Ø°Ù„ÙƒØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ…Ø¬Ø²Ù‰Ø¡ Ù„ØºÙˆÙ‰. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ `pad_token_id` Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù…Ø¹Ø±ÙØ© Ù‚ÙŠÙ…ØªÙ‡. Ù‚Ø¯ ØªÙƒÙˆÙ† `pad_token_id` `None` Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ ÙˆÙ„ÙƒÙ† ÙŠÙ…ÙƒÙ†Ùƒ Ø¯Ø§Ø¦Ù…Ù‹Ø§ ØªØ¹ÙŠÙŠÙ†Ù‡Ø§ ÙŠØ¯ÙˆÙŠÙ‹Ø§.\n+\n+```python\n+>>> from transformers import AutoModelForSequenceClassification\n+>>> import torch\n+\n+>>> model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-uncased\")\n+>>> model.config.pad_token_id\n+0\n+```\n+\n+ÙŠÙˆØ¶Ø­ Ø§Ù„Ù…Ø«Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ø§Ù„Ù…ÙØ®Ø±Ø¬Ø§Øª Ø¨Ø¯ÙˆÙ† Ø¥Ø®ÙØ§Ø¡ Ø±Ù…ÙˆØ² Ø§Ù„Ø­Ø´Ùˆ:\n+\n+```python\n+>>> input_ids = torch.tensor([[7592, 2057, 2097, 2393, 9611, 2115], [7592, 0, 0, 0, 0, 0]])\n+>>> output = model(input_ids)\n+>>> print(output.logits)\n+tensor([[ 0.0082, -0.2307],\n+[ 0.1317, -0.1683]], grad_fn=<AddmmBackward0>)\n+```\n+\n+Ù‡Ù†Ø§ Ø§Ù„Ù…ÙØ®Ø±Ø¬Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ© Ù„Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø«Ø§Ù†ÙŠ:\n+\n+```python\n+>>> input_ids = torch.tensor([[7592]])\n+>>> output = model(input_ids)\n+>>> print(output.logits)\n+tensor([[-0.1008, -0.4061]], grad_fn=<AddmmBackward0>)\n+```\n+\n+ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ ÙÙŠ Ù…Ø¹Ø¸Ù… Ø§Ù„ÙˆÙ‚Øª ØªÙˆÙÙŠØ± `attention_mask` Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØ¬Ø§Ù‡Ù„ Ø±Ù…ÙˆØ² Ø§Ù„Ø­Ø´Ùˆ Ù„ØªØ¬Ù†Ø¨ Ù‡Ø°Ø§ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„ØµØ§Ù…Øª. Ø§Ù„Ø¢Ù† ÙŠØªØ·Ø§Ø¨Ù‚ Ù…ÙØ®Ø±Ø¬Ø§Øª Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø«Ø§Ù†ÙŠ Ù…Ø¹ Ù…ÙØ®Ø±Ø¬Ø§ØªÙ‡ Ø§Ù„ÙØ¹Ù„ÙŠØ©:\n+\n+<Tip>\n+Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠØŒ ÙŠÙ†Ø´Ø¦ Ù…Ø¬Ø²Ù‰Ø¡ Ø§Ù„Ù†ØµÙˆØµ `attention_mask` Ù„Ùƒ Ø§Ø³ØªÙ†Ø§Ø¯Ù‹Ø§ Ø¥Ù„Ù‰ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø¬Ø²Ù‰Ø¡ Ø§Ù„Ù…Ø­Ø¯Ø¯.\n+</Tip>\n+\n+```python\n+>>> attention_mask = torch.tensor([[1, 1, 1, 1, 1, 1], [1, 0, 0, 0, 0, 0]])\n+>>> output = model(input_ids, attention_mask=attention_mask)\n+>>> print(output.logits)\n+tensor([[ 0.0082, -0.2307],\n+[-0.1008, -0.4061]], grad_fn=<AddmmBackward0>)\n+```\n+\n+Ù„Ø§ ÙŠÙ†Ø´Ø¦ ğŸ¤— Transformers ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ `attention_mask` Ù„Ø¥Ø®ÙØ§Ø¡ Ø±Ù…Ø² Ø§Ù„Ø­Ø´Ùˆ Ø¥Ø°Ø§ ØªÙ… ØªÙˆÙÙŠØ±Ù‡ Ù„Ø£Ù†:\n+\n+- Ø¨Ø¹Ø¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„ÙŠØ³ Ù„Ù‡Ø§ Ø±Ù…Ø² Ø­Ø´Ùˆ.\n+\n+- Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§ØªØŒ ÙŠØ±ÙŠØ¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙˆÙ† Ø£Ù† ÙŠÙ†ØªØ¨Ù‡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø±Ù…Ø² Ø§Ù„Ø­Ø´Ùˆ.\n+## ValueError: ÙØ¦Ø© Ø§Ù„ØªÙƒÙˆÙŠÙ† ØºÙŠØ± Ø§Ù„Ù…Ø¹ØªØ±Ù Ø¨Ù‡Ø§ XYZ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹ Ù…Ù† AutoModel\n+\n+Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…ØŒ Ù†ÙˆØµÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙØ¦Ø© [`AutoModel`] Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù…Ø¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù…Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬. ÙŠÙ…ÙƒÙ† Ù„Ù‡Ø°Ù‡ Ø§Ù„ÙØ¦Ø© Ø£Ù† ØªØ³ØªÙ†ØªØ¬ ÙˆØªÙØ­Ù…Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØµØ­ÙŠØ­Ø© Ù…Ù† Ù†Ø³Ø® Ù…Ø¹ÙŠÙ†Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙƒÙˆÙŠÙ†. Ø¥Ø°Ø§ Ø±Ø£ÙŠØª Ù‡Ø°Ø§ Ø§Ù„Ø®Ø·Ø£ `ValueError` Ø¹Ù†Ø¯ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ù†Ø³Ø®Ø©ØŒ ÙÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„ÙØ¦Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ© (Auto) Ù„Ù… ØªØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø®Ø±ÙŠØ·Ø© Ù…Ù† Ø§Ù„ØªÙƒÙˆÙŠÙ† ÙÙŠ Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙØªÙŠØ´ Ø§Ù„Ù…Ø¹Ø·Ø§Ø© Ø¥Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙŠ ØªÙØ­Ø§ÙˆÙ„ ØªØ­Ù…ÙŠÙ„Ù‡. ÙˆØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ÙŠØ­Ø¯Ø« Ù‡Ø°Ø§ Ø¹Ù†Ø¯Ù…Ø§ Ù„Ø§ ØªØ¯Ø¹Ù… Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙØªÙŠØ´ Ù…Ù‡Ù…Ø© Ù…Ø¹ÙŠÙ†Ø©.\n+\n+Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø³ØªØ±Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø«Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ø£Ù†Ù‡ Ù„Ø§ ÙŠÙˆØ¬Ø¯ GPT2 Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©:\n+\n+```py\n+>>> from transformers import AutoProcessor, AutoModelForQuestionAnswering\n+\n+>>> processor = AutoProcessor.from_pretrained(\"openai-community/gpt2-medium\")\n+>>> model = AutoModelForQuestionAnswering.from_pretrained(\"openai-community/gpt2-medium\")\n+ValueError: Unrecognized configuration class <class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'> for this kind of AutoModel: AutoModelForQuestionAnswering.\n+Model type should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BloomConfig, ...\n+```"
        }
    ],
    "stats": {
        "total": 333,
        "additions": 329,
        "deletions": 4
    }
}