{
    "author": "vasqu",
    "message": "[`Auto`] Make processor subclasses overridable on load time (#42912)\n\nfix",
    "sha": "79432f7a4c1a4dd39ebdc3622dfe2dd45eac2589",
    "files": [
        {
            "sha": "ffac1fa7e88fa9500ddeeca3f936c65a4654eb4a",
            "filename": "src/transformers/models/auto/feature_extraction_auto.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/79432f7a4c1a4dd39ebdc3622dfe2dd45eac2589/src%2Ftransformers%2Fmodels%2Fauto%2Ffeature_extraction_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/79432f7a4c1a4dd39ebdc3622dfe2dd45eac2589/src%2Ftransformers%2Fmodels%2Fauto%2Ffeature_extraction_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Ffeature_extraction_auto.py?ref=79432f7a4c1a4dd39ebdc3622dfe2dd45eac2589",
            "patch": "@@ -348,13 +348,13 @@ def from_pretrained(cls, pretrained_model_name_or_path, **kwargs):\n             )\n             _ = kwargs.pop(\"code_revision\", None)\n             feature_extractor_class.register_for_auto_class()\n-            return feature_extractor_class.from_dict(config_dict, **kwargs)\n+            return feature_extractor_class.from_pretrained(pretrained_model_name_or_path, **kwargs)\n         elif feature_extractor_class is not None:\n-            return feature_extractor_class.from_dict(config_dict, **kwargs)\n+            return feature_extractor_class.from_pretrained(pretrained_model_name_or_path, **kwargs)\n         # Last try: we use the FEATURE_EXTRACTOR_MAPPING.\n         elif type(config) in FEATURE_EXTRACTOR_MAPPING:\n             feature_extractor_class = FEATURE_EXTRACTOR_MAPPING[type(config)]\n-            return feature_extractor_class.from_dict(config_dict, **kwargs)\n+            return feature_extractor_class.from_pretrained(pretrained_model_name_or_path, **kwargs)\n \n         raise ValueError(\n             f\"Unrecognized feature extractor in {pretrained_model_name_or_path}. Should have a \""
        },
        {
            "sha": "9733b7bc9e34944e8fe468eaa074c762c904c745",
            "filename": "src/transformers/models/auto/image_processing_auto.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/79432f7a4c1a4dd39ebdc3622dfe2dd45eac2589/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/79432f7a4c1a4dd39ebdc3622dfe2dd45eac2589/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py?ref=79432f7a4c1a4dd39ebdc3622dfe2dd45eac2589",
            "patch": "@@ -605,9 +605,9 @@ def from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs):\n             image_processor_class = get_class_from_dynamic_module(class_ref, pretrained_model_name_or_path, **kwargs)\n             _ = kwargs.pop(\"code_revision\", None)\n             image_processor_class.register_for_auto_class()\n-            return image_processor_class.from_dict(config_dict, **kwargs)\n+            return image_processor_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n         elif image_processor_class is not None:\n-            return image_processor_class.from_dict(config_dict, **kwargs)\n+            return image_processor_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n         # Last try: we use the IMAGE_PROCESSOR_MAPPING.\n         elif type(config) in IMAGE_PROCESSOR_MAPPING:\n             image_processor_tuple = IMAGE_PROCESSOR_MAPPING[type(config)]"
        },
        {
            "sha": "06656715d5e6b04bdfbd1c1dcfda6000356619c9",
            "filename": "src/transformers/models/auto/video_processing_auto.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/79432f7a4c1a4dd39ebdc3622dfe2dd45eac2589/src%2Ftransformers%2Fmodels%2Fauto%2Fvideo_processing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/79432f7a4c1a4dd39ebdc3622dfe2dd45eac2589/src%2Ftransformers%2Fmodels%2Fauto%2Fvideo_processing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fvideo_processing_auto.py?ref=79432f7a4c1a4dd39ebdc3622dfe2dd45eac2589",
            "patch": "@@ -375,9 +375,9 @@ def from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs):\n             video_processor_class = get_class_from_dynamic_module(class_ref, pretrained_model_name_or_path, **kwargs)\n             _ = kwargs.pop(\"code_revision\", None)\n             video_processor_class.register_for_auto_class()\n-            return video_processor_class.from_dict(config_dict, **kwargs)\n+            return video_processor_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n         elif video_processor_class is not None:\n-            return video_processor_class.from_dict(config_dict, **kwargs)\n+            return video_processor_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n         # Last try: we use the VIDEO_PROCESSOR_MAPPING.\n         elif type(config) in VIDEO_PROCESSOR_MAPPING:\n             video_processor_class = VIDEO_PROCESSOR_MAPPING[type(config)]"
        }
    ],
    "stats": {
        "total": 14,
        "additions": 7,
        "deletions": 7
    }
}