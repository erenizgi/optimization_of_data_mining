{
    "author": "yonigozlan",
    "message": "Remove hardcoded slow image processor class in processors supporting fast ones (#36266)\n\n* Add fast image processor class to processors supporting them\n\n* fix test kosmos2",
    "sha": "bc3253f07678538188185f179cf332be702ce6d5",
    "files": [
        {
            "sha": "1198cf2afd24bc14c4f055f4f0259e6c988610de",
            "filename": "src/transformers/models/altclip/processing_altclip.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Faltclip%2Fprocessing_altclip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Faltclip%2Fprocessing_altclip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faltclip%2Fprocessing_altclip.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -44,7 +44,7 @@ class AltCLIPProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    image_processor_class = \"CLIPImageProcessor\"\n+    image_processor_class = (\"CLIPImageProcessor\", \"CLIPImageProcessorFast\")\n     tokenizer_class = (\"XLMRobertaTokenizer\", \"XLMRobertaTokenizerFast\")\n \n     @deprecate_kwarg(old_name=\"feature_extractor\", version=\"5.0.0\", new_name=\"image_processor\")"
        },
        {
            "sha": "336d3bf116241619a95a82720d628bd7593dc584",
            "filename": "src/transformers/models/auto/image_processing_auto.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -490,15 +490,15 @@ def from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs):\n                 image_processor_auto_map = config.auto_map[\"AutoImageProcessor\"]\n \n         image_processor_class = None\n-        # TODO: @yoni, change logic in v4.48 (when use_fast set to True by default)\n+        # TODO: @yoni, change logic in v4.50 (when use_fast set to True by default)\n         if image_processor_type is not None:\n             # if use_fast is not set and the processor was saved with a fast processor, we use it, otherwise we use the slow processor.\n             if use_fast is None:\n                 use_fast = image_processor_type.endswith(\"Fast\")\n                 if not use_fast:\n                     logger.warning_once(\n                         \"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. \"\n-                        \"`use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. \"\n+                        \"`use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. \"\n                         \"This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\"\n                     )\n             # Update class name to reflect the use_fast option. If class is not found, we fall back to the slow version."
        },
        {
            "sha": "c65ff6b66fdcbc1c04a5c8f89b358da93d56ae2b",
            "filename": "src/transformers/models/blip/processing_blip.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fblip%2Fprocessing_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fblip%2Fprocessing_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fprocessing_blip.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -56,7 +56,7 @@ class BlipProcessor(ProcessorMixin):\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n     valid_kwargs = []\n-    image_processor_class = \"BlipImageProcessor\"\n+    image_processor_class = (\"BlipImageProcessor\", \"BlipImageProcessorFast\")\n     tokenizer_class = (\"BertTokenizer\", \"BertTokenizerFast\")\n \n     def __init__(self, image_processor, tokenizer, **kwargs):"
        },
        {
            "sha": "36b663dccb7651aba9320948e2594638cff5bb5e",
            "filename": "src/transformers/models/blip_2/processing_blip_2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fblip_2%2Fprocessing_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fblip_2%2Fprocessing_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip_2%2Fprocessing_blip_2.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -68,7 +68,7 @@ class Blip2Processor(ProcessorMixin):\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n     valid_kwargs = [\"num_query_tokens\"]\n-    image_processor_class = \"BlipImageProcessor\"\n+    image_processor_class = (\"BlipImageProcessor\", \"BlipImageProcessorFast\")\n     tokenizer_class = \"AutoTokenizer\"\n \n     def __init__(self, image_processor, tokenizer, num_query_tokens=None, **kwargs):"
        },
        {
            "sha": "0218d2af6ae45e1df5e22b522eea0aa05db83378",
            "filename": "src/transformers/models/clip/processing_clip.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fclip%2Fprocessing_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fclip%2Fprocessing_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclip%2Fprocessing_clip.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -37,7 +37,7 @@ class CLIPProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    image_processor_class = \"CLIPImageProcessor\"\n+    image_processor_class = (\"CLIPImageProcessor\", \"CLIPImageProcessorFast\")\n     tokenizer_class = (\"CLIPTokenizer\", \"CLIPTokenizerFast\")\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):"
        },
        {
            "sha": "fd7fe7c094c69d9d4150626ad14798007fcf48d6",
            "filename": "src/transformers/models/clipseg/processing_clipseg.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fclipseg%2Fprocessing_clipseg.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fclipseg%2Fprocessing_clipseg.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclipseg%2Fprocessing_clipseg.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -37,7 +37,7 @@ class CLIPSegProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    image_processor_class = \"ViTImageProcessor\"\n+    image_processor_class = (\"ViTImageProcessor\", \"ViTImageProcessorFast\")\n     tokenizer_class = (\"CLIPTokenizer\", \"CLIPTokenizerFast\")\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):"
        },
        {
            "sha": "be3ec4e035c01dc9dbf79144251db033d98a9c31",
            "filename": "src/transformers/models/colpali/processing_colpali.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fcolpali%2Fprocessing_colpali.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fcolpali%2Fprocessing_colpali.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcolpali%2Fprocessing_colpali.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -91,7 +91,7 @@ class ColPaliProcessor(ProcessorMixin):\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n     valid_kwargs = [\"chat_template\"]\n-    image_processor_class = \"SiglipImageProcessor\"\n+    image_processor_class = (\"SiglipImageProcessor\", \"SiglipImageProcessorFast\")\n     tokenizer_class = (\"GemmaTokenizer\", \"GemmaTokenizerFast\")\n \n     visual_prompt_prefix: ClassVar[str] = \"Describe the image.\""
        },
        {
            "sha": "408dfbd07565d0db8c3776bf100d231d2df997db",
            "filename": "src/transformers/models/instructblip/processing_instructblip.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Finstructblip%2Fprocessing_instructblip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Finstructblip%2Fprocessing_instructblip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finstructblip%2Fprocessing_instructblip.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -73,7 +73,7 @@ class InstructBlipProcessor(ProcessorMixin):\n \n     attributes = [\"image_processor\", \"tokenizer\", \"qformer_tokenizer\"]\n     valid_kwargs = [\"num_query_tokens\"]\n-    image_processor_class = \"BlipImageProcessor\"\n+    image_processor_class = (\"BlipImageProcessor\", \"BlipImageProcessorFast\")\n     tokenizer_class = \"AutoTokenizer\"\n     qformer_tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "73a3f66f9b5dbbe015b62f8fdce46e50e45b7358",
            "filename": "src/transformers/models/kosmos2/processing_kosmos2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fprocessing_kosmos2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fprocessing_kosmos2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fprocessing_kosmos2.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -85,7 +85,7 @@ class Kosmos2Processor(ProcessorMixin):\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n     valid_kwargs = [\"num_patch_index_tokens\"]\n-    image_processor_class = \"CLIPImageProcessor\"\n+    image_processor_class = (\"CLIPImageProcessor\", \"CLIPImageProcessorFast\")\n     tokenizer_class = \"AutoTokenizer\"\n \n     def __init__(self, image_processor, tokenizer, num_patch_index_tokens=1024, *kwargs):"
        },
        {
            "sha": "c6a0f94c06f2fbaecbcd7375b7ab775c378304b9",
            "filename": "src/transformers/models/llava_next_video/processing_llava_next_video.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fprocessing_llava_next_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fprocessing_llava_next_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fprocessing_llava_next_video.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -85,7 +85,7 @@ class LlavaNextVideoProcessor(ProcessorMixin):\n         \"video_token\",\n         \"num_additional_image_tokens\",\n     ]\n-    image_processor_class = \"LlavaNextImageProcessor\"\n+    image_processor_class = (\"LlavaNextImageProcessor\", \"LlavaNextImageProcessorFast\")\n     video_processor_class = \"LlavaNextVideoImageProcessor\"\n     tokenizer_class = (\"LlamaTokenizer\", \"LlamaTokenizerFast\")\n "
        },
        {
            "sha": "66ea06fc18457a47358552a6e1df0e407371e0a9",
            "filename": "src/transformers/models/mgp_str/processing_mgp_str.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fmgp_str%2Fprocessing_mgp_str.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fmgp_str%2Fprocessing_mgp_str.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmgp_str%2Fprocessing_mgp_str.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -51,7 +51,7 @@ class MgpstrProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"char_tokenizer\"]\n-    image_processor_class = \"ViTImageProcessor\"\n+    image_processor_class = (\"ViTImageProcessor\", \"ViTImageProcessorFast\")\n     char_tokenizer_class = \"MgpstrTokenizer\"\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):"
        },
        {
            "sha": "6d59202e5748f97df4a69d635e1573045fbf35dd",
            "filename": "src/transformers/models/omdet_turbo/processing_omdet_turbo.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fomdet_turbo%2Fprocessing_omdet_turbo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fomdet_turbo%2Fprocessing_omdet_turbo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fomdet_turbo%2Fprocessing_omdet_turbo.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -216,7 +216,7 @@ class OmDetTurboProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    image_processor_class = \"DetrImageProcessor\"\n+    image_processor_class = (\"DetrImageProcessor\", \"DetrImageProcessorFast\")\n     tokenizer_class = \"AutoTokenizer\"\n \n     def __init__(self, image_processor, tokenizer):"
        },
        {
            "sha": "91deeb3f4f005b006a72469418ffd44d00ad9396",
            "filename": "src/transformers/models/paligemma/processing_paligemma.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fprocessing_paligemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fprocessing_paligemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fprocessing_paligemma.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -117,7 +117,7 @@ class PaliGemmaProcessor(ProcessorMixin):\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n     valid_kwargs = [\"chat_template\"]\n-    image_processor_class = \"SiglipImageProcessor\"\n+    image_processor_class = (\"SiglipImageProcessor\", \"SiglipImageProcessorFast\")\n     tokenizer_class = (\"GemmaTokenizer\", \"GemmaTokenizerFast\")\n \n     def __init__("
        },
        {
            "sha": "21597cb3c62d5ec6eb18c612e2f95454b94dc7b2",
            "filename": "src/transformers/models/siglip/processing_siglip.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fsiglip%2Fprocessing_siglip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fmodels%2Fsiglip%2Fprocessing_siglip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsiglip%2Fprocessing_siglip.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -40,7 +40,7 @@ class SiglipProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    image_processor_class = \"SiglipImageProcessor\"\n+    image_processor_class = (\"SiglipImageProcessor\", \"SiglipImageProcessorFast\")\n     tokenizer_class = \"AutoTokenizer\"\n \n     def __init__(self, image_processor, tokenizer):"
        },
        {
            "sha": "e709878f1c2a75e321d9c6cc730648980845396b",
            "filename": "src/transformers/processing_utils.py",
            "status": "modified",
            "additions": 11,
            "deletions": 1,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fprocessing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/src%2Ftransformers%2Fprocessing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fprocessing_utils.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -1105,7 +1105,17 @@ def _get_arguments_from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\n             class_name = getattr(cls, f\"{attribute_name}_class\")\n             if isinstance(class_name, tuple):\n                 classes = tuple(getattr(transformers_module, n) if n is not None else None for n in class_name)\n-                use_fast = kwargs.get(\"use_fast\", True)\n+                if attribute_name == \"image_processor\":\n+                    # TODO: @yoni, change logic in v4.50 (when use_fast set to True by default)\n+                    use_fast = kwargs.get(\"use_fast\", None)\n+                    if use_fast is None:\n+                        logger.warning_once(\n+                            \"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. \"\n+                            \"`use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. \"\n+                            \"This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\"\n+                        )\n+                else:\n+                    use_fast = kwargs.get(\"use_fast\", True)\n                 if use_fast and classes[1] is not None:\n                     attribute_class = classes[1]\n                 else:"
        },
        {
            "sha": "0a34c39681889438e9a279f15a04488d45ed687d",
            "filename": "tests/models/kosmos2/test_processor_kosmos2.py",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc3253f07678538188185f179cf332be702ce6d5/tests%2Fmodels%2Fkosmos2%2Ftest_processor_kosmos2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc3253f07678538188185f179cf332be702ce6d5/tests%2Fmodels%2Fkosmos2%2Ftest_processor_kosmos2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fkosmos2%2Ftest_processor_kosmos2.py?ref=bc3253f07678538188185f179cf332be702ce6d5",
            "patch": "@@ -70,12 +70,15 @@ def setUp(self):\n         processor = Kosmos2Processor(image_processor, fast_tokenizer)\n         processor.save_pretrained(self.tmpdirname)\n \n-    # We override this method to take the fast tokenizer or image processor by default\n+    # We override this method to take the fast tokenizer by default\n     def get_component(self, attribute, **kwargs):\n         assert attribute in self.processor_class.attributes\n         component_class_name = getattr(self.processor_class, f\"{attribute}_class\")\n         if isinstance(component_class_name, tuple):\n-            component_class_name = component_class_name[-1]\n+            if attribute == \"image_processor\":\n+                component_class_name = component_class_name[0]\n+            else:\n+                component_class_name = component_class_name[-1]\n \n         component_class = processor_class_from_name(component_class_name)\n         component = component_class.from_pretrained(self.tmpdirname, **kwargs)  # noqa"
        }
    ],
    "stats": {
        "total": 49,
        "additions": 31,
        "deletions": 18
    }
}