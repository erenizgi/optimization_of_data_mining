{
    "author": "molbap",
    "message": "Double router compute? (#41653)\n\n* weird double router compute?\n\n* flip it",
    "sha": "9176af574a993ea308210cdbe1bb9e161da39088",
    "files": [
        {
            "sha": "bb3057e6c5b326d697ba1f7a3abe3d9d82616e4f",
            "filename": "src/transformers/models/deepseek_v2/modeling_deepseek_v2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/9176af574a993ea308210cdbe1bb9e161da39088/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9176af574a993ea308210cdbe1bb9e161da39088/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py?ref=9176af574a993ea308210cdbe1bb9e161da39088",
            "patch": "@@ -117,7 +117,6 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n         residuals = hidden_states\n         orig_shape = hidden_states.shape\n         router_logits = nn.functional.linear(hidden_states.type(torch.float32), self.gate.weight.type(torch.float32))\n-        router_logits = self.gate(hidden_states)\n         topk_indices, topk_weights = self.route_tokens_to_experts(router_logits)\n         hidden_states = hidden_states.view(-1, hidden_states.shape[-1])\n         hidden_states = self.experts(hidden_states, topk_indices, topk_weights).view(*orig_shape)"
        },
        {
            "sha": "31b3401d01230df8f49a04b2ce794be9e4f9a1fa",
            "filename": "src/transformers/models/deepseek_v2/modular_deepseek_v2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/9176af574a993ea308210cdbe1bb9e161da39088/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodular_deepseek_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9176af574a993ea308210cdbe1bb9e161da39088/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodular_deepseek_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodular_deepseek_v2.py?ref=9176af574a993ea308210cdbe1bb9e161da39088",
            "patch": "@@ -275,7 +275,6 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n         residuals = hidden_states\n         orig_shape = hidden_states.shape\n         router_logits = nn.functional.linear(hidden_states.type(torch.float32), self.gate.weight.type(torch.float32))\n-        router_logits = self.gate(hidden_states)\n         topk_indices, topk_weights = self.route_tokens_to_experts(router_logits)\n         hidden_states = hidden_states.view(-1, hidden_states.shape[-1])\n         hidden_states = self.experts(hidden_states, topk_indices, topk_weights).view(*orig_shape)"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 0,
        "deletions": 2
    }
}