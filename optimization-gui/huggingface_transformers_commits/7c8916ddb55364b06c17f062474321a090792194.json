{
    "author": "jiqing-feng",
    "message": "fix audio classification pipeline fp16 test on cuda (#36359)\n\n* fix audio classification pipeline fp16 test on cuda\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\n\n* fix format\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\n\n* add comments\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\n\n* Update tests/pipelines/test_pipelines_audio_classification.py\n\n---------\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\nCo-authored-by: Yih-Dar <2521628+ydshieh@users.noreply.github.com>",
    "sha": "7c8916ddb55364b06c17f062474321a090792194",
    "files": [
        {
            "sha": "db2d3b3b59ed684ac7b4b35c63c90d30d7896e51",
            "filename": "tests/pipelines/test_pipelines_audio_classification.py",
            "status": "modified",
            "additions": 9,
            "deletions": 6,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/7c8916ddb55364b06c17f062474321a090792194/tests%2Fpipelines%2Ftest_pipelines_audio_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7c8916ddb55364b06c17f062474321a090792194/tests%2Fpipelines%2Ftest_pipelines_audio_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_audio_classification.py?ref=7c8916ddb55364b06c17f062474321a090792194",
            "patch": "@@ -144,18 +144,21 @@ def test_small_model_pt_fp16(self):\n         audio = np.ones((8000,))\n         output = audio_classifier(audio, top_k=4)\n \n+        # Expected outputs are collected running the test on torch 2.6 in few scenarios.\n+        # Running on CUDA T4/A100 and on XPU PVC (note: using stock torch xpu, NOT using IPEX):\n         EXPECTED_OUTPUT = [\n+            {\"score\": 0.0833, \"label\": \"go\"},\n+            {\"score\": 0.0833, \"label\": \"off\"},\n+            {\"score\": 0.0833, \"label\": \"stop\"},\n+            {\"score\": 0.0833, \"label\": \"on\"},\n+        ]\n+        # Running on CPU:\n+        EXPECTED_OUTPUT_PT_2 = [\n             {\"score\": 0.0839, \"label\": \"no\"},\n             {\"score\": 0.0837, \"label\": \"go\"},\n             {\"score\": 0.0836, \"label\": \"yes\"},\n             {\"score\": 0.0835, \"label\": \"right\"},\n         ]\n-        EXPECTED_OUTPUT_PT_2 = [\n-            {\"score\": 0.0845, \"label\": \"stop\"},\n-            {\"score\": 0.0844, \"label\": \"on\"},\n-            {\"score\": 0.0841, \"label\": \"right\"},\n-            {\"score\": 0.0834, \"label\": \"left\"},\n-        ]\n         self.assertIn(nested_simplify(output, decimals=4), [EXPECTED_OUTPUT, EXPECTED_OUTPUT_PT_2])\n \n         audio_dict = {\"array\": np.ones((8000,)), \"sampling_rate\": audio_classifier.feature_extractor.sampling_rate}"
        }
    ],
    "stats": {
        "total": 15,
        "additions": 9,
        "deletions": 6
    }
}