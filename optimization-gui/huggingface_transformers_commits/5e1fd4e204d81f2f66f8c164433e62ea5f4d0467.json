{
    "author": "BenjaminBossan",
    "message": "FIX: Broken repr of TorchAoConfig (#34560)\n\nFIX Broken repr of TorchAoConfig\r\n\r\nThe __repr__ method references a non-existent self.kwargs. This is now\r\nfixed.\r\n\r\nThere does not appear to be a uniform way of defining __repr__ for\r\nquantization configs. I copied the method as implemented for HQQ:\r\n\r\nhttps://github.com/huggingface/transformers/blob/e2ac16b28a0b8b900e136750309ca40c49d975c5/src/transformers/utils/quantization_config.py#L285-L287",
    "sha": "5e1fd4e204d81f2f66f8c164433e62ea5f4d0467",
    "files": [
        {
            "sha": "2f04df97e863a505775601c53b5f8f34fff97d62",
            "filename": "src/transformers/utils/quantization_config.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/5e1fd4e204d81f2f66f8c164433e62ea5f4d0467/src%2Ftransformers%2Futils%2Fquantization_config.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5e1fd4e204d81f2f66f8c164433e62ea5f4d0467/src%2Ftransformers%2Futils%2Fquantization_config.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fquantization_config.py?ref=5e1fd4e204d81f2f66f8c164433e62ea5f4d0467",
            "patch": "@@ -1309,7 +1309,8 @@ def get_apply_tensor_subclass(self):\n         return _STR_TO_METHOD[self.quant_type](**self.quant_type_kwargs)\n \n     def __repr__(self):\n-        return f\"{self.quant_type}({', '.join(str(k) + '=' + str(v) for k, v in self.kwargs.items())})\"\n+        config_dict = self.to_dict()\n+        return f\"{self.__class__.__name__} {json.dumps(config_dict, indent=2, sort_keys=True)}\\n\"\n \n \n @dataclass"
        },
        {
            "sha": "c3ab06ee61ba59a06d11635f330ecae43fd221b8",
            "filename": "tests/quantization/torchao_integration/test_torchao.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/5e1fd4e204d81f2f66f8c164433e62ea5f4d0467/tests%2Fquantization%2Ftorchao_integration%2Ftest_torchao.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5e1fd4e204d81f2f66f8c164433e62ea5f4d0467/tests%2Fquantization%2Ftorchao_integration%2Ftest_torchao.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fquantization%2Ftorchao_integration%2Ftest_torchao.py?ref=5e1fd4e204d81f2f66f8c164433e62ea5f4d0467",
            "patch": "@@ -74,6 +74,13 @@ def test_post_init_check(self):\n         with self.assertRaisesRegex(ValueError, \"Unexpected keyword arg\"):\n             _ = TorchAoConfig(\"int4_weight_only\", group_size1=32)\n \n+    def test_repr(self):\n+        \"\"\"\n+        Check that there is no error in the repr\n+        \"\"\"\n+        quantization_config = TorchAoConfig(\"int4_weight_only\", modules_to_not_convert=[\"conv\"], group_size=8)\n+        repr(quantization_config)\n+\n \n @require_torch_gpu\n @require_torchao"
        }
    ],
    "stats": {
        "total": 10,
        "additions": 9,
        "deletions": 1
    }
}