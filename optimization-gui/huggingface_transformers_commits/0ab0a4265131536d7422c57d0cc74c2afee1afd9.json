{
    "author": "simonJJJ",
    "message": "fix-qwen2vl-no-position_ids (#33487)",
    "sha": "0ab0a4265131536d7422c57d0cc74c2afee1afd9",
    "files": [
        {
            "sha": "17e722a217dfd6f2ffe767a8b79c88cd53419b6b",
            "filename": "src/transformers/models/qwen2_vl/modeling_qwen2_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/0ab0a4265131536d7422c57d0cc74c2afee1afd9/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0ab0a4265131536d7422c57d0cc74c2afee1afd9/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py?ref=0ab0a4265131536d7422c57d0cc74c2afee1afd9",
            "patch": "@@ -1719,6 +1719,9 @@ def forward(\n             if attention_mask is not None:\n                 attention_mask = attention_mask.to(inputs_embeds.device)\n \n+        if position_ids is None and input_ids is not None:\n+            position_ids, _ = self.get_rope_index(input_ids, image_grid_thw, video_grid_thw, attention_mask)\n+\n         outputs = self.model(\n             input_ids=None,\n             position_ids=position_ids,"
        }
    ],
    "stats": {
        "total": 3,
        "additions": 3,
        "deletions": 0
    }
}