{
    "author": "ebezzam",
    "message": "Convenient default behavior for pipeline TTS usage. (#42473)",
    "sha": "26dbe643d1599e9550e279498ea0a23753953723",
    "files": [
        {
            "sha": "9331d3365a3e68be0b5d85f2ddaf280047ba5ecb",
            "filename": "src/transformers/pipelines/text_to_audio.py",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/26dbe643d1599e9550e279498ea0a23753953723/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/26dbe643d1599e9550e279498ea0a23753953723/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py?ref=26dbe643d1599e9550e279498ea0a23753953723",
            "patch": "@@ -172,6 +172,11 @@ def preprocess(self, text, **kwargs):\n                 **kwargs,\n             )\n         else:\n+            # Add speaker ID if needed and user didn't insert at start of text\n+            if self.model.config.model_type == \"csm\":\n+                text = [f\"[0]{t}\" if not t.startswith(\"[\") else t for t in text]\n+            if self.model.config.model_type == \"dia\":\n+                text = [f\"[S1] {t}\" if not t.startswith(\"[\") else t for t in text]\n             output = preprocessor(text, **kwargs, return_tensors=\"pt\")\n \n         return output\n@@ -196,6 +201,12 @@ def _forward(self, model_inputs, **kwargs):\n             # ensure dict output to facilitate postprocessing\n             forward_params.update({\"return_dict_in_generate\": True})\n \n+            if self.model.config.model_type in [\"csm\"]:\n+                # NOTE (ebezzam): CSM does not have the audio tokenizer in the processor therefore `output_audio=True`\n+                # needed for decoding to audio\n+                if \"output_audio\" not in forward_params:\n+                    forward_params[\"output_audio\"] = True\n+\n             output = self.model.generate(**model_inputs, **forward_params)\n         else:\n             if len(generate_kwargs):"
        },
        {
            "sha": "8f8462b2288a74d2d5d79c772f4d9249adba8038",
            "filename": "tests/pipelines/test_pipelines_text_to_audio.py",
            "status": "modified",
            "additions": 7,
            "deletions": 9,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/26dbe643d1599e9550e279498ea0a23753953723/tests%2Fpipelines%2Ftest_pipelines_text_to_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/26dbe643d1599e9550e279498ea0a23753953723/tests%2Fpipelines%2Ftest_pipelines_text_to_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_text_to_audio.py?ref=26dbe643d1599e9550e279498ea0a23753953723",
            "patch": "@@ -251,26 +251,26 @@ def test_generative_model_kwargs(self):\n     @require_torch\n     def test_csm_model_pt(self):\n         speech_generator = pipeline(task=\"text-to-audio\", model=\"sesame/csm-1b\", device=torch_device)\n-        generate_kwargs = {\"max_new_tokens\": 10, \"output_audio\": True}\n+        generate_kwargs = {\"max_new_tokens\": 10}\n         num_channels = 1  # model generates mono audio\n \n-        outputs = speech_generator(\"[0]This is a test\", generate_kwargs=generate_kwargs)\n+        outputs = speech_generator(\"This is a test\", generate_kwargs=generate_kwargs)\n         self.assertEqual(outputs[\"sampling_rate\"], 24000)\n         audio = outputs[\"audio\"]\n         self.assertEqual(ANY(np.ndarray), audio)\n         # ensure audio and not discrete codes\n         self.assertEqual(len(audio.shape), num_channels)\n \n         # test two examples side-by-side\n-        outputs = speech_generator([\"[0]This is a test\", \"[0]This is a second test\"], generate_kwargs=generate_kwargs)\n+        outputs = speech_generator([\"This is a test\", \"This is a second test\"], generate_kwargs=generate_kwargs)\n         audio = [output[\"audio\"] for output in outputs]\n         self.assertEqual([ANY(np.ndarray), ANY(np.ndarray)], audio)\n         self.assertEqual(len(audio[0].shape), num_channels)\n \n         # test batching\n         batch_size = 2\n         outputs = speech_generator(\n-            [\"[0]This is a test\", \"[0]This is a second test\"], generate_kwargs=generate_kwargs, batch_size=batch_size\n+            [\"This is a test\", \"This is a second test\"], generate_kwargs=generate_kwargs, batch_size=batch_size\n         )\n         self.assertEqual(len(outputs), batch_size)\n         audio = [output[\"audio\"] for output in outputs]\n@@ -284,9 +284,7 @@ def test_dia_model(self):\n         generate_kwargs = {\"max_new_tokens\": 20}\n         num_channels = 1  # model generates mono audio\n \n-        outputs = speech_generator(\n-            \"[S1] Dia is an open weights text to dialogue model.\", generate_kwargs=generate_kwargs\n-        )\n+        outputs = speech_generator(\"Dia is an open weights text to dialogue model.\", generate_kwargs=generate_kwargs)\n         self.assertEqual(outputs[\"sampling_rate\"], 44100)\n         audio = outputs[\"audio\"]\n         self.assertEqual(ANY(np.ndarray), audio)\n@@ -295,7 +293,7 @@ def test_dia_model(self):\n \n         # test two examples side-by-side\n         outputs = speech_generator(\n-            [\"[S1] Dia is an open weights text to dialogue model.\", \"[S2] This is a second example.\"],\n+            [\"Dia is an open weights text to dialogue model.\", \"This is a second example.\"],\n             generate_kwargs=generate_kwargs,\n         )\n         audio = [output[\"audio\"] for output in outputs]\n@@ -305,7 +303,7 @@ def test_dia_model(self):\n         # test batching\n         batch_size = 2\n         outputs = speech_generator(\n-            [\"[S1] Dia is an open weights text to dialogue model.\", \"[S2] This is a second example.\"],\n+            [\"Dia is an open weights text to dialogue model.\", \"This is a second example.\"],\n             generate_kwargs=generate_kwargs,\n             batch_size=2,\n         )"
        }
    ],
    "stats": {
        "total": 27,
        "additions": 18,
        "deletions": 9
    }
}