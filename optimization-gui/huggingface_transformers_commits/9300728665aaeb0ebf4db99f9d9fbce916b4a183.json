{
    "author": "Cyrilvallez",
    "message": "Fix peft integration (#38841)\n\nUpdate peft.py",
    "sha": "9300728665aaeb0ebf4db99f9d9fbce916b4a183",
    "files": [
        {
            "sha": "fb927da23d49bc2c333b6bbea44c65ba4eabff1c",
            "filename": "src/transformers/integrations/peft.py",
            "status": "modified",
            "additions": 20,
            "deletions": 1,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/9300728665aaeb0ebf4db99f9d9fbce916b4a183/src%2Ftransformers%2Fintegrations%2Fpeft.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9300728665aaeb0ebf4db99f9d9fbce916b4a183/src%2Ftransformers%2Fintegrations%2Fpeft.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Fpeft.py?ref=9300728665aaeb0ebf4db99f9d9fbce916b4a183",
            "patch": "@@ -28,7 +28,6 @@\n     is_torch_available,\n     logging,\n )\n-from ..modeling_utils import VLMS\n \n \n if is_torch_available():\n@@ -45,6 +44,26 @@\n logger = logging.get_logger(__name__)\n \n \n+# DO NOT MODIFY, KEPT FOR BC ONLY\n+VLMS = [\n+    \"aria\",\n+    \"ayavision\",\n+    \"emu3\",\n+    \"fuyu\",\n+    \"gotocr2\",\n+    \"gemma3\",\n+    \"internvl\",\n+    \"llava\",  # all llava prefixed models fall under this check\n+    \"mistral3\",\n+    \"mllama\",\n+    \"paligemma\",\n+    \"qwen2vl\",\n+    \"qwen2_5_vl\",\n+    \"videollava\",\n+    \"vipllava\",\n+]\n+\n+\n class PeftAdapterMixin:\n     \"\"\"\n     A class containing all functions for loading and using adapters weights that are supported in PEFT library. For"
        }
    ],
    "stats": {
        "total": 21,
        "additions": 20,
        "deletions": 1
    }
}