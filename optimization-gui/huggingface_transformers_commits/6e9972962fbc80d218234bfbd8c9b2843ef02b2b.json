{
    "author": "qgallouedec",
    "message": "ðŸŽ¯ Trackio integration (#38814)\n\n* First attempt\n\n* fix\n\n* fix\n\n* Enhance TrackioCallback to log GPU memory usage and allocation\n\n* Enhance Trackio integration in callbacks and training arguments documentation\n\n* re order\n\n* remove unused lines\n\n* fix torch optional",
    "sha": "6e9972962fbc80d218234bfbd8c9b2843ef02b2b",
    "files": [
        {
            "sha": "0a7c73c667542da390e02ed5ccb3d7f4d7b569fc",
            "filename": "docs/source/en/main_classes/callback.md",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/6e9972962fbc80d218234bfbd8c9b2843ef02b2b/docs%2Fsource%2Fen%2Fmain_classes%2Fcallback.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/6e9972962fbc80d218234bfbd8c9b2843ef02b2b/docs%2Fsource%2Fen%2Fmain_classes%2Fcallback.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmain_classes%2Fcallback.md?ref=6e9972962fbc80d218234bfbd8c9b2843ef02b2b",
            "patch": "@@ -33,6 +33,7 @@ By default, `TrainingArguments.report_to` is set to `\"all\"`, so a [`Trainer`] wi\n   it's the second one).\n - [`~integrations.TensorBoardCallback`] if tensorboard is accessible (either through PyTorch >= 1.4\n   or tensorboardX).\n+- [`~integrations.TrackioCallback`] if [trackio](https://github.com/gradio-app/trackio) is installed.\n - [`~integrations.WandbCallback`] if [wandb](https://www.wandb.com/) is installed.\n - [`~integrations.CometCallback`] if [comet_ml](https://www.comet.com/site/) is installed.\n - [`~integrations.MLflowCallback`] if [mlflow](https://www.mlflow.org/) is installed.\n@@ -72,6 +73,9 @@ Here is the list of the available [`TrainerCallback`] in the library:\n \n [[autodoc]] integrations.TensorBoardCallback\n \n+[[autodoc]] integrations.TrackioCallback\n+    - setup\n+\n [[autodoc]] integrations.WandbCallback\n     - setup\n "
        },
        {
            "sha": "f6f6fd6f6e282b181a1aabd1b7c90668319c263e",
            "filename": "src/transformers/__init__.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/6e9972962fbc80d218234bfbd8c9b2843ef02b2b/src%2Ftransformers%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6e9972962fbc80d218234bfbd8c9b2843ef02b2b/src%2Ftransformers%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2F__init__.py?ref=6e9972962fbc80d218234bfbd8c9b2843ef02b2b",
            "patch": "@@ -127,6 +127,7 @@\n         \"is_sigopt_available\",\n         \"is_swanlab_available\",\n         \"is_tensorboard_available\",\n+        \"is_trackio_available\",\n         \"is_wandb_available\",\n     ],\n     \"loss\": [],\n@@ -759,6 +760,7 @@\n         is_sigopt_available,\n         is_swanlab_available,\n         is_tensorboard_available,\n+        is_trackio_available,\n         is_wandb_available,\n     )\n     from .integrations.executorch import ("
        },
        {
            "sha": "0c4d169380b57308745c07f01e4533980e869d59",
            "filename": "src/transformers/integrations/__init__.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/6e9972962fbc80d218234bfbd8c9b2843ef02b2b/src%2Ftransformers%2Fintegrations%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6e9972962fbc80d218234bfbd8c9b2843ef02b2b/src%2Ftransformers%2Fintegrations%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2F__init__.py?ref=6e9972962fbc80d218234bfbd8c9b2843ef02b2b",
            "patch": "@@ -90,6 +90,7 @@\n         \"NeptuneMissingConfiguration\",\n         \"SwanLabCallback\",\n         \"TensorBoardCallback\",\n+        \"TrackioCallback\",\n         \"WandbCallback\",\n         \"get_available_reporting_integrations\",\n         \"get_reporting_integration_callbacks\",\n@@ -110,6 +111,7 @@\n         \"is_sigopt_available\",\n         \"is_swanlab_available\",\n         \"is_tensorboard_available\",\n+        \"is_trackio_available\",\n         \"is_wandb_available\",\n         \"rewrite_logs\",\n         \"run_hp_search_optuna\",\n@@ -224,6 +226,7 @@\n         NeptuneMissingConfiguration,\n         SwanLabCallback,\n         TensorBoardCallback,\n+        TrackioCallback,\n         WandbCallback,\n         get_available_reporting_integrations,\n         get_reporting_integration_callbacks,\n@@ -244,6 +247,7 @@\n         is_sigopt_available,\n         is_swanlab_available,\n         is_tensorboard_available,\n+        is_trackio_available,\n         is_wandb_available,\n         rewrite_logs,\n         run_hp_search_optuna,"
        },
        {
            "sha": "8a621929c7ebc4c6707862e9541c219230bff302",
            "filename": "src/transformers/integrations/integration_utils.py",
            "status": "modified",
            "additions": 117,
            "deletions": 0,
            "changes": 117,
            "blob_url": "https://github.com/huggingface/transformers/blob/6e9972962fbc80d218234bfbd8c9b2843ef02b2b/src%2Ftransformers%2Fintegrations%2Fintegration_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6e9972962fbc80d218234bfbd8c9b2843ef02b2b/src%2Ftransformers%2Fintegrations%2Fintegration_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Fintegration_utils.py?ref=6e9972962fbc80d218234bfbd8c9b2843ef02b2b",
            "patch": "@@ -56,6 +56,7 @@\n \n if is_torch_available():\n     import torch\n+    import torch.distributed as dist\n \n # comet_ml requires to be imported before any ML frameworks\n _MIN_COMET_VERSION = \"3.43.2\"\n@@ -111,6 +112,10 @@ def is_wandb_available():\n     return importlib.util.find_spec(\"wandb\") is not None\n \n \n+def is_trackio_available():\n+    return importlib.util.find_spec(\"trackio\") is not None\n+\n+\n def is_clearml_available():\n     return importlib.util.find_spec(\"clearml\") is not None\n \n@@ -630,6 +635,8 @@ def get_available_reporting_integrations():\n         integrations.append(\"clearml\")\n     if is_swanlab_available():\n         integrations.append(\"swanlab\")\n+    if is_trackio_available():\n+        integrations.append(\"trackio\")\n     return integrations\n \n \n@@ -1033,6 +1040,115 @@ def on_predict(self, args, state, control, metrics, **kwargs):\n             self._wandb.log(metrics)\n \n \n+class TrackioCallback(TrainerCallback):\n+    \"\"\"\n+    A [`TrainerCallback`] that logs metrics to Trackio.\n+    \"\"\"\n+\n+    def __init__(self):\n+        has_trackio = is_trackio_available()\n+        if not has_trackio:\n+            raise RuntimeError(\"TrackioCallback requires trackio to be installed. Run `pip install trackio`.\")\n+        if has_trackio:\n+            import trackio\n+\n+            self._trackio = trackio\n+        self._initialized = False\n+\n+    def setup(self, args, state, model, **kwargs):\n+        \"\"\"\n+        Setup the optional Trackio integration.\n+\n+        To customize the setup you can also override the following environment variables:\n+\n+        Environment:\n+        - **TRACKIO_PROJECT** (`str`, *optional*, defaults to `\"huggingface\"`):\n+            The name of the project (can be an existing project to continue tracking or a new project to start tracking\n+            from scratch).\n+        - **TRACKIO_SPACE_ID** (`str`, *optional*, defaults to `None`):\n+            If set, the project will be logged to a Hugging Face Space instead of a local directory. Should be a\n+            complete Space name like `\"username/reponame\"` or `\"orgname/reponame\"`, or just `\"reponame\" in which case\n+            the Space will be created in the currently-logged-in Hugging Face user's namespace. If the Space does not\n+            exist, it will be created. If the Space already exists, the project will be logged to it.\n+        \"\"\"\n+        if state.is_world_process_zero:\n+            combined_dict = {**args.to_dict()}\n+\n+            if hasattr(model, \"config\") and model.config is not None:\n+                model_config = model.config if isinstance(model.config, dict) else model.config.to_dict()\n+                combined_dict = {**model_config, **combined_dict}\n+            if hasattr(model, \"peft_config\") and model.peft_config is not None:\n+                peft_config = model.peft_config\n+                combined_dict = {**{\"peft_config\": peft_config}, **combined_dict}\n+\n+            self._trackio.init(\n+                project=os.getenv(\"TRACKIO_PROJECT\", \"huggingface\"),\n+                name=args.run_name,\n+                space_id=os.getenv(\"TRACKIO_SPACE_ID\", None),\n+                resume=\"allow\",\n+            )\n+\n+            # Add config parameters (run may have been created manually)\n+            self._trackio.config.update(combined_dict, allow_val_change=True)\n+\n+            # Add number of model parameters to trackio config\n+            try:\n+                self._trackio.config[\"model/num_parameters\"] = model.num_parameters()\n+            except AttributeError:\n+                logger.info(\"Could not log the number of model parameters in Trackio due to an AttributeError.\")\n+        self._initialized = True\n+\n+    def on_train_begin(self, args, state, control, model=None, **kwargs):\n+        if not self._initialized:\n+            self.setup(args, state, model, **kwargs)\n+\n+    def on_train_end(self, args: TrainingArguments, state, control, model=None, processing_class=None, **kwargs):\n+        if state.is_world_process_zero and self._initialized:\n+            self._trackio.finish()\n+\n+    def on_log(self, args, state, control, model=None, logs=None, **kwargs):\n+        single_value_scalars = [\n+            \"train_runtime\",\n+            \"train_samples_per_second\",\n+            \"train_steps_per_second\",\n+            \"train_loss\",\n+            \"total_flos\",\n+        ]\n+\n+        if is_torch_available() and torch.cuda.is_available() and dist.is_available() and dist.is_initialized():\n+            device_idx = torch.cuda.current_device()\n+            total_memory = torch.cuda.get_device_properties(device_idx).total_memory\n+            memory_allocated = torch.cuda.memory_allocated(device_idx)\n+\n+            gpu_memory_logs = {\n+                f\"gpu/{device_idx}/allocated_memory\": memory_allocated / (1024**3),  # GB\n+                f\"gpu/{device_idx}/memory_usage\": memory_allocated / total_memory,  # ratio\n+            }\n+\n+            gathered_logs = [None] * dist.get_world_size()\n+            dist.all_gather_object(gathered_logs, gpu_memory_logs)\n+            gpu_memory_logs = {k: v for d in gathered_logs for k, v in d.items()}\n+\n+        if not self._initialized:\n+            self.setup(args, state, model)\n+        if state.is_world_process_zero:\n+            non_scalar_logs = {k: v for k, v in logs.items() if k not in single_value_scalars}\n+            non_scalar_logs = rewrite_logs(non_scalar_logs)\n+            self._trackio.log({**non_scalar_logs, **gpu_memory_logs, \"train/global_step\": state.global_step})\n+\n+    def on_save(self, args, state, control, **kwargs):\n+        return\n+\n+    def on_predict(self, args, state, control, metrics, **kwargs):\n+        if self._trackio is None:\n+            return\n+        if not self._initialized:\n+            self.setup(args, state, **kwargs)\n+        if state.is_world_process_zero:\n+            metrics = rewrite_logs(metrics)\n+            self._trackio.log(metrics)\n+\n+\n class CometCallback(TrainerCallback):\n     \"\"\"\n     A [`TrainerCallback`] that sends the logs to [Comet ML](https://www.comet.com/site/).\n@@ -2329,6 +2445,7 @@ def on_predict(self, args, state, control, metrics, **kwargs):\n     \"mlflow\": MLflowCallback,\n     \"neptune\": NeptuneCallback,\n     \"tensorboard\": TensorBoardCallback,\n+    \"trackio\": TrackioCallback,\n     \"wandb\": WandbCallback,\n     \"codecarbon\": CodeCarbonCallback,\n     \"clearml\": ClearMLCallback,"
        },
        {
            "sha": "d6b425cca6a1f6dfcae88858155d75b35784491c",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/6e9972962fbc80d218234bfbd8c9b2843ef02b2b/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6e9972962fbc80d218234bfbd8c9b2843ef02b2b/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=6e9972962fbc80d218234bfbd8c9b2843ef02b2b",
            "patch": "@@ -59,6 +59,7 @@\n     is_sigopt_available,\n     is_swanlab_available,\n     is_tensorboard_available,\n+    is_trackio_available,\n     is_wandb_available,\n )\n from .integrations.deepspeed import is_deepspeed_available\n@@ -1274,6 +1275,16 @@ def require_swanlab(test_case):\n     return unittest.skipUnless(is_swanlab_available(), \"test requires swanlab\")(test_case)\n \n \n+def require_trackio(test_case):\n+    \"\"\"\n+    Decorator marking a test that requires trackio.\n+\n+    These tests are skipped when trackio isn't installed.\n+\n+    \"\"\"\n+    return unittest.skipUnless(is_trackio_available(), \"test requires trackio\")(test_case)\n+\n+\n def require_wandb(test_case):\n     \"\"\"\n     Decorator marking a test that requires wandb."
        },
        {
            "sha": "cf5ece295ee7207a678ce8086c06d499d6151c46",
            "filename": "src/transformers/training_args.py",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/6e9972962fbc80d218234bfbd8c9b2843ef02b2b/src%2Ftransformers%2Ftraining_args.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6e9972962fbc80d218234bfbd8c9b2843ef02b2b/src%2Ftransformers%2Ftraining_args.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftraining_args.py?ref=6e9972962fbc80d218234bfbd8c9b2843ef02b2b",
            "patch": "@@ -438,9 +438,9 @@ class TrainingArguments:\n             use the corresponding output (usually index 2) as the past state and feed it to the model at the next\n             training step under the keyword argument `mems`.\n         run_name (`str`, *optional*, defaults to `output_dir`):\n-            A descriptor for the run. Typically used for [wandb](https://www.wandb.com/),\n-            [mlflow](https://www.mlflow.org/), [comet](https://www.comet.com/site) and [swanlab](https://swanlab.cn)\n-            logging. If not specified, will be the same as `output_dir`.\n+            A descriptor for the run. Typically used for [trackio](https://github.com/gradio-app/trackio),\n+            [wandb](https://www.wandb.com/), [mlflow](https://www.mlflow.org/), [comet](https://www.comet.com/site) and\n+            [swanlab](https://swanlab.cn) logging. If not specified, will be the same as `output_dir`.\n         disable_tqdm (`bool`, *optional*):\n             Whether or not to disable the tqdm progress bars and table of metrics produced by\n             [`~notebook.NotebookTrainingTracker`] in Jupyter Notebooks. Will default to `True` if the logging level is\n@@ -626,8 +626,8 @@ class TrainingArguments:\n         report_to (`str` or `list[str]`, *optional*, defaults to `\"all\"`):\n             The list of integrations to report the results and logs to. Supported platforms are `\"azure_ml\"`,\n             `\"clearml\"`, `\"codecarbon\"`, `\"comet_ml\"`, `\"dagshub\"`, `\"dvclive\"`, `\"flyte\"`, `\"mlflow\"`, `\"neptune\"`,\n-            `\"swanlab\"`, `\"tensorboard\"`, and `\"wandb\"`. Use `\"all\"` to report to all integrations installed, `\"none\"`\n-            for no integrations.\n+            `\"swanlab\"`, `\"tensorboard\"`, `\"trackio\"` and `\"wandb\"`. Use `\"all\"` to report to all integrations\n+            installed, `\"none\"` for no integrations.\n         ddp_find_unused_parameters (`bool`, *optional*):\n             When using distributed training, the value of the flag `find_unused_parameters` passed to\n             `DistributedDataParallel`. Will default to `False` if gradient checkpointing is used, `True` otherwise.\n@@ -1182,7 +1182,10 @@ class TrainingArguments:\n     run_name: Optional[str] = field(\n         default=None,\n         metadata={\n-            \"help\": \"An optional descriptor for the run. Notably used for wandb, mlflow comet and swanlab logging.\"\n+            \"help\": (\n+                \"An optional descriptor for the run. Notably used for trackio, wandb, mlflow comet and swanlab \"\n+                \"logging.\"\n+            )\n         },\n     )\n     disable_tqdm: Optional[bool] = field(\n@@ -2838,8 +2841,8 @@ def set_logging(\n             report_to (`str` or `list[str]`, *optional*, defaults to `\"all\"`):\n                 The list of integrations to report the results and logs to. Supported platforms are `\"azure_ml\"`,\n                 `\"clearml\"`, `\"codecarbon\"`, `\"comet_ml\"`, `\"dagshub\"`, `\"dvclive\"`, `\"flyte\"`, `\"mlflow\"`,\n-                `\"neptune\"`, `\"swanlab\"`, `\"tensorboard\"`, and `\"wandb\"`. Use `\"all\"` to report to all integrations\n-                installed, `\"none\"` for no integrations.\n+                `\"neptune\"`, `\"swanlab\"`, `\"tensorboard\"`, `\"trackio\"` and `\"wandb\"`. Use `\"all\"` to report to all\n+                integrations installed, `\"none\"` for no integrations.\n             first_step (`bool`, *optional*, defaults to `False`):\n                 Whether to log and evaluate the first `global_step` or not.\n             nan_inf_filter (`bool`, *optional*, defaults to `True`):"
        },
        {
            "sha": "cf20503d63cc72f7ea5e28b2eef23d1338868d54",
            "filename": "src/transformers/training_args_tf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/6e9972962fbc80d218234bfbd8c9b2843ef02b2b/src%2Ftransformers%2Ftraining_args_tf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6e9972962fbc80d218234bfbd8c9b2843ef02b2b/src%2Ftransformers%2Ftraining_args_tf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftraining_args_tf.py?ref=6e9972962fbc80d218234bfbd8c9b2843ef02b2b",
            "patch": "@@ -160,7 +160,7 @@ class TFTrainingArguments(TrainingArguments):\n             Google Cloud Project name for the Cloud TPU-enabled project. If not specified, we will attempt to\n             automatically detect from metadata.\n         run_name (`str`, *optional*):\n-            A descriptor for the run. Notably used for wandb, mlflow, comet and swanlab logging.\n+            A descriptor for the run. Notably used for trackio, wandb, mlflow, comet and swanlab logging.\n         xla (`bool`, *optional*):\n             Whether to activate the XLA compilation or not.\n     \"\"\""
        }
    ],
    "stats": {
        "total": 159,
        "additions": 150,
        "deletions": 9
    }
}