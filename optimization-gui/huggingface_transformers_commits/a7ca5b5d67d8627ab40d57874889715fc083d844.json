{
    "author": "zucchini-nlp",
    "message": "Fix processor tests (#39450)\n\nfix",
    "sha": "a7ca5b5d67d8627ab40d57874889715fc083d844",
    "files": [
        {
            "sha": "9f30ad1c12d9d2e0a557e7cf31caa50a15b479b2",
            "filename": "src/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/a7ca5b5d67d8627ab40d57874889715fc083d844/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a7ca5b5d67d8627ab40d57874889715fc083d844/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py?ref=a7ca5b5d67d8627ab40d57874889715fc083d844",
            "patch": "@@ -332,8 +332,11 @@ def decode(self, *args, **kwargs):\n         return self.tokenizer.decode(*args, **kwargs)\n \n     def apply_chat_template(self, conversations, chat_template=None, **kwargs):\n+        is_batched = False\n         if isinstance(conversations[0], dict):\n             conversations = [conversations]\n+            is_batched = True\n+\n         for conversation in conversations:\n             if (\n                 conversation[0][\"role\"] != \"system\"\n@@ -344,6 +347,9 @@ def apply_chat_template(self, conversations, chat_template=None, **kwargs):\n                     \"System prompt modified, audio output may not work as expected. \"\n                     + \"Audio output mode only works when using default system prompt 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'\"\n                 )\n+        if is_batched:\n+            conversations = conversations[0]\n+\n         return super().apply_chat_template(conversations, chat_template, **kwargs)\n \n     @property"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 6,
        "deletions": 0
    }
}