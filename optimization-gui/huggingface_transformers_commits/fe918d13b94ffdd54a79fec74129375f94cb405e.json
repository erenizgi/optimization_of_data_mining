{
    "author": "ritwickchaudhry",
    "message": "Fix temporal padding in Qwen2VLImageProcessor when the number of frames is not divisible by temporal_patch_size (#38076)\n\nQwen2VL: Fix temporal padding in Qwen2VLImageProcessor when frames are not divisible by temporal_patch_size",
    "sha": "fe918d13b94ffdd54a79fec74129375f94cb405e",
    "files": [
        {
            "sha": "b85085476cd066ebaee271e2674897cde0345ca9",
            "filename": "src/transformers/models/qwen2_vl/image_processing_qwen2_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/fe918d13b94ffdd54a79fec74129375f94cb405e/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fimage_processing_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fe918d13b94ffdd54a79fec74129375f94cb405e/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fimage_processing_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fimage_processing_qwen2_vl.py?ref=fe918d13b94ffdd54a79fec74129375f94cb405e",
            "patch": "@@ -274,7 +274,9 @@ def _preprocess(\n         if data_format == ChannelDimension.LAST:\n             patches = patches.transpose(0, 3, 1, 2)\n         if patches.shape[0] % temporal_patch_size != 0:\n-            repeats = np.repeat(patches[-1][np.newaxis], temporal_patch_size - 1, axis=0)\n+            repeats = np.repeat(\n+                patches[-1][np.newaxis], temporal_patch_size - (patches.shape[0] % temporal_patch_size), axis=0\n+            )\n             patches = np.concatenate([patches, repeats], axis=0)\n         channel = patches.shape[1]\n         grid_t = patches.shape[0] // temporal_patch_size"
        },
        {
            "sha": "5e600338b3c7d679ebedc5d476a2b94777f37ea6",
            "filename": "tests/models/qwen2_vl/test_image_processing_qwen2_vl.py",
            "status": "modified",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/fe918d13b94ffdd54a79fec74129375f94cb405e/tests%2Fmodels%2Fqwen2_vl%2Ftest_image_processing_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fe918d13b94ffdd54a79fec74129375f94cb405e/tests%2Fmodels%2Fqwen2_vl%2Ftest_image_processing_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_vl%2Ftest_image_processing_qwen2_vl.py?ref=fe918d13b94ffdd54a79fec74129375f94cb405e",
            "patch": "@@ -312,6 +312,24 @@ def test_custom_image_size(self):\n             expected_output_video_shape = [112, 1176]\n             self.assertListEqual(list(prcocess_out.pixel_values.shape), expected_output_video_shape)\n \n+    def test_temporal_padding(self):\n+        for image_processing_class in self.image_processor_list:\n+            # Initialize image_processing\n+            image_processing = image_processing_class(**self.image_processor_dict)\n+            # Create random video inputs with a number of frames not divisible by temporal_patch_size\n+            image_processor_tester = Qwen2VLImageProcessingTester(self, num_frames=5, temporal_patch_size=4)\n+            video_inputs = image_processor_tester.prepare_video_inputs(equal_resolution=True)\n+\n+            # Process the video inputs\n+            process_out = image_processing(None, videos=video_inputs, return_tensors=\"pt\")\n+            encoded_video = process_out.pixel_values_videos\n+\n+            # Check the shape after padding\n+            expected_output_video_shape = (102900, 1176)  # Adjusted based on padding\n+            self.assertEqual(tuple(encoded_video.shape), expected_output_video_shape)\n+            # Check divisibility by temporal_patch_size\n+            self.assertEqual(encoded_video.shape[0] % 4, 0)\n+\n     @require_vision\n     @require_torch\n     def test_slow_fast_equivalence(self):"
        }
    ],
    "stats": {
        "total": 22,
        "additions": 21,
        "deletions": 1
    }
}