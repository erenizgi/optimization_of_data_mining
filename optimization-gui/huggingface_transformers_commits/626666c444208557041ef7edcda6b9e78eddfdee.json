{
    "author": "ydshieh",
    "message": "Au revoir flaky `test_fast_is_faster_than_slow` (#36240)\n\n* fix\r\n\r\n* fix\r\n\r\n* fix\r\n\r\n---------\r\n\r\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "626666c444208557041ef7edcda6b9e78eddfdee",
    "files": [
        {
            "sha": "41e26e2a1328d05f6ad3e31fe049ba6c0aa48f01",
            "filename": "tests/models/rt_detr/test_image_processing_rt_detr.py",
            "status": "modified",
            "additions": 14,
            "deletions": 1,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/626666c444208557041ef7edcda6b9e78eddfdee/tests%2Fmodels%2Frt_detr%2Ftest_image_processing_rt_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/626666c444208557041ef7edcda6b9e78eddfdee/tests%2Fmodels%2Frt_detr%2Ftest_image_processing_rt_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Frt_detr%2Ftest_image_processing_rt_detr.py?ref=626666c444208557041ef7edcda6b9e78eddfdee",
            "patch": "@@ -16,7 +16,14 @@\n \n import requests\n \n-from transformers.testing_utils import require_torch, require_torch_gpu, require_torchvision, require_vision, slow\n+from transformers.testing_utils import (\n+    is_flaky,\n+    require_torch,\n+    require_torch_gpu,\n+    require_torchvision,\n+    require_vision,\n+    slow,\n+)\n from transformers.utils import is_torch_available, is_torchvision_available, is_vision_available\n \n from ...test_image_processing_common import ImageProcessingTestMixin, prepare_image_inputs\n@@ -427,3 +434,9 @@ def test_fast_processor_equivalence_cpu_gpu_coco_detection_annotations(self):\n         )\n         # verify size\n         torch.testing.assert_close(encoding_cpu[\"labels\"][0][\"size\"], encoding_gpu[\"labels\"][0][\"size\"].to(\"cpu\"))\n+\n+    @is_flaky(\n+        description=\"Still flaky with a failing ratio of ~0.6% after #36240\",\n+    )\n+    def test_fast_is_faster_than_slow(self):\n+        super().test_fast_is_faster_than_slow()"
        },
        {
            "sha": "cd11c4ac01f0bdcb97e1e457fd7fa85e917305cf",
            "filename": "tests/test_image_processing_common.py",
            "status": "modified",
            "additions": 8,
            "deletions": 3,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/626666c444208557041ef7edcda6b9e78eddfdee/tests%2Ftest_image_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/626666c444208557041ef7edcda6b9e78eddfdee/tests%2Ftest_image_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_image_processing_common.py?ref=626666c444208557041ef7edcda6b9e78eddfdee",
            "patch": "@@ -223,9 +223,14 @@ def measure_time(image_processor, image):\n             # Warmup\n             for _ in range(5):\n                 _ = image_processor(image, return_tensors=\"pt\")\n-            start = time.time()\n-            _ = image_processor(image, return_tensors=\"pt\")\n-            return time.time() - start\n+            all_times = []\n+            for _ in range(10):\n+                start = time.time()\n+                _ = image_processor(image, return_tensors=\"pt\")\n+                all_times.append(time.time() - start)\n+            # Take the average of the fastest 3 runs\n+            avg_time = sum(sorted(all_times[:3])) / 3.0\n+            return avg_time\n \n         dummy_images = torch.randint(0, 255, (4, 3, 224, 224), dtype=torch.uint8)\n         image_processor_slow = self.image_processing_class(**self.image_processor_dict)"
        }
    ],
    "stats": {
        "total": 26,
        "additions": 22,
        "deletions": 4
    }
}