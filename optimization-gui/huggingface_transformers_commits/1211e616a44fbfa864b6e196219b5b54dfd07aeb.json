{
    "author": "muellerzr",
    "message": "Use inherit tempdir makers for tests + fix failing DS tests (#35600)\n\n* Use existing APIs to make tempdir folders\r\n\r\n* Fixup deepspeed too\r\n\r\n* output_dir -> tmp_dir",
    "sha": "1211e616a44fbfa864b6e196219b5b54dfd07aeb",
    "files": [
        {
            "sha": "95a8036016133d7ac0be55a2127e0302d6770e30",
            "filename": "tests/deepspeed/test_deepspeed.py",
            "status": "modified",
            "additions": 22,
            "deletions": 6,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/1211e616a44fbfa864b6e196219b5b54dfd07aeb/tests%2Fdeepspeed%2Ftest_deepspeed.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1211e616a44fbfa864b6e196219b5b54dfd07aeb/tests%2Fdeepspeed%2Ftest_deepspeed.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fdeepspeed%2Ftest_deepspeed.py?ref=1211e616a44fbfa864b6e196219b5b54dfd07aeb",
            "patch": "@@ -482,6 +482,7 @@ def test_hf_ds_config_mismatch(self):\n                 max_grad_norm=max_grad_norm,\n                 adam_beta1=adam_beta1,\n                 adam_beta2=adam_beta2,\n+                output_dir=self.get_auto_remove_tmp_dir(),\n             )\n             with self.assertRaises(Exception) as context:\n                 trainer.train()\n@@ -506,7 +507,9 @@ def test_hf_scheduler_hf_optimizer(self):\n             del ds_config_zero2_dict[\"scheduler\"]  # force default HF Trainer scheduler\n             ds_config_zero2_dict[\"zero_optimization\"][\"offload_optimizer\"][\"device\"] = \"none\"\n             ds_config_zero2_dict[\"fp16\"][\"initial_scale_power\"] = 1  # force optimizer on the first step\n-            trainer = get_regression_trainer(a=a, local_rank=0, fp16=True, deepspeed=ds_config_zero2_dict)\n+            trainer = get_regression_trainer(\n+                a=a, local_rank=0, fp16=True, deepspeed=ds_config_zero2_dict, output_dir=self.get_auto_remove_tmp_dir()\n+            )\n             trainer.train()\n         new_a = trainer.model.a.item()\n         self.assertNotEqual(new_a, a)\n@@ -518,7 +521,9 @@ def test_ds_scheduler_hf_optimizer(self):\n             del ds_config_zero2_dict[\"optimizer\"]  # force default HF Trainer optimizer\n             ds_config_zero2_dict[\"zero_optimization\"][\"offload_optimizer\"][\"device\"] = \"none\"\n             ds_config_zero2_dict[\"fp16\"][\"initial_scale_power\"] = 1  # force optimizer on the first step\n-            trainer = get_regression_trainer(a=a, local_rank=0, fp16=True, deepspeed=ds_config_zero2_dict)\n+            trainer = get_regression_trainer(\n+                a=a, local_rank=0, fp16=True, deepspeed=ds_config_zero2_dict, output_dir=self.get_auto_remove_tmp_dir()\n+            )\n             trainer.train()\n         new_a = trainer.model.a.item()\n         self.assertNotEqual(new_a, a)\n@@ -530,7 +535,9 @@ def test_hf_scheduler_ds_optimizer(self):\n             del ds_config_zero2_dict[\"scheduler\"]  # force default HF Trainer scheduler\n             ds_config_zero2_dict[\"zero_optimization\"][\"offload_optimizer\"][\"device\"] = \"none\"\n             ds_config_zero2_dict[\"fp16\"][\"initial_scale_power\"] = 1  # force optimizer on the first step\n-            trainer = get_regression_trainer(a=a, local_rank=0, fp16=True, deepspeed=ds_config_zero2_dict)\n+            trainer = get_regression_trainer(\n+                a=a, local_rank=0, fp16=True, deepspeed=ds_config_zero2_dict, output_dir=self.get_auto_remove_tmp_dir()\n+            )\n             trainer.train()\n         new_a = trainer.model.a.item()\n         self.assertNotEqual(new_a, a)\n@@ -546,7 +553,9 @@ def test_stage3_nvme_offload(self):\n             ds_config_zero3_dict[\"zero_optimization\"][\"offload_optimizer\"] = nvme_config\n             ds_config_zero3_dict[\"zero_optimization\"][\"offload_param\"] = nvme_config\n             ds_config_zero3_dict[\"zero_optimization\"][\"stage3_gather_16bit_weights_on_model_save\"] = True\n-            trainer = get_regression_trainer(local_rank=0, fp16=True, deepspeed=ds_config_zero3_dict)\n+            trainer = get_regression_trainer(\n+                local_rank=0, fp16=True, deepspeed=ds_config_zero3_dict, output_dir=self.get_auto_remove_tmp_dir()\n+            )\n             with CaptureLogger(deepspeed_logger) as cl:\n                 trainer.train()\n             self.assertIn(\"DeepSpeed info\", cl.out, \"expected DeepSpeed logger output but got none\")\n@@ -567,6 +576,7 @@ def model_init():\n                 fp16=True,\n                 model_init=model_init,\n                 deepspeed=ds_config_zero3_dict,\n+                output_dir=self.get_auto_remove_tmp_dir(),\n             )\n \n             n_trials = 3\n@@ -588,7 +598,7 @@ def test_hf_optimizer_with_offload(self, stage, dtype):\n         ds_config_dict[\"zero_optimization\"][\"offload_optimizer\"][\"device\"] = \"cpu\"\n         ds_config_dict[\"zero_force_ds_cpu_optimizer\"] = False  # offload is not efficient w/o CPUAdam\n         with mockenv_context(**self.dist_env_1_gpu):\n-            kwargs = {\"local_rank\": 0, \"deepspeed\": ds_config_dict}\n+            kwargs = {\"local_rank\": 0, \"deepspeed\": ds_config_dict, \"output_dir\": self.get_auto_remove_tmp_dir()}\n             kwargs[dtype] = True\n             trainer = get_regression_trainer(**kwargs)\n             with CaptureLogger(deepspeed_logger) as cl:\n@@ -604,7 +614,11 @@ def test_fake_notebook_no_launcher(self, stage, dtype):\n         # it's run not as a first test as `sys.stdout` will no longer be the same. So we either have\n         # to reset `deepspeed_logger.handlers[0].setStream(sys.stdout)` or directly capture from the deepspeed_logger.\n         with mockenv_context(**self.dist_env_1_gpu):\n-            kwargs = {\"local_rank\": 0, \"deepspeed\": self.get_config_dict(stage)}\n+            kwargs = {\n+                \"local_rank\": 0,\n+                \"deepspeed\": self.get_config_dict(stage),\n+                \"output_dir\": self.get_auto_remove_tmp_dir(),\n+            }\n             kwargs[dtype] = True\n             trainer = get_regression_trainer(**kwargs)\n \n@@ -630,6 +644,7 @@ def test_early_get_last_lr(self, stage, dtype):\n                 \"deepspeed\": self.get_config_dict(stage),\n                 \"per_device_train_batch_size\": 8,\n                 \"logging_steps\": 1,\n+                \"output_dir\": self.get_auto_remove_tmp_dir(),\n             }\n             kwargs[dtype] = True\n             trainer = get_regression_trainer(**kwargs)\n@@ -673,6 +688,7 @@ def test_gradient_accumulation(self, stage, dtype):\n             \"local_rank\": 0,\n             \"train_len\": train_len,\n             \"deepspeed\": self.get_config_dict(stage),\n+            \"output_dir\": self.get_auto_remove_tmp_dir(),\n         }\n         kwargs[dtype] = True\n "
        },
        {
            "sha": "1703cb40098aef4290f261da5407bdf32859ec1b",
            "filename": "tests/trainer/test_trainer.py",
            "status": "modified",
            "additions": 622,
            "deletions": 622,
            "changes": 1244,
            "blob_url": "https://github.com/huggingface/transformers/blob/1211e616a44fbfa864b6e196219b5b54dfd07aeb/tests%2Ftrainer%2Ftest_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1211e616a44fbfa864b6e196219b5b54dfd07aeb/tests%2Ftrainer%2Ftest_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_trainer.py?ref=1211e616a44fbfa864b6e196219b5b54dfd07aeb",
            "patch": "@@ -1222,87 +1222,85 @@ def test_trainer_works_with_dict(self):\n         train_dataset = RegressionDataset()\n         eval_dataset = RegressionDataset()\n         model = RegressionDictModel()\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            args = TrainingArguments(tmp_dir, report_to=\"none\")\n-            trainer = Trainer(model, args, train_dataset=train_dataset, eval_dataset=eval_dataset)\n-            trainer.train()\n-            _ = trainer.evaluate()\n-            _ = trainer.predict(eval_dataset)\n+        args = TrainingArguments(self.get_auto_remove_tmp_dir(), report_to=\"none\")\n+        trainer = Trainer(model, args, train_dataset=train_dataset, eval_dataset=eval_dataset)\n+        trainer.train()\n+        _ = trainer.evaluate()\n+        _ = trainer.predict(eval_dataset)\n \n     def test_evaluation_with_keys_to_drop(self):\n         config = GPT2Config(vocab_size=100, n_positions=128, n_embd=32, n_layer=3, n_head=4)\n         tiny_gpt2 = GPT2LMHeadModel(config)\n         x = torch.randint(0, 100, (128,))\n         eval_dataset = RepeatDataset(x)\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            args = TrainingArguments(tmp_dir, report_to=\"none\")\n-            trainer = Trainer(tiny_gpt2, args, eval_dataset=eval_dataset)\n-            # By default the past_key_values are removed\n-            result = trainer.predict(eval_dataset)\n-            self.assertTrue(isinstance(result.predictions, np.ndarray))\n-            # We can still get them by setting ignore_keys to []\n-            result = trainer.predict(eval_dataset, ignore_keys=[])\n-            self.assertTrue(isinstance(result.predictions, tuple))\n-            self.assertEqual(len(result.predictions), 2)\n+        args = TrainingArguments(self.get_auto_remove_tmp_dir(), report_to=\"none\")\n+        trainer = Trainer(tiny_gpt2, args, eval_dataset=eval_dataset)\n+        # By default the past_key_values are removed\n+        result = trainer.predict(eval_dataset)\n+        self.assertTrue(isinstance(result.predictions, np.ndarray))\n+        # We can still get them by setting ignore_keys to []\n+        result = trainer.predict(eval_dataset, ignore_keys=[])\n+        self.assertTrue(isinstance(result.predictions, tuple))\n+        self.assertEqual(len(result.predictions), 2)\n \n     def test_training_arguments_are_left_untouched(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            trainer = get_regression_trainer(output_dir=tmp_dir)\n-            trainer.train()\n-            args = TrainingArguments(tmp_dir, report_to=[])\n-            dict1, dict2 = args.to_dict(), trainer.args.to_dict()\n-            for key in dict1.keys():\n-                # Logging dir can be slightly different as they default to something with the time.\n-                if key != \"logging_dir\":\n-                    self.assertEqual(dict1[key], dict2[key])\n+        tmp_dir = self.get_auto_remove_tmp_dir()\n+        trainer = get_regression_trainer(output_dir=tmp_dir)\n+        trainer.train()\n+        args = TrainingArguments(tmp_dir, report_to=[])\n+        dict1, dict2 = args.to_dict(), trainer.args.to_dict()\n+        for key in dict1.keys():\n+            # Logging dir can be slightly different as they default to something with the time.\n+            if key != \"logging_dir\":\n+                self.assertEqual(dict1[key], dict2[key])\n \n     def test_number_of_steps_in_training(self):\n         # Regular training has n_epochs * len(train_dl) steps\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            trainer = get_regression_trainer(learning_rate=0.1, output_dir=tmp_dir)\n-            train_output = trainer.train()\n-            self.assertEqual(train_output.global_step, self.n_epochs * 64 / self.batch_size)\n+        tmp_dir = self.get_auto_remove_tmp_dir()\n+        trainer = get_regression_trainer(learning_rate=0.1, output_dir=tmp_dir)\n+        train_output = trainer.train()\n+        self.assertEqual(train_output.global_step, self.n_epochs * 64 / self.batch_size)\n \n-            # Check passing num_train_epochs works (and a float version too):\n-            trainer = get_regression_trainer(learning_rate=0.1, num_train_epochs=1.5, output_dir=tmp_dir)\n-            train_output = trainer.train()\n-            self.assertEqual(train_output.global_step, int(1.5 * 64 / self.batch_size))\n+        # Check passing num_train_epochs works (and a float version too):\n+        trainer = get_regression_trainer(learning_rate=0.1, num_train_epochs=1.5, output_dir=tmp_dir)\n+        train_output = trainer.train()\n+        self.assertEqual(train_output.global_step, int(1.5 * 64 / self.batch_size))\n \n-            # If we pass a max_steps, num_train_epochs is ignored\n-            trainer = get_regression_trainer(learning_rate=0.1, max_steps=10, output_dir=tmp_dir)\n-            train_output = trainer.train()\n-            self.assertEqual(train_output.global_step, 10)\n+        # If we pass a max_steps, num_train_epochs is ignored\n+        trainer = get_regression_trainer(learning_rate=0.1, max_steps=10, output_dir=tmp_dir)\n+        train_output = trainer.train()\n+        self.assertEqual(train_output.global_step, 10)\n \n     @require_torch_bf16\n     @require_intel_extension_for_pytorch\n     def test_number_of_steps_in_training_with_ipex(self):\n         for mix_bf16 in [True, False]:\n-            with tempfile.TemporaryDirectory() as tmp_dir:\n-                # Regular training has n_epochs * len(train_dl) steps\n-                trainer = get_regression_trainer(\n-                    learning_rate=0.1, use_ipex=True, bf16=mix_bf16, use_cpu=True, output_dir=tmp_dir\n-                )\n-                train_output = trainer.train()\n-                self.assertEqual(train_output.global_step, self.n_epochs * 64 / trainer.args.train_batch_size)\n+            tmp_dir = self.get_auto_remove_tmp_dir()\n+            # Regular training has n_epochs * len(train_dl) steps\n+            trainer = get_regression_trainer(\n+                learning_rate=0.1, use_ipex=True, bf16=mix_bf16, use_cpu=True, output_dir=tmp_dir\n+            )\n+            train_output = trainer.train()\n+            self.assertEqual(train_output.global_step, self.n_epochs * 64 / trainer.args.train_batch_size)\n \n-                # Check passing num_train_epochs works (and a float version too):\n-                trainer = get_regression_trainer(\n-                    learning_rate=0.1,\n-                    num_train_epochs=1.5,\n-                    use_ipex=True,\n-                    bf16=mix_bf16,\n-                    use_cpu=True,\n-                    output_dir=tmp_dir,\n-                )\n-                train_output = trainer.train()\n-                self.assertEqual(train_output.global_step, int(1.5 * 64 / trainer.args.train_batch_size))\n+            # Check passing num_train_epochs works (and a float version too):\n+            trainer = get_regression_trainer(\n+                learning_rate=0.1,\n+                num_train_epochs=1.5,\n+                use_ipex=True,\n+                bf16=mix_bf16,\n+                use_cpu=True,\n+                output_dir=tmp_dir,\n+            )\n+            train_output = trainer.train()\n+            self.assertEqual(train_output.global_step, int(1.5 * 64 / trainer.args.train_batch_size))\n \n-                # If we pass a max_steps, num_train_epochs is ignored\n-                trainer = get_regression_trainer(\n-                    learning_rate=0.1, max_steps=10, use_ipex=True, bf16=mix_bf16, use_cpu=True, output_dir=tmp_dir\n-                )\n-                train_output = trainer.train()\n-                self.assertEqual(train_output.global_step, 10)\n+            # If we pass a max_steps, num_train_epochs is ignored\n+            trainer = get_regression_trainer(\n+                learning_rate=0.1, max_steps=10, use_ipex=True, bf16=mix_bf16, use_cpu=True, output_dir=tmp_dir\n+            )\n+            train_output = trainer.train()\n+            self.assertEqual(train_output.global_step, 10)\n \n     def test_torch_compile_loss_func_compatibility(self):\n         config = LlamaConfig(vocab_size=100, hidden_size=32, num_hidden_layers=3, num_attention_heads=4)\n@@ -1311,15 +1309,14 @@ def test_torch_compile_loss_func_compatibility(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            args = TrainingArguments(\n-                tmp_dir,\n-                per_device_train_batch_size=2,\n-                torch_compile=True,\n-                max_steps=1,  # compile happens on the first step\n-            )\n-            trainer = Trainer(model=tiny_llama, args=args, train_dataset=train_dataset)  # noqa\n-            trainer.train()\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            per_device_train_batch_size=2,\n+            torch_compile=True,\n+            max_steps=1,  # compile happens on the first step\n+        )\n+        trainer = Trainer(model=tiny_llama, args=args, train_dataset=train_dataset)  # noqa\n+        trainer.train()\n \n     @require_peft\n     @require_bitsandbytes\n@@ -1348,14 +1345,13 @@ def test_bnb_compile(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            args = TrainingArguments(\n-                tmp_dir,\n-                learning_rate=1e-9,\n-                logging_steps=5,\n-            )\n-            with self.assertRaises(ValueError):\n-                _ = Trainer(tiny_model, args, train_dataset=train_dataset)  # noqa\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+        )\n+        with self.assertRaises(ValueError):\n+            _ = Trainer(tiny_model, args, train_dataset=train_dataset)  # noqa\n \n     @require_peft\n     def test_multiple_peft_adapters(self):\n@@ -1387,32 +1383,32 @@ def test_multiple_peft_adapters(self):\n \n         tokenizer.pad_token = tokenizer.eos_token\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            args = TrainingArguments(\n-                tmpdir,\n-                per_device_train_batch_size=1,\n-                learning_rate=1e-9,\n-                save_steps=5,\n-                logging_steps=5,\n-                max_steps=10,\n-                use_cpu=True,\n-            )\n-            trainer = Trainer(tiny_model, args, processing_class=tokenizer, train_dataset=train_dataset)\n+        tmp_dir = self.get_auto_remove_tmp_dir()\n+        args = TrainingArguments(\n+            tmp_dir,\n+            per_device_train_batch_size=1,\n+            learning_rate=1e-9,\n+            save_steps=5,\n+            logging_steps=5,\n+            max_steps=10,\n+            use_cpu=True,\n+        )\n+        trainer = Trainer(tiny_model, args, processing_class=tokenizer, train_dataset=train_dataset)\n \n-            trainer.train()\n-            parameters = dict(tiny_model.named_parameters())\n-            state = dataclasses.asdict(trainer.state)\n+        trainer.train()\n+        parameters = dict(tiny_model.named_parameters())\n+        state = dataclasses.asdict(trainer.state)\n \n-            # Reinitialize trainer\n-            trainer = Trainer(tiny_model, args, processing_class=tokenizer, train_dataset=train_dataset)\n+        # Reinitialize trainer\n+        trainer = Trainer(tiny_model, args, processing_class=tokenizer, train_dataset=train_dataset)\n \n-            checkpoint = os.path.join(tmpdir, \"checkpoint-5\")\n+        checkpoint = os.path.join(tmp_dir, \"checkpoint-5\")\n \n-            trainer.train(resume_from_checkpoint=checkpoint)\n-            parameters1 = dict(tiny_model.named_parameters())\n-            state1 = dataclasses.asdict(trainer.state)\n-            self.assertEqual(parameters, parameters1)\n-            self.check_trainer_state_are_the_same(state, state1)\n+        trainer.train(resume_from_checkpoint=checkpoint)\n+        parameters1 = dict(tiny_model.named_parameters())\n+        state1 = dataclasses.asdict(trainer.state)\n+        self.assertEqual(parameters, parameters1)\n+        self.check_trainer_state_are_the_same(state, state1)\n \n     @require_bitsandbytes\n     def test_rmsprop_bnb(self):\n@@ -1421,15 +1417,18 @@ def test_rmsprop_bnb(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir, learning_rate=1e-9, logging_steps=5, logging_nan_inf_filter=False, optim=\"rmsprop_bnb\"\n-            )\n-            trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+            logging_nan_inf_filter=False,\n+            optim=\"rmsprop_bnb\",\n+        )\n+        trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n \n-            # Check that it trains without errors\n-            trainer.train()\n+        # Check that it trains without errors\n+        trainer.train()\n \n     @require_bitsandbytes\n     def test_ademamix_bnb(self):\n@@ -1438,15 +1437,18 @@ def test_ademamix_bnb(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir, learning_rate=1e-9, logging_steps=5, logging_nan_inf_filter=False, optim=\"ademamix\"\n-            )\n-            trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+            logging_nan_inf_filter=False,\n+            optim=\"ademamix\",\n+        )\n+        trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n \n-            # Check that it trains without errors\n-            trainer.train()\n+        # Check that it trains without errors\n+        trainer.train()\n \n     @require_bitsandbytes\n     def test_ademamix_bnb_8bit(self):\n@@ -1455,15 +1457,18 @@ def test_ademamix_bnb_8bit(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir, learning_rate=1e-9, logging_steps=5, logging_nan_inf_filter=False, optim=\"ademamix_8bit\"\n-            )\n-            trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+            logging_nan_inf_filter=False,\n+            optim=\"ademamix_8bit\",\n+        )\n+        trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n \n-            # Check that it trains without errors\n-            trainer.train()\n+        # Check that it trains without errors\n+        trainer.train()\n \n     @require_bitsandbytes\n     def test_rmsprop_bnb_8bit(self):\n@@ -1472,31 +1477,37 @@ def test_rmsprop_bnb_8bit(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir, learning_rate=1e-9, logging_steps=5, logging_nan_inf_filter=False, optim=\"rmsprop_bnb_8bit\"\n-            )\n-            trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+            logging_nan_inf_filter=False,\n+            optim=\"rmsprop_bnb_8bit\",\n+        )\n+        trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n \n-            # Check that it trains without errors\n-            trainer.train()\n+        # Check that it trains without errors\n+        trainer.train()\n \n     @require_bitsandbytes\n     def test_rmsprop_bnb_32bit(self):\n         config = GPT2Config(vocab_size=100, n_positions=128, n_embd=32, n_layer=3, n_head=4)\n         tiny_gpt2 = GPT2LMHeadModel(config)\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir, learning_rate=1e-9, logging_steps=5, logging_nan_inf_filter=False, optim=\"rmsprop_bnb_32bit\"\n-            )\n-            trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+            logging_nan_inf_filter=False,\n+            optim=\"rmsprop_bnb_32bit\",\n+        )\n+        trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n \n-            # Check that it trains without errors\n-            trainer.train()\n+        # Check that it trains without errors\n+        trainer.train()\n \n     def test_neftune(self):\n         config = GPT2Config(vocab_size=100, n_positions=128, n_embd=32, n_layer=3, n_head=4)\n@@ -1505,54 +1516,52 @@ def test_neftune(self):\n         train_dataset = RepeatDataset(x)\n \n         # Trainer without inf/nan filter\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            args = TrainingArguments(\n-                tmp_dir,\n-                learning_rate=1e-9,\n-                logging_steps=5,\n-                logging_nan_inf_filter=False,\n-                neftune_noise_alpha=0.4,\n-                report_to=\"none\",\n-            )\n-            trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+            logging_nan_inf_filter=False,\n+            neftune_noise_alpha=0.4,\n+            report_to=\"none\",\n+        )\n+        trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n \n-            trainer.model = trainer._activate_neftune(trainer.model)\n+        trainer.model = trainer._activate_neftune(trainer.model)\n \n-            dummy_input = torch.LongTensor([[1, 0, 1]]).to(torch_device)\n+        dummy_input = torch.LongTensor([[1, 0, 1]]).to(torch_device)\n \n-            emb1 = trainer.model.get_input_embeddings()(dummy_input)\n-            emb2 = trainer.model.get_input_embeddings()(dummy_input)\n+        emb1 = trainer.model.get_input_embeddings()(dummy_input)\n+        emb2 = trainer.model.get_input_embeddings()(dummy_input)\n \n-            self.assertFalse(torch.allclose(emb1, emb2), \"Neftune noise is not applied!\")\n+        self.assertFalse(torch.allclose(emb1, emb2), \"Neftune noise is not applied!\")\n \n         # redefine the model\n         tiny_gpt2 = GPT2LMHeadModel(config)\n         # Trainer without inf/nan filter\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            args = TrainingArguments(\n-                tmp_dir,\n-                learning_rate=1e-9,\n-                logging_steps=5,\n-                logging_nan_inf_filter=False,\n-                neftune_noise_alpha=0.4,\n-                report_to=\"none\",\n-            )\n-            trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+            logging_nan_inf_filter=False,\n+            neftune_noise_alpha=0.4,\n+            report_to=\"none\",\n+        )\n+        trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n \n-            # Check that it trains without errors\n-            trainer.train()\n+        # Check that it trains without errors\n+        trainer.train()\n \n-            # Make sure forward pass works fine\n-            _ = trainer.model(dummy_input)\n-            self.assertTrue(len(trainer.model.get_input_embeddings()._forward_hooks) == 0)\n+        # Make sure forward pass works fine\n+        _ = trainer.model(dummy_input)\n+        self.assertTrue(len(trainer.model.get_input_embeddings()._forward_hooks) == 0)\n \n-            trainer.model.eval()\n+        trainer.model.eval()\n \n-            # Check that we get identical embeddings just in case\n-            emb1 = trainer.model.get_input_embeddings()(dummy_input)\n-            emb2 = trainer.model.get_input_embeddings()(dummy_input)\n+        # Check that we get identical embeddings just in case\n+        emb1 = trainer.model.get_input_embeddings()(dummy_input)\n+        emb2 = trainer.model.get_input_embeddings()(dummy_input)\n \n-            self.assertTrue(torch.allclose(emb1, emb2), \"Neftune noise is still applied!\")\n+        self.assertTrue(torch.allclose(emb1, emb2), \"Neftune noise is still applied!\")\n \n     def test_logging_inf_nan_filter(self):\n         config = GPT2Config(vocab_size=100, n_positions=128, n_embd=32, n_layer=3, n_head=4)\n@@ -1561,176 +1570,179 @@ def test_logging_inf_nan_filter(self):\n         train_dataset = RepeatDataset(x)\n \n         # Trainer without inf/nan filter\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            args = TrainingArguments(\n-                tmp_dir, learning_rate=1e9, logging_steps=5, logging_nan_inf_filter=False, report_to=\"none\"\n-            )\n-            trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n-            trainer.train()\n-            log_history_no_filter = trainer.state.log_history\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e9,\n+            logging_steps=5,\n+            logging_nan_inf_filter=False,\n+            report_to=\"none\",\n+        )\n+        trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n+        trainer.train()\n+        log_history_no_filter = trainer.state.log_history\n \n         # Trainer with inf/nan filter\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            args = TrainingArguments(\n-                tmp_dir, learning_rate=1e9, logging_steps=5, logging_nan_inf_filter=True, report_to=\"none\"\n-            )\n-            trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n-            trainer.train()\n-            log_history_filter = trainer.state.log_history\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e9,\n+            logging_steps=5,\n+            logging_nan_inf_filter=True,\n+            report_to=\"none\",\n+        )\n+        trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset)\n+        trainer.train()\n+        log_history_filter = trainer.state.log_history\n \n-            def is_any_loss_nan_or_inf(log_history):\n-                losses = [l[\"loss\"] for l in log_history[:-1]]\n-                return any(math.isnan(x) for x in losses) or any(math.isinf(x) for x in losses)\n+        def is_any_loss_nan_or_inf(log_history):\n+            losses = [l[\"loss\"] for l in log_history[:-1]]\n+            return any(math.isnan(x) for x in losses) or any(math.isinf(x) for x in losses)\n \n-            self.assertTrue(is_any_loss_nan_or_inf(log_history_no_filter))\n-            self.assertFalse(is_any_loss_nan_or_inf(log_history_filter))\n+        self.assertTrue(is_any_loss_nan_or_inf(log_history_no_filter))\n+        self.assertFalse(is_any_loss_nan_or_inf(log_history_filter))\n \n     def test_train_and_eval_dataloaders(self):\n         if torch_device == \"cuda\":\n             n_gpu = max(1, backend_device_count(torch_device))\n         else:\n             n_gpu = 1\n \n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            trainer = get_regression_trainer(learning_rate=0.1, per_device_train_batch_size=16, output_dir=tmp_dir)\n-            self.assertEqual(trainer.get_train_dataloader().total_batch_size, 16 * n_gpu)\n-            trainer = get_regression_trainer(learning_rate=0.1, per_device_eval_batch_size=16, output_dir=tmp_dir)\n-            self.assertEqual(trainer.get_eval_dataloader().total_batch_size, 16 * n_gpu)\n-\n-            # Check drop_last works\n-            trainer = get_regression_trainer(\n-                train_len=66,\n-                eval_len=74,\n-                learning_rate=0.1,\n-                per_device_train_batch_size=16,\n-                per_device_eval_batch_size=32,\n-                output_dir=tmp_dir,\n-            )\n-            self.assertEqual(len(trainer.get_train_dataloader()), 66 // (16 * n_gpu) + 1)\n-            self.assertEqual(len(trainer.get_eval_dataloader()), 74 // (32 * n_gpu) + 1)\n+        tmp_dir = self.get_auto_remove_tmp_dir()\n+        trainer = get_regression_trainer(learning_rate=0.1, per_device_train_batch_size=16, output_dir=tmp_dir)\n+        self.assertEqual(trainer.get_train_dataloader().total_batch_size, 16 * n_gpu)\n+        trainer = get_regression_trainer(learning_rate=0.1, per_device_eval_batch_size=16, output_dir=tmp_dir)\n+        self.assertEqual(trainer.get_eval_dataloader().total_batch_size, 16 * n_gpu)\n+\n+        # Check drop_last works\n+        trainer = get_regression_trainer(\n+            train_len=66,\n+            eval_len=74,\n+            learning_rate=0.1,\n+            per_device_train_batch_size=16,\n+            per_device_eval_batch_size=32,\n+            output_dir=tmp_dir,\n+        )\n+        self.assertEqual(len(trainer.get_train_dataloader()), 66 // (16 * n_gpu) + 1)\n+        self.assertEqual(len(trainer.get_eval_dataloader()), 74 // (32 * n_gpu) + 1)\n \n-            trainer = get_regression_trainer(\n-                train_len=66,\n-                eval_len=74,\n-                learning_rate=0.1,\n-                per_device_train_batch_size=16,\n-                per_device_eval_batch_size=32,\n-                dataloader_drop_last=True,\n-                output_dir=tmp_dir,\n-            )\n-            self.assertEqual(len(trainer.get_train_dataloader()), 66 // (16 * n_gpu))\n-            self.assertEqual(len(trainer.get_eval_dataloader()), 74 // (32 * n_gpu))\n+        trainer = get_regression_trainer(\n+            train_len=66,\n+            eval_len=74,\n+            learning_rate=0.1,\n+            per_device_train_batch_size=16,\n+            per_device_eval_batch_size=32,\n+            dataloader_drop_last=True,\n+            output_dir=tmp_dir,\n+        )\n+        self.assertEqual(len(trainer.get_train_dataloader()), 66 // (16 * n_gpu))\n+        self.assertEqual(len(trainer.get_eval_dataloader()), 74 // (32 * n_gpu))\n \n-            # Check passing a new dataset for evaluation works\n-            new_eval_dataset = RegressionDataset(length=128)\n-            self.assertEqual(len(trainer.get_eval_dataloader(new_eval_dataset)), 128 // (32 * n_gpu))\n+        # Check passing a new dataset for evaluation works\n+        new_eval_dataset = RegressionDataset(length=128)\n+        self.assertEqual(len(trainer.get_eval_dataloader(new_eval_dataset)), 128 // (32 * n_gpu))\n \n     # tests that we do not require dataloader to have a .dataset attribute\n     def test_dataloader_without_dataset(self):\n         train_dataset = RegressionDataset(length=128)\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            trainer = CustomDataloaderTrainer(\n-                model=RegressionModel(),\n-                train_dataset=train_dataset,\n-                eval_dataset=train_dataset,\n-                args=TrainingArguments(output_dir=tmp_dir, report_to=\"none\"),\n-            )\n+        trainer = CustomDataloaderTrainer(\n+            model=RegressionModel(),\n+            train_dataset=train_dataset,\n+            eval_dataset=train_dataset,\n+            args=TrainingArguments(output_dir=self.get_auto_remove_tmp_dir(), report_to=\"none\"),\n+        )\n \n-            trainer.train()\n-            trainer.evaluate()\n+        trainer.train()\n+        trainer.evaluate()\n \n     def test_get_eval_dataloader_without_persistent_workers(self):\n         train_dataset = RegressionDataset()\n         config = GPT2Config(vocab_size=100, n_positions=128, n_embd=32, n_layer=3, n_head=4)\n         tiny_gpt2 = GPT2LMHeadModel(config)\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            args = TrainingArguments(tmp_dir, report_to=\"none\", dataloader_persistent_workers=False)\n-\n-            # Single evaluation dataset\n-            eval_dataset = RegressionDataset()\n-            trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset, eval_dataset=eval_dataset)\n-            # Mocking the prepare method to avoid the dataloader changing with each call to get_eval_dataloader\n-            trainer.accelerator.prepare = lambda x: x\n+        args = TrainingArguments(self.get_auto_remove_tmp_dir(), report_to=\"none\", dataloader_persistent_workers=False)\n \n-            default_dataloader = trainer.get_eval_dataloader()\n-            dataloader_with_dataset = trainer.get_eval_dataloader(eval_dataset)\n-\n-            self.assertEqual(default_dataloader.dataset, eval_dataset)\n-            self.assertEqual(dataloader_with_dataset.dataset, eval_dataset)\n-            self.assertNotEqual(default_dataloader, dataloader_with_dataset)\n-\n-            # Multiple evaluation datasets\n-            first_dataset = RegressionDataset()\n-            second_dataset = RegressionDataset()\n-            trainer = Trainer(\n-                tiny_gpt2,\n-                args,\n-                train_dataset=train_dataset,\n-                eval_dataset={\"first\": first_dataset, \"second\": second_dataset},\n-            )\n-            # Mocking the prepare method to avoid the dataloader changing with each call to get_eval_dataloader\n-            trainer.accelerator.prepare = lambda x: x\n+        # Single evaluation dataset\n+        eval_dataset = RegressionDataset()\n+        trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset, eval_dataset=eval_dataset)\n+        # Mocking the prepare method to avoid the dataloader changing with each call to get_eval_dataloader\n+        trainer.accelerator.prepare = lambda x: x\n+\n+        default_dataloader = trainer.get_eval_dataloader()\n+        dataloader_with_dataset = trainer.get_eval_dataloader(eval_dataset)\n+\n+        self.assertEqual(default_dataloader.dataset, eval_dataset)\n+        self.assertEqual(dataloader_with_dataset.dataset, eval_dataset)\n+        self.assertNotEqual(default_dataloader, dataloader_with_dataset)\n+\n+        # Multiple evaluation datasets\n+        first_dataset = RegressionDataset()\n+        second_dataset = RegressionDataset()\n+        trainer = Trainer(\n+            tiny_gpt2,\n+            args,\n+            train_dataset=train_dataset,\n+            eval_dataset={\"first\": first_dataset, \"second\": second_dataset},\n+        )\n+        # Mocking the prepare method to avoid the dataloader changing with each call to get_eval_dataloader\n+        trainer.accelerator.prepare = lambda x: x\n \n-            first_dataloader = trainer.get_eval_dataloader(\"first\")\n-            first_dataloader_repeated = trainer.get_eval_dataloader(\"first\")\n-            second_dataloader = trainer.get_eval_dataloader(\"second\")\n-            second_dataloader_repeated = trainer.get_eval_dataloader(\"second\")\n+        first_dataloader = trainer.get_eval_dataloader(\"first\")\n+        first_dataloader_repeated = trainer.get_eval_dataloader(\"first\")\n+        second_dataloader = trainer.get_eval_dataloader(\"second\")\n+        second_dataloader_repeated = trainer.get_eval_dataloader(\"second\")\n \n-            self.assertEqual(first_dataset, first_dataloader.dataset)\n-            self.assertEqual(first_dataloader.dataset, first_dataloader_repeated.dataset)\n-            self.assertEqual(second_dataset, second_dataloader.dataset)\n-            self.assertEqual(second_dataloader.dataset, second_dataloader_repeated.dataset)\n-            self.assertNotEqual(first_dataloader, first_dataloader_repeated)\n-            self.assertNotEqual(second_dataloader, second_dataloader_repeated)\n+        self.assertEqual(first_dataset, first_dataloader.dataset)\n+        self.assertEqual(first_dataloader.dataset, first_dataloader_repeated.dataset)\n+        self.assertEqual(second_dataset, second_dataloader.dataset)\n+        self.assertEqual(second_dataloader.dataset, second_dataloader_repeated.dataset)\n+        self.assertNotEqual(first_dataloader, first_dataloader_repeated)\n+        self.assertNotEqual(second_dataloader, second_dataloader_repeated)\n \n     def test_get_eval_dataloader_with_persistent_workers(self):\n         train_dataset = RegressionDataset()\n         config = GPT2Config(vocab_size=100, n_positions=128, n_embd=32, n_layer=3, n_head=4)\n         tiny_gpt2 = GPT2LMHeadModel(config)\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            args = TrainingArguments(\n-                tmp_dir,\n-                report_to=\"none\",\n-                dataloader_persistent_workers=True,\n-                dataloader_num_workers=2,\n-            )\n-\n-            # Single evaluation dataset\n-            eval_dataset = RegressionDataset()\n-            trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset, eval_dataset=eval_dataset)\n-            # Mocking the prepare method to avoid the dataloader changing with each call to get_eval_dataloader\n-            trainer.accelerator.prepare = lambda x: x\n-\n-            default_dataloader = trainer.get_eval_dataloader()\n-            dataloader_with_dataset = trainer.get_eval_dataloader(eval_dataset)\n-\n-            self.assertEqual(default_dataloader.dataset, eval_dataset)\n-            self.assertEqual(dataloader_with_dataset.dataset, eval_dataset)\n-            self.assertEqual(default_dataloader, dataloader_with_dataset)\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            report_to=\"none\",\n+            dataloader_persistent_workers=True,\n+            dataloader_num_workers=2,\n+        )\n \n-            # Multiple evaluation datasets\n-            first_dataset = RegressionDataset()\n-            second_dataset = RegressionDataset()\n-            trainer = Trainer(\n-                tiny_gpt2,\n-                args,\n-                train_dataset=train_dataset,\n-                eval_dataset={\"first\": first_dataset, \"second\": second_dataset},\n-            )\n-            # Mocking the prepare method to avoid the dataloader changing with each call to get_eval_dataloader\n-            trainer.accelerator.prepare = lambda x: x\n+        # Single evaluation dataset\n+        eval_dataset = RegressionDataset()\n+        trainer = Trainer(tiny_gpt2, args, train_dataset=train_dataset, eval_dataset=eval_dataset)\n+        # Mocking the prepare method to avoid the dataloader changing with each call to get_eval_dataloader\n+        trainer.accelerator.prepare = lambda x: x\n+\n+        default_dataloader = trainer.get_eval_dataloader()\n+        dataloader_with_dataset = trainer.get_eval_dataloader(eval_dataset)\n+\n+        self.assertEqual(default_dataloader.dataset, eval_dataset)\n+        self.assertEqual(dataloader_with_dataset.dataset, eval_dataset)\n+        self.assertEqual(default_dataloader, dataloader_with_dataset)\n+\n+        # Multiple evaluation datasets\n+        first_dataset = RegressionDataset()\n+        second_dataset = RegressionDataset()\n+        trainer = Trainer(\n+            tiny_gpt2,\n+            args,\n+            train_dataset=train_dataset,\n+            eval_dataset={\"first\": first_dataset, \"second\": second_dataset},\n+        )\n+        # Mocking the prepare method to avoid the dataloader changing with each call to get_eval_dataloader\n+        trainer.accelerator.prepare = lambda x: x\n \n-            first_dataloader = trainer.get_eval_dataloader(\"first\")\n-            first_dataloader_repeated = trainer.get_eval_dataloader(\"first\")\n-            second_dataloader = trainer.get_eval_dataloader(\"second\")\n-            second_dataloader_repeated = trainer.get_eval_dataloader(\"second\")\n+        first_dataloader = trainer.get_eval_dataloader(\"first\")\n+        first_dataloader_repeated = trainer.get_eval_dataloader(\"first\")\n+        second_dataloader = trainer.get_eval_dataloader(\"second\")\n+        second_dataloader_repeated = trainer.get_eval_dataloader(\"second\")\n \n-            self.assertEqual(first_dataset, first_dataloader.dataset)\n-            self.assertEqual(first_dataloader.dataset, first_dataloader_repeated.dataset)\n-            self.assertEqual(second_dataset, second_dataloader.dataset)\n-            self.assertEqual(second_dataloader.dataset, second_dataloader_repeated.dataset)\n-            self.assertEqual(first_dataloader, first_dataloader_repeated)\n-            self.assertEqual(second_dataloader, second_dataloader_repeated)\n+        self.assertEqual(first_dataset, first_dataloader.dataset)\n+        self.assertEqual(first_dataloader.dataset, first_dataloader_repeated.dataset)\n+        self.assertEqual(second_dataset, second_dataloader.dataset)\n+        self.assertEqual(second_dataloader.dataset, second_dataloader_repeated.dataset)\n+        self.assertEqual(first_dataloader, first_dataloader_repeated)\n+        self.assertEqual(second_dataloader, second_dataloader_repeated)\n \n     @require_liger_kernel\n     def test_use_liger_kernel_patching(self):\n@@ -1747,16 +1759,15 @@ def test_use_liger_kernel_patching(self):\n             self.assertNotEqual(modeling_llama.apply_rotary_pos_emb, liger_rotary_pos_emb)\n             self.assertFalse(isinstance(tiny_llama.model.norm, LigerRMSNorm))\n \n-            with tempfile.TemporaryDirectory() as tmp_dir:\n-                args = TrainingArguments(\n-                    tmp_dir,\n-                    use_liger_kernel=True,\n-                )\n-                Trainer(tiny_llama, args)\n+            args = TrainingArguments(\n+                self.get_auto_remove_tmp_dir(),\n+                use_liger_kernel=True,\n+            )\n+            Trainer(tiny_llama, args)\n \n-                # Spot check that modeling code and model instance variables are patched\n-                self.assertEqual(modeling_llama.apply_rotary_pos_emb, liger_rotary_pos_emb)\n-                self.assertTrue(isinstance(tiny_llama.model.norm, LigerRMSNorm))\n+            # Spot check that modeling code and model instance variables are patched\n+            self.assertEqual(modeling_llama.apply_rotary_pos_emb, liger_rotary_pos_emb)\n+            self.assertTrue(isinstance(tiny_llama.model.norm, LigerRMSNorm))\n \n     @require_liger_kernel\n     @require_torch_gpu\n@@ -1768,12 +1779,13 @@ def test_use_liger_kernel_trainer(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            args = TrainingArguments(tmpdir, learning_rate=1e-2, logging_steps=5, max_steps=20, use_liger_kernel=True)\n-            trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(), learning_rate=1e-2, logging_steps=5, max_steps=20, use_liger_kernel=True\n+        )\n+        trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n \n-            # Check this works\n-            _ = trainer.train()\n+        # Check this works\n+        _ = trainer.train()\n \n     @require_lomo\n     @require_torch_gpu\n@@ -1786,13 +1798,14 @@ def test_lomo(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(tmpdir, learning_rate=1e-2, logging_steps=5, optim=\"lomo\", max_steps=20)\n-            trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(), learning_rate=1e-2, logging_steps=5, optim=\"lomo\", max_steps=20\n+        )\n+        trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n \n-            # Check this works\n-            _ = trainer.train()\n+        # Check this works\n+        _ = trainer.train()\n \n         for name, param in tiny_llama.named_parameters():\n             self.assertFalse(torch.allclose(param, previous_params[name].to(param.device), rtol=1e-12, atol=1e-12))\n@@ -1805,40 +1818,38 @@ def test_adalomo(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir,\n-                learning_rate=1e-9,\n-                logging_steps=5,\n-                optim=\"adalomo\",\n-            )\n-            trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+            optim=\"adalomo\",\n+        )\n+        trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n \n-            # Check this works\n-            _ = trainer.train()\n+        # Check this works\n+        _ = trainer.train()\n \n     @require_grokadamw\n     @require_torch_gpu\n-    def test_grokadamw():\n+    def test_grokadamw(self):\n         config = LlamaConfig(vocab_size=100, hidden_size=32, num_hidden_layers=3, num_attention_heads=4)\n         tiny_llama = LlamaForCausalLM(config)\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir,\n-                learning_rate=2e-5,\n-                logging_steps=5,\n-                optim=\"grokadamw\",\n-                max_steps=20,\n-            )\n-            trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=2e-5,\n+            logging_steps=5,\n+            optim=\"grokadamw\",\n+            max_steps=20,\n+        )\n+        trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n \n-            # Check this works\n-            _ = trainer.train()\n+        # Check this works\n+        _ = trainer.train()\n \n     @require_schedulefree\n     @require_torch_gpu\n@@ -1848,18 +1859,17 @@ def test_schedulefree_adam(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir,\n-                learning_rate=1e-9,\n-                logging_steps=5,\n-                optim=\"schedule_free_adamw\",\n-            )\n-            trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+            optim=\"schedule_free_adamw\",\n+        )\n+        trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n \n-            # Check this works\n-            _ = trainer.train()\n+        # Check this works\n+        _ = trainer.train()\n \n     def test_galore_matched_modules(self):\n         regex_patterns = [r\".*.attn.*\", r\".*.mlp.*\"]\n@@ -1950,19 +1960,18 @@ def test_galore(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir,\n-                learning_rate=1e-9,\n-                logging_steps=5,\n-                optim=\"galore_adamw\",\n-                optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n-            )\n-            trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+            optim=\"galore_adamw\",\n+            optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n+        )\n+        trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n \n-            # Check this works\n-            _ = trainer.train()\n+        # Check this works\n+        _ = trainer.train()\n \n     @require_galore_torch\n     @require_torch_gpu\n@@ -1972,20 +1981,19 @@ def test_galore_extra_args(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir,\n-                learning_rate=1e-9,\n-                logging_steps=5,\n-                optim=\"galore_adamw\",\n-                optim_args=\"rank=64, update_proj_gap=100, scale=0.10\",\n-                optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n-            )\n-            trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+            optim=\"galore_adamw\",\n+            optim_args=\"rank=64, update_proj_gap=100, scale=0.10\",\n+            optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n+        )\n+        trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n \n-            # Check this works\n-            _ = trainer.train()\n+        # Check this works\n+        _ = trainer.train()\n \n     @require_galore_torch\n     @require_torch_gpu\n@@ -1995,19 +2003,18 @@ def test_galore_layerwise(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir,\n-                learning_rate=1e-9,\n-                logging_steps=5,\n-                optim=\"galore_adamw_layerwise\",\n-                optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n-            )\n-            trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+            optim=\"galore_adamw_layerwise\",\n+            optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n+        )\n+        trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n \n-            # Check this works\n-            _ = trainer.train()\n+        # Check this works\n+        _ = trainer.train()\n \n     @require_galore_torch\n     @require_torch_gpu\n@@ -2017,20 +2024,19 @@ def test_galore_layerwise_with_scheduler(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir,\n-                learning_rate=1e-9,\n-                logging_steps=5,\n-                optim=\"galore_adamw_layerwise\",\n-                lr_scheduler_type=\"cosine\",\n-                optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n-            )\n-            trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+            optim=\"galore_adamw_layerwise\",\n+            lr_scheduler_type=\"cosine\",\n+            optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n+        )\n+        trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n \n-            # Check this works\n-            _ = trainer.train()\n+        # Check this works\n+        _ = trainer.train()\n \n     @require_galore_torch\n     @require_torch_gpu\n@@ -2040,19 +2046,18 @@ def test_galore_adamw_8bit(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir,\n-                learning_rate=1e-9,\n-                logging_steps=5,\n-                optim=\"galore_adamw_8bit\",\n-                optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n-            )\n-            trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=1e-9,\n+            logging_steps=5,\n+            optim=\"galore_adamw_8bit\",\n+            optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n+        )\n+        trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n \n-            # Check this works\n-            _ = trainer.train()\n+        # Check this works\n+        _ = trainer.train()\n \n     @require_galore_torch\n     @require_torch_gpu\n@@ -2156,23 +2161,22 @@ def test_galore_lr_display_without_scheduler(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            learning_rate = 1e-9\n-            num_steps = 10\n+        learning_rate = 1e-9\n+        num_steps = 10\n \n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir,\n-                learning_rate=learning_rate,\n-                logging_steps=5,\n-                optim=\"galore_adamw\",\n-                optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n-            )\n-            trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n-            trainer.create_optimizer_and_scheduler(num_training_steps=num_steps)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            learning_rate=learning_rate,\n+            logging_steps=5,\n+            optim=\"galore_adamw\",\n+            optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n+        )\n+        trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n+        trainer.create_optimizer_and_scheduler(num_training_steps=num_steps)\n \n-            # reflects displayed lr in trainer\n-            self.assertEqual(trainer.get_learning_rates(), [learning_rate, learning_rate])\n+        # reflects displayed lr in trainer\n+        self.assertEqual(trainer.get_learning_rates(), [learning_rate, learning_rate])\n \n     @require_galore_torch\n     @require_torch_gpu\n@@ -2182,49 +2186,48 @@ def test_galore_lr_display_with_scheduler(self):\n         x = torch.randint(0, 100, (128,))\n         train_dataset = RepeatDataset(x)\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            learning_rate = 2e-4\n-            num_train_epochs = 2\n-            num_warmup_steps = 5\n+        learning_rate = 2e-4\n+        num_train_epochs = 2\n+        num_warmup_steps = 5\n \n-            # Trainer without inf/nan filter\n-            args = TrainingArguments(\n-                tmpdir,\n-                num_train_epochs=num_train_epochs,\n-                learning_rate=learning_rate,\n-                warmup_steps=num_warmup_steps,\n-                lr_scheduler_type=\"cosine\",\n-                logging_steps=1,\n-                optim=\"galore_adamw\",\n-                optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n-            )\n-            trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n+        # Trainer without inf/nan filter\n+        args = TrainingArguments(\n+            self.get_auto_remove_tmp_dir(),\n+            num_train_epochs=num_train_epochs,\n+            learning_rate=learning_rate,\n+            warmup_steps=num_warmup_steps,\n+            lr_scheduler_type=\"cosine\",\n+            logging_steps=1,\n+            optim=\"galore_adamw\",\n+            optim_target_modules=[r\".*attn.*\", r\".*mlp.*\"],\n+        )\n+        trainer = Trainer(tiny_llama, args, train_dataset=train_dataset)\n \n-            # creating log history of trainer, results don't matter\n-            trainer.train()\n-            logs = trainer.state.log_history[1:][:-1]\n+        # creating log history of trainer, results don't matter\n+        trainer.train()\n+        logs = trainer.state.log_history[1:][:-1]\n \n-            # reach given learning rate peak and end with 0 lr\n-            self.assertTrue(logs[num_warmup_steps - 2][\"learning_rate\"] == learning_rate)\n-            self.assertTrue(logs[-1][\"learning_rate\"] == 0)\n+        # reach given learning rate peak and end with 0 lr\n+        self.assertTrue(logs[num_warmup_steps - 2][\"learning_rate\"] == learning_rate)\n+        self.assertTrue(logs[-1][\"learning_rate\"] == 0)\n \n-            # increasing and decreasing pattern of lrs\n-            increasing_lrs = [\n-                logs[i][\"learning_rate\"] < logs[i + 1][\"learning_rate\"]\n-                for i in range(len(logs))\n-                if i < num_warmup_steps - 2\n-            ]\n-            decreasing_lrs = [\n-                logs[i][\"learning_rate\"] > logs[i + 1][\"learning_rate\"]\n-                for i in range(len(logs) - 1)\n-                if i >= num_warmup_steps - 2\n-            ]\n+        # increasing and decreasing pattern of lrs\n+        increasing_lrs = [\n+            logs[i][\"learning_rate\"] < logs[i + 1][\"learning_rate\"]\n+            for i in range(len(logs))\n+            if i < num_warmup_steps - 2\n+        ]\n+        decreasing_lrs = [\n+            logs[i][\"learning_rate\"] > logs[i + 1][\"learning_rate\"]\n+            for i in range(len(logs) - 1)\n+            if i >= num_warmup_steps - 2\n+        ]\n \n-            self.assertTrue(all(increasing_lrs))\n-            self.assertTrue(all(decreasing_lrs))\n+        self.assertTrue(all(increasing_lrs))\n+        self.assertTrue(all(decreasing_lrs))\n \n-            # warm up steps << total steps\n-            self.assertTrue(len(decreasing_lrs) > len(increasing_lrs))\n+        # warm up steps << total steps\n+        self.assertTrue(len(decreasing_lrs) > len(increasing_lrs))\n \n     @require_torch_multi_accelerator\n     def test_data_is_not_parallelized_when_model_is_parallel(self):\n@@ -2707,200 +2710,197 @@ def test_log_level(self):\n                 self.assertNotIn(log_info_string, cl.out)\n \n     def test_save_checkpoints(self):\n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            trainer = get_regression_trainer(output_dir=tmpdir, save_steps=5)\n-            trainer.train()\n-            self.check_saved_checkpoints(tmpdir, 5, int(self.n_epochs * 64 / self.batch_size))\n+        tmp_dir = self.get_auto_remove_tmp_dir()\n+        trainer = get_regression_trainer(output_dir=tmp_dir, save_steps=5)\n+        trainer.train()\n+        self.check_saved_checkpoints(tmp_dir, 5, int(self.n_epochs * 64 / self.batch_size))\n \n         # With a regular model that is not a PreTrainedModel\n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            trainer = get_regression_trainer(output_dir=tmpdir, save_steps=5, pretrained=False)\n-            trainer.train()\n-            self.check_saved_checkpoints(tmpdir, 5, int(self.n_epochs * 64 / self.batch_size), False)\n+        tmp_dir = self.get_auto_remove_tmp_dir()\n+        trainer = get_regression_trainer(output_dir=tmp_dir, save_steps=5, pretrained=False)\n+        trainer.train()\n+        self.check_saved_checkpoints(tmp_dir, 5, int(self.n_epochs * 64 / self.batch_size), False)\n \n     @require_safetensors\n     def test_safe_checkpoints(self):\n         for save_safetensors in [True, False]:\n-            with tempfile.TemporaryDirectory() as tmpdir:\n-                trainer = get_regression_trainer(output_dir=tmpdir, save_steps=5, save_safetensors=save_safetensors)\n-                trainer.train()\n-                self.check_saved_checkpoints(\n-                    tmpdir, 5, int(self.n_epochs * 64 / self.batch_size), safe_weights=save_safetensors\n-                )\n+            tmp_dir = self.get_auto_remove_tmp_dir()\n+            trainer = get_regression_trainer(output_dir=tmp_dir, save_steps=5, save_safetensors=save_safetensors)\n+            trainer.train()\n+            self.check_saved_checkpoints(\n+                tmp_dir, 5, int(self.n_epochs * 64 / self.batch_size), safe_weights=save_safetensors\n+            )\n \n             # With a regular model that is not a PreTrainedModel\n-            with tempfile.TemporaryDirectory() as tmpdir:\n-                trainer = get_regression_trainer(\n-                    output_dir=tmpdir, save_steps=5, pretrained=False, save_safetensors=save_safetensors\n-                )\n-                trainer.train()\n-                self.check_saved_checkpoints(\n-                    tmpdir, 5, int(self.n_epochs * 64 / self.batch_size), False, safe_weights=save_safetensors\n-                )\n-\n-    def test_load_best_model_with_save(self):\n-        with tempfile.TemporaryDirectory() as tmpdir:\n+            tmp_dir = self.get_auto_remove_tmp_dir()\n             trainer = get_regression_trainer(\n-                output_dir=tmpdir,\n-                save_steps=5,\n-                evaluation_strategy=\"steps\",\n-                eval_steps=5,\n-                max_steps=9,\n+                output_dir=tmp_dir, save_steps=5, pretrained=False, save_safetensors=save_safetensors\n             )\n             trainer.train()\n-            # Check that we have the last known step:\n-            assert os.path.exists(\n-                os.path.join(tmpdir, f\"checkpoint-{trainer.state.max_steps}\")\n-            ), f\"Could not find checkpoint-{trainer.state.max_steps}\"\n-            # And then check the last step\n-            assert os.path.exists(os.path.join(tmpdir, \"checkpoint-9\")), \"Could not find checkpoint-9\"\n+            self.check_saved_checkpoints(\n+                tmp_dir, 5, int(self.n_epochs * 64 / self.batch_size), False, safe_weights=save_safetensors\n+            )\n+\n+    def test_load_best_model_with_save(self):\n+        tmp_dir = self.get_auto_remove_tmp_dir()\n+        trainer = get_regression_trainer(\n+            output_dir=tmp_dir,\n+            save_steps=5,\n+            evaluation_strategy=\"steps\",\n+            eval_steps=5,\n+            max_steps=9,\n+        )\n+        trainer.train()\n+        # Check that we have the last known step:\n+        assert os.path.exists(\n+            os.path.join(tmp_dir, f\"checkpoint-{trainer.state.max_steps}\")\n+        ), f\"Could not find checkpoint-{trainer.state.max_steps}\"\n+        # And then check the last step\n+        assert os.path.exists(os.path.join(tmp_dir, \"checkpoint-9\")), \"Could not find checkpoint-9\"\n \n         # Now test that using a limit works\n         # Should result in:\n         # - save at step 5 (but is deleted)\n         # - save at step 10 (loaded in at the end when `load_best_model=True`)\n         # - save at step 11\n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            trainer = get_regression_trainer(\n-                output_dir=tmpdir,\n-                save_steps=5,\n-                evaluation_strategy=\"steps\",\n-                eval_steps=5,\n-                load_best_model_at_end=True,\n-                save_total_limit=2,\n-                max_steps=11,\n-            )\n-            trainer.train()\n-            # Check that we have the last known step:\n-            assert os.path.exists(os.path.join(tmpdir, \"checkpoint-11\")), \"Could not find checkpoint-11\"\n-            # And then check the last multiple\n-            assert os.path.exists(os.path.join(tmpdir, \"checkpoint-10\")), \"Could not find checkpoint-10\"\n-            # Finally check that we don't have an old one\n-            assert not os.path.exists(os.path.join(tmpdir, \"checkpoint-5\")), \"Found checkpoint-5, limit not respected\"\n-\n-            # Finally check that the right model was loaded in, checkpoint-10\n-            # this goes by the last `eval` step check to do so, so it won't be\n-            # the last model *saved*\n-            model_state = trainer.model.state_dict()\n-            final_model_weights = safetensors.torch.load_file(\n-                os.path.join(tmpdir, \"checkpoint-10\", \"model.safetensors\")\n-            )\n-            for k, v in model_state.items():\n-                assert torch.allclose(v, final_model_weights[k]), f\"{k} is not the same\"\n+        tmp_dir = self.get_auto_remove_tmp_dir()\n+        trainer = get_regression_trainer(\n+            output_dir=tmp_dir,\n+            save_steps=5,\n+            evaluation_strategy=\"steps\",\n+            eval_steps=5,\n+            load_best_model_at_end=True,\n+            save_total_limit=2,\n+            max_steps=11,\n+        )\n+        trainer.train()\n+        # Check that we have the last known step:\n+        assert os.path.exists(os.path.join(tmp_dir, \"checkpoint-11\")), \"Could not find checkpoint-11\"\n+        # And then check the last multiple\n+        assert os.path.exists(os.path.join(tmp_dir, \"checkpoint-10\")), \"Could not find checkpoint-10\"\n+        # Finally check that we don't have an old one\n+        assert not os.path.exists(os.path.join(tmp_dir, \"checkpoint-5\")), \"Found checkpoint-5, limit not respected\"\n+\n+        # Finally check that the right model was loaded in, checkpoint-10\n+        # this goes by the last `eval` step check to do so, so it won't be\n+        # the last model *saved*\n+        model_state = trainer.model.state_dict()\n+        final_model_weights = safetensors.torch.load_file(os.path.join(tmp_dir, \"checkpoint-10\", \"model.safetensors\"))\n+        for k, v in model_state.items():\n+            assert torch.allclose(v, final_model_weights[k]), f\"{k} is not the same\"\n \n     @require_torch_multi_accelerator\n     def test_run_seq2seq_double_train_wrap_once(self):\n         # test that we don't wrap the model more than once\n         # since wrapping primarily happens on multi-gpu setup we want multiple gpus to test for\n         # example DataParallel(DataParallel(model))\n \n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            trainer = get_regression_trainer(output_dir=tmp_dir)\n-            trainer.train()\n-            model_wrapped_before = trainer.model_wrapped\n-            trainer.train()\n-            model_wrapped_after = trainer.model_wrapped\n-            self.assertIs(model_wrapped_before, model_wrapped_after, \"should be not wrapped twice\")\n+        trainer = get_regression_trainer(output_dir=self.get_auto_remove_tmp_dir())\n+        trainer.train()\n+        model_wrapped_before = trainer.model_wrapped\n+        trainer.train()\n+        model_wrapped_after = trainer.model_wrapped\n+        self.assertIs(model_wrapped_before, model_wrapped_after, \"should be not wrapped twice\")\n \n     @require_torch_up_to_2_accelerators\n     def test_can_resume_training(self):\n         # This test will fail for more than 2 GPUs since the batch size will get bigger and with the number of\n         # save_steps, the checkpoint will resume training at epoch 2 or more (so the data seen by the model\n         # won't be the same since the training dataloader is shuffled).\n \n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            kwargs = {\n-                \"output_dir\": tmpdir,\n-                \"train_len\": 128,\n-                \"save_steps\": 5,\n-                \"learning_rate\": 0.1,\n-                \"logging_steps\": 5,\n-            }\n-            trainer = get_regression_trainer(**kwargs)\n-            trainer.train()\n-            (a, b) = trainer.model.a.item(), trainer.model.b.item()\n-            state = dataclasses.asdict(trainer.state)\n+        tmp_dir = self.get_auto_remove_tmp_dir()\n+        kwargs = {\n+            \"output_dir\": tmp_dir,\n+            \"train_len\": 128,\n+            \"save_steps\": 5,\n+            \"learning_rate\": 0.1,\n+            \"logging_steps\": 5,\n+        }\n+        trainer = get_regression_trainer(**kwargs)\n+        trainer.train()\n+        (a, b) = trainer.model.a.item(), trainer.model.b.item()\n+        state = dataclasses.asdict(trainer.state)\n \n-            checkpoint = os.path.join(tmpdir, \"checkpoint-5\")\n+        checkpoint = os.path.join(tmp_dir, \"checkpoint-5\")\n \n-            # Reinitialize trainer\n-            trainer = get_regression_trainer(**kwargs)\n+        # Reinitialize trainer\n+        trainer = get_regression_trainer(**kwargs)\n \n-            trainer.train(resume_from_checkpoint=checkpoint)\n-            (a1, b1) = trainer.model.a.item(), trainer.model.b.item()\n-            state1 = dataclasses.asdict(trainer.state)\n-            self.assertEqual(a, a1)\n-            self.assertEqual(b, b1)\n-            self.check_trainer_state_are_the_same(state, state1)\n+        trainer.train(resume_from_checkpoint=checkpoint)\n+        (a1, b1) = trainer.model.a.item(), trainer.model.b.item()\n+        state1 = dataclasses.asdict(trainer.state)\n+        self.assertEqual(a, a1)\n+        self.assertEqual(b, b1)\n+        self.check_trainer_state_are_the_same(state, state1)\n \n-            # Now check with a later checkpoint that it also works when we span over one epoch\n-            checkpoint = os.path.join(tmpdir, \"checkpoint-15\")\n+        # Now check with a later checkpoint that it also works when we span over one epoch\n+        checkpoint = os.path.join(tmp_dir, \"checkpoint-15\")\n \n-            # Reinitialize trainer and load model\n-            trainer = get_regression_trainer(**kwargs)\n+        # Reinitialize trainer and load model\n+        trainer = get_regression_trainer(**kwargs)\n \n-            trainer.train(resume_from_checkpoint=checkpoint)\n-            (a1, b1) = trainer.model.a.item(), trainer.model.b.item()\n-            state1 = dataclasses.asdict(trainer.state)\n-            self.assertEqual(a, a1)\n-            self.assertEqual(b, b1)\n-            self.check_trainer_state_are_the_same(state, state1)\n+        trainer.train(resume_from_checkpoint=checkpoint)\n+        (a1, b1) = trainer.model.a.item(), trainer.model.b.item()\n+        state1 = dataclasses.asdict(trainer.state)\n+        self.assertEqual(a, a1)\n+        self.assertEqual(b, b1)\n+        self.check_trainer_state_are_the_same(state, state1)\n \n         # With a regular model that is not a PreTrainedModel\n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            kwargs = {\n-                \"output_dir\": tmpdir,\n-                \"train_len\": 128,\n-                \"save_steps\": 5,\n-                \"learning_rate\": 0.1,\n-                \"pretrained\": False,\n-            }\n+        tmp_dir = self.get_auto_remove_tmp_dir()\n+        kwargs = {\n+            \"output_dir\": tmp_dir,\n+            \"train_len\": 128,\n+            \"save_steps\": 5,\n+            \"learning_rate\": 0.1,\n+            \"pretrained\": False,\n+        }\n \n-            trainer = get_regression_trainer(**kwargs)\n-            trainer.train()\n-            (a, b) = trainer.model.a.item(), trainer.model.b.item()\n-            state = dataclasses.asdict(trainer.state)\n+        trainer = get_regression_trainer(**kwargs)\n+        trainer.train()\n+        (a, b) = trainer.model.a.item(), trainer.model.b.item()\n+        state = dataclasses.asdict(trainer.state)\n \n-            checkpoint = os.path.join(tmpdir, \"checkpoint-5\")\n+        checkpoint = os.path.join(tmp_dir, \"checkpoint-5\")\n \n-            # Reinitialize trainer and load model\n-            trainer = get_regression_trainer(**kwargs)\n+        # Reinitialize trainer and load model\n+        trainer = get_regression_trainer(**kwargs)\n \n-            trainer.train(resume_from_checkpoint=checkpoint)\n-            (a1, b1) = trainer.model.a.item(), trainer.model.b.item()\n-            state1 = dataclasses.asdict(trainer.state)\n-            self.assertEqual(a, a1)\n-            self.assertEqual(b, b1)\n-            self.check_trainer_state_are_the_same(state, state1)\n+        trainer.train(resume_from_checkpoint=checkpoint)\n+        (a1, b1) = trainer.model.a.item(), trainer.model.b.item()\n+        state1 = dataclasses.asdict(trainer.state)\n+        self.assertEqual(a, a1)\n+        self.assertEqual(b, b1)\n+        self.check_trainer_state_are_the_same(state, state1)\n \n-            # Now check with a later checkpoint that it also works when we span over one epoch\n-            checkpoint = os.path.join(tmpdir, \"checkpoint-15\")\n+        # Now check with a later checkpoint that it also works when we span over one epoch\n+        checkpoint = os.path.join(tmp_dir, \"checkpoint-15\")\n \n-            # Reinitialize trainer and load model\n-            trainer = get_regression_trainer(**kwargs)\n+        # Reinitialize trainer and load model\n+        trainer = get_regression_trainer(**kwargs)\n \n-            trainer.train(resume_from_checkpoint=checkpoint)\n-            (a1, b1) = trainer.model.a.item(), trainer.model.b.item()\n-            state1 = dataclasses.asdict(trainer.state)\n-            self.assertEqual(a, a1)\n-            self.assertEqual(b, b1)\n-            self.check_trainer_state_are_the_same(state, state1)\n+        trainer.train(resume_from_checkpoint=checkpoint)\n+        (a1, b1) = trainer.model.a.item(), trainer.model.b.item()\n+        state1 = dataclasses.asdict(trainer.state)\n+        self.assertEqual(a, a1)\n+        self.assertEqual(b, b1)\n+        self.check_trainer_state_are_the_same(state, state1)\n \n         # Now check failures\n \n         # 1. fail to find a bogus checkpoint\n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            trainer = get_regression_trainer(output_dir=tmpdir)\n-            with self.assertRaises(Exception) as context:\n-                trainer.train(resume_from_checkpoint=f\"{checkpoint}-bogus\")\n-            self.assertTrue(\"Can't find a valid checkpoint at\" in str(context.exception))\n+        tmp_dir = self.get_auto_remove_tmp_dir()\n+        trainer = get_regression_trainer(output_dir=tmp_dir)\n+        with self.assertRaises(Exception) as context:\n+            trainer.train(resume_from_checkpoint=f\"{checkpoint}-bogus\")\n+        self.assertTrue(\"Can't find a valid checkpoint at\" in str(context.exception))\n \n         # 2. fail to find any checkpoint - due a fresh output_dir\n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            trainer = get_regression_trainer(output_dir=tmpdir)\n-            with self.assertRaises(Exception) as context:\n-                trainer.train(resume_from_checkpoint=True)\n-            self.assertTrue(\"No valid checkpoint found in output directory\" in str(context.exception))\n+        tmp_dir = self.get_auto_remove_tmp_dir()\n+        trainer = get_regression_trainer(output_dir=tmp_dir)\n+        with self.assertRaises(Exception) as context:\n+            trainer.train(resume_from_checkpoint=True)\n+        self.assertTrue(\"No valid checkpoint found in output directory\" in str(context.exception))\n \n     @unittest.skip(\n         reason=\"@muellerzr: Fix once Trainer can take an accelerate configuration. Need to set `seedable_sampler=True`.\""
        }
    ],
    "stats": {
        "total": 1272,
        "additions": 644,
        "deletions": 628
    }
}