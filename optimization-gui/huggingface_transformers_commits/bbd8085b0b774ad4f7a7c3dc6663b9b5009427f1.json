{
    "author": "zucchini-nlp",
    "message": "Fix processor chat template (#40613)\n\nfix tests",
    "sha": "bbd8085b0b774ad4f7a7c3dc6663b9b5009427f1",
    "files": [
        {
            "sha": "c7b0ab247abb89ed99172093c800291e2d6d9d62",
            "filename": "src/transformers/processing_utils.py",
            "status": "modified",
            "additions": 7,
            "deletions": 4,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/bbd8085b0b774ad4f7a7c3dc6663b9b5009427f1/src%2Ftransformers%2Fprocessing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bbd8085b0b774ad4f7a7c3dc6663b9b5009427f1/src%2Ftransformers%2Fprocessing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fprocessing_utils.py?ref=bbd8085b0b774ad4f7a7c3dc6663b9b5009427f1",
            "patch": "@@ -1572,6 +1572,7 @@ def apply_chat_template(\n             batch_images, batch_videos = [], []\n             batch_audios = []\n             for conversation in conversations:\n+                images, videos = [], []\n                 for message in conversation:\n                     visuals = [content for content in message[\"content\"] if content[\"type\"] in [\"image\", \"video\"]]\n                     audio_fnames = [\n@@ -1586,12 +1587,14 @@ def apply_chat_template(\n                         for key in [\"image\", \"url\", \"path\", \"base64\"]\n                         if key in vision_info and vision_info[\"type\"] == \"image\"\n                     ]\n+                    images.extend(image_fnames)\n                     video_fnames = [\n                         vision_info[key]\n                         for vision_info in visuals\n                         for key in [\"video\", \"url\", \"path\"]\n                         if key in vision_info and vision_info[\"type\"] == \"video\"\n                     ]\n+                    videos.extend(video_fnames)\n \n                     # Audio models do not accept nested list of audios (yet!) so we construct a flat input audio list\n                     if not mm_load_kwargs[\"load_audio_from_video\"]:\n@@ -1601,10 +1604,10 @@ def apply_chat_template(\n                         for fname in video_fnames:\n                             batch_audios.append(load_audio(fname, sampling_rate=mm_load_kwargs[\"sampling_rate\"]))\n \n-                    # Currently all processors can accept nested list of batches, but not flat list of visuals\n-                    # So we'll make a batched list of images and let the processor handle it\n-                    batch_images.append(image_fnames)\n-                    batch_videos.append(video_fnames)\n+                # Currently all processors can accept nested list of batches, but not flat list of visuals\n+                # So we'll make a batched list of images and let the processor handle it\n+                batch_images.append(images)\n+                batch_videos.append(videos)\n \n         prompt, generation_indices = render_jinja_template(\n             conversations=conversations,"
        },
        {
            "sha": "e3a692c25455a93b21f9b0b54a10dbbaa057e13c",
            "filename": "tests/test_processing_common.py",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/bbd8085b0b774ad4f7a7c3dc6663b9b5009427f1/tests%2Ftest_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bbd8085b0b774ad4f7a7c3dc6663b9b5009427f1/tests%2Ftest_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_processing_common.py?ref=bbd8085b0b774ad4f7a7c3dc6663b9b5009427f1",
            "patch": "@@ -1003,10 +1003,8 @@ def _test_apply_chat_template(\n \n         batch_messages = [\n             [\n-                {\n-                    \"role\": \"user\",\n-                    \"content\": [{\"type\": \"text\", \"text\": \"Describe this.\"}],\n-                },\n+                {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]},\n+                {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"Describe this.\"}]},\n             ]\n         ] * batch_size\n \n@@ -1053,7 +1051,7 @@ def _test_apply_chat_template(\n \n         # Test that with modality URLs and `return_dict=True`, we get modality inputs in the dict\n         for idx, url in enumerate(input_data[:batch_size]):\n-            batch_messages[idx][0][\"content\"] = [batch_messages[idx][0][\"content\"][0], {\"type\": modality, \"url\": url}]\n+            batch_messages[idx][1][\"content\"] = [batch_messages[idx][1][\"content\"][0], {\"type\": modality, \"url\": url}]\n \n         out_dict = processor.apply_chat_template(\n             batch_messages,"
        }
    ],
    "stats": {
        "total": 19,
        "additions": 10,
        "deletions": 9
    }
}