{
    "author": "Abdennacer-Badaoui",
    "message": "[CI] Fixing some AMD failures (#42879)\n\n* fix qwen2 & qwen2_5_omni\n\n* one more fix\n\n* fix qwen2_5_vl\n\n* fix\n\n* fix some more failures on nvidia",
    "sha": "c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f",
    "files": [
        {
            "sha": "e3750d853e481b1e6a33d9cce8733d2e1954cb87",
            "filename": "src/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fmodeling_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fmodeling_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fmodeling_qwen2_5_omni.py?ref=c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f",
            "patch": "@@ -2459,7 +2459,11 @@ def forward(\n                 self.rope_deltas = rope_deltas\n \n             else:\n-                batch_size, seq_length, _ = inputs_embeds.shape\n+                if inputs_embeds is not None:\n+                    batch_size, seq_length, _ = inputs_embeds.shape\n+                else:\n+                    batch_size, seq_length = input_ids.shape\n+\n                 delta = (past_key_values_length + self.rope_deltas).to(input_ids.device)\n                 position_ids = torch.arange(seq_length, device=input_ids.device)\n                 position_ids = position_ids.view(1, -1).expand(batch_size, -1)"
        },
        {
            "sha": "9411f91f86cb1dc093394495a06a6afe2aac6bdb",
            "filename": "src/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fmodular_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fmodular_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fmodular_qwen2_5_omni.py?ref=c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f",
            "patch": "@@ -2615,7 +2615,11 @@ def forward(\n                 self.rope_deltas = rope_deltas\n \n             else:\n-                batch_size, seq_length, _ = inputs_embeds.shape\n+                if inputs_embeds is not None:\n+                    batch_size, seq_length, _ = inputs_embeds.shape\n+                else:\n+                    batch_size, seq_length = input_ids.shape\n+\n                 delta = (past_key_values_length + self.rope_deltas).to(input_ids.device)\n                 position_ids = torch.arange(seq_length, device=input_ids.device)\n                 position_ids = position_ids.view(1, -1).expand(batch_size, -1)"
        },
        {
            "sha": "e1c2f4e6aa79ed5dd12477710713a37570fa29b8",
            "filename": "tests/models/qwen2/test_modeling_qwen2.py",
            "status": "modified",
            "additions": 5,
            "deletions": 9,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py?ref=c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f",
            "patch": "@@ -78,11 +78,10 @@ def test_model_450m_logits(self):\n         with torch.no_grad():\n             out = model(input_ids).logits.float().cpu()\n         # Expected mean on dim = -1\n-        EXPECTED_MEAN = torch.tensor([[-1.9537, -1.6193, -1.4123, -1.4673, -1.8511, -1.9309, -1.9826, -2.1776]])\n+        EXPECTED_MEAN = torch.tensor([[-2.2121, -1.6335, -1.4816, -1.5035, -1.9110, -1.8979, -1.9682, -2.1980]])\n         torch.testing.assert_close(out.mean(-1), EXPECTED_MEAN, rtol=1e-2, atol=1e-2)\n         # slicing logits[0, 0, 0:30]\n-        EXPECTED_SLICE = torch.tensor([3.2025, 7.1265, 4.6058, 3.6423, 1.6357, 3.9265, 5.1883, 5.8760, 2.7942, 4.4823, 3.2571, 2.1063, 3.4275, 4.2028, 1.9767, 5.2115, 6.6756, 6.3999, 6.0483, 5.7378, 5.6660, 5.2298, 5.4103, 5.1248, 5.4376, 2.4570, 2.6107, 5.4039, 2.8077, 4.7777])  # fmt: skip\n-        print(out[0, 0, :30])\n+        EXPECTED_SLICE = torch.tensor([2.7344, 4.2812, 4.1562, 2.3906, 1.1875, 2.1562, 3.1719, 3.1406, 1.2891, 3.6094, 3.3125, 1.8203, 2.9219, 3.2344, 1.5938, 6.2500, 7.4062, 7.2188, 6.5938, 6.0312, 6.1562, 5.3750, 5.9688, 5.5938, 6.1250, 1.2656, 1.6016, 3.4062, 1.7891, 3.6406])  # fmt: skip\n         torch.testing.assert_close(out[0, 0, :30], EXPECTED_SLICE, rtol=1e-4, atol=1e-4)\n \n         del model\n@@ -92,7 +91,7 @@ def test_model_450m_logits(self):\n     @slow\n     def test_model_450m_generation(self):\n         EXPECTED_TEXT_COMPLETION = (\n-            \"\"\"My favourite condiment is 100% natural, organic and vegan. I love to use it in my cooking and I\"\"\"\n+            \"\"\"My favourite condiment is 100% natural, organic and vegan. I love to use it in my cooking, but\"\"\"\n         )\n         prompt = \"My favourite condiment is \"\n         tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\", use_fast=False)\n@@ -161,7 +160,7 @@ def test_model_450m_long_prompt_sdpa(self):\n         gc.collect()\n \n         EXPECTED_TEXT_COMPLETION = (\n-            \"My favourite condiment is 100% natural, organic and vegan. I love to use it in my cooking and I\"\n+            \"My favourite condiment is 100% natural, organic and vegan. I love to use it in my cooking, but\"\n         )\n         prompt = \"My favourite condiment is \"\n         tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\", use_fast=False)\n@@ -211,11 +210,8 @@ def test_export_static_cache(self):\n         tokenizer = AutoTokenizer.from_pretrained(qwen_model, pad_token=\"</s>\", padding_side=\"right\")\n \n         expected_text_completions = Expectations({\n-            (\"cuda\", None): [\n-                \"My favourite condiment is 100% natural, organic, gluten free, vegan, and free from preservatives. I\"\n-            ],\n             (\"cuda\", 8): [\n-                \"My favourite condiment is 100% natural, organic, gluten free, vegan, and vegetarian. I love to use\"\n+                \"My favourite condiment is 100% natural, organic, gluten free, vegan, and free from preservatives. I\"\n             ],\n             (\"rocm\", (9, 4)): [\n                 \"My favourite condiment is 100% natural, organic and vegan. I love to use it in my cooking, but\""
        },
        {
            "sha": "ab094e35d2991b7ecba43000be030b125350517a",
            "filename": "tests/models/qwen2_5_omni/test_modeling_qwen2_5_omni.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_modeling_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_modeling_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_modeling_qwen2_5_omni.py?ref=c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f",
            "patch": "@@ -684,7 +684,7 @@ def test_small_model_integration_test(self):\n \n         EXPECTED_DECODED_TEXT = Expectations({\n             (\"xpu\", None): \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is glass shattering, and the dog is a Labrador Retriever.\",\n-            (\"cuda\", (8, 6)): \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is glass shattering, and the dog is a Labrador Retriever.\",\n+            (\"cuda\", (8, 6)): \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is a glass shattering. The dog in the picture is a Labrador Retriever.\",\n             (\"rocm\", (9, 4)): \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is glass shattering, and the dog is a Labrador Retriever.\",\n         }).get_expectation()  # fmt: skip\n \n@@ -720,11 +720,11 @@ def test_small_model_integration_test_batch(self):\n                     \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is of glass shattering, and the dog in the picture is a Labrador Retriever\",\n                 ],\n                 (\"cuda\", 8): [\n-                    \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is glass shattering, and the dog is a Labrador Retriever.\",\n-                    \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is glass shattering, and the dog is a Labrador Retriever.\",\n+                    \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is a glass shattering. The dog in the picture is a Labrador Retriever.\",\n+                    \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is a glass shattering. The dog in the picture is a Labrador Retriever.\",\n                 ],\n                 (\"rocm\", (9, 4)): [\n-                    \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is glass shattering, and the dog is a Labrador Retriever.\",\n+                    \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is a glass shattering. The dog in the picture is a Labrador Retriever.\",\n                     \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is glass shattering, and the dog is a Labrador Retriever.\",\n                 ],\n             }"
        },
        {
            "sha": "8b707329a74d006e2be3fd5d35058296bdbf52fc",
            "filename": "tests/models/qwen2_5_vl/test_modeling_qwen2_5_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py?ref=c154b0218ab78c2df076ab8cf4a7bde1cd2bf40f",
            "patch": "@@ -572,8 +572,8 @@ def test_small_model_integration_test_batch_different_resolutions(self):\n                     \"system\\nYou are a helpful assistant.\\nuser\\nWhat kind of dog is this?\\nassistant\\n addCriterion\\nThe dog in the picture appears to be a Labrador Retriever. Labradors are known for their friendly and gentle nature, which is\",\n                 ],\n                 (\"cuda\", (8, 6)): [\n-                    'system\\nYou are a helpful assistant.\\nuser\\nWhat kind of dog is this?\\nassistant\\nThe dog in the picture appears to be a Labrador Retriever. Labradors are known for their friendly and energetic nature, which is evident in',\n-                    'system\\nYou are a helpful assistant.\\nuser\\nWhat kind of dog is this?\\nassistant\\nThe dog in the picture appears to be a Labrador Retriever. Labradors are known for their friendly and energetic nature, which is evident in',\n+                    'system\\nYou are a helpful assistant.\\nuser\\nWhat kind of dog is this?\\nassistant\\n addCriterion\\nThe dog in the picture appears to be a Labrador Retriever. Labradors are known for their friendly and gentle nature, which is',\n+                    'system\\nYou are a helpful assistant.\\nuser\\nWhat kind of dog is this?\\nassistant\\n addCriterion\\nThe dog in the picture appears to be a Labrador Retriever. Labradors are known for their friendly and gentle nature, which is',\n                 ],\n                 (\"rocm\", None): [\n                     'system\\nYou are a helpful assistant.\\nuser\\nWhat kind of dog is this?\\nassistant\\nThe dog in the picture appears to be a Labrador Retriever. Labradors are known for their friendly and energetic nature, which is evident in',\n@@ -706,7 +706,7 @@ def test_small_model_integration_test_with_video(self):\n         output = model.generate(**inputs, max_new_tokens=30)\n \n         EXPECTED_DECODED_TEXT = [\n-            'system\\nYou are a helpful assistant.\\nuser\\nWhat is shown in this video?\\nassistant\\nThe video shows an indoor tennis court with a person standing on one side, preparing to serve the ball. The individual is dressed in athletic attire, including',\n+            'system\\nYou are a helpful assistant.\\nuser\\nWhat is shown in this video?\\nassistant\\nThe video shows an indoor tennis court with a player standing on the baseline, preparing to serve. The player is wearing a white shirt and black shorts,',\n         ]  # fmt: skip\n         self.assertEqual(\n             self.processor.batch_decode(output, skip_special_tokens=True),"
        }
    ],
    "stats": {
        "total": 40,
        "additions": 22,
        "deletions": 18
    }
}