{
    "author": "zhanluxianshen",
    "message": "Reuse \"if not\" logic in image_processing. (#35405)",
    "sha": "1fe2d53d4ebdab22a7e30ed6de5816049898953d",
    "files": [
        {
            "sha": "a6ce7af3fa8076958d4a4ac87ca3ab13716c7955",
            "filename": "src/transformers/image_processing_base.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/1fe2d53d4ebdab22a7e30ed6de5816049898953d/src%2Ftransformers%2Fimage_processing_base.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1fe2d53d4ebdab22a7e30ed6de5816049898953d/src%2Ftransformers%2Fimage_processing_base.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fimage_processing_base.py?ref=1fe2d53d4ebdab22a7e30ed6de5816049898953d",
            "patch": "@@ -381,8 +381,6 @@ def get_image_processor_dict(\n             logger.info(\n                 f\"loading configuration file {image_processor_file} from cache at {resolved_image_processor_file}\"\n             )\n-\n-        if not is_local:\n             if \"auto_map\" in image_processor_dict:\n                 image_processor_dict[\"auto_map\"] = add_model_info_to_auto_map(\n                     image_processor_dict[\"auto_map\"], pretrained_model_name_or_path\n@@ -391,6 +389,7 @@ def get_image_processor_dict(\n                 image_processor_dict[\"custom_pipelines\"] = add_model_info_to_custom_pipelines(\n                     image_processor_dict[\"custom_pipelines\"], pretrained_model_name_or_path\n                 )\n+\n         return image_processor_dict, kwargs\n \n     @classmethod"
        }
    ],
    "stats": {
        "total": 3,
        "additions": 1,
        "deletions": 2
    }
}