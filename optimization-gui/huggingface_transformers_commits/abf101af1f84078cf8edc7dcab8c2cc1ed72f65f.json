{
    "author": "Cyrilvallez",
    "message": "Fix version issue in modeling_utils.py (#39759)\n\nfix version issue",
    "sha": "abf101af1f84078cf8edc7dcab8c2cc1ed72f65f",
    "files": [
        {
            "sha": "4d21b0a556879c08725674aa09240a6ed1d65866",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/abf101af1f84078cf8edc7dcab8c2cc1ed72f65f/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/abf101af1f84078cf8edc7dcab8c2cc1ed72f65f/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=abf101af1f84078cf8edc7dcab8c2cc1ed72f65f",
            "patch": "@@ -2881,9 +2881,7 @@ def _init_weights(self, module):\n         # We cannot use `isinstance` on the RMSNorms or LayerNorms, as they usually are custom modules which change names\n         # between modelings (because they are prefixed with the model name)\n         elif (\n-            isinstance(\n-                module, (nn.LayerNorm, nn.RMSNorm, nn.GroupNorm, nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)\n-            )\n+            isinstance(module, (nn.GroupNorm, nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d))\n             or \"LayerNorm\" in module.__class__.__name__\n             or \"RMSNorm\" in module.__class__.__name__\n         ):"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 1,
        "deletions": 3
    }
}