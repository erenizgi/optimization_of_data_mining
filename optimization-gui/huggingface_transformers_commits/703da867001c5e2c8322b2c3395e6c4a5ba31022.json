{
    "author": "yonigozlan",
    "message": "Fix add_dates script: Fetch github repo from url to check if model is new (#42878)\n\nFetch github repo from url to check if model is new",
    "sha": "703da867001c5e2c8322b2c3395e6c4a5ba31022",
    "files": [
        {
            "sha": "79c3dea96eb0adc515056a9e724fcbaf1b9f10cc",
            "filename": "docs/source/en/model_doc/paddleocr_vl.md",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/703da867001c5e2c8322b2c3395e6c4a5ba31022/docs%2Fsource%2Fen%2Fmodel_doc%2Fpaddleocr_vl.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/703da867001c5e2c8322b2c3395e6c4a5ba31022/docs%2Fsource%2Fen%2Fmodel_doc%2Fpaddleocr_vl.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fpaddleocr_vl.md?ref=703da867001c5e2c8322b2c3395e6c4a5ba31022",
            "patch": "@@ -13,7 +13,7 @@ specific language governing permissions and limitations under the License.\n rendered properly in your Markdown viewer.\n \n -->\n-*This model was released on 2025.10.16 and added to Hugging Face Transformers on 2025.12.10*\n+*This model was released on 2025-10-16 and added to Hugging Face Transformers on 2025-12-10.*\n \n # PaddleOCR-VL\n \n@@ -27,7 +27,7 @@ rendered properly in your Markdown viewer.\n \n **Huggingface Hub**: [PaddleOCR-VL](https://huggingface.co/collections/PaddlePaddle/paddleocr-vl) | **Github Repo**: [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR)\n \n-**Official Website**: [Baidu AI Studio](https://aistudio.baidu.com/paddleocr) | **arXiv**: [Technical Report](https://arxiv.org/pdf/2510.14528)\n+**Official Website**: [Baidu AI Studio](https://aistudio.baidu.com/paddleocr) | **arXiv**: [Technical Report](https://huggingface.co/papers/2510.14528)\n \n **PaddleOCR-VL** is a SOTA and resource-efficient model tailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a compact yet powerful vision-language model (VLM) that integrates a NaViT-style dynamic resolution visual encoder with the ERNIE-4.5-0.3B language model to enable accurate element recognition. This innovative model efficiently supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption. Through comprehensive evaluations on widely used public benchmarks and in-house benchmarks, PaddleOCR-VL achieves SOTA performance in both page-level document parsing and element-level recognition. It significantly outperforms existing solutions, exhibits strong competitiveness against top-tier VLMs, and delivers fast inference speeds. These strengths make it highly suitable for practical deployment in real-world scenarios.\n \n@@ -43,7 +43,7 @@ rendered properly in your Markdown viewer.\n \n 3. **Multilingual Support:** PaddleOCR-VL Supports 109 languages, covering major global languages, including but not limited to Chinese, English, Japanese, Latin, and Korean, as well as languages with different scripts and structures, such as Russian (Cyrillic script), Arabic, Hindi (Devanagari script), and Thai. This broad language coverage substantially enhances the applicability of our system to multilingual and globalized document processing scenarios.\n \n-### **Model Architecture** \n+### **Model Architecture**\n \n <div align=\"center\">\n <img src=\"https://huggingface.co/datasets/PaddlePaddle/PaddleOCR-VL_demo/resolve/main/imgs/paddleocrvl.png\" width=\"800\"/>\n@@ -54,7 +54,7 @@ rendered properly in your Markdown viewer.\n ### Usage tips\n \n > [!IMPORTANT]\n-> We currently recommend using the [PaddleOCR official method for inference](https://www.paddleocr.ai/latest/en/version3.x/pipeline_usage/PaddleOCR-VL.html), as it is faster and supports page-level document parsing. \n+> We currently recommend using the [PaddleOCR official method for inference](https://www.paddleocr.ai/latest/en/version3.x/pipeline_usage/PaddleOCR-VL.html), as it is faster and supports page-level document parsing.\n > The example code below only supports element-level recognition.\n \n We have four types of element-level recognition:"
        },
        {
            "sha": "5a77935ccca853e812a7cd9d1a25d2b0b404e923",
            "filename": "utils/add_dates.py",
            "status": "modified",
            "additions": 59,
            "deletions": 8,
            "changes": 67,
            "blob_url": "https://github.com/huggingface/transformers/blob/703da867001c5e2c8322b2c3395e6c4a5ba31022/utils%2Fadd_dates.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/703da867001c5e2c8322b2c3395e6c4a5ba31022/utils%2Fadd_dates.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fadd_dates.py?ref=703da867001c5e2c8322b2c3395e6c4a5ba31022",
            "patch": "@@ -3,13 +3,17 @@\n import re\n import subprocess\n from datetime import date, datetime\n+from urllib.error import HTTPError\n+from urllib.request import Request, urlopen\n \n from huggingface_hub import paper_info\n \n \n ROOT = os.getcwd().split(\"utils\")[0]\n DOCS_PATH = os.path.join(ROOT, \"docs/source/en/model_doc\")\n MODELS_PATH = os.path.join(ROOT, \"src/transformers/models\")\n+GITHUB_REPO_URL = \"https://github.com/huggingface/transformers\"\n+GITHUB_RAW_URL = \"https://raw.githubusercontent.com/huggingface/transformers/main\"\n \n COPYRIGHT_DISCLAIMER = \"\"\"<!--Copyright 2025 The HuggingFace Team. All rights reserved.\n \n@@ -33,6 +37,53 @@\n }\n \n \n+def check_file_exists_on_github(file_path: str) -> bool:\n+    \"\"\"Check if a file exists on the main branch of the GitHub repository.\n+\n+    Args:\n+        file_path: Relative path from repository root\n+\n+    Returns:\n+        True if file exists on GitHub main branch (or if check failed), False only if confirmed 404\n+\n+    Note:\n+        On network errors or other issues, returns True (assumes file exists) with a warning.\n+        This prevents the script from failing due to temporary network issues.\n+    \"\"\"\n+    # Convert absolute path to relative path from repository root if needed\n+    if file_path.startswith(ROOT):\n+        file_path = file_path[len(ROOT) :].lstrip(\"/\")\n+\n+    # Construct the raw GitHub URL for the file\n+    url = f\"{GITHUB_RAW_URL}/{file_path}\"\n+\n+    try:\n+        # Make a HEAD request to check if file exists (more efficient than GET)\n+        request = Request(url, method=\"HEAD\")\n+        request.add_header(\"User-Agent\", \"transformers-add-dates-script\")\n+\n+        with urlopen(request, timeout=10) as response:\n+            return response.status == 200\n+    except HTTPError as e:\n+        if e.code == 404:\n+            # File doesn't exist on GitHub\n+            return False\n+        # Fall through to generic exception handler for other HTTP errors\n+        print(\n+            f\"Warning: Could not verify file existence on GitHub (HTTP {e.code}): {url}\\n\"\n+            f\"Assuming file exists and continuing with local git history.\"\n+        )\n+        return True\n+    except Exception as e:\n+        # Handle all other errors (network issues, timeouts, etc.)\n+        print(\n+            f\"Warning: Could not verify file existence on GitHub: {url}\\n\"\n+            f\"Error: {e}\\n\"\n+            f\"Assuming file exists and continuing with local git history.\"\n+        )\n+        return True\n+\n+\n def get_modified_cards() -> list[str]:\n     \"\"\"Get the list of model names from modified files in docs/source/en/model_doc/\"\"\"\n \n@@ -105,15 +156,15 @@ def get_first_commit_date(model_name: str | None) -> str:\n     if not os.path.exists(file_path):\n         file_path = os.path.join(DOCS_PATH, f\"{model_name}.md\")\n \n-    # Check if file exists in upstream/main\n-    result_main = subprocess.check_output(\n-        [\"git\", \"ls-tree\", \"upstream/main\", \"--\", file_path], text=True, stderr=subprocess.DEVNULL\n-    )\n-    if not result_main:\n-        # File does not exist in upstream/main (new model), use today's date\n+    # Check if file exists on GitHub main branch\n+    file_exists_on_github = check_file_exists_on_github(file_path)\n+\n+    if not file_exists_on_github:\n+        # File does not exist on GitHub main branch (new model), use today's date\n+        print(f\"Model {model_name} not found on GitHub main branch, using today's date\")\n         final_date = date.today().isoformat()\n     else:\n-        # File exists in upstream/main, get the first commit date\n+        # File exists on GitHub main branch, get the first commit date from local git history\n         final_date = subprocess.check_output(\n             [\"git\", \"log\", \"--reverse\", \"--pretty=format:%ad\", \"--date=iso\", file_path], text=True\n         )\n@@ -292,7 +343,7 @@ def insert_dates(model_card_list: list[str]):\n             if existing_release_date not in (r\"{release_date}\", \"None\"):\n                 release_date = existing_release_date\n \n-            if existing_hf_date != hf_commit_date or existing_release_date != release_date:\n+            if _dates_differ_significantly(existing_hf_date, hf_commit_date) or existing_release_date != release_date:\n                 old_line = match.group(0)\n                 new_line = f\"\\n*This model was released on {release_date} and added to Hugging Face Transformers on {hf_commit_date}.*\"\n                 content = content.replace(old_line, new_line)"
        }
    ],
    "stats": {
        "total": 75,
        "additions": 63,
        "deletions": 12
    }
}