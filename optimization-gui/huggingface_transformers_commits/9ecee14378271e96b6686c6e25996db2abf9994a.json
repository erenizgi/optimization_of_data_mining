{
    "author": "faaany",
    "message": "[doc] fix bugs in `how_to_hack_models.md` (#38198)\n\nfix several bugs",
    "sha": "9ecee14378271e96b6686c6e25996db2abf9994a",
    "files": [
        {
            "sha": "0a3c38a3e14f955051df88812393076e625f3ed8",
            "filename": "docs/source/en/how_to_hack_models.md",
            "status": "modified",
            "additions": 7,
            "deletions": 11,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/9ecee14378271e96b6686c6e25996db2abf9994a/docs%2Fsource%2Fen%2Fhow_to_hack_models.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/9ecee14378271e96b6686c6e25996db2abf9994a/docs%2Fsource%2Fen%2Fhow_to_hack_models.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fhow_to_hack_models.md?ref=9ecee14378271e96b6686c6e25996db2abf9994a",
            "patch": "@@ -90,11 +90,6 @@ class SamVisionAttentionSplit(SamVisionAttention, nn.Module):\n \n         attn_weights = (query * self.scale) @ key.transpose(-2, -1)\n \n-        if self.use_rel_pos:\n-            attn_weights = self.add_decomposed_rel_pos(\n-                attn_weights, query, self.rel_pos_h, self.rel_pos_w, (height, width), (height, width)\n-            )\n-\n         attn_weights = torch.nn.functional.softmax(attn_weights, dtype=torch.float32, dim=-1).to(query.dtype)\n         attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)\n         attn_output = (attn_probs @ value).reshape(batch_size, self.num_attention_heads, height, width, -1)\n@@ -114,13 +109,14 @@ Load the model with [`~PreTrainedModel.from_pretrained`].\n \n ```py\n from transformers import SamModel\n-from transformers.models.sam import modeling_sam\n-\n-# replace the attention class in the modeling_sam module\n-modeling_sam.SamVisionAttention = SamVisionAttentionSplit\n \n # load the pretrained SAM model\n model = SamModel.from_pretrained(\"facebook/sam-vit-base\")\n+\n+# replace the attention class in the vision_encoder module\n+for layer in model.vision_encoder.layers:\n+    if hasattr(layer, \"attn\"):\n+        layer.attn = SamVisionAttentionSplit(model.config.vision_config, model.config.vision_config.window_size)\n ```\n \n ## LoRA\n@@ -138,7 +134,7 @@ config = LoraConfig(\n     # apply LoRA to q and v\n     target_modules=[\"q\", \"v\"],\n     lora_dropout=0.1,\n-    task_type=\"mask-generation\"\n+    task_type=\"FEATURE_EXTRACTION\"\n )\n ```\n \n@@ -152,5 +148,5 @@ Call [print_trainable_parameters](https://huggingface.co/docs/peft/package_refer\n \n ```py\n model.print_trainable_parameters()\n-\"trainable params: 608,256 || all params: 94,343,728 || trainable%: 0.6447\"\n+\"trainable params: 589,824 || all params: 94,274,096 || trainable%: 0.6256\"\n ```\n\\ No newline at end of file"
        }
    ],
    "stats": {
        "total": 18,
        "additions": 7,
        "deletions": 11
    }
}