{
    "author": "luaenrique",
    "message": "Fix: avoid duplicate token in maybe_load_adapters (#41903)",
    "sha": "4d0b6758b90aa54e4077171e6d42c55e0c01c622",
    "files": [
        {
            "sha": "2aa515199d72070a9b77aa3054aa75969bfceb36",
            "filename": "src/transformers/integrations/peft.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0b6758b90aa54e4077171e6d42c55e0c01c622/src%2Ftransformers%2Fintegrations%2Fpeft.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0b6758b90aa54e4077171e6d42c55e0c01c622/src%2Ftransformers%2Fintegrations%2Fpeft.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Fpeft.py?ref=4d0b6758b90aa54e4077171e6d42c55e0c01c622",
            "patch": "@@ -651,13 +651,15 @@ def maybe_load_adapters(\n \n     _adapter_model_path = adapter_kwargs.pop(\"_adapter_model_path\", None)\n \n+    token_from_adapter_kwargs = adapter_kwargs.pop(\"token\", None)\n+\n     if _adapter_model_path is None:\n         _adapter_model_path = find_adapter_config_file(\n             pretrained_model_name_or_path,\n             cache_dir=download_kwargs.get(\"cache_dir\"),\n             force_download=bool(download_kwargs.get(\"force_download\", False)),\n             proxies=download_kwargs.get(\"proxies\"),\n-            token=token,\n+            token=token or token_from_adapter_kwargs,\n             revision=download_kwargs.get(\"revision\"),\n             local_files_only=bool(download_kwargs.get(\"local_files_only\", False)),\n             subfolder=download_kwargs.get(\"subfolder\", \"\"),"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 3,
        "deletions": 1
    }
}