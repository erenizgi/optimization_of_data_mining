{
    "author": "kylesayrs",
    "message": "Raise `accelerate` dependency error in case of defaulting `low_cpu_mem_usage=True` (#33830)\n\nClarify warning, add import check",
    "sha": "f8110a6ddf3d441412912d415cf6b7cd5fef9c8a",
    "files": [
        {
            "sha": "b3250dbb82b1d81e469e60438017875b4b7536d7",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f8110a6ddf3d441412912d415cf6b7cd5fef9c8a/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f8110a6ddf3d441412912d415cf6b7cd5fef9c8a/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=f8110a6ddf3d441412912d415cf6b7cd5fef9c8a",
            "patch": "@@ -3477,7 +3477,7 @@ def from_pretrained(\n             # Force-set to `True` for more mem efficiency\n             if low_cpu_mem_usage is None:\n                 low_cpu_mem_usage = True\n-                logger.warning(\"`low_cpu_mem_usage` was None, now set to True since model is quantized.\")\n+                logger.warning(\"`low_cpu_mem_usage` was None, now default to True since model is quantized.\")\n         is_quantized = hf_quantizer is not None\n \n         # This variable will flag if we're loading a sharded checkpoint. In this case the archive file is just the\n@@ -3891,6 +3891,10 @@ def from_pretrained(\n             logger.info(\"Detected DeepSpeed ZeRO-3: activating zero.init() for this model\")\n             init_contexts = [deepspeed.zero.Init(config_dict_or_path=deepspeed_config())] + init_contexts\n         elif low_cpu_mem_usage:\n+            if not is_accelerate_available():\n+                raise ImportError(\n+                    f\"Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install 'accelerate>={ACCELERATE_MIN_VERSION}'`\"\n+                )\n             init_contexts.append(init_empty_weights())\n \n         config = copy.deepcopy(config)  # We do not want to modify the config inplace in from_pretrained."
        }
    ],
    "stats": {
        "total": 6,
        "additions": 5,
        "deletions": 1
    }
}