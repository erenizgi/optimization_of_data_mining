{
    "author": "hqkqn32",
    "message": "fix: support tensor labels in DataCollatorWithFlattening (#42620)\n\n* fix: support tensor labels in DataCollatorWithFlattening\n\n- Add tensor to list conversion in DataCollatorWithFlattening\n- Convert input_ids and labels to list if they are tensors\n- Add tests for both tensor and list labels\n- Fixes #42599\n\n* style: fix whitespace linting errors\n\n* style: apply ruff format to test file",
    "sha": "f54647c80ea7091d425087546725b56371bf6068",
    "files": [
        {
            "sha": "8412ab5ae25a942c3c2be029fa51101a5ee90f41",
            "filename": "src/transformers/data/data_collator.py",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/f54647c80ea7091d425087546725b56371bf6068/src%2Ftransformers%2Fdata%2Fdata_collator.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f54647c80ea7091d425087546725b56371bf6068/src%2Ftransformers%2Fdata%2Fdata_collator.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdata%2Fdata_collator.py?ref=f54647c80ea7091d425087546725b56371bf6068",
            "patch": "@@ -1413,9 +1413,17 @@ def __call__(self, features, return_tensors=None, separator_id=None):\n             max_length = 0\n         for seq_idx, sample in enumerate(features):\n             input_ids = sample[\"input_ids\"]\n+            # Convert to list if tensor\n+            if hasattr(input_ids, \"tolist\"):\n+                input_ids = input_ids.tolist()\n             batch[\"input_ids\"] += input_ids\n+\n             if is_labels_provided:\n-                batch[\"labels\"] += [separator_id] + sample[\"labels\"][1:]\n+                labels = sample[\"labels\"]\n+                # Convert to list if tensor\n+                if hasattr(labels, \"tolist\"):\n+                    labels = labels.tolist()\n+                batch[\"labels\"] += [separator_id] + labels[1:]\n             else:\n                 batch[\"labels\"] += [separator_id] + input_ids[1:]\n             if self.return_position_ids:"
        },
        {
            "sha": "4c57d284686ed171dc75e18435e043b6fd60278f",
            "filename": "tests/trainer/test_data_collator.py",
            "status": "modified",
            "additions": 52,
            "deletions": 0,
            "changes": 52,
            "blob_url": "https://github.com/huggingface/transformers/blob/f54647c80ea7091d425087546725b56371bf6068/tests%2Ftrainer%2Ftest_data_collator.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f54647c80ea7091d425087546725b56371bf6068/tests%2Ftrainer%2Ftest_data_collator.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_data_collator.py?ref=f54647c80ea7091d425087546725b56371bf6068",
            "patch": "@@ -1965,3 +1965,55 @@ def test__whole_word_mask(self):\n         ).astype(bool)\n \n         np.testing.assert_array_equal(output_mask, expected_mask)\n+\n+\n+class DataCollatorWithFlatteningTest(unittest.TestCase):\n+    \"\"\"Tests for DataCollatorWithFlattening\"\"\"\n+\n+    def test_flattening_with_tensor_labels(self):\n+        \"\"\"Test that DataCollatorWithFlattening supports tensor labels (fixes issue #42599).\"\"\"\n+        features = [\n+            {\n+                \"input_ids\": torch.tensor([1, 2, 3, 4]),\n+                \"labels\": torch.tensor([10, 11, 12, 13]),\n+            },\n+            {\n+                \"input_ids\": torch.tensor([5, 6, 7]),\n+                \"labels\": torch.tensor([14, 15, 16]),\n+            },\n+        ]\n+        collator = DataCollatorWithFlattening(return_tensors=\"pt\")\n+\n+        # This should not raise TypeError anymore\n+        batch = collator(features)\n+\n+        # Verify the output\n+        self.assertIsInstance(batch, dict)\n+        self.assertIn(\"input_ids\", batch)\n+        self.assertIn(\"labels\", batch)\n+        self.assertIn(\"position_ids\", batch)\n+\n+        # Check shapes\n+        self.assertEqual(batch[\"input_ids\"].shape, (1, 7))  # 4 + 3 tokens\n+        self.assertEqual(batch[\"labels\"].shape, (1, 7))\n+        self.assertEqual(batch[\"position_ids\"].shape, (1, 7))\n+\n+    def test_flattening_with_list_labels(self):\n+        \"\"\"Test that DataCollatorWithFlattening still works with list labels.\"\"\"\n+        features = [\n+            {\n+                \"input_ids\": torch.tensor([1, 2, 3, 4]),\n+                \"labels\": [10, 11, 12, 13],\n+            },\n+            {\n+                \"input_ids\": torch.tensor([5, 6, 7]),\n+                \"labels\": [14, 15, 16],\n+            },\n+        ]\n+        collator = DataCollatorWithFlattening(return_tensors=\"pt\")\n+        batch = collator(features)\n+\n+        # Verify it still works with lists\n+        self.assertIsInstance(batch, dict)\n+        self.assertEqual(batch[\"input_ids\"].shape, (1, 7))\n+        self.assertEqual(batch[\"labels\"].shape, (1, 7))"
        }
    ],
    "stats": {
        "total": 62,
        "additions": 61,
        "deletions": 1
    }
}