{
    "author": "casinca",
    "message": "fix(Qwen3VLCausalLMOutputWithPast): missing `hidden_states` and `atteâ€¦ (#42609)\n\n* fix(Qwen3VLCausalLMOutputWithPast): missing `hidden_states` and `attentions` kwargs\n\n* revert kwargs for the base class\n\n* make regenerated model files\n\n* symmetrical change for `modular_qwen3_vl_moe.py`\n\n* regenerated `modeling_qwen3_vl_moe.py`",
    "sha": "0c3d043e659e022146a84c8931a5f2b06543f29b",
    "files": [
        {
            "sha": "b0b099a35e0c6a5576b02437c8b61334fa2eede6",
            "filename": "src/transformers/models/qwen3_vl/modeling_qwen3_vl.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/0c3d043e659e022146a84c8931a5f2b06543f29b/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodeling_qwen3_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0c3d043e659e022146a84c8931a5f2b06543f29b/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodeling_qwen3_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodeling_qwen3_vl.py?ref=0c3d043e659e022146a84c8931a5f2b06543f29b",
            "patch": "@@ -38,7 +38,7 @@\n from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update\n from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n from ...processing_utils import Unpack\n-from ...utils import TransformersKwargs, auto_docstring\n+from ...utils import TransformersKwargs, auto_docstring, can_return_tuple\n from ...utils.generic import check_model_inputs\n from .configuration_qwen3_vl import Qwen3VLConfig, Qwen3VLTextConfig, Qwen3VLVisionConfig\n \n@@ -1297,7 +1297,7 @@ def get_video_features(\n     def get_image_features(self, pixel_values: torch.FloatTensor, image_grid_thw: Optional[torch.LongTensor] = None):\n         return self.model.get_image_features(pixel_values, image_grid_thw)\n \n-    @check_model_inputs\n+    @can_return_tuple\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,\n@@ -1389,6 +1389,8 @@ def forward(\n             loss=loss,\n             logits=logits,\n             past_key_values=outputs.past_key_values,\n+            hidden_states=outputs.hidden_states,\n+            attentions=outputs.attentions,\n             rope_deltas=outputs.rope_deltas,\n         )\n "
        },
        {
            "sha": "20585db81039a9f4005889e9bc72361b47e01806",
            "filename": "src/transformers/models/qwen3_vl/modular_qwen3_vl.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/0c3d043e659e022146a84c8931a5f2b06543f29b/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodular_qwen3_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0c3d043e659e022146a84c8931a5f2b06543f29b/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodular_qwen3_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodular_qwen3_vl.py?ref=0c3d043e659e022146a84c8931a5f2b06543f29b",
            "patch": "@@ -34,7 +34,7 @@\n from ...modeling_utils import ALL_ATTENTION_FUNCTIONS\n from ...processing_utils import ProcessingKwargs, Unpack\n from ...tokenization_utils_base import PreTokenizedInput, TextInput\n-from ...utils import auto_docstring, logging\n+from ...utils import auto_docstring, can_return_tuple, logging\n from ...utils.generic import check_model_inputs\n from ...video_utils import VideoInput\n from ..llama.modeling_llama import LlamaRotaryEmbedding\n@@ -1080,7 +1080,7 @@ class Qwen3VLForConditionalGeneration(Qwen2_5_VLForConditionalGeneration):\n     config: Qwen3VLConfig\n     _checkpoint_conversion_mapping = {}\n \n-    @check_model_inputs\n+    @can_return_tuple\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,\n@@ -1172,6 +1172,8 @@ def forward(\n             loss=loss,\n             logits=logits,\n             past_key_values=outputs.past_key_values,\n+            hidden_states=outputs.hidden_states,\n+            attentions=outputs.attentions,\n             rope_deltas=outputs.rope_deltas,\n         )\n "
        },
        {
            "sha": "2c52b23f6cf8c6e4cf6ada4f7e378c6220520a08",
            "filename": "src/transformers/models/qwen3_vl_moe/modeling_qwen3_vl_moe.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/0c3d043e659e022146a84c8931a5f2b06543f29b/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodeling_qwen3_vl_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0c3d043e659e022146a84c8931a5f2b06543f29b/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodeling_qwen3_vl_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodeling_qwen3_vl_moe.py?ref=0c3d043e659e022146a84c8931a5f2b06543f29b",
            "patch": "@@ -39,7 +39,7 @@\n from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update\n from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n from ...processing_utils import Unpack\n-from ...utils import TransformersKwargs, auto_docstring\n+from ...utils import TransformersKwargs, auto_docstring, can_return_tuple\n from ...utils.generic import OutputRecorder, check_model_inputs\n from .configuration_qwen3_vl_moe import Qwen3VLMoeConfig, Qwen3VLMoeTextConfig, Qwen3VLMoeVisionConfig\n \n@@ -1507,7 +1507,7 @@ def get_video_features(\n     def get_image_features(self, pixel_values: torch.FloatTensor, image_grid_thw: Optional[torch.LongTensor] = None):\n         return self.model.get_image_features(pixel_values, image_grid_thw)\n \n-    @check_model_inputs\n+    @can_return_tuple\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,\n@@ -1617,6 +1617,8 @@ def forward(\n             aux_loss=aux_loss,\n             logits=logits,\n             past_key_values=outputs.past_key_values,\n+            hidden_states=outputs.hidden_states,\n+            attentions=outputs.attentions,\n             rope_deltas=outputs.rope_deltas,\n         )\n "
        },
        {
            "sha": "eb01b91ec83b7cc00237ca289161329033cc2c87",
            "filename": "src/transformers/models/qwen3_vl_moe/modular_qwen3_vl_moe.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/0c3d043e659e022146a84c8931a5f2b06543f29b/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodular_qwen3_vl_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0c3d043e659e022146a84c8931a5f2b06543f29b/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodular_qwen3_vl_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodular_qwen3_vl_moe.py?ref=0c3d043e659e022146a84c8931a5f2b06543f29b",
            "patch": "@@ -26,7 +26,7 @@\n from ...modeling_rope_utils import RopeParameters\n from ...modeling_utils import PreTrainedModel\n from ...processing_utils import Unpack\n-from ...utils import TransformersKwargs, logging\n+from ...utils import TransformersKwargs, can_return_tuple, logging\n from ..qwen3_moe.modeling_qwen3_moe import (\n     Qwen3MoeDecoderLayer,\n     Qwen3MoePreTrainedModel,\n@@ -387,6 +387,7 @@ class Qwen3VLMoeModel(Qwen3VLModel):\n \n \n class Qwen3VLMoeForConditionalGeneration(Qwen3VLForConditionalGeneration):\n+    @can_return_tuple\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,\n@@ -496,6 +497,8 @@ def forward(\n             aux_loss=aux_loss,\n             logits=logits,\n             past_key_values=outputs.past_key_values,\n+            hidden_states=outputs.hidden_states,\n+            attentions=outputs.attentions,\n             rope_deltas=outputs.rope_deltas,\n         )\n "
        }
    ],
    "stats": {
        "total": 23,
        "additions": 16,
        "deletions": 7
    }
}