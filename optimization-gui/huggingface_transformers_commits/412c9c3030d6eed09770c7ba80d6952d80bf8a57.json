{
    "author": "Cyrilvallez",
    "message": "Remove an old badly designed test (#40142)\n\nremove it",
    "sha": "412c9c3030d6eed09770c7ba80d6952d80bf8a57",
    "files": [
        {
            "sha": "97bca3317ae2981604253e20f1b60c488c8981b8",
            "filename": "tests/models/bert/test_modeling_bert.py",
            "status": "modified",
            "additions": 0,
            "deletions": 25,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/412c9c3030d6eed09770c7ba80d6952d80bf8a57/tests%2Fmodels%2Fbert%2Ftest_modeling_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/412c9c3030d6eed09770c7ba80d6952d80bf8a57/tests%2Fmodels%2Fbert%2Ftest_modeling_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbert%2Ftest_modeling_bert.py?ref=412c9c3030d6eed09770c7ba80d6952d80bf8a57",
            "patch": "@@ -11,8 +11,6 @@\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.\n-import os\n-import tempfile\n import unittest\n \n from packaging import version\n@@ -22,7 +20,6 @@\n from transformers.testing_utils import (\n     CaptureLogger,\n     require_torch,\n-    require_torch_accelerator,\n     slow,\n     torch_device,\n )\n@@ -643,28 +640,6 @@ def test_model_from_pretrained(self):\n         model = BertModel.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    @slow\n-    @require_torch_accelerator\n-    def test_torchscript_device_change(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-        for model_class in self.all_model_classes:\n-            # BertForMultipleChoice behaves incorrectly in JIT environments.\n-            if model_class == BertForMultipleChoice:\n-                self.skipTest(reason=\"BertForMultipleChoice behaves incorrectly in JIT environments.\")\n-\n-            config.torchscript = True\n-            model = model_class(config=config)\n-\n-            inputs_dict = self._prepare_for_class(inputs_dict, model_class)\n-            traced_model = torch.jit.trace(\n-                model, (inputs_dict[\"input_ids\"].to(\"cpu\"), inputs_dict[\"attention_mask\"].to(\"cpu\"))\n-            )\n-\n-            with tempfile.TemporaryDirectory() as tmp:\n-                torch.jit.save(traced_model, os.path.join(tmp, \"bert.pt\"))\n-                loaded = torch.jit.load(os.path.join(tmp, \"bert.pt\"), map_location=torch_device)\n-                loaded(inputs_dict[\"input_ids\"].to(torch_device), inputs_dict[\"attention_mask\"].to(torch_device))\n-\n \n @require_torch\n class BertModelIntegrationTest(unittest.TestCase):"
        },
        {
            "sha": "c3a8fca28ce990f97e7a46d39ec54e521b071fe2",
            "filename": "tests/models/convbert/test_modeling_convbert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 25,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/412c9c3030d6eed09770c7ba80d6952d80bf8a57/tests%2Fmodels%2Fconvbert%2Ftest_modeling_convbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/412c9c3030d6eed09770c7ba80d6952d80bf8a57/tests%2Fmodels%2Fconvbert%2Ftest_modeling_convbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fconvbert%2Ftest_modeling_convbert.py?ref=412c9c3030d6eed09770c7ba80d6952d80bf8a57",
            "patch": "@@ -13,13 +13,11 @@\n # limitations under the License.\n \"\"\"Testing suite for the PyTorch ConvBERT model.\"\"\"\n \n-import os\n-import tempfile\n import unittest\n \n from transformers import ConvBertConfig, is_torch_available\n from transformers.models.auto import get_values\n-from transformers.testing_utils import require_torch, require_torch_accelerator, slow, torch_device\n+from transformers.testing_utils import require_torch, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor, random_attention_mask\n@@ -426,28 +424,6 @@ def test_attention_outputs(self):\n                     [self.model_tester.num_attention_heads / 2, encoder_seq_length, encoder_key_length],\n                 )\n \n-    @slow\n-    @require_torch_accelerator\n-    def test_torchscript_device_change(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-        for model_class in self.all_model_classes:\n-            # ConvBertForMultipleChoice behaves incorrectly in JIT environments.\n-            if model_class == ConvBertForMultipleChoice:\n-                self.skipTest(reason=\"ConvBertForMultipleChoice behaves incorrectly in JIT environments.\")\n-\n-            config.torchscript = True\n-            model = model_class(config=config)\n-\n-            inputs_dict = self._prepare_for_class(inputs_dict, model_class)\n-            traced_model = torch.jit.trace(\n-                model, (inputs_dict[\"input_ids\"].to(\"cpu\"), inputs_dict[\"attention_mask\"].to(\"cpu\"))\n-            )\n-\n-            with tempfile.TemporaryDirectory() as tmp:\n-                torch.jit.save(traced_model, os.path.join(tmp, \"traced_model.pt\"))\n-                loaded = torch.jit.load(os.path.join(tmp, \"traced_model.pt\"), map_location=torch_device)\n-                loaded(inputs_dict[\"input_ids\"].to(torch_device), inputs_dict[\"attention_mask\"].to(torch_device))\n-\n     def test_model_for_input_embeds(self):\n         batch_size = 2\n         seq_length = 10"
        },
        {
            "sha": "3124689b0eaf2214ee2dafee947ea544dad65c25",
            "filename": "tests/models/distilbert/test_modeling_distilbert.py",
            "status": "modified",
            "additions": 0,
            "deletions": 23,
            "changes": 23,
            "blob_url": "https://github.com/huggingface/transformers/blob/412c9c3030d6eed09770c7ba80d6952d80bf8a57/tests%2Fmodels%2Fdistilbert%2Ftest_modeling_distilbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/412c9c3030d6eed09770c7ba80d6952d80bf8a57/tests%2Fmodels%2Fdistilbert%2Ftest_modeling_distilbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdistilbert%2Ftest_modeling_distilbert.py?ref=412c9c3030d6eed09770c7ba80d6952d80bf8a57",
            "patch": "@@ -11,7 +11,6 @@\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.\n-import os\n import tempfile\n import unittest\n \n@@ -275,28 +274,6 @@ def test_model_from_pretrained(self):\n         model = DistilBertModel.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    @slow\n-    @require_torch_accelerator\n-    def test_torchscript_device_change(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-        for model_class in self.all_model_classes:\n-            # BertForMultipleChoice behaves incorrectly in JIT environments.\n-            if model_class == DistilBertForMultipleChoice:\n-                self.skipTest(reason=\"DistilBertForMultipleChoice behaves incorrectly in JIT environments.\")\n-\n-            config.torchscript = True\n-            model = model_class(config=config)\n-\n-            inputs_dict = self._prepare_for_class(inputs_dict, model_class)\n-            traced_model = torch.jit.trace(\n-                model, (inputs_dict[\"input_ids\"].to(\"cpu\"), inputs_dict[\"attention_mask\"].to(\"cpu\"))\n-            )\n-\n-            with tempfile.TemporaryDirectory() as tmp:\n-                torch.jit.save(traced_model, os.path.join(tmp, \"traced_model.pt\"))\n-                loaded = torch.jit.load(os.path.join(tmp, \"traced_model.pt\"), map_location=torch_device)\n-                loaded(inputs_dict[\"input_ids\"].to(torch_device), inputs_dict[\"attention_mask\"].to(torch_device))\n-\n     # Because DistilBertForMultipleChoice requires inputs with different shapes we need to override this test.\n     @require_flash_attn\n     @require_torch_accelerator"
        },
        {
            "sha": "86500deeda50673158bd3f220faec303ecdc86cb",
            "filename": "tests/models/ernie/test_modeling_ernie.py",
            "status": "modified",
            "additions": 1,
            "deletions": 24,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/412c9c3030d6eed09770c7ba80d6952d80bf8a57/tests%2Fmodels%2Fernie%2Ftest_modeling_ernie.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/412c9c3030d6eed09770c7ba80d6952d80bf8a57/tests%2Fmodels%2Fernie%2Ftest_modeling_ernie.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fernie%2Ftest_modeling_ernie.py?ref=412c9c3030d6eed09770c7ba80d6952d80bf8a57",
            "patch": "@@ -11,13 +11,11 @@\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.\n-import os\n-import tempfile\n import unittest\n \n from transformers import ErnieConfig, is_torch_available\n from transformers.models.auto import get_values\n-from transformers.testing_utils import require_torch, require_torch_accelerator, slow, torch_device\n+from transformers.testing_utils import require_torch, slow, torch_device\n \n from ...generation.test_utils import GenerationTesterMixin\n from ...test_configuration_common import ConfigTester\n@@ -568,24 +566,3 @@ def test_model_from_pretrained(self):\n         model_name = \"nghuyong/ernie-1.0-base-zh\"\n         model = ErnieModel.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n-\n-    @slow\n-    @require_torch_accelerator\n-    def test_torchscript_device_change(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-        for model_class in self.all_model_classes:\n-            if model_class == ErnieForMultipleChoice:\n-                self.skipTest(reason=\"ErnieForMultipleChoice behaves incorrectly in JIT environments.\")\n-\n-            config.torchscript = True\n-            model = model_class(config=config)\n-\n-            inputs_dict = self._prepare_for_class(inputs_dict, model_class)\n-            traced_model = torch.jit.trace(\n-                model, (inputs_dict[\"input_ids\"].to(\"cpu\"), inputs_dict[\"attention_mask\"].to(\"cpu\"))\n-            )\n-\n-            with tempfile.TemporaryDirectory() as tmp:\n-                torch.jit.save(traced_model, os.path.join(tmp, \"ernie.pt\"))\n-                loaded = torch.jit.load(os.path.join(tmp, \"ernie.pt\"), map_location=torch_device)\n-                loaded(inputs_dict[\"input_ids\"].to(torch_device), inputs_dict[\"attention_mask\"].to(torch_device))"
        },
        {
            "sha": "031abc4cda11bb2b73f6fb669215eca13e831b2f",
            "filename": "tests/models/flaubert/test_modeling_flaubert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 25,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/412c9c3030d6eed09770c7ba80d6952d80bf8a57/tests%2Fmodels%2Fflaubert%2Ftest_modeling_flaubert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/412c9c3030d6eed09770c7ba80d6952d80bf8a57/tests%2Fmodels%2Fflaubert%2Ftest_modeling_flaubert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fflaubert%2Ftest_modeling_flaubert.py?ref=412c9c3030d6eed09770c7ba80d6952d80bf8a57",
            "patch": "@@ -11,12 +11,10 @@\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.\n-import os\n-import tempfile\n import unittest\n \n from transformers import FlaubertConfig, is_sacremoses_available, is_torch_available\n-from transformers.testing_utils import require_torch, require_torch_accelerator, slow, torch_device\n+from transformers.testing_utils import require_torch, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import ModelTesterMixin, ids_tensor, random_attention_mask\n@@ -478,28 +476,6 @@ def test_model_from_pretrained(self):\n         model = FlaubertModel.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    @slow\n-    @require_torch_accelerator\n-    def test_torchscript_device_change(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-        for model_class in self.all_model_classes:\n-            # FlauBertForMultipleChoice behaves incorrectly in JIT environments.\n-            if model_class == FlaubertForMultipleChoice:\n-                self.skipTest(reason=\"FlauBertForMultipleChoice behaves incorrectly in JIT environments.\")\n-\n-            config.torchscript = True\n-            model = model_class(config=config)\n-\n-            inputs_dict = self._prepare_for_class(inputs_dict, model_class)\n-            traced_model = torch.jit.trace(\n-                model, (inputs_dict[\"input_ids\"].to(\"cpu\"), inputs_dict[\"attention_mask\"].to(\"cpu\"))\n-            )\n-\n-            with tempfile.TemporaryDirectory() as tmp:\n-                torch.jit.save(traced_model, os.path.join(tmp, \"traced_model.pt\"))\n-                loaded = torch.jit.load(os.path.join(tmp, \"traced_model.pt\"), map_location=torch_device)\n-                loaded(inputs_dict[\"input_ids\"].to(torch_device), inputs_dict[\"attention_mask\"].to(torch_device))\n-\n \n @require_torch\n class FlaubertModelIntegrationTest(unittest.TestCase):"
        }
    ],
    "stats": {
        "total": 125,
        "additions": 3,
        "deletions": 122
    }
}