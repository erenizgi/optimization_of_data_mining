{
    "author": "hlky",
    "message": "Fix _load_state_dict_into_meta_model with device_map=None (#36488)\n\n* Fix _load_state_dict_into_meta_model with device_map=None\n\n* Update src/transformers/modeling_utils.py",
    "sha": "dcbdf7e962c4b36140cc9ee76f870016121e69e5",
    "files": [
        {
            "sha": "0554fa9d7d8c596be95c14e836f570f7ad127b1c",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/dcbdf7e962c4b36140cc9ee76f870016121e69e5/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dcbdf7e962c4b36140cc9ee76f870016121e69e5/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=dcbdf7e962c4b36140cc9ee76f870016121e69e5",
            "patch": "@@ -785,8 +785,8 @@ def _load_state_dict_into_meta_model(\n     tensor_device = None\n     if device_map is not None and device_map.get(\"\", None) is not None:\n         tensor_device = device_map[\"\"].index if isinstance(device_map[\"\"], torch.device) else device_map[\"\"]\n-\n-    device_map_regex = \"|\".join(sorted(device_map.keys(), reverse=True))\n+    if device_map is not None:\n+        device_map_regex = \"|\".join(sorted(device_map.keys(), reverse=True))\n \n     # we need this later to initialize tensor parallelism\n     if device_mesh is not None:"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}