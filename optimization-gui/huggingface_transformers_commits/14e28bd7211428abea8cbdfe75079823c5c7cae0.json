{
    "author": "Cyrilvallez",
    "message": "Correctly raise errors when downloading tokenizer files (#37740)\n\n* first try\n\n* Update tokenization_utils_base.py\n\n* Update tokenization_utils_base.py\n\n* standardize",
    "sha": "14e28bd7211428abea8cbdfe75079823c5c7cae0",
    "files": [
        {
            "sha": "7c2778e947621dc390725586b1c1dca1c3cba170",
            "filename": "src/transformers/tokenization_utils_base.py",
            "status": "modified",
            "additions": 56,
            "deletions": 44,
            "changes": 100,
            "blob_url": "https://github.com/huggingface/transformers/blob/14e28bd7211428abea8cbdfe75079823c5c7cae0/src%2Ftransformers%2Ftokenization_utils_base.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/14e28bd7211428abea8cbdfe75079823c5c7cae0/src%2Ftransformers%2Ftokenization_utils_base.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_utils_base.py?ref=14e28bd7211428abea8cbdfe75079823c5c7cae0",
            "patch": "@@ -1989,23 +1989,35 @@ def from_pretrained(\n                 if \"tokenizer_file\" in vocab_files:\n                     # Try to get the tokenizer config to see if there are versioned tokenizer files.\n                     fast_tokenizer_file = FULL_TOKENIZER_FILE\n-                    resolved_config_file = cached_file(\n-                        pretrained_model_name_or_path,\n-                        TOKENIZER_CONFIG_FILE,\n-                        cache_dir=cache_dir,\n-                        force_download=force_download,\n-                        resume_download=resume_download,\n-                        proxies=proxies,\n-                        token=token,\n-                        revision=revision,\n-                        local_files_only=local_files_only,\n-                        subfolder=subfolder,\n-                        user_agent=user_agent,\n-                        _raise_exceptions_for_gated_repo=False,\n-                        _raise_exceptions_for_missing_entries=False,\n-                        _raise_exceptions_for_connection_errors=False,\n-                        _commit_hash=commit_hash,\n-                    )\n+\n+                    try:\n+                        resolved_config_file = cached_file(\n+                            pretrained_model_name_or_path,\n+                            TOKENIZER_CONFIG_FILE,\n+                            cache_dir=cache_dir,\n+                            force_download=force_download,\n+                            resume_download=resume_download,\n+                            proxies=proxies,\n+                            token=token,\n+                            revision=revision,\n+                            local_files_only=local_files_only,\n+                            subfolder=subfolder,\n+                            user_agent=user_agent,\n+                            _raise_exceptions_for_missing_entries=False,\n+                            _commit_hash=commit_hash,\n+                        )\n+                    except OSError:\n+                        # Re-raise any error raised by cached_file in order to get a helpful error message\n+                        raise\n+                    except Exception:\n+                        # For any other exception, we throw a generic error.\n+                        raise OSError(\n+                            f\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\n+                            \"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\n+                            f\"Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a directory \"\n+                            f\"containing all relevant files for a {cls.__name__} tokenizer.\"\n+                        )\n+\n                     commit_hash = extract_commit_hash(resolved_config_file, commit_hash)\n                     if resolved_config_file is not None:\n                         with open(resolved_config_file, encoding=\"utf-8\") as reader:\n@@ -2043,35 +2055,35 @@ def from_pretrained(\n                 elif is_remote_url(file_path):\n                     resolved_vocab_files[file_id] = download_url(file_path, proxies=proxies)\n             else:\n-                resolved_vocab_files[file_id] = cached_file(\n-                    pretrained_model_name_or_path,\n-                    file_path,\n-                    cache_dir=cache_dir,\n-                    force_download=force_download,\n-                    proxies=proxies,\n-                    resume_download=resume_download,\n-                    local_files_only=local_files_only,\n-                    token=token,\n-                    user_agent=user_agent,\n-                    revision=revision,\n-                    subfolder=subfolder,\n-                    _raise_exceptions_for_gated_repo=False,\n-                    _raise_exceptions_for_missing_entries=False,\n-                    _raise_exceptions_for_connection_errors=False,\n-                    _commit_hash=commit_hash,\n-                )\n+                try:\n+                    resolved_vocab_files[file_id] = cached_file(\n+                        pretrained_model_name_or_path,\n+                        file_path,\n+                        cache_dir=cache_dir,\n+                        force_download=force_download,\n+                        proxies=proxies,\n+                        resume_download=resume_download,\n+                        local_files_only=local_files_only,\n+                        token=token,\n+                        user_agent=user_agent,\n+                        revision=revision,\n+                        subfolder=subfolder,\n+                        _raise_exceptions_for_missing_entries=False,\n+                        _commit_hash=commit_hash,\n+                    )\n+                except OSError:\n+                    # Re-raise any error raised by cached_file in order to get a helpful error message\n+                    raise\n+                except Exception:\n+                    # For any other exception, we throw a generic error.\n+                    raise OSError(\n+                        f\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\n+                        \"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\n+                        f\"Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a directory \"\n+                        f\"containing all relevant files for a {cls.__name__} tokenizer.\"\n+                    )\n                 commit_hash = extract_commit_hash(resolved_vocab_files[file_id], commit_hash)\n \n-        # If one passes a GGUF file path to `gguf_file` there is no need for this check as the tokenizer will be\n-        # loaded directly from the GGUF file.\n-        if all(full_file_name is None for full_file_name in resolved_vocab_files.values()) and not gguf_file:\n-            raise EnvironmentError(\n-                f\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\n-                \"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\n-                f\"Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a directory \"\n-                f\"containing all relevant files for a {cls.__name__} tokenizer.\"\n-            )\n-\n         for file_id, file_path in vocab_files.items():\n             if file_id not in resolved_vocab_files:\n                 continue"
        }
    ],
    "stats": {
        "total": 100,
        "additions": 56,
        "deletions": 44
    }
}