{
    "author": "Cyrilvallez",
    "message": "Fix meta state dict loading with quantizers (#37136)\n\nUpdate modeling_utils.py\n\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>",
    "sha": "bc2dea3f549d512503640a7f244d45490d918378",
    "files": [
        {
            "sha": "352c86a13da676c393784830b2725cb5fc8cc33b",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 10,
            "deletions": 2,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc2dea3f549d512503640a7f244d45490d918378/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc2dea3f549d512503640a7f244d45490d918378/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=bc2dea3f549d512503640a7f244d45490d918378",
            "patch": "@@ -752,7 +752,11 @@ def _load_state_dict_into_meta_model(\n         device_map_regex = \"|\".join([re.escape(k) for k in sorted(device_map.keys(), reverse=True)])\n \n     is_quantized = hf_quantizer is not None\n-    is_meta_state_dict = shard_file.endswith(\".safetensors\")\n+    is_hqq_or_bnb = is_quantized and hf_quantizer.quantization_config.quant_method in [\n+        QuantizationMethod.HQQ,\n+        QuantizationMethod.BITS_AND_BYTES,\n+    ]\n+    is_meta_state_dict = shard_file.endswith(\".safetensors\") and not is_hqq_or_bnb\n     file_pointer = None\n     if is_meta_state_dict:\n         file_pointer = safe_open(shard_file, framework=\"pt\", device=tensor_device)\n@@ -4828,14 +4832,18 @@ def _load_pretrained_model(\n             caching_allocator_warmup(model_to_load, expanded_device_map, factor=2 if hf_quantizer is None else 4)\n \n         error_msgs = []\n+        is_hqq_or_bnb = is_quantized and hf_quantizer.quantization_config.quant_method in [\n+            QuantizationMethod.HQQ,\n+            QuantizationMethod.BITS_AND_BYTES,\n+        ]\n         # Iterate on all the shards to load the weights\n         for shard_file in checkpoint_files:\n             # Skip the load for shards that only contain disk-offloaded weights\n             if shard_file in disk_only_shard_files:\n                 continue\n \n             map_location = \"cpu\"\n-            if shard_file.endswith(\".safetensors\"):\n+            if shard_file.endswith(\".safetensors\") and not is_hqq_or_bnb:\n                 map_location = \"meta\"\n             elif (\n                 device_map is not None"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 10,
        "deletions": 2
    }
}