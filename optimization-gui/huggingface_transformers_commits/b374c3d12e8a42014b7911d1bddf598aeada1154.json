{
    "author": "Isotr0py",
    "message": "Fix broken image inference for Fuyu model (#39915)\n\n* fix fuyu\n\nSigned-off-by: Isotr0py <2037008807@qq.com>\n\n* oops\n\nSigned-off-by: Isotr0py <2037008807@qq.com>\n\n* run test on GPU\n\nSigned-off-by: Isotr0py <mozf@mail2.sysu.edu.cn>\n\n* clean unused\n\nSigned-off-by: Isotr0py <mozf@mail2.sysu.edu.cn>\n\n* revert\n\nSigned-off-by: Isotr0py <mozf@mail2.sysu.edu.cn>\n\n* add fuyu multimodal test\n\nSigned-off-by: Isotr0py <2037008807@qq.com>\n\n* fix\n\nSigned-off-by: Isotr0py <2037008807@qq.com>\n\n---------\n\nSigned-off-by: Isotr0py <2037008807@qq.com>\nSigned-off-by: Isotr0py <mozf@mail2.sysu.edu.cn>",
    "sha": "b374c3d12e8a42014b7911d1bddf598aeada1154",
    "files": [
        {
            "sha": "2e10866f31b16bee734073a925f5b28b55c0cfe6",
            "filename": "src/transformers/models/fuyu/modeling_fuyu.py",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/b374c3d12e8a42014b7911d1bddf598aeada1154/src%2Ftransformers%2Fmodels%2Ffuyu%2Fmodeling_fuyu.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b374c3d12e8a42014b7911d1bddf598aeada1154/src%2Ftransformers%2Fmodels%2Ffuyu%2Fmodeling_fuyu.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffuyu%2Fmodeling_fuyu.py?ref=b374c3d12e8a42014b7911d1bddf598aeada1154",
            "patch": "@@ -225,7 +225,7 @@ def forward(\n         if image_patches is not None:\n             patch_embeddings = self.get_image_features(image_patches)\n             patch_embeddings = torch.cat(patch_embeddings, dim=0).to(inputs_embeds.device, inputs_embeds.dtype)\n-            special_image_mask = self.get_placeholder_tokens(\n+            special_image_mask = self.get_placeholder_mask(\n                 input_ids, inputs_embeds=inputs_embeds, image_features=patch_embeddings\n             )\n             inputs_embeds = inputs_embeds.masked_scatter(special_image_mask, patch_embeddings)\n@@ -379,6 +379,7 @@ def prepare_inputs_for_generation(\n         inputs_embeds=None,\n         image_patches=None,\n         image_patches_indices=None,\n+        cache_position=None,\n         **kwargs,\n     ):\n         # Overwritten -- in specific circumstances we don't want to forward image inputs to the model\n@@ -390,10 +391,12 @@ def prepare_inputs_for_generation(\n             inputs_embeds=inputs_embeds,\n             image_patches=image_patches,\n             image_patches_indices=image_patches_indices,\n+            cache_position=cache_position,\n             **kwargs,\n         )\n \n-        if past_key_values is not None:\n+        if cache_position[0] != 0:\n+            # set image_patches and image_patches_indices to `None` for decoding stage\n             model_inputs[\"image_patches_indices\"] = None\n             model_inputs[\"image_patches\"] = None\n "
        },
        {
            "sha": "d23518f8a01cf656c25f82b8e849a14e346120b3",
            "filename": "tests/models/fuyu/test_modeling_fuyu.py",
            "status": "modified",
            "additions": 44,
            "deletions": 9,
            "changes": 53,
            "blob_url": "https://github.com/huggingface/transformers/blob/b374c3d12e8a42014b7911d1bddf598aeada1154/tests%2Fmodels%2Ffuyu%2Ftest_modeling_fuyu.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b374c3d12e8a42014b7911d1bddf598aeada1154/tests%2Fmodels%2Ffuyu%2Ftest_modeling_fuyu.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ffuyu%2Ftest_modeling_fuyu.py?ref=b374c3d12e8a42014b7911d1bddf598aeada1154",
            "patch": "@@ -13,19 +13,21 @@\n # limitations under the License.\n \"\"\"Testing suite for the PyTorch Fuyu model.\"\"\"\n \n+import copy\n import io\n import unittest\n \n import pytest\n import requests\n+import torch\n from parameterized import parameterized\n \n from transformers import FuyuConfig, is_torch_available, is_vision_available\n-from transformers.testing_utils import require_torch, require_torch_accelerator, slow\n+from transformers.testing_utils import require_torch, require_torch_accelerator, slow, torch_device\n from transformers.utils import cached_property\n \n from ...generation.test_utils import GenerationTesterMixin\n-from ...test_modeling_common import ModelTesterMixin, ids_tensor, random_attention_mask\n+from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor, random_attention_mask\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -47,6 +49,7 @@ def __init__(\n         parent,\n         batch_size=13,\n         seq_length=7,\n+        num_image_tokens=2,\n         image_size=30,\n         patch_size=15,\n         num_channels=3,\n@@ -67,12 +70,14 @@ def __init__(\n         initializer_range=0.02,\n         num_labels=3,\n         num_choices=4,\n-        pad_token_id=0,\n+        pad_token_id=10,\n+        image_token_id=1,\n         scope=None,\n     ):\n         self.parent = parent\n         self.batch_size = batch_size\n-        self.seq_length = seq_length\n+        self.num_image_tokens = num_image_tokens\n+        self.seq_length = seq_length + num_image_tokens\n         self.image_size = image_size\n         self.patch_size = patch_size\n         self.num_channels = num_channels\n@@ -94,10 +99,15 @@ def __init__(\n         self.num_labels = num_labels\n         self.num_choices = num_choices\n         self.pad_token_id = pad_token_id\n+        self.image_token_id = image_token_id\n         self.scope = scope\n \n     def prepare_config_and_inputs(self):\n+        config = self.get_config()\n+\n         input_ids = ids_tensor([self.batch_size, self.seq_length], self.vocab_size)\n+        input_ids[input_ids == config.image_token_id] = self.pad_token_id\n+        input_ids[:, : self.num_image_tokens] = config.image_token_id\n \n         input_mask = None\n         if self.use_input_mask:\n@@ -109,8 +119,6 @@ def prepare_config_and_inputs(self):\n             sequence_labels = ids_tensor([self.batch_size], self.type_sequence_label_size)\n             token_labels = ids_tensor([self.batch_size, self.seq_length], self.num_labels)\n \n-        config = self.get_config()\n-\n         return config, input_ids, input_mask, sequence_labels, token_labels\n \n     def get_config(self):\n@@ -128,6 +136,7 @@ def get_config(self):\n             is_decoder=False,\n             initializer_range=self.initializer_range,\n             pad_token_id=self.pad_token_id,\n+            image_token_id=self.image_token_id,\n         )\n \n     def prepare_config_and_inputs_for_common(self):\n@@ -139,7 +148,10 @@ def prepare_config_and_inputs_for_common(self):\n             sequence_labels,\n             token_labels,\n         ) = config_and_inputs\n-        inputs_dict = {\"input_ids\": input_ids, \"attention_mask\": input_mask}\n+        image_patches = floats_tensor(\n+            [self.batch_size, self.num_image_tokens, config.num_channels * config.patch_size**2]\n+        )\n+        inputs_dict = {\"input_ids\": input_ids, \"attention_mask\": input_mask, \"image_patches\": image_patches}\n         return config, inputs_dict\n \n \n@@ -166,6 +178,27 @@ class FuyuModelTest(ModelTesterMixin, GenerationTesterMixin, PipelineTesterMixin\n     def setUp(self):\n         self.model_tester = FuyuModelTester(self)\n \n+    def test_mismatching_image_patches(self):\n+        config, input_dict = self.model_tester.prepare_config_and_inputs_for_common()\n+        for model_class in self.all_model_classes:\n+            model = model_class(config).to(torch_device)\n+            curr_input_dict = copy.deepcopy(input_dict)  # in=place modifications further\n+\n+            # two image token and two image\n+            _ = model(**curr_input_dict)  # successful forward with no modifications\n+\n+            # remove one image but leave the image token in text\n+            input_ids = curr_input_dict[\"input_ids\"]\n+            image_patches = curr_input_dict[\"image_patches\"][1:, ...]\n+            with self.assertRaises(ValueError):\n+                _ = model(input_ids=input_ids, image_patches=image_patches)\n+\n+            # remove one image token from text\n+            input_ids = curr_input_dict[\"input_ids\"][2:]\n+            image_patches = curr_input_dict[\"image_patches\"]\n+            with self.assertRaises(ValueError):\n+                _ = model(input_ids=input_ids, image_patches=image_patches)\n+\n     @unittest.skip(\n         reason=\"This architecture seem to not compute gradients properly when using GC, check: https://github.com/huggingface/transformers/pull/27124\"\n     )\n@@ -232,7 +265,7 @@ def default_processor(self):\n \n     @cached_property\n     def default_model(self):\n-        return FuyuForCausalLM.from_pretrained(\"adept/fuyu-8b\")\n+        return FuyuForCausalLM.from_pretrained(\"adept/fuyu-8b\", torch_dtype=\"float16\", device_map=torch_device)\n \n     def test_greedy_generation(self):\n         processor = self.default_processor\n@@ -243,7 +276,9 @@ def test_greedy_generation(self):\n \n         text_prompt_coco_captioning = \"Generate a coco-style caption.\\n\"\n \n-        inputs = processor(images=image, text=text_prompt_coco_captioning, return_tensors=\"pt\")\n+        inputs = processor(images=image, text=text_prompt_coco_captioning, return_tensors=\"pt\").to(\n+            torch_device, torch.float16\n+        )\n         generated_ids = model.generate(**inputs, max_new_tokens=10)\n \n         # take the last 8 tokens (in order to skip special \\n\\x04 characters) and decode them"
        }
    ],
    "stats": {
        "total": 60,
        "additions": 49,
        "deletions": 11
    }
}