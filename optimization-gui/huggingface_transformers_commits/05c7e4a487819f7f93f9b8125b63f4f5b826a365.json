{
    "author": "SunMarc",
    "message": "Fix cuda index (#42897)\n\nfix index\n\nCo-authored-by: Mohamed Mekkouri <93391238+MekkCyber@users.noreply.github.com>",
    "sha": "05c7e4a487819f7f93f9b8125b63f4f5b826a365",
    "files": [
        {
            "sha": "8188d1bb242a75d723adceff0e159dac19fee2c8",
            "filename": "src/transformers/integrations/accelerate.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/05c7e4a487819f7f93f9b8125b63f4f5b826a365/src%2Ftransformers%2Fintegrations%2Faccelerate.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/05c7e4a487819f7f93f9b8125b63f4f5b826a365/src%2Ftransformers%2Fintegrations%2Faccelerate.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Faccelerate.py?ref=05c7e4a487819f7f93f9b8125b63f4f5b826a365",
            "patch": "@@ -182,6 +182,10 @@ def check_and_set_device_map(device_map: \"torch.device | int | str | dict | None\n         device_map = {\"\": device_map}\n     elif isinstance(device_map, str) and device_map not in [\"auto\", \"balanced\", \"balanced_low_0\", \"sequential\"]:\n         try:\n+            if device_map == \"cuda\":\n+                # setting to the local rank\n+                local_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n+                device_map = f\"cuda:{local_rank}\"\n             device_map = {\"\": torch.device(device_map)}\n         except RuntimeError:\n             raise ValueError("
        }
    ],
    "stats": {
        "total": 4,
        "additions": 4,
        "deletions": 0
    }
}