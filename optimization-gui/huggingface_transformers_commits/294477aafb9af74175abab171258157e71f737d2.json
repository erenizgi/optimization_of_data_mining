{
    "author": "unknown",
    "message": "Doc and config mismatch for DeBERTa (#33713)\n\n* Update modeling_deberta_v2.py\r\n\r\n* Update configuration_deberta.py\r\n\r\n* Revert \"Update modeling_deberta_v2.py\"\r\n\r\n* Revert \"Update configuration_deberta.py\"\r\n\r\n* fix the config doc mismatch\r\n\r\n---------\r\n\r\nCo-authored-by: Fedor Krasnov <fedor.krasnov@gmail.com>",
    "sha": "294477aafb9af74175abab171258157e71f737d2",
    "files": [
        {
            "sha": "1c826a784f34547a03d1492380ecb31a8c6ff548",
            "filename": "src/transformers/models/deberta/configuration_deberta.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/294477aafb9af74175abab171258157e71f737d2/src%2Ftransformers%2Fmodels%2Fdeberta%2Fconfiguration_deberta.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/294477aafb9af74175abab171258157e71f737d2/src%2Ftransformers%2Fmodels%2Fdeberta%2Fconfiguration_deberta.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeberta%2Fconfiguration_deberta.py?ref=294477aafb9af74175abab171258157e71f737d2",
            "patch": "@@ -40,7 +40,7 @@ class DebertaConfig(PretrainedConfig):\n     documentation from [`PretrainedConfig`] for more information.\n \n     Arguments:\n-        vocab_size (`int`, *optional*, defaults to 30522):\n+        vocab_size (`int`, *optional*, defaults to 50265):\n             Vocabulary size of the DeBERTa model. Defines the number of different tokens that can be represented by the\n             `inputs_ids` passed when calling [`DebertaModel`] or [`TFDebertaModel`].\n         hidden_size (`int`, *optional*, defaults to 768):\n@@ -62,7 +62,7 @@ class DebertaConfig(PretrainedConfig):\n         max_position_embeddings (`int`, *optional*, defaults to 512):\n             The maximum sequence length that this model might ever be used with. Typically set this to something large\n             just in case (e.g., 512 or 1024 or 2048).\n-        type_vocab_size (`int`, *optional*, defaults to 2):\n+        type_vocab_size (`int`, *optional*, defaults to 0):\n             The vocabulary size of the `token_type_ids` passed when calling [`DebertaModel`] or [`TFDebertaModel`].\n         initializer_range (`float`, *optional*, defaults to 0.02):\n             The standard deviation of the truncated_normal_initializer for initializing all weight matrices."
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}