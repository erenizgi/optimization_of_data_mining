{
    "author": "gudwls215",
    "message": "Fix license text, duplicate assignment, and typo in constant names (#39250)\n\n- Complete Apache License text in Italian documentation\n- Remove duplicate variable assignment in Perceiver converter\n- Fix typo in MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES constant",
    "sha": "ea3c2c027769980c0501dc615ef7e755d206af62",
    "files": [
        {
            "sha": "23ba034e8e2d310dafc1ff8e2eaf6b93467b634f",
            "filename": "docs/source/it/perf_train_special.md",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/ea3c2c027769980c0501dc615ef7e755d206af62/docs%2Fsource%2Fit%2Fperf_train_special.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/ea3c2c027769980c0501dc615ef7e755d206af62/docs%2Fsource%2Fit%2Fperf_train_special.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fit%2Fperf_train_special.md?ref=ea3c2c027769980c0501dc615ef7e755d206af62",
            "patch": "@@ -7,6 +7,7 @@ http://www.apache.org/licenses/LICENSE-2.0\n \n Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n \n ⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n rendered properly in your Markdown viewer."
        },
        {
            "sha": "e8876eac7006aeb7ff8f6347c01c0142002d061c",
            "filename": "src/transformers/models/perceiver/convert_perceiver_haiku_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ea3c2c027769980c0501dc615ef7e755d206af62/src%2Ftransformers%2Fmodels%2Fperceiver%2Fconvert_perceiver_haiku_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ea3c2c027769980c0501dc615ef7e755d206af62/src%2Ftransformers%2Fmodels%2Fperceiver%2Fconvert_perceiver_haiku_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fperceiver%2Fconvert_perceiver_haiku_to_pytorch.py?ref=ea3c2c027769980c0501dc615ef7e755d206af62",
            "patch": "@@ -148,7 +148,7 @@ def rename_keys(state_dict, architecture):\n         )\n         name = name.replace(\"classification_decoder/~/basic_decoder/output/b\", \"decoder.decoder.final_layer.bias\")\n         name = name.replace(\"classification_decoder/~/basic_decoder/output/w\", \"decoder.decoder.final_layer.weight\")\n-        name = name = name.replace(\"classification_decoder/~/basic_decoder/~/\", \"decoder.decoder.\")\n+        name = name.replace(\"classification_decoder/~/basic_decoder/~/\", \"decoder.decoder.\")\n         name = name.replace(\"basic_decoder/cross_attention/\", \"decoder.decoding_cross_attention.\")\n         name = name.replace(\"basic_decoder/~/\", \"decoder.\")\n "
        },
        {
            "sha": "8d60c4b374b8a24d6ef6c8e8d5ca2be86b86de2a",
            "filename": "utils/update_metadata.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ea3c2c027769980c0501dc615ef7e755d206af62/utils%2Fupdate_metadata.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ea3c2c027769980c0501dc615ef7e755d206af62/utils%2Fupdate_metadata.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fupdate_metadata.py?ref=ea3c2c027769980c0501dc615ef7e755d206af62",
            "patch": "@@ -109,7 +109,7 @@\n         \"MODEL_FOR_VISUAL_QUESTION_ANSWERING_MAPPING_NAMES\",\n         \"AutoModelForVisualQuestionAnswering\",\n     ),\n-    (\"image-to-text\", \"MODEL_FOR_FOR_VISION_2_SEQ_MAPPING_NAMES\", \"AutoModelForVision2Seq\"),\n+    (\"image-to-text\", \"MODEL_FOR_VISION_2_SEQ_MAPPING_NAMES\", \"AutoModelForVision2Seq\"),\n     (\n         \"zero-shot-image-classification\",\n         \"MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING_NAMES\","
        }
    ],
    "stats": {
        "total": 5,
        "additions": 3,
        "deletions": 2
    }
}