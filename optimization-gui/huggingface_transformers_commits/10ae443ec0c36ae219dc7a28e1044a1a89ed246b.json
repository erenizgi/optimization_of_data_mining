{
    "author": "yeliudev",
    "message": "Fix Qwen2.5-VL Video Processor (#38366)\n\n* Update processing_qwen2_5_vl.py\n\n* Update processing_qwen2_5_vl.py\n\n* Update modular_qwen2_5_vl.py\n\n* Fix CI\n\n* Update modular_qwen2_5_vl.py\n\n* Update processing_qwen2_5_vl.py\n\n* Update video_processing_utils.py",
    "sha": "10ae443ec0c36ae219dc7a28e1044a1a89ed246b",
    "files": [
        {
            "sha": "530d74d51b5bb66fb95f77dd90696d954c5356e3",
            "filename": "src/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/10ae443ec0c36ae219dc7a28e1044a1a89ed246b/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10ae443ec0c36ae219dc7a28e1044a1a89ed246b/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py?ref=10ae443ec0c36ae219dc7a28e1044a1a89ed246b",
            "patch": "@@ -1013,10 +1013,12 @@ def __call__(\n             image_grid_thw = image_inputs[\"image_grid_thw\"]\n \n         if videos is not None:\n+            # pop fps in advance for passing kwargs validation\n+            fps = output_kwargs[\"videos_kwargs\"].pop(\"fps\", 2.0)\n+\n             videos_inputs = self.video_processor(videos=videos, **output_kwargs[\"videos_kwargs\"])\n             video_grid_thw = videos_inputs[\"video_grid_thw\"]\n \n-            fps = output_kwargs[\"videos_kwargs\"].pop(\"fps\", 2.0)\n             if isinstance(fps, (int, float)):\n                 second_per_grid_ts = [self.video_processor.temporal_patch_size / fps] * len(video_grid_thw)\n             elif hasattr(fps, \"__len__\") and len(fps) == len(video_grid_thw):"
        },
        {
            "sha": "8b05b725bf94cc1b1a9a60ec9fe46739b43d94e8",
            "filename": "src/transformers/models/qwen2_5_vl/processing_qwen2_5_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/10ae443ec0c36ae219dc7a28e1044a1a89ed246b/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fprocessing_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10ae443ec0c36ae219dc7a28e1044a1a89ed246b/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fprocessing_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fprocessing_qwen2_5_vl.py?ref=10ae443ec0c36ae219dc7a28e1044a1a89ed246b",
            "patch": "@@ -152,10 +152,12 @@ def __call__(\n             image_grid_thw = image_inputs[\"image_grid_thw\"]\n \n         if videos is not None:\n+            # pop fps in advance for passing kwargs validation\n+            fps = output_kwargs[\"videos_kwargs\"].pop(\"fps\", 2.0)\n+\n             videos_inputs = self.video_processor(videos=videos, **output_kwargs[\"videos_kwargs\"])\n             video_grid_thw = videos_inputs[\"video_grid_thw\"]\n \n-            fps = output_kwargs[\"videos_kwargs\"].pop(\"fps\", 2.0)\n             if isinstance(fps, (int, float)):\n                 second_per_grid_ts = [self.video_processor.temporal_patch_size / fps] * len(video_grid_thw)\n             elif hasattr(fps, \"__len__\") and len(fps) == len(video_grid_thw):"
        },
        {
            "sha": "527760eb8daf9e8b1e04110fc879a4bea25c70a1",
            "filename": "src/transformers/video_processing_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/10ae443ec0c36ae219dc7a28e1044a1a89ed246b/src%2Ftransformers%2Fvideo_processing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10ae443ec0c36ae219dc7a28e1044a1a89ed246b/src%2Ftransformers%2Fvideo_processing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fvideo_processing_utils.py?ref=10ae443ec0c36ae219dc7a28e1044a1a89ed246b",
            "patch": "@@ -250,7 +250,10 @@ def preprocess(\n         videos: VideoInput,\n         **kwargs: Unpack[VideosKwargs],\n     ) -> BatchFeature:\n-        validate_kwargs(captured_kwargs=kwargs.keys(), valid_processor_keys=self.valid_kwargs.__annotations__.keys())\n+        validate_kwargs(\n+            captured_kwargs=kwargs.keys(),\n+            valid_processor_keys=list(self.valid_kwargs.__annotations__.keys()) + [\"return_tensors\"],\n+        )\n         # Set default kwargs from self. This ensures that if a kwarg is not provided\n         # by the user, it gets its default value from the instance, or is set to None.\n         for kwarg_name in self.valid_kwargs.__annotations__:"
        }
    ],
    "stats": {
        "total": 13,
        "additions": 10,
        "deletions": 3
    }
}