{
    "author": "ved1beta",
    "message": "fix default value of config to match checkpionts in LLaVa-OV models (#39163)",
    "sha": "9b2f5b66d83e1b15dd1430f887f2037fd4039992",
    "files": [
        {
            "sha": "f6f40c1bd83e0d41095d9d68907a51388aa3ff1f",
            "filename": "src/transformers/models/llava_onevision/configuration_llava_onevision.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9b2f5b66d83e1b15dd1430f887f2037fd4039992/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fconfiguration_llava_onevision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9b2f5b66d83e1b15dd1430f887f2037fd4039992/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fconfiguration_llava_onevision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fconfiguration_llava_onevision.py?ref=9b2f5b66d83e1b15dd1430f887f2037fd4039992",
            "patch": "@@ -176,7 +176,7 @@ def __init__(\n                 patch_size=14,\n                 image_size=384,\n                 num_hidden_layers=26,\n-                num_attention_heads=14,\n+                num_attention_heads=16,\n                 vision_use_head=False,\n             )\n "
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}