{
    "author": "yuekaizhang",
    "message": "Fix qwen-omni processor text only mode (#40336)\n\n* Fix qwen-omni processor text only mode\n\n* remove try except\n\n---------\n\nCo-authored-by: yuekaiz <yuekaiz@mgmt1-login.cm.cluster>",
    "sha": "022af24fccd5426a06de9b9f6c79aeffec6f7cdd",
    "files": [
        {
            "sha": "7a72f02c22d329ab5b87c374ad5a50d7be296746",
            "filename": "src/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py",
            "status": "modified",
            "additions": 11,
            "deletions": 10,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/022af24fccd5426a06de9b9f6c79aeffec6f7cdd/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/022af24fccd5426a06de9b9f6c79aeffec6f7cdd/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py?ref=022af24fccd5426a06de9b9f6c79aeffec6f7cdd",
            "patch": "@@ -195,16 +195,17 @@ def __call__(\n         if not isinstance(text, list):\n             text = [text]\n \n-        text = self.replace_multimodal_special_tokens(\n-            text,\n-            audio_lengths,\n-            image_grid_thw,\n-            video_grid_thw,\n-            video_second_per_grid=video_second_per_grid,\n-            use_audio_in_video=use_audio_in_video,\n-            position_id_per_seconds=position_id_per_seconds,\n-            seconds_per_chunk=seconds_per_chunk,\n-        )\n+        if images is not None or videos is not None or audio is not None:\n+            text = self.replace_multimodal_special_tokens(\n+                text,\n+                audio_lengths,\n+                image_grid_thw,\n+                video_grid_thw,\n+                video_second_per_grid=video_second_per_grid,\n+                use_audio_in_video=use_audio_in_video,\n+                position_id_per_seconds=position_id_per_seconds,\n+                seconds_per_chunk=seconds_per_chunk,\n+            )\n \n         texts_inputs = self.tokenizer(text, **output_kwargs[\"text_kwargs\"])\n "
        }
    ],
    "stats": {
        "total": 21,
        "additions": 11,
        "deletions": 10
    }
}