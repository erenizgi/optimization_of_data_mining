{
    "author": "stevhliu",
    "message": "[docs] Remove sortish_sampler (#35539)\n\nremove",
    "sha": "b05df6611e6e3e6834acca2b50baeb7cdd5fbe3c",
    "files": [
        {
            "sha": "5342b7add3932c542e35247e52920d8fc91ed325",
            "filename": "src/transformers/training_args_seq2seq.py",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/b05df6611e6e3e6834acca2b50baeb7cdd5fbe3c/src%2Ftransformers%2Ftraining_args_seq2seq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b05df6611e6e3e6834acca2b50baeb7cdd5fbe3c/src%2Ftransformers%2Ftraining_args_seq2seq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftraining_args_seq2seq.py?ref=b05df6611e6e3e6834acca2b50baeb7cdd5fbe3c",
            "patch": "@@ -30,12 +30,6 @@\n class Seq2SeqTrainingArguments(TrainingArguments):\n     \"\"\"\n     Args:\n-        sortish_sampler (`bool`, *optional*, defaults to `False`):\n-            Whether to use a *sortish sampler* or not. Only possible if the underlying datasets are *Seq2SeqDataset*\n-            for now but will become generally available in the near future.\n-\n-            It sorts the inputs according to lengths in order to minimize the padding size, with a bit of randomness\n-            for the training set.\n         predict_with_generate (`bool`, *optional*, defaults to `False`):\n             Whether to use generate to calculate generative metrics (ROUGE, BLEU).\n         generation_max_length (`int`, *optional*):"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 0,
        "deletions": 6
    }
}