{
    "author": "zucchini-nlp",
    "message": "Check model inputs - hidden states (#40994)\n\n* update all models\n\n* fix copies\n\n* skip aria tests\n\n* update other models\n\n* skip should be in test, not tester\n\n* i think this is more descriptive as a name\n\n* find and replace for new models",
    "sha": "9db58abd6e21c34dbb44068432f2e4b146ab472b",
    "files": [
        {
            "sha": "e1f9929e645059f6e49b9d9a06d15baca5e172ed",
            "filename": "examples/modular-transformers/modeling_dummy_bert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/examples%2Fmodular-transformers%2Fmodeling_dummy_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/examples%2Fmodular-transformers%2Fmodeling_dummy_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fmodular-transformers%2Fmodeling_dummy_bert.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -657,7 +657,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "ff80e8d70b0f8e2cca11fb6e35dbe85f5b598437",
            "filename": "examples/modular-transformers/modeling_roberta.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/examples%2Fmodular-transformers%2Fmodeling_roberta.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/examples%2Fmodular-transformers%2Fmodeling_roberta.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fmodular-transformers%2Fmodeling_roberta.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -660,7 +660,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "e2b5452bea0e047bc01a6cdacb223ee3d681d510",
            "filename": "examples/modular-transformers/modeling_super.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/examples%2Fmodular-transformers%2Fmodeling_super.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/examples%2Fmodular-transformers%2Fmodeling_super.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fmodular-transformers%2Fmodeling_super.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -323,7 +323,7 @@ def __init__(self, config: SuperConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "c29270b5687db779ecffa3bc90fb9955b453ac05",
            "filename": "src/transformers/models/aimv2/modeling_aimv2.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Faimv2%2Fmodeling_aimv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Faimv2%2Fmodeling_aimv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faimv2%2Fmodeling_aimv2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -444,7 +444,7 @@ def get_input_embeddings(self) -> nn.Module:\n         return self.embeddings.patch_embed\n \n     @deprecate_kwarg(\"attention_mask\", version=\"v4.58.0\")\n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,\n@@ -520,7 +520,7 @@ def get_input_embeddings(self) -> nn.Module:\n     def set_input_embeddings(self, value):\n         self.embeddings.token_embedding = value\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "18ef50e5bcc1c153aee1b11c8875a02eebc166ff",
            "filename": "src/transformers/models/aimv2/modular_aimv2.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Faimv2%2Fmodular_aimv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Faimv2%2Fmodular_aimv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faimv2%2Fmodular_aimv2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -488,7 +488,7 @@ def get_input_embeddings(self) -> nn.Module:\n         return self.embeddings.patch_embed\n \n     @deprecate_kwarg(\"attention_mask\", version=\"v4.58.0\")\n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,\n@@ -564,7 +564,7 @@ def get_input_embeddings(self) -> nn.Module:\n     def set_input_embeddings(self, value):\n         self.embeddings.token_embedding = value\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a5758742070dea0bec27bb7bd086d0424588a5e5",
            "filename": "src/transformers/models/albert/modeling_albert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Falbert%2Fmodeling_albert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Falbert%2Fmodeling_albert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Falbert%2Fmodeling_albert.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -457,7 +457,7 @@ def _prune_heads(self, heads_to_prune: dict[int, list[int]]) -> None:\n             inner_group_idx = int(layer - group_idx * self.config.inner_group_num)\n             self.encoder.albert_layer_groups[group_idx].albert_layers[inner_group_idx].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a121146d86989fbad6ece183259df0e06be3dbe4",
            "filename": "src/transformers/models/apertus/modeling_apertus.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fapertus%2Fmodeling_apertus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fapertus%2Fmodeling_apertus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fapertus%2Fmodeling_apertus.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -339,7 +339,7 @@ def __init__(self, config: ApertusConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "7dc4ba885af2f704ae275a51b6f4aef0d7451174",
            "filename": "src/transformers/models/arcee/modeling_arcee.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Farcee%2Fmodeling_arcee.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Farcee%2Fmodeling_arcee.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Farcee%2Fmodeling_arcee.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -344,7 +344,7 @@ def __init__(self, config: ArceeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "fa6ef38045a3eed4d0bb3e0270ad8ae23b62fd27",
            "filename": "src/transformers/models/aria/modeling_aria.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -669,7 +669,7 @@ def __init__(self, config: AriaTextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "9281905799066be6e80fdbf449da0ddf627717f7",
            "filename": "src/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -363,7 +363,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "bccbea0264b766811a43e0cfe05f1987536ad12b",
            "filename": "src/transformers/models/aya_vision/modeling_aya_vision.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodeling_aya_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodeling_aya_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodeling_aya_vision.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -263,7 +263,7 @@ def get_placeholder_mask(\n             )\n         return special_image_mask\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "8b34aa5617bfedf92fa9082992784b6861a45940",
            "filename": "src/transformers/models/aya_vision/modular_aya_vision.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodular_aya_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodular_aya_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodular_aya_vision.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -162,7 +162,7 @@ def get_image_features(\n         image_features = self.multi_modal_projector(selected_image_feature)\n         return image_features\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "f3525485e9a2a5712a5f56eb98c12677471007a6",
            "filename": "src/transformers/models/bert/modeling_bert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fbert%2Fmodeling_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fbert%2Fmodeling_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbert%2Fmodeling_bert.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -739,7 +739,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "192df08164cf6b522b78b70cd4a0d42c97c14565",
            "filename": "src/transformers/models/bert_generation/modeling_bert_generation.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fbert_generation%2Fmodeling_bert_generation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fbert_generation%2Fmodeling_bert_generation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbert_generation%2Fmodeling_bert_generation.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -600,7 +600,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "9ef0885770c51d540b42bd885cd17987dc25ba61",
            "filename": "src/transformers/models/bitnet/modeling_bitnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fbitnet%2Fmodeling_bitnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fbitnet%2Fmodeling_bitnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbitnet%2Fmodeling_bitnet.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -343,7 +343,7 @@ def __init__(self, config: BitNetConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "7a586e92f0ee3534cbd02625d9c346a9eeb6c72f",
            "filename": "src/transformers/models/blip/modeling_blip.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -499,7 +499,7 @@ def __init__(self, config: BlipVisionConfig):\n \n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "99823a69385dfe2b89add27ef1a9644758e28ba7",
            "filename": "src/transformers/models/blip_2/modeling_blip_2.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -490,7 +490,7 @@ def __init__(self, config: Blip2VisionConfig):\n \n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,\n@@ -989,7 +989,7 @@ def get_extended_attention_mask(\n         extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n         return extended_attention_mask\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "3f5459ccbff02cc132b330076c94d68d9fdd0efc",
            "filename": "src/transformers/models/blt/modeling_blt.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fblt%2Fmodeling_blt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fblt%2Fmodeling_blt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblt%2Fmodeling_blt.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -577,7 +577,7 @@ def __init__(self, config: BltLocalDecoderConfig):\n \n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,\n@@ -1047,7 +1047,7 @@ def __init__(self, config: BltConfig):\n             self.patcher = None\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "b9047bc852d5363a8cb0a24b1ef91dfc5cb8df8f",
            "filename": "src/transformers/models/blt/modular_blt.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fblt%2Fmodular_blt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fblt%2Fmodular_blt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblt%2Fmodular_blt.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -536,7 +536,7 @@ def __init__(self, config: BltLocalDecoderConfig):\n \n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,\n@@ -799,7 +799,7 @@ def __init__(self, config: BltConfig):\n             self.patcher = None\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "002598dd2af8f7aef26d36fe65e9372e92d8c653",
            "filename": "src/transformers/models/camembert/modeling_camembert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -719,7 +719,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "1449b2c3e1b6c413fd80589cc9933c7c4c580a5a",
            "filename": "src/transformers/models/cohere/modeling_cohere.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fcohere%2Fmodeling_cohere.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fcohere%2Fmodeling_cohere.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere%2Fmodeling_cohere.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -376,7 +376,7 @@ def __init__(self, config: CohereConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "8459df776f630fed45bc79286062c74b2dbc82a2",
            "filename": "src/transformers/models/cohere2/modeling_cohere2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodeling_cohere2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodeling_cohere2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodeling_cohere2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -351,7 +351,7 @@ def __init__(self, config: Cohere2Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "5337f0dac45ac32134ff77a014c29c3c8fd86a19",
            "filename": "src/transformers/models/cohere2_vision/modeling_cohere2_vision.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodeling_cohere2_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodeling_cohere2_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodeling_cohere2_vision.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -213,7 +213,7 @@ def get_placeholder_mask(\n             )\n         return special_image_mask\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,\n@@ -306,7 +306,7 @@ def vision_tower(self):\n     def multi_modal_projector(self):\n         return self.model.multi_modal_projector\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "997a6f2d638e1a5df9a0f96cc3bccdeb7c8052fe",
            "filename": "src/transformers/models/cohere2_vision/modular_cohere2_vision.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodular_cohere2_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodular_cohere2_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodular_cohere2_vision.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -109,7 +109,7 @@ def get_image_features(self, pixel_values: torch.FloatTensor):\n         image_features = self.multi_modal_projector(selected_image_feature)\n         return image_features\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,\n@@ -162,7 +162,7 @@ class Cohere2VisionForConditionalGeneration(AyaVisionForConditionalGeneration):\n     def get_image_features(self, pixel_values: torch.FloatTensor):\n         return self.model.get_image_features(pixel_values=pixel_values)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "18b80b1ef12d1b28a3ba381815bf406b4a649def",
            "filename": "src/transformers/models/csm/modeling_csm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodeling_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodeling_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodeling_csm.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -409,7 +409,7 @@ def __init__(self, config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,\n@@ -662,7 +662,7 @@ def __init__(self, config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "89a6e52a063b4a491f1c2df2a06648d35ea39789",
            "filename": "src/transformers/models/csm/modular_csm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodular_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodular_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodular_csm.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -156,7 +156,7 @@ def __init__(self, config):\n         self.embed_tokens = nn.Embedding((config.num_codebooks * config.vocab_size), config.backbone_hidden_size)\n         self.inputs_embeds_projector = nn.Linear(config.backbone_hidden_size, config.hidden_size, bias=False)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,\n@@ -395,7 +395,7 @@ def __init__(self, config):\n         super().__init__(config)\n         self.embed_tokens = CsmBackboneModelEmbeddings(config)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(self, **super_kwargs):\n         r\"\"\""
        },
        {
            "sha": "23c600bbbb6ab615e95048b917f636e359487b46",
            "filename": "src/transformers/models/data2vec/modeling_data2vec_text.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_text.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -679,7 +679,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "e82031a27c5972d4408ef4fe12be47bc9b0f5c1a",
            "filename": "src/transformers/models/dbrx/modeling_dbrx.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodeling_dbrx.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodeling_dbrx.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodeling_dbrx.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -489,7 +489,7 @@ def get_input_embeddings(self) -> nn.Embedding:\n     def set_input_embeddings(self, value: nn.Embedding):\n         self.wte = value\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "9201fadeca142ea523bd05ce4184a6a0f39f182c",
            "filename": "src/transformers/models/dbrx/modular_dbrx.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodular_dbrx.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodular_dbrx.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodular_dbrx.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -388,7 +388,7 @@ def get_input_embeddings(self) -> nn.Embedding:\n     def set_input_embeddings(self, value: nn.Embedding):\n         self.wte = value\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "66135270c6212769f8131ce0c22eb1dbfeb0bf47",
            "filename": "src/transformers/models/deepseek_v2/modeling_deepseek_v2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -459,7 +459,7 @@ def __init__(self, config: DeepseekV2Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "ab314a7d21a7f3a028c307fc6146334cb5f07cce",
            "filename": "src/transformers/models/deepseek_v3/modeling_deepseek_v3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -539,7 +539,7 @@ def __init__(self, config: DeepseekV3Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "dfa2f191e7892a9efc05c681e7610cd48664cb14",
            "filename": "src/transformers/models/deit/modeling_deit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -438,7 +438,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "599f427280fce1ab7e640e4e438e3e7052ea1caf",
            "filename": "src/transformers/models/diffllama/modeling_diffllama.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdiffllama%2Fmodeling_diffllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdiffllama%2Fmodeling_diffllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdiffllama%2Fmodeling_diffllama.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -608,7 +608,7 @@ def __init__(self, config: DiffLlamaConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "2bf76b9db35c5f9578b321f40ed622ab90be2740",
            "filename": "src/transformers/models/dinov2/modeling_dinov2.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -490,7 +490,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,\n@@ -602,7 +602,7 @@ def __init__(self, config):\n     def get_input_embeddings(self) -> Dinov2PatchEmbeddings:\n         return self.embeddings.patch_embeddings\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self, pixel_values: torch.Tensor, output_hidden_states: Optional[bool] = None, **kwargs"
        },
        {
            "sha": "5679f6bcf250a06af639661fb868f04ef8581c53",
            "filename": "src/transformers/models/dinov2_with_registers/modeling_dinov2_with_registers.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -507,7 +507,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,\n@@ -622,7 +622,7 @@ def __init__(self, config):\n     def get_input_embeddings(self) -> Dinov2WithRegistersPatchEmbeddings:\n         return self.embeddings.patch_embeddings\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "99b9794c3235215df905707d39138b315ced46a1",
            "filename": "src/transformers/models/dinov3_vit/modeling_dinov3_vit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodeling_dinov3_vit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodeling_dinov3_vit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodeling_dinov3_vit.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -494,7 +494,7 @@ def __init__(self, config: DINOv3ViTConfig):\n     def get_input_embeddings(self):\n         return self.embeddings.patch_embeddings\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "9acb2561163a051417e109c518f667915d590f22",
            "filename": "src/transformers/models/dinov3_vit/modular_dinov3_vit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodular_dinov3_vit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodular_dinov3_vit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodular_dinov3_vit.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -389,7 +389,7 @@ def __init__(self, config: DINOv3ViTConfig):\n     def get_input_embeddings(self):\n         return self.embeddings.patch_embeddings\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "706f3a40a70e93a52356bc5f7f0d1fd8d222d7e3",
            "filename": "src/transformers/models/distilbert/modeling_distilbert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdistilbert%2Fmodeling_distilbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdistilbert%2Fmodeling_distilbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdistilbert%2Fmodeling_distilbert.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -412,7 +412,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.transformer.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "dd495a948356c6f8df581f8777b185569d12ff9a",
            "filename": "src/transformers/models/doge/modeling_doge.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdoge%2Fmodeling_doge.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdoge%2Fmodeling_doge.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdoge%2Fmodeling_doge.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -527,7 +527,7 @@ def __init__(self, config: DogeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "41081e6defe692dde5c0768d6f6285f9753737e2",
            "filename": "src/transformers/models/dots1/modeling_dots1.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -457,7 +457,7 @@ def __init__(self, config: Dots1Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "f302b8dc94aecfe2d622dd32436c9575ce0f351c",
            "filename": "src/transformers/models/dpt/modeling_dpt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -801,7 +801,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a3eef22dce552b9a6f983b69dfbbd213f4cc01f6",
            "filename": "src/transformers/models/edgetam/modeling_edgetam.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodeling_edgetam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodeling_edgetam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodeling_edgetam.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -444,7 +444,7 @@ def __init__(self, config: EdgeTamVisionConfig):\n \n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         pixel_values: Optional[torch.FloatTensor] = None,\n@@ -1028,7 +1028,7 @@ def get_prompt_embeddings(\n         )\n         return prompt_output\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "5ed9841aad694a186d91877fcfe61324c4490694",
            "filename": "src/transformers/models/edgetam/modular_edgetam.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodular_edgetam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodular_edgetam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodular_edgetam.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -208,7 +208,7 @@ class EdgeTamVisionModel(Sam2VisionModel):\n     def get_input_embeddings(self):\n         raise NotImplementedError(\"Can't get input embeddings from timm wrapper model\")\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         pixel_values: Optional[torch.FloatTensor] = None,"
        },
        {
            "sha": "1fb93d48eb9bbef86796b21f8b1e0af9f275bba1",
            "filename": "src/transformers/models/efficientloftr/modeling_efficientloftr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fefficientloftr%2Fmodeling_efficientloftr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fefficientloftr%2Fmodeling_efficientloftr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fefficientloftr%2Fmodeling_efficientloftr.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -680,7 +680,7 @@ def __init__(self, config: EfficientLoFTRConfig):\n \n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "16369986b6418b607cf4ed9a0536f6129120dd3c",
            "filename": "src/transformers/models/electra/modeling_electra.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Felectra%2Fmodeling_electra.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Felectra%2Fmodeling_electra.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Felectra%2Fmodeling_electra.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -677,7 +677,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "ad070efc1d3e18bf773394411a4042e8a2641e8a",
            "filename": "src/transformers/models/emu3/modeling_emu3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -1166,7 +1166,7 @@ def __init__(self, config: Emu3Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a593678e7950df1b184d7ff9fa2159b3a9c39748",
            "filename": "src/transformers/models/eomt/modeling_eomt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Feomt%2Fmodeling_eomt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Feomt%2Fmodeling_eomt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Feomt%2Fmodeling_eomt.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -1082,7 +1082,7 @@ def get_loss_dict(\n     def get_loss(self, loss_dict: dict[str, Tensor]) -> Tensor:\n         return sum(loss_dict.values())\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "7204a064e2035b9d94f2c069fb7dd48bb296c933",
            "filename": "src/transformers/models/eomt/modular_eomt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Feomt%2Fmodular_eomt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Feomt%2Fmodular_eomt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Feomt%2Fmodular_eomt.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -492,7 +492,7 @@ def _disable_attention_mask(attn_mask, prob, num_query_tokens, encoder_start_tok\n \n         return attn_mask\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "138cf9d0cb244b27904e81bc105e5e70566224fd",
            "filename": "src/transformers/models/ernie/modeling_ernie.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fernie%2Fmodeling_ernie.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fernie%2Fmodeling_ernie.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie%2Fmodeling_ernie.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -701,7 +701,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "27d1bca686ac2082e35ddca0fc8a6c28dc16e109",
            "filename": "src/transformers/models/ernie/modular_ernie.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fernie%2Fmodular_ernie.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fernie%2Fmodular_ernie.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie%2Fmodular_ernie.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -203,7 +203,7 @@ def __init__(self, config, add_pooling_layer=True):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "8f4e6e36b0dd61bb98e40f1d162fbee8526e8a52",
            "filename": "src/transformers/models/ernie4_5/modeling_ernie4_5.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fernie4_5%2Fmodeling_ernie4_5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fernie4_5%2Fmodeling_ernie4_5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie4_5%2Fmodeling_ernie4_5.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -342,7 +342,7 @@ def __init__(self, config: Ernie4_5Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "26b90355393ab680a79abcbb5d10d5a8d837e251",
            "filename": "src/transformers/models/ernie4_5_moe/modeling_ernie4_5_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fernie4_5_moe%2Fmodeling_ernie4_5_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fernie4_5_moe%2Fmodeling_ernie4_5_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie4_5_moe%2Fmodeling_ernie4_5_moe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -489,7 +489,7 @@ def __init__(self, config: Ernie4_5_MoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "125963d5d66cae71f1527eb1bae4a900014e0221",
            "filename": "src/transformers/models/ernie4_5_moe/modular_ernie4_5_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fernie4_5_moe%2Fmodular_ernie4_5_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fernie4_5_moe%2Fmodular_ernie4_5_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie4_5_moe%2Fmodular_ernie4_5_moe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -256,7 +256,7 @@ def __init__(self, config: Ernie4_5_MoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "da16913d8448eb917ce7f7c42007416f104b3fd6",
            "filename": "src/transformers/models/esm/modeling_esm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fesm%2Fmodeling_esm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fesm%2Fmodeling_esm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fesm%2Fmodeling_esm.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -662,7 +662,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "2cabbbc93d7e54c857a3e050ff32c2f7dd27e3c6",
            "filename": "src/transformers/models/evolla/modeling_evolla.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fevolla%2Fmodeling_evolla.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fevolla%2Fmodeling_evolla.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fevolla%2Fmodeling_evolla.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -596,7 +596,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.Tensor],\n@@ -1383,7 +1383,7 @@ def set_input_embeddings(self, value):\n         self.embed_tokens = value\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "496a284935abd6031f03ccfec8bfe208d70c1a5f",
            "filename": "src/transformers/models/evolla/modular_evolla.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fevolla%2Fmodular_evolla.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fevolla%2Fmodular_evolla.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fevolla%2Fmodular_evolla.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -241,7 +241,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.Tensor],\n@@ -835,7 +835,7 @@ def set_input_embeddings(self, value):\n         self.embed_tokens = value\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "c0c233cc5c20debf400498030de7e00391e8f048",
            "filename": "src/transformers/models/exaone4/modeling_exaone4.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodeling_exaone4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodeling_exaone4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodeling_exaone4.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -352,7 +352,7 @@ def __init__(self, config: Exaone4Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "d437b12bffb7d527a7b6c29475365ef5b758d145",
            "filename": "src/transformers/models/exaone4/modular_exaone4.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodular_exaone4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodular_exaone4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodular_exaone4.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -364,7 +364,7 @@ def __init__(self, config: Exaone4Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "4a32ed4eb82bd52484dce81d27b750fa99a69c03",
            "filename": "src/transformers/models/flex_olmo/modeling_flex_olmo.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodeling_flex_olmo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodeling_flex_olmo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodeling_flex_olmo.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -406,7 +406,7 @@ def __init__(self, config: FlexOlmoConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "8a341b19ea4e64b0cffec37ecdb866bea689a437",
            "filename": "src/transformers/models/flex_olmo/modular_flex_olmo.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodular_flex_olmo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodular_flex_olmo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodular_flex_olmo.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -282,7 +282,7 @@ class FlexOlmoPreTrainedModel(MixtralPreTrainedModel):\n # FlexOlmo model is identical to Mixtral model except:\n # - FlexOlmo does not use sliding window attention.\n class FlexOlmoModel(MixtralModel):\n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "2b3c298183b0a51d681e5b5ae4591f7f452defe5",
            "filename": "src/transformers/models/gemma/modeling_gemma.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgemma%2Fmodeling_gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgemma%2Fmodeling_gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma%2Fmodeling_gemma.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -349,7 +349,7 @@ def __init__(self, config: GemmaConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "038d8746ac2dd633aace3dd29b84861a2ad976a7",
            "filename": "src/transformers/models/gemma2/modeling_gemma2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -379,7 +379,7 @@ def __init__(self, config: Gemma2Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "8c331737314618dc2e5464ddd9c4c9bceb398663",
            "filename": "src/transformers/models/gemma3/modeling_gemma3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodeling_gemma3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodeling_gemma3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodeling_gemma3.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -482,7 +482,7 @@ def __init__(self, config: Gemma3TextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "1ed2bcb52099b97e847987f51e2b220f8eadb4fd",
            "filename": "src/transformers/models/glm/modeling_glm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fglm%2Fmodeling_glm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fglm%2Fmodeling_glm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm%2Fmodeling_glm.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -358,7 +358,7 @@ def __init__(self, config: GlmConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "d1e7a30102fa9c930d231464fff8ba48e8847a6a",
            "filename": "src/transformers/models/glm4/modeling_glm4.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fglm4%2Fmodeling_glm4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fglm4%2Fmodeling_glm4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4%2Fmodeling_glm4.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -362,7 +362,7 @@ def __init__(self, config: Glm4Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "93fad05de128d4850a32312090f4485e9402fdb6",
            "filename": "src/transformers/models/glm4_moe/modeling_glm4_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fglm4_moe%2Fmodeling_glm4_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fglm4_moe%2Fmodeling_glm4_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4_moe%2Fmodeling_glm4_moe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -481,7 +481,7 @@ def __init__(self, config: Glm4MoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "da19208119885e0274ebf679e757654d1c98a2e1",
            "filename": "src/transformers/models/glm4v/modeling_glm4v.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -806,7 +806,7 @@ def __init__(self, config: Glm4vTextConfig):\n         self.post_init()\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "2afc02923cb7e356106e7e2dbdc0cbab63d1685a",
            "filename": "src/transformers/models/glm4v/modular_glm4v.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -871,7 +871,7 @@ def __init__(self, config: Glm4vTextConfig):\n         del self.has_sliding_layers\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "6d9ba48e99b2c51411d4c10543a533e6ce3b440a",
            "filename": "src/transformers/models/glm4v_moe/modeling_glm4v_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -927,7 +927,7 @@ def __init__(self, config: Glm4vMoeTextConfig):\n         self.post_init()\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "eb22e62bfd7df1f56b8c5b13ac6fcacb90df6696",
            "filename": "src/transformers/models/got_ocr2/modeling_got_ocr2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fmodeling_got_ocr2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fmodeling_got_ocr2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fmodeling_got_ocr2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -433,7 +433,7 @@ def __init__(self, config: GotOcr2VisionConfig):\n     def get_input_embeddings(self):\n         return self.patch_embed\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     def forward(\n         self, pixel_values: Optional[torch.FloatTensor] = None, **kwargs: Unpack[TransformersKwargs]\n     ) -> GotOcr2VisionEncoderOutput:"
        },
        {
            "sha": "60a53b2668e3e508186831a75ed0c5f4555de7c6",
            "filename": "src/transformers/models/gpt_neox/modeling_gpt_neox.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgpt_neox%2Fmodeling_gpt_neox.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgpt_neox%2Fmodeling_gpt_neox.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_neox%2Fmodeling_gpt_neox.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -384,7 +384,7 @@ def __init__(self, config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "cac0c383cefeabbb5f8bb020d8449daae11f1ef7",
            "filename": "src/transformers/models/gpt_oss/modeling_gpt_oss.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodeling_gpt_oss.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodeling_gpt_oss.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodeling_gpt_oss.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -456,7 +456,7 @@ def __init__(self, config: GptOssConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "9a25b1e629025296ddf6bc7ae7c0737efbe66d7e",
            "filename": "src/transformers/models/gpt_oss/modular_gpt_oss.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodular_gpt_oss.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodular_gpt_oss.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodular_gpt_oss.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -386,7 +386,7 @@ def _init_weights(self, module):\n class GptOssModel(MixtralModel):\n     _no_split_modules = [\"GptOssDecoderLayer\"]\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "21cf1af6e2355cb7a8b143107d5f7e157488bf4a",
            "filename": "src/transformers/models/granite/modeling_granite.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgranite%2Fmodeling_granite.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgranite%2Fmodeling_granite.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranite%2Fmodeling_granite.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -375,7 +375,7 @@ def __init__(self, config: GraniteConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "f62074a0b2776447ab8e85ef09371f85e6bc0a3e",
            "filename": "src/transformers/models/granitemoe/modeling_granitemoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -460,7 +460,7 @@ def __init__(self, config: GraniteMoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "cfe08cebee536263dff9600a1cd64ffbc7f103f9",
            "filename": "src/transformers/models/granitemoe/modular_granitemoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodular_granitemoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodular_granitemoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodular_granitemoe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -163,7 +163,7 @@ def __init__(self, config: GraniteMoeConfig):\n         self.norm = GraniteMoeRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n         self.embedding_multiplier = config.embedding_multiplier\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "94cd836acbbf8ab3e374e461d56d1b5d87ab827c",
            "filename": "src/transformers/models/granitemoehybrid/modeling_granitemoehybrid.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -1203,7 +1203,7 @@ def __init__(self, config: GraniteMoeHybridConfig):\n         self.post_init()\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "b71c89c69f1078735564687236415b4615f66b05",
            "filename": "src/transformers/models/granitemoehybrid/modular_granitemoehybrid.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodular_granitemoehybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodular_granitemoehybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodular_granitemoehybrid.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -187,7 +187,7 @@ def __init__(self, config: GraniteMoeHybridConfig):\n         self.embedding_multiplier = config.embedding_multiplier\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "05ae91159a8fa03bc90eda79e8d3a3b7cfdb9db7",
            "filename": "src/transformers/models/granitemoeshared/modeling_granitemoeshared.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodeling_granitemoeshared.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodeling_granitemoeshared.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodeling_granitemoeshared.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -531,7 +531,7 @@ def __init__(self, config: GraniteMoeSharedConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "c0103cefa9b08fc7af627359817c0b6191d4452b",
            "filename": "src/transformers/models/helium/modeling_helium.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fhelium%2Fmodeling_helium.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fhelium%2Fmodeling_helium.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhelium%2Fmodeling_helium.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -343,7 +343,7 @@ def __init__(self, config: HeliumConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "acd6f926ea436904611db8dc43eca5852c9b966d",
            "filename": "src/transformers/models/hunyuan_v1_dense/modeling_hunyuan_v1_dense.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_dense%2Fmodeling_hunyuan_v1_dense.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_dense%2Fmodeling_hunyuan_v1_dense.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_dense%2Fmodeling_hunyuan_v1_dense.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -365,7 +365,7 @@ def __init__(self, config: HunYuanDenseV1Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "751eab26cccf9f5262fdaf109505a24834c98b7b",
            "filename": "src/transformers/models/hunyuan_v1_moe/modeling_hunyuan_v1_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodeling_hunyuan_v1_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodeling_hunyuan_v1_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodeling_hunyuan_v1_moe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -443,7 +443,7 @@ def __init__(self, config: HunYuanMoEV1Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a97cbcb130308751673ba42215dfeaca4ae769e8",
            "filename": "src/transformers/models/idefics/modeling_idefics.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fidefics%2Fmodeling_idefics.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fidefics%2Fmodeling_idefics.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics%2Fmodeling_idefics.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -943,7 +943,7 @@ def freeze_text_layers(self, module_exceptions=[]):\n     def freeze_vision_layers(self, module_exceptions=[]):\n         freeze_model(self.vision_model, module_exceptions=module_exceptions)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "9703a43d605c66735702668c619b18408cda8154",
            "filename": "src/transformers/models/idefics2/modeling_idefics2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -462,7 +462,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings = value\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "89bbd931fadc35845f1d15428d428c188de3c3ae",
            "filename": "src/transformers/models/idefics3/modeling_idefics3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -473,7 +473,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings = value\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     def forward(\n         self,\n         pixel_values,"
        },
        {
            "sha": "44df2898c309ea518e0b86969b309a7b164d37d7",
            "filename": "src/transformers/models/ijepa/modeling_ijepa.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -426,7 +426,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "db75024a99853236916c92f63eb17e7ea15604cc",
            "filename": "src/transformers/models/instructblip/modeling_instructblip.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Finstructblip%2Fmodeling_instructblip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Finstructblip%2Fmodeling_instructblip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finstructblip%2Fmodeling_instructblip.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -395,7 +395,7 @@ def __init__(self, config: InstructBlipVisionConfig):\n \n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,\n@@ -897,7 +897,7 @@ def get_extended_attention_mask(\n         extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n         return extended_attention_mask\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "0c5b6bc25c617a9d3bfe4e8dfa7c65e246919e92",
            "filename": "src/transformers/models/instructblipvideo/modeling_instructblipvideo.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodeling_instructblipvideo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodeling_instructblipvideo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodeling_instructblipvideo.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -362,7 +362,7 @@ def __init__(self, config: InstructBlipVideoVisionConfig):\n \n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,\n@@ -859,7 +859,7 @@ def get_extended_attention_mask(\n         extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n         return extended_attention_mask\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "df66e8b14cf161e29a1f7a1ca2e382353820646b",
            "filename": "src/transformers/models/internvl/modeling_internvl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodeling_internvl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodeling_internvl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodeling_internvl.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -380,7 +380,6 @@ def __init__(self, config: InternVLVisionConfig) -> None:\n         self.layer = nn.ModuleList([InternVLVisionLayer(config) for i in range(config.num_hidden_layers)])\n         self.gradient_checkpointing = False\n \n-    @check_model_inputs\n     def forward(\n         self,\n         hidden_states: torch.Tensor,\n@@ -443,7 +442,7 @@ def __init__(self, config: InternVLVisionConfig) -> None:\n     def get_input_embeddings(self):\n         return self.embeddings.patch_embeddings\n \n-    @can_return_tuple\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "d282de65a4b54b3544a75d5e7af737ae4efeae4e",
            "filename": "src/transformers/models/internvl/modular_internvl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodular_internvl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodular_internvl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodular_internvl.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -337,7 +337,6 @@ def __init__(self, config: InternVLVisionConfig) -> None:\n         self.layer = nn.ModuleList([InternVLVisionLayer(config) for i in range(config.num_hidden_layers)])\n         self.gradient_checkpointing = False\n \n-    @check_model_inputs\n     def forward(\n         self,\n         hidden_states: torch.Tensor,\n@@ -400,7 +399,7 @@ def __init__(self, config: InternVLVisionConfig) -> None:\n     def get_input_embeddings(self):\n         return self.embeddings.patch_embeddings\n \n-    @can_return_tuple\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "1a54c44c9554b94bf75b61a3b4ac17be1d5e7553",
            "filename": "src/transformers/models/jamba/modeling_jamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -750,7 +750,7 @@ def __init__(self, config: JambaConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "47a7362eba3c190f078c81e913d905838821078b",
            "filename": "src/transformers/models/jamba/modular_jamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodular_jamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodular_jamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodular_jamba.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -635,7 +635,7 @@ def __init__(self, config: JambaConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "306d2c19ac18292e7b95de9b44a6c3bdc909f763",
            "filename": "src/transformers/models/janus/modeling_janus.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -561,7 +561,7 @@ def __init__(self, config: JanusVisionConfig):\n \n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "935480f5097982d79e6ff7cedda7fedd71ff9154",
            "filename": "src/transformers/models/jetmoe/modeling_jetmoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -585,7 +585,7 @@ def __init__(self, config: JetMoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "be91abf73f1edf266ce5f5cfa26d18dafd55e529",
            "filename": "src/transformers/models/jetmoe/modular_jetmoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodular_jetmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodular_jetmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodular_jetmoe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -460,7 +460,7 @@ def __init__(self, config: JetMoeConfig):\n         self._attn_implementation = config._attn_implementation\n         self.norm = JetMoeRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "0674cd18319aa9ea5523617a11cfba212de13fe6",
            "filename": "src/transformers/models/lfm2/modeling_lfm2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Flfm2%2Fmodeling_lfm2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Flfm2%2Fmodeling_lfm2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flfm2%2Fmodeling_lfm2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -609,7 +609,7 @@ def __init__(self, config: Lfm2Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "8f4bd09d2229b88d5d6395e695ccfe4687e921c3",
            "filename": "src/transformers/models/llama/modeling_llama.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fllama%2Fmodeling_llama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fllama%2Fmodeling_llama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllama%2Fmodeling_llama.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -348,7 +348,7 @@ def __init__(self, config: LlamaConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a974ed81ba2fbf4c9ef934c6b1fbf4ab54bcc4d4",
            "filename": "src/transformers/models/llama4/modeling_llama4.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -491,7 +491,7 @@ def __init__(self, config: Llama4TextConfig):\n         self.post_init()\n \n     @can_return_tuple\n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "de69a7320016ff738a4e67bb4a212e8eb3873118",
            "filename": "src/transformers/models/longcat_flash/modeling_longcat_flash.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Flongcat_flash%2Fmodeling_longcat_flash.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Flongcat_flash%2Fmodeling_longcat_flash.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flongcat_flash%2Fmodeling_longcat_flash.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -537,7 +537,7 @@ def __init__(self, config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "bdfa7661349a7c983abfdec2805c8a3dba509bcb",
            "filename": "src/transformers/models/metaclip_2/modeling_metaclip_2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmetaclip_2%2Fmodeling_metaclip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmetaclip_2%2Fmodeling_metaclip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmetaclip_2%2Fmodeling_metaclip_2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -480,7 +480,7 @@ def __init__(self, config: MetaClip2TextConfig):\n         # For `pooled_output` computation\n         self.eos_token_id = config.eos_token_id\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "cd42344bd4063163bd7662d0d3345d65c828dd22",
            "filename": "src/transformers/models/metaclip_2/modular_metaclip_2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmetaclip_2%2Fmodular_metaclip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmetaclip_2%2Fmodular_metaclip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmetaclip_2%2Fmodular_metaclip_2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -287,7 +287,7 @@ def _init_weights(self, module):\n \n \n class MetaClip2TextTransformer(CLIPTextTransformer):\n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "3580142b8c38a45cbf67d45baa2dbbc9bb5dfcf8",
            "filename": "src/transformers/models/minimax/modeling_minimax.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodeling_minimax.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodeling_minimax.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodeling_minimax.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -608,7 +608,7 @@ def __init__(self, config: MiniMaxConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "6eb3d5f11bbef87dd9c82d1192163e09df25a16c",
            "filename": "src/transformers/models/minimax/modular_minimax.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodular_minimax.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodular_minimax.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodular_minimax.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -447,7 +447,7 @@ class MiniMaxPreTrainedModel(MixtralPreTrainedModel):\n \n \n class MiniMaxModel(MixtralModel):\n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "33eb554d6ba0f3760e5aabd5a8163ad594d92407",
            "filename": "src/transformers/models/ministral/modeling_ministral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fministral%2Fmodeling_ministral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fministral%2Fmodeling_ministral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fministral%2Fmodeling_ministral.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -325,7 +325,7 @@ def __init__(self, config: MinistralConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "13130dae29b22c3e967c8d7bb71c0e1cfad41ac0",
            "filename": "src/transformers/models/ministral/modular_ministral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fministral%2Fmodular_ministral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fministral%2Fmodular_ministral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fministral%2Fmodular_ministral.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -198,7 +198,7 @@ def __init__(self, config: MinistralConfig):\n         super().__init__(config)\n         del self.has_sliding_layers\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "00f039a73cd812f1ed1fa7992684c37d62f4d9c0",
            "filename": "src/transformers/models/mistral/modeling_mistral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodeling_mistral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodeling_mistral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodeling_mistral.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -321,7 +321,7 @@ def __init__(self, config: MistralConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "c88cd612589100baffd7a59242c2b681148e898c",
            "filename": "src/transformers/models/mistral/modular_mistral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodular_mistral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodular_mistral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodular_mistral.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -112,7 +112,7 @@ class MistralPreTrainedModel(LlamaPreTrainedModel):\n \n \n class MistralModel(LlamaModel):\n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "30441cc8d69fb1dd70677796ca0460cd145152ff",
            "filename": "src/transformers/models/mixtral/modeling_mixtral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -402,7 +402,7 @@ def __init__(self, config: MixtralConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "6c601ff6a20ef868cd614e202167d7f84266c276",
            "filename": "src/transformers/models/mllama/modeling_mllama.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -993,7 +993,7 @@ def apply_class_embedding(self, hidden_state: torch.Tensor) -> torch.Tensor:\n         hidden_state = torch.cat([class_embedding, hidden_state], dim=1)\n         return hidden_state\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self, pixel_values: torch.Tensor, aspect_ratio_ids: torch.Tensor, aspect_ratio_mask: torch.Tensor, **kwargs\n@@ -1161,7 +1161,7 @@ def __init__(self, config: MllamaTextConfig):\n         self.gradient_checkpointing = False\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @can_return_tuple\n     @auto_docstring\n     def forward(\n@@ -1429,7 +1429,7 @@ def set_decoder(self, decoder):\n     def get_decoder(self):\n         return self.language_model\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @can_return_tuple\n     @auto_docstring\n     def forward("
        },
        {
            "sha": "facd6b738cb565df92c3526e10a635b65d1bd9dd",
            "filename": "src/transformers/models/mobilebert/modeling_mobilebert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmobilebert%2Fmodeling_mobilebert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmobilebert%2Fmodeling_mobilebert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilebert%2Fmodeling_mobilebert.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -650,7 +650,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "f576153471ad1b3b23a0fdb4f26d2763a4863b99",
            "filename": "src/transformers/models/modernbert_decoder/modeling_modernbert_decoder.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodeling_modernbert_decoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodeling_modernbert_decoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodeling_modernbert_decoder.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -430,7 +430,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.tok_embeddings = value\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "c44b1f7cfe1d5db812ef4d2ba1d41947a4f4b79a",
            "filename": "src/transformers/models/modernbert_decoder/modular_modernbert_decoder.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodular_modernbert_decoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodular_modernbert_decoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodular_modernbert_decoder.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -501,7 +501,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.tok_embeddings = value\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "ed0f879aa102f59d5541afe01c897cb6ed8b2de1",
            "filename": "src/transformers/models/moonshine/modeling_moonshine.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodeling_moonshine.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodeling_moonshine.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodeling_moonshine.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -520,7 +520,7 @@ def get_input_embeddings(self) -> nn.Module:\n     def set_input_embeddings(self, value: nn.Module):\n         self.conv1 = value\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_values: torch.FloatTensor,\n@@ -605,7 +605,7 @@ def __init__(self, config: MoonshineConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "cadc770dea83a9d8912caa4024e7fcc1de756def",
            "filename": "src/transformers/models/moonshine/modular_moonshine.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodular_moonshine.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodular_moonshine.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodular_moonshine.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -552,7 +552,7 @@ def get_input_embeddings(self) -> nn.Module:\n     def set_input_embeddings(self, value: nn.Module):\n         self.conv1 = value\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_values: torch.FloatTensor,\n@@ -627,7 +627,7 @@ def __init__(self, config: MoonshineConfig):\n             [MoonshineDecoderLayer(config, idx) for idx in range(config.decoder_num_hidden_layers)]\n         )\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "29c417240d2c913a69a8ee93fe4c42e99ba4c64b",
            "filename": "src/transformers/models/nllb_moe/modeling_nllb_moe.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fmodeling_nllb_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fmodeling_nllb_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fmodeling_nllb_moe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -726,7 +726,7 @@ def __init__(self, config: NllbMoeConfig, embed_tokens: Optional[nn.Embedding] =\n         self.gradient_checkpointing = False\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,\n@@ -833,7 +833,7 @@ def __init__(self, config: NllbMoeConfig, embed_tokens: Optional[nn.Embedding] =\n         self.post_init()\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.Tensor] = None,"
        },
        {
            "sha": "f94b25f12f55c3a75457821b61fbe03da5b84ada",
            "filename": "src/transformers/models/olmo/modeling_olmo.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Folmo%2Fmodeling_olmo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Folmo%2Fmodeling_olmo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmo%2Fmodeling_olmo.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -325,7 +325,7 @@ def __init__(self, config: OlmoConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "b8ba03f17b5bb7e167f94cf9cb41d886938f0e2d",
            "filename": "src/transformers/models/olmo2/modeling_olmo2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Folmo2%2Fmodeling_olmo2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Folmo2%2Fmodeling_olmo2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmo2%2Fmodeling_olmo2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -330,7 +330,7 @@ def __init__(self, config: Olmo2Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "ca4ba1bfc789dcc37cd725ec27d4744375d2f356",
            "filename": "src/transformers/models/olmo3/modeling_olmo3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Folmo3%2Fmodeling_olmo3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Folmo3%2Fmodeling_olmo3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmo3%2Fmodeling_olmo3.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -358,7 +358,7 @@ def __init__(self, config: Olmo3Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "4c61f0c542b50764f753fa9715ab67dd686c097d",
            "filename": "src/transformers/models/olmoe/modeling_olmoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -409,7 +409,7 @@ def __init__(self, config: OlmoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "9ee029de30f257d86a747902b01878171f6440ed",
            "filename": "src/transformers/models/parakeet/modeling_parakeet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodeling_parakeet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodeling_parakeet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodeling_parakeet.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -507,7 +507,7 @@ def __init__(self, config: ParakeetEncoderConfig):\n         self.post_init()\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     @can_return_tuple\n     def forward(\n         self,"
        },
        {
            "sha": "dc9c10c5dfb12d81df67621acdf54d413390484f",
            "filename": "src/transformers/models/parakeet/modular_parakeet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodular_parakeet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodular_parakeet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodular_parakeet.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -391,7 +391,7 @@ def __init__(self, config: ParakeetEncoderConfig):\n         self.post_init()\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     @can_return_tuple\n     def forward(\n         self,"
        },
        {
            "sha": "e98939206b854dc6ea5975fadc98750b5985779c",
            "filename": "src/transformers/models/phi/modeling_phi.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fphi%2Fmodeling_phi.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fphi%2Fmodeling_phi.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi%2Fmodeling_phi.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -330,7 +330,7 @@ def __init__(self, config: PhiConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "cf803b3e2130005ef24fd2b0d87be6d60a4bf71e",
            "filename": "src/transformers/models/phi3/modeling_phi3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodeling_phi3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodeling_phi3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodeling_phi3.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -353,7 +353,7 @@ def __init__(self, config: Phi3Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "d07200fc01f19abb0302f7d1aa907dba5d50af7e",
            "filename": "src/transformers/models/phi4_multimodal/modeling_phi4_multimodal.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodeling_phi4_multimodal.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodeling_phi4_multimodal.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodeling_phi4_multimodal.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -488,7 +488,7 @@ def __init__(self, config: Phi4MultimodalVisionConfig):\n     def get_input_embeddings(self) -> nn.Module:\n         return self.embeddings.patch_embedding\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     def forward(\n         self,\n         pixel_values,\n@@ -1562,7 +1562,7 @@ def __init__(self, config: Phi4MultimodalConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "486d701a43114977aa00a4fbcbf810aa9eef1f81",
            "filename": "src/transformers/models/phi4_multimodal/modular_phi4_multimodal.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodular_phi4_multimodal.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodular_phi4_multimodal.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodular_phi4_multimodal.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -672,7 +672,7 @@ def __init__(self, config: Phi4MultimodalVisionConfig):\n     def get_input_embeddings(self) -> nn.Module:\n         return self.embeddings.patch_embedding\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     def forward(\n         self,\n         pixel_values,\n@@ -1472,7 +1472,7 @@ def __init__(self, config: Phi4MultimodalConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "c007d80c1d58ac083a55504ce0f15a903b744141",
            "filename": "src/transformers/models/phimoe/modeling_phimoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fphimoe%2Fmodeling_phimoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fphimoe%2Fmodeling_phimoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphimoe%2Fmodeling_phimoe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -623,7 +623,7 @@ def __init__(self, config: PhimoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "262e03cb1568dad0c9b2d027fa8ebdc36301b88b",
            "filename": "src/transformers/models/qwen2/modeling_qwen2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodeling_qwen2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodeling_qwen2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodeling_qwen2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -325,7 +325,7 @@ def __init__(self, config: Qwen2Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "2a5ede71b704894c8044e334bfafde359c07d84f",
            "filename": "src/transformers/models/qwen2/modular_qwen2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodular_qwen2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodular_qwen2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodular_qwen2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -143,7 +143,7 @@ def __init__(self, config: Qwen2Config):\n         super().__init__(config)\n         self.has_sliding_layers = \"sliding_attention\" in self.config.layer_types\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a3a1637a7c683cfd241ac35a849b2ae335ba5c21",
            "filename": "src/transformers/models/qwen2_moe/modeling_qwen2_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -416,7 +416,7 @@ def __init__(self, config: Qwen2MoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "c402ac0f92a8c8222ff3e309f674d10da10c48b2",
            "filename": "src/transformers/models/qwen2_moe/modular_qwen2_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodular_qwen2_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodular_qwen2_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodular_qwen2_moe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -158,7 +158,7 @@ def __init__(self, config: Qwen2MoeConfig):\n         self.norm = Qwen2MoeRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n         self.rotary_emb = Qwen2MoeRotaryEmbedding(config=config)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "45e878e60428c53ad5d36bc223a7276701e31bc1",
            "filename": "src/transformers/models/qwen3/modeling_qwen3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3%2Fmodeling_qwen3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3%2Fmodeling_qwen3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3%2Fmodeling_qwen3.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -351,7 +351,7 @@ def __init__(self, config: Qwen3Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "f44150ff6cf1fd3fdacf7e1b3392a511edfc4413",
            "filename": "src/transformers/models/qwen3_moe/modeling_qwen3_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_moe%2Fmodeling_qwen3_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_moe%2Fmodeling_qwen3_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_moe%2Fmodeling_qwen3_moe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -412,7 +412,7 @@ def __init__(self, config: Qwen3MoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "0decff0d61ab1835b82b9fcef103fc5b93428073",
            "filename": "src/transformers/models/qwen3_next/modeling_qwen3_next.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodeling_qwen3_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodeling_qwen3_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodeling_qwen3_next.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -970,7 +970,7 @@ def __init__(self, config: Qwen3NextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "6411c4ffacb0ab60d3968709eb526b800281ed9a",
            "filename": "src/transformers/models/qwen3_next/modular_qwen3_next.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodular_qwen3_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodular_qwen3_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodular_qwen3_next.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -727,7 +727,7 @@ def __init__(self, config: Qwen3NextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "796065d9756152263196e0bd8eaea3b987ad214b",
            "filename": "src/transformers/models/qwen3_omni_moe/modeling_qwen3_omni_moe.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -1598,7 +1598,7 @@ def __init__(self, config: Qwen3OmniMoeTextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,\n@@ -2450,7 +2450,7 @@ def __init__(self, config: Qwen3OmniMoeTalkerCodePredictorConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,\n@@ -2794,7 +2794,7 @@ def __init__(self, config: Qwen3OmniMoeTalkerTextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,\n@@ -3483,7 +3483,7 @@ def __init__(self, config: Qwen3OmniMoeCode2WavConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "504cbb2f368984875ee37a755cce70fc35357343",
            "filename": "src/transformers/models/qwen3_omni_moe/modular_qwen3_omni_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodular_qwen3_omni_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodular_qwen3_omni_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodular_qwen3_omni_moe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -1518,7 +1518,7 @@ def __init__(self, config: Qwen3OmniMoeTalkerCodePredictorConfig):\n     def get_input_embeddings(self):\n         return self.codec_embedding\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "6fa91b03cea8c6f9be720177baadb95483d6f65c",
            "filename": "src/transformers/models/qwen3_vl/modeling_qwen3_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodeling_qwen3_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodeling_qwen3_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodeling_qwen3_vl.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -779,7 +779,7 @@ def __init__(self, config: Qwen3VLTextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,\n@@ -1104,7 +1104,7 @@ def get_placeholder_mask(\n         return special_image_mask, special_video_mask\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,\n@@ -1311,7 +1311,7 @@ def language_model(self):\n     def visual(self):\n         return self.model.visual\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,"
        },
        {
            "sha": "d5314936fe257acfe32cd862f5275dc709da0780",
            "filename": "src/transformers/models/qwen3_vl/modular_qwen3_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodular_qwen3_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodular_qwen3_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodular_qwen3_vl.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -749,7 +749,7 @@ def _deepstack_process(\n         hidden_states[visual_pos_masks, :] = local_this\n         return hidden_states\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,\n@@ -1006,7 +1006,7 @@ def get_video_features(\n         return self.get_image_features(pixel_values_videos, video_grid_thw)\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,\n@@ -1149,7 +1149,7 @@ class Qwen3VLForConditionalGeneration(Qwen2_5_VLForConditionalGeneration):\n     config: Qwen3VLConfig\n     _checkpoint_conversion_mapping = {}\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,"
        },
        {
            "sha": "3cd95aed00fddcfcb7f3b39fa5edb0ca8f8d44cb",
            "filename": "src/transformers/models/qwen3_vl_moe/modeling_qwen3_vl_moe.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodeling_qwen3_vl_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodeling_qwen3_vl_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodeling_qwen3_vl_moe.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -860,7 +860,7 @@ def __init__(self, config: Qwen3VLMoeTextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,\n@@ -1239,7 +1239,7 @@ def get_placeholder_mask(\n         return special_image_mask, special_video_mask\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,\n@@ -1499,7 +1499,7 @@ def language_model(self):\n     def visual(self):\n         return self.model.visual\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,"
        },
        {
            "sha": "178369fa01b2eada5ec8383766ba496fe59f1520",
            "filename": "src/transformers/models/roberta/modeling_roberta.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Froberta%2Fmodeling_roberta.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Froberta%2Fmodeling_roberta.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froberta%2Fmodeling_roberta.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -689,7 +689,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "2988afb83f7bb1b97fe06ce34b6fe984f83e711c",
            "filename": "src/transformers/models/roberta_prelayernorm/modeling_roberta_prelayernorm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fmodeling_roberta_prelayernorm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fmodeling_roberta_prelayernorm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fmodeling_roberta_prelayernorm.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -701,7 +701,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a5c043cf6a5925f1be0855fec767f719c68a95c0",
            "filename": "src/transformers/models/roc_bert/modeling_roc_bert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Froc_bert%2Fmodeling_roc_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Froc_bert%2Fmodeling_roc_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froc_bert%2Fmodeling_roc_bert.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -780,7 +780,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "034f7485f426c5ea7ab344af885f8954f1b8c408",
            "filename": "src/transformers/models/sam/modeling_sam.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -1059,7 +1059,7 @@ def __init__(self, config: SamVisionConfig):\n     def get_input_embeddings(self):\n         return self.patch_embed\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     def forward(\n         self, pixel_values: Optional[torch.FloatTensor] = None, **kwargs: Unpack[TransformersKwargs]\n     ) -> SamVisionEncoderOutput:\n@@ -1197,7 +1197,7 @@ def get_prompt_embeddings(\n         )\n         return prompt_output\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a1f5489fed0fd88264789ff4293a36f30074a422",
            "filename": "src/transformers/models/sam2/modeling_sam2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodeling_sam2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodeling_sam2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodeling_sam2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -618,7 +618,7 @@ def _get_pos_embed(self, hw: tuple[int, int]) -> torch.Tensor:\n         pos_embed = pos_embed.permute(0, 2, 3, 1)\n         return pos_embed\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         pixel_values: Optional[torch.FloatTensor] = None,\n@@ -670,7 +670,7 @@ def __init__(self, config: Sam2VisionConfig):\n     def get_input_embeddings(self):\n         return self.backbone.get_input_embeddings()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         pixel_values: Optional[torch.FloatTensor] = None,\n@@ -1387,7 +1387,7 @@ def get_prompt_embeddings(\n         )\n         return prompt_output\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "e6058db272fee2618bd4207e9749a818a721741f",
            "filename": "src/transformers/models/sam2/modular_sam2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -739,7 +739,7 @@ def _get_pos_embed(self, hw: tuple[int, int]) -> torch.Tensor:\n         pos_embed = pos_embed.permute(0, 2, 3, 1)\n         return pos_embed\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         pixel_values: Optional[torch.FloatTensor] = None,\n@@ -791,7 +791,7 @@ def __init__(self, config: Sam2VisionConfig):\n     def get_input_embeddings(self):\n         return self.backbone.get_input_embeddings()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         pixel_values: Optional[torch.FloatTensor] = None,\n@@ -1293,7 +1293,7 @@ def get_image_features(\n \n         return feature_maps, feature_maps_position_embeddings, vision_outputs.hidden_states, vision_outputs.attentions\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "5cc322184faa0088b8c8dda42b5a90f93c8ff533",
            "filename": "src/transformers/models/sam_hq/modeling_sam_hq.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodeling_sam_hq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodeling_sam_hq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodeling_sam_hq.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -532,7 +532,7 @@ def __init__(self, config: SamHQVisionConfig):\n     def get_input_embeddings(self):\n         return self.patch_embed\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     def forward(\n         self, pixel_values: Optional[torch.FloatTensor] = None, **kwargs: Unpack[TransformersKwargs]\n     ) -> Union[tuple, SamHQVisionEncoderOutput]:\n@@ -1320,7 +1320,7 @@ def get_prompt_embeddings(\n         )\n         return prompt_output\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "b3c5da57413c17d3d7ae91e4ec0740826b0a721c",
            "filename": "src/transformers/models/sam_hq/modular_sam_hq.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodular_sam_hq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodular_sam_hq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodular_sam_hq.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -195,7 +195,7 @@ class SamHQVisionEncoder(SamVisionEncoder, SamHQPreTrainedModel):\n         \"attentions\": SamHQVisionAttention,\n     }\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     def forward(\n         self, pixel_values: Optional[torch.FloatTensor] = None, **kwargs: Unpack[TransformersKwargs]\n     ) -> Union[tuple, SamHQVisionEncoderOutput]:"
        },
        {
            "sha": "7d5633b37c0934e40d034ebdcd79471ce49b3486",
            "filename": "src/transformers/models/seed_oss/modeling_seed_oss.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fseed_oss%2Fmodeling_seed_oss.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fseed_oss%2Fmodeling_seed_oss.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fseed_oss%2Fmodeling_seed_oss.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -349,7 +349,7 @@ def __init__(self, config: SeedOssConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "072ec9721f041ef05d06e8ac5c5ba037c86f1248",
            "filename": "src/transformers/models/siglip/modeling_siglip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsiglip%2Fmodeling_siglip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsiglip%2Fmodeling_siglip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsiglip%2Fmodeling_siglip.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -641,7 +641,7 @@ def get_input_embeddings(self) -> nn.Module:\n     def set_input_embeddings(self, value):\n         self.text_model.embeddings.token_embedding = value\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,\n@@ -688,7 +688,6 @@ def __init__(self, config: SiglipVisionConfig):\n         if self.use_head:\n             self.head = SiglipMultiheadAttentionPoolingHead(config)\n \n-    @can_return_tuple\n     @auto_docstring\n     def forward(\n         self,\n@@ -758,7 +757,7 @@ def __init__(self, config: SiglipVisionConfig):\n     def get_input_embeddings(self) -> nn.Module:\n         return self.vision_model.embeddings.patch_embedding\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,\n@@ -1024,7 +1023,7 @@ def __init__(self, config: SiglipConfig) -> None:\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "4fbaf32dff901861d944419039db0f3566dfa65a",
            "filename": "src/transformers/models/siglip2/modeling_siglip2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsiglip2%2Fmodeling_siglip2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsiglip2%2Fmodeling_siglip2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsiglip2%2Fmodeling_siglip2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -395,7 +395,6 @@ def __init__(self, config: Siglip2VisionConfig):\n         if self.use_head:\n             self.head = Siglip2MultiheadAttentionPoolingHead(config)\n \n-    @can_return_tuple\n     @auto_docstring\n     def forward(\n         self,\n@@ -722,7 +721,7 @@ def get_input_embeddings(self) -> nn.Module:\n     def set_input_embeddings(self, value):\n         self.text_model.embeddings.token_embedding = value\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,\n@@ -807,7 +806,7 @@ def __init__(self, config: Siglip2VisionConfig):\n     def get_input_embeddings(self) -> nn.Module:\n         return self.vision_model.embeddings.patch_embedding\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,\n@@ -1103,7 +1102,7 @@ def __init__(self, config: Siglip2Config) -> None:\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "c3db5f1f708dfc6b97aa994f49c8cb656c9e9207",
            "filename": "src/transformers/models/smollm3/modeling_smollm3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsmollm3%2Fmodeling_smollm3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsmollm3%2Fmodeling_smollm3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsmollm3%2Fmodeling_smollm3.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -355,7 +355,7 @@ def __init__(self, config: SmolLM3Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "5ff2b041dd2decf4fbe45aa5da489e85fe2e61b6",
            "filename": "src/transformers/models/smolvlm/modeling_smolvlm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fmodeling_smolvlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fmodeling_smolvlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fmodeling_smolvlm.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -363,7 +363,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings = value\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     def forward(\n         self,\n         pixel_values,"
        },
        {
            "sha": "bc2ed2a9e5d0f9a9596c9f11a74ea197f39fee71",
            "filename": "src/transformers/models/starcoder2/modeling_starcoder2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodeling_starcoder2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodeling_starcoder2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodeling_starcoder2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -325,7 +325,7 @@ def __init__(self, config: Starcoder2Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "df505bd4a13345ac31cbe3eea3cc4bc88fdc5199",
            "filename": "src/transformers/models/starcoder2/modular_starcoder2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodular_starcoder2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodular_starcoder2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodular_starcoder2.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -150,7 +150,7 @@ def __init__(self, config: Starcoder2Config):\n         self.norm = nn.LayerNorm(config.hidden_size, eps=config.norm_epsilon)\n         self.embedding_dropout = config.embedding_dropout\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "d13a95d2f4be69d289960f8000d25f665880c020",
            "filename": "src/transformers/models/switch_transformers/modeling_switch_transformers.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fswitch_transformers%2Fmodeling_switch_transformers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fswitch_transformers%2Fmodeling_switch_transformers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fswitch_transformers%2Fmodeling_switch_transformers.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -716,7 +716,7 @@ def __init__(self, config, embed_tokens=None):\n \n         self.gradient_checkpointing = False\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids=None,\n@@ -1299,7 +1299,7 @@ def get_encoder(self):\n         return self.encoder\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "1aaa0999e4672523c58e4b12e2c017864ad7e5b7",
            "filename": "src/transformers/models/switch_transformers/modular_switch_transformers.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fswitch_transformers%2Fmodular_switch_transformers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fswitch_transformers%2Fmodular_switch_transformers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fswitch_transformers%2Fmodular_switch_transformers.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -445,7 +445,7 @@ def __init__(self, config, embed_tokens=None):\n \n         self.gradient_checkpointing = False\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids=None,\n@@ -963,7 +963,7 @@ def get_encoder(self):\n         return self.encoder\n \n     @auto_docstring\n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "fdcb8ddb6f8de41ec5d7f3a191250ee3e9c7c078",
            "filename": "src/transformers/models/t5gemma/modeling_t5gemma.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodeling_t5gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodeling_t5gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodeling_t5gemma.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -636,7 +636,7 @@ def __init__(self, config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,\n@@ -720,7 +720,7 @@ def __init__(self, config):\n \n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "1b8988bd5f63a3f156abbe25f1d48d40bd8d914e",
            "filename": "src/transformers/models/t5gemma/modular_t5gemma.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodular_t5gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodular_t5gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodular_t5gemma.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -700,7 +700,7 @@ def __init__(self, config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,\n@@ -784,7 +784,7 @@ def __init__(self, config):\n \n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "9b28ded3d729c51c19e163ecf0434399418e112c",
            "filename": "src/transformers/models/vaultgemma/modeling_vaultgemma.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvaultgemma%2Fmodeling_vaultgemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvaultgemma%2Fmodeling_vaultgemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvaultgemma%2Fmodeling_vaultgemma.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -368,7 +368,7 @@ def __init__(self, config: VaultGemmaConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "497e4f47b9e17fc5889bf646a6724ef3e632047d",
            "filename": "src/transformers/models/videomae/modeling_videomae.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvideomae%2Fmodeling_videomae.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvideomae%2Fmodeling_videomae.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvideomae%2Fmodeling_videomae.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -450,7 +450,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "0aad13ca896ab905219e070fef0f506f943ab3bc",
            "filename": "src/transformers/models/vit/modeling_vit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvit%2Fmodeling_vit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvit%2Fmodeling_vit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvit%2Fmodeling_vit.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -445,7 +445,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "98e1579a1ca13ed54786f009a97b735d00634ef8",
            "filename": "src/transformers/models/vit_mae/modeling_vit_mae.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvit_mae%2Fmodeling_vit_mae.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvit_mae%2Fmodeling_vit_mae.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvit_mae%2Fmodeling_vit_mae.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -590,7 +590,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "c7a409578a1a7918fe3327b96755ec5951db4d8c",
            "filename": "src/transformers/models/vit_msn/modeling_vit_msn.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvit_msn%2Fmodeling_vit_msn.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvit_msn%2Fmodeling_vit_msn.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvit_msn%2Fmodeling_vit_msn.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -434,7 +434,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "cf786a7263a5dc29d5bcb06ecb2f8e638bcf0fe3",
            "filename": "src/transformers/models/vitpose_backbone/modeling_vitpose_backbone.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvitpose_backbone%2Fmodeling_vitpose_backbone.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvitpose_backbone%2Fmodeling_vitpose_backbone.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvitpose_backbone%2Fmodeling_vitpose_backbone.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -415,7 +415,7 @@ def __init__(self, config: VitPoseBackboneConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "75d58393324aff2afb92a37f0942e9d9002abaa8",
            "filename": "src/transformers/models/vivit/modeling_vivit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvivit%2Fmodeling_vivit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvivit%2Fmodeling_vivit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvivit%2Fmodeling_vivit.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -445,7 +445,7 @@ def _prune_heads(self, heads_to_prune):\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "ce790148d826c560b209eced4a48ccb0036e4486",
            "filename": "src/transformers/models/voxtral/modeling_voxtral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodeling_voxtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodeling_voxtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodeling_voxtral.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -311,7 +311,7 @@ def get_input_embeddings(self) -> nn.Module:\n     def set_input_embeddings(self, value: nn.Module):\n         self.conv1 = value\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_features,"
        },
        {
            "sha": "adec806f8e90ff5a34d44b3234a84114dc69bd48",
            "filename": "src/transformers/models/voxtral/modular_voxtral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodular_voxtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodular_voxtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodular_voxtral.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -65,7 +65,7 @@ class VoxtralEncoder(Qwen2AudioEncoder):\n         \"hidden_states\": VoxtralEncoderLayer,\n     }\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     def forward(\n         self,\n         input_features,"
        },
        {
            "sha": "c45ec4119f88debae1e5b56f8cec06f40e11d370",
            "filename": "src/transformers/models/xlm_roberta/modeling_xlm_roberta.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fxlm_roberta%2Fmodeling_xlm_roberta.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fxlm_roberta%2Fmodeling_xlm_roberta.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fxlm_roberta%2Fmodeling_xlm_roberta.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -708,7 +708,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "2b53bbd8e6eb3fa9b36ab6a0e00eece23e70ba48",
            "filename": "src/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fxlm_roberta_xl%2Fmodeling_xlm_roberta_xl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fxlm_roberta_xl%2Fmodeling_xlm_roberta_xl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fxlm_roberta_xl%2Fmodeling_xlm_roberta_xl.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -696,7 +696,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "b08de5c354c95157c948b8d14fcd824992a69760",
            "filename": "src/transformers/models/xmod/modeling_xmod.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fxmod%2Fmodeling_xmod.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fxmod%2Fmodeling_xmod.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fxmod%2Fmodeling_xmod.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -803,7 +803,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs()\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "1a06517f76e18068f27623bc79a0566b7ba42c3d",
            "filename": "src/transformers/models/yolos/modeling_yolos.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fyolos%2Fmodeling_yolos.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Fmodels%2Fyolos%2Fmodeling_yolos.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fyolos%2Fmodeling_yolos.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -509,7 +509,7 @@ def _prune_heads(self, heads_to_prune: dict[int, list[int]]) -> None:\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs\n+    @check_model_inputs(tie_last_hidden_states=False)\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "ae4f8972b2cd671bddd2146c378ddeea3e3a2ac9",
            "filename": "src/transformers/utils/generic.py",
            "status": "modified",
            "additions": 158,
            "deletions": 146,
            "changes": 304,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Futils%2Fgeneric.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/src%2Ftransformers%2Futils%2Fgeneric.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fgeneric.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -781,166 +781,178 @@ class OutputRecorder:\n     class_name: Optional[str] = None\n \n \n-def check_model_inputs(func):\n+def check_model_inputs(tie_last_hidden_states=True):\n     \"\"\"\n     Decorator to intercept specific layer outputs without using hooks.\n     Compatible with torch.compile (Dynamo tracing).\n-    \"\"\"\n \n-    @wraps(func)\n-    def wrapper(self, *args, **kwargs):\n-        use_cache = (\n-            kwargs[\"use_cache\"] if kwargs.get(\"use_cache\") is not None else getattr(self.config, \"use_cache\", None)\n-        )\n-        if use_cache is not None:\n-            if getattr(self, \"gradient_checkpointing\", False) and self.training and use_cache:\n-                logger.warning_once(\n-                    \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\"\n-                )\n-                use_cache = False\n-\n-            kwargs[\"use_cache\"] = use_cache\n-\n-        return_dict = kwargs.pop(\"return_dict\", None)\n-        if return_dict is None:\n-            return_dict = getattr(self.config, \"return_dict\", True)\n-\n-        all_args = kwargs.copy()\n-        if \"kwargs\" in all_args:\n-            for k, v in all_args[\"kwargs\"].items():\n-                all_args[k] = v\n+    Args:\n+        tie_last_hidden_states (`bool`, *optional*, defaults to `True`):\n+            Whether to overwrite `out.hidden_states[-1]` with the `out.last_hidden_state`.\n+            This is true for all language models and should be toggled off only if\n+            `out.hidden_states[-1]` has to be the hidden state before last layer norm, which\n+            is needed for some vision models (e.g. CLIP, SigLIP)\n+    \"\"\"\n \n-        capture_flags = _CAN_RECORD_REGISTRY.get(str(self.__class__), {})  # there is a weak ref for executorch\n-        recordable_keys = {\n-            f\"output_{k}\": all_args.get(\n-                f\"output_{k}\",\n-                getattr(\n-                    self.config,\n-                    f\"output_{k}\",\n-                    all_args.get(\"output_attentions\", getattr(self.config, \"output_attentions\", False)),\n-                ),\n+    def wrapped_fn(func):\n+        @wraps(func)\n+        def wrapper(self, *args, **kwargs):\n+            use_cache = (\n+                kwargs[\"use_cache\"] if kwargs.get(\"use_cache\") is not None else getattr(self.config, \"use_cache\", None)\n             )\n-            for k in capture_flags\n-        }\n-\n-        # We let cross attentions to be saved separately because some models add `cross-attn` layer\n-        # when certain conditions are met. Let's output cross attention if attentions are requested (for BC)\n-        if \"output_attentions\" in recordable_keys:\n-            recordable_keys[\"output_cross_attentions\"] = recordable_keys[\"output_attentions\"]\n-\n-        collected_outputs = defaultdict(tuple)\n-        monkey_patched_layers = []\n-\n-        # Check attention implementation is properly set for capturing attention outputs\n-        if recordable_keys.get(\"output_attentions\", False):\n-            supported_attn = [\"eager\", \"eager_paged\", \"flex_attention\"]\n-            config_attn = getattr(self.config, \"_attn_implementation\", None)\n-            sub_configs = [getattr(self.config, key, None) for key in self.config.sub_configs]\n-            sub_configs_attn = [\n-                getattr(config, \"_attn_implementation\", None) for config in sub_configs if config is not None\n-            ]\n-            if config_attn not in supported_attn or any(attn not in supported_attn for attn in sub_configs_attn):\n-                warnings.warn(\n-                    f\"`output_attentions=True` is not supported with `attn_implementation` other than {supported_attn}. \"\n-                    \"Please use `model.set_attn_implementation('eager')` to enable capturing attention outputs.\",\n-                    UserWarning,\n+            if use_cache is not None:\n+                if getattr(self, \"gradient_checkpointing\", False) and self.training and use_cache:\n+                    logger.warning_once(\n+                        \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\"\n+                    )\n+                    use_cache = False\n+\n+                kwargs[\"use_cache\"] = use_cache\n+\n+            return_dict = kwargs.pop(\"return_dict\", None)\n+            if return_dict is None:\n+                return_dict = getattr(self.config, \"return_dict\", True)\n+\n+            all_args = kwargs.copy()\n+            if \"kwargs\" in all_args:\n+                for k, v in all_args[\"kwargs\"].items():\n+                    all_args[k] = v\n+\n+            capture_flags = _CAN_RECORD_REGISTRY.get(str(self.__class__), {})  # there is a weak ref for executorch\n+            recordable_keys = {\n+                f\"output_{k}\": all_args.get(\n+                    f\"output_{k}\",\n+                    getattr(\n+                        self.config,\n+                        f\"output_{k}\",\n+                        all_args.get(\"output_attentions\", getattr(self.config, \"output_attentions\", False)),\n+                    ),\n                 )\n-\n-        def make_capture_wrapper(module, orig_forward, key, index):\n-            @wraps(orig_forward)\n-            def wrapped_forward(*args, **kwargs):\n-                if key == \"hidden_states\" and len(collected_outputs[key]) == 0:\n-                    collected_outputs[key] += (args[0],)\n-                if kwargs.get(\"debug_io\", False):\n-                    with model_addition_debugger_context(\n-                        module, kwargs.get(\"debug_io_dir\", \"~/model_debug\"), kwargs.get(\"prune_layers\")\n-                    ):\n-                        output = orig_forward(*args, **kwargs)\n-                else:\n-                    output = orig_forward(*args, **kwargs)\n-                if not isinstance(output, tuple):\n-                    collected_outputs[key] += (output,)\n-                elif output[index] is not None:\n-                    if key not in collected_outputs:\n-                        collected_outputs[key] = (output[index],)\n+                for k in capture_flags\n+            }\n+\n+            # We let cross attentions to be saved separately because some models add `cross-attn` layer\n+            # when certain condtions are met. Let's output cross attention if attentions are requested (for BC)\n+            if \"output_attentions\" in recordable_keys:\n+                recordable_keys[\"output_cross_attentions\"] = recordable_keys[\"output_attentions\"]\n+\n+            collected_outputs = defaultdict(tuple)\n+            monkey_patched_layers = []\n+\n+            # Check attention implementation is properly set for capturing attention outputs\n+            if recordable_keys.get(\"output_attentions\", False):\n+                supported_attn = [\"eager\", \"eager_paged\", \"flex_attention\"]\n+                config_attn = getattr(self.config, \"_attn_implementation\", None)\n+                sub_configs = [getattr(self.config, key, None) for key in self.config.sub_configs]\n+                sub_configs_attn = [\n+                    getattr(config, \"_attn_implementation\", None) for config in sub_configs if config is not None\n+                ]\n+                if config_attn not in supported_attn or any(attn not in supported_attn for attn in sub_configs_attn):\n+                    warnings.warn(\n+                        f\"`output_attentions=True` is not supported with `attn_implementation` other than {supported_attn}. \"\n+                        \"Please use `model.set_attn_implementation('eager')` to enable capturing attention outputs.\",\n+                        UserWarning,\n+                    )\n+\n+            def make_capture_wrapper(module, orig_forward, key, index):\n+                @wraps(orig_forward)\n+                def wrapped_forward(*args, **kwargs):\n+                    if key == \"hidden_states\" and len(collected_outputs[key]) == 0:\n+                        collected_outputs[key] += (args[0],)\n+                    if kwargs.get(\"debug_io\", False):\n+                        with model_addition_debugger_context(\n+                            module, kwargs.get(\"debug_io_dir\", \"~/model_debug\"), kwargs.get(\"prune_layers\")\n+                        ):\n+                            output = orig_forward(*args, **kwargs)\n                     else:\n-                        collected_outputs[key] += (output[index],)\n-                return output\n-\n-            return wrapped_forward\n-\n-        if any(recordable_keys.values()):\n-            capture_tasks = []\n-            for key, layer_specs in capture_flags.items():\n-                if not recordable_keys.get(f\"output_{key}\", False):\n-                    continue\n-                if not isinstance(layer_specs, list):\n-                    layer_specs = [layer_specs]\n-                for specs in layer_specs:\n-                    if not isinstance(specs, OutputRecorder):\n-                        index = 0 if \"hidden_states\" in key else 1\n-                        class_name = None if not isinstance(specs, str) else specs\n-                        target_class = specs if not isinstance(specs, str) else None\n-                        specs = OutputRecorder(target_class=target_class, index=index, class_name=class_name)\n-                    capture_tasks.append((key, specs))\n-\n-            for name, module in self.named_modules():\n-                for key, specs in capture_tasks:\n-                    # The second check is for multimodals where only backbone layer suffix is available\n-                    if (specs.target_class is not None and isinstance(module, specs.target_class)) or (\n-                        specs.class_name is not None and name.endswith(specs.class_name)\n-                    ):\n-                        if specs.layer_name is not None and specs.layer_name not in name:\n-                            continue\n-                        # Monkey patch forward\n-                        original_forward = module.forward\n-                        module.forward = make_capture_wrapper(module, original_forward, key, specs.index)\n-                        monkey_patched_layers.append((module, original_forward))\n+                        output = orig_forward(*args, **kwargs)\n+                    if not isinstance(output, tuple):\n+                        collected_outputs[key] += (output,)\n+                    elif output[index] is not None:\n+                        if key not in collected_outputs:\n+                            collected_outputs[key] = (output[index],)\n+                        else:\n+                            collected_outputs[key] += (output[index],)\n+                    return output\n+\n+                return wrapped_forward\n+\n+            if any(recordable_keys.values()):\n+                capture_tasks = []\n+                for key, layer_specs in capture_flags.items():\n+                    if not recordable_keys.get(f\"output_{key}\", False):\n+                        continue\n+                    if not isinstance(layer_specs, list):\n+                        layer_specs = [layer_specs]\n+                    for specs in layer_specs:\n+                        if not isinstance(specs, OutputRecorder):\n+                            index = 0 if \"hidden_states\" in key else 1\n+                            class_name = None if not isinstance(specs, str) else specs\n+                            target_class = specs if not isinstance(specs, str) else None\n+                            specs = OutputRecorder(target_class=target_class, index=index, class_name=class_name)\n+                        capture_tasks.append((key, specs))\n+\n+                for name, module in self.named_modules():\n+                    for key, specs in capture_tasks:\n+                        # The second check is for multimodals where only backbone layer suffix is available\n+                        if (specs.target_class is not None and isinstance(module, specs.target_class)) or (\n+                            specs.class_name is not None and name.endswith(specs.class_name)\n+                        ):\n+                            if specs.layer_name is not None and specs.layer_name not in name:\n+                                continue\n+                            # Monkey patch forward\n+                            original_forward = module.forward\n+                            module.forward = make_capture_wrapper(module, original_forward, key, specs.index)\n+                            monkey_patched_layers.append((module, original_forward))\n \n-        try:\n-            outputs = func(self, *args, **kwargs)\n-        except TypeError as original_exception:\n-            # If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\n-            # Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\n-            # Otherwise -> we're probably missing `**kwargs` in the decorated function\n-            kwargs_without_recordable = {k: v for k, v in kwargs.items() if k not in recordable_keys}\n             try:\n-                outputs = func(self, *args, **kwargs_without_recordable)\n-            except TypeError:\n-                raise original_exception\n-            raise TypeError(\n-                \"Missing `**kwargs` in the signature of the `@check_model_inputs`-decorated function \"\n-                f\"({func.__qualname__})\"\n-            )\n+                outputs = func(self, *args, **kwargs)\n+            except TypeError as original_exception:\n+                # If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\n+                # Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\n+                # Otherwise -> we're probably missing `**kwargs` in the decorated function\n+                kwargs_without_recordable = {k: v for k, v in kwargs.items() if k not in recordable_keys}\n+                try:\n+                    outputs = func(self, *args, **kwargs_without_recordable)\n+                except TypeError:\n+                    raise original_exception\n+                raise TypeError(\n+                    \"Missing `**kwargs` in the signature of the `@check_model_inputs`-decorated function \"\n+                    f\"({func.__qualname__})\"\n+                )\n+\n+            # Restore original forward methods\n+            for module, original_forward in monkey_patched_layers:\n+                module.forward = original_forward\n+\n+            # Inject collected outputs into model output\n+            for key in collected_outputs:\n+                if key == \"hidden_states\":\n+                    if not tie_last_hidden_states:\n+                        pass\n+                    elif hasattr(outputs, \"vision_hidden_states\"):\n+                        collected_outputs[key] = collected_outputs[key][:-1]\n+                        collected_outputs[key] += (outputs.vision_hidden_states,)\n+                    elif hasattr(outputs, \"last_hidden_state\"):\n+                        collected_outputs[key] = collected_outputs[key][:-1]\n+                        collected_outputs[key] += (outputs.last_hidden_state,)\n \n-        # Restore original forward methods\n-        for module, original_forward in monkey_patched_layers:\n-            module.forward = original_forward\n-\n-        # Inject collected outputs into model output\n-        for key in collected_outputs:\n-            if key == \"hidden_states\":\n-                if hasattr(outputs, \"vision_hidden_states\"):\n-                    collected_outputs[key] = collected_outputs[key][:-1]\n-                    collected_outputs[key] += (outputs.vision_hidden_states,)\n-                elif hasattr(outputs, \"last_hidden_state\"):\n-                    collected_outputs[key] = collected_outputs[key][:-1]\n-                    collected_outputs[key] += (outputs.last_hidden_state,)\n-\n-                outputs[key] = collected_outputs[key]\n-            elif key == \"attentions\":\n-                if isinstance(capture_flags[key], list) and len(capture_flags[key]) == 2:\n-                    outputs[key] = collected_outputs[key][0::2]\n-                    outputs[\"cross_\" + key] = collected_outputs[key][1::2]\n+                    outputs[key] = collected_outputs[key]\n+                elif key == \"attentions\":\n+                    if isinstance(capture_flags[key], list) and len(capture_flags[key]) == 2:\n+                        outputs[key] = collected_outputs[key][0::2]\n+                        outputs[\"cross_\" + key] = collected_outputs[key][1::2]\n+                    else:\n+                        outputs[key] = collected_outputs[key]\n                 else:\n                     outputs[key] = collected_outputs[key]\n-            else:\n-                outputs[key] = collected_outputs[key]\n-        if return_dict is False:\n-            outputs = outputs.to_tuple()\n-        return outputs\n+            if return_dict is False:\n+                outputs = outputs.to_tuple()\n+            return outputs\n \n-    return wrapper\n+        return wrapper\n+\n+    return wrapped_fn\n \n \n class GeneralInterface(MutableMapping):"
        },
        {
            "sha": "a2e97c4389a8010a18735e66c512862db7017edf",
            "filename": "tests/models/aria/test_modeling_aria.py",
            "status": "modified",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db58abd6e21c34dbb44068432f2e4b146ab472b/tests%2Fmodels%2Faria%2Ftest_modeling_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db58abd6e21c34dbb44068432f2e4b146ab472b/tests%2Fmodels%2Faria%2Ftest_modeling_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faria%2Ftest_modeling_aria.py?ref=9db58abd6e21c34dbb44068432f2e4b146ab472b",
            "patch": "@@ -198,6 +198,24 @@ def setUp(self):\n         self.model_tester = AriaVisionText2TextModelTester(self)\n         self.config_tester = ConfigTester(self, config_class=AriaConfig, has_text_modality=False)\n \n+    @unittest.skip(\n+        reason=\"This architecture seems to not compute gradients for the last vision-layernorm because the model uses hidden states pre-norm\"\n+    )\n+    def test_training_gradient_checkpointing(self):\n+        pass\n+\n+    @unittest.skip(\n+        reason=\"This architecture seems to not compute gradients for the last vision-layernorm because the model uses hidden states pre-norm\"\n+    )\n+    def test_training_gradient_checkpointing_use_reentrant(self):\n+        pass\n+\n+    @unittest.skip(\n+        reason=\"This architecture seems to not compute gradients for the last vision-layernorm because the model uses hidden states pre-norm\"\n+    )\n+    def test_training_gradient_checkpointing_use_reentrant_false(self):\n+        pass\n+\n \n SKIP = False\n torch_accelerator_module = getattr(torch, torch_device)"
        }
    ],
    "stats": {
        "total": 760,
        "additions": 393,
        "deletions": 367
    }
}