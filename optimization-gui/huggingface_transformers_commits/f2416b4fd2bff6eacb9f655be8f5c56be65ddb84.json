{
    "author": "jiqing-feng",
    "message": "fix pipeline dtype (#40638)\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>",
    "sha": "f2416b4fd2bff6eacb9f655be8f5c56be65ddb84",
    "files": [
        {
            "sha": "92da22477f55f763d0f53c3bfa5477755a17438f",
            "filename": "src/transformers/pipelines/__init__.py",
            "status": "modified",
            "additions": 22,
            "deletions": 22,
            "changes": 44,
            "blob_url": "https://github.com/huggingface/transformers/blob/f2416b4fd2bff6eacb9f655be8f5c56be65ddb84/src%2Ftransformers%2Fpipelines%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f2416b4fd2bff6eacb9f655be8f5c56be65ddb84/src%2Ftransformers%2Fpipelines%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2F__init__.py?ref=f2416b4fd2bff6eacb9f655be8f5c56be65ddb84",
            "patch": "@@ -995,29 +995,29 @@ def pipeline(\n             )\n         model_kwargs[\"device_map\"] = device_map\n \n-        # BC for the `torch_dtype` argument\n-        if (torch_dtype := kwargs.get(\"torch_dtype\")) is not None:\n+    # BC for the `torch_dtype` argument\n+    if (torch_dtype := kwargs.get(\"torch_dtype\")) is not None:\n+        logger.warning_once(\"`torch_dtype` is deprecated! Use `dtype` instead!\")\n+        # If both are provided, keep `dtype`\n+        dtype = torch_dtype if dtype == \"auto\" else dtype\n+    if \"torch_dtype\" in model_kwargs or \"dtype\" in model_kwargs:\n+        if \"torch_dtype\" in model_kwargs:\n             logger.warning_once(\"`torch_dtype` is deprecated! Use `dtype` instead!\")\n-            # If both are provided, keep `dtype`\n-            dtype = torch_dtype if dtype == \"auto\" else dtype\n-        if \"torch_dtype\" in model_kwargs or \"dtype\" in model_kwargs:\n-            if \"torch_dtype\" in model_kwargs:\n-                logger.warning_once(\"`torch_dtype` is deprecated! Use `dtype` instead!\")\n-            # If the user did not explicitly provide `dtype` (i.e. the function default \"auto\" is still\n-            # present) but a value is supplied inside `model_kwargs`, we silently defer to the latter instead of\n-            # raising. This prevents false positives like providing `dtype` only via `model_kwargs` while the\n-            # top-level argument keeps its default value \"auto\".\n-            if dtype == \"auto\":\n-                dtype = None\n-            else:\n-                raise ValueError(\n-                    'You cannot use both `pipeline(... dtype=..., model_kwargs={\"dtype\":...})` as those'\n-                    \" arguments might conflict, use only one.)\"\n-                )\n-        if dtype is not None:\n-            if isinstance(dtype, str) and hasattr(torch, dtype):\n-                dtype = getattr(torch, dtype)\n-            model_kwargs[\"dtype\"] = dtype\n+        # If the user did not explicitly provide `dtype` (i.e. the function default \"auto\" is still\n+        # present) but a value is supplied inside `model_kwargs`, we silently defer to the latter instead of\n+        # raising. This prevents false positives like providing `dtype` only via `model_kwargs` while the\n+        # top-level argument keeps its default value \"auto\".\n+        if dtype == \"auto\":\n+            dtype = None\n+        else:\n+            raise ValueError(\n+                'You cannot use both `pipeline(... dtype=..., model_kwargs={\"dtype\":...})` as those'\n+                \" arguments might conflict, use only one.)\"\n+            )\n+    if dtype is not None:\n+        if isinstance(dtype, str) and hasattr(torch, dtype):\n+            dtype = getattr(torch, dtype)\n+        model_kwargs[\"dtype\"] = dtype\n \n     model_name = model if isinstance(model, str) else None\n "
        }
    ],
    "stats": {
        "total": 44,
        "additions": 22,
        "deletions": 22
    }
}