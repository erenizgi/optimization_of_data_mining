{
    "author": "abdokaseb",
    "message": "Add GptOssForTokenClassification for GPT-OSS models (#40190)\n\n* Add GptOssForTokenClassification for GPT-OSS models\n\n* After run make fixup",
    "sha": "894b2d84b697a9c1b502eb6b18d703b39ec1464a",
    "files": [
        {
            "sha": "136ebeb295708ee263388f4a992c7a598ac609b9",
            "filename": "docs/source/en/model_doc/gpt_oss.md",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/894b2d84b697a9c1b502eb6b18d703b39ec1464a/docs%2Fsource%2Fen%2Fmodel_doc%2Fgpt_oss.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/894b2d84b697a9c1b502eb6b18d703b39ec1464a/docs%2Fsource%2Fen%2Fmodel_doc%2Fgpt_oss.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fgpt_oss.md?ref=894b2d84b697a9c1b502eb6b18d703b39ec1464a",
            "patch": "@@ -60,3 +60,8 @@ The original code can be found [here](<INSERT LINK TO GITHUB REPO HERE>).\n \n [[autodoc]] GptOssForSequenceClassification\n     - forward\n+\n+## GptOssForTokenClassification\n+\n+[[autodoc]] GptOssForTokenClassification\n+    - forward"
        },
        {
            "sha": "88a6e49180d304a46956c339838f95c6d04e553d",
            "filename": "src/transformers/models/auto/modeling_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/894b2d84b697a9c1b502eb6b18d703b39ec1464a/src%2Ftransformers%2Fmodels%2Fauto%2Fmodeling_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/894b2d84b697a9c1b502eb6b18d703b39ec1464a/src%2Ftransformers%2Fmodels%2Fauto%2Fmodeling_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fmodeling_auto.py?ref=894b2d84b697a9c1b502eb6b18d703b39ec1464a",
            "patch": "@@ -1429,6 +1429,7 @@ class _BaseModelWithGenerate(PreTrainedModel, GenerationMixin):\n         (\"gpt_bigcode\", \"GPTBigCodeForTokenClassification\"),\n         (\"gpt_neo\", \"GPTNeoForTokenClassification\"),\n         (\"gpt_neox\", \"GPTNeoXForTokenClassification\"),\n+        (\"gpt_oss\", \"GptOssForTokenClassification\"),\n         (\"helium\", \"HeliumForTokenClassification\"),\n         (\"ibert\", \"IBertForTokenClassification\"),\n         (\"layoutlm\", \"LayoutLMForTokenClassification\"),"
        },
        {
            "sha": "5ed91bb86890ba2cdec63e8fcb41b7ceebc46677",
            "filename": "src/transformers/models/gpt_oss/modeling_gpt_oss.py",
            "status": "modified",
            "additions": 16,
            "deletions": 2,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/894b2d84b697a9c1b502eb6b18d703b39ec1464a/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodeling_gpt_oss.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/894b2d84b697a9c1b502eb6b18d703b39ec1464a/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodeling_gpt_oss.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodeling_gpt_oss.py?ref=894b2d84b697a9c1b502eb6b18d703b39ec1464a",
            "patch": "@@ -28,7 +28,11 @@\n from ...generation import GenerationMixin\n from ...integrations.hub_kernels import use_kernel_forward_from_hub\n from ...masking_utils import create_causal_mask, create_sliding_window_causal_mask\n-from ...modeling_layers import GenericForSequenceClassification, GradientCheckpointingLayer\n+from ...modeling_layers import (\n+    GenericForSequenceClassification,\n+    GenericForTokenClassification,\n+    GradientCheckpointingLayer,\n+)\n from ...modeling_outputs import MoeCausalLMOutputWithPast, MoeModelOutputWithPast\n from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update\n from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n@@ -707,4 +711,14 @@ class GptOssForSequenceClassification(GenericForSequenceClassification, GptOssPr\n     pass\n \n \n-__all__ = [\"GptOssForCausalLM\", \"GptOssForSequenceClassification\", \"GptOssModel\", \"GptOssPreTrainedModel\"]\n+class GptOssForTokenClassification(GenericForTokenClassification, GptOssPreTrainedModel):\n+    pass\n+\n+\n+__all__ = [\n+    \"GptOssForCausalLM\",\n+    \"GptOssForSequenceClassification\",\n+    \"GptOssForTokenClassification\",\n+    \"GptOssModel\",\n+    \"GptOssPreTrainedModel\",\n+]"
        },
        {
            "sha": "845d6e94fe2243dc7c928f515aa6397f876d6fef",
            "filename": "src/transformers/models/gpt_oss/modular_gpt_oss.py",
            "status": "modified",
            "additions": 11,
            "deletions": 1,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/894b2d84b697a9c1b502eb6b18d703b39ec1464a/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodular_gpt_oss.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/894b2d84b697a9c1b502eb6b18d703b39ec1464a/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodular_gpt_oss.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodular_gpt_oss.py?ref=894b2d84b697a9c1b502eb6b18d703b39ec1464a",
            "patch": "@@ -41,7 +41,12 @@\n     LlamaRotaryEmbedding,\n     repeat_kv,\n )\n-from ..mixtral.modeling_mixtral import MixtralForCausalLM, MixtralForSequenceClassification, MixtralModel\n+from ..mixtral.modeling_mixtral import (\n+    MixtralForCausalLM,\n+    MixtralForSequenceClassification,\n+    MixtralForTokenClassification,\n+    MixtralModel,\n+)\n from ..qwen2.modeling_qwen2 import Qwen2Attention\n from .configuration_gpt_oss import GptOssConfig\n \n@@ -447,9 +452,14 @@ class GptOssForSequenceClassification(MixtralForSequenceClassification):\n     pass\n \n \n+class GptOssForTokenClassification(MixtralForTokenClassification):\n+    pass\n+\n+\n __all__ = [\n     \"GptOssForCausalLM\",\n     \"GptOssForSequenceClassification\",\n+    \"GptOssForTokenClassification\",\n     \"GptOssModel\",\n     \"GptOssPreTrainedModel\",\n ]"
        },
        {
            "sha": "e1c0b9d67bf1ac5fe8b27e8140299e8ba6dfd174",
            "filename": "tests/models/gpt_oss/test_modeling_gpt_oss.py",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/894b2d84b697a9c1b502eb6b18d703b39ec1464a/tests%2Fmodels%2Fgpt_oss%2Ftest_modeling_gpt_oss.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/894b2d84b697a9c1b502eb6b18d703b39ec1464a/tests%2Fmodels%2Fgpt_oss%2Ftest_modeling_gpt_oss.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgpt_oss%2Ftest_modeling_gpt_oss.py?ref=894b2d84b697a9c1b502eb6b18d703b39ec1464a",
            "patch": "@@ -50,6 +50,7 @@\n     from transformers import (\n         GptOssForCausalLM,\n         GptOssForSequenceClassification,\n+        GptOssForTokenClassification,\n         GptOssModel,\n     )\n \n@@ -62,12 +63,14 @@ class GptOssModelTester(CausalLMModelTester):\n         base_model_class = GptOssModel\n         causal_lm_class = GptOssForCausalLM\n         sequence_class = GptOssForSequenceClassification\n+        token_class = GptOssForTokenClassification\n \n     pipeline_model_mapping = (\n         {\n             \"feature-extraction\": GptOssModel,\n             \"text-classification\": GptOssForSequenceClassification,\n             \"text-generation\": GptOssForCausalLM,\n+            \"token-classification\": GptOssForTokenClassification,\n         }\n         if is_torch_available()\n         else {}\n@@ -77,13 +80,16 @@ class GptOssModelTester(CausalLMModelTester):\n @require_torch\n class GptOssModelTest(CausalLMModelTest, unittest.TestCase):\n     all_model_classes = (\n-        (GptOssModel, GptOssForCausalLM, GptOssForSequenceClassification) if is_torch_available() else ()\n+        (GptOssModel, GptOssForCausalLM, GptOssForSequenceClassification, GptOssForTokenClassification)\n+        if is_torch_available()\n+        else ()\n     )\n     pipeline_model_mapping = (\n         {\n             \"feature-extraction\": GptOssModel,\n             \"text-classification\": GptOssForSequenceClassification,\n             \"text-generation\": GptOssForCausalLM,\n+            \"token-classification\": GptOssForTokenClassification,\n         }\n         if is_torch_available()\n         else {}"
        }
    ],
    "stats": {
        "total": 44,
        "additions": 40,
        "deletions": 4
    }
}