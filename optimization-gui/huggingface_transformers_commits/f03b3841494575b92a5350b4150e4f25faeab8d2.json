{
    "author": "cyyever",
    "message": "Fix invalid property (#39384)\n\nSigned-off-by: cyy <cyyever@outlook.com>",
    "sha": "f03b3841494575b92a5350b4150e4f25faeab8d2",
    "files": [
        {
            "sha": "6880d9b1321d0603fc5088975924aebd8aaebda4",
            "filename": "src/transformers/quantizers/quantizer_aqlm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f03b3841494575b92a5350b4150e4f25faeab8d2/src%2Ftransformers%2Fquantizers%2Fquantizer_aqlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f03b3841494575b92a5350b4150e4f25faeab8d2/src%2Ftransformers%2Fquantizers%2Fquantizer_aqlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizer_aqlm.py?ref=f03b3841494575b92a5350b4150e4f25faeab8d2",
            "patch": "@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n import importlib\n-from typing import TYPE_CHECKING, Optional\n+from typing import TYPE_CHECKING\n \n from packaging import version\n \n@@ -83,7 +83,7 @@ def _process_model_after_weight_loading(self, model: \"PreTrainedModel\", **kwargs\n         return model\n \n     @property\n-    def is_trainable(self, model: Optional[\"PreTrainedModel\"] = None):\n+    def is_trainable(self) -> bool:\n         aqlm_supports_training = version.parse(importlib.metadata.version(\"aqlm\")) >= version.parse(\"1.0.2\")\n         if aqlm_supports_training:\n             return True"
        },
        {
            "sha": "9f6783daee464f21f714d11905f17a761edf2d3c",
            "filename": "src/transformers/quantizers/quantizer_auto_round.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f03b3841494575b92a5350b4150e4f25faeab8d2/src%2Ftransformers%2Fquantizers%2Fquantizer_auto_round.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f03b3841494575b92a5350b4150e4f25faeab8d2/src%2Ftransformers%2Fquantizers%2Fquantizer_auto_round.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizer_auto_round.py?ref=f03b3841494575b92a5350b4150e4f25faeab8d2",
            "patch": "@@ -11,7 +11,7 @@\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.\n-from typing import TYPE_CHECKING, Optional\n+from typing import TYPE_CHECKING\n \n from .base import HfQuantizer\n \n@@ -73,7 +73,7 @@ def _process_model_after_weight_loading(self, model: \"PreTrainedModel\", **kwargs\n             raise ValueError(\"AutoRound only sports pre-quantized models.\")\n \n     @property\n-    def is_trainable(self, model: Optional[\"PreTrainedModel\"] = None):\n+    def is_trainable(self) -> bool:\n         return False\n \n     def is_serializable(self, safe_serialization=None):"
        },
        {
            "sha": "3670941f2fc46304639eb16247e5b2563e2f399a",
            "filename": "src/transformers/quantizers/quantizer_gptq.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f03b3841494575b92a5350b4150e4f25faeab8d2/src%2Ftransformers%2Fquantizers%2Fquantizer_gptq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f03b3841494575b92a5350b4150e4f25faeab8d2/src%2Ftransformers%2Fquantizers%2Fquantizer_gptq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizer_gptq.py?ref=f03b3841494575b92a5350b4150e4f25faeab8d2",
            "patch": "@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n import importlib\n-from typing import TYPE_CHECKING, Optional\n+from typing import TYPE_CHECKING\n \n from packaging import version\n \n@@ -117,7 +117,7 @@ def _process_model_after_weight_loading(self, model: \"PreTrainedModel\", **kwargs\n             model.config.quantization_config = GPTQConfig.from_dict(self.optimum_quantizer.to_dict())\n \n     @property\n-    def is_trainable(self, model: Optional[\"PreTrainedModel\"] = None):\n+    def is_trainable(self) -> bool:\n         return True\n \n     def is_serializable(self, safe_serialization=None):"
        },
        {
            "sha": "e1a319021fe5e00984840e52c76b0e995d8bb5bb",
            "filename": "src/transformers/quantizers/quantizer_higgs.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f03b3841494575b92a5350b4150e4f25faeab8d2/src%2Ftransformers%2Fquantizers%2Fquantizer_higgs.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f03b3841494575b92a5350b4150e4f25faeab8d2/src%2Ftransformers%2Fquantizers%2Fquantizer_higgs.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizer_higgs.py?ref=f03b3841494575b92a5350b4150e4f25faeab8d2",
            "patch": "@@ -172,7 +172,7 @@ def should_update(key: str) -> bool:\n         return [key for key in missing_keys if not should_update(key)]\n \n     @property\n-    def is_trainable(self, model: Optional[\"PreTrainedModel\"] = None):\n+    def is_trainable(self) -> bool:\n         return False\n \n     def is_serializable(self, safe_serialization=None):"
        },
        {
            "sha": "675d54ed2f77db4d38753f07df8b63639da173a9",
            "filename": "src/transformers/quantizers/quantizer_quanto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f03b3841494575b92a5350b4150e4f25faeab8d2/src%2Ftransformers%2Fquantizers%2Fquantizer_quanto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f03b3841494575b92a5350b4150e4f25faeab8d2/src%2Ftransformers%2Fquantizers%2Fquantizer_quanto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizer_quanto.py?ref=f03b3841494575b92a5350b4150e4f25faeab8d2",
            "patch": "@@ -194,7 +194,7 @@ def _process_model_after_weight_loading(self, model, **kwargs):\n         return model\n \n     @property\n-    def is_trainable(self, model: Optional[\"PreTrainedModel\"] = None):\n+    def is_trainable(self) -> bool:\n         return True\n \n     def is_serializable(self, safe_serialization=None):"
        },
        {
            "sha": "b4824ddc407f832b9814942c7050cee90a4de07f",
            "filename": "src/transformers/quantizers/quantizer_spqr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f03b3841494575b92a5350b4150e4f25faeab8d2/src%2Ftransformers%2Fquantizers%2Fquantizer_spqr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f03b3841494575b92a5350b4150e4f25faeab8d2/src%2Ftransformers%2Fquantizers%2Fquantizer_spqr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizer_spqr.py?ref=f03b3841494575b92a5350b4150e4f25faeab8d2",
            "patch": "@@ -83,7 +83,7 @@ def _process_model_after_weight_loading(self, model: \"PreTrainedModel\", **kwargs\n         return model\n \n     @property\n-    def is_trainable(self, model: Optional[\"PreTrainedModel\"] = None):\n+    def is_trainable(self):\n         return False\n \n     def is_serializable(self, safe_serialization=None):"
        },
        {
            "sha": "f49fcdb4976f95ddc161075267e275c69f2db544",
            "filename": "src/transformers/quantizers/quantizer_vptq.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f03b3841494575b92a5350b4150e4f25faeab8d2/src%2Ftransformers%2Fquantizers%2Fquantizer_vptq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f03b3841494575b92a5350b4150e4f25faeab8d2/src%2Ftransformers%2Fquantizers%2Fquantizer_vptq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizer_vptq.py?ref=f03b3841494575b92a5350b4150e4f25faeab8d2",
            "patch": "@@ -92,7 +92,7 @@ def _process_model_after_weight_loading(self, model: \"PreTrainedModel\", **kwargs\n         return model\n \n     @property\n-    def is_trainable(self, model: Optional[\"PreTrainedModel\"] = None):\n+    def is_trainable(self) -> bool:\n         return False\n \n     def is_serializable(self, safe_serialization=None):"
        }
    ],
    "stats": {
        "total": 20,
        "additions": 10,
        "deletions": 10
    }
}