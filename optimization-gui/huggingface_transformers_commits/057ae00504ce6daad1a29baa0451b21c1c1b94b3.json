{
    "author": "nlhmnlhmnlhm",
    "message": "Small typo lines 47 and 199 perf_infer_gpu_one.md (#37938)\n\n* Small typo line 199 perf_infer_gpu_one.md\n\n* Typo l. 47 perf_infer_gpu_one.md",
    "sha": "057ae00504ce6daad1a29baa0451b21c1c1b94b3",
    "files": [
        {
            "sha": "c3a7ddc8d8aff175243506311cf28380c7749224",
            "filename": "docs/source/en/perf_infer_gpu_one.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/057ae00504ce6daad1a29baa0451b21c1c1b94b3/docs%2Fsource%2Fen%2Fperf_infer_gpu_one.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/057ae00504ce6daad1a29baa0451b21c1c1b94b3/docs%2Fsource%2Fen%2Fperf_infer_gpu_one.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fperf_infer_gpu_one.md?ref=057ae00504ce6daad1a29baa0451b21c1c1b94b3",
            "patch": "@@ -44,7 +44,7 @@ Place all inputs on the same device as the model.\n from transformers import BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM\n \n quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n-tokenizer = AutoTokenizer(\"meta-llama/Llama-3.1-8B\")\n+tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B\")\n model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.1-8B\", device_map=\"auto\", quantization_config=quantization_config)\n \n prompt = \"Hello, my llama is cute\"\n@@ -196,7 +196,7 @@ model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.1-8B\", device_m\n input_text = \"Hello, my llama is cute\"\n inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n \n-with sdpa_kernel(SDPBackend.FLASH_ATTENTION)::\n+with sdpa_kernel(SDPBackend.FLASH_ATTENTION):\n     outputs = model.generate(**inputs)\n \n print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}