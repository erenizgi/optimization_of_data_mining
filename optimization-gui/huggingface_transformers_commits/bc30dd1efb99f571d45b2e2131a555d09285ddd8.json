{
    "author": "hlky",
    "message": "Modular Conversion --fix_and_overwrite on Windows (#36583)\n\n* Modular Conversion --fix_and_overwrite on Windows\n\n* -newline on read",
    "sha": "bc30dd1efb99f571d45b2e2131a555d09285ddd8",
    "files": [
        {
            "sha": "5406809cddc1cabde4dbe876c6d390c2f3b5289b",
            "filename": "utils/check_modular_conversion.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc30dd1efb99f571d45b2e2131a555d09285ddd8/utils%2Fcheck_modular_conversion.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc30dd1efb99f571d45b2e2131a555d09285ddd8/utils%2Fcheck_modular_conversion.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_modular_conversion.py?ref=bc30dd1efb99f571d45b2e2131a555d09285ddd8",
            "patch": "@@ -23,7 +23,7 @@ def process_file(modular_file_path, generated_modeling_content, file_type=\"model\n     file_name_suffix = file_type.split(\"*\")[-1] if \"*\" in file_type else \"\"\n     file_path = modular_file_path.replace(\"modular_\", f\"{file_name_prefix}_\").replace(\".py\", f\"{file_name_suffix}.py\")\n     # Read the actual modeling file\n-    with open(file_path, \"r\") as modeling_file:\n+    with open(file_path, \"r\", encoding=\"utf-8\") as modeling_file:\n         content = modeling_file.read()\n     output_buffer = StringIO(generated_modeling_content[file_type][0])\n     output_buffer.seek(0)\n@@ -39,7 +39,7 @@ def process_file(modular_file_path, generated_modeling_content, file_type=\"model\n     # Check for differences\n     if diff_list:\n         if fix_and_overwrite:\n-            with open(file_path, \"w\") as modeling_file:\n+            with open(file_path, \"w\", encoding=\"utf-8\", newline=\"\\n\") as modeling_file:\n                 modeling_file.write(generated_modeling_content[file_type][0])\n             console.print(f\"[bold blue]Overwritten {file_path} with the generated content.[/bold blue]\")\n         else:"
        },
        {
            "sha": "782617e27c28066958075a076071a9e5b32efeb3",
            "filename": "utils/create_dependency_mapping.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bc30dd1efb99f571d45b2e2131a555d09285ddd8/utils%2Fcreate_dependency_mapping.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bc30dd1efb99f571d45b2e2131a555d09285ddd8/utils%2Fcreate_dependency_mapping.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcreate_dependency_mapping.py?ref=bc30dd1efb99f571d45b2e2131a555d09285ddd8",
            "patch": "@@ -30,7 +30,7 @@ def topological_sort(dependencies: dict):\n \n # Function to extract class and import info from a file\n def extract_classes_and_imports(file_path):\n-    with open(file_path, \"r\") as file:\n+    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n         tree = ast.parse(file.read(), filename=file_path)\n     imports = set()\n "
        }
    ],
    "stats": {
        "total": 6,
        "additions": 3,
        "deletions": 3
    }
}