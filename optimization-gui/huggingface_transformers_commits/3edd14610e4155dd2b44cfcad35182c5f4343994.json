{
    "author": "ydshieh",
    "message": "Set `torch.backends.cudnn.allow_tf32 = False` for CI (#39885)\n\n* fix\n\n* fix\n\n* [test all]\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "3edd14610e4155dd2b44cfcad35182c5f4343994",
    "files": [
        {
            "sha": "1abe8fb4a3cfd19cfd78cd7ec4b80f2cfbb355c9",
            "filename": "conftest.py",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/3edd14610e4155dd2b44cfcad35182c5f4343994/conftest.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3edd14610e4155dd2b44cfcad35182c5f4343994/conftest.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/conftest.py?ref=3edd14610e4155dd2b44cfcad35182c5f4343994",
            "patch": "@@ -23,7 +23,7 @@\n import _pytest\n import pytest\n \n-from transformers.testing_utils import HfDoctestModule, HfDocTestParser\n+from transformers.testing_utils import HfDoctestModule, HfDocTestParser, is_torch_available\n \n \n NOT_DEVICE_TESTS = {\n@@ -127,3 +127,9 @@ def check_output(self, want, got, optionflags):\n doctest.OutputChecker = CustomOutputChecker\n _pytest.doctest.DoctestModule = HfDoctestModule\n doctest.DocTestParser = HfDocTestParser\n+\n+if is_torch_available():\n+    import torch\n+    # The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n+    # We set it to `False` for CI. See https://github.com/pytorch/pytorch/issues/157274#issuecomment-3090791615\n+    torch.backends.cudnn.allow_tf32 = False"
        }
    ],
    "stats": {
        "total": 8,
        "additions": 7,
        "deletions": 1
    }
}