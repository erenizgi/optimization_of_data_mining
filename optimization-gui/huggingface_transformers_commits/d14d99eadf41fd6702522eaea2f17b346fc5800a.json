{
    "author": "LysandreJik",
    "message": "Fix infinity in JSON serialized files (#42959)\n\n* Handle inifinity and NaNs in JSON serialization\n\n* Docs\n\n* Tests",
    "sha": "d14d99eadf41fd6702522eaea2f17b346fc5800a",
    "files": [
        {
            "sha": "73d8a48b20a2d161dd8818fc1778541c5d286325",
            "filename": "src/transformers/configuration_utils.py",
            "status": "modified",
            "additions": 58,
            "deletions": 1,
            "changes": 59,
            "blob_url": "https://github.com/huggingface/transformers/blob/d14d99eadf41fd6702522eaea2f17b346fc5800a/src%2Ftransformers%2Fconfiguration_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d14d99eadf41fd6702522eaea2f17b346fc5800a/src%2Ftransformers%2Fconfiguration_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fconfiguration_utils.py?ref=d14d99eadf41fd6702522eaea2f17b346fc5800a",
            "patch": "@@ -16,6 +16,7 @@\n \n import copy\n import json\n+import math\n import os\n import warnings\n from typing import TYPE_CHECKING, Any, Optional, TypeVar, Union\n@@ -50,6 +51,9 @@\n # type hinting: specifying the type of config class that inherits from PreTrainedConfig\n SpecificPreTrainedConfigType = TypeVar(\"SpecificPreTrainedConfigType\", bound=\"PreTrainedConfig\")\n \n+_FLOAT_TAG_KEY = \"__float__\"\n+_FLOAT_TAG_VALUES = {\"Infinity\": float(\"inf\"), \"-Infinity\": float(\"-inf\"), \"NaN\": float(\"nan\")}\n+\n \n class PreTrainedConfig(PushToHubMixin, RotaryEmbeddingConfigMixin):\n     # no-format\n@@ -812,7 +816,56 @@ def from_json_file(\n     def _dict_from_json_file(cls, json_file: str | os.PathLike):\n         with open(json_file, encoding=\"utf-8\") as reader:\n             text = reader.read()\n-        return json.loads(text)\n+        config_dict = json.loads(text)\n+\n+        return cls._decode_special_floats(config_dict)\n+\n+    @classmethod\n+    def _encode_special_floats(cls, obj: Any) -> Any:\n+        \"\"\"\n+        Iterates over the passed object and encode specific floats that cannot be JSON-serialized. Python's JSON\n+        engine saves floats like `Infinity` (+/-) or `NaN` which are not compatible with other JSON engines.\n+\n+        It serializes floats like `Infinity` as an object: `{'__float__': Infinity}`.\n+        \"\"\"\n+        if isinstance(obj, float):\n+            if math.isnan(obj):\n+                return {_FLOAT_TAG_KEY: \"NaN\"}\n+            if obj == float(\"inf\"):\n+                return {_FLOAT_TAG_KEY: \"Infinity\"}\n+            if obj == float(\"-inf\"):\n+                return {_FLOAT_TAG_KEY: \"-Infinity\"}\n+            return obj\n+\n+        if isinstance(obj, dict):\n+            return {k: cls._encode_special_floats(v) for k, v in obj.items()}\n+\n+        if isinstance(obj, (list, tuple)):\n+            return [cls._encode_special_floats(v) for v in obj]\n+\n+        return obj\n+\n+    @classmethod\n+    def _decode_special_floats(cls, obj: Any) -> Any:\n+        \"\"\"\n+        Iterates over the passed object and decode specific floats that cannot be JSON-serialized. Python's JSON\n+        engine saves floats like `Infinity` (+/-) or `NaN` which are not compatible with other JSON engines.\n+\n+        This method deserializes objects like `{'__float__': Infinity}` to their float values like `Infinity`.\n+        \"\"\"\n+        if isinstance(obj, dict):\n+            if set(obj.keys()) == {_FLOAT_TAG_KEY} and isinstance(obj[_FLOAT_TAG_KEY], str):\n+                tag = obj[_FLOAT_TAG_KEY]\n+                if tag in _FLOAT_TAG_VALUES:\n+                    return _FLOAT_TAG_VALUES[tag]\n+                return obj\n+\n+            return {k: cls._decode_special_floats(v) for k, v in obj.items()}\n+\n+        if isinstance(obj, list):\n+            return [cls._decode_special_floats(v) for v in obj]\n+\n+        return obj\n \n     def __eq__(self, other):\n         return isinstance(other, PreTrainedConfig) and (self.__dict__ == other.__dict__)\n@@ -932,6 +985,10 @@ def to_json_string(self, use_diff: bool = True) -> str:\n             config_dict = self.to_diff_dict()\n         else:\n             config_dict = self.to_dict()\n+\n+        # Handle +/-Infinity and NaNs\n+        config_dict = self._encode_special_floats(config_dict)\n+\n         return json.dumps(config_dict, indent=2, sort_keys=True) + \"\\n\"\n \n     def to_json_file(self, json_file_path: str | os.PathLike, use_diff: bool = True):"
        },
        {
            "sha": "bee78d25b6eb57c4965703eff7ff57e8d07295a6",
            "filename": "tests/utils/test_configuration_utils.py",
            "status": "modified",
            "additions": 41,
            "deletions": 0,
            "changes": 41,
            "blob_url": "https://github.com/huggingface/transformers/blob/d14d99eadf41fd6702522eaea2f17b346fc5800a/tests%2Futils%2Ftest_configuration_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d14d99eadf41fd6702522eaea2f17b346fc5800a/tests%2Futils%2Ftest_configuration_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_configuration_utils.py?ref=d14d99eadf41fd6702522eaea2f17b346fc5800a",
            "patch": "@@ -329,3 +329,44 @@ def test_bc_torch_dtype(self):\n \n             config = PreTrainedConfig.from_pretrained(tmpdirname, torch_dtype=\"float32\")\n             self.assertEqual(config.dtype, \"float32\")\n+\n+    def test_unserializable_json_is_encoded(self):\n+        class NewConfig(PreTrainedConfig):\n+            def __init__(\n+                self,\n+                inf_positive: float = float(\"inf\"),\n+                inf_negative: float = float(\"-inf\"),\n+                nan: float = float(\"nan\"),\n+                **kwargs,\n+            ):\n+                self.inf_positive = inf_positive\n+                self.inf_negative = inf_negative\n+                self.nan = nan\n+\n+                super().__init__(**kwargs)\n+\n+        new_config = NewConfig()\n+\n+        # All floats should remain as floats when being accessed in the config\n+        self.assertIsInstance(new_config.inf_positive, float)\n+        self.assertIsInstance(new_config.inf_negative, float)\n+        self.assertIsInstance(new_config.nan, float)\n+\n+        with tempfile.TemporaryDirectory() as tmpdirname:\n+            new_config.save_pretrained(tmpdirname)\n+            config_file = Path(tmpdirname) / \"config.json\"\n+            config_contents = json.loads(config_file.read_text())\n+            new_config_instance = NewConfig.from_pretrained(tmpdirname)\n+\n+        # In the serialized JSON file, the non-JSON compatible floats should be updated\n+        self.assertDictEqual(config_contents[\"inf_positive\"], {\"__float__\": \"Infinity\"})\n+        self.assertDictEqual(config_contents[\"inf_negative\"], {\"__float__\": \"-Infinity\"})\n+        self.assertDictEqual(config_contents[\"nan\"], {\"__float__\": \"NaN\"})\n+\n+        with tempfile.TemporaryDirectory() as tmpdirname:\n+            new_config.save_pretrained(tmpdirname)\n+\n+        # When reloading the config, it should have correct float values\n+        self.assertIsInstance(new_config_instance.inf_positive, float)\n+        self.assertIsInstance(new_config_instance.inf_negative, float)\n+        self.assertIsInstance(new_config_instance.nan, float)"
        }
    ],
    "stats": {
        "total": 100,
        "additions": 99,
        "deletions": 1
    }
}