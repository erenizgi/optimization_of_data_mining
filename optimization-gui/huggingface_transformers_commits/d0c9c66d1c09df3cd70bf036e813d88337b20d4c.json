{
    "author": "ydshieh",
    "message": "new failure CI reports for all jobs  (#38298)\n\n* new failures\n\n* report_repo_id\n\n* report_repo_id\n\n* report_repo_id\n\n* More fixes\n\n* More fixes\n\n* More fixes\n\n* ruff\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "d0c9c66d1c09df3cd70bf036e813d88337b20d4c",
    "files": [
        {
            "sha": "478f9d0ae2aed1d05d6fca4705667b711fd12185",
            "filename": ".github/workflows/check_failed_tests.yml",
            "status": "renamed",
            "additions": 40,
            "deletions": 10,
            "changes": 50,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/.github%2Fworkflows%2Fcheck_failed_tests.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/.github%2Fworkflows%2Fcheck_failed_tests.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fcheck_failed_tests.yml?ref=d0c9c66d1c09df3cd70bf036e813d88337b20d4c",
            "patch": "@@ -9,6 +9,18 @@ on:\n       start_sha:\n         required: true\n         type: string\n+      job:\n+        required: true\n+        type: string\n+      slack_report_channel:\n+        required: true\n+        type: string\n+      ci_event:\n+        required: true\n+        type: string\n+      report_repo_id:\n+        required: true\n+        type: string\n \n \n env:\n@@ -26,7 +38,7 @@ env:\n \n \n jobs:\n-  run_models_gpu:\n+  check_new_failures:\n     name: \" \"\n     runs-on:\n       group: aws-g4dn-4xlarge-cache\n@@ -36,17 +48,17 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@v4\n         with:\n-          name: ci_results_run_models_gpu\n-          path: /transformers/ci_results_run_models_gpu\n+          name: ci_results_${{ inputs.job }}\n+          path: /transformers/ci_results_${{ inputs.job }}\n \n       - name: Check file\n         working-directory: /transformers\n         run: |\n-          if [ -f ci_results_run_models_gpu/new_model_failures.json ]; then\n-            echo \"`ci_results_run_models_gpu/new_model_failures.json` exists, continue ...\"\n+          if [ -f ci_results_${{ inputs.job }}/new_failures.json ]; then\n+            echo \"`ci_results_${{ inputs.job }}/new_failures.json` exists, continue ...\"\n             echo \"process=true\" >> $GITHUB_ENV\n           else\n-            echo \"`ci_results_run_models_gpu/new_model_failures.json` doesn't exist, abort.\"\n+            echo \"`ci_results_${{ inputs.job }}/new_failures.json` doesn't exist, abort.\"\n             echo \"process=false\" >> $GITHUB_ENV\n           fi\n \n@@ -112,14 +124,14 @@ jobs:\n       - name: Check failed tests\n         working-directory: /transformers\n         if: ${{ env.process == 'true' }}\n-        run: python3 utils/check_bad_commit.py --start_commit ${{ inputs.start_sha }} --end_commit ${{ env.END_SHA }} --file ci_results_run_models_gpu/new_model_failures.json --output_file new_model_failures_with_bad_commit.json\n+        run: python3 utils/check_bad_commit.py --start_commit ${{ inputs.start_sha }} --end_commit ${{ env.END_SHA }} --file ci_results_${{ inputs.job }}/new_failures.json --output_file new_failures_with_bad_commit.json\n \n       - name: Show results\n         working-directory: /transformers\n         if: ${{ env.process == 'true' }}\n         run: |\n-          ls -l new_model_failures_with_bad_commit.json\n-          cat new_model_failures_with_bad_commit.json\n+          ls -l new_failures_with_bad_commit.json\n+          cat new_failures_with_bad_commit.json\n \n       - name: Checkout back\n         working-directory: /transformers\n@@ -134,6 +146,8 @@ jobs:\n         env:\n           ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n           TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN: ${{ secrets.TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN }}\n+          JOB_NAME: ${{ inputs.job }}\n+          REPORT_REPO_ID: ${{ inputs.report_repo_id }}\n         run: |\n           python3 utils/process_bad_commit_report.py\n \n@@ -144,24 +158,40 @@ jobs:\n         env:\n           ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n           TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN: ${{ secrets.TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN }}\n+          JOB_NAME: ${{ inputs.job }}\n+          REPORT_REPO_ID: ${{ inputs.report_repo_id }}\n         run: |\n           {\n             echo 'REPORT_TEXT<<EOF'\n             python3 utils/process_bad_commit_report.py\n             echo EOF\n           } >> \"$GITHUB_ENV\"\n \n+      - name: Prepare Slack report title\n+        working-directory: /transformers\n+        if: ${{ env.process == 'true' }}\n+        run: |\n+          pip install slack_sdk\n+          echo \"title=$(python3 -c 'import sys; sys.path.append(\"utils\"); from utils.notification_service import job_to_test_map; ci_event = \"${{ inputs.ci_event }}\"; job = \"${{ inputs.job }}\"; test_name = job_to_test_map[job]; title = f\"New failed tests of {ci_event}\" + \":\" + f\" {test_name}\"; print(title)')\" >> $GITHUB_ENV\n+\n       - name: Send processed report\n         if: ${{ env.process == 'true' && !endsWith(env.REPORT_TEXT, '{}') }}\n         uses: slackapi/slack-github-action@6c661ce58804a1a20f6dc5fbee7f0381b469e001\n         with:\n           # Slack channel id, channel name, or user id to post message.\n           # See also: https://api.slack.com/methods/chat.postMessage#channels\n-          channel-id: '#transformers-ci-feedback-tests'\n+          channel-id: '#${{ inputs.slack_report_channel }}'\n           # For posting a rich message using Block Kit\n           payload: |\n             {\n               \"blocks\": [\n+                {\n+                  \"type\": \"header\",\n+                  \"text\": {\n+                    \"type\": \"plain_text\",\n+                    \"text\": \"${{ env.title }}\"\n+                  }\n+                },\n                 {\n                   \"type\": \"section\",\n                   \"text\": {",
            "previous_filename": ".github/workflows/check_failed_model_tests.yml"
        },
        {
            "sha": "8c75f453b487ab1b559fef2f2f53082373e29380",
            "filename": ".github/workflows/self-scheduled-amd-mi210-caller.yml",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/.github%2Fworkflows%2Fself-scheduled-amd-mi210-caller.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/.github%2Fworkflows%2Fself-scheduled-amd-mi210-caller.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-scheduled-amd-mi210-caller.yml?ref=d0c9c66d1c09df3cd70bf036e813d88337b20d4c",
            "patch": "@@ -19,6 +19,7 @@ jobs:\n       runner: mi210\n       docker: huggingface/transformers-pytorch-amd-gpu\n       ci_event: Scheduled CI (AMD) - mi210\n+      report_repo_id: optimum-amd/transformers_daily_ci\n     secrets: inherit\n \n   torch-pipeline:\n@@ -30,6 +31,7 @@ jobs:\n       runner: mi210\n       docker: huggingface/transformers-pytorch-amd-gpu\n       ci_event: Scheduled CI (AMD) - mi210\n+      report_repo_id: optimum-amd/transformers_daily_ci\n     secrets: inherit\n \n   example-ci:\n@@ -41,6 +43,7 @@ jobs:\n       runner: mi210\n       docker: huggingface/transformers-pytorch-amd-gpu\n       ci_event: Scheduled CI (AMD) - mi210\n+      report_repo_id: optimum-amd/transformers_daily_ci\n     secrets: inherit\n \n   deepspeed-ci:\n@@ -52,4 +55,5 @@ jobs:\n       runner: mi210\n       docker: huggingface/transformers-pytorch-deepspeed-amd-gpu\n       ci_event: Scheduled CI (AMD) - mi210\n+      report_repo_id: optimum-amd/transformers_daily_ci\n     secrets: inherit"
        },
        {
            "sha": "476fba31ee29d012efe26d9741d75f689fae68f1",
            "filename": ".github/workflows/self-scheduled-amd-mi250-caller.yml",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/.github%2Fworkflows%2Fself-scheduled-amd-mi250-caller.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/.github%2Fworkflows%2Fself-scheduled-amd-mi250-caller.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-scheduled-amd-mi250-caller.yml?ref=d0c9c66d1c09df3cd70bf036e813d88337b20d4c",
            "patch": "@@ -19,6 +19,7 @@ jobs:\n       runner: mi250\n       docker: huggingface/transformers-pytorch-amd-gpu\n       ci_event: Scheduled CI (AMD) - mi250\n+      report_repo_id: optimum-amd/transformers_daily_ci\n     secrets: inherit\n \n   torch-pipeline:\n@@ -30,6 +31,7 @@ jobs:\n       runner: mi250\n       docker: huggingface/transformers-pytorch-amd-gpu\n       ci_event: Scheduled CI (AMD) - mi250\n+      report_repo_id: optimum-amd/transformers_daily_ci\n     secrets: inherit\n \n   example-ci:\n@@ -41,6 +43,7 @@ jobs:\n       runner: mi250\n       docker: huggingface/transformers-pytorch-amd-gpu\n       ci_event: Scheduled CI (AMD) - mi250\n+      report_repo_id: optimum-amd/transformers_daily_ci\n     secrets: inherit\n \n   deepspeed-ci:\n@@ -52,4 +55,5 @@ jobs:\n       runner: mi250\n       docker: huggingface/transformers-pytorch-deepspeed-amd-gpu\n       ci_event: Scheduled CI (AMD) - mi250\n+      report_repo_id: optimum-amd/transformers_daily_ci\n     secrets: inherit"
        },
        {
            "sha": "f48d357cd5d98cabba2e192cf20c32c5cf430427",
            "filename": ".github/workflows/self-scheduled-caller.yml",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/.github%2Fworkflows%2Fself-scheduled-caller.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/.github%2Fworkflows%2Fself-scheduled-caller.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-scheduled-caller.yml?ref=d0c9c66d1c09df3cd70bf036e813d88337b20d4c",
            "patch": "@@ -54,6 +54,7 @@ jobs:\n       runner: daily-ci\n       docker: huggingface/transformers-all-latest-gpu\n       ci_event: Daily CI\n+      report_repo_id: hf-internal-testing/transformers_daily_ci\n     secrets: inherit\n \n   torch-pipeline:\n@@ -65,6 +66,7 @@ jobs:\n       runner: daily-ci\n       docker: huggingface/transformers-pytorch-gpu\n       ci_event: Daily CI\n+      report_repo_id: hf-internal-testing/transformers_daily_ci\n     secrets: inherit\n \n   tf-pipeline:\n@@ -76,6 +78,7 @@ jobs:\n       runner: daily-ci\n       docker: huggingface/transformers-tensorflow-gpu\n       ci_event: Daily CI\n+      report_repo_id: hf-internal-testing/transformers_daily_ci\n     secrets: inherit\n \n   example-ci:\n@@ -87,6 +90,7 @@ jobs:\n       runner: daily-ci\n       docker: huggingface/transformers-all-latest-gpu\n       ci_event: Daily CI\n+      report_repo_id: hf-internal-testing/transformers_daily_ci\n     secrets: inherit\n \n   trainer-fsdp-ci:\n@@ -98,6 +102,7 @@ jobs:\n       runner: daily-ci\n       docker: huggingface/transformers-all-latest-gpu\n       ci_event: Daily CI\n+      report_repo_id: hf-internal-testing/transformers_daily_ci\n     secrets: inherit\n \n   deepspeed-ci:\n@@ -110,6 +115,7 @@ jobs:\n       docker: huggingface/transformers-pytorch-deepspeed-latest-gpu\n       ci_event: Daily CI\n       working-directory-prefix: /workspace\n+      report_repo_id: hf-internal-testing/transformers_daily_ci\n     secrets: inherit\n \n   quantization-ci:\n@@ -121,4 +127,5 @@ jobs:\n       runner: daily-ci\n       docker: huggingface/transformers-quantization-latest-gpu\n       ci_event: Daily CI\n+      report_repo_id: hf-internal-testing/transformers_daily_ci\n     secrets: inherit"
        },
        {
            "sha": "5fc037fec203753397d89da9977f2828c71e843a",
            "filename": ".github/workflows/self-scheduled.yml",
            "status": "modified",
            "additions": 15,
            "deletions": 4,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/.github%2Fworkflows%2Fself-scheduled.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/.github%2Fworkflows%2Fself-scheduled.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-scheduled.yml?ref=d0c9c66d1c09df3cd70bf036e813d88337b20d4c",
            "patch": "@@ -28,6 +28,10 @@ on:\n         default: ''\n         required: false\n         type: string\n+      report_repo_id:\n+        required: true\n+        type: string\n+\n \n env:\n   HF_HOME: /mnt/cache\n@@ -584,15 +588,22 @@ jobs:\n       folder_slices: ${{ needs.setup.outputs.folder_slices }}\n       quantization_matrix: ${{ needs.setup.outputs.quantization_matrix }}\n       ci_event: ${{ inputs.ci_event }}\n+      report_repo_id: ${{ inputs.report_repo_id }}\n \n     secrets: inherit\n \n-  check_new_model_failures:\n-    if: ${{ always() && inputs.ci_event == 'Daily CI' && inputs.job == 'run_models_gpu' && needs.send_results.result == 'success' }}\n-    name: Check new model failures\n+  check_new_failures:\n+    # TODO: work on `run_quantization_torch_gpu`\n+    if: ${{ always() && inputs.ci_event == 'Daily CI' && inputs.job != 'run_quantization_torch_gpu' && needs.send_results.result == 'success' }}\n+    name: Check new failures\n     needs: send_results\n-    uses: ./.github/workflows/check_failed_model_tests.yml\n+    uses: ./.github/workflows/check_failed_tests.yml\n     with:\n       docker: ${{ inputs.docker }}\n       start_sha: ${{ github.sha }}\n+      job: ${{ inputs.job }}\n+      slack_report_channel: ${{ inputs.slack_report_channel }}\n+      ci_event: ${{ inputs.ci_event }}\n+      report_repo_id: ${{ inputs.report_repo_id }}\n+\n     secrets: inherit"
        },
        {
            "sha": "c6aa336e8f481ade70ce37428dd8427034c4e1e9",
            "filename": ".github/workflows/slack-report.yml",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/.github%2Fworkflows%2Fslack-report.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/.github%2Fworkflows%2Fslack-report.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fslack-report.yml?ref=d0c9c66d1c09df3cd70bf036e813d88337b20d4c",
            "patch": "@@ -21,6 +21,9 @@ on:\n       ci_event:\n         required: true\n         type: string\n+      report_repo_id:\n+        required: true\n+        type: string\n \n env:\n   TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN: ${{ secrets.TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN }}\n@@ -67,6 +70,7 @@ jobs:\n           CI_SHA: ${{ github.sha }}\n           CI_TEST_JOB: ${{ inputs.job }}\n           SETUP_STATUS: ${{ inputs.setup_status }}\n+          REPORT_REPO_ID: ${{ inputs.report_repo_id }}\n         # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n         # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n         # For a job that doesn't depend on (i.e. `needs`) `setup`, the value for `inputs.folder_slices` would be an\n@@ -96,6 +100,7 @@ jobs:\n           CI_SHA: ${{ github.sha }}\n           CI_TEST_JOB: ${{ inputs.job }}\n           SETUP_STATUS: ${{ inputs.setup_status }}\n+          REPORT_REPO_ID: ${{ inputs.report_repo_id }}\n         # We pass `needs.setup.outputs.quantization_matrix` as the argument. A processing in `notification_service_quantization.py` to change\n         # `quantization/bnb` to `quantization_bnb` is required, as the artifact names use `_` instead of `/`.\n         run: |"
        },
        {
            "sha": "a251b9541502d0489d41d1e778235962190a990c",
            "filename": "utils/check_bad_commit.py",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/utils%2Fcheck_bad_commit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/utils%2Fcheck_bad_commit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_bad_commit.py?ref=d0c9c66d1c09df3cd70bf036e813d88337b20d4c",
            "patch": "@@ -39,13 +39,16 @@ def create_script(target_test):\n import subprocess\n \n result = subprocess.run(\n-    [\"python3\", \"-m\", \"pytest\", \"-v\", f\"{target_test}\"],\n+    [\"python3\", \"-m\", \"pytest\", \"-v\", \"-rfEp\", f\"{target_test}\"],\n     capture_output = True,\n     text=True,\n )\n print(result.stdout)\n \n-if len(result.stderr) > 0:\n+if f\"PASSED {target_test}\" in result.stdout:\n+    print(\"test passed\")\n+    exit(0)\n+elif len(result.stderr) > 0:\n     if \"ERROR: file or directory not found: \" in result.stderr:\n         print(\"test file or directory not found in this commit\")\n         exit(0)"
        },
        {
            "sha": "83828d645de75785922ecf13e762813c1dfb7d1a",
            "filename": "utils/get_previous_daily_ci.py",
            "status": "modified",
            "additions": 7,
            "deletions": 3,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/utils%2Fget_previous_daily_ci.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/utils%2Fget_previous_daily_ci.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fget_previous_daily_ci.py?ref=d0c9c66d1c09df3cd70bf036e813d88337b20d4c",
            "patch": "@@ -28,11 +28,15 @@ def get_daily_ci_runs(token, num_runs=7, workflow_id=None):\n \n     url = f\"https://api.github.com/repos/huggingface/transformers/actions/workflows/{workflow_id}/runs\"\n     # On `main` branch + event being `schedule` + not returning PRs + only `num_runs` results\n-    url += f\"?branch=main&event=schedule&exclude_pull_requests=true&per_page={num_runs}\"\n+    url += f\"?branch=main&exclude_pull_requests=true&per_page={num_runs}\"\n \n-    result = requests.get(url, headers=headers).json()\n+    result = requests.get(f\"{url}&event=schedule\", headers=headers).json()\n+    workflow_runs = result[\"workflow_runs\"]\n+    if len(workflow_runs) == 0:\n+        result = requests.get(f\"{url}&event=workflow_run\", headers=headers).json()\n+        workflow_runs = result[\"workflow_runs\"]\n \n-    return result[\"workflow_runs\"]\n+    return workflow_runs\n \n \n def get_last_daily_ci_run(token, workflow_run_id=None, workflow_id=None, commit_sha=None):"
        },
        {
            "sha": "96f4370da5735ed78076f99464ab4f298f1f8edc",
            "filename": "utils/notification_service.py",
            "status": "modified",
            "additions": 140,
            "deletions": 91,
            "changes": 231,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/utils%2Fnotification_service.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/utils%2Fnotification_service.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fnotification_service.py?ref=d0c9c66d1c09df3cd70bf036e813d88337b20d4c",
            "patch": "@@ -30,8 +30,17 @@\n from slack_sdk import WebClient\n \n \n-api = HfApi()\n-client = WebClient(token=os.environ[\"CI_SLACK_BOT_TOKEN\"])\n+# A map associating the job names (specified by `inputs.job` in a workflow file) with the keys of\n+# `additional_files`. This is used to remove some entries in `additional_files` that are not concerned by a\n+# specific job. See below.\n+job_to_test_map = {\n+    \"run_models_gpu\": \"Models\",\n+    \"run_trainer_and_fsdp_gpu\": \"Trainer & FSDP\",\n+    \"run_pipelines_torch_gpu\": \"PyTorch pipelines\",\n+    \"run_pipelines_tf_gpu\": \"TensorFlow pipelines\",\n+    \"run_examples_gpu\": \"Examples directory\",\n+    \"run_torch_cuda_extensions_gpu\": \"DeepSpeed\",\n+}\n \n NON_MODEL_TEST_MODULES = [\n     \"deepspeed\",\n@@ -516,6 +525,7 @@ def payload(self) -> str:\n         if len(self.selected_warnings) > 0:\n             blocks.append(self.warnings)\n \n+        new_failure_blocks = []\n         for idx, (prev_workflow_run_id, prev_ci_artifacts) in enumerate(\n             [self.prev_ci_artifacts] + self.other_ci_artifacts\n         ):\n@@ -524,13 +534,11 @@ def payload(self) -> str:\n                 new_failure_blocks = self.get_new_model_failure_blocks(\n                     prev_ci_artifacts=prev_ci_artifacts, with_header=False\n                 )\n-                if len(new_failure_blocks) > 0:\n-                    blocks.extend(new_failure_blocks)\n \n             # To save the list of new model failures and uploaed to hub repositories\n             extra_blocks = self.get_new_model_failure_blocks(prev_ci_artifacts=prev_ci_artifacts, to_truncate=False)\n             if extra_blocks:\n-                filename = \"new_model_failures\"\n+                filename = \"new_failures\"\n                 if idx > 0:\n                     filename = f\"{filename}_against_{prev_workflow_run_id}\"\n \n@@ -541,17 +549,17 @@ def payload(self) -> str:\n \n                 # upload results to Hub dataset\n                 file_path = os.path.join(os.getcwd(), f\"ci_results_{job_name}/{filename}.txt\")\n-                commit_info = api.upload_file(\n+                _ = api.upload_file(\n                     path_or_fileobj=file_path,\n                     path_in_repo=f\"{report_repo_folder}/ci_results_{job_name}/{filename}.txt\",\n-                    repo_id=\"hf-internal-testing/transformers_daily_ci\",\n+                    repo_id=report_repo_id,\n                     repo_type=\"dataset\",\n                     token=os.environ.get(\"TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN\", None),\n                 )\n-                url = f\"https://huggingface.co/datasets/hf-internal-testing/transformers_daily_ci/raw/{commit_info.oid}/{report_repo_folder}/ci_results_{job_name}/{filename}.txt\"\n \n                 # extra processing to save to json format\n                 new_failed_tests = {}\n+                nb_new_failed_tests = 0\n                 for line in failure_text.split():\n                     if \"https://github.com/huggingface/transformers/actions/runs\" in line:\n                         pattern = r\"<(https://github.com/huggingface/transformers/actions/runs/.+?/job/.+?)\\|(.+?)>\"\n@@ -563,36 +571,56 @@ def payload(self) -> str:\n                             model = line.split(\"/\")[1]\n                         if model not in new_failed_tests:\n                             new_failed_tests[model] = {\"single-gpu\": [], \"multi-gpu\": []}\n-                        for url, device in items:\n+                        for _, device in items:\n                             new_failed_tests[model][f\"{device}-gpu\"].append(line)\n+                            nb_new_failed_tests += 1\n                 file_path = os.path.join(os.getcwd(), f\"ci_results_{job_name}/{filename}.json\")\n                 with open(file_path, \"w\", encoding=\"UTF-8\") as fp:\n                     json.dump(new_failed_tests, fp, ensure_ascii=False, indent=4)\n \n                 # upload results to Hub dataset\n                 file_path = os.path.join(os.getcwd(), f\"ci_results_{job_name}/{filename}.json\")\n-                _ = api.upload_file(\n+                commit_info = api.upload_file(\n                     path_or_fileobj=file_path,\n                     path_in_repo=f\"{report_repo_folder}/ci_results_{job_name}/{filename}.json\",\n-                    repo_id=\"hf-internal-testing/transformers_daily_ci\",\n+                    repo_id=report_repo_id,\n                     repo_type=\"dataset\",\n                     token=os.environ.get(\"TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN\", None),\n                 )\n+                new_failures_url = f\"https://huggingface.co/datasets/{report_repo_id}/raw/{commit_info.oid}/{report_repo_folder}/ci_results_{job_name}/{filename}.json\"\n \n                 if idx == 0:\n                     block = {\n                         \"type\": \"section\",\n                         \"text\": {\n-                            \"type\": \"plain_text\",\n-                            \"text\": \" \",\n+                            \"type\": \"mrkdwn\",\n+                            \"text\": f\"*There are {nb_new_failed_tests} new failed tests*\\n\\n(compared to previous run: <https://github.com/huggingface/transformers/actions/runs/{prev_workflow_run_id}|{prev_workflow_run_id}>)\",\n                         },\n                         \"accessory\": {\n                             \"type\": \"button\",\n-                            \"text\": {\"type\": \"plain_text\", \"text\": \"Check New model failures\"},\n-                            \"url\": url,\n+                            \"text\": {\"type\": \"plain_text\", \"text\": \"Check new failures\"},\n+                            \"url\": new_failures_url,\n                         },\n                     }\n                     blocks.append(block)\n+                else:\n+                    block = {\n+                        \"type\": \"section\",\n+                        \"text\": {\n+                            \"type\": \"mrkdwn\",\n+                            # TODO: We should NOT assume it's always Nvidia CI, but it's the case at this moment.\n+                            \"text\": f\"*There are {nb_new_failed_tests} failed tests unique to this run*\\n\\n(compared to Nvidia CI: <https://github.com/huggingface/transformers/actions/runs/{prev_workflow_run_id}|{prev_workflow_run_id}>)\",\n+                        },\n+                        \"accessory\": {\n+                            \"type\": \"button\",\n+                            \"text\": {\"type\": \"plain_text\", \"text\": \"Check failures\"},\n+                            \"url\": new_failures_url,\n+                        },\n+                    }\n+                    blocks.append(block)\n+\n+        if len(new_failure_blocks) > 0:\n+            blocks.extend(new_failure_blocks)\n \n         return json.dumps(blocks)\n \n@@ -717,14 +745,28 @@ def get_new_model_failure_blocks(self, prev_ci_artifacts, with_header=True, to_t\n         if prev_ci_artifacts is None:\n             return []\n \n-        sorted_dict = sorted(self.model_results.items(), key=lambda t: t[0])\n+        if len(self.model_results) > 0:\n+            target_results = self.model_results\n+        else:\n+            target_results = self.additional_results[job_to_test_map[job_name]]\n+\n+        # Make the format uniform between `model_results` and `additional_results[XXX]`\n+        if \"failures\" in target_results:\n+            target_results = {job_name: target_results}\n+        sorted_dict = sorted(target_results.items(), key=lambda t: t[0])\n \n+        job = job_to_test_map[job_name]\n         prev_model_results = {}\n         if (\n             f\"ci_results_{job_name}\" in prev_ci_artifacts\n-            and \"model_results.json\" in prev_ci_artifacts[f\"ci_results_{job_name}\"]\n+            and f\"{test_to_result_name[job]}_results.json\" in prev_ci_artifacts[f\"ci_results_{job_name}\"]\n         ):\n-            prev_model_results = json.loads(prev_ci_artifacts[f\"ci_results_{job_name}\"][\"model_results.json\"])\n+            prev_model_results = json.loads(\n+                prev_ci_artifacts[f\"ci_results_{job_name}\"][f\"{test_to_result_name[job]}_results.json\"]\n+            )\n+            # Make the format uniform between `model_results` and `additional_results[XXX]`\n+            if \"failures\" in prev_model_results:\n+                prev_model_results = {job_name: prev_model_results}\n \n         all_failure_lines = {}\n         for job, job_result in sorted_dict:\n@@ -751,7 +793,7 @@ def get_new_model_failure_blocks(self, prev_ci_artifacts, with_header=True, to_t\n \n                         all_failure_lines[new_text].append(f\"<{url}|{device}>\" if url is not None else device)\n \n-        MAX_ERROR_TEXT = 3000 - len(\"[Truncated]\") - len(\"```New model failures```\\n\\n\")\n+        MAX_ERROR_TEXT = 3000 - len(\"[Truncated]\") - len(\"```New failures```\\n\\n\")\n         if not to_truncate:\n             MAX_ERROR_TEXT = float(\"inf\")\n         failure_text = \"\"\n@@ -768,10 +810,10 @@ def get_new_model_failure_blocks(self, prev_ci_artifacts, with_header=True, to_t\n         if failure_text:\n             if with_header:\n                 blocks.append(\n-                    {\"type\": \"header\", \"text\": {\"type\": \"plain_text\", \"text\": \"New model failures\", \"emoji\": True}}\n+                    {\"type\": \"header\", \"text\": {\"type\": \"plain_text\", \"text\": \"New failures\", \"emoji\": True}}\n                 )\n             else:\n-                failure_text = f\"*New model failures*\\n\\n{failure_text}\"\n+                failure_text = f\"{failure_text}\"\n             blocks.append({\"type\": \"section\", \"text\": {\"type\": \"mrkdwn\", \"text\": failure_text}})\n \n         return blocks\n@@ -927,6 +969,9 @@ def pop_default(l: list[Any], i: int, default: Any) -> Any:\n \n \n if __name__ == \"__main__\":\n+    api = HfApi()\n+    client = WebClient(token=os.environ[\"CI_SLACK_BOT_TOKEN\"])\n+\n     SLACK_REPORT_CHANNEL_ID = os.environ[\"SLACK_REPORT_CHANNEL\"]\n \n     # runner_status = os.environ.get(\"RUNNER_STATUS\")\n@@ -1157,15 +1202,7 @@ def pop_default(l: list[Any], i: int, default: Any) -> Any:\n     elif ci_event.startswith(\"Push CI (AMD)\"):\n         additional_files = {}\n \n-    # A map associating the job names (specified by `inputs.job` in a workflow file) with the keys of\n-    # `additional_files`. This is used to remove some entries in `additional_files` that are not concerned by a\n-    # specific job. See below.\n-    job_to_test_map = {\n-        \"run_pipelines_torch_gpu\": \"PyTorch pipelines\",\n-        \"run_pipelines_tf_gpu\": \"TensorFlow pipelines\",\n-        \"run_examples_gpu\": \"Examples directory\",\n-        \"run_torch_cuda_extensions_gpu\": \"DeepSpeed\",\n-    }\n+    report_repo_id = os.getenv(\"REPORT_REPO_ID\")\n \n     # if it is not a scheduled run, upload the reports to a subfolder under `report_repo_folder`\n     report_repo_subfolder = \"\"\n@@ -1258,81 +1295,100 @@ def pop_default(l: list[Any], i: int, default: Any) -> Any:\n         os.makedirs(os.path.join(os.getcwd(), f\"ci_results_{job_name}\"))\n \n     nvidia_daily_ci_workflow = \"huggingface/transformers/.github/workflows/self-scheduled-caller.yml\"\n+    amd_daily_ci_workflows = (\n+        \"huggingface/transformers/.github/workflows/self-scheduled-amd-mi210-caller.yml\",\n+        \"huggingface/transformers/.github/workflows/self-scheduled-amd-mi250-caller.yml\",\n+    )\n     is_nvidia_daily_ci_workflow = os.environ.get(\"GITHUB_WORKFLOW_REF\").startswith(nvidia_daily_ci_workflow)\n-    is_scheduled_ci_run = os.environ.get(\"GITHUB_EVENT_NAME\") == \"schedule\"\n-\n-    # Only the model testing job is concerned: this condition is to avoid other jobs to upload the empty list as\n-    # results.\n-    if job_name == \"run_models_gpu\":\n-        with open(f\"ci_results_{job_name}/model_results.json\", \"w\", encoding=\"UTF-8\") as fp:\n-            json.dump(model_results, fp, indent=4, ensure_ascii=False)\n+    is_amd_daily_ci_workflow = os.environ.get(\"GITHUB_WORKFLOW_REF\").startswith(amd_daily_ci_workflows)\n \n-        api.upload_file(\n-            path_or_fileobj=f\"ci_results_{job_name}/model_results.json\",\n-            path_in_repo=f\"{report_repo_folder}/ci_results_{job_name}/model_results.json\",\n-            repo_id=\"hf-internal-testing/transformers_daily_ci\",\n-            repo_type=\"dataset\",\n-            token=os.environ.get(\"TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN\", None),\n-        )\n-\n-        # Let's create a file contain job --> job link\n-        model_job_links = {}\n-        sorted_dict = sorted(model_results.items(), key=lambda t: t[0])\n-        for job, job_result in sorted_dict:\n-            model_name = job\n-            if model_name.startswith(\"models_\"):\n-                model_name = model_name[len(\"models_\") :]\n-            model_job_links[model_name] = job_result[\"job_link\"]\n-\n-        with open(f\"ci_results_{job_name}/model_job_links.json\", \"w\", encoding=\"UTF-8\") as fp:\n-            json.dump(model_job_links, fp, indent=4, ensure_ascii=False)\n-\n-        api.upload_file(\n-            path_or_fileobj=f\"ci_results_{job_name}/model_job_links.json\",\n-            path_in_repo=f\"{report_repo_folder}/ci_results_{job_name}/model_job_links.json\",\n-            repo_id=\"hf-internal-testing/transformers_daily_ci\",\n-            repo_type=\"dataset\",\n-            token=os.environ.get(\"TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN\", None),\n-        )\n+    is_scheduled_ci_run = os.environ.get(\"GITHUB_EVENT_NAME\") == \"schedule\"\n+    # For AMD workflow runs: the different AMD CI callers (MI210/MI250/MI300, etc.) are triggered by `workflow_run`\n+    #  event of `.github/workflows/self-scheduled-amd-caller.yml`.\n+    if is_amd_daily_ci_workflow:\n+        # Get the path to the file on the runner that contains the full event webhook payload.\n+        event_payload_path = os.environ.get(\"GITHUB_EVENT_PATH\")\n+        # Load the event payload\n+        with open(event_payload_path) as fp:\n+            event_payload = json.load(fp)\n+            # The event that triggers the `workflow_run` event.\n+            if \"workflow_run\" in event_payload:\n+                is_scheduled_ci_run = event_payload[\"event\"] == \"schedule\"\n \n-    # Must have the same keys as in `additional_results`.\n     # The values are used as the file names where to save the corresponding CI job results.\n     test_to_result_name = {\n+        \"Models\": \"model\",\n+        \"Trainer & FSDP\": \"trainer_and_fsdp\",\n         \"PyTorch pipelines\": \"torch_pipeline\",\n         \"TensorFlow pipelines\": \"tf_pipeline\",\n         \"Examples directory\": \"example\",\n         \"DeepSpeed\": \"deepspeed\",\n     }\n-    for job, job_result in additional_results.items():\n-        with open(f\"ci_results_{job_name}/{test_to_result_name[job]}_results.json\", \"w\", encoding=\"UTF-8\") as fp:\n-            json.dump(job_result, fp, indent=4, ensure_ascii=False)\n+\n+    test_name_and_result_pairs = []\n+    if len(model_results) > 0:\n+        test_name = job_to_test_map[job_name]\n+        test_name_and_result_pairs.append((test_name, model_results))\n+\n+    for test_name, result in additional_results.items():\n+        test_name_and_result_pairs.append((test_name, result))\n+\n+    for test_name, result in test_name_and_result_pairs:\n+        with open(f\"ci_results_{job_name}/{test_to_result_name[test_name]}_results.json\", \"w\", encoding=\"UTF-8\") as fp:\n+            json.dump(result, fp, indent=4, ensure_ascii=False)\n \n         api.upload_file(\n-            path_or_fileobj=f\"ci_results_{job_name}/{test_to_result_name[job]}_results.json\",\n-            path_in_repo=f\"{report_repo_folder}/ci_results_{job_name}/{test_to_result_name[job]}_results.json\",\n-            repo_id=\"hf-internal-testing/transformers_daily_ci\",\n+            path_or_fileobj=f\"ci_results_{job_name}/{test_to_result_name[test_name]}_results.json\",\n+            path_in_repo=f\"{report_repo_folder}/ci_results_{job_name}/{test_to_result_name[test_name]}_results.json\",\n+            repo_id=report_repo_id,\n             repo_type=\"dataset\",\n             token=os.environ.get(\"TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN\", None),\n         )\n \n+    # Let's create a file contain job --> job link\n+    if len(model_results) > 0:\n+        target_results = model_results\n+    else:\n+        target_results = additional_results[job_to_test_map[job_name]]\n+\n+    # Make the format uniform between `model_results` and `additional_results[XXX]`\n+    if \"failures\" in target_results:\n+        target_results = {job_name: target_results}\n+\n+    job_links = {}\n+    sorted_dict = sorted(target_results.items(), key=lambda t: t[0])\n+    for job, job_result in sorted_dict:\n+        if job.startswith(\"models_\"):\n+            job = job[len(\"models_\") :]\n+        job_links[job] = job_result[\"job_link\"]\n+\n+    with open(f\"ci_results_{job_name}/job_links.json\", \"w\", encoding=\"UTF-8\") as fp:\n+        json.dump(job_links, fp, indent=4, ensure_ascii=False)\n+\n+    api.upload_file(\n+        path_or_fileobj=f\"ci_results_{job_name}/job_links.json\",\n+        path_in_repo=f\"{report_repo_folder}/ci_results_{job_name}/job_links.json\",\n+        repo_id=report_repo_id,\n+        repo_type=\"dataset\",\n+        token=os.environ.get(\"TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN\", None),\n+    )\n+\n     prev_workflow_run_id = None\n     other_workflow_run_ids = []\n \n     if is_scheduled_ci_run:\n-        # TODO: remove `if job_name == \"run_models_gpu\"`\n-        if job_name == \"run_models_gpu\":\n-            prev_workflow_run_id = get_last_daily_ci_workflow_run_id(\n-                token=os.environ[\"ACCESS_REPO_INFO_TOKEN\"], workflow_id=workflow_id\n+        prev_workflow_run_id = get_last_daily_ci_workflow_run_id(\n+            token=os.environ[\"ACCESS_REPO_INFO_TOKEN\"], workflow_id=workflow_id\n+        )\n+        # For a scheduled run that is not the Nvidia's scheduled daily CI, add Nvidia's scheduled daily CI run as a target to compare.\n+        if not is_nvidia_daily_ci_workflow:\n+            # The id of the workflow `.github/workflows/self-scheduled-caller.yml` (not of a workflow run of it).\n+            other_workflow_id = \"90575235\"\n+            # We need to get the Nvidia's scheduled daily CI run that match the current run (i.e. run with the same commit SHA)\n+            other_workflow_run_id = get_last_daily_ci_workflow_run_id(\n+                token=os.environ[\"ACCESS_REPO_INFO_TOKEN\"], workflow_id=other_workflow_id, commit_sha=ci_sha\n             )\n-            # For a scheduled run that is not the Nvidia's scheduled daily CI, add Nvidia's scheduled daily CI run as a target to compare.\n-            if not is_nvidia_daily_ci_workflow:\n-                # The id of the workflow `.github/workflows/self-scheduled-caller.yml` (not of a workflow run of it).\n-                other_workflow_id = \"90575235\"\n-                # We need to get the Nvidia's scheduled daily CI run that match the current run (i.e. run with the same commit SHA)\n-                other_workflow_run_id = get_last_daily_ci_workflow_run_id(\n-                    token=os.environ[\"ACCESS_REPO_INFO_TOKEN\"], workflow_id=other_workflow_id, commit_sha=ci_sha\n-                )\n-                other_workflow_run_ids.append(other_workflow_run_id)\n+            other_workflow_run_ids.append(other_workflow_run_id)\n     else:\n         prev_workflow_run_id = os.environ[\"PREV_WORKFLOW_RUN_ID\"]\n         other_workflow_run_id = os.environ[\"OTHER_WORKFLOW_RUN_ID\"]\n@@ -1359,13 +1415,6 @@ def pop_default(l: list[Any], i: int, default: Any) -> Any:\n             else:\n                 other_ci_artifacts.append((target_workflow_run_id, ci_artifacts))\n \n-    job_to_test_map.update(\n-        {\n-            \"run_models_gpu\": \"Models\",\n-            \"run_trainer_and_fsdp_gpu\": \"Trainer & FSDP\",\n-        }\n-    )\n-\n     ci_name_in_report = \"\"\n     if job_name in job_to_test_map:\n         ci_name_in_report = job_to_test_map[job_name]"
        },
        {
            "sha": "b533a7a9cf1eb5db24b4266281e51092f548838d",
            "filename": "utils/notification_service_quantization.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/utils%2Fnotification_service_quantization.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/utils%2Fnotification_service_quantization.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fnotification_service_quantization.py?ref=d0c9c66d1c09df3cd70bf036e813d88337b20d4c",
            "patch": "@@ -274,11 +274,13 @@ def post_reply(self):\n     with open(f\"ci_results_{job_name}/quantization_results.json\", \"w\", encoding=\"UTF-8\") as fp:\n         json.dump(quantization_results, fp, indent=4, ensure_ascii=False)\n \n+    report_repo_id = os.getenv(\"REPORT_REPO_ID\")\n+\n     # upload results to Hub dataset (only for the scheduled daily CI run on `main`)\n     api.upload_file(\n         path_or_fileobj=f\"ci_results_{job_name}/quantization_results.json\",\n         path_in_repo=f\"{report_repo_folder}/ci_results_{job_name}/quantization_results.json\",\n-        repo_id=\"hf-internal-testing/transformers_daily_ci\",\n+        repo_id=report_repo_id,\n         repo_type=\"dataset\",\n         token=os.environ.get(\"TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN\", None),\n     )"
        },
        {
            "sha": "432291faec235c56283b92bda26089ce3990a7ea",
            "filename": "utils/process_bad_commit_report.py",
            "status": "modified",
            "additions": 18,
            "deletions": 10,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/utils%2Fprocess_bad_commit_report.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0c9c66d1c09df3cd70bf036e813d88337b20d4c/utils%2Fprocess_bad_commit_report.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fprocess_bad_commit_report.py?ref=d0c9c66d1c09df3cd70bf036e813d88337b20d4c",
            "patch": "@@ -1,4 +1,4 @@\n-\"\"\"An internal script to process `new_model_failures_with_bad_commit.json` produced by `utils/check_bad_commit.py`.\n+\"\"\"An internal script to process `new_failures_with_bad_commit.json` produced by `utils/check_bad_commit.py`.\n \n This is used by `.github/workflows/check_failed_model_tests.yml` to produce a slack report of the following form\n \n@@ -24,11 +24,13 @@\n if __name__ == \"__main__\":\n     api = HfApi()\n \n-    with open(\"new_model_failures_with_bad_commit.json\") as fp:\n+    job_name = os.environ.get(\"JOB_NAME\")\n+\n+    with open(\"new_failures_with_bad_commit.json\") as fp:\n         data = json.load(fp)\n \n-    with open(\"ci_results_run_models_gpu/model_job_links.json\") as fp:\n-        model_job_links = json.load(fp)\n+    with open(f\"ci_results_{job_name}/job_links.json\") as fp:\n+        job_links = json.load(fp)\n \n     # TODO: extend\n     team_members = [\n@@ -67,7 +69,11 @@\n             for device, failed_tests in model_result.items():\n                 # prepare job_link and add it to each entry of new failed test information.\n                 # need to change from `single-gpu` to `single` and same for `multi-gpu` to match `job_link`.\n-                job_link = model_job_links[model][device.replace(\"-gpu\", \"\")]\n+                key = model\n+                if list(job_links.keys()) == [job_name]:\n+                    key = job_name\n+                job_link = job_links[key][device.replace(\"-gpu\", \"\")]\n+\n                 failed_tests = [x for x in failed_tests if x[\"author\"] == author or x[\"merged_by\"] == author]\n                 for x in failed_tests:\n                     x.update({\"job_link\": job_link})\n@@ -92,16 +98,18 @@\n     if report_repo_subfolder:\n         report_repo_folder = f\"{report_repo_folder}/{report_repo_subfolder}\"\n \n-    with open(\"new_model_failures_with_bad_commit_grouped_by_authors.json\", \"w\") as fp:\n+    report_repo_id = os.getenv(\"REPORT_REPO_ID\")\n+\n+    with open(\"new_failures_with_bad_commit_grouped_by_authors.json\", \"w\") as fp:\n         json.dump(new_data_full, fp, ensure_ascii=False, indent=4)\n     commit_info = api.upload_file(\n-        path_or_fileobj=\"new_model_failures_with_bad_commit_grouped_by_authors.json\",\n-        path_in_repo=f\"{report_repo_folder}/ci_results_run_models_gpu/new_model_failures_with_bad_commit_grouped_by_authors.json\",\n-        repo_id=\"hf-internal-testing/transformers_daily_ci\",\n+        path_or_fileobj=\"new_failures_with_bad_commit_grouped_by_authors.json\",\n+        path_in_repo=f\"{report_repo_folder}/ci_results_{job_name}/new_failures_with_bad_commit_grouped_by_authors.json\",\n+        repo_id=report_repo_id,\n         repo_type=\"dataset\",\n         token=os.environ.get(\"TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN\", None),\n     )\n-    url = f\"https://huggingface.co/datasets/hf-internal-testing/transformers_daily_ci/raw/{commit_info.oid}/{report_repo_folder}/ci_results_run_models_gpu/new_model_failures_with_bad_commit_grouped_by_authors.json\"\n+    url = f\"https://huggingface.co/datasets/{report_repo_id}/raw/{commit_info.oid}/{report_repo_folder}/ci_results_{job_name}/new_failures_with_bad_commit_grouped_by_authors.json\"\n \n     # Add `GH_` prefix as keyword mention\n     output = {}"
        }
    ],
    "stats": {
        "total": 369,
        "additions": 248,
        "deletions": 121
    }
}