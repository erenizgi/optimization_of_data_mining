{
    "author": "JINO-ROHIT",
    "message": "fixed typo for docstring in prepare_inputs method (#39071)",
    "sha": "993665a5ffc9bb985c2adb1a51b94d8bad9b040a",
    "files": [
        {
            "sha": "bb15454c7f5ba33e70aaca961a0e138a94fc7e15",
            "filename": "src/transformers/generation/utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/993665a5ffc9bb985c2adb1a51b94d8bad9b040a/src%2Ftransformers%2Fgeneration%2Futils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/993665a5ffc9bb985c2adb1a51b94d8bad9b040a/src%2Ftransformers%2Fgeneration%2Futils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Futils.py?ref=993665a5ffc9bb985c2adb1a51b94d8bad9b040a",
            "patch": "@@ -558,7 +558,7 @@ def prepare_inputs_for_generation(\n         **kwargs,\n     ):\n         \"\"\"\n-        Prepare the model inputs for generation. In includes operations like computing the 4D attention mask or\n+        Prepare the model inputs for generation. It includes operations like computing the 4D attention mask or\n         slicing inputs given the existing cache.\n \n         See the forward pass in the model documentation for expected arguments (different models might have different"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}