{
    "author": "gante",
    "message": "[image-text-to-text pipeline] Accept a chat as a positional arg (#38204)\n\naccept chat as a positional arg",
    "sha": "6f9da7649f2b23b22543424140ce2421fccff8af",
    "files": [
        {
            "sha": "9723b139364ff77b7ee5ff931fbeb908c501a9d5",
            "filename": "src/transformers/pipelines/image_text_to_text.py",
            "status": "modified",
            "additions": 50,
            "deletions": 24,
            "changes": 74,
            "blob_url": "https://github.com/huggingface/transformers/blob/6f9da7649f2b23b22543424140ce2421fccff8af/src%2Ftransformers%2Fpipelines%2Fimage_text_to_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6f9da7649f2b23b22543424140ce2421fccff8af/src%2Ftransformers%2Fpipelines%2Fimage_text_to_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fimage_text_to_text.py?ref=6f9da7649f2b23b22543424140ce2421fccff8af",
            "patch": "@@ -54,7 +54,9 @@ class Chat:\n     to this format because the rest of the pipeline code tends to assume that lists of messages are\n     actually a batch of samples rather than messages in the same conversation.\"\"\"\n \n-    def __init__(self, messages: Dict, images: Union[str, List[str], \"Image.Image\", List[\"Image.Image\"]]):\n+    def __init__(\n+        self, messages: Dict, images: Optional[Union[str, List[str], \"Image.Image\", List[\"Image.Image\"]]] = None\n+    ):\n         for message in messages:\n             if not (\"role\" in message and \"content\" in message):\n                 raise ValueError(\"When passing chat dicts as input, each dict must have a 'role' and 'content' key.\")\n@@ -241,7 +243,15 @@ def _sanitize_parameters(\n     def __call__(\n         self,\n         images: Optional[\n-            Union[str, List[str], List[List[str]], \"Image.Image\", List[\"Image.Image\"], List[List[\"Image.Image\"]]]\n+            Union[\n+                str,\n+                List[str],\n+                List[List[str]],\n+                \"Image.Image\",\n+                List[\"Image.Image\"],\n+                List[List[\"Image.Image\"]],\n+                List[dict],\n+            ]\n         ] = None,\n         text: Optional[Union[str, List[str], List[dict]]] = None,\n         **kwargs,\n@@ -250,21 +260,22 @@ def __call__(\n         Generate a text given text and the image(s) passed as inputs.\n \n         Args:\n-            images (`str`, `List[str]`, `PIL.Image or `List[PIL.Image]`):\n+            images (`str`, `List[str]`, `PIL.Image, `List[PIL.Image]`, `List[Dict[str, Union[str, PIL.Image]]]`):\n                 The pipeline handles three types of images:\n \n                 - A string containing a HTTP(s) link pointing to an image\n                 - A string containing a local path to an image\n                 - An image loaded in PIL directly\n \n-                The pipeline accepts either a single image or a batch of images.\n+                The pipeline accepts either a single image or a batch of images. Finally, this pipeline also supports\n+                the chat format (see `text`) containing images and text in this argument.\n             text (str, List[str], `List[Dict[str, Union[str, PIL.Image]]]`):\n-                The text to be used for generation. If a list of strings is passed, the length of the list should be the\n-                same as the number of images. Text can also follow the chat format: a list of dictionaries where each\n-                dictionary represents a message in a conversation. Each dictionary should have two keys: 'role' and\n-                'content'. 'role' should be one of 'user', 'system' or 'assistant'. 'content' should be a list of dictionary\n-                containing the text of the message and the type of the message. The type of the message can be either\n-                'text' or 'image'. If the type is 'image', no text is needed.\n+                The text to be used for generation. If a list of strings is passed, the length of the list should be\n+                the same as the number of images. Text can also follow the chat format: a list of dictionaries where\n+                each dictionary represents a message in a conversation. Each dictionary should have two keys: 'role'\n+                and 'content'. 'role' should be one of 'user', 'system' or 'assistant'. 'content' should be a list of\n+                dictionary containing the text of the message and the type of the message. The type of the message\n+                can be either 'text' or 'image'. If the type is 'image', no text is needed.\n             return_tensors (`bool`, *optional*, defaults to `False`):\n                 Returns the tensors of predictions (as token indices) in the outputs. If set to\n                 `True`, the decoded text is not returned.\n@@ -281,8 +292,8 @@ def __call__(\n                 `False` otherwise, but you can manually override that behaviour by setting this flag.\n \n         Return:\n-            A list or a list of list of `dict`: Each result comes as a dictionary with the following key (cannot return a combination\n-            of both `generated_text` and `generated_token_ids`):\n+            A list or a list of list of `dict`: Each result comes as a dictionary with the following key (cannot\n+            return a combination of both `generated_text` and `generated_token_ids`):\n \n             - **generated_text** (`str`, present when `return_text=True`) -- The generated text.\n             - **generated_token_ids** (`torch.Tensor`, present when `return_tensors=True`) -- The token\n@@ -291,17 +302,11 @@ def __call__(\n         \"\"\"\n         if images is None and text is None:\n             raise ValueError(\"You must at least provide either text or images.\")\n-        if images is not None and text is None and not valid_images(images):\n-            \"\"\"\n-            Supports the following format\n-            - {\"image\": image, \"text\": text}\n-            - [{\"image\": image, \"text\": text}]\n-            - Generator and datasets\n-            This is a common pattern in other multimodal pipelines, so we support it here as well.\n-            \"\"\"\n-            return super().__call__(images, **kwargs)\n \n-        if isinstance(text, (list, tuple, KeyDataset)) and isinstance(text[0], (list, tuple, dict)):\n+        def _is_chat(arg):\n+            return isinstance(arg, (list, tuple, KeyDataset)) and isinstance(arg[0], (list, tuple, dict))\n+\n+        if _is_chat(text):\n             # We have one or more prompts in list-of-dicts format, so this is chat mode\n             if isinstance(text[0], dict):\n                 return super().__call__(Chat(text, images), **kwargs)\n@@ -311,11 +316,32 @@ def __call__(\n                 chats = [Chat(chat, image) for chat, image in zip(text, images)]  # üêà üêà üêà\n                 return super().__call__(chats, **kwargs)\n \n+        # Same as above, but the `images` argument contains the chat. This can happen e.g. is the user only passes a\n+        # chat as a positional argument.\n+        elif text is None and _is_chat(images):\n+            # We have one or more prompts in list-of-dicts format, so this is chat mode\n+            if isinstance(images[0], dict):\n+                return super().__call__(Chat(images), **kwargs)\n+            else:\n+                chats = [Chat(image) for image in images]  # üêà üêà üêà\n+                return super().__call__(chats, **kwargs)\n+\n+        elif images is not None and text is None and not valid_images(images):\n+            \"\"\"\n+            Supports the following format\n+            - {\"image\": image, \"text\": text}\n+            - [{\"image\": image, \"text\": text}]\n+            - Generator and datasets\n+            This is a common pattern in other multimodal pipelines, so we support it here as well.\n+            \"\"\"\n+            return super().__call__(images, **kwargs)\n+\n         # encourage the user to use the chat format if supported\n         if getattr(self.processor, \"chat_template\", None) is not None:\n             logger.warning_once(\n-                \"The input data was not formatted as a chat with dicts containing 'role' and 'content' keys, even though this model supports chat. \"\n-                \"Consider using the chat format for better results. For more information, see https://huggingface.co/docs/transformers/en/chat_templating\"\n+                \"The input data was not formatted as a chat with dicts containing 'role' and 'content' keys, even \"\n+                \"though this model supports chat. Consider using the chat format for better results. For more \"\n+                \"information, see https://huggingface.co/docs/transformers/en/chat_templating\"\n             )\n \n         # support text only generation"
        }
    ],
    "stats": {
        "total": 74,
        "additions": 50,
        "deletions": 24
    }
}