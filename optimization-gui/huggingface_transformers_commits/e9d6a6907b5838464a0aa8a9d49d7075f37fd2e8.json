{
    "author": "gante",
    "message": "[tests] remove overwrites of removed test (#40720)\n\nrm tests from method moved to hub",
    "sha": "e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8",
    "files": [
        {
            "sha": "9ed521509408b95af8a0f55f871b874bd925cb81",
            "filename": "tests/models/deepseek_v3/test_modeling_deepseek_v3.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fdeepseek_v3%2Ftest_modeling_deepseek_v3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fdeepseek_v3%2Ftest_modeling_deepseek_v3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdeepseek_v3%2Ftest_modeling_deepseek_v3.py?ref=e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8",
            "patch": "@@ -263,10 +263,6 @@ def test_prompt_lookup_decoding_matches_greedy_search(self, assistant_type):\n     def test_assisted_decoding_sample(self):\n         pass\n \n-    @unittest.skip(\"DeepseekV3 doesn't support contrastive generation\")\n-    def test_contrastive_generate_dict_outputs_use_cache(self):\n-        pass\n-\n     @unittest.skip(\"Deepseek-V3 uses MLA so it is not compatible with the standard cache format\")\n     def test_beam_search_generate_dict_outputs_use_cache(self):\n         pass"
        },
        {
            "sha": "fe6dfb05edd5bd960054668ee3ff7fa308be8eaa",
            "filename": "tests/models/gemma3n/test_modeling_gemma3n.py",
            "status": "modified",
            "additions": 0,
            "deletions": 21,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fgemma3n%2Ftest_modeling_gemma3n.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fgemma3n%2Ftest_modeling_gemma3n.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgemma3n%2Ftest_modeling_gemma3n.py?ref=e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8",
            "patch": "@@ -405,27 +405,6 @@ def test_eager_matches_sdpa_inference(\n             self, name, dtype, padding_side, use_attention_mask, output_attentions, enable_kernels, atols=atols\n         )\n \n-    @pytest.mark.generate\n-    @unittest.skip(\n-        \"Gemma3n has a special shape for hidden states (due to per-layer projs) which is not compatible with contrastive decoding\"\n-    )\n-    def test_contrastive_generate(self):\n-        pass\n-\n-    @pytest.mark.generate\n-    @unittest.skip(\n-        \"Gemma3n has a special shape for hidden states (due to per-layer projs) which is not compatible with contrastive decoding\"\n-    )\n-    def test_contrastive_generate_dict_outputs_use_cache(self):\n-        pass\n-\n-    @pytest.mark.generate\n-    @unittest.skip(\n-        \"Gemma3n has a special shape for hidden states (due to per-layer projs) which is not compatible with contrastive decoding\"\n-    )\n-    def test_contrastive_generate_low_memory(self):\n-        pass\n-\n     @pytest.mark.generate\n     @unittest.skip(\"Gemma3n does not support QuantizedCache as it performs cache manipulation in the forward pass\")\n     def test_generate_with_quant_cache(self):"
        },
        {
            "sha": "931b3fcc8f07fdf18927fcc8b9d026c0452f0a2c",
            "filename": "tests/models/git/test_modeling_git.py",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fgit%2Ftest_modeling_git.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fgit%2Ftest_modeling_git.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgit%2Ftest_modeling_git.py?ref=e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8",
            "patch": "@@ -455,18 +455,6 @@ def test_model_from_pretrained(self):\n     def test_beam_search_generate_dict_outputs_use_cache(self):\n         pass\n \n-    @unittest.skip(reason=\"GIT has pixel values as additional input\")\n-    def test_contrastive_generate(self):\n-        pass\n-\n-    @unittest.skip(reason=\"GIT has pixel values as additional input\")\n-    def test_contrastive_generate_dict_outputs_use_cache(self):\n-        pass\n-\n-    @unittest.skip(reason=\"GIT has pixel values as additional input\")\n-    def test_contrastive_generate_low_memory(self):\n-        pass\n-\n     @unittest.skip(reason=\"GIT has pixel values as additional input\")\n     def test_greedy_generate_dict_outputs_use_cache(self):\n         pass"
        },
        {
            "sha": "33ba384511c219cbd9dd02551b35f3062b7ea03a",
            "filename": "tests/models/idefics/test_modeling_idefics.py",
            "status": "modified",
            "additions": 0,
            "deletions": 15,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fidefics%2Ftest_modeling_idefics.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fidefics%2Ftest_modeling_idefics.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fidefics%2Ftest_modeling_idefics.py?ref=e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8",
            "patch": "@@ -496,21 +496,6 @@ def test_generate_without_input_ids(self):\n     def test_generate_continue_from_inputs_embeds(self):\n         pass\n \n-    @pytest.mark.generate\n-    @unittest.skip(reason=\"\"\"IDEFICS cannot do contrastive generation yet and it is not worth fixing\"\"\")\n-    def test_contrastive_generate(self):\n-        pass\n-\n-    @pytest.mark.generate\n-    @unittest.skip(reason=\"\"\"IDEFICS cannot do contrastive generation yet and it is not worth fixing\"\"\")\n-    def test_contrastive_generate_low_memory(self):\n-        pass\n-\n-    @pytest.mark.generate\n-    @unittest.skip(reason=\"\"\"IDEFICS cannot do contrastive generation yet and it is not worth fixing\"\"\")\n-    def test_contrastive_generate_dict_outputs_use_cache(self):\n-        pass\n-\n     def test_attention_outputs(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n         config.return_dict = True"
        },
        {
            "sha": "00b76b0e389ba4204edf563fb8cde2a61133abc3",
            "filename": "tests/models/minimax/test_modeling_minimax.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fminimax%2Ftest_modeling_minimax.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fminimax%2Ftest_modeling_minimax.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fminimax%2Ftest_modeling_minimax.py?ref=e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8",
            "patch": "@@ -209,10 +209,6 @@ def test_past_key_values_format(self, custom_all_cache_shapes=None):\n     def test_prompt_lookup_decoding_matches_greedy_search(self):\n         pass\n \n-    @unittest.skip(reason=\"MiniMaxCache does not support `crop()` method\")\n-    def test_contrastive_generate_low_memory(self):\n-        pass\n-\n     @unittest.skip(reason=\"MiniMaxCache does not support `crop()` method\")\n     def test_assisted_decoding_sample(self):\n         pass\n@@ -225,10 +221,6 @@ def test_assisted_decoding_matches_greedy_search_0_random(self):\n     def test_assisted_decoding_matches_greedy_search_1_same(self):\n         pass\n \n-    @unittest.skip(reason=\"MiniMaxCache does not support `crop()` method\")\n-    def test_contrastive_generate_dict_outputs_use_cache(self):\n-        pass\n-\n     @unittest.skip(\"Model needs refactor\")\n     def test_attention_outputs(self):\n         pass"
        },
        {
            "sha": "ca5579ecb058fccbc3bc59ec84a8bc24dc680585",
            "filename": "tests/models/mllama/test_modeling_mllama.py",
            "status": "modified",
            "additions": 0,
            "deletions": 10,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fmllama%2Ftest_modeling_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fmllama%2Ftest_modeling_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmllama%2Ftest_modeling_mllama.py?ref=e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8",
            "patch": "@@ -368,16 +368,6 @@ def test_sdpa_can_compile_dynamic(self):\n     def test_model_parallelism(self):\n         pass\n \n-    @unittest.skip(\n-        reason=\"Mllama cache type doesn't allow correct check on output `past_key_values` due to `Cache.crop()`\"\n-    )\n-    def test_contrastive_generate_dict_outputs_use_cache(self, assistant_type):\n-        pass\n-\n-    @unittest.skip(reason=\"Mllama can't do low memory due to `Cache.crop()`\")\n-    def test_contrastive_generate_low_memory(self, assistant_type):\n-        pass\n-\n     @unittest.skip(reason=\"Mllama can't assisted decoding due to cache format and `Cache.crop()`\")\n     def test_assisted_decoding_with_num_logits_to_keep(self):\n         pass"
        },
        {
            "sha": "b6a84850311718ee25b407b99585f86623ee3546",
            "filename": "tests/models/moshi/test_modeling_moshi.py",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fmoshi%2Ftest_modeling_moshi.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fmoshi%2Ftest_modeling_moshi.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmoshi%2Ftest_modeling_moshi.py?ref=e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8",
            "patch": "@@ -603,18 +603,6 @@ def test_initialization(self):\n     def test_generate_continue_from_past_key_values(self):\n         pass\n \n-    @unittest.skip(\"Moshi doesn't support contrastive generation yet.\")\n-    def test_contrastive_generate(self):\n-        pass\n-\n-    @unittest.skip(\"Moshi doesn't support contrastive generation yet.\")\n-    def test_contrastive_generate_dict_outputs_use_cache(self):\n-        pass\n-\n-    @unittest.skip(\"Moshi doesn't support contrastive generation yet.\")\n-    def test_contrastive_generate_low_memory(self):\n-        pass\n-\n     @unittest.skip(\n         \"Moshi either needs default generation config or fix for fullgraph compile because it hardcodes SlidingWindowCache in custom generation loop.\"\n     )"
        },
        {
            "sha": "32ebdd0ab036dedb9fb8c0f53728700d419b9bd8",
            "filename": "tests/models/qwen2_5_omni/test_modeling_qwen2_5_omni.py",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_modeling_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_modeling_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_modeling_qwen2_5_omni.py?ref=e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8",
            "patch": "@@ -418,18 +418,6 @@ def attention_mask_padding_matches_padding_free_with_position_ids(\n                 tol = torch.finfo(torch.bfloat16).eps\n                 torch.testing.assert_close(logits_padded, logits_padfree, rtol=tol, atol=tol)\n \n-    @unittest.skip(\"Cannot do contrastive generation, has custom `generate()`\")\n-    def test_contrastive_generate(self):\n-        pass\n-\n-    @unittest.skip(\"Cannot do contrastive generation, has custom `generate()`\")\n-    def test_contrastive_generate_dict_outputs_use_cache(self):\n-        pass\n-\n-    @unittest.skip(\"Cannot do contrastive generation, has custom `generate()`\")\n-    def test_contrastive_generate_low_memory(self):\n-        pass\n-\n     @unittest.skip(\"Cannot generate from inputs embeds\")\n     def test_generate_from_inputs_embeds_with_static_cache(self):\n         pass"
        },
        {
            "sha": "29f85455c50e130ff2756658cc669126afc58aeb",
            "filename": "tests/models/recurrent_gemma/test_modeling_recurrent_gemma.py",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Frecurrent_gemma%2Ftest_modeling_recurrent_gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8/tests%2Fmodels%2Frecurrent_gemma%2Ftest_modeling_recurrent_gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Frecurrent_gemma%2Ftest_modeling_recurrent_gemma.py?ref=e9d6a6907b5838464a0aa8a9d49d7075f37fd2e8",
            "patch": "@@ -66,18 +66,6 @@ class RecurrentGemmaModelTest(CausalLMModelTest, unittest.TestCase):\n     def test_eager_matches_sdpa_generate(self):\n         pass\n \n-    @unittest.skip(reason=\"RecurrentGemma does not return the cache\")\n-    def test_contrastive_generate_low_memory(self):\n-        pass\n-\n-    @unittest.skip(reason=\"RecurrentGemma does not return the cache\")\n-    def test_contrastive_generate_dict_outputs_use_cache(self):\n-        pass\n-\n-    @unittest.skip(reason=\"RecurrentGemma does not return the cache\")\n-    def test_contrastive_generate(self):\n-        pass\n-\n     @unittest.skip(reason=\"SQRBound is known to have issues with gc\")\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass"
        }
    ],
    "stats": {
        "total": 106,
        "additions": 0,
        "deletions": 106
    }
}