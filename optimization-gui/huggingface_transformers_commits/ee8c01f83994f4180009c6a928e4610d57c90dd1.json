{
    "author": "Isotr0py",
    "message": "Add chat_template for tokenizer extracted from GGUF model (#32908)\n\n* add chat_template to gguf tokenizer\r\n\r\n* add template through tokenizer config",
    "sha": "ee8c01f83994f4180009c6a928e4610d57c90dd1",
    "files": [
        {
            "sha": "dec3ccd343d49f375041c50c8fde6759e83e0499",
            "filename": "src/transformers/tokenization_utils_fast.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ee8c01f83994f4180009c6a928e4610d57c90dd1/src%2Ftransformers%2Ftokenization_utils_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ee8c01f83994f4180009c6a928e4610d57c90dd1/src%2Ftransformers%2Ftokenization_utils_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_utils_fast.py?ref=ee8c01f83994f4180009c6a928e4610d57c90dd1",
            "patch": "@@ -121,8 +121,10 @@ def __init__(self, *args, **kwargs):\n             gguf_param = load_gguf_checkpoint(kwargs.get(\"vocab_file\"))\n             architecture = gguf_param[\"config\"][\"model_type\"]\n             tokenizer_dict = gguf_param[\"tokenizer\"]\n+            tokenizer_config = gguf_param[\"tokenizer_config\"]\n             fast_tokenizer, additional_kwargs = convert_gguf_tokenizer(architecture, tokenizer_dict)\n \n+            kwargs.update(tokenizer_config)\n             if len(additional_kwargs) > 0:\n                 kwargs.update(additional_kwargs)\n "
        }
    ],
    "stats": {
        "total": 2,
        "additions": 2,
        "deletions": 0
    }
}