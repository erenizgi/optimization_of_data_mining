{
    "author": "remi-or",
    "message": "Fix test_all_tensors_are_parameter_or_buffer (#43111)\n\n* Fix test_all_tensors_are_parameter_or_buffer\n\n* Simplify\n\n* Review compliance",
    "sha": "02ddf5d47abb61730d157ddf3cb75f76715d05f5",
    "files": [
        {
            "sha": "86cbc0d90c0d05156222a5103a97d78d2be93c95",
            "filename": "tests/models/modernbert/test_modeling_modernbert.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/02ddf5d47abb61730d157ddf3cb75f76715d05f5/tests%2Fmodels%2Fmodernbert%2Ftest_modeling_modernbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/02ddf5d47abb61730d157ddf3cb75f76715d05f5/tests%2Fmodels%2Fmodernbert%2Ftest_modeling_modernbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmodernbert%2Ftest_modeling_modernbert.py?ref=02ddf5d47abb61730d157ddf3cb75f76715d05f5",
            "patch": "@@ -27,6 +27,7 @@\n     require_flash_attn,\n     require_torch,\n     require_torch_accelerator,\n+    require_torch_gpu,\n     slow,\n     torch_device,\n )\n@@ -506,6 +507,10 @@ def flash_attn_inference_equivalence(\n                 f\"Model architecture does not support {attn_implementation}, or setting its attention dynamically\"\n             )\n \n+    @require_torch_gpu  # modernbert contains triton code which cannot run on CPU, so we only test on GPU\n+    def test_all_tensors_are_parameter_or_buffer(self):\n+        super().test_all_tensors_are_parameter_or_buffer()\n+\n \n @require_torch\n class ModernBertModelIntegrationTest(unittest.TestCase):"
        },
        {
            "sha": "81ed0b065ec3e59fea48baca80dc7e115719e25a",
            "filename": "tests/models/pe_audio/test_modeling_pe_audio.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/02ddf5d47abb61730d157ddf3cb75f76715d05f5/tests%2Fmodels%2Fpe_audio%2Ftest_modeling_pe_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/02ddf5d47abb61730d157ddf3cb75f76715d05f5/tests%2Fmodels%2Fpe_audio%2Ftest_modeling_pe_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpe_audio%2Ftest_modeling_pe_audio.py?ref=02ddf5d47abb61730d157ddf3cb75f76715d05f5",
            "patch": "@@ -17,6 +17,7 @@\n from transformers.audio_utils import load_audio\n from transformers.testing_utils import (\n     require_torch,\n+    require_torch_gpu,\n     slow,\n     torch_device,\n )\n@@ -330,6 +331,10 @@ def test_batching_equivalence(self):\n     def test_can_init_all_missing_weights(self):\n         pass\n \n+    @require_torch_gpu  # pe-audio contains triton code which cannot run on CPU, so we only test on GPU\n+    def test_all_tensors_are_parameter_or_buffer(self):\n+        super().test_all_tensors_are_parameter_or_buffer()\n+\n \n @require_torch\n class PeAudioIntegrationTest(unittest.TestCase):"
        },
        {
            "sha": "960f12818b56cba8d73d4c13282af7a25ed19832",
            "filename": "tests/models/pe_video/test_modeling_pe_video.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/02ddf5d47abb61730d157ddf3cb75f76715d05f5/tests%2Fmodels%2Fpe_video%2Ftest_modeling_pe_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/02ddf5d47abb61730d157ddf3cb75f76715d05f5/tests%2Fmodels%2Fpe_video%2Ftest_modeling_pe_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpe_video%2Ftest_modeling_pe_video.py?ref=02ddf5d47abb61730d157ddf3cb75f76715d05f5",
            "patch": "@@ -27,6 +27,7 @@\n     floats_tensor,\n     ids_tensor,\n     random_attention_mask,\n+    require_torch_gpu,\n )\n \n \n@@ -362,6 +363,10 @@ def test_batching_equivalence(self):\n     def test_can_init_all_missing_weights(self):\n         pass\n \n+    @require_torch_gpu  # pe-video contains triton code which cannot run on CPU, so we only test on GPU\n+    def test_all_tensors_are_parameter_or_buffer(self):\n+        super().test_all_tensors_are_parameter_or_buffer()\n+\n \n @require_torch\n class PeVideoIntegrationTest(unittest.TestCase):"
        },
        {
            "sha": "4728e40334a6e22471f84407d9ba61274ba212cf",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 7,
            "deletions": 9,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/02ddf5d47abb61730d157ddf3cb75f76715d05f5/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/02ddf5d47abb61730d157ddf3cb75f76715d05f5/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=02ddf5d47abb61730d157ddf3cb75f76715d05f5",
            "patch": "@@ -1286,30 +1286,28 @@ def test_init_weights_can_init_buffers(self):\n                 f\"them correctly if the model is on meta device):\\n{unique_bad_module_traceback}\",\n             )\n \n-    def test_all_tensors_are_parameter_or_buffer(self):\n+    def test_all_tensors_are_parameter_or_buffer(self) -> None:\n         \"\"\"Check that all tensors are registered as Parameter or Buffer, i.e. we don't have simple assignments such\n-        as `self.x = torch.tensor(...)` in a Module (as we cannot correctly recover from meta device if it's not registered as\n-        parameter/buffer)\"\"\"\n+        as `self.x = torch.tensor(...)` in a Module (as we cannot correctly recover from meta device if it's not\n+        registered as parameter/buffer). To test this, we initialize the model on a meta device and then move it onto\n+        the torch_device and perform a forward pass.\"\"\"\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n \n         for model_class in self.all_model_classes:\n             # Apparently this model cannot correctly create its inputs and has to use another function....\n             if \"modeling_perceiver.py\" in inspect.getfile(model_class):\n                 _, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)\n \n-            # Initialize the model fully on meta device, then move everything to cpu and run `init_weights`\n+            # Initialize the model fully on meta device, then move everything to torch_device and run `init_weights`\n             with torch.device(\"meta\"):\n                 model = model_class(copy.deepcopy(config)).eval()\n-            # Move everything randomly to cpu\n-            model.to_empty(device=\"cpu\")\n+            # Move everything randomly to torch_device\n+            model.to_empty(device=torch_device)\n             # Now, run all the inits\n             model.init_weights()\n \n             # Prepare inputs\n             inputs = self._prepare_for_class(inputs_dict, model_class)\n-            # Inputs may be on cuda -> move to cpu, we don't care about accelerator for this test\n-            inputs = {k: v.to(\"cpu\") if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n-\n             # Try running a forward, to see if a tensor stayed on meta somewhere\n             try:\n                 _ = model(**inputs)"
        }
    ],
    "stats": {
        "total": 31,
        "additions": 22,
        "deletions": 9
    }
}