{
    "author": "threewebcode",
    "message": "fix typos in the tests directory (#36932)\n\n* chore: fix typos in test codes\n\n* chore: fix typos in test codes\n\n* chore: fix typos in test codes\n\n* chore: fix typos in test codes\n\n* chore: fix typos in test codes\n\n* chore: fix typos in test codes\n\n* chore: fix typos in test codes\n\n* chore: fix typos in test codes\n\n* chore: format codes",
    "sha": "19085c28dae05ff88027b85cb465b252d934cdcb",
    "files": [
        {
            "sha": "e13e918ba0a9874ffe97131e77fbd1d243aa541d",
            "filename": "tests/models/chameleon/test_modeling_chameleon.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fchameleon%2Ftest_modeling_chameleon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fchameleon%2Ftest_modeling_chameleon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fchameleon%2Ftest_modeling_chameleon.py?ref=19085c28dae05ff88027b85cb465b252d934cdcb",
            "patch": "@@ -130,7 +130,7 @@ def prepare_config_and_inputs(self):\n \n     def get_config(self):\n         # create dummy vocab map for image2bpe mapping if it needs remapping\n-        # we assume that vocab size is big enough to accoun for image tokens somewhere in the beginning\n+        # we assume that vocab size is big enough to account for image tokens somewhere in the beginning\n         # same way as in real ckpt, when img tokens are in first half of embeds\n         # we will need \"vq_num_embeds\" amount of tokens\n "
        },
        {
            "sha": "572efc5de5d675c872c290a19b01c6c9c80bf08b",
            "filename": "tests/models/dab_detr/test_modeling_dab_detr.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fdab_detr%2Ftest_modeling_dab_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fdab_detr%2Ftest_modeling_dab_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdab_detr%2Ftest_modeling_dab_detr.py?ref=19085c28dae05ff88027b85cb465b252d934cdcb",
            "patch": "@@ -699,10 +699,10 @@ def test_different_timm_backbone(self):\n                     self.model_tester.num_labels,\n                 )\n                 self.assertEqual(outputs.logits.shape, expected_shape)\n-                # Confirm out_indices was propogated to backbone\n+                # Confirm out_indices was propagated to backbone\n                 self.assertEqual(len(model.model.backbone.conv_encoder.intermediate_channel_sizes), 3)\n             else:\n-                # Confirm out_indices was propogated to backbone\n+                # Confirm out_indices was propagated to backbone\n                 self.assertEqual(len(model.backbone.conv_encoder.intermediate_channel_sizes), 3)\n \n             self.assertTrue(outputs)\n@@ -726,7 +726,7 @@ def test_initialization(self):\n                             abs(param.data.max().item()),\n                             msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n                         )\n-                    # Modifed from RT-DETR\n+                    # Modified from RT-DETR\n                     elif \"class_embed\" in name and \"bias\" in name:\n                         bias_tensor = torch.full_like(param.data, bias_value)\n                         torch.testing.assert_close("
        },
        {
            "sha": "28787870d8d5700686ec7660cae5c0c9773f5885",
            "filename": "tests/models/granitemoeshared/test_modeling_granitemoeshared.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fgranitemoeshared%2Ftest_modeling_granitemoeshared.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fgranitemoeshared%2Ftest_modeling_granitemoeshared.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgranitemoeshared%2Ftest_modeling_granitemoeshared.py?ref=19085c28dae05ff88027b85cb465b252d934cdcb",
            "patch": "@@ -358,7 +358,9 @@ def test_model_rope_scaling(self):\n         long_input_length = int(config.max_position_embeddings * 1.5)\n \n         # Inputs\n-        x = torch.randn(1, dtype=torch.float32, device=torch_device)  # used exlusively to get the dtype and the device\n+        x = torch.randn(\n+            1, dtype=torch.float32, device=torch_device\n+        )  # used exclusively to get the dtype and the device\n         position_ids_short = torch.arange(short_input_length, dtype=torch.long, device=torch_device)\n         position_ids_short = position_ids_short.unsqueeze(0)\n         position_ids_long = torch.arange(long_input_length, dtype=torch.long, device=torch_device)"
        },
        {
            "sha": "2b591aa04f36d0078607a4cb87106d1dca214fe1",
            "filename": "tests/models/idefics/test_modeling_idefics.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fidefics%2Ftest_modeling_idefics.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fidefics%2Ftest_modeling_idefics.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fidefics%2Ftest_modeling_idefics.py?ref=19085c28dae05ff88027b85cb465b252d934cdcb",
            "patch": "@@ -521,7 +521,7 @@ def test_attention_outputs(self):\n             with torch.no_grad():\n                 outputs = model(**self._prepare_for_class(inputs_dict, model_class))\n             attentions = outputs.attentions\n-            # IDEFICS does not support outputting attention score becuase it uses SDPA under the hood\n+            # IDEFICS does not support outputting attention score because it uses SDPA under the hood\n             self.assertTrue(attentions[0] is None)\n             out_len = len(outputs)\n \n@@ -539,7 +539,7 @@ def test_attention_outputs(self):\n             self_attentions = outputs.encoder_attentions if config.is_encoder_decoder else outputs.attentions\n \n             self.assertEqual(len(self_attentions), self.model_tester.num_hidden_layers)\n-            # IDEFICS does not support outputting attention score becuase it uses SDPA under the hood\n+            # IDEFICS does not support outputting attention score because it uses SDPA under the hood\n             self.assertTrue(self_attentions[0] is None)\n \n     def test_hidden_states_output(self):"
        },
        {
            "sha": "3d2ba3f78c04a8e0404b471a21049964f98d1877",
            "filename": "tests/models/idefics/test_modeling_tf_idefics.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fidefics%2Ftest_modeling_tf_idefics.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fidefics%2Ftest_modeling_tf_idefics.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fidefics%2Ftest_modeling_tf_idefics.py?ref=19085c28dae05ff88027b85cb465b252d934cdcb",
            "patch": "@@ -372,7 +372,7 @@ def test_attention_outputs(self):\n             model = model_class(config)\n             outputs = model(**self._prepare_for_class(inputs_dict, model_class))\n             attentions = outputs.attentions\n-            # IDEFICS does not support outputting attention score becuase it uses SDPA under the hood\n+            # IDEFICS does not support outputting attention score because it uses SDPA under the hood\n             self.assertTrue(attentions[0] is None)\n             out_len = len(outputs)\n \n@@ -386,7 +386,7 @@ def test_attention_outputs(self):\n             self_attentions = outputs.encoder_attentions if config.is_encoder_decoder else outputs.attentions\n \n             self.assertEqual(len(self_attentions), self.model_tester.num_hidden_layers)\n-            # IDEFICS does not support outputting attention score becuase it uses SDPA under the hood\n+            # IDEFICS does not support outputting attention score because it uses SDPA under the hood\n             self.assertTrue(self_attentions[0] is None)\n \n     def test_hidden_states_output(self):"
        },
        {
            "sha": "bf9155bf70ffc7ac6475989f2616b2a7eddd523e",
            "filename": "tests/models/mimi/test_modeling_mimi.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fmimi%2Ftest_modeling_mimi.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fmimi%2Ftest_modeling_mimi.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmimi%2Ftest_modeling_mimi.py?ref=19085c28dae05ff88027b85cb465b252d934cdcb",
            "patch": "@@ -485,7 +485,7 @@ def test_integration_using_cache_decode(self):\n \n         for num_codebooks, expected_rmse in expected_rmse.items():\n             with torch.no_grad():\n-                # use max bandwith for best possible reconstruction\n+                # use max bandwidth for best possible reconstruction\n                 encoder_outputs = model.encode(inputs[\"input_values\"], num_quantizers=int(num_codebooks))\n \n                 audio_codes = encoder_outputs[0]\n@@ -537,7 +537,7 @@ def test_integration(self):\n             model = MimiModel.from_pretrained(model_id, use_cache=use_cache).to(torch_device)\n             for num_codebooks, expected_rmse in expected_rmses.items():\n                 with torch.no_grad():\n-                    # use max bandwith for best possible reconstruction\n+                    # use max bandwidth for best possible reconstruction\n                     encoder_outputs = model.encode(inputs[\"input_values\"], num_quantizers=int(num_codebooks))\n \n                     audio_code_sums = encoder_outputs[0].sum().cpu().item()"
        },
        {
            "sha": "5dedeaceaeccc8841b4f0f785786e7c24b147b1d",
            "filename": "tests/models/rt_detr/test_modeling_rt_detr.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Frt_detr%2Ftest_modeling_rt_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Frt_detr%2Ftest_modeling_rt_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Frt_detr%2Ftest_modeling_rt_detr.py?ref=19085c28dae05ff88027b85cb465b252d934cdcb",
            "patch": "@@ -547,10 +547,10 @@ def test_different_timm_backbone(self):\n                     self.model_tester.num_labels,\n                 )\n                 self.assertEqual(outputs.logits.shape, expected_shape)\n-                # Confirm out_indices was propogated to backbone\n+                # Confirm out_indices was propagated to backbone\n                 self.assertEqual(len(model.model.backbone.intermediate_channel_sizes), 3)\n             else:\n-                # Confirm out_indices was propogated to backbone\n+                # Confirm out_indices was propagated to backbone\n                 self.assertEqual(len(model.backbone.intermediate_channel_sizes), 3)\n \n             self.assertTrue(outputs)\n@@ -579,10 +579,10 @@ def test_hf_backbone(self):\n                     self.model_tester.num_labels,\n                 )\n                 self.assertEqual(outputs.logits.shape, expected_shape)\n-                # Confirm out_indices was propogated to backbone\n+                # Confirm out_indices was propagated to backbone\n                 self.assertEqual(len(model.model.backbone.intermediate_channel_sizes), 3)\n             else:\n-                # Confirm out_indices was propogated to backbone\n+                # Confirm out_indices was propagated to backbone\n                 self.assertEqual(len(model.backbone.intermediate_channel_sizes), 3)\n \n             self.assertTrue(outputs)"
        },
        {
            "sha": "d38c0f29c6b5bccdab44a848f05072a870b3ead8",
            "filename": "tests/models/shieldgemma2/test_processing_shieldgemma2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fshieldgemma2%2Ftest_processing_shieldgemma2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fshieldgemma2%2Ftest_processing_shieldgemma2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fshieldgemma2%2Ftest_processing_shieldgemma2.py?ref=19085c28dae05ff88027b85cb465b252d934cdcb",
            "patch": "@@ -140,7 +140,7 @@ def test_with_custom_policies(self, name, policies, expected_batch_size):\n         if processor.chat_template is None:\n             self.skipTest(\"Processor has no chat template\")\n \n-        # Test policies adapated from https://ailuminate.mlcommons.org/benchmarks/ hazard categories\n+        # Test policies adapted from https://ailuminate.mlcommons.org/benchmarks/ hazard categories\n         custom_policies = {\n             \"cbrne\": \"Test policy related to indiscriminate weapons.\",\n             \"ip\": \"Test policy related to intellectual property.\","
        },
        {
            "sha": "208c793a9b04c310ead23b1c208b0364653d8144",
            "filename": "tests/models/video_llava/test_modeling_video_llava.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fvideo_llava%2Ftest_modeling_video_llava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/19085c28dae05ff88027b85cb465b252d934cdcb/tests%2Fmodels%2Fvideo_llava%2Ftest_modeling_video_llava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvideo_llava%2Ftest_modeling_video_llava.py?ref=19085c28dae05ff88027b85cb465b252d934cdcb",
            "patch": "@@ -391,7 +391,7 @@ def test_mismatching_num_image_tokens(self):\n         config, input_dict = self.model_tester.prepare_config_and_inputs_for_common()\n         for model_class in self.all_model_classes:\n             model = model_class(config).to(torch_device)\n-            _ = model(**input_dict)  # successfull forward with no modifications\n+            _ = model(**input_dict)  # successful forward with no modifications\n \n             # remove one image but leave the image token in text\n             input_dict[\"pixel_values_images\"] = input_dict[\"pixel_values_images\"][-1:, ...]"
        }
    ],
    "stats": {
        "total": 36,
        "additions": 19,
        "deletions": 17
    }
}