{
    "author": "pcuenca",
    "message": "Zero-shot pipelines: minor doc changes (#33127)\n\nMinor zero-shot doc changes for pipelines.",
    "sha": "f4c86d04162339f4ee56254048c7dc64088ede60",
    "files": [
        {
            "sha": "8ed339a5b7f889c21991eaec6901887ce97d90cd",
            "filename": "src/transformers/pipelines/zero_shot_audio_classification.py",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/f4c86d04162339f4ee56254048c7dc64088ede60/src%2Ftransformers%2Fpipelines%2Fzero_shot_audio_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f4c86d04162339f4ee56254048c7dc64088ede60/src%2Ftransformers%2Fpipelines%2Fzero_shot_audio_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fzero_shot_audio_classification.py?ref=f4c86d04162339f4ee56254048c7dc64088ede60",
            "patch": "@@ -78,16 +78,17 @@ def __call__(self, audios: Union[np.ndarray, bytes, str], **kwargs):\n                 - A string containing a local path to an audio\n                 - An audio loaded in numpy\n             candidate_labels (`List[str]`):\n-                The candidate labels for this audio\n+                The candidate labels for this audio. They will be formatted using *hypothesis_template*.\n             hypothesis_template (`str`, *optional*, defaults to `\"This is a sound of {}\"`):\n-                The sentence used in cunjunction with *candidate_labels* to attempt the audio classification by\n-                replacing the placeholder with the candidate_labels. Then likelihood is estimated by using\n-                logits_per_audio\n+                The format used in conjunction with *candidate_labels* to attempt the audio classification by\n+                replacing the placeholder with the candidate_labels. Pass \"{}\" if *candidate_labels* are\n+                already formatted.\n         Return:\n-            A list of dictionaries containing result, one dictionary per proposed label. The dictionaries contain the\n+            A list of dictionaries containing one entry per proposed label. Each dictionary contains the\n             following keys:\n-            - **label** (`str`) -- The label identified by the model. It is one of the suggested `candidate_label`.\n-            - **score** (`float`) -- The score attributed by the model for that label (between 0 and 1).\n+            - **label** (`str`) -- One of the suggested *candidate_labels*.\n+            - **score** (`float`) -- The score attributed by the model to that label. It is a value between\n+                0 and 1, computed as the `softmax` of `logits_per_audio`.\n         \"\"\"\n         return super().__call__(audios, **kwargs)\n "
        },
        {
            "sha": "b7e13e782e78cc9da6af491b1872d19ae8cb281d",
            "filename": "src/transformers/pipelines/zero_shot_image_classification.py",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f4c86d04162339f4ee56254048c7dc64088ede60/src%2Ftransformers%2Fpipelines%2Fzero_shot_image_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f4c86d04162339f4ee56254048c7dc64088ede60/src%2Ftransformers%2Fpipelines%2Fzero_shot_image_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fzero_shot_image_classification.py?ref=f4c86d04162339f4ee56254048c7dc64088ede60",
            "patch": "@@ -86,12 +86,12 @@ def __call__(self, images: Union[str, List[str], \"Image\", List[\"Image\"]], **kwar\n                 - An image loaded in PIL directly\n \n             candidate_labels (`List[str]`):\n-                The candidate labels for this image\n+                The candidate labels for this image. They will be formatted using *hypothesis_template*.\n \n             hypothesis_template (`str`, *optional*, defaults to `\"This is a photo of {}\"`):\n-                The sentence used in cunjunction with *candidate_labels* to attempt the image classification by\n-                replacing the placeholder with the candidate_labels. Then likelihood is estimated by using\n-                logits_per_image\n+                The format used in conjunction with *candidate_labels* to attempt the image classification by\n+                replacing the placeholder with the candidate_labels. Pass \"{}\" if *candidate_labels* are\n+                already formatted.\n \n             timeout (`float`, *optional*, defaults to None):\n                 The maximum time in seconds to wait for fetching images from the web. If None, no timeout is set and\n@@ -101,11 +101,11 @@ def __call__(self, images: Union[str, List[str], \"Image\", List[\"Image\"]], **kwar\n                 Additional dictionary of keyword arguments passed along to the tokenizer.\n \n         Return:\n-            A list of dictionaries containing result, one dictionary per proposed label. The dictionaries contain the\n+            A list of dictionaries containing one entry per proposed label. Each dictionary contains the\n             following keys:\n-\n-            - **label** (`str`) -- The label identified by the model. It is one of the suggested `candidate_label`.\n-            - **score** (`float`) -- The score attributed by the model for that label (between 0 and 1).\n+            - **label** (`str`) -- One of the suggested *candidate_labels*.\n+            - **score** (`float`) -- The score attributed by the model to that label. It is a value between\n+                0 and 1, computed as the `softmax` of `logits_per_image`.\n         \"\"\"\n         return super().__call__(images, **kwargs)\n "
        }
    ],
    "stats": {
        "total": 31,
        "additions": 16,
        "deletions": 15
    }
}