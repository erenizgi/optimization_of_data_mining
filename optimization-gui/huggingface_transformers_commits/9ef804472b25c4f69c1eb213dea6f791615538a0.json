{
    "author": "ydshieh",
    "message": "Pickle - part 2 (#41476)\n\n* pickle 2\n\n* pickle 2\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "9ef804472b25c4f69c1eb213dea6f791615538a0",
    "files": [
        {
            "sha": "63c3ebd1370db150d1c15f16836e716d340709be",
            "filename": "src/transformers/models/deprecated/mega/convert_mega_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 11,
            "deletions": 2,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/9ef804472b25c4f69c1eb213dea6f791615538a0/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fmega%2Fconvert_mega_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9ef804472b25c4f69c1eb213dea6f791615538a0/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fmega%2Fconvert_mega_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fmega%2Fconvert_mega_original_pytorch_checkpoint_to_pytorch.py?ref=9ef804472b25c4f69c1eb213dea6f791615538a0",
            "patch": "@@ -29,14 +29,16 @@\n \n # utilities to import the model weights and config file\n import os\n-import pickle as pkl\n+import pickle\n \n # PyTorch + new model classes\n import torch\n from torch import nn\n \n from transformers import AutoTokenizer, MegaConfig, MegaForMaskedLM\n \n+from ....utils import strtobool\n+\n \n # import the EncoderLayer class used to pretrain\n # !! NOTE !! this requires the version of fairseq that is built when you install the Mega source\n@@ -122,8 +124,15 @@ def forward(self, input_ids, attention_mask, batch_first=True, ignore_mask_value\n \n # code to convert the checkpoint located in the user-specified location\n def convert_checkpoint_to_huggingface(pretrained_checkpoint_path, output_path, includes_tokenizer):\n+    if not strtobool(os.environ.get(\"TRUST_REMOTE_CODE\", \"False\")):\n+        raise ValueError(\n+            \"This part uses `pickle.load` which is insecure and will execute arbitrary code that is potentially \"\n+            \"malicious. It's recommended to never unpickle data that could have come from an untrusted source, or \"\n+            \"that could have been tampered with. If you already verified the pickle data and decided to use it, \"\n+            \"you can set the environment variable `TRUST_REMOTE_CODE` to `True` to allow it.\"\n+        )\n     with open(os.path.join(pretrained_checkpoint_path, \"model_args.pkl\"), \"rb\") as f:\n-        mega_original_args = pkl.load(f)\n+        mega_original_args = pickle.load(f)\n \n     # load the original encoder\n     original_mlm = OriginalMegaForMaskedLM(**mega_original_args).eval()"
        },
        {
            "sha": "946dac551519be6fceae564748832831cb37cff8",
            "filename": "src/transformers/models/glm4v/convert_glm4v_mgt_weights_to_hf.py",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/9ef804472b25c4f69c1eb213dea6f791615538a0/src%2Ftransformers%2Fmodels%2Fglm4v%2Fconvert_glm4v_mgt_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9ef804472b25c4f69c1eb213dea6f791615538a0/src%2Ftransformers%2Fmodels%2Fglm4v%2Fconvert_glm4v_mgt_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v%2Fconvert_glm4v_mgt_weights_to_hf.py?ref=9ef804472b25c4f69c1eb213dea6f791615538a0",
            "patch": "@@ -25,6 +25,8 @@\n import torch\n from safetensors.torch import save_file\n \n+from ...utils import strtobool\n+\n \n # Avoid Using Megatron Lib\n class UnpicklerWrapper(pickle.Unpickler):\n@@ -249,6 +251,14 @@ def save_sharded_model(state_dict, output_path, max_shard_size_gb=5, num_layers=\n \n \n def merge_tp_weights(model_path, output_path, vllm_config_path=None):\n+    if not strtobool(os.environ.get(\"TRUST_REMOTE_CODE\", \"False\")):\n+        raise ValueError(\n+            \"This part uses `pickle.load` which is insecure and will execute arbitrary code that is potentially \"\n+            \"malicious. It's recommended to never unpickle data that could have come from an untrusted source, or \"\n+            \"that could have been tampered with. If you already verified the pickle data and decided to use it, \"\n+            \"you can set the environment variable `TRUST_REMOTE_CODE` to `True` to allow it.\"\n+        )\n+\n     tp_size = 0\n     for item in Path(model_path).iterdir():\n         if item.is_dir():"
        },
        {
            "sha": "98f73ce66b69fc39b8e1bc3b4bfb053b90eba976",
            "filename": "src/transformers/models/maskformer/convert_maskformer_resnet_to_pytorch.py",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/9ef804472b25c4f69c1eb213dea6f791615538a0/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fconvert_maskformer_resnet_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9ef804472b25c4f69c1eb213dea6f791615538a0/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fconvert_maskformer_resnet_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fconvert_maskformer_resnet_to_pytorch.py?ref=9ef804472b25c4f69c1eb213dea6f791615538a0",
            "patch": "@@ -17,6 +17,7 @@\n \n import argparse\n import json\n+import os\n import pickle\n from pathlib import Path\n \n@@ -28,6 +29,8 @@\n from transformers import MaskFormerConfig, MaskFormerForInstanceSegmentation, MaskFormerImageProcessor, ResNetConfig\n from transformers.utils import logging\n \n+from ...utils import strtobool\n+\n \n logging.set_verbosity_info()\n logger = logging.get_logger(__name__)\n@@ -266,6 +269,13 @@ def convert_maskformer_checkpoint(\n     \"\"\"\n     config = get_maskformer_config(model_name)\n \n+    if not strtobool(os.environ.get(\"TRUST_REMOTE_CODE\", \"False\")):\n+        raise ValueError(\n+            \"This part uses `pickle.load` which is insecure and will execute arbitrary code that is potentially \"\n+            \"malicious. It's recommended to never unpickle data that could have come from an untrusted source, or \"\n+            \"that could have been tampered with. If you already verified the pickle data and decided to use it, \"\n+            \"you can set the environment variable `TRUST_REMOTE_CODE` to `True` to allow it.\"\n+        )\n     # load original state_dict\n     with open(checkpoint_path, \"rb\") as f:\n         data = pickle.load(f)"
        },
        {
            "sha": "ef6147fbe1a52ff021dc3e32338e75d6a56e3ff6",
            "filename": "src/transformers/models/maskformer/convert_maskformer_swin_to_pytorch.py",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/9ef804472b25c4f69c1eb213dea6f791615538a0/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fconvert_maskformer_swin_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9ef804472b25c4f69c1eb213dea6f791615538a0/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fconvert_maskformer_swin_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fconvert_maskformer_swin_to_pytorch.py?ref=9ef804472b25c4f69c1eb213dea6f791615538a0",
            "patch": "@@ -17,6 +17,7 @@\n \n import argparse\n import json\n+import os\n import pickle\n from pathlib import Path\n \n@@ -28,6 +29,8 @@\n from transformers import MaskFormerConfig, MaskFormerForInstanceSegmentation, MaskFormerImageProcessor, SwinConfig\n from transformers.utils import logging\n \n+from ...utils import strtobool\n+\n \n logging.set_verbosity_info()\n logger = logging.get_logger(__name__)\n@@ -235,6 +238,13 @@ def convert_maskformer_checkpoint(\n     \"\"\"\n     config = get_maskformer_config(model_name)\n \n+    if not strtobool(os.environ.get(\"TRUST_REMOTE_CODE\", \"False\")):\n+        raise ValueError(\n+            \"This part uses `pickle.load` which is insecure and will execute arbitrary code that is potentially \"\n+            \"malicious. It's recommended to never unpickle data that could have come from an untrusted source, or \"\n+            \"that could have been tampered with. If you already verified the pickle data and decided to use it, \"\n+            \"you can set the environment variable `TRUST_REMOTE_CODE` to `True` to allow it.\"\n+        )\n     # load original state_dict\n     with open(checkpoint_path, \"rb\") as f:\n         data = pickle.load(f)"
        },
        {
            "sha": "11050075d4c7b5cc04a7daf8c7053812a1cb04b7",
            "filename": "src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py",
            "status": "modified",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/9ef804472b25c4f69c1eb213dea6f791615538a0/src%2Ftransformers%2Fmodels%2Folmo3%2Fconvert_olmo3_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9ef804472b25c4f69c1eb213dea6f791615538a0/src%2Ftransformers%2Fmodels%2Folmo3%2Fconvert_olmo3_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmo3%2Fconvert_olmo3_weights_to_hf.py?ref=9ef804472b25c4f69c1eb213dea6f791615538a0",
            "patch": "@@ -39,6 +39,8 @@\n \n from transformers import AutoTokenizer, Olmo3Config, Olmo3ForCausalLM\n \n+from ...utils import strtobool\n+\n \n \"\"\"\n Sample usage:\n@@ -198,6 +200,13 @@ def read_data(self, plan: dist_cp.LoadPlan, planner: dist_cp.LoadPlanner) -> Fut\n     def read_metadata(self) -> Metadata:\n         if self._metadata is None:\n             try:\n+                if not strtobool(os.environ.get(\"TRUST_REMOTE_CODE\", \"False\")):\n+                    raise ValueError(\n+                        \"This part uses `pickle.load` which is insecure and will execute arbitrary code that is potentially \"\n+                        \"malicious. It's recommended to never unpickle data that could have come from an untrusted source, or \"\n+                        \"that could have been tampered with. If you already verified the pickle data and decided to use it, \"\n+                        \"you can set the environment variable `TRUST_REMOTE_CODE` to `True` to allow it.\"\n+                    )\n                 with (Path(self.path) / \".metadata\").open(\"rb\") as metadata_file:\n                     metadata = pickle.load(metadata_file)\n             except FileNotFoundError as exc:\n@@ -256,6 +265,13 @@ def _load_unsharded_keys(\n         )\n         return state_dict\n \n+    if not strtobool(os.environ.get(\"TRUST_REMOTE_CODE\", \"False\")):\n+        raise ValueError(\n+            \"This part uses `pickle.load` which is insecure and will execute arbitrary code that is potentially \"\n+            \"malicious. It's recommended to never unpickle data that could have come from an untrusted source, or \"\n+            \"that could have been tampered with. If you already verified the pickle data and decided to use it, \"\n+            \"you can set the environment variable `TRUST_REMOTE_CODE` to `True` to allow it.\"\n+        )\n     with (Path(model_path) / \".metadata\").open(\"rb\") as metadata_file:\n         metadata = pickle.load(metadata_file)\n         keys = [key for key in metadata.state_dict_metadata.keys() if key.startswith(\"model.\")]"
        },
        {
            "sha": "020a5feab0f869e5af87555c71064702c17397e8",
            "filename": "src/transformers/models/perceiver/convert_perceiver_haiku_to_pytorch.py",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/9ef804472b25c4f69c1eb213dea6f791615538a0/src%2Ftransformers%2Fmodels%2Fperceiver%2Fconvert_perceiver_haiku_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9ef804472b25c4f69c1eb213dea6f791615538a0/src%2Ftransformers%2Fmodels%2Fperceiver%2Fconvert_perceiver_haiku_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fperceiver%2Fconvert_perceiver_haiku_to_pytorch.py?ref=9ef804472b25c4f69c1eb213dea6f791615538a0",
            "patch": "@@ -16,6 +16,7 @@\n \n import argparse\n import json\n+import os\n import pickle\n from pathlib import Path\n \n@@ -39,6 +40,8 @@\n )\n from transformers.utils import logging\n \n+from ...utils import strtobool\n+\n \n logging.set_verbosity_info()\n logger = logging.get_logger(__name__)\n@@ -264,6 +267,13 @@ def convert_perceiver_checkpoint(pickle_file, pytorch_dump_folder_path, architec\n     \"\"\"\n     Copy/paste/tweak model's weights to our Perceiver structure.\n     \"\"\"\n+    if not strtobool(os.environ.get(\"TRUST_REMOTE_CODE\", \"False\")):\n+        raise ValueError(\n+            \"This part uses `pickle.load` which is insecure and will execute arbitrary code that is potentially \"\n+            \"malicious. It's recommended to never unpickle data that could have come from an untrusted source, or \"\n+            \"that could have been tampered with. If you already verified the pickle data and decided to use it, \"\n+            \"you can set the environment variable `TRUST_REMOTE_CODE` to `True` to allow it.\"\n+        )\n \n     # load parameters as FlatMapping data structure\n     with open(pickle_file, \"rb\") as f:"
        },
        {
            "sha": "d94b2a56cc4a6b75dc81cd5e3ccc91cc2972a176",
            "filename": "src/transformers/models/reformer/convert_reformer_trax_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/9ef804472b25c4f69c1eb213dea6f791615538a0/src%2Ftransformers%2Fmodels%2Freformer%2Fconvert_reformer_trax_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9ef804472b25c4f69c1eb213dea6f791615538a0/src%2Ftransformers%2Fmodels%2Freformer%2Fconvert_reformer_trax_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Freformer%2Fconvert_reformer_trax_checkpoint_to_pytorch.py?ref=9ef804472b25c4f69c1eb213dea6f791615538a0",
            "patch": "@@ -15,6 +15,7 @@\n \"\"\"Convert Reformer checkpoint.\"\"\"\n \n import argparse\n+import os\n import pickle\n \n import numpy as np\n@@ -24,6 +25,8 @@\n from transformers import ReformerConfig, ReformerModelWithLMHead\n from transformers.utils import logging\n \n+from ...utils import strtobool\n+\n \n logging.set_verbosity_info()\n \n@@ -188,6 +191,13 @@ def convert_trax_checkpoint_to_pytorch(trax_model_pkl_path, config_file, pytorch\n     print(f\"Building PyTorch model from configuration: {config}\")\n     model = ReformerModelWithLMHead(config)\n \n+    if not strtobool(os.environ.get(\"TRUST_REMOTE_CODE\", \"False\")):\n+        raise ValueError(\n+            \"This part uses `pickle.load` which is insecure and will execute arbitrary code that is potentially \"\n+            \"malicious. It's recommended to never unpickle data that could have come from an untrusted source, or \"\n+            \"that could have been tampered with. If you already verified the pickle data and decided to use it, \"\n+            \"you can set the environment variable `TRUST_REMOTE_CODE` to `True` to allow it.\"\n+        )\n     with open(trax_model_pkl_path, \"rb\") as f:\n         model_weights = pickle.load(f)[\"weights\"]\n "
        }
    ],
    "stats": {
        "total": 79,
        "additions": 77,
        "deletions": 2
    }
}