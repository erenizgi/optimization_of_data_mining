{
    "author": "gante",
    "message": "[serve] guard imports (#39825)\n\nguard imports",
    "sha": "d6fad86d23787e54218dbec362ae9f7dc20dd1b0",
    "files": [
        {
            "sha": "6708dcc5dde9ef8cf3a7c1a4095f4d942d44d791",
            "filename": "src/transformers/commands/serving.py",
            "status": "modified",
            "additions": 11,
            "deletions": 5,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/d6fad86d23787e54218dbec362ae9f7dc20dd1b0/src%2Ftransformers%2Fcommands%2Fserving.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d6fad86d23787e54218dbec362ae9f7dc20dd1b0/src%2Ftransformers%2Fcommands%2Fserving.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fserving.py?ref=d6fad86d23787e54218dbec362ae9f7dc20dd1b0",
            "patch": "@@ -32,7 +32,6 @@\n \n from huggingface_hub import model_info\n from huggingface_hub.constants import HF_HUB_OFFLINE\n-from PIL import Image\n \n import transformers\n from transformers.models.auto.modeling_auto import (\n@@ -45,6 +44,7 @@\n     is_openai_available,\n     is_pydantic_available,\n     is_uvicorn_available,\n+    is_vision_available,\n )\n \n from .. import (\n@@ -54,7 +54,6 @@\n     ProcessorMixin,\n     TextIteratorStreamer,\n )\n-from ..generation.continuous_batching import ContinuousBatchingManager, RequestStatus\n from ..utils import is_torch_available, logging\n from . import BaseTransformersCLICommand\n \n@@ -69,9 +68,14 @@\n         PreTrainedModel,\n     )\n \n+    from ..generation.continuous_batching import ContinuousBatchingManager, RequestStatus\n+\n if is_librosa_available():\n     import librosa\n \n+if is_vision_available():\n+    from PIL import Image\n+\n serve_dependencies_available = (\n     is_pydantic_available() and is_fastapi_available() and is_uvicorn_available() and is_openai_available()\n )\n@@ -811,7 +815,7 @@ def stream_chat_completion(_inputs):\n         return stream_chat_completion(inputs[0])\n \n     @staticmethod\n-    def get_model_modality(model: PreTrainedModel) -> Modality:\n+    def get_model_modality(model: \"PreTrainedModel\") -> Modality:\n         model_classname = model.__class__.__name__\n         if model_classname in MODEL_FOR_IMAGE_TEXT_TO_TEXT_MAPPING_NAMES.values():\n             modality = Modality.VLM\n@@ -1545,7 +1549,9 @@ def _load_model_and_data_processor(self, model_id_and_revision: str):\n         logger.info(f\"Loaded model {model_id_and_revision}\")\n         return model, data_processor\n \n-    def load_model_and_processor(self, model_id_and_revision: str) -> tuple[PreTrainedModel, PreTrainedTokenizerFast]:\n+    def load_model_and_processor(\n+        self, model_id_and_revision: str\n+    ) -> tuple[\"PreTrainedModel\", PreTrainedTokenizerFast]:\n         \"\"\"\n         Loads the text model and processor from the given model ID and revision into the ServeCommand instance.\n \n@@ -1570,7 +1576,7 @@ def load_model_and_processor(self, model_id_and_revision: str) -> tuple[PreTrain\n \n         return model, processor\n \n-    def load_audio_model_and_processor(self, model_id_and_revision: str) -> tuple[PreTrainedModel, ProcessorMixin]:\n+    def load_audio_model_and_processor(self, model_id_and_revision: str) -> tuple[\"PreTrainedModel\", ProcessorMixin]:\n         \"\"\"\n         Loads the audio model and processor from the given model ID and revision into the ServeCommand instance.\n "
        }
    ],
    "stats": {
        "total": 16,
        "additions": 11,
        "deletions": 5
    }
}