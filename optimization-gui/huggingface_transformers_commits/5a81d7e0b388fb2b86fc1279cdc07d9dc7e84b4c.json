{
    "author": "winglian",
    "message": "revert behavior of _prepare_from_posids (#39622)\n\n* revert behavior of _prepare_from_posids\n\n* add back cu_seqlens_k and max_k for inference",
    "sha": "5a81d7e0b388fb2b86fc1279cdc07d9dc7e84b4c",
    "files": [
        {
            "sha": "fec93422146792fa0d3b7afa902347acc32a5fb7",
            "filename": "src/transformers/modeling_flash_attention_utils.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/5a81d7e0b388fb2b86fc1279cdc07d9dc7e84b4c/src%2Ftransformers%2Fmodeling_flash_attention_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5a81d7e0b388fb2b86fc1279cdc07d9dc7e84b4c/src%2Ftransformers%2Fmodeling_flash_attention_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_flash_attention_utils.py?ref=5a81d7e0b388fb2b86fc1279cdc07d9dc7e84b4c",
            "patch": "@@ -222,16 +222,18 @@ def _prepare_from_posids(query, key, value, position_ids):\n     query = query.contiguous().view(-1, query.size(-2), query.size(-1))\n     key = key.contiguous().view(-1, key.size(-2), key.size(-1))\n     value = value.contiguous().view(-1, value.size(-2), value.size(-1))\n+\n     cu_seqlens_k = torch.cat(\n         [torch.tensor([0], dtype=torch.int32, device=query.device), position_ids[:, -1].cumsum(dim=0) + 1], dim=0\n     )\n     max_k = torch.max(position_ids, dim=1).values.max().item() + 1\n+\n     position_ids = position_ids.flatten()\n     indices_q = torch.arange(position_ids.size(0), device=position_ids.device, dtype=torch.int32)\n \n     cu_seq_lens = torch.cat(\n         (\n-            torch.tensor([0], device=position_ids.device, dtype=torch.int32),\n+            indices_q[position_ids == 0],\n             torch.tensor(position_ids.size(), device=position_ids.device, dtype=torch.int32),\n         )\n     )"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 3,
        "deletions": 1
    }
}