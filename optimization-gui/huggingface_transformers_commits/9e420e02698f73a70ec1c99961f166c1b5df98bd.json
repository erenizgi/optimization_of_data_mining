{
    "author": "NielsRogge",
    "message": "[I-JEPA] Update docs (#35148)\n\nUpdate docs",
    "sha": "9e420e02698f73a70ec1c99961f166c1b5df98bd",
    "files": [
        {
            "sha": "cb2afd25e20bcaa3c04558a67abf54473598f832",
            "filename": "docs/source/en/model_doc/ijepa.md",
            "status": "modified",
            "additions": 16,
            "deletions": 2,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/9e420e02698f73a70ec1c99961f166c1b5df98bd/docs%2Fsource%2Fen%2Fmodel_doc%2Fijepa.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/9e420e02698f73a70ec1c99961f166c1b5df98bd/docs%2Fsource%2Fen%2Fmodel_doc%2Fijepa.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fijepa.md?ref=9e420e02698f73a70ec1c99961f166c1b5df98bd",
            "patch": "@@ -18,13 +18,18 @@ rendered properly in your Markdown viewer.\n \n ## Overview\n \n-The I-JEPA model was proposed in [Image-based Joint-Embedding Predictive Architecture](https://arxiv.org/pdf/2301.08243.pdf) by Mahmoud Assran, Quentin Duval, Ishan Misra, Piotr Bojanowski, Pascal Vincent, Michael Rabbat, Yann LeCun, Nicolas Ballas.\n+The I-JEPA model was proposed in [Image-based Joint-Embedding Predictive Architecture](https://arxiv.org/abs/2301.08243) by Mahmoud Assran, Quentin Duval, Ishan Misra, Piotr Bojanowski, Pascal Vincent, Michael Rabbat, Yann LeCun, Nicolas Ballas.\n I-JEPA is a self-supervised learning method that predicts the representations of one part of an image based on other parts of the same image. This approach focuses on learning semantic features without relying on pre-defined invariances from hand-crafted data transformations, which can bias specific tasks, or on filling in pixel-level details, which often leads to less meaningful representations.\n \n The abstract from the paper is the following:\n \n This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations. We introduce the Image- based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images. The idea behind I-JEPA is simple: from a single context block, predict the representations of various target blocks in the same image. A core design choice to guide I-JEPA towards producing semantic representations is the masking strategy; specifically, it is crucial to (a) sample tar- get blocks with sufficiently large scale (semantic), and to (b) use a sufficiently informative (spatially distributed) context block. Empirically, when combined with Vision Transform- ers, we find I-JEPA to be highly scalable. For instance, we train a ViT-Huge/14 on ImageNet using 16 A100 GPUs in under 72 hours to achieve strong downstream performance across a wide range of tasks, from linear classification to object counting and depth prediction.\n \n+<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/model_doc/ijepa_architecture.jpg\"\n+alt=\"drawing\" width=\"600\"/>\n+\n+<small> I-JEPA architecture. Taken from the <a href=\"https://arxiv.org/abs/2301.08243\">original paper.</a> </small>\n+\n This model was contributed by [jmtzt](https://huggingface.co/jmtzt).\n The original code can be found [here](https://github.com/facebookresearch/ijepa).\n \n@@ -63,6 +68,15 @@ similarity = cosine_similarity(embed_1, embed_2)\n print(similarity)\n ```\n \n+## Resources\n+\n+A list of official Hugging Face and community (indicated by ðŸŒŽ) resources to help you get started with I-JEPA.\n+\n+<PipelineTag pipeline=\"image-classification\"/>\n+\n+- [`IJepaForImageClassification`] is supported by this [example script](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification) and [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb).\n+- See also: [Image classification task guide](../tasks/image_classification)\n+\n ## IJepaConfig\n \n [[autodoc]] IJepaConfig\n@@ -75,4 +89,4 @@ print(similarity)\n ## IJepaForImageClassification\n \n [[autodoc]] IJepaForImageClassification\n-    - forward\n+    - forward\n\\ No newline at end of file"
        }
    ],
    "stats": {
        "total": 18,
        "additions": 16,
        "deletions": 2
    }
}