{
    "author": "st81",
    "message": "Fix Docstring of BarkProcessor (#39546)\n\n* Fix Docstring of BarkProcessor\n\n* Fix typo\n\n* Add type hint of return value for BarkProcessor.__call__",
    "sha": "a419a40234d2061c2e3480d1c5d699b575129a74",
    "files": [
        {
            "sha": "9825a34a3ba00a3df3cd3bc1ea534ab37fc1a470",
            "filename": "src/transformers/models/bark/processing_bark.py",
            "status": "modified",
            "additions": 5,
            "deletions": 3,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/a419a40234d2061c2e3480d1c5d699b575129a74/src%2Ftransformers%2Fmodels%2Fbark%2Fprocessing_bark.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a419a40234d2061c2e3480d1c5d699b575129a74/src%2Ftransformers%2Fmodels%2Fbark%2Fprocessing_bark.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbark%2Fprocessing_bark.py?ref=a419a40234d2061c2e3480d1c5d699b575129a74",
            "patch": "@@ -24,6 +24,7 @@\n \n from ...feature_extraction_utils import BatchFeature\n from ...processing_utils import ProcessorMixin\n+from ...tokenization_utils_base import BatchEncoding\n from ...utils import logging\n from ...utils.hub import cached_file\n from ..auto import AutoTokenizer\n@@ -232,7 +233,7 @@ def __call__(\n         return_attention_mask=True,\n         return_token_type_ids=False,\n         **kwargs,\n-    ):\n+    ) -> BatchEncoding:\n         \"\"\"\n         Main method to prepare for the model one or several sequences(s). This method forwards the `text` and `kwargs`\n         arguments to the AutoTokenizer's [`~AutoTokenizer.__call__`] to encode the text. The method also proposes a\n@@ -255,8 +256,9 @@ def __call__(\n                 - `'np'`: Return NumPy `np.ndarray` objects.\n \n         Returns:\n-            Tuple([`BatchEncoding`], [`BatchFeature`]): A tuple composed of a [`BatchEncoding`], i.e the output of the\n-            `tokenizer` and a [`BatchFeature`], i.e the voice preset with the right tensors type.\n+            [`BatchEncoding`]: A [`BatchEncoding`] object containing the output of the `tokenizer`.\n+            If a voice preset is provided, the returned object will include a `\"history_prompt\"` key\n+            containing a [`BatchFeature`], i.e the voice preset with the right tensors type.\n         \"\"\"\n         if voice_preset is not None and not isinstance(voice_preset, dict):\n             if ("
        }
    ],
    "stats": {
        "total": 8,
        "additions": 5,
        "deletions": 3
    }
}