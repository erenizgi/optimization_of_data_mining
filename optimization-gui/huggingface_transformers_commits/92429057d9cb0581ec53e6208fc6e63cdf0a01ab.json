{
    "author": "MekkCyber",
    "message": "Skip FP8 linear tests For device capability < 9.0(#37008)\n\n* skip fp8 linear\n\n* add capability check\n\n* format",
    "sha": "92429057d9cb0581ec53e6208fc6e63cdf0a01ab",
    "files": [
        {
            "sha": "69881b4cbbf197589081317f8148c50b4e738c6d",
            "filename": "tests/quantization/finegrained_fp8/test_fp8.py",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/92429057d9cb0581ec53e6208fc6e63cdf0a01ab/tests%2Fquantization%2Ffinegrained_fp8%2Ftest_fp8.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/92429057d9cb0581ec53e6208fc6e63cdf0a01ab/tests%2Fquantization%2Ffinegrained_fp8%2Ftest_fp8.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fquantization%2Ffinegrained_fp8%2Ftest_fp8.py?ref=92429057d9cb0581ec53e6208fc6e63cdf0a01ab",
            "patch": "@@ -250,6 +250,10 @@ def test_save_pretrained_offload(self):\n class FP8LinearTest(unittest.TestCase):\n     device = \"cuda\"\n \n+    @unittest.skipIf(\n+        torch.cuda.is_available() and torch.cuda.get_device_capability()[0] < 9,\n+        \"Skipping FP8LinearTest because it is not supported on GPU with capability < 9.0\",\n+    )\n     def test_linear_preserves_shape(self):\n         \"\"\"\n         Test that FP8Linear preserves shape when in_features == out_features.\n@@ -262,6 +266,10 @@ def test_linear_preserves_shape(self):\n         x_ = linear(x)\n         self.assertEqual(x_.shape, x.shape)\n \n+    @unittest.skipIf(\n+        torch.cuda.is_available() and torch.cuda.get_device_capability()[0] < 9,\n+        \"Skipping FP8LinearTest because it is not supported on GPU with capability < 9.0\",\n+    )\n     def test_linear_with_diff_feature_size_preserves_shape(self):\n         \"\"\"\n         Test that FP8Linear generates the correct shape when in_features != out_features."
        }
    ],
    "stats": {
        "total": 8,
        "additions": 8,
        "deletions": 0
    }
}