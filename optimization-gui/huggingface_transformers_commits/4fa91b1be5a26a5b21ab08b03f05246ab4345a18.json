{
    "author": "yao-matrix",
    "message": "fix \"Cannot copy out of meta tensor; no data!\" issue for BartForConditionalGeneration model (#36572)\n\n* fix \"Cannot copy out of meta tensor; no data!\" issue for BartForConditionalGeneration model\n\n* follow Marc's suggestion to use _tie_weights to fix\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>\n\n* fix review comments.\n\nSigned-off-by: N <matrix.yao@intel.com>\n\n* fix quality\n\nSigned-off-by: N <matrix.yao@intel.com>\n\n---------\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>\nSigned-off-by: N <matrix.yao@intel.com>",
    "sha": "4fa91b1be5a26a5b21ab08b03f05246ab4345a18",
    "files": [
        {
            "sha": "ac9945df71b7ac22a93454f803f12c6edd8ab33f",
            "filename": "src/transformers/models/bart/modeling_bart.py",
            "status": "modified",
            "additions": 14,
            "deletions": 2,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/4fa91b1be5a26a5b21ab08b03f05246ab4345a18/src%2Ftransformers%2Fmodels%2Fbart%2Fmodeling_bart.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4fa91b1be5a26a5b21ab08b03f05246ab4345a18/src%2Ftransformers%2Fmodels%2Fbart%2Fmodeling_bart.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbart%2Fmodeling_bart.py?ref=4fa91b1be5a26a5b21ab08b03f05246ab4345a18",
            "patch": "@@ -1442,8 +1442,15 @@ def __init__(self, config: BartConfig):\n \n     def _tie_weights(self):\n         if self.config.tie_word_embeddings:\n-            self._tie_or_clone_weights(self.encoder.embed_tokens, self.shared)\n-            self._tie_or_clone_weights(self.decoder.embed_tokens, self.shared)\n+            # Some model checkpoints like \"facebook/bart-large-cnn\"'s embedding weight is in decoder.embed_tokens, need check here, see issue #36247\n+            if self.shared.weight.device == torch.device(\n+                \"meta\"\n+            ) and self.decoder.embed_tokens.weight.device != torch.device(\"meta\"):\n+                self._tie_or_clone_weights(self.encoder.embed_tokens, self.decoder.embed_tokens)\n+                self._tie_or_clone_weights(self.shared, self.decoder.embed_tokens)\n+            else:\n+                self._tie_or_clone_weights(self.encoder.embed_tokens, self.shared)\n+                self._tie_or_clone_weights(self.decoder.embed_tokens, self.shared)\n \n     def get_input_embeddings(self):\n         return self.shared\n@@ -1599,6 +1606,11 @@ def get_output_embeddings(self):\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def _tie_weights(self):\n+        if self.config.tie_word_embeddings:\n+            self.model._tie_weights()\n+            self._tie_or_clone_weights(self.lm_head, self.model.shared)\n+\n     @add_start_docstrings_to_model_forward(BART_INPUTS_DOCSTRING)\n     @replace_return_docstrings(output_type=Seq2SeqLMOutput, config_class=_CONFIG_FOR_DOC)\n     @add_end_docstrings(BART_GENERATION_EXAMPLE)"
        },
        {
            "sha": "935e5ee9fd6a3904be1f3842016f60797339289f",
            "filename": "src/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/4fa91b1be5a26a5b21ab08b03f05246ab4345a18/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fmodeling_bigbird_pegasus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4fa91b1be5a26a5b21ab08b03f05246ab4345a18/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fmodeling_bigbird_pegasus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fmodeling_bigbird_pegasus.py?ref=4fa91b1be5a26a5b21ab08b03f05246ab4345a18",
            "patch": "@@ -2479,6 +2479,11 @@ def get_output_embeddings(self):\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def _tie_weights(self):\n+        if self.config.tie_word_embeddings:\n+            self.model._tie_weights()\n+            self._tie_or_clone_weights(self.lm_head, self.model.shared)\n+\n     @add_start_docstrings_to_model_forward(BIGBIRD_PEGASUS_INPUTS_DOCSTRING)\n     @replace_return_docstrings(output_type=Seq2SeqLMOutput, config_class=_CONFIG_FOR_DOC)\n     @add_end_docstrings(BIGBIRD_PEGASUS_GENERATION_EXAMPLE)"
        }
    ],
    "stats": {
        "total": 21,
        "additions": 19,
        "deletions": 2
    }
}