{
    "author": "zucchini-nlp",
    "message": "Fix  \"test_chat_template_dict\" in video LLMs (#35660)\n\n* fix  \"test_chat_template_dict\" in llava_onevision\r\n\r\n* Update src/transformers/models/llava_next_video/processing_llava_next_video.py\r\n\r\nCo-authored-by: Pavel Iakubovskii <qubvel@gmail.com>\r\n\r\n* get one video calles once\r\n\r\n---------\r\n\r\nCo-authored-by: Pavel Iakubovskii <qubvel@gmail.com>",
    "sha": "705aeaaa12738e3832f4911edcfb2f356ecd0f62",
    "files": [
        {
            "sha": "349a2253a2337efc1803b42d1c21b06450b2f1dc",
            "filename": "src/transformers/models/llava_next_video/processing_llava_next_video.py",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/705aeaaa12738e3832f4911edcfb2f356ecd0f62/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fprocessing_llava_next_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/705aeaaa12738e3832f4911edcfb2f356ecd0f62/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fprocessing_llava_next_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fprocessing_llava_next_video.py?ref=705aeaaa12738e3832f4911edcfb2f356ecd0f62",
            "patch": "@@ -18,6 +18,8 @@\n \n from typing import TYPE_CHECKING, List, Optional, Union\n \n+import numpy as np\n+\n from ...feature_extraction_utils import BatchFeature\n from ...image_processing_utils import select_best_resolution\n from ...image_utils import ImageInput, VideoInput, get_image_size, to_numpy_array\n@@ -193,7 +195,11 @@ def __call__(\n \n         # videos are easier, simply get frames and multiply\n         if videos_inputs:\n-            one_video = to_numpy_array(videos_inputs.get(\"pixel_values_videos\")[0])\n+            one_video = videos_inputs.get(\"pixel_values_videos\")[0]\n+            if isinstance(one_video, (list, tuple)):\n+                one_video = np.array(one_video)\n+            else:\n+                one_video = to_numpy_array(one_video)\n             height, width = get_image_size(one_video[0])\n             num_frames = one_video.shape[0]  # frame dim is always after batch dim\n "
        },
        {
            "sha": "eded6084e91ee00bbe98bc2a0a71f23a1edc1a92",
            "filename": "src/transformers/models/llava_onevision/processing_llava_onevision.py",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/705aeaaa12738e3832f4911edcfb2f356ecd0f62/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fprocessing_llava_onevision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/705aeaaa12738e3832f4911edcfb2f356ecd0f62/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fprocessing_llava_onevision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fprocessing_llava_onevision.py?ref=705aeaaa12738e3832f4911edcfb2f356ecd0f62",
            "patch": "@@ -20,6 +20,8 @@\n import os\n from typing import Iterable, List, Union\n \n+import numpy as np\n+\n from ...feature_extraction_utils import BatchFeature\n from ...image_processing_utils import select_best_resolution\n from ...image_utils import ImageInput, VideoInput, get_image_size, to_numpy_array\n@@ -164,7 +166,11 @@ def __call__(\n         if videos is not None:\n             video_inputs = self.video_processor(videos, **output_kwargs[\"videos_kwargs\"])\n \n-            one_video = to_numpy_array(video_inputs.get(\"pixel_values_videos\")[0])\n+            one_video = video_inputs.get(\"pixel_values_videos\")[0]\n+            if isinstance(video_inputs.get(\"pixel_values_videos\")[0], (list, tuple)):\n+                one_video = np.array(one_video)\n+            else:\n+                one_video = to_numpy_array(one_video)\n             height, width = get_image_size(one_video[0], channel_dim=output_kwargs[\"images_kwargs\"].get(\"data_format\"))\n             num_frames = one_video.shape[0]  # frame dim is always after batch dim\n             patches_height_width = int(math.sqrt(self.num_image_tokens))"
        },
        {
            "sha": "19c10f8b4b214da9710615a65004e3b5a7f58d5d",
            "filename": "src/transformers/models/video_llava/processing_video_llava.py",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/705aeaaa12738e3832f4911edcfb2f356ecd0f62/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fprocessing_video_llava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/705aeaaa12738e3832f4911edcfb2f356ecd0f62/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fprocessing_video_llava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fprocessing_video_llava.py?ref=705aeaaa12738e3832f4911edcfb2f356ecd0f62",
            "patch": "@@ -18,6 +18,8 @@\n \n from typing import List, Optional, Union\n \n+import numpy as np\n+\n from ...feature_extraction_utils import BatchFeature\n from ...image_utils import ImageInput, get_image_size, to_numpy_array\n from ...processing_utils import ProcessorMixin\n@@ -165,7 +167,11 @@ def __call__(\n                 num_frames = 1\n \n             if \"pixel_values_videos\" in encoded_images.keys():\n-                one_video = to_numpy_array(encoded_images.get(\"pixel_values_videos\")[0])\n+                one_video = encoded_images.get(\"pixel_values_videos\")[0]\n+                if isinstance(encoded_images.get(\"pixel_values_videos\")[0], (list, tuple)):\n+                    one_video = np.array(one_video)\n+                else:\n+                    one_video = to_numpy_array(one_video)\n                 height, width = get_image_size(one_video[0])\n                 num_frames = one_video.shape[0]  # frame dim is always after batch dim\n "
        }
    ],
    "stats": {
        "total": 24,
        "additions": 21,
        "deletions": 3
    }
}