{
    "author": "remi-or",
    "message": "Fix inits in modernbert (#43115)\n\n* Fix inits in moderbert\n\n* Repo consistency\n\n* Update modular_modernbert.py\n\nCo-authored-by: Cyril Vallez <cyril.vallez@huggingface.co>\n\n* Repo consistency\n\n---------\n\nCo-authored-by: Cyril Vallez <cyril.vallez@huggingface.co>",
    "sha": "491e0cd2345b0a43344d4c92c0f58c70088ceb89",
    "files": [
        {
            "sha": "fdf8d6062a905e7681b639b145862675d409082f",
            "filename": "src/transformers/models/modernbert/modeling_modernbert.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/491e0cd2345b0a43344d4c92c0f58c70088ceb89/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodeling_modernbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/491e0cd2345b0a43344d4c92c0f58c70088ceb89/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodeling_modernbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodeling_modernbert.py?ref=491e0cd2345b0a43344d4c92c0f58c70088ceb89",
            "patch": "@@ -685,6 +685,9 @@ def init_weight(module: nn.Module, std: float):\n                 curr_inv_freq, _ = rope_init_fn(module.config, layer_type=layer_type)\n                 init.copy_(getattr(module, f\"{layer_type}_inv_freq\"), curr_inv_freq)\n                 init.copy_(getattr(module, f\"{layer_type}_original_inv_freq\"), curr_inv_freq)\n+        elif isinstance(module, ModernBertUnpaddedRotaryEmbedding):\n+            inv_freq = module._compute_inv_freq()\n+            init.copy_(module.inv_freq, inv_freq)\n \n     def _check_and_adjust_attn_implementation(\n         self, attn_implementation: Optional[str], is_init_check: bool = False"
        },
        {
            "sha": "7c1f1253dbd4a5060fd6a0eea34eda00dee68bae",
            "filename": "src/transformers/models/modernbert/modular_modernbert.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/491e0cd2345b0a43344d4c92c0f58c70088ceb89/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodular_modernbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/491e0cd2345b0a43344d4c92c0f58c70088ceb89/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodular_modernbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodular_modernbert.py?ref=491e0cd2345b0a43344d4c92c0f58c70088ceb89",
            "patch": "@@ -879,6 +879,9 @@ def init_weight(module: nn.Module, std: float):\n                 curr_inv_freq, _ = rope_init_fn(module.config, layer_type=layer_type)\n                 init.copy_(getattr(module, f\"{layer_type}_inv_freq\"), curr_inv_freq)\n                 init.copy_(getattr(module, f\"{layer_type}_original_inv_freq\"), curr_inv_freq)\n+        elif isinstance(module, ModernBertUnpaddedRotaryEmbedding):\n+            inv_freq = module._compute_inv_freq()\n+            init.copy_(module.inv_freq, inv_freq)\n \n     def _check_and_adjust_attn_implementation(\n         self, attn_implementation: Optional[str], is_init_check: bool = False"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 6,
        "deletions": 0
    }
}