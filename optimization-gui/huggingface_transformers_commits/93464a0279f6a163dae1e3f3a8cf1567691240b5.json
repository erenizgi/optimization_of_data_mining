{
    "author": "Sai-Suraj-27",
    "message": "Prefer raising `TypeError` exception for invalid type (#41346)\n\n* Fixed raising of TypeError exception for invalid type\n\n* Fixed failing tests.",
    "sha": "93464a0279f6a163dae1e3f3a8cf1567691240b5",
    "files": [
        {
            "sha": "1b1e0bd5cf4020b7c26b6f8b7a1ec87c5f0917d2",
            "filename": "src/transformers/cache_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fcache_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fcache_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcache_utils.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -1313,7 +1313,7 @@ def check_dynamic_cache(self, method: str):\n             isinstance(self.self_attention_cache, DynamicCache)\n             and isinstance(self.cross_attention_cache, DynamicCache)\n         ):\n-            raise ValueError(\n+            raise TypeError(\n                 f\"`{method}` is only defined for dynamic cache, got {self.self_attention_cache.__str__()} for the self \"\n                 f\"attention cache and {self.cross_attention_cache.__str__()} for the cross attention cache.\"\n             )"
        },
        {
            "sha": "3fccadcc6253edb7951c349c59bb2a3ebc3e94a9",
            "filename": "src/transformers/commands/serving.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fcommands%2Fserving.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fcommands%2Fserving.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fserving.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -1186,7 +1186,7 @@ def generate_response(self, req: dict) -> Generator[str, None, None]:\n             inputs = [{\"role\": \"system\", \"content\": req[\"instructions\"]}] if \"instructions\" in req else []\n             inputs.append(req[\"input\"])\n         else:\n-            raise ValueError(\"inputs should be a list, dict, or str\")\n+            raise TypeError(\"inputs should be a list, dict, or str\")\n \n         inputs = processor.apply_chat_template(inputs, add_generation_prompt=True, return_tensors=\"pt\")\n         inputs = inputs.to(model.device)"
        },
        {
            "sha": "3be0e07364a60e3130c0e9745937c96f7feb0411",
            "filename": "src/transformers/models/evolla/processing_evolla.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fevolla%2Fprocessing_evolla.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fevolla%2Fprocessing_evolla.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fevolla%2Fprocessing_evolla.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -165,7 +165,7 @@ def __call__(\n         if isinstance(messages_list, (list, tuple)):\n             for messages in messages_list:\n                 if not isinstance(messages, (list, tuple)):\n-                    raise ValueError(f\"Each messages in messages_list should be a list instead of {type(messages)}.\")\n+                    raise TypeError(f\"Each messages in messages_list should be a list instead of {type(messages)}.\")\n                 if not all(isinstance(m, dict) for m in messages):\n                     raise ValueError(\n                         \"Each message in messages_list should be a list of dictionaries, but not all elements are dictionaries.\""
        },
        {
            "sha": "913336b8d3f5e346fccaf3735080ead3115a0c08",
            "filename": "src/transformers/models/gemma3n/processing_gemma3n.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fgemma3n%2Fprocessing_gemma3n.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fgemma3n%2Fprocessing_gemma3n.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma3n%2Fprocessing_gemma3n.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -107,7 +107,7 @@ def __call__(\n         if isinstance(text, str):\n             text = [text]\n         elif not isinstance(text, list) and not isinstance(text[0], str):\n-            raise ValueError(\"Invalid input text. Please provide a string, or a list of strings\")\n+            raise TypeError(\"Invalid input text. Please provide a string, or a list of strings\")\n \n         if audio is not None:\n             audio_inputs = self.feature_extractor(audio, **output_kwargs[\"audio_kwargs\"])"
        },
        {
            "sha": "037e3cbc25b2339def4321783d47e0b08e559931",
            "filename": "src/transformers/models/lfm2_vl/processing_lfm2_vl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Flfm2_vl%2Fprocessing_lfm2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Flfm2_vl%2Fprocessing_lfm2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flfm2_vl%2Fprocessing_lfm2_vl.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -135,7 +135,7 @@ def __call__(\n         if isinstance(text, str):\n             text = [text]\n         elif not isinstance(text, list) and not isinstance(text[0], str):\n-            raise ValueError(\"Invalid input text. Please provide a string, or a list of strings\")\n+            raise TypeError(\"Invalid input text. Please provide a string, or a list of strings\")\n \n         n_images_in_text = [sample.count(self.image_token) for sample in text]\n         if sum(n_images_in_text) > 0 and images is None:"
        },
        {
            "sha": "82cd686682a94ffb4ddec734134b39cc477fc9b8",
            "filename": "src/transformers/models/ovis2/processing_ovis2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fovis2%2Fprocessing_ovis2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fovis2%2Fprocessing_ovis2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fovis2%2Fprocessing_ovis2.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -118,7 +118,7 @@ def __call__(\n         if isinstance(text, str):\n             text = [text]\n         elif not isinstance(text, list) and not isinstance(text[0], str):\n-            raise ValueError(\"Invalid input text. Please provide a string, or a list of strings\")\n+            raise TypeError(\"Invalid input text. Please provide a string, or a list of strings\")\n \n         image_inputs = {}\n "
        },
        {
            "sha": "41016765c1fdfe3d2fd661471ffc5ba30c9b1867",
            "filename": "src/transformers/models/perception_lm/processing_perception_lm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fprocessing_perception_lm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fprocessing_perception_lm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fprocessing_perception_lm.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -144,7 +144,7 @@ def __call__(\n         if isinstance(text, str):\n             text = [text]\n         elif not isinstance(text, list) and not isinstance(text[0], str):\n-            raise ValueError(\"Invalid input text. Please provide a string, or a list of strings\")\n+            raise TypeError(\"Invalid input text. Please provide a string, or a list of strings\")\n \n         # try to expand inputs in processing if we have the necessary parts\n         prompt_strings = []"
        },
        {
            "sha": "54dbcf52c17f46302fab2d261dd107a5347b98af",
            "filename": "src/transformers/models/sam/image_processing_sam_fast.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fsam%2Fimage_processing_sam_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fsam%2Fimage_processing_sam_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam%2Fimage_processing_sam_fast.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -390,7 +390,7 @@ def post_process_masks(\n             if isinstance(masks[i], np.ndarray):\n                 masks[i] = torch.from_numpy(masks[i])\n             elif not isinstance(masks[i], torch.Tensor):\n-                raise ValueError(\"Input masks should be a list of `torch.tensors` or a list of `np.ndarray`\")\n+                raise TypeError(\"Input masks should be a list of `torch.tensors` or a list of `np.ndarray`\")\n             interpolated_mask = F.interpolate(masks[i], target_image_size, mode=\"bilinear\", align_corners=False)\n             interpolated_mask = interpolated_mask[..., : reshaped_input_sizes[i][0], : reshaped_input_sizes[i][1]]\n             interpolated_mask = F.interpolate(interpolated_mask, original_size, mode=\"bilinear\", align_corners=False)"
        },
        {
            "sha": "c468f6400d547386b87a525bb7e03975f0c7f8ce",
            "filename": "src/transformers/models/sam2/image_processing_sam2_fast.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fsam2%2Fimage_processing_sam2_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fsam2%2Fimage_processing_sam2_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2%2Fimage_processing_sam2_fast.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -669,7 +669,7 @@ def post_process_masks(\n             if isinstance(masks[i], np.ndarray):\n                 masks[i] = torch.from_numpy(masks[i])\n             elif not isinstance(masks[i], torch.Tensor):\n-                raise ValueError(\"Input masks should be a list of `torch.tensors` or a list of `np.ndarray`\")\n+                raise TypeError(\"Input masks should be a list of `torch.tensors` or a list of `np.ndarray`\")\n             interpolated_mask = F.interpolate(masks[i], original_size, mode=\"bilinear\", align_corners=False)\n             if apply_non_overlapping_constraints:\n                 interpolated_mask = self._apply_non_overlapping_constraints(interpolated_mask)"
        },
        {
            "sha": "8fcfe36a759e6df561de10cdb5949b4c9a46b2c7",
            "filename": "src/transformers/models/sam2/modular_sam2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -287,7 +287,7 @@ def post_process_masks(\n             if isinstance(masks[i], np.ndarray):\n                 masks[i] = torch.from_numpy(masks[i])\n             elif not isinstance(masks[i], torch.Tensor):\n-                raise ValueError(\"Input masks should be a list of `torch.tensors` or a list of `np.ndarray`\")\n+                raise TypeError(\"Input masks should be a list of `torch.tensors` or a list of `np.ndarray`\")\n             interpolated_mask = F.interpolate(masks[i], original_size, mode=\"bilinear\", align_corners=False)\n             if apply_non_overlapping_constraints:\n                 interpolated_mask = self._apply_non_overlapping_constraints(interpolated_mask)"
        },
        {
            "sha": "a2d90581ec70e15be5a209cdc1e0b27e0e108483",
            "filename": "src/transformers/models/sam2/processing_sam2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fsam2%2Fprocessing_sam2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fsam2%2Fprocessing_sam2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2%2Fprocessing_sam2.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -258,7 +258,7 @@ def _convert_to_nested_list(self, data, expected_depth, current_depth=0):\n         elif isinstance(data, (int, float)):\n             return data\n         else:\n-            raise ValueError(f\"Unsupported data type: {type(data)}\")\n+            raise TypeError(f\"Unsupported data type: {type(data)}\")\n \n     def _get_nested_dimensions(self, nested_list, max_dims=None):\n         \"\"\""
        },
        {
            "sha": "0c0df9490152bd282d5f9da0f4825f7235eb95d0",
            "filename": "src/transformers/models/sam2_video/processing_sam2_video.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fprocessing_sam2_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fprocessing_sam2_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fprocessing_sam2_video.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -262,7 +262,7 @@ def _convert_to_nested_list(self, data, expected_depth, current_depth=0):\n         elif isinstance(data, (int, float)):\n             return data\n         else:\n-            raise ValueError(f\"Unsupported data type: {type(data)}\")\n+            raise TypeError(f\"Unsupported data type: {type(data)}\")\n \n     def _get_nested_dimensions(self, nested_list, max_dims=None):\n         \"\"\""
        },
        {
            "sha": "873bf2c378abdcbbc3ba281e33af234d60a766f7",
            "filename": "src/transformers/models/sam2_video/video_processing_sam2_video.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fvideo_processing_sam2_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fvideo_processing_sam2_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fvideo_processing_sam2_video.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -92,7 +92,7 @@ def post_process_masks(\n             if isinstance(masks[i], np.ndarray):\n                 masks[i] = torch.from_numpy(masks[i])\n             elif not isinstance(masks[i], torch.Tensor):\n-                raise ValueError(\"Input masks should be a list of `torch.tensors` or a list of `np.ndarray`\")\n+                raise TypeError(\"Input masks should be a list of `torch.tensors` or a list of `np.ndarray`\")\n             interpolated_mask = F_t.interpolate(masks[i], target_image_size, mode=\"bilinear\", align_corners=False)\n             interpolated_mask = interpolated_mask[..., : reshaped_input_sizes[i][0], : reshaped_input_sizes[i][1]]\n             interpolated_mask = F_t.interpolate(interpolated_mask, original_size, mode=\"bilinear\", align_corners=False)"
        },
        {
            "sha": "e21423a8fe12e9fc300edd3c8e1d36893b8417db",
            "filename": "src/transformers/quantizers/auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fquantizers%2Fauto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Fquantizers%2Fauto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fauto.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -287,7 +287,7 @@ def register_quantizer_fn(cls):\n             raise ValueError(f\"Quantizer '{name}' already registered\")\n \n         if not issubclass(cls, HfQuantizer):\n-            raise ValueError(\"Quantizer must extend HfQuantizer\")\n+            raise TypeError(\"Quantizer must extend HfQuantizer\")\n \n         AUTO_QUANTIZER_MAPPING[name] = cls\n         return cls"
        },
        {
            "sha": "027a9deccafdb3e00e977e465a36806738352711",
            "filename": "src/transformers/tokenization_mistral_common.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Ftokenization_mistral_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/src%2Ftransformers%2Ftokenization_mistral_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_mistral_common.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -1433,7 +1433,7 @@ def apply_chat_template(\n                 f\"Kwargs {list(kwargs.keys())} are not supported by `MistralCommonTokenizer.apply_chat_template`.\"\n             )\n         if not isinstance(truncation, bool):\n-            raise ValueError(\"`truncation` must be a boolean for `apply_chat_template` method.\")\n+            raise TypeError(\"`truncation` must be a boolean for `apply_chat_template` method.\")\n \n         if isinstance(conversation, (list, tuple)) and (\n             isinstance(conversation[0], (list, tuple)) or hasattr(conversation[0], \"messages\")"
        },
        {
            "sha": "db1b27738bf7922f40717f4e2b2ac5c2e22a121b",
            "filename": "tests/models/sam2/test_processor_sam2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/tests%2Fmodels%2Fsam2%2Ftest_processor_sam2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/tests%2Fmodels%2Fsam2%2Ftest_processor_sam2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsam2%2Ftest_processor_sam2.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -140,5 +140,5 @@ def test_post_process_masks(self):\n         self.assertEqual(masks[0].shape, (1, 3, 1764, 2646))\n \n         dummy_masks = [[1, 0], [0, 1]]\n-        with self.assertRaises(ValueError):\n+        with self.assertRaises(TypeError):\n             masks = processor.post_process_masks(dummy_masks, np.array(original_sizes))"
        },
        {
            "sha": "5e4d07bed1bed06a6597f1eb2400b7b63e0454ab",
            "filename": "tests/models/sam2_video/test_processor_sam2_video.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/tests%2Fmodels%2Fsam2_video%2Ftest_processor_sam2_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/tests%2Fmodels%2Fsam2_video%2Ftest_processor_sam2_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsam2_video%2Ftest_processor_sam2_video.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -149,5 +149,5 @@ def test_post_process_masks(self):\n         self.assertEqual(masks[0].shape, (1, 3, 1764, 2646))\n \n         dummy_masks = [[1, 0], [0, 1]]\n-        with self.assertRaises(ValueError):\n+        with self.assertRaises(TypeError):\n             masks = processor.post_process_masks(dummy_masks, np.array(original_sizes))"
        },
        {
            "sha": "9b574f85fb1caca64f5b3ac6f579187bf4f8c2d1",
            "filename": "tests/test_tokenization_mistral_common.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/93464a0279f6a163dae1e3f3a8cf1567691240b5/tests%2Ftest_tokenization_mistral_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93464a0279f6a163dae1e3f3a8cf1567691240b5/tests%2Ftest_tokenization_mistral_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_tokenization_mistral_common.py?ref=93464a0279f6a163dae1e3f3a8cf1567691240b5",
            "patch": "@@ -945,7 +945,7 @@ def test_appsly_chat_template_with_truncation(self):\n \n         # Test 3:\n         # assert truncation is boolean\n-        with self.assertRaises(ValueError):\n+        with self.assertRaises(TypeError):\n             self.tokenizer.apply_chat_template(\n                 conversation, tokenize=True, truncation=TruncationStrategy.LONGEST_FIRST, max_length=20\n             )\n@@ -1189,7 +1189,7 @@ def test_batch_apply_chat_template_with_truncation(\n \n         # Test 3:\n         # assert truncation is boolean\n-        with self.assertRaises(ValueError):\n+        with self.assertRaises(TypeError):\n             self.tokenizer.apply_chat_template(\n                 self.fixture_conversations, tokenize=True, truncation=TruncationStrategy.LONGEST_FIRST, max_length=20\n             )"
        }
    ],
    "stats": {
        "total": 38,
        "additions": 19,
        "deletions": 19
    }
}