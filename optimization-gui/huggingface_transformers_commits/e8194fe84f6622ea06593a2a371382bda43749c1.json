{
    "author": "Cyrilvallez",
    "message": "Fix some tests (#41503)\n\n* fix\n\n* fix\n\n* doc",
    "sha": "e8194fe84f6622ea06593a2a371382bda43749c1",
    "files": [
        {
            "sha": "fca34aab0ddc48254a004b0fac6b65fa45cd313f",
            "filename": "docs/source/ar/llm_tutorial_optimization.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e8194fe84f6622ea06593a2a371382bda43749c1/docs%2Fsource%2Far%2Fllm_tutorial_optimization.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e8194fe84f6622ea06593a2a371382bda43749c1/docs%2Fsource%2Far%2Fllm_tutorial_optimization.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fllm_tutorial_optimization.md?ref=e8194fe84f6622ea06593a2a371382bda43749c1",
            "patch": "@@ -472,7 +472,7 @@ for _ in range(5):\n   next_token_id = torch.argmax(next_logits, dim=-1)\n \n   print(\"shape of input_ids\", next_token_id.shape)\n-  print(\"length of key-value cache\", len(past_key_values[0][0]))  # past_key_values are of shape [num_layers, 0 for k, 1 for v, batch_size, length, hidden_dim]\n+  print(\"length of key-value cache\", past_key_values.get_seq_length())  # past_key_values are of shape [num_layers, 0 for k, 1 for v, batch_size, length, hidden_dim]\n   generated_tokens.append(next_token_id.item())\n \n generated_text = tokenizer.batch_decode(generated_tokens)"
        },
        {
            "sha": "6eb5cc747b6e916f97b2694f59da7b9eddb4ac91",
            "filename": "docs/source/en/llm_tutorial_optimization.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e8194fe84f6622ea06593a2a371382bda43749c1/docs%2Fsource%2Fen%2Fllm_tutorial_optimization.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e8194fe84f6622ea06593a2a371382bda43749c1/docs%2Fsource%2Fen%2Fllm_tutorial_optimization.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fllm_tutorial_optimization.md?ref=e8194fe84f6622ea06593a2a371382bda43749c1",
            "patch": "@@ -484,7 +484,7 @@ for _ in range(5):\n   next_token_id = torch.argmax(next_logits, dim=-1)\n \n   print(\"shape of input_ids\", next_token_id.shape)\n-  print(\"length of key-value cache\", len(past_key_values[0][0]))  # past_key_values are of shape [num_layers, 0 for k, 1 for v, batch_size, length, hidden_dim]\n+  print(\"length of key-value cache\", past_key_values.get_seq_length())  # past_key_values are of shape [num_layers, 0 for k, 1 for v, batch_size, length, hidden_dim]\n   generated_tokens.append(next_token_id.item())\n \n generated_text = tokenizer.batch_decode(generated_tokens)"
        },
        {
            "sha": "d4ea10735ca317aee4a3db148f7c6ea0bb4d959c",
            "filename": "docs/source/ko/llm_tutorial_optimization.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e8194fe84f6622ea06593a2a371382bda43749c1/docs%2Fsource%2Fko%2Fllm_tutorial_optimization.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e8194fe84f6622ea06593a2a371382bda43749c1/docs%2Fsource%2Fko%2Fllm_tutorial_optimization.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fllm_tutorial_optimization.md?ref=e8194fe84f6622ea06593a2a371382bda43749c1",
            "patch": "@@ -457,7 +457,7 @@ for _ in range(5):\n   next_token_id = torch.argmax(next_logits, dim=-1)\n \n   print(\"shape of input_ids\", next_token_id.shape)\n-  print(\"length of key-value cache\", len(past_key_values[0][0]))  # past_key_values 형태: [num_layers, 0 for k, 1 for v, batch_size, length, hidden_dim]\n+  print(\"length of key-value cache\", past_key_values.get_seq_length())  # past_key_values 형태: [num_layers, 0 for k, 1 for v, batch_size, length, hidden_dim]\n   generated_tokens.append(next_token_id.item())\n \n generated_text = tokenizer.batch_decode(generated_tokens)"
        },
        {
            "sha": "80e081883fe2b68138a3a955b97ccfbe2b2a2a90",
            "filename": "src/transformers/models/big_bird/modeling_big_bird.py",
            "status": "modified",
            "additions": 1,
            "deletions": 7,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fmodeling_big_bird.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fmodeling_big_bird.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fmodeling_big_bird.py?ref=e8194fe84f6622ea06593a2a371382bda43749c1",
            "patch": "@@ -1689,13 +1689,7 @@ def forward(\n         batch_size, seq_length = input_shape\n         device = input_ids.device if input_ids is not None else inputs_embeds.device\n \n-        past_key_values_length = 0\n-        if past_key_values is not None:\n-            past_key_values_length = (\n-                past_key_values[0][0].shape[-2]\n-                if not isinstance(past_key_values, Cache)\n-                else past_key_values.get_seq_length()\n-            )\n+        past_key_values_length = 0 if past_key_values is None else past_key_values.get_seq_length()\n \n         if attention_mask is None:\n             attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)"
        },
        {
            "sha": "1793aa831d5ceb072c0cb8c2aa479ee50b66f7ba",
            "filename": "src/transformers/models/blip/modeling_blip_text.py",
            "status": "modified",
            "additions": 1,
            "deletions": 7,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip_text.py?ref=e8194fe84f6622ea06593a2a371382bda43749c1",
            "patch": "@@ -674,13 +674,7 @@ def forward(\n         else:\n             raise ValueError(\"You have to specify either input_ids or inputs_embeds or encoder_embeds\")\n \n-        past_key_values_length = 0\n-        if past_key_values is not None:\n-            past_key_values_length = (\n-                past_key_values[0][0].shape[-2]\n-                if not isinstance(past_key_values, Cache)\n-                else past_key_values.get_seq_length()\n-            )\n+        past_key_values_length = 0 if past_key_values is None else past_key_values.get_seq_length()\n \n         if attention_mask is None:\n             attention_mask = torch.ones((batch_size, seq_length + past_key_values_length)).to(device)"
        },
        {
            "sha": "caddf8b52fdddd2a73a52abf5874326f2ca1a0b4",
            "filename": "src/transformers/models/ctrl/modeling_ctrl.py",
            "status": "modified",
            "additions": 0,
            "deletions": 34,
            "changes": 34,
            "blob_url": "https://github.com/huggingface/transformers/blob/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Fctrl%2Fmodeling_ctrl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Fctrl%2Fmodeling_ctrl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fctrl%2Fmodeling_ctrl.py?ref=e8194fe84f6622ea06593a2a371382bda43749c1",
            "patch": "@@ -250,18 +250,6 @@ def forward(\n         **kwargs,  # NOOP kwargs, for now\n     ) -> Union[tuple[torch.Tensor], BaseModelOutputWithPast]:\n         r\"\"\"\n-        input_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\n-            `input_ids_length` = `sequence_length` if `past_key_values` is `None` else `past_key_values[0].shape[-2]`\n-            (`sequence_length` of input past key value states). Indices of input sequence tokens in the vocabulary.\n-\n-            If `past_key_values` is used, only input IDs that do not have their past calculated should be passed as\n-            `input_ids`.\n-\n-            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.__call__`] and\n-            [`PreTrainedTokenizer.encode`] for details.\n-\n-            [What are input IDs?](../glossary#input-ids)\n-\n         Example:\n \n         ```python\n@@ -424,17 +412,6 @@ def forward(\n         **kwargs,\n     ) -> Union[tuple[torch.Tensor], CausalLMOutputWithPast]:\n         r\"\"\"\n-        input_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\n-            `input_ids_length` = `sequence_length` if `past_key_values` is `None` else `past_key_values[0].shape[-2]`\n-            (`sequence_length` of input past key value states). Indices of input sequence tokens in the vocabulary.\n-\n-            If `past_key_values` is used, only input IDs that do not have their past calculated should be passed as\n-            `input_ids`.\n-\n-            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.__call__`] and\n-            [`PreTrainedTokenizer.encode`] for details.\n-\n-            [What are input IDs?](../glossary#input-ids)\n         labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n             Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\n             `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\n@@ -572,17 +549,6 @@ def forward(\n         return_dict: Optional[bool] = None,\n     ) -> Union[tuple[torch.Tensor], SequenceClassifierOutput]:\n         r\"\"\"\n-        input_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\n-            `input_ids_length` = `sequence_length` if `past_key_values` is `None` else `past_key_values[0].shape[-2]`\n-            (`sequence_length` of input past key value states). Indices of input sequence tokens in the vocabulary.\n-\n-            If `past_key_values` is used, only input IDs that do not have their past calculated should be passed as\n-            `input_ids`.\n-\n-            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.__call__`] and\n-            [`PreTrainedTokenizer.encode`] for details.\n-\n-            [What are input IDs?](../glossary#input-ids)\n         labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n             Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n             config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If"
        },
        {
            "sha": "910accfed4bd4d53eb63395009c2401c0a6c4f46",
            "filename": "src/transformers/models/megatron_bert/modeling_megatron_bert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 7,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Fmegatron_bert%2Fmodeling_megatron_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Fmegatron_bert%2Fmodeling_megatron_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmegatron_bert%2Fmodeling_megatron_bert.py?ref=e8194fe84f6622ea06593a2a371382bda43749c1",
            "patch": "@@ -644,13 +644,7 @@ def forward(\n         batch_size, seq_length = input_shape\n         device = input_ids.device if input_ids is not None else inputs_embeds.device\n \n-        past_key_values_length = 0\n-        if past_key_values is not None:\n-            past_key_values_length = (\n-                past_key_values[0][0].shape[-2]\n-                if not isinstance(past_key_values, Cache)\n-                else past_key_values.get_seq_length()\n-            )\n+        past_key_values_length = 0 if past_key_values is None else past_key_values.get_seq_length()\n \n         if attention_mask is None:\n             attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)"
        },
        {
            "sha": "58c85c6081269bb617e6feccf836858170eb9475",
            "filename": "src/transformers/models/pix2struct/modeling_pix2struct.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Fpix2struct%2Fmodeling_pix2struct.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Fpix2struct%2Fmodeling_pix2struct.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpix2struct%2Fmodeling_pix2struct.py?ref=e8194fe84f6622ea06593a2a371382bda43749c1",
            "patch": "@@ -160,7 +160,6 @@ def forward(\n         \"\"\"\n         # Input is (batch_size, seq_length, dim)\n         # Mask is (batch_size, key_length) (non-causal) or (batch_size, key_length, key_length)\n-        # past_key_values[0] is (batch_size, n_heads, q_len - 1, dim_per_head)\n         batch_size, seq_length = hidden_states.shape[:2]\n \n         def to_projection_shape(states):"
        },
        {
            "sha": "21ebe9d7487773136717c14ed9da72c6fe80162a",
            "filename": "src/transformers/models/rembert/modeling_rembert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 7,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Frembert%2Fmodeling_rembert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Frembert%2Fmodeling_rembert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frembert%2Fmodeling_rembert.py?ref=e8194fe84f6622ea06593a2a371382bda43749c1",
            "patch": "@@ -579,13 +579,7 @@ def forward(\n         batch_size, seq_length = input_shape\n         device = input_ids.device if input_ids is not None else inputs_embeds.device\n \n-        past_key_values_length = 0\n-        if past_key_values is not None:\n-            past_key_values_length = (\n-                past_key_values[0][0].shape[-2]\n-                if not isinstance(past_key_values, Cache)\n-                else past_key_values.get_seq_length()\n-            )\n+        past_key_values_length = 0 if past_key_values is None else past_key_values.get_seq_length()\n \n         if attention_mask is None:\n             attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)"
        },
        {
            "sha": "70f9da0980f102dc8fc86a391b98e533b95c2aa4",
            "filename": "src/transformers/models/roformer/modeling_roformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 7,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Froformer%2Fmodeling_roformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Froformer%2Fmodeling_roformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froformer%2Fmodeling_roformer.py?ref=e8194fe84f6622ea06593a2a371382bda43749c1",
            "patch": "@@ -736,13 +736,7 @@ def forward(\n         batch_size, seq_length = input_shape\n         device = input_ids.device if input_ids is not None else inputs_embeds.device\n \n-        past_key_values_length = 0\n-        if past_key_values is not None:\n-            past_key_values_length = (\n-                past_key_values[0][0].shape[-2]\n-                if not isinstance(past_key_values, Cache)\n-                else past_key_values.get_seq_length()\n-            )\n+        past_key_values_length = 0 if past_key_values is None else past_key_values.get_seq_length()\n \n         if attention_mask is None:\n             attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)"
        },
        {
            "sha": "abf82ced4a3f8f87d7ac3664819bb77c483f35f7",
            "filename": "src/transformers/models/speecht5/modeling_speecht5.py",
            "status": "modified",
            "additions": 1,
            "deletions": 8,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fmodeling_speecht5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e8194fe84f6622ea06593a2a371382bda43749c1/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fmodeling_speecht5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fmodeling_speecht5.py?ref=e8194fe84f6622ea06593a2a371382bda43749c1",
            "patch": "@@ -805,14 +805,7 @@ def forward(\n         else:\n             raise ValueError(\"You have to specify `decoder_input_ids`\")\n \n-        past_key_values_length = 0\n-        if past_key_values is not None:\n-            past_key_values_length = (\n-                past_key_values[0][0].shape[-2]\n-                if not isinstance(past_key_values, Cache)\n-                else past_key_values.get_seq_length()\n-            )\n-\n+        past_key_values_length = 0 if past_key_values is None else past_key_values.get_seq_length()\n         positions = self.embed_positions(input_ids, past_key_values_length)\n \n         inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale"
        },
        {
            "sha": "b5e8984ce6f737d5e4721c72409f33b53203b2d2",
            "filename": "tests/generation/test_utils.py",
            "status": "modified",
            "additions": 13,
            "deletions": 8,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/e8194fe84f6622ea06593a2a371382bda43749c1/tests%2Fgeneration%2Ftest_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e8194fe84f6622ea06593a2a371382bda43749c1/tests%2Fgeneration%2Ftest_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fgeneration%2Ftest_utils.py?ref=e8194fe84f6622ea06593a2a371382bda43749c1",
            "patch": "@@ -4665,7 +4665,7 @@ def test_generate_custom_cache_position(self):\n             value=1,\n         )\n         inputs_2b[\"past_key_values\"] = outputs_1b.past_key_values\n-        cache_length_1b = outputs_1b.past_key_values[0][0].shape[-2]\n+        cache_length_1b = outputs_1b.past_key_values.get_seq_length()\n         inputs_2b[\"cache_position\"] = torch.arange(\n             cache_length_1b,\n             cache_length_1b + inputs_2b[\"input_ids\"].shape[1],\n@@ -4677,14 +4677,19 @@ def test_generate_custom_cache_position(self):\n \n         # The two sets of generated text and past kv should be equal to each other\n         self.assertTrue(has_similar_generate_outputs(traditional_outputs, incremental_outputs))\n-        for layer_idx in range(len(traditional_outputs.past_key_values)):\n-            for kv_idx in range(len(traditional_outputs.past_key_values[layer_idx])):\n-                self.assertTrue(\n-                    torch.allclose(\n-                        traditional_outputs.past_key_values[layer_idx][kv_idx],\n-                        incremental_outputs.past_key_values[layer_idx][kv_idx],\n+        cache1, cache2 = traditional_outputs.past_key_values, incremental_outputs.past_key_values\n+        for idx in range(len(cache1)):\n+            if isinstance(cache1, EncoderDecoderCache):\n+                for subcache in [\"self_attention_cache\", \"cross_attention_cache\"]:\n+                    torch.testing.assert_close(\n+                        getattr(cache1, subcache).layers[idx].keys, getattr(cache2, subcache).layers[idx].keys\n                     )\n-                )\n+                    torch.testing.assert_close(\n+                        getattr(cache1, subcache).layers[idx].values, getattr(cache2, subcache).layers[idx].values\n+                    )\n+            else:\n+                torch.testing.assert_close(cache1.layers[idx].keys, cache2.layers[idx].keys)\n+                torch.testing.assert_close(cache1.layers[idx].values, cache2.layers[idx].values)\n \n     @pytest.mark.generate\n     @parameterized.expand("
        }
    ],
    "stats": {
        "total": 111,
        "additions": 22,
        "deletions": 89
    }
}