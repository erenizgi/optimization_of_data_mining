{
    "author": "MekkCyber",
    "message": "[Quantization]Â Misc tests fixes (#42940)\n\n* initial commit\n\n* update",
    "sha": "d7dd443a4cdbdc39b8d45c98f3edd2c0840bdbcb",
    "files": [
        {
            "sha": "949c493c1126605014d785e54a430afc28ae0e8c",
            "filename": "src/transformers/conversion_mapping.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/d7dd443a4cdbdc39b8d45c98f3edd2c0840bdbcb/src%2Ftransformers%2Fconversion_mapping.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d7dd443a4cdbdc39b8d45c98f3edd2c0840bdbcb/src%2Ftransformers%2Fconversion_mapping.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fconversion_mapping.py?ref=d7dd443a4cdbdc39b8d45c98f3edd2c0840bdbcb",
            "patch": "@@ -142,12 +142,12 @@ def _build_checkpoint_conversion_mapping():\n     if hasattr(torch.nn.utils.parametrizations, \"weight_norm\"):\n         mapping[\"legacy\"] += [\n             WeightRenaming(\n-                source_patterns=\"weight_g\",\n-                target_patterns=\"parametrizations.weight.original0\",\n+                source_patterns=\".weight_g$\",\n+                target_patterns=\".parametrizations.weight.original0\",\n             ),\n             WeightRenaming(\n-                source_patterns=\"weight_v\",\n-                target_patterns=\"parametrizations.weight.original1\",\n+                source_patterns=\".weight_v$\",\n+                target_patterns=\".parametrizations.weight.original1\",\n             ),\n         ]\n     else:"
        },
        {
            "sha": "e700cb34e992f25fdbfd9f51db1e7f8660c9b9e7",
            "filename": "src/transformers/core_model_loading.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d7dd443a4cdbdc39b8d45c98f3edd2c0840bdbcb/src%2Ftransformers%2Fcore_model_loading.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d7dd443a4cdbdc39b8d45c98f3edd2c0840bdbcb/src%2Ftransformers%2Fcore_model_loading.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcore_model_loading.py?ref=d7dd443a4cdbdc39b8d45c98f3edd2c0840bdbcb",
            "patch": "@@ -302,6 +302,8 @@ def __post_init__(self):\n         for i, pattern in enumerate(self.target_patterns):\n             # Some mapping contains `^` to notify start of string when matching -> remove it during reverse mapping\n             pattern = pattern.removeprefix(\"^\")\n+            # Some mapping contains `$` to notify end of string when matching -> remove it during reverse mapping\n+            pattern = pattern.removesuffix(\"$\")\n             # Remove negative lookahead if any. This is ugly but needed for reverse mapping of Qwen2.5 and Sam3!\n             pattern = re.sub(r\"\\(\\?!.+\\)\", \"\", pattern)\n             # Allow capturing groups in patterns, i.e. to add/remove a prefix to all keys (e.g. timm_wrapper, sam3)"
        },
        {
            "sha": "7172e981da227c493fca56c7a19c8f09838cc053",
            "filename": "tests/quantization/gptq/test_gptq.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/d7dd443a4cdbdc39b8d45c98f3edd2c0840bdbcb/tests%2Fquantization%2Fgptq%2Ftest_gptq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d7dd443a4cdbdc39b8d45c98f3edd2c0840bdbcb/tests%2Fquantization%2Fgptq%2Ftest_gptq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fquantization%2Fgptq%2Ftest_gptq.py?ref=d7dd443a4cdbdc39b8d45c98f3edd2c0840bdbcb",
            "patch": "@@ -70,6 +70,7 @@ def test_from_dict(self):\n         self.assertEqual(dict[\"bits\"], quantization_config.bits)\n \n     @require_optimum\n+    @require_gptqmodel\n     def test_optimum_config(self):\n         from optimum.gptq import GPTQQuantizer\n "
        },
        {
            "sha": "96080ab0566c91236e3202b919688bb1221e9994",
            "filename": "tests/quantization/mxfp4/test_mxfp4.py",
            "status": "modified",
            "additions": 0,
            "deletions": 15,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/d7dd443a4cdbdc39b8d45c98f3edd2c0840bdbcb/tests%2Fquantization%2Fmxfp4%2Ftest_mxfp4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d7dd443a4cdbdc39b8d45c98f3edd2c0840bdbcb/tests%2Fquantization%2Fmxfp4%2Ftest_mxfp4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fquantization%2Fmxfp4%2Ftest_mxfp4.py?ref=d7dd443a4cdbdc39b8d45c98f3edd2c0840bdbcb",
            "patch": "@@ -225,21 +225,6 @@ def test_quantizer_validation_missing_triton_pre_quantized_no_dequantize(self):\n             quantizer.validate_environment()\n             self.assertTrue(quantizer.quantization_config.dequantize)\n \n-    def test_update_dtype(self):\n-        \"\"\"Test torch dtype updating\"\"\"\n-        from transformers.quantizers.quantizer_mxfp4 import Mxfp4HfQuantizer\n-\n-        config = Mxfp4Config()\n-        quantizer = Mxfp4HfQuantizer(config)\n-\n-        # Should default to bfloat16\n-        result_dtype = quantizer.update_dtype(None)\n-        self.assertEqual(result_dtype, torch.bfloat16)\n-\n-        # Should preserve existing dtype\n-        result_dtype = quantizer.update_dtype(torch.float32)\n-        self.assertEqual(result_dtype, torch.float32)\n-\n     def test_get_param_name_dequantize(self):\n         \"\"\"Test parameter name updating when dequantizing\"\"\"\n         from transformers.quantizers.quantizer_mxfp4 import Mxfp4HfQuantizer"
        }
    ],
    "stats": {
        "total": 26,
        "additions": 7,
        "deletions": 19
    }
}