{
    "author": "gante",
    "message": "[tests] reset logs in `torch.compile` test (#37894)",
    "sha": "8e8025b384f11e786b617304c724d0d28a308552",
    "files": [
        {
            "sha": "46a1b90001b022c2933223179ba042d44084d662",
            "filename": "tests/generation/test_utils.py",
            "status": "modified",
            "additions": 21,
            "deletions": 17,
            "changes": 38,
            "blob_url": "https://github.com/huggingface/transformers/blob/8e8025b384f11e786b617304c724d0d28a308552/tests%2Fgeneration%2Ftest_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8e8025b384f11e786b617304c724d0d28a308552/tests%2Fgeneration%2Ftest_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fgeneration%2Ftest_utils.py?ref=8e8025b384f11e786b617304c724d0d28a308552",
            "patch": "@@ -2175,23 +2175,27 @@ def test_generate_compile_model_forward(self):\n \n             compiled_outputs = []\n             # Uses a context manager to catch recompilation logs. If there is any recompilation, this test fails.\n-            torch._logging.set_logs(recompiles_verbose=True)\n-            logger = logging.get_logger(\"torch._dynamo.guards\")\n-            with CaptureLogger(logger) as cl:\n-                for model_inputs in model_input_sets:\n-                    # with torch.compiler.set_stance(\"fail_on_recompile\"):\n-                    gen_out = model.generate(**model_inputs, **generation_kwargs)\n-                    compiled_outputs.append(gen_out)\n-                    # sanity checks\n-                    decoder_cache = (\n-                        gen_out.past_key_values.self_attention_cache\n-                        if config.is_encoder_decoder\n-                        else gen_out.past_key_values\n-                    )\n-                    self.assertFalse(isinstance(decoder_cache, DynamicCache))\n-                    self.assertTrue(decoder_cache.is_compileable)\n-                    # our auto compile should have been called\n-                    self.assertTrue(hasattr(model_to_be_compiled, \"_compiled_call\"))\n+            # Try/Finally is used to ensure that the log options are reset even if an error is raised.\n+            try:\n+                torch._logging.set_logs(recompiles_verbose=True)\n+                logger = logging.get_logger(\"torch._dynamo.guards\")\n+                with CaptureLogger(logger) as cl:\n+                    for model_inputs in model_input_sets:\n+                        # with torch.compiler.set_stance(\"fail_on_recompile\"):\n+                        gen_out = model.generate(**model_inputs, **generation_kwargs)\n+                        compiled_outputs.append(gen_out)\n+                        # sanity checks\n+                        decoder_cache = (\n+                            gen_out.past_key_values.self_attention_cache\n+                            if config.is_encoder_decoder\n+                            else gen_out.past_key_values\n+                        )\n+                        self.assertFalse(isinstance(decoder_cache, DynamicCache))\n+                        self.assertTrue(decoder_cache.is_compileable)\n+                        # our auto compile should have been called\n+                        self.assertTrue(hasattr(model_to_be_compiled, \"_compiled_call\"))\n+            finally:\n+                torch._logging.set_logs()\n \n             if \"Recompiling\" in cl.out or (\"guard\" in cl.out and \"failure\" in cl.out):\n                 raise RuntimeError("
        }
    ],
    "stats": {
        "total": 38,
        "additions": 21,
        "deletions": 17
    }
}