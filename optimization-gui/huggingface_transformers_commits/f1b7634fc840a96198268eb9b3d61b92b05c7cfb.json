{
    "author": "ydshieh",
    "message": "Trigger GitHub CI with a comment on PR (#35211)\n\n* fix\r\n\r\n* fix\r\n\r\n* comment\r\n\r\n* final\r\n\r\n* final\r\n\r\n* final\r\n\r\n---------\r\n\r\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "f1b7634fc840a96198268eb9b3d61b92b05c7cfb",
    "files": [
        {
            "sha": "d6ef0af9ff83b5af470373b4591709b1cce8b25d",
            "filename": ".github/workflows/self-comment-ci.yml",
            "status": "added",
            "additions": 253,
            "deletions": 0,
            "changes": 253,
            "blob_url": "https://github.com/huggingface/transformers/blob/f1b7634fc840a96198268eb9b3d61b92b05c7cfb/.github%2Fworkflows%2Fself-comment-ci.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/f1b7634fc840a96198268eb9b3d61b92b05c7cfb/.github%2Fworkflows%2Fself-comment-ci.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-comment-ci.yml?ref=f1b7634fc840a96198268eb9b3d61b92b05c7cfb",
            "patch": "@@ -0,0 +1,253 @@\n+name: PR comment GitHub CI\n+\n+on:\n+  issue_comment:\n+    types:\n+      - created\n+    branches-ignore:\n+      - main\n+concurrency:\n+  group: ${{ github.workflow }}-${{ github.event.issue.number }}-${{ startsWith(github.event.comment.body, 'run-slow') || startsWith(github.event.comment.body, 'run slow') || startsWith(github.event.comment.body, 'run_slow') }}\n+  cancel-in-progress: true\n+\n+jobs:\n+  get-pr-number:\n+    runs-on: ubuntu-22.04\n+    name: Get PR number\n+    # For security: only allow team members to run\n+    if: contains(fromJSON('[\"ydshieh\", \"ArthurZucker\", \"zucchini-nlp\", \"qubvel\", \"molbap\", \"gante\", \"LysandreJik\", \"Cyrilvallez\"]'), github.actor)\n+    outputs:\n+      PR_NUMBER: ${{ steps.set_pr_number.outputs.PR_NUMBER }}\n+    steps:\n+      - name: Get PR number\n+        shell: bash\n+        run: |\n+          if [[ \"${{ github.event.issue.number }}\" != \"\" && \"${{ github.event.issue.pull_request }}\" != \"\" ]]; then\n+            echo \"PR_NUMBER=${{ github.event.issue.number }}\" >> $GITHUB_ENV\n+          else\n+            echo \"PR_NUMBER=\" >> $GITHUB_ENV\n+          fi\n+\n+      - name: Check PR number\n+        shell: bash\n+        run: |\n+          echo \"${{ env.PR_NUMBER }}\"\n+\n+      - name: Set PR number\n+        id: set_pr_number\n+        run: echo \"PR_NUMBER=${{ env.PR_NUMBER }}\" >> \"$GITHUB_OUTPUT\"\n+\n+  get-sha:\n+    runs-on: ubuntu-22.04\n+    needs: get-pr-number\n+    if: ${{ needs.get-pr-number.outputs.PR_NUMBER != ''}}\n+    outputs:\n+      PR_HEAD_SHA: ${{ steps.get_sha.outputs.PR_HEAD_SHA }}\n+    steps:\n+      - uses: actions/checkout@v4\n+        with:\n+          fetch-depth: \"0\"\n+          ref: \"refs/pull/${{needs.get-pr-number.outputs.PR_NUMBER}}/merge\"\n+\n+      - name: Get SHA\n+        id: get_sha\n+        env:\n+          PR_NUMBER: ${{needs.get-pr-number.outputs.PR_NUMBER}}\n+        run: |\n+            git fetch origin refs/pull/$PR_NUMBER/head:refs/remotes/pull/$PR_NUMBER/head\n+            git checkout refs/remotes/pull/$PR_NUMBER/head\n+            echo \"PR_HEAD_SHA: $(git log -1 --format=%H)\"\n+            echo \"PR_HEAD_SHA=$(git log -1 --format=%H)\" >> \"$GITHUB_OUTPUT\"\n+\n+  # use a python script to handle this complex logic\n+  # case 1: `run-slow` (auto. infer with limited number of models, but in particular, new model)\n+  # case 2: `run-slow model_1, model_2`\n+  get-tests:\n+    runs-on: ubuntu-22.04\n+    needs: get-pr-number\n+    if: ${{ needs.get-pr-number.outputs.PR_NUMBER != ''}}\n+    permissions: write-all\n+    outputs:\n+      models: ${{ steps.models_to_run.outputs.models }}\n+    steps:\n+      - uses: actions/checkout@v4\n+        with:\n+          fetch-depth: \"0\"\n+          ref: \"refs/pull/${{needs.get-pr-number.outputs.PR_NUMBER}}/merge\"\n+\n+      - name: Get models to test\n+        env:\n+          PR_COMMENT: ${{ github.event.comment.body }}\n+        run: |\n+          python -m pip install GitPython\n+          python utils/pr_slow_ci_models.py --message \"$PR_COMMENT\" | tee output.txt\n+          echo \"models=$(tail -n 1 output.txt)\" >> $GITHUB_ENV\n+\n+      - name: Show models to test\n+        id: models_to_run\n+        run: |\n+          echo \"${{ env.models }}\"\n+          echo \"models=${{ env.models }}\" >> $GITHUB_ENV\n+          echo \"models=${{ env.models }}\" >> $GITHUB_OUTPUT\n+\n+      - name: Reply to the comment\n+        if: ${{ env.models != '[]' }}\n+        env:\n+          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n+        run: |\n+          gh api \\\n+            --method POST \\\n+            -H \"Accept: application/vnd.github+json\" \\\n+            -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n+            repos/${{ github.repository }}/issues/${{ needs.get-pr-number.outputs.PR_NUMBER }}/comments \\\n+            -f \"body=This comment contains run-slow, running the specified jobs: ${{ env.models }} ...\"\n+\n+  create_run:\n+    name: Create run\n+    if: ${{ needs.get-tests.outputs.models != '[]' }}\n+    needs: [get-sha, get-tests]\n+    permissions: write-all\n+    runs-on: ubuntu-22.04\n+    steps:\n+      - name: Create Run\n+        id: create_run\n+        env:\n+          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n+          # Create a commit status (pending) for a run of this workflow. The status has to be updated later in `update_run_status`.\n+          # See https://docs.github.com/en/rest/commits/statuses?apiVersion=2022-11-28#create-a-commit-status\n+          GITHUB_RUN_URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\n+        run: |\n+          gh api \\\n+            --method POST \\\n+            -H \"Accept: application/vnd.github+json\" \\\n+            -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n+            repos/${{ github.repository }}/statuses/${{ needs.get-sha.outputs.PR_HEAD_SHA }} \\\n+            -f \"target_url=$GITHUB_RUN_URL\" -f \"state=pending\" -f \"description=Slow CI job\" -f \"context=pytest/custom-tests\"\n+\n+  run_models_gpu:\n+      name: Run all tests for the model\n+      if: ${{ needs.get-tests.outputs.models != '[]' }}\n+      needs: [get-pr-number, get-tests, create_run]\n+      strategy:\n+        fail-fast: false\n+        matrix:\n+          folders: ${{ fromJson(needs.get-tests.outputs.models) }}\n+          machine_type: [aws-g4dn-2xlarge-cache, aws-g4dn-12xlarge-cache]\n+      runs-on:\n+         group: '${{ matrix.machine_type }}'\n+      container:\n+        image: huggingface/transformers-all-latest-gpu\n+        options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n+      steps:\n+      - name: Echo input and matrix info\n+        shell: bash\n+        run: |\n+          echo \"${{ matrix.folders }}\"\n+\n+      - name: Echo folder ${{ matrix.folders }}\n+        shell: bash\n+        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n+        # set the artifact folder names (because the character `/` is not allowed).\n+        run: |\n+          echo \"${{ matrix.folders }}\"\n+          matrix_folders=${{ matrix.folders }}\n+          matrix_folders=${matrix_folders/'models/'/'models_'}\n+          echo \"$matrix_folders\"\n+          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n+\n+      - name: Checkout to PR merge commit\n+        working-directory: /transformers\n+        run: |\n+            git fetch origin refs/pull/${{ needs.get-pr-number.outputs.PR_NUMBER }}/merge:refs/remotes/pull/${{ needs.get-pr-number.outputs.PR_NUMBER }}/merge\n+            git checkout refs/remotes/pull/${{ needs.get-pr-number.outputs.PR_NUMBER }}/merge\n+            git log -1 --format=%H\n+\n+      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n+        working-directory: /transformers\n+        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n+\n+      - name: NVIDIA-SMI\n+        run: |\n+          nvidia-smi\n+\n+      - name: Set `machine_type` for report and artifact names\n+        working-directory: /transformers\n+        shell: bash\n+        run: |\n+          echo \"${{ matrix.machine_type }}\"\n+          if [ \"${{ matrix.machine_type }}\" = \"aws-g4dn-2xlarge-cache\" ]; then\n+            machine_type=single-gpu\n+          elif [ \"${{ matrix.machine_type }}\" = \"aws-g4dn-12xlarge-cache\" ]; then\n+            machine_type=multi-gpu\n+          else\n+            machine_type=${{ matrix.machine_type }}\n+          fi\n+          echo \"$machine_type\"\n+          echo \"machine_type=$machine_type\" >> $GITHUB_ENV\n+\n+      - name: Environment\n+        working-directory: /transformers\n+        run: |\n+          python3 utils/print_env.py\n+\n+      - name: Show installed libraries and their versions\n+        working-directory: /transformers\n+        run: pip freeze\n+\n+      - name: Run all tests on GPU\n+        working-directory: /transformers\n+        run: |\n+          export CUDA_VISIBLE_DEVICES=\"$(python3 utils/set_cuda_devices_for_ci.py --test_folder ${{ matrix.folders }})\"\n+          echo $CUDA_VISIBLE_DEVICES\n+          python3 -m pytest -v -rsfE --make-reports=${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports tests/${{ matrix.folders }}\n+\n+      - name: Failure short reports\n+        if: ${{ failure() }}\n+        continue-on-error: true\n+        run: cat /transformers/reports/${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports/failures_short.txt\n+\n+      - name: Make sure report directory exists\n+        shell: bash\n+        run: |\n+          mkdir -p /transformers/reports/${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports\n+          echo \"hello\" > /transformers/reports/${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports/hello.txt\n+          echo \"${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports\"\n+\n+      - name: \"Test suite reports artifacts: ${{ env.machine_type }}_run_models_gpu_${{ env.matrix_folders }}_test_reports\"\n+        if: ${{ always() }}\n+        uses: actions/upload-artifact@v4\n+        with:\n+          name: ${{ env.machine_type }}_run_models_gpu_${{ env.matrix_folders }}_test_reports\n+          path: /transformers/reports/${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports\n+\n+  update_run_status:\n+    name: Update Check Run Status\n+    needs: [get-sha, create_run, run_models_gpu]\n+    permissions: write-all\n+    if: ${{ always() && needs.create_run.result == 'success' }}\n+    runs-on: ubuntu-22.04\n+    env:\n+      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n+      GITHUB_RUN_URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\n+    steps:\n+      - name: Get `run_models_gpu` job status\n+        run: |\n+          echo \"${{ needs.run_models_gpu.result }}\"\n+          if [ \"${{ needs.run_models_gpu.result }}\" = \"cancelled\" ]; then\n+            echo \"STATUS=failure\" >> $GITHUB_ENV\n+          elif [ \"${{ needs.run_models_gpu.result }}\" = \"skipped\" ]; then\n+            echo \"STATUS=success\" >> $GITHUB_ENV\n+          else\n+            echo \"STATUS=${{ needs.run_models_gpu.result }}\" >> $GITHUB_ENV\n+          fi\n+\n+      - name: Update PR commit statuses\n+        run: |\n+          echo \"${{ needs.run_models_gpu.result }}\"\n+          echo \"${{ env.STATUS }}\"\n+          gh api \\\n+            --method POST \\\n+            -H \"Accept: application/vnd.github+json\" \\\n+            -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n+            repos/${{ github.repository }}/statuses/${{ needs.get-sha.outputs.PR_HEAD_SHA }} \\\n+            -f \"target_url=$GITHUB_RUN_URL\" -f \"state=${{ env.STATUS }}\" -f \"description=Slow CI job\" -f \"context=pytest/custom-tests\""
        },
        {
            "sha": "43fcecd8def21e00444581a79886cccf9ad76d4a",
            "filename": ".github/workflows/self-pr-slow-ci.yml",
            "status": "removed",
            "additions": 0,
            "deletions": 151,
            "changes": 151,
            "blob_url": "https://github.com/huggingface/transformers/blob/c7e48053aab09ad11efa2ad12513e9ab56f29563/.github%2Fworkflows%2Fself-pr-slow-ci.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/c7e48053aab09ad11efa2ad12513e9ab56f29563/.github%2Fworkflows%2Fself-pr-slow-ci.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-pr-slow-ci.yml?ref=c7e48053aab09ad11efa2ad12513e9ab56f29563",
            "patch": "@@ -1,151 +0,0 @@\n-name: PR slow CI\n-\n-on:\n-  pull_request:\n-    paths:\n-      - \"src/transformers/models/*/modeling_*.py\"\n-      - \"tests/**/test_*.py\"\n-\n-concurrency:\n-  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}\n-  cancel-in-progress: true\n-\n-env:\n-  HF_HOME: /mnt/cache\n-  TRANSFORMERS_IS_CI: yes\n-  OMP_NUM_THREADS: 8\n-  MKL_NUM_THREADS: 8\n-  RUN_SLOW: yes\n-  # For gated repositories, we still need to agree to share information on the Hub repo. page in order to get access.\n-  # This token is created under the bot `hf-transformers-bot`.\n-  HF_HUB_READ_TOKEN: ${{ secrets.HF_HUB_READ_TOKEN }}\n-  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}\n-  TF_FORCE_GPU_ALLOW_GROWTH: true\n-  RUN_PT_TF_CROSS_TESTS: 1\n-  CUDA_VISIBLE_DEVICES: 0,1\n-\n-jobs:\n-  find_models_to_run:\n-      runs-on: ubuntu-22.04\n-      name: Find models to run slow tests\n-      # Triggered only if the required label `run-slow` is added\n-      if: ${{ contains(github.event.pull_request.labels.*.name, 'run-slow') }}\n-      outputs:\n-        models: ${{ steps.models_to_run.outputs.models }}\n-      steps:\n-        - uses: actions/checkout@v4\n-          with:\n-            fetch-depth: \"0\"\n-            ref: ${{ github.event.pull_request.head.sha }}\n-\n-        - name: Get commit message\n-          run: |\n-            echo \"commit_message=$(git show -s --format=%s)\" >> $GITHUB_ENV\n-\n-        - name: Get models to run slow tests\n-          run: |\n-            echo \"${{ env.commit_message }}\"\n-            python -m pip install GitPython\n-            python utils/pr_slow_ci_models.py --commit_message \"${{ env.commit_message }}\" | tee output.txt\n-            echo \"models=$(tail -n 1 output.txt)\" >> $GITHUB_ENV\n-\n-        - name: Models to run slow tests\n-          id: models_to_run\n-          run: |\n-            echo \"${{ env.models }}\"\n-            echo \"models=${{ env.models }}\" >> $GITHUB_OUTPUT\n-\n-  run_models_gpu:\n-      name: Run all tests for the model\n-      # Triggered only `find_models_to_run` is triggered (label `run-slow` is added) which gives the models to run\n-      # (either a new model PR or via a commit message)\n-      if: ${{ needs.find_models_to_run.outputs.models != '[]' }}\n-      needs: find_models_to_run\n-      strategy:\n-        fail-fast: false\n-        matrix:\n-          folders: ${{ fromJson(needs.find_models_to_run.outputs.models) }}\n-          machine_type: [aws-g4dn-2xlarge-cache, aws-g4dn-12xlarge-cache]\n-      runs-on:\n-        group: '${{ matrix.machine_type }}'\n-      container:\n-        image: huggingface/transformers-all-latest-gpu\n-        options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n-      steps:\n-      - name: Echo input and matrix info\n-        shell: bash\n-        run: |\n-          echo \"${{ matrix.folders }}\"\n-\n-      - name: Echo folder ${{ matrix.folders }}\n-        shell: bash\n-        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n-        # set the artifact folder names (because the character `/` is not allowed).\n-        run: |\n-          echo \"${{ matrix.folders }}\"\n-          matrix_folders=${{ matrix.folders }}\n-          matrix_folders=${matrix_folders/'models/'/'models_'}\n-          echo \"$matrix_folders\"\n-          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n-\n-      - name: Update clone\n-        working-directory: /transformers\n-        run: git fetch && git fetch origin pull/${{ github.event.pull_request.number }}/head:pull/${{ github.event.pull_request.number }}/merge && git checkout pull/${{ github.event.pull_request.number }}/merge\n-\n-      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n-        working-directory: /transformers\n-        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e . && python3 -m pip install --upgrade torch torchaudio torchvision\n-\n-      - name: NVIDIA-SMI\n-        run: |\n-          nvidia-smi\n-\n-      - name: Set `machine_type` for report and artifact names\n-        working-directory: /transformers\n-        shell: bash\n-        run: |\n-          echo \"${{ matrix.machine_type }}\"\n-          if [ \"${{ matrix.machine_type }}\" = \"aws-g4dn-2xlarge-cache\" ]; then\n-            machine_type=single-gpu\n-          elif [ \"${{ matrix.machine_type }}\" = \"aws-g4dn-12xlarge-cache\" ]; then\n-            machine_type=multi-gpu\n-          else\n-            machine_type=${{ matrix.machine_type }}\n-          fi\n-          echo \"$machine_type\"\n-          echo \"machine_type=$machine_type\" >> $GITHUB_ENV    \n-\n-      - name: Environment\n-        working-directory: /transformers\n-        run: |\n-          python3 utils/print_env.py\n-\n-      - name: Show installed libraries and their versions\n-        working-directory: /transformers\n-        run: pip freeze\n-\n-      - name: Run all tests on GPU\n-        working-directory: /transformers\n-        run: |\n-          export CUDA_VISIBLE_DEVICES=\"$(python3 utils/set_cuda_devices_for_ci.py --test_folder ${{ matrix.folders }})\"\n-          echo $CUDA_VISIBLE_DEVICES\n-          python3 -m pytest -v -rsfE --make-reports=${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports tests/${{ matrix.folders }}\n-\n-      - name: Failure short reports\n-        if: ${{ failure() }}\n-        continue-on-error: true\n-        run: cat /transformers/reports/${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports/failures_short.txt\n-\n-      - name: Make sure report directory exists\n-        shell: bash\n-        run: |\n-          mkdir -p /transformers/reports/${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports\n-          echo \"hello\" > /transformers/reports/${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports/hello.txt\n-          echo \"${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports\"\n-\n-      - name: \"Test suite reports artifacts: ${{ env.machine_type }}_run_models_gpu_${{ env.matrix_folders }}_test_reports\"\n-        if: ${{ always() }}\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: ${{ env.machine_type }}_run_models_gpu_${{ env.matrix_folders }}_test_reports\n-          path: /transformers/reports/${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports"
        },
        {
            "sha": "c6a24c0f219ae754ac6d2b725cc367f5552f57d4",
            "filename": "utils/pr_slow_ci_models.py",
            "status": "modified",
            "additions": 35,
            "deletions": 26,
            "changes": 61,
            "blob_url": "https://github.com/huggingface/transformers/blob/f1b7634fc840a96198268eb9b3d61b92b05c7cfb/utils%2Fpr_slow_ci_models.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f1b7634fc840a96198268eb9b3d61b92b05c7cfb/utils%2Fpr_slow_ci_models.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fpr_slow_ci_models.py?ref=f1b7634fc840a96198268eb9b3d61b92b05c7cfb",
            "patch": "@@ -15,19 +15,20 @@\n \"\"\"\n This script is used to get the models for which to run slow CI.\n \n-A new model added in a pull request will be included, as well as models specified in a commit message with a prefix\n-`[run-slow]`, `[run_slow]` or `[run slow]`. For example, the commit message `[run_slow]bert, gpt2` will give `bert` and\n-`gpt2`.\n+A new model added in a pull request will be included, as well as models specified in a GitHub pull request's comment\n+with a prefix `run-slow`, `run_slow` or `run slow`. For example, the commit message `run_slow: bert, gpt2` will give\n+`bert` and `gpt2`.\n \n Usage:\n \n ```bash\n-python utils/pr_slow_ci_models.py.py\n+python utils/pr_slow_ci_models.py\n ```\n \"\"\"\n \n import argparse\n import re\n+import string\n from pathlib import Path\n from typing import List\n \n@@ -89,7 +90,7 @@ def get_new_python_files() -> List[str]:\n \n def get_new_model():\n     new_files = get_new_python_files()\n-    reg = re.compile(r\"src/transformers/(models/.*)/modeling_.*\\.py\")\n+    reg = re.compile(r\"src/transformers/models/(.*)/modeling_.*\\.py\")\n \n     new_model = \"\"\n     for x in new_files:\n@@ -101,45 +102,53 @@ def get_new_model():\n     return new_model\n \n \n-def parse_commit_message(commit_message: str) -> str:\n+def parse_message(message: str) -> str:\n     \"\"\"\n-    Parses the commit message to find the models specified in it to run slow CI.\n+    Parses a GitHub pull request's comment to find the models specified in it to run slow CI.\n \n     Args:\n-        commit_message (`str`): The commit message of the current commit.\n+        message (`str`): The body of a GitHub pull request's comment.\n \n     Returns:\n-        `str`: The substring in `commit_message` after `[run-slow]`, [run_slow]` or [run slow]`. If no such prefix is\n-         found, the empty string is returned.\n+        `str`: The substring in `message` after `run-slow`, run_slow` or run slow`. If no such prefix is found, the\n+        empty string is returned.\n     \"\"\"\n-    if commit_message is None:\n+    if message is None:\n         return \"\"\n \n-    command_search = re.search(r\"\\[([^\\]]*)\\](.*)\", commit_message)\n-    if command_search is None:\n-        return \"\"\n+    message = message.strip().lower()\n \n-    command = command_search.groups()[0]\n-    command = command.lower().replace(\"-\", \" \").replace(\"_\", \" \")\n-    run_slow = command == \"run slow\"\n-    if run_slow:\n-        models = command_search.groups()[1].strip()\n-        return models\n-    else:\n+    # run-slow: model_1, model_2\n+    if not message.startswith((\"run-slow\", \"run_slow\", \"run slow\")):\n         return \"\"\n+    message = message[len(\"run slow\") :]\n+    # remove leading `:`\n+    while message.strip().startswith(\":\"):\n+        message = message.strip()[1:]\n+\n+    return message\n+\n+\n+def get_models(message: str):\n+    models = parse_message(message)\n+    return models.replace(\",\", \" \").split()\n \n \n-def get_models(commit_message: str):\n-    models = parse_commit_message(commit_message)\n-    return [f\"models/{x}\" for x in models.replace(\",\", \" \").split()]\n+def check_model_names(model_name: str):\n+    allowed = string.ascii_letters + string.digits + \"_\"\n+    return not (model_name.startswith(\"_\") or model_name.endswith(\"_\")) and all(c in allowed for c in model_name)\n \n \n if __name__ == \"__main__\":\n     parser = argparse.ArgumentParser()\n-    parser.add_argument(\"--commit_message\", type=str, default=\"\", help=\"The commit message.\")\n+    parser.add_argument(\"--message\", type=str, default=\"\", help=\"The content of a comment.\")\n     args = parser.parse_args()\n \n     new_model = get_new_model()\n-    specified_models = get_models(args.commit_message)\n+    specified_models = get_models(args.message)\n     models = ([] if new_model == \"\" else [new_model]) + specified_models\n+    # a guard for strange model names\n+    models = [model for model in models if check_model_names(model)]\n+    # Add \"models/\"\n+    models = [f\"models/{model}\" for model in models]\n     print(sorted(set(models)))"
        }
    ],
    "stats": {
        "total": 465,
        "additions": 288,
        "deletions": 177
    }
}