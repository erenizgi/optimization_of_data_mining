{
    "author": "faaany",
    "message": "[docs] minor fixes in `models.md` (#38193)\n\nminor gix",
    "sha": "7d93f93f83bce983d6bb142155444f6e992a3ca9",
    "files": [
        {
            "sha": "4cef0d1553ef37cad84e538a730865053288b842",
            "filename": "docs/source/en/models.md",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d93f93f83bce983d6bb142155444f6e992a3ca9/docs%2Fsource%2Fen%2Fmodels.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d93f93f83bce983d6bb142155444f6e992a3ca9/docs%2Fsource%2Fen%2Fmodels.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodels.md?ref=7d93f93f83bce983d6bb142155444f6e992a3ca9",
            "patch": "@@ -54,8 +54,8 @@ For each model type, there is a separate class for each machine learning framewo\n from transformers import AutoModelForCausalLM, MistralForCausalLM\n \n # load with AutoClass or model-specific class\n-model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", , torch_dtype=\"auto\", device_map=\"auto\")\n-model = MistralForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", , torch_dtype=\"auto\", device_map=\"auto\")\n+model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", torch_dtype=\"auto\", device_map=\"auto\")\n+model = MistralForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", torch_dtype=\"auto\", device_map=\"auto\")\n ```\n \n </hfoption>\n@@ -272,6 +272,7 @@ Explicitly set the [torch_dtype](https://pytorch.org/docs/stable/tensor_attribut\n <hfoption id=\"specific dtype\">\n \n ```py\n+import torch\n from transformers import AutoModelForCausalLM\n \n gemma = AutoModelForCausalLM.from_pretrained(\"google/gemma-7b\", torch_dtype=torch.float16)"
        }
    ],
    "stats": {
        "total": 5,
        "additions": 3,
        "deletions": 2
    }
}