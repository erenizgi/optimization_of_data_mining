{
    "author": "hmellor",
    "message": "Handle decorator with optional arguments better (#42512)\n\nSigned-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>",
    "sha": "2dba972530b405d70a49f8f7338590db6722843e",
    "files": [
        {
            "sha": "a2bd77c78bdc79b7264652dcada4dab85a778430",
            "filename": "examples/modular-transformers/modeling_dummy_bert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/examples%2Fmodular-transformers%2Fmodeling_dummy_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/examples%2Fmodular-transformers%2Fmodeling_dummy_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fmodular-transformers%2Fmodeling_dummy_bert.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -590,7 +590,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "66f1c4f65cbe017f6a4af90e730727059e96b462",
            "filename": "examples/modular-transformers/modeling_roberta.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/examples%2Fmodular-transformers%2Fmodeling_roberta.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/examples%2Fmodular-transformers%2Fmodeling_roberta.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fmodular-transformers%2Fmodeling_roberta.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -593,7 +593,7 @@ class PreTrainedModel\n         for layer, heads in heads_to_prune.items():\n             self.encoder.layer[layer].attention.prune_heads(heads)\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "2868b82db8dbebcc42a3b16fbc954bff8ec71e31",
            "filename": "examples/modular-transformers/modeling_super.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/examples%2Fmodular-transformers%2Fmodeling_super.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/examples%2Fmodular-transformers%2Fmodeling_super.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fmodular-transformers%2Fmodeling_super.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -321,7 +321,7 @@ def __init__(self, config: SuperConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "663971ac7e09f778b0ee25876f4e93bd6f7fac74",
            "filename": "src/transformers/models/afmoe/modeling_afmoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fafmoe%2Fmodeling_afmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fafmoe%2Fmodeling_afmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fafmoe%2Fmodeling_afmoe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -572,7 +572,7 @@ def __init__(self, config: AfmoeConfig):\n         self.post_init()\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "97ec692398cef1bd8cf78a28f6149dc50c98a4ea",
            "filename": "src/transformers/models/afmoe/modular_afmoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fafmoe%2Fmodular_afmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fafmoe%2Fmodular_afmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fafmoe%2Fmodular_afmoe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -391,7 +391,7 @@ def __init__(self, config: AfmoeConfig):\n         self.post_init()\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "22b9e10f041b1d3b18114cd7f96f7211831d9e0c",
            "filename": "src/transformers/models/albert/modeling_albert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Falbert%2Fmodeling_albert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Falbert%2Fmodeling_albert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Falbert%2Fmodeling_albert.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -380,7 +380,7 @@ def get_input_embeddings(self) -> nn.Embedding:\n     def set_input_embeddings(self, value: nn.Embedding) -> None:\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "0273c43f16abd8527a0349cf37296310b7615cbb",
            "filename": "src/transformers/models/apertus/modeling_apertus.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fapertus%2Fmodeling_apertus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fapertus%2Fmodeling_apertus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fapertus%2Fmodeling_apertus.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -368,7 +368,7 @@ def __init__(self, config: ApertusConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "9bfdf72d45f4a8ed173ab579c08a5e9e6a809dd3",
            "filename": "src/transformers/models/arcee/modeling_arcee.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Farcee%2Fmodeling_arcee.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Farcee%2Fmodeling_arcee.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Farcee%2Fmodeling_arcee.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -373,7 +373,7 @@ def __init__(self, config: ArceeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "86c6e6145ba53040d1c3dc8536e44a59a08aafa1",
            "filename": "src/transformers/models/aria/modeling_aria.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -702,7 +702,7 @@ def __init__(self, config: AriaTextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "2b611b3a9567f650d429a77f9f0a53e3b3d3f91d",
            "filename": "src/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -334,7 +334,7 @@ def __init__(self, config: ASTConfig) -> None:\n     def get_input_embeddings(self) -> ASTPatchEmbeddings:\n         return self.embeddings.patch_embeddings\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "41ac2cc765292f17ecefe5774db7e0599bf60514",
            "filename": "src/transformers/models/aya_vision/modeling_aya_vision.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodeling_aya_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodeling_aya_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodeling_aya_vision.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -260,7 +260,7 @@ def get_placeholder_mask(\n             )\n         return special_image_mask\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "f76e046e0b948f0e4b33e361082bbd7332d254d1",
            "filename": "src/transformers/models/aya_vision/modular_aya_vision.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodular_aya_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodular_aya_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodular_aya_vision.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -162,7 +162,7 @@ def get_image_features(\n         image_features = self.multi_modal_projector(selected_image_feature)\n         return image_features\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "417694f770e84f7d4657722cb08a22659bcb088e",
            "filename": "src/transformers/models/bert/modeling_bert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fbert%2Fmodeling_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fbert%2Fmodeling_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbert%2Fmodeling_bert.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -634,7 +634,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "81ec49067cf86031a8d5599b0e10d9feada41e6e",
            "filename": "src/transformers/models/bert_generation/modeling_bert_generation.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fbert_generation%2Fmodeling_bert_generation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fbert_generation%2Fmodeling_bert_generation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbert_generation%2Fmodeling_bert_generation.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -504,7 +504,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "7958295645ebf6ce4899cc16921fddb02b35cbb1",
            "filename": "src/transformers/models/bitnet/modeling_bitnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fbitnet%2Fmodeling_bitnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fbitnet%2Fmodeling_bitnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbitnet%2Fmodeling_bitnet.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -372,7 +372,7 @@ def __init__(self, config: BitNetConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "9c6ca0da621ffe4dde5492b9e1926eca89daca1b",
            "filename": "src/transformers/models/blip_2/modeling_blip_2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -936,7 +936,7 @@ def get_extended_attention_mask(\n         extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n         return extended_attention_mask\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "294c0c2e99f01a0e7bfa1fe4b08642f45e0cd6e3",
            "filename": "src/transformers/models/blt/modeling_blt.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fblt%2Fmodeling_blt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fblt%2Fmodeling_blt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblt%2Fmodeling_blt.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -587,7 +587,7 @@ def __init__(self, config: BltLocalDecoderConfig):\n \n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,\n@@ -1057,7 +1057,7 @@ def __init__(self, config: BltConfig):\n             self.patcher = None\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "66876d58e404a3f99bbc0f71e48410ab74fe15cf",
            "filename": "src/transformers/models/blt/modular_blt.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fblt%2Fmodular_blt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fblt%2Fmodular_blt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblt%2Fmodular_blt.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -512,7 +512,7 @@ def __init__(self, config: BltLocalDecoderConfig):\n \n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,\n@@ -775,7 +775,7 @@ def __init__(self, config: BltConfig):\n             self.patcher = None\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "2f31f45fae55dd78c01f7d61c511da3d6293cc02",
            "filename": "src/transformers/models/camembert/modeling_camembert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -612,7 +612,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "4099e52e636934158b9bb716662d0d7f7335571b",
            "filename": "src/transformers/models/cohere/modeling_cohere.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcohere%2Fmodeling_cohere.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcohere%2Fmodeling_cohere.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere%2Fmodeling_cohere.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -404,7 +404,7 @@ def __init__(self, config: CohereConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "c2690e2150814a5af8dce2504d05c1dfe1b8b12d",
            "filename": "src/transformers/models/cohere2/modeling_cohere2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodeling_cohere2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodeling_cohere2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodeling_cohere2.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -379,7 +379,7 @@ def __init__(self, config: Cohere2Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a6edbbf128ebed426fda0b14879f450cb3f934f4",
            "filename": "src/transformers/models/cohere2_vision/modeling_cohere2_vision.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodeling_cohere2_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodeling_cohere2_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodeling_cohere2_vision.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -208,7 +208,7 @@ def get_placeholder_mask(\n             )\n         return special_image_mask\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,\n@@ -282,7 +282,7 @@ def get_output_embeddings(self) -> nn.Module:\n     def get_image_features(self, pixel_values: torch.FloatTensor):\n         return self.model.get_image_features(pixel_values=pixel_values)\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "5f417075a9310997bf442cffc472941fa295c605",
            "filename": "src/transformers/models/cohere2_vision/modular_cohere2_vision.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodular_cohere2_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodular_cohere2_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodular_cohere2_vision.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -114,7 +114,7 @@ def get_image_features(self, pixel_values: torch.FloatTensor):\n         image_features = self.multi_modal_projector(selected_image_feature)\n         return image_features\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,\n@@ -167,7 +167,7 @@ class Cohere2VisionForConditionalGeneration(AyaVisionForConditionalGeneration):\n     def get_image_features(self, pixel_values: torch.FloatTensor):\n         return self.model.get_image_features(pixel_values=pixel_values)\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "f2f00bf998755e0860c6b303fee4c04f6b4c5fcb",
            "filename": "src/transformers/models/csm/modeling_csm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodeling_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodeling_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodeling_csm.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -442,7 +442,7 @@ def __init__(self, config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,\n@@ -695,7 +695,7 @@ def __init__(self, config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a58421c30b0d38f84c69c0a090cc766b585d8880",
            "filename": "src/transformers/models/csm/modular_csm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodular_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodular_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodular_csm.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -160,7 +160,7 @@ def __init__(self, config):\n         self.embed_tokens = nn.Embedding((config.num_codebooks * config.vocab_size), config.backbone_hidden_size)\n         self.inputs_embeds_projector = nn.Linear(config.backbone_hidden_size, config.hidden_size, bias=False)\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,\n@@ -399,7 +399,7 @@ def __init__(self, config):\n         super().__init__(config)\n         self.embed_tokens = CsmBackboneModelEmbeddings(config)\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(self, **super_kwargs):\n         r\"\"\""
        },
        {
            "sha": "0b27322eb6a4c9f93bc9a1dfe4917c010032cad6",
            "filename": "src/transformers/models/cwm/modeling_cwm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcwm%2Fmodeling_cwm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fcwm%2Fmodeling_cwm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcwm%2Fmodeling_cwm.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -369,7 +369,7 @@ def __init__(self, config: CwmConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "2387e1d1ab73268e1ac6d63beac815a203fdebb8",
            "filename": "src/transformers/models/data2vec/modeling_data2vec_text.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_text.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -571,7 +571,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "f3aa337828ab48b5b295fc828db98f7114bc5c2c",
            "filename": "src/transformers/models/dbrx/modeling_dbrx.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodeling_dbrx.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodeling_dbrx.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodeling_dbrx.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -509,7 +509,7 @@ def get_input_embeddings(self) -> nn.Embedding:\n     def set_input_embeddings(self, value: nn.Embedding):\n         self.wte = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "39ede3f9bd61d366677a885c2ac1f27eb89685e9",
            "filename": "src/transformers/models/dbrx/modular_dbrx.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodular_dbrx.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodular_dbrx.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodular_dbrx.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -377,7 +377,7 @@ def get_input_embeddings(self) -> nn.Embedding:\n     def set_input_embeddings(self, value: nn.Embedding):\n         self.wte = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "92b0d03e1800a0b912511880e637ec86eb4b3199",
            "filename": "src/transformers/models/deepseek_v2/modeling_deepseek_v2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -488,7 +488,7 @@ def __init__(self, config: DeepseekV2Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "5fd8e2718b2bea3777caa5a557f0c64d30698672",
            "filename": "src/transformers/models/deepseek_v3/modeling_deepseek_v3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -580,7 +580,7 @@ def __init__(self, config: DeepseekV3Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "92be6a50bc38eae9dc55ea86c02e2d3d1d79e5a7",
            "filename": "src/transformers/models/diffllama/modeling_diffllama.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdiffllama%2Fmodeling_diffllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdiffllama%2Fmodeling_diffllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdiffllama%2Fmodeling_diffllama.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -627,7 +627,7 @@ def __init__(self, config: DiffLlamaConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "96ae3b0819991c87a1e8e305b4c7af32fb41765a",
            "filename": "src/transformers/models/dinov2/modeling_dinov2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -563,7 +563,7 @@ def __init__(self, config):\n     def get_input_embeddings(self) -> Dinov2PatchEmbeddings:\n         return self.embeddings.patch_embeddings\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self, pixel_values: torch.Tensor, output_hidden_states: Optional[bool] = None, **kwargs"
        },
        {
            "sha": "94cf54409d9d5cfd71f49d271377c3247663d21c",
            "filename": "src/transformers/models/dinov2_with_registers/modeling_dinov2_with_registers.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -583,7 +583,7 @@ def __init__(self, config):\n     def get_input_embeddings(self) -> Dinov2WithRegistersPatchEmbeddings:\n         return self.embeddings.patch_embeddings\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "018b071d61790b1a6ed147c5b25246cb54793d9c",
            "filename": "src/transformers/models/dinov3_vit/modeling_dinov3_vit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodeling_dinov3_vit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodeling_dinov3_vit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodeling_dinov3_vit.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -532,7 +532,7 @@ def __init__(self, config):\n     def get_input_embeddings(self):\n         return self.embeddings.patch_embeddings\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @can_return_tuple\n     def forward(\n         self,"
        },
        {
            "sha": "0e04f532ea651a59f63d37f4dd624e1749f7a9b9",
            "filename": "src/transformers/models/dinov3_vit/modular_dinov3_vit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodular_dinov3_vit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodular_dinov3_vit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodular_dinov3_vit.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -427,7 +427,7 @@ def __init__(self, config):\n     def get_input_embeddings(self):\n         return self.embeddings.patch_embeddings\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @can_return_tuple\n     def forward(\n         self,"
        },
        {
            "sha": "e1c01243768a7109daf8bcad0a797aa476fa8e33",
            "filename": "src/transformers/models/distilbert/modeling_distilbert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdistilbert%2Fmodeling_distilbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdistilbert%2Fmodeling_distilbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdistilbert%2Fmodeling_distilbert.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -381,7 +381,7 @@ def get_input_embeddings(self) -> nn.Embedding:\n     def set_input_embeddings(self, new_embeddings: nn.Embedding):\n         self.embeddings.word_embeddings = new_embeddings\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "57f4b9d8890276520c265933ddfc1bf98c483024",
            "filename": "src/transformers/models/doge/modeling_doge.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdoge%2Fmodeling_doge.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdoge%2Fmodeling_doge.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdoge%2Fmodeling_doge.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -558,7 +558,7 @@ def __init__(self, config: DogeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "cbb39727e9e56243272f918885c618afd90c6df8",
            "filename": "src/transformers/models/dots1/modeling_dots1.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -498,7 +498,7 @@ def __init__(self, config: Dots1Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "1e0126d0ffbbda5caba78f7f248b43d7366a3240",
            "filename": "src/transformers/models/edgetam/modeling_edgetam.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodeling_edgetam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodeling_edgetam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodeling_edgetam.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -437,7 +437,7 @@ def __init__(self, config: EdgeTamVisionConfig):\n \n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         pixel_values: Optional[torch.FloatTensor] = None,\n@@ -1014,7 +1014,7 @@ def get_prompt_embeddings(\n         )\n         return prompt_output\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "cfa14885874a8a5934b538915598bd05843a3158",
            "filename": "src/transformers/models/edgetam/modular_edgetam.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodular_edgetam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodular_edgetam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodular_edgetam.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -196,7 +196,7 @@ class EdgeTamVisionModel(Sam2VisionModel):\n     def get_input_embeddings(self):\n         raise NotImplementedError(\"Can't get input embeddings from timm wrapper model\")\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         pixel_values: Optional[torch.FloatTensor] = None,"
        },
        {
            "sha": "a6711138ba4946e2cdd7d57ea86c0e0a3f114dc2",
            "filename": "src/transformers/models/efficientloftr/modeling_efficientloftr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fefficientloftr%2Fmodeling_efficientloftr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fefficientloftr%2Fmodeling_efficientloftr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fefficientloftr%2Fmodeling_efficientloftr.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -722,7 +722,7 @@ def __init__(self, config: EfficientLoFTRConfig):\n \n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a26d99a2e8c4550f0e7bc8ccecb13d8716e78ea8",
            "filename": "src/transformers/models/electra/modeling_electra.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Felectra%2Fmodeling_electra.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Felectra%2Fmodeling_electra.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Felectra%2Fmodeling_electra.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -574,7 +574,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "d35196c0c44082f5d8e1091a20e6c1c916f65205",
            "filename": "src/transformers/models/emu3/modeling_emu3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -1199,7 +1199,7 @@ def __init__(self, config: Emu3Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "12c2a313d73c50301fd389072aad9c62e7bfa4f1",
            "filename": "src/transformers/models/eomt/modeling_eomt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Feomt%2Fmodeling_eomt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Feomt%2Fmodeling_eomt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Feomt%2Fmodeling_eomt.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -1085,7 +1085,7 @@ def get_loss_dict(\n     def get_loss(self, loss_dict: dict[str, Tensor]) -> Tensor:\n         return sum(loss_dict.values())\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "293af7728e096b216c01382b8829d11b017d74e7",
            "filename": "src/transformers/models/eomt/modular_eomt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Feomt%2Fmodular_eomt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Feomt%2Fmodular_eomt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Feomt%2Fmodular_eomt.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -494,7 +494,7 @@ def _disable_attention_mask(attn_mask, prob, num_query_tokens, encoder_start_tok\n \n         return attn_mask\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "69db1224f9d07c18491ca17ab1c0e710ac680fe7",
            "filename": "src/transformers/models/ernie/modeling_ernie.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fernie%2Fmodeling_ernie.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fernie%2Fmodeling_ernie.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie%2Fmodeling_ernie.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -593,7 +593,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "b34ce7ba85dc2049f97f6208f4214a7225da7b80",
            "filename": "src/transformers/models/ernie/modular_ernie.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fernie%2Fmodular_ernie.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fernie%2Fmodular_ernie.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie%2Fmodular_ernie.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -187,7 +187,7 @@ def __init__(self, config, add_pooling_layer=True):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "b85ad6d1d2087a97d452044d9d69586b95f0e04e",
            "filename": "src/transformers/models/ernie4_5/modeling_ernie4_5.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fernie4_5%2Fmodeling_ernie4_5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fernie4_5%2Fmodeling_ernie4_5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie4_5%2Fmodeling_ernie4_5.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -370,7 +370,7 @@ def __init__(self, config: Ernie4_5Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "ecb87cd6fc5893e5e9d3c637b12a80824631ee53",
            "filename": "src/transformers/models/ernie4_5_moe/modeling_ernie4_5_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fernie4_5_moe%2Fmodeling_ernie4_5_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fernie4_5_moe%2Fmodeling_ernie4_5_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie4_5_moe%2Fmodeling_ernie4_5_moe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -528,7 +528,7 @@ def __init__(self, config: Ernie4_5_MoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "4684c8280fbb3ae6449289c76a62a2d395414a20",
            "filename": "src/transformers/models/ernie4_5_moe/modular_ernie4_5_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fernie4_5_moe%2Fmodular_ernie4_5_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fernie4_5_moe%2Fmodular_ernie4_5_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie4_5_moe%2Fmodular_ernie4_5_moe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -268,7 +268,7 @@ def __init__(self, config: Ernie4_5_MoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "e94aad1bd3ff503d0395a5a031daad75e71974f2",
            "filename": "src/transformers/models/esm/modeling_esm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fesm%2Fmodeling_esm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fesm%2Fmodeling_esm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fesm%2Fmodeling_esm.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -605,7 +605,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "55f4fac497d475d61a91c4a904a62ab5445a4cee",
            "filename": "src/transformers/models/evolla/modeling_evolla.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fevolla%2Fmodeling_evolla.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fevolla%2Fmodeling_evolla.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fevolla%2Fmodeling_evolla.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -531,7 +531,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.Tensor],\n@@ -1297,7 +1297,7 @@ def set_input_embeddings(self, value):\n         self.embed_tokens = value\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "6fb3245049a272de113c0df5f1bbae6129fc9f66",
            "filename": "src/transformers/models/evolla/modular_evolla.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fevolla%2Fmodular_evolla.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fevolla%2Fmodular_evolla.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fevolla%2Fmodular_evolla.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -216,7 +216,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.Tensor],\n@@ -759,7 +759,7 @@ def set_input_embeddings(self, value):\n         self.embed_tokens = value\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "ff083bd93a180f9498818a3bfe0883c7bcaf630a",
            "filename": "src/transformers/models/exaone4/modeling_exaone4.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodeling_exaone4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodeling_exaone4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodeling_exaone4.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -382,7 +382,7 @@ def __init__(self, config: Exaone4Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "0fe105518ab4a1d16638815248a23e722264756e",
            "filename": "src/transformers/models/exaone4/modular_exaone4.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodular_exaone4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodular_exaone4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodular_exaone4.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -330,7 +330,7 @@ def __init__(self, config: Exaone4Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "836c02aa3fb4809f25847ca172a1f7d7f7b61a70",
            "filename": "src/transformers/models/flex_olmo/modeling_flex_olmo.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodeling_flex_olmo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodeling_flex_olmo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodeling_flex_olmo.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -460,7 +460,7 @@ def __init__(self, config: FlexOlmoConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "d3a31d1b52d415ce060d14e44e4592c5ab8a8d44",
            "filename": "src/transformers/models/flex_olmo/modular_flex_olmo.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodular_flex_olmo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodular_flex_olmo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodular_flex_olmo.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -281,7 +281,7 @@ class FlexOlmoPreTrainedModel(MixtralPreTrainedModel):\n # FlexOlmo model is identical to Mixtral model except:\n # - FlexOlmo does not use sliding window attention.\n class FlexOlmoModel(MixtralModel):\n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "eef862eb3bf953dd03adc80a55ea9cac37756e25",
            "filename": "src/transformers/models/gemma/modeling_gemma.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgemma%2Fmodeling_gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgemma%2Fmodeling_gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma%2Fmodeling_gemma.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -379,7 +379,7 @@ def __init__(self, config: GemmaConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "bbce96855ffd5cb722e9e41ccb9b825af93fbe72",
            "filename": "src/transformers/models/gemma2/modeling_gemma2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -399,7 +399,7 @@ def __init__(self, config: Gemma2Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "9919cb0b08882c088c0aed19431082af79708647",
            "filename": "src/transformers/models/gemma3/modeling_gemma3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodeling_gemma3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodeling_gemma3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodeling_gemma3.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -517,7 +517,7 @@ def __init__(self, config: Gemma3TextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "5f83c5cabf81a51c1b96cbd7a8d9945135563d5f",
            "filename": "src/transformers/models/glm/modeling_glm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fglm%2Fmodeling_glm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fglm%2Fmodeling_glm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm%2Fmodeling_glm.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -388,7 +388,7 @@ def __init__(self, config: GlmConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "2d03acdee6489e0d24cc788bb6649ed6e7e15fc4",
            "filename": "src/transformers/models/glm4/modeling_glm4.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fglm4%2Fmodeling_glm4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fglm4%2Fmodeling_glm4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4%2Fmodeling_glm4.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -392,7 +392,7 @@ def __init__(self, config: Glm4Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "b6c9beb0131c8a08387e018af1e8a4ee130f2335",
            "filename": "src/transformers/models/glm4_moe/modeling_glm4_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fglm4_moe%2Fmodeling_glm4_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fglm4_moe%2Fmodeling_glm4_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4_moe%2Fmodeling_glm4_moe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -523,7 +523,7 @@ def __init__(self, config: Glm4MoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "6b83d1f011f33765689e4dd02a3f3552b2d283e2",
            "filename": "src/transformers/models/glm4v/modeling_glm4v.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -839,7 +839,7 @@ def __init__(self, config: Glm4vTextConfig):\n         self.post_init()\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "8cabe1793ab73fa9aac68ef25f131204f3632153",
            "filename": "src/transformers/models/glm4v/modular_glm4v.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -847,7 +847,7 @@ def __init__(self, config: Glm4vTextConfig):\n         del self.has_sliding_layers\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "86540f8fba506ddafe6f99218b505a875a260874",
            "filename": "src/transformers/models/glm4v_moe/modeling_glm4v_moe.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -1047,7 +1047,7 @@ def __init__(self, config: Glm4vMoeTextConfig):\n         self.post_init()\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,\n@@ -1647,7 +1647,7 @@ def get_image_features(self, pixel_values: torch.FloatTensor, image_grid_thw: Op\n         return self.model.get_image_features(pixel_values, image_grid_thw)\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "06967fb07642dd9621607f783da7e108cbd81f53",
            "filename": "src/transformers/models/glm4v_moe/modular_glm4v_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodular_glm4v_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodular_glm4v_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodular_glm4v_moe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -579,7 +579,7 @@ def forward(\n \n class Glm4vMoeForConditionalGeneration(Glm4vForConditionalGeneration):\n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "967a0850c998844dbed2e255a10d7794d6d168e2",
            "filename": "src/transformers/models/gpt_neox/modeling_gpt_neox.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgpt_neox%2Fmodeling_gpt_neox.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgpt_neox%2Fmodeling_gpt_neox.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_neox%2Fmodeling_gpt_neox.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -413,7 +413,7 @@ def __init__(self, config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "74efe5d5f2f09ff00bdb619caeb7a2e9206e770c",
            "filename": "src/transformers/models/gpt_oss/modeling_gpt_oss.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodeling_gpt_oss.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodeling_gpt_oss.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodeling_gpt_oss.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -478,7 +478,7 @@ def __init__(self, config: GptOssConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "17f93fb32cf3a2735c3ec570ff826b8299d6d1ca",
            "filename": "src/transformers/models/gpt_oss/modular_gpt_oss.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodular_gpt_oss.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodular_gpt_oss.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodular_gpt_oss.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -376,7 +376,7 @@ def _init_weights(self, module):\n class GptOssModel(MixtralModel):\n     _no_split_modules = [\"GptOssDecoderLayer\"]\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "633cf5e5df44e865c8605dc52eecbcce6bc9a2c0",
            "filename": "src/transformers/models/granite/modeling_granite.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgranite%2Fmodeling_granite.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgranite%2Fmodeling_granite.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranite%2Fmodeling_granite.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -404,7 +404,7 @@ def __init__(self, config: GraniteConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "30d8be76aea2fa190095172f32b38f5796f9cf45",
            "filename": "src/transformers/models/granitemoe/modeling_granitemoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -490,7 +490,7 @@ def __init__(self, config: GraniteMoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "2d76fea03a6e6a6229bbf7f4e3e4135d0630c6e3",
            "filename": "src/transformers/models/granitemoe/modular_granitemoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodular_granitemoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodular_granitemoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodular_granitemoe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -166,7 +166,7 @@ def __init__(self, config: GraniteMoeConfig):\n         self.norm = GraniteMoeRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n         self.embedding_multiplier = config.embedding_multiplier\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "0d3e717cfb5fa98310b64e7ac2b6a8c262699f6f",
            "filename": "src/transformers/models/granitemoehybrid/modeling_granitemoehybrid.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -1273,7 +1273,7 @@ def __init__(self, config: GraniteMoeHybridConfig):\n         self.post_init()\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "65e729cac9a4fc6af0ef3e7ac301a83a2e36e30b",
            "filename": "src/transformers/models/granitemoehybrid/modular_granitemoehybrid.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodular_granitemoehybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodular_granitemoehybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodular_granitemoehybrid.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -205,7 +205,7 @@ def __init__(self, config: GraniteMoeHybridConfig):\n         self.embedding_multiplier = config.embedding_multiplier\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "6e9986ddbadaba363e291c65b8695fa7571db1e5",
            "filename": "src/transformers/models/granitemoeshared/modeling_granitemoeshared.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodeling_granitemoeshared.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodeling_granitemoeshared.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodeling_granitemoeshared.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -561,7 +561,7 @@ def __init__(self, config: GraniteMoeSharedConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "9c9c6217ad7076a59cf49f1b18c932dbf58deb49",
            "filename": "src/transformers/models/helium/modeling_helium.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fhelium%2Fmodeling_helium.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fhelium%2Fmodeling_helium.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhelium%2Fmodeling_helium.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -371,7 +371,7 @@ def __init__(self, config: HeliumConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "5afd1b7a8fac789e6e2545c4c35ec3b03b49fa05",
            "filename": "src/transformers/models/hunyuan_v1_dense/modeling_hunyuan_v1_dense.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_dense%2Fmodeling_hunyuan_v1_dense.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_dense%2Fmodeling_hunyuan_v1_dense.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_dense%2Fmodeling_hunyuan_v1_dense.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -386,7 +386,7 @@ def __init__(self, config: HunYuanDenseV1Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "52d0af99048f99fea26d7d90fe7892dd7e0c7d30",
            "filename": "src/transformers/models/hunyuan_v1_moe/modeling_hunyuan_v1_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodeling_hunyuan_v1_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodeling_hunyuan_v1_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodeling_hunyuan_v1_moe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -480,7 +480,7 @@ def __init__(self, config: HunYuanMoEV1Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a5b91c556f988a1a4ae0813fe3de236c2fbda486",
            "filename": "src/transformers/models/idefics/modeling_idefics.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fidefics%2Fmodeling_idefics.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fidefics%2Fmodeling_idefics.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics%2Fmodeling_idefics.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -930,7 +930,7 @@ def freeze_text_layers(self, module_exceptions=[]):\n     def freeze_vision_layers(self, module_exceptions=[]):\n         freeze_model(self.vision_model, module_exceptions=module_exceptions)\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "eb97ea42623f524020f843e2de02125ec078da4e",
            "filename": "src/transformers/models/instructblip/modeling_instructblip.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Finstructblip%2Fmodeling_instructblip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Finstructblip%2Fmodeling_instructblip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finstructblip%2Fmodeling_instructblip.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -845,7 +845,7 @@ def get_extended_attention_mask(\n         extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n         return extended_attention_mask\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "42f6a7aea58e2d8fe7165572b70b6fddbc71ca0d",
            "filename": "src/transformers/models/instructblipvideo/modeling_instructblipvideo.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodeling_instructblipvideo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodeling_instructblipvideo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodeling_instructblipvideo.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -807,7 +807,7 @@ def get_extended_attention_mask(\n         extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n         return extended_attention_mask\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "cb1076b4244efeba87880a9298bd680df145e253",
            "filename": "src/transformers/models/jamba/modeling_jamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -795,7 +795,7 @@ def __init__(self, config: JambaConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "343dc19f9707ca8276fe55ded5edcbbf56cfad40",
            "filename": "src/transformers/models/jamba/modular_jamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodular_jamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodular_jamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodular_jamba.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -641,7 +641,7 @@ def __init__(self, config: JambaConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "275f67592eb3ce93c6f7fb22c227ba61366f1271",
            "filename": "src/transformers/models/jetmoe/modeling_jetmoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -613,7 +613,7 @@ def __init__(self, config: JetMoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "b1f8da412d6ba716e9910ded80241123ae173034",
            "filename": "src/transformers/models/jetmoe/modular_jetmoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodular_jetmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodular_jetmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodular_jetmoe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -460,7 +460,7 @@ def __init__(self, config: JetMoeConfig):\n         self._attn_implementation = config._attn_implementation\n         self.norm = JetMoeRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "91d4abdd533b3601cf8f94e16a75afadd53c02c4",
            "filename": "src/transformers/models/lfm2/modeling_lfm2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Flfm2%2Fmodeling_lfm2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Flfm2%2Fmodeling_lfm2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flfm2%2Fmodeling_lfm2.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -626,7 +626,7 @@ def __init__(self, config: Lfm2Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a7e9d879afaa4eeeab463a8f5af19cccd5b993d8",
            "filename": "src/transformers/models/lfm2_moe/modeling_lfm2_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Flfm2_moe%2Fmodeling_lfm2_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Flfm2_moe%2Fmodeling_lfm2_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flfm2_moe%2Fmodeling_lfm2_moe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -705,7 +705,7 @@ def __init__(self, config: Lfm2MoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "733092de9c2485c1dae4339177c6877a5d61ca3e",
            "filename": "src/transformers/models/llama/modeling_llama.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fllama%2Fmodeling_llama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fllama%2Fmodeling_llama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllama%2Fmodeling_llama.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -377,7 +377,7 @@ def __init__(self, config: LlamaConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "0a9f6e2439cfb04bdadab9df15e1cb4426a8b970",
            "filename": "src/transformers/models/llama4/modeling_llama4.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -518,7 +518,7 @@ def __init__(self, config: Llama4TextConfig):\n         self.post_init()\n \n     @can_return_tuple\n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "331049d23a88615ad1f9819e77e2340f2af9dc50",
            "filename": "src/transformers/models/longcat_flash/modeling_longcat_flash.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Flongcat_flash%2Fmodeling_longcat_flash.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Flongcat_flash%2Fmodeling_longcat_flash.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flongcat_flash%2Fmodeling_longcat_flash.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -593,7 +593,7 @@ def __init__(self, config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "e8d7919a8c424e559d452dccd4d3c6c63cb4a1ff",
            "filename": "src/transformers/models/minimax/modeling_minimax.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodeling_minimax.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodeling_minimax.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodeling_minimax.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -634,7 +634,7 @@ def __init__(self, config: MiniMaxConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "d5a5e0ebc43854f411cc37f0508a6be109859fc4",
            "filename": "src/transformers/models/minimax/modular_minimax.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodular_minimax.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodular_minimax.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodular_minimax.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -529,7 +529,7 @@ class MiniMaxPreTrainedModel(MixtralPreTrainedModel):\n \n \n class MiniMaxModel(MixtralModel):\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "e66bf40cf8f33077b3a70d09d3dcb602e4e61b2e",
            "filename": "src/transformers/models/ministral/modeling_ministral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fministral%2Fmodeling_ministral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fministral%2Fmodeling_ministral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fministral%2Fmodeling_ministral.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -355,7 +355,7 @@ def __init__(self, config: MinistralConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "5acca3517f5752115ec2c1a75c3cfd541267d0e5",
            "filename": "src/transformers/models/ministral/modular_ministral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fministral%2Fmodular_ministral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fministral%2Fmodular_ministral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fministral%2Fmodular_ministral.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -203,7 +203,7 @@ def __init__(self, config: MinistralConfig):\n         super().__init__(config)\n         del self.has_sliding_layers\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "808a47294569925bc0e81014172db0ca31f2b95e",
            "filename": "src/transformers/models/mistral/modeling_mistral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodeling_mistral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodeling_mistral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodeling_mistral.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -350,7 +350,7 @@ def __init__(self, config: MistralConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "90aed5eeb9b2f0029e56cdf48d41cfe7fcd14d7c",
            "filename": "src/transformers/models/mistral/modular_mistral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodular_mistral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodular_mistral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodular_mistral.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -111,7 +111,7 @@ class MistralPreTrainedModel(LlamaPreTrainedModel):\n \n \n class MistralModel(LlamaModel):\n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "ee393bcd94faa57ee476890cd0dc02079b85de7c",
            "filename": "src/transformers/models/mixtral/modeling_mixtral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -441,7 +441,7 @@ def __init__(self, config: MixtralConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "0dc1770cc139262b309be6d6fc0f9166c8a38406",
            "filename": "src/transformers/models/mllama/modeling_mllama.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -1033,7 +1033,7 @@ def apply_class_embedding(self, hidden_state: torch.Tensor) -> torch.Tensor:\n         hidden_state = torch.cat([class_embedding, hidden_state], dim=1)\n         return hidden_state\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self, pixel_values: torch.Tensor, aspect_ratio_ids: torch.Tensor, aspect_ratio_mask: torch.Tensor, **kwargs\n@@ -1203,7 +1203,7 @@ def __init__(self, config: MllamaTextConfig):\n         self.gradient_checkpointing = False\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @can_return_tuple\n     @auto_docstring\n     def forward(\n@@ -1465,7 +1465,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.language_model.set_input_embeddings(value)\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @can_return_tuple\n     @auto_docstring\n     def forward("
        },
        {
            "sha": "489cc497fe9f1904e25302a88d358ec0edf96409",
            "filename": "src/transformers/models/mobilebert/modeling_mobilebert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmobilebert%2Fmodeling_mobilebert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmobilebert%2Fmodeling_mobilebert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilebert%2Fmodeling_mobilebert.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -612,7 +612,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a06aecd669fa1edf721b126080e86566fb383e64",
            "filename": "src/transformers/models/modernbert_decoder/modeling_modernbert_decoder.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodeling_modernbert_decoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodeling_modernbert_decoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodeling_modernbert_decoder.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -466,7 +466,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.tok_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "ed547ea8dfdcc48f93a289c69ead70456418fe25",
            "filename": "src/transformers/models/modernbert_decoder/modular_modernbert_decoder.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodular_modernbert_decoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodular_modernbert_decoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodular_modernbert_decoder.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -514,7 +514,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.tok_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "9df55aee6ccc20ff480ee095d9aa39c9f95f0222",
            "filename": "src/transformers/models/moonshine/modeling_moonshine.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodeling_moonshine.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodeling_moonshine.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodeling_moonshine.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -550,7 +550,7 @@ def get_input_embeddings(self) -> nn.Module:\n     def set_input_embeddings(self, value: nn.Module):\n         self.conv1 = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_values: torch.FloatTensor,\n@@ -635,7 +635,7 @@ def __init__(self, config: MoonshineConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "109dfc197c813fcdf27c11f6e4345f060b35e60f",
            "filename": "src/transformers/models/moonshine/modular_moonshine.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodular_moonshine.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodular_moonshine.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodular_moonshine.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -508,7 +508,7 @@ def get_input_embeddings(self) -> nn.Module:\n     def set_input_embeddings(self, value: nn.Module):\n         self.conv1 = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_values: torch.FloatTensor,\n@@ -583,7 +583,7 @@ def __init__(self, config: MoonshineConfig):\n             [MoonshineDecoderLayer(config, idx) for idx in range(config.decoder_num_hidden_layers)]\n         )\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "541d3b08e9a2339973952cf27e513cb8b5d0077d",
            "filename": "src/transformers/models/nanochat/modeling_nanochat.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fnanochat%2Fmodeling_nanochat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fnanochat%2Fmodeling_nanochat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fnanochat%2Fmodeling_nanochat.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -381,7 +381,7 @@ def __init__(self, config: NanoChatConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "51085b0a6b4a13fe02d76269f3f966247660defd",
            "filename": "src/transformers/models/nllb_moe/modeling_nllb_moe.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fmodeling_nllb_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fmodeling_nllb_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fmodeling_nllb_moe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -703,7 +703,7 @@ def __init__(self, config: NllbMoeConfig):\n         self.gradient_checkpointing = False\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,\n@@ -788,7 +788,7 @@ def __init__(self, config: NllbMoeConfig):\n         self.post_init()\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.Tensor] = None,"
        },
        {
            "sha": "9fec11326150400a5fc8c95097e18f11271de4ce",
            "filename": "src/transformers/models/olmo/modeling_olmo.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Folmo%2Fmodeling_olmo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Folmo%2Fmodeling_olmo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmo%2Fmodeling_olmo.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -374,7 +374,7 @@ def __init__(self, config: OlmoConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a16538f4257e6f6b8c5ff4b8a821b21095710f43",
            "filename": "src/transformers/models/olmo2/modeling_olmo2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Folmo2%2Fmodeling_olmo2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Folmo2%2Fmodeling_olmo2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmo2%2Fmodeling_olmo2.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -379,7 +379,7 @@ def __init__(self, config: Olmo2Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "c4313424adf154439043b57a4e067a8d6f53cbd9",
            "filename": "src/transformers/models/olmo3/modeling_olmo3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Folmo3%2Fmodeling_olmo3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Folmo3%2Fmodeling_olmo3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmo3%2Fmodeling_olmo3.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -378,7 +378,7 @@ def __init__(self, config: Olmo3Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "be8888425115b9908fa42734d2fd5f75c1d1a0e9",
            "filename": "src/transformers/models/olmoe/modeling_olmoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -462,7 +462,7 @@ def __init__(self, config: OlmoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "6a23ebb454a1d9a48eeadc3cfbcb03f7920a4d9a",
            "filename": "src/transformers/models/parakeet/modeling_parakeet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodeling_parakeet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodeling_parakeet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodeling_parakeet.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -566,7 +566,7 @@ def __init__(self, config: ParakeetEncoderConfig):\n         self.post_init()\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     @can_return_tuple\n     def forward(\n         self,"
        },
        {
            "sha": "2424a4afadd922766298210e48f84c2fbcfde7e0",
            "filename": "src/transformers/models/parakeet/modular_parakeet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodular_parakeet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodular_parakeet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodular_parakeet.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -405,7 +405,7 @@ def __init__(self, config: ParakeetEncoderConfig):\n         self.post_init()\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     @can_return_tuple\n     def forward(\n         self,"
        },
        {
            "sha": "b08bb1a05fb5d3098ee13b73fa856efbfa7d4810",
            "filename": "src/transformers/models/phi/modeling_phi.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fphi%2Fmodeling_phi.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fphi%2Fmodeling_phi.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi%2Fmodeling_phi.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -363,7 +363,7 @@ def __init__(self, config: PhiConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "56d09ad58c187382dcae5ed10823ea5c540f803d",
            "filename": "src/transformers/models/phi3/modeling_phi3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodeling_phi3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodeling_phi3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodeling_phi3.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -382,7 +382,7 @@ def __init__(self, config: Phi3Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "5eb2f45c46729db46c4248df5591ebd1b2fb995e",
            "filename": "src/transformers/models/phi4_multimodal/modeling_phi4_multimodal.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodeling_phi4_multimodal.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodeling_phi4_multimodal.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodeling_phi4_multimodal.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -1532,7 +1532,7 @@ def __init__(self, config: Phi4MultimodalConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "3b5e425baa4db9e7ebaaff8d087380d5c4649d39",
            "filename": "src/transformers/models/phi4_multimodal/modular_phi4_multimodal.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodular_phi4_multimodal.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodular_phi4_multimodal.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodular_phi4_multimodal.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -1468,7 +1468,7 @@ def __init__(self, config: Phi4MultimodalConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "78757e2e120906b999c8dbae92ba38af8609e594",
            "filename": "src/transformers/models/phimoe/modeling_phimoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fphimoe%2Fmodeling_phimoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fphimoe%2Fmodeling_phimoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphimoe%2Fmodeling_phimoe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -655,7 +655,7 @@ def __init__(self, config: PhimoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "54c38c76c9180828db52dbb4f2e3dfebd9d6a361",
            "filename": "src/transformers/models/qwen2/modeling_qwen2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodeling_qwen2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodeling_qwen2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodeling_qwen2.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -355,7 +355,7 @@ def __init__(self, config: Qwen2Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "c56d7df329db2fabaa0d2fd8e5338c78249599ab",
            "filename": "src/transformers/models/qwen2/modular_qwen2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodular_qwen2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodular_qwen2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodular_qwen2.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -148,7 +148,7 @@ def __init__(self, config: Qwen2Config):\n         super().__init__(config)\n         self.has_sliding_layers = \"sliding_attention\" in self.config.layer_types\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "f64697c4e0ac374357e76aace8f7e2ab6a3100a3",
            "filename": "src/transformers/models/qwen2_moe/modeling_qwen2_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -470,7 +470,7 @@ def __init__(self, config: Qwen2MoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "ea3ba32125f93f7f1784542df8d87a05d22af6ba",
            "filename": "src/transformers/models/qwen2_moe/modular_qwen2_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodular_qwen2_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodular_qwen2_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodular_qwen2_moe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -166,7 +166,7 @@ def __init__(self, config: Qwen2MoeConfig):\n         self.norm = Qwen2MoeRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n         self.rotary_emb = Qwen2MoeRotaryEmbedding(config=config)\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "f55efae0894fa1c67fb1ca12d2c4fe0c3e8b4cc6",
            "filename": "src/transformers/models/qwen3/modeling_qwen3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3%2Fmodeling_qwen3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3%2Fmodeling_qwen3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3%2Fmodeling_qwen3.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -381,7 +381,7 @@ def __init__(self, config: Qwen3Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "85a6d01a2e92f22f75637f7137c923f835f2fa1a",
            "filename": "src/transformers/models/qwen3_moe/modeling_qwen3_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_moe%2Fmodeling_qwen3_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_moe%2Fmodeling_qwen3_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_moe%2Fmodeling_qwen3_moe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -468,7 +468,7 @@ def __init__(self, config: Qwen3MoeConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "0dcc3fce8933cd4d78d994459feef803bfca9884",
            "filename": "src/transformers/models/qwen3_next/modeling_qwen3_next.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodeling_qwen3_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodeling_qwen3_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodeling_qwen3_next.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -1019,7 +1019,7 @@ def __init__(self, config: Qwen3NextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "6ef5f0faa4690cf68e1ef37126606e55ee18b66e",
            "filename": "src/transformers/models/qwen3_next/modular_qwen3_next.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodular_qwen3_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodular_qwen3_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodular_qwen3_next.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -766,7 +766,7 @@ def __init__(self, config: Qwen3NextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "809346e0f3019a57ff80df8e6ddf2bcfb4aa2c96",
            "filename": "src/transformers/models/qwen3_omni_moe/modeling_qwen3_omni_moe.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -1669,7 +1669,7 @@ def __init__(self, config: Qwen3OmniMoeTextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,\n@@ -2558,7 +2558,7 @@ def __init__(self, config: Qwen3OmniMoeTalkerCodePredictorConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,\n@@ -2914,7 +2914,7 @@ def __init__(self, config: Qwen3OmniMoeTalkerTextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,\n@@ -3569,7 +3569,7 @@ def __init__(self, config: Qwen3OmniMoeCode2WavConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "8988259af84b57cca0fea339ee939d4b102b912d",
            "filename": "src/transformers/models/qwen3_omni_moe/modular_qwen3_omni_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodular_qwen3_omni_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodular_qwen3_omni_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodular_qwen3_omni_moe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -1643,7 +1643,7 @@ def __init__(self, config: Qwen3OmniMoeTalkerCodePredictorConfig):\n     def get_input_embeddings(self):\n         return self.codec_embedding\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a4508920e76a822014d14faea8668719646ffe91",
            "filename": "src/transformers/models/qwen3_vl/modeling_qwen3_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodeling_qwen3_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodeling_qwen3_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodeling_qwen3_vl.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -810,7 +810,7 @@ def __init__(self, config: Qwen3VLTextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,\n@@ -1130,7 +1130,7 @@ def get_placeholder_mask(\n         return special_image_mask, special_video_mask\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,\n@@ -1322,7 +1322,7 @@ def get_video_features(\n     def get_image_features(self, pixel_values: torch.FloatTensor, image_grid_thw: Optional[torch.LongTensor] = None):\n         return self.model.get_image_features(pixel_values, image_grid_thw)\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,"
        },
        {
            "sha": "ee58105ff3a44e9ede7d00e2b4c20aeb74827691",
            "filename": "src/transformers/models/qwen3_vl/modular_qwen3_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodular_qwen3_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodular_qwen3_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodular_qwen3_vl.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -704,7 +704,7 @@ def _deepstack_process(\n         hidden_states[visual_pos_masks, :] = local_this\n         return hidden_states\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,\n@@ -962,7 +962,7 @@ def get_video_features(\n         return self.get_image_features(pixel_values_videos, video_grid_thw)\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,\n@@ -1105,7 +1105,7 @@ class Qwen3VLForConditionalGeneration(Qwen2_5_VLForConditionalGeneration):\n     config: Qwen3VLConfig\n     _checkpoint_conversion_mapping = {}\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,"
        },
        {
            "sha": "f7126db8cbda928bc631fa00b9d6ed3c84d03014",
            "filename": "src/transformers/models/qwen3_vl_moe/modeling_qwen3_vl_moe.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodeling_qwen3_vl_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodeling_qwen3_vl_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodeling_qwen3_vl_moe.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -913,7 +913,7 @@ def __init__(self, config: Qwen3VLMoeTextConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,\n@@ -1287,7 +1287,7 @@ def get_placeholder_mask(\n         return special_image_mask, special_video_mask\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,\n@@ -1532,7 +1532,7 @@ def get_video_features(\n     def get_image_features(self, pixel_values: torch.FloatTensor, image_grid_thw: Optional[torch.LongTensor] = None):\n         return self.model.get_image_features(pixel_values, image_grid_thw)\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,"
        },
        {
            "sha": "1afe0627a7f076e375e4442be3fd47c0b5efefc1",
            "filename": "src/transformers/models/roberta/modeling_roberta.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Froberta%2Fmodeling_roberta.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Froberta%2Fmodeling_roberta.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froberta%2Fmodeling_roberta.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -590,7 +590,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "190a8cefd0854a77d999453d02f9cbcb9ebfa1f5",
            "filename": "src/transformers/models/roberta_prelayernorm/modeling_roberta_prelayernorm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fmodeling_roberta_prelayernorm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fmodeling_roberta_prelayernorm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fmodeling_roberta_prelayernorm.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -603,7 +603,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "1405d274bc0c205767a5d91a5c0a236679ce0256",
            "filename": "src/transformers/models/roc_bert/modeling_roc_bert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Froc_bert%2Fmodeling_roc_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Froc_bert%2Fmodeling_roc_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froc_bert%2Fmodeling_roc_bert.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -674,7 +674,7 @@ def get_shape_embeddings(self):\n     def set_shape_embeddings(self, value):\n         self.embeddings.shape_embed = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "03151d19fb2d93e7904b0f8d24ac91429a9c1ad9",
            "filename": "src/transformers/models/sam/modeling_sam.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -1182,7 +1182,7 @@ def get_prompt_embeddings(\n         )\n         return prompt_output\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a55ceb59d9a80695bb71a6c34251f0fe0610990e",
            "filename": "src/transformers/models/sam2/modeling_sam2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodeling_sam2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodeling_sam2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodeling_sam2.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -611,7 +611,7 @@ def _get_pos_embed(self, hw: tuple[int, int]) -> torch.Tensor:\n         pos_embed = pos_embed.permute(0, 2, 3, 1)\n         return pos_embed\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         pixel_values: Optional[torch.FloatTensor] = None,\n@@ -663,7 +663,7 @@ def __init__(self, config: Sam2VisionConfig):\n     def get_input_embeddings(self):\n         return self.backbone.get_input_embeddings()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         pixel_values: Optional[torch.FloatTensor] = None,\n@@ -1373,7 +1373,7 @@ def get_prompt_embeddings(\n         )\n         return prompt_output\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "92f878ba8492e57b17305468b440b28923780b20",
            "filename": "src/transformers/models/sam2/modular_sam2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -727,7 +727,7 @@ def _get_pos_embed(self, hw: tuple[int, int]) -> torch.Tensor:\n         pos_embed = pos_embed.permute(0, 2, 3, 1)\n         return pos_embed\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         pixel_values: Optional[torch.FloatTensor] = None,\n@@ -779,7 +779,7 @@ def __init__(self, config: Sam2VisionConfig):\n     def get_input_embeddings(self):\n         return self.backbone.get_input_embeddings()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         pixel_values: Optional[torch.FloatTensor] = None,\n@@ -1281,7 +1281,7 @@ def get_image_features(\n \n         return feature_maps, feature_maps_position_embeddings, vision_outputs.hidden_states, vision_outputs.attentions\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "98e616bbef3bc22e6046de40eacf0edd25917f30",
            "filename": "src/transformers/models/sam3/modeling_sam3.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsam3%2Fmodeling_sam3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsam3%2Fmodeling_sam3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam3%2Fmodeling_sam3.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -1002,7 +1002,7 @@ def __init__(self, config: Sam3VisionConfig):\n     def get_input_embeddings(self):\n         return self.backbone.get_input_embeddings()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         pixel_values: Optional[torch.FloatTensor] = None,\n@@ -1373,7 +1373,7 @@ def _prepare_multilevel_features(\n             spatial_shapes,\n         )\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         vision_features: list[torch.Tensor],\n@@ -1690,7 +1690,7 @@ def _get_rpb_matrix(\n         rpb_matrix = rpb_matrix.permute(0, 3, 1, 2).contiguous()  # [batch_size, num_heads, num_queries, height*width]\n         return rpb_matrix\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         vision_features: torch.Tensor,\n@@ -1990,7 +1990,7 @@ def __init__(self, config: Sam3MaskDecoderConfig):\n         self.prompt_cross_attn_norm = nn.LayerNorm(hidden_size)\n         self.prompt_cross_attn_dropout = nn.Dropout(config.dropout)\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         decoder_queries: torch.Tensor,\n@@ -2203,7 +2203,7 @@ def get_vision_features(\n         vision_outputs = self.vision_encoder(pixel_values, **kwargs)\n         return vision_outputs\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "c3baaf7e3a07644170c4bae2e8b8a5b1530c2a78",
            "filename": "src/transformers/models/sam3_tracker/modeling_sam3_tracker.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsam3_tracker%2Fmodeling_sam3_tracker.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsam3_tracker%2Fmodeling_sam3_tracker.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam3_tracker%2Fmodeling_sam3_tracker.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -870,7 +870,7 @@ def get_prompt_embeddings(\n         )\n         return prompt_output\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "a5531fd4947747851c859e9df73cfce8e2a00e50",
            "filename": "src/transformers/models/sam_hq/modeling_sam_hq.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodeling_sam_hq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodeling_sam_hq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodeling_sam_hq.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -1311,7 +1311,7 @@ def get_prompt_embeddings(\n         )\n         return prompt_output\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "bcec8e2aee31f16f84ef3ec175201a8221f21328",
            "filename": "src/transformers/models/seed_oss/modeling_seed_oss.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fseed_oss%2Fmodeling_seed_oss.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fseed_oss%2Fmodeling_seed_oss.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fseed_oss%2Fmodeling_seed_oss.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -377,7 +377,7 @@ def __init__(self, config: SeedOssConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "64ee423c929402183a15f1e6a48f1722cff6a939",
            "filename": "src/transformers/models/siglip/modeling_siglip.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsiglip%2Fmodeling_siglip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsiglip%2Fmodeling_siglip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsiglip%2Fmodeling_siglip.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -969,7 +969,7 @@ def __init__(self, config: SiglipConfig) -> None:\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "b29f892d935884f8349bf15c608f802257deafd0",
            "filename": "src/transformers/models/siglip2/modeling_siglip2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsiglip2%2Fmodeling_siglip2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsiglip2%2Fmodeling_siglip2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsiglip2%2Fmodeling_siglip2.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -1048,7 +1048,7 @@ def __init__(self, config: Siglip2Config) -> None:\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "e36481f7271cb4fa54742a8b0176b1a3cc7cdc06",
            "filename": "src/transformers/models/smollm3/modeling_smollm3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsmollm3%2Fmodeling_smollm3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fsmollm3%2Fmodeling_smollm3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsmollm3%2Fmodeling_smollm3.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -384,7 +384,7 @@ def __init__(self, config: SmolLM3Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "8e73c1744094b4a43ec83b72d929d7d9d81ec5bc",
            "filename": "src/transformers/models/starcoder2/modeling_starcoder2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodeling_starcoder2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodeling_starcoder2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodeling_starcoder2.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -355,7 +355,7 @@ def __init__(self, config: Starcoder2Config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "9d79c7828bc47eacf744ea53f0d9dd16233c5d63",
            "filename": "src/transformers/models/starcoder2/modular_starcoder2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodular_starcoder2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodular_starcoder2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodular_starcoder2.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -144,7 +144,7 @@ def __init__(self, config: Starcoder2Config):\n         self.norm = nn.LayerNorm(config.hidden_size, eps=config.norm_epsilon)\n         self.embedding_dropout = config.embedding_dropout\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "34b1ee8d87a36f09f1ca7cd3f0635cab616675ac",
            "filename": "src/transformers/models/switch_transformers/modeling_switch_transformers.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fswitch_transformers%2Fmodeling_switch_transformers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fswitch_transformers%2Fmodeling_switch_transformers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fswitch_transformers%2Fmodeling_switch_transformers.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -680,7 +680,7 @@ def __init__(self, config):\n \n         self.gradient_checkpointing = False\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids=None,\n@@ -1241,7 +1241,7 @@ def set_input_embeddings(self, new_embeddings):\n         self.encoder.set_input_embeddings(new_embeddings)\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "5e1aac79101e4f8f2fe25218648396920978aaf9",
            "filename": "src/transformers/models/switch_transformers/modular_switch_transformers.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fswitch_transformers%2Fmodular_switch_transformers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fswitch_transformers%2Fmodular_switch_transformers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fswitch_transformers%2Fmodular_switch_transformers.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -436,7 +436,7 @@ def __init__(self, config):\n \n         self.gradient_checkpointing = False\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids=None,\n@@ -932,7 +932,7 @@ def set_input_embeddings(self, new_embeddings):\n         self.encoder.set_input_embeddings(new_embeddings)\n \n     @auto_docstring\n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "5167abd51e8ed02e3cae76b64c04ed70f7c90bb1",
            "filename": "src/transformers/models/t5gemma/modeling_t5gemma.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodeling_t5gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodeling_t5gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodeling_t5gemma.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -686,7 +686,7 @@ def __init__(self, config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,\n@@ -780,7 +780,7 @@ def __init__(self, config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "dd44b73b0b8e6d02ca92f805b8101c44a3df8689",
            "filename": "src/transformers/models/t5gemma/modular_t5gemma.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodular_t5gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodular_t5gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodular_t5gemma.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -689,7 +689,7 @@ def __init__(self, config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,\n@@ -783,7 +783,7 @@ def __init__(self, config):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_ids: Optional[torch.LongTensor] = None,"
        },
        {
            "sha": "3c9cb46b6eb9cc863cb79d6b1b6c86f350ac20b2",
            "filename": "src/transformers/models/vaultgemma/modeling_vaultgemma.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fvaultgemma%2Fmodeling_vaultgemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fvaultgemma%2Fmodeling_vaultgemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvaultgemma%2Fmodeling_vaultgemma.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -389,7 +389,7 @@ def __init__(self, config: VaultGemmaConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "f61148769b48b0421bc7c918255c4f6e67a44e0a",
            "filename": "src/transformers/models/voxtral/modeling_voxtral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodeling_voxtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodeling_voxtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodeling_voxtral.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -293,7 +293,7 @@ def get_input_embeddings(self) -> nn.Module:\n     def set_input_embeddings(self, value: nn.Module):\n         self.conv1 = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_features,"
        },
        {
            "sha": "de638c08a9911bd0e5d6732fcb3cf9acc336e23f",
            "filename": "src/transformers/models/voxtral/modular_voxtral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodular_voxtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodular_voxtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodular_voxtral.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -64,7 +64,7 @@ class VoxtralEncoder(Qwen2AudioEncoder):\n         \"hidden_states\": VoxtralEncoderLayer,\n     }\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     def forward(\n         self,\n         input_features,"
        },
        {
            "sha": "350158580ca5a3a0466428f1b85f9c5adf9f8830",
            "filename": "src/transformers/models/xlm_roberta/modeling_xlm_roberta.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fxlm_roberta%2Fmodeling_xlm_roberta.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fxlm_roberta%2Fmodeling_xlm_roberta.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fxlm_roberta%2Fmodeling_xlm_roberta.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -601,7 +601,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "e48c8463ffdfb8031f3421ee066da57924c0e072",
            "filename": "src/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fxlm_roberta_xl%2Fmodeling_xlm_roberta_xl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fxlm_roberta_xl%2Fmodeling_xlm_roberta_xl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fxlm_roberta_xl%2Fmodeling_xlm_roberta_xl.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -597,7 +597,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "1342a3d6760ce8be48bfcf736c56fb6ddc3869cf",
            "filename": "src/transformers/models/xmod/modeling_xmod.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fxmod%2Fmodeling_xmod.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Fmodels%2Fxmod%2Fmodeling_xmod.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fxmod%2Fmodeling_xmod.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -705,7 +705,7 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.embeddings.word_embeddings = value\n \n-    @check_model_inputs()\n+    @check_model_inputs\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "aef86d382a7641c58d855357969bbefc771acc6c",
            "filename": "src/transformers/utils/generic.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Futils%2Fgeneric.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2dba972530b405d70a49f8f7338590db6722843e/src%2Ftransformers%2Futils%2Fgeneric.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fgeneric.py?ref=2dba972530b405d70a49f8f7338590db6722843e",
            "patch": "@@ -788,7 +788,7 @@ class OutputRecorder:\n     class_name: str | None = None\n \n \n-def check_model_inputs(tie_last_hidden_states=True):\n+def check_model_inputs(func=None, *, tie_last_hidden_states=True):\n     \"\"\"\n     Decorator to intercept specific layer outputs without using hooks.\n     Compatible with torch.compile (Dynamo tracing).\n@@ -962,6 +962,8 @@ def wrapped_forward(*args, **kwargs):\n \n         return wrapper\n \n+    if func is not None:\n+        return wrapped_fn(func)\n     return wrapped_fn\n \n "
        }
    ],
    "stats": {
        "total": 388,
        "additions": 195,
        "deletions": 193
    }
}