{
    "author": "Rocketknight1",
    "message": "Fix chat schema tests (#41793)\n\n* Fix chat schema tests\n\n* make fixup",
    "sha": "2ca506ca1db3a20ef0d74b989edface7aecdef80",
    "files": [
        {
            "sha": "6e1a79cd97e3e6e22eb1e34f95506fcea9405364",
            "filename": "src/transformers/utils/chat_parsing_utils.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2ca506ca1db3a20ef0d74b989edface7aecdef80/src%2Ftransformers%2Futils%2Fchat_parsing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2ca506ca1db3a20ef0d74b989edface7aecdef80/src%2Ftransformers%2Futils%2Fchat_parsing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fchat_parsing_utils.py?ref=2ca506ca1db3a20ef0d74b989edface7aecdef80",
            "patch": "@@ -55,7 +55,7 @@ def recursive_parse(\n         return None\n \n     # If not, we have to do a little parsing. First, set some vars and do basic validation\n-    node_type = node_schema[\"type\"]\n+    node_type = node_schema.get(\"type\")\n     has_regex = \"x-regex\" in node_schema or \"x-regex-iterator\" in node_schema or \"x-regex-key-value\" in node_schema\n     if has_regex and not isinstance(node_content, str):\n         raise TypeError(\n@@ -232,5 +232,7 @@ def recursive_parse(\n         else:\n             # String type\n             return node_content\n+    elif node_type is None:\n+        return node_content  # Don't touch it\n     else:\n         raise TypeError(f\"Unsupported schema type {node_type} for node: {node_content}\")"
        },
        {
            "sha": "75bbb776c38b3767ed6dda85059c9728c86db2d0",
            "filename": "tests/utils/test_chat_schema_utils.py",
            "status": "modified",
            "additions": 5,
            "deletions": 13,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/2ca506ca1db3a20ef0d74b989edface7aecdef80/tests%2Futils%2Ftest_chat_schema_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2ca506ca1db3a20ef0d74b989edface7aecdef80/tests%2Futils%2Ftest_chat_schema_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_chat_schema_utils.py?ref=2ca506ca1db3a20ef0d74b989edface7aecdef80",
            "patch": "@@ -15,7 +15,7 @@\n import tempfile\n import unittest\n \n-from transformers import AutoProcessor, AutoTokenizer\n+from transformers import AutoTokenizer\n from transformers.testing_utils import require_jmespath\n from transformers.utils.chat_parsing_utils import recursive_parse\n \n@@ -43,7 +43,7 @@\n                             \"name\": {\"type\": \"string\"},\n                             \"arguments\": {\n                                 \"type\": \"object\",\n-                                \"additionalProperties\": {\"type\": \"any\"},\n+                                \"additionalProperties\": {},\n                             },\n                         },\n                     },\n@@ -74,7 +74,7 @@\n                             \"name\": {\"type\": \"string\"},\n                             \"arguments\": {\n                                 \"type\": \"object\",\n-                                \"additionalProperties\": {\"type\": \"any\"},\n+                                \"additionalProperties\": {},\n                             },\n                         },\n                     },\n@@ -105,7 +105,7 @@\n                                 \"type\": \"object\",\n                                 \"x-regex\": r\"<\\|message\\|>(.*)\",\n                                 \"x-parser\": \"json\",\n-                                \"additionalProperties\": {\"type\": \"any\"},\n+                                \"additionalProperties\": {},\n                             },\n                         },\n                     },\n@@ -136,7 +136,7 @@\n                             \"name\": {\"type\": \"string\"},\n                             \"arguments\": {\n                                 \"type\": \"object\",\n-                                \"additionalProperties\": {\"type\": \"any\"},\n+                                \"additionalProperties\": {},\n                             },\n                         },\n                     },\n@@ -192,14 +192,6 @@ def test_schema_save_load(self):\n             reloaded_tokenizer = AutoTokenizer.from_pretrained(tmpdir)\n         self.assertEqual(reloaded_tokenizer.response_schema, ernie_schema)\n \n-        # Has no schema by default\n-        processor = AutoProcessor.from_pretrained(\"hf-internal-testing/tiny-random-Qwen2VLForConditionalGeneration\")\n-        processor.response_schema = ernie_schema\n-        with tempfile.TemporaryDirectory() as tmpdir:\n-            processor.save_pretrained(tmpdir)\n-            reloaded_processor = AutoProcessor.from_pretrained(tmpdir)\n-        self.assertEqual(reloaded_processor.response_schema, ernie_schema)\n-\n     def test_tokenizer_method(self):\n         tokenizer = AutoTokenizer.from_pretrained(\"hf-internal-testing/tiny-random-gpt2\")\n         model_out = '<|START_THINKING|>I should call a tool.<|END_THINKING|><|START_ACTION|>[\\n    {\"tool_call_id\": \"0\", \"tool_name\": \"simple_tool\", \"parameters\": {\"temperature_format\": \"Celsius\"}}\\n]<|END_ACTION|><|END_OF_TURN_TOKEN|>'"
        }
    ],
    "stats": {
        "total": 22,
        "additions": 8,
        "deletions": 14
    }
}