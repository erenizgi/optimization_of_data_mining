{
    "author": "arjunaskykok",
    "message": "fix(conversion): Fix size mismatch error during TF->PT model loading (#38014)",
    "sha": "716819b8309324302e00a3488a3c3d6faa427f79",
    "files": [
        {
            "sha": "24bdf4faa0679d0d29e3e9001535190530c16ce1",
            "filename": "src/transformers/modeling_tf_pytorch_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/716819b8309324302e00a3488a3c3d6faa427f79/src%2Ftransformers%2Fmodeling_tf_pytorch_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/716819b8309324302e00a3488a3c3d6faa427f79/src%2Ftransformers%2Fmodeling_tf_pytorch_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_tf_pytorch_utils.py?ref=716819b8309324302e00a3488a3c3d6faa427f79",
            "patch": "@@ -585,8 +585,8 @@ def load_tf2_state_dict_in_pytorch_model(pt_model, tf_state_dict, allow_missing_\n     loaded_pt_weights_data_ptr = {}\n     missing_keys_pt = []\n     for pt_weight_name, pt_weight in current_pt_params_dict.items():\n-        # Handle PyTorch shared weight ()not duplicated in TF 2.0\n-        if pt_weight.data_ptr() in loaded_pt_weights_data_ptr:\n+        # Handle PyTorch shared weight not duplicated in TF 2.0\n+        if pt_weight.data_ptr() in loaded_pt_weights_data_ptr and pt_weight.data_ptr() != 0:\n             new_pt_params_dict[pt_weight_name] = loaded_pt_weights_data_ptr[pt_weight.data_ptr()]\n             continue\n "
        },
        {
            "sha": "a5aef44c38d3d16e7a2f0e89c0b519ad52cf8d84",
            "filename": "tests/utils/test_modeling_utils.py",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/716819b8309324302e00a3488a3c3d6faa427f79/tests%2Futils%2Ftest_modeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/716819b8309324302e00a3488a3c3d6faa427f79/tests%2Futils%2Ftest_modeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_modeling_utils.py?ref=716819b8309324302e00a3488a3c3d6faa427f79",
            "patch": "@@ -1571,6 +1571,14 @@ def test_safetensors_torch_from_tf(self):\n         for p1, p2 in zip(hub_model.parameters(), new_model.parameters()):\n             self.assertTrue(torch.equal(p1, p2))\n \n+    @require_tf\n+    def test_torch_from_tf(self):\n+        model = TFBertModel.from_pretrained(\"hf-internal-testing/tiny-bert-tf-only\")\n+\n+        with tempfile.TemporaryDirectory() as tmp_dir:\n+            model.save_pretrained(tmp_dir)\n+            _ = BertModel.from_pretrained(tmp_dir, from_tf=True)\n+\n     @require_safetensors\n     def test_safetensors_torch_from_torch_sharded(self):\n         model = BertModel.from_pretrained(\"hf-internal-testing/tiny-bert-pt-only\")"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 10,
        "deletions": 2
    }
}