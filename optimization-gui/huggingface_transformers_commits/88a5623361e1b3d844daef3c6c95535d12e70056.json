{
    "author": "lilin-1",
    "message": "Update Japanese README to match English version (#43069)",
    "sha": "88a5623361e1b3d844daef3c6c95535d12e70056",
    "files": [
        {
            "sha": "8e2ecbd68aa09bddb82ba037d112da951947f1dd",
            "filename": "i18n/README_ja.md",
            "status": "modified",
            "additions": 181,
            "deletions": 156,
            "changes": 337,
            "blob_url": "https://github.com/huggingface/transformers/blob/88a5623361e1b3d844daef3c6c95535d12e70056/i18n%2FREADME_ja.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/88a5623361e1b3d844daef3c6c95535d12e70056/i18n%2FREADME_ja.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_ja.md?ref=88a5623361e1b3d844daef3c6c95535d12e70056",
            "patch": "@@ -60,6 +60,7 @@ user: ãƒ¦ãƒ¼ã‚¶\n </p>\n \n <p align=\"center\">\n+    <a href=\"https://huggingface.com/models\"><img alt=\"Checkpoints on Hub\" src=\"https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen\"></a>\n     <a href=\"https://circleci.com/gh/huggingface/transformers\"><img alt=\"Build\" src=\"https://img.shields.io/circleci/build/github/huggingface/transformers/main\"></a>\n     <a href=\"https://github.com/huggingface/transformers/blob/main/LICENSE\"><img alt=\"GitHub\" src=\"https://img.shields.io/github/license/huggingface/transformers.svg?color=blue\"></a>\n     <a href=\"https://huggingface.co/docs/transformers/index\"><img alt=\"Documentation\" src=\"https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online\"></a>\n@@ -78,7 +79,7 @@ user: ãƒ¦ãƒ¼ã‚¶\n         <b>æ—¥æœ¬èª</b> |\n         <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md\">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a> |\n         <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a> |\n-        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md\">Ğ ortuguÃªs</a> |\n+        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md\">PortuguÃªs</a> |\n         <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_te.md\">à°¤à±†à°²à±à°—à±</a> |\n         <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md\">FranÃ§ais</a> |\n         <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_de.md\">Deutsch</a> |\n@@ -91,237 +92,261 @@ user: ãƒ¦ãƒ¼ã‚¶\n </h4>\n \n <h3 align=\"center\">\n-    <p>JAXã€PyTorchã€TensorFlowã®ãŸã‚ã®æœ€å…ˆç«¯æ©Ÿæ¢°å­¦ç¿’</p>\n+    <p>æ¨è«–ã¨å­¦ç¿’ã®ãŸã‚ã®æœ€å…ˆç«¯ã®äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«</p>\n </h3>\n \n <h3 align=\"center\">\n-    <a href=\"https://hf.co/course\"><img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png\"></a>\n+    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/transformers_as_a_model_definition.png\"/>\n </h3>\n \n-ğŸ¤—Transformersã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã€è¦–è¦šã€éŸ³å£°ãªã©ã®ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«å¯¾ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã«ã€äº‹å‰ã«å­¦ç¿’ã•ã›ãŸæ•°åƒã®ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã—ã¾ã™ã€‚\n+Transformersã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã€éŸ³å£°ã€å‹•ç”»ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸæœ€å…ˆç«¯ã®æ©Ÿæ¢°å­¦ç¿’ã®ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«å®šç¾©ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ã—ã¦ã€æ¨è«–ã¨å­¦ç¿’ã®ä¸¡æ–¹ã§æ©Ÿèƒ½ã—ã¾ã™ã€‚\n \n-ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯æ¬¡ã®ã‚ˆã†ãªå ´åˆã«é©ç”¨ã§ãã¾ã™:\n+ãƒ¢ãƒ‡ãƒ«å®šç¾©ã‚’ä¸€å…ƒåŒ–ã™ã‚‹ã“ã¨ã§ã€ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã§ãã®å®šç¾©ãŒåˆæ„ã•ã‚Œã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚`transformers`ã¯ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é–“ã®ãƒ”ãƒœãƒƒãƒˆï¼ˆè¦ï¼‰ã¨ãªã‚Šã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«å®šç¾©ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚Œã°ã€å¤§éƒ¨åˆ†ã®å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯(Axolotl, Unsloth, DeepSpeed, FSDP, PyTorch-Lightning, ...)ã€æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³(vLLM, SGLang, TGI, ...)ã€ãŠã‚ˆã³`transformers`ã®ãƒ¢ãƒ‡ãƒ«å®šç¾©ã‚’æ´»ç”¨ã™ã‚‹éš£æ¥ã™ã‚‹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒª(llama.cpp, mlx, ...)ã¨äº’æ›æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n \n-* ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†é¡ã€æƒ…å ±æŠ½å‡ºã€è³ªå•å¿œç­”ã€è¦ç´„ã€ç¿»è¨³ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãªã©ã®ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã«ã€100ä»¥ä¸Šã®è¨€èªã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\n-* ğŸ–¼ï¸ ç”»åƒåˆ†é¡ã€ç‰©ä½“æ¤œå‡ºã€ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãªã©ã®ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã®ç”»åƒã€‚\n-* ğŸ—£ï¸ éŸ³å£°ã¯ã€éŸ³å£°èªè­˜ã‚„éŸ³å£°åˆ†é¡ãªã©ã®ã‚¿ã‚¹ã‚¯ã«ä½¿ç”¨ã—ã¾ã™ã€‚\n+ç§ãŸã¡ã¯ã€ãƒ¢ãƒ‡ãƒ«å®šç¾©ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã€ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ã€ã‹ã¤åŠ¹ç‡çš„ãªã‚‚ã®ã«ã™ã‚‹ã“ã¨ã§ã€æ–°ã—ã„æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã®ã‚µãƒãƒ¼ãƒˆã‚’æ”¯æ´ã—ã€ãã®åˆ©ç”¨ã‚’æ°‘ä¸»åŒ–ã™ã‚‹ã“ã¨ã‚’èª“ã„ã¾ã™ã€‚\n \n-ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ†ãƒ¼ãƒ–ãƒ«è³ªå•å¿œç­”ã€å…‰å­¦æ–‡å­—èªè­˜ã€ã‚¹ã‚­ãƒ£ãƒ³æ–‡æ›¸ã‹ã‚‰ã®æƒ…å ±æŠ½å‡ºã€ãƒ“ãƒ‡ã‚ªåˆ†é¡ã€è¦–è¦šçš„è³ªå•å¿œç­”ãªã©ã€**è¤‡æ•°ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’çµ„ã¿åˆã‚ã›ãŸ**ã‚¿ã‚¹ã‚¯ã‚‚å®Ÿè¡Œå¯èƒ½ã§ã™ã€‚\n+[Hugging Face Hub](https://huggingface.com/models)ã«ã¯ã€100ä¸‡ã‚’è¶…ãˆã‚‹Transformersã®[ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ](https://huggingface.co/models?library=transformers&sort=trending)ãŒã‚ã‚Šã€ã™ãã«ä½¿ç”¨ã§ãã¾ã™ã€‚\n \n-ğŸ¤—Transformersã¯ã€ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã¦ãã‚Œã‚‰ã®äº‹å‰å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ç´ æ—©ããƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ç”¨ã—ã€ã‚ãªãŸè‡ªèº«ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãã‚Œã‚‰ã‚’å¾®èª¿æ•´ã—ã€ç§ãŸã¡ã®[model hub](https://huggingface.co/models)ã§ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨å…±æœ‰ã™ã‚‹ãŸã‚ã®APIã‚’æä¾›ã—ã¾ã™ã€‚åŒæ™‚ã«ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å®šç¾©ã™ã‚‹å„Pythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯å®Œå…¨ã«ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ã§ã‚ã‚Šã€è¿…é€Ÿãªç ”ç©¶å®Ÿé¨“ã‚’å¯èƒ½ã«ã™ã‚‹ãŸã‚ã«å¤‰æ›´ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n+[Hub](https://huggingface.com/)ã‚’æ¢ç´¢ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è¦‹ã¤ã‘ã€Transformersã‚’ä½¿ã£ã¦ã™ãã«å§‹ã‚ã¾ã—ã‚‡ã†ã€‚\n \n-ğŸ¤—Transformersã¯[Jax](https://jax.readthedocs.io/en/latest/)ã€[PyTorch](https://pytorch.org/)ã€[TensorFlow](https://www.tensorflow.org/)ã¨ã„ã†3å¤§ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼ã«æ”¯ãˆã‚‰ã‚Œã€ãã‚Œãã‚Œã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã—ã¦ã„ã¾ã™ã€‚ç‰‡æ–¹ã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ã‹ã‚‰ã€ã‚‚ã†ç‰‡æ–¹ã§æ¨è«–ç”¨ã«ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã®ã¯ç°¡å˜ãªã“ã¨ã§ã™ã€‚\n+## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n \n-## ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¢\n+Transformersã¯Python 3.9ä»¥ä¸Šã€[PyTorch](https://pytorch.org/get-started/locally/) 2.1ä»¥ä¸Šã§å‹•ä½œã—ã¾ã™ã€‚\n \n-[model hub](https://huggingface.co/models)ã‹ã‚‰ã€ã»ã¨ã‚“ã©ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒšãƒ¼ã‚¸ã§ç›´æ¥ãƒ†ã‚¹ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã¾ãŸã€ãƒ‘ãƒ–ãƒªãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€[ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã®ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã€æ¨è«–API](https://huggingface.co/pricing)ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚\n+[venv](https://docs.python.org/3/library/venv.html)ã¾ãŸã¯ã€é«˜é€ŸãªRustãƒ™ãƒ¼ã‚¹ã®Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŠã‚ˆã³ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã‚ã‚‹[uv](https://docs.astral.sh/uv/)ã‚’ä½¿ç”¨ã—ã¦ã€ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã€æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚\n \n-ä»¥ä¸‹ã¯ãã®ä¸€ä¾‹ã§ã™:\n+```py\n+# venv\n+python -m venv .my-env\n+source .my-env/bin/activate\n+# uv\n+uv venv .my-env\n+source .my-env/bin/activate\n+```\n \n- è‡ªç„¶è¨€èªå‡¦ç†ã«ã¦:\n-- [BERTã«ã‚ˆã‚‹ãƒã‚¹ã‚¯ãƒ‰ãƒ¯ãƒ¼ãƒ‰è£œå®Œ](https://huggingface.co/google-bert/bert-base-uncased?text=Paris+is+the+%5BMASK%5D+of+France)\n-- [Electraã«ã‚ˆã‚‹åå‰å®Ÿä½“èªè­˜](https://huggingface.co/dbmdz/electra-large-discriminator-finetuned-conll03-english?text=My+name+is+Sarah+and+I+live+in+London+city)\n-- [GPT-2ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ](https://huggingface.co/openai-community/gpt2?text=A+long+time+ago%2C+)\n-- [RoBERTaã«ã‚ˆã‚‹è‡ªç„¶è¨€èªæ¨è«–](https://huggingface.co/FacebookAI/roberta-large-mnli?text=The+dog+was+lost.+Nobody+lost+any+animal)\n-- [BARTã«ã‚ˆã‚‹è¦ç´„](https://huggingface.co/facebook/bart-large-cnn?text=The+tower+is+324+metres+%281%2C063+ft%29+tall%2C+about+the+same+height+as+an+81-storey+building%2C+and+the+tallest+structure+in+Paris.+Its+base+is+square%2C+measuring+125+metres+%28410+ft%29+on+each+side.+During+its+construction%2C+the+Eiffel+Tower+surpassed+the+Washington+Monument+to+become+the+tallest+man-made+structure+in+the+world%2C+a+title+it+held+for+41+years+until+the+Chrysler+Building+in+New+York+City+was+finished+in+1930.+It+was+the+first+structure+to+reach+a+height+of+300+metres.+Due+to+the+addition+of+a+broadcasting+aerial+at+the+top+of+the+tower+in+1957%2C+it+is+now+taller+than+the+Chrysler+Building+by+5.2+metres+%2817+ft%29.+Excluding+transmitters%2C+the+Eiffel+Tower+is+the+second+tallest+free-standing+structure+in+France+after+the+Millau+Viaduct)\n-- [DistilBERTã«ã‚ˆã‚‹è³ªå•å¿œç­”](https://huggingface.co/distilbert/distilbert-base-uncased-distilled-squad?text=Which+name+is+also+used+to+describe+the+Amazon+rainforest+in+English%3F&context=The+Amazon+rainforest+%28Portuguese%3A+Floresta+Amaz%C3%B4nica+or+Amaz%C3%B4nia%3B+Spanish%3A+Selva+Amaz%C3%B3nica%2C+Amazon%C3%ADa+or+usually+Amazonia%3B+French%3A+For%C3%AAt+amazonienne%3B+Dutch%3A+Amazoneregenwoud%29%2C+also+known+in+English+as+Amazonia+or+the+Amazon+Jungle%2C+is+a+moist+broadleaf+forest+that+covers+most+of+the+Amazon+basin+of+South+America.+This+basin+encompasses+7%2C000%2C000+square+kilometres+%282%2C700%2C000+sq+mi%29%2C+of+which+5%2C500%2C000+square+kilometres+%282%2C100%2C000+sq+mi%29+are+covered+by+the+rainforest.+This+region+includes+territory+belonging+to+nine+nations.+The+majority+of+the+forest+is+contained+within+Brazil%2C+with+60%25+of+the+rainforest%2C+followed+by+Peru+with+13%25%2C+Colombia+with+10%25%2C+and+with+minor+amounts+in+Venezuela%2C+Ecuador%2C+Bolivia%2C+Guyana%2C+Suriname+and+French+Guiana.+States+or+departments+in+four+nations+contain+%22Amazonas%22+in+their+names.+The+Amazon+represents+over+half+of+the+planet%27s+remaining+rainforests%2C+and+comprises+the+largest+and+most+biodiverse+tract+of+tropical+rainforest+in+the+world%2C+with+an+estimated+390+billion+individual+trees+divided+into+16%2C000+species)\n-- [T5ã«ã‚ˆã‚‹ç¿»è¨³](https://huggingface.co/google-t5/t5-base?text=My+name+is+Wolfgang+and+I+live+in+Berlin)\n+ä»®æƒ³ç’°å¢ƒã«Transformersã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚\n \n-ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¦:\n-- [ViTã«ã‚ˆã‚‹ç”»åƒåˆ†é¡](https://huggingface.co/google/vit-base-patch16-224)\n-- [DETRã«ã‚ˆã‚‹ç‰©ä½“æ¤œå‡º](https://huggingface.co/facebook/detr-resnet-50)\n-- [SegFormerã«ã‚ˆã‚‹ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³](https://huggingface.co/nvidia/segformer-b0-finetuned-ade-512-512)\n-- [DETRã«ã‚ˆã‚‹ãƒ‘ãƒãƒ—ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³](https://huggingface.co/facebook/detr-resnet-50-panoptic)\n+```py\n+# pip\n+pip install \"transformers[torch]\"\n \n-ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã«ã¦:\n-- [Wav2Vec2ã«ã‚ˆã‚‹è‡ªå‹•éŸ³å£°èªè­˜](https://huggingface.co/facebook/wav2vec2-base-960h)\n-- [Wav2Vec2ã«ã‚ˆã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢](https://huggingface.co/superb/wav2vec2-base-superb-ks)\n+# uv\n+uv pip install \"transformers[torch]\"\n+```\n \n-ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªã‚¿ã‚¹ã‚¯ã«ã¦:\n-- [ViLTã«ã‚ˆã‚‹è¦–è¦šçš„è³ªå•å¿œç­”](https://huggingface.co/dandelin/vilt-b32-finetuned-vqa)\n+ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æœ€æ–°ã®å¤‰æ›´ãŒå¿…è¦ãªå ´åˆã‚„ã€è²¢çŒ®ã«èˆˆå‘³ãŒã‚ã‚‹å ´åˆã¯ã€ã‚½ãƒ¼ã‚¹ã‹ã‚‰Transformersã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚ãŸã ã—ã€*æœ€æ–°*ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å®‰å®šã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€ãŠæ°—è»½ã«[issue](https://github.com/huggingface/transformers/issues)ã‚’é–‹ã„ã¦ãã ã•ã„ã€‚\n \n-Hugging Faceãƒãƒ¼ãƒ ã«ã‚ˆã£ã¦ä½œã‚‰ã‚ŒãŸ **[ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’ä½¿ã£ãŸæ›¸ãè¾¼ã¿](https://transformer.huggingface.co)** ã¯ã€ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆæ©Ÿèƒ½ã®å…¬å¼ãƒ‡ãƒ¢ã§ã‚ã‚‹ã€‚\n+```shell\n+git clone https://github.com/huggingface/transformers.git\n+cd transformers\n \n-## Hugging Faceãƒãƒ¼ãƒ ã«ã‚ˆã‚‹ã‚«ã‚¹ã‚¿ãƒ ãƒ»ã‚µãƒãƒ¼ãƒˆã‚’ã”å¸Œæœ›ã®å ´åˆ\n+# pip\n+pip install '.[torch]'\n \n-<a target=\"_blank\" href=\"https://huggingface.co/support\">\n-    <img alt=\"HuggingFace Expert Acceleration Program\" src=\"https://cdn-media.huggingface.co/marketing/transformers/new-support-improved.png\" style=\"max-width: 600px; border: 1px solid #eee; border-radius: 4px; box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);\">\n-</a><br>\n+# uv\n+uv pip install '.[torch]'\n+```\n \n-## ã‚¯ã‚¤ãƒƒã‚¯ãƒ„ã‚¢ãƒ¼\n+## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ\n \n-ä¸ãˆã‚‰ã‚ŒãŸå…¥åŠ›ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€éŸ³å£°ã€...ï¼‰ã«å¯¾ã—ã¦ã™ãã«ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†ãŸã‚ã«ã€æˆ‘ã€…ã¯`pipeline`ã¨ã„ã†APIã‚’æä¾›ã—ã¦ãŠã‚Šã¾ã™ã€‚pipelineã¯ã€å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã¨ã€ãã®ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’æ™‚ã«ä½¿ç”¨ã•ã‚ŒãŸå‰å‡¦ç†ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ãŸã‚‚ã®ã§ã™ã€‚ä»¥ä¸‹ã¯ã€è‚¯å®šçš„ãªãƒ†ã‚­ã‚¹ãƒˆã¨å¦å®šçš„ãªãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†é¡ã™ã‚‹ãŸã‚ã«pipelineã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã§ã™:\n+[Pipeline](https://huggingface.co/docs/transformers/pipeline_tutorial) APIã‚’ä½¿ç”¨ã—ã¦ã€ã™ãã«Transformersã‚’å§‹ã‚ã¾ã—ã‚‡ã†ã€‚`Pipeline`ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã€éŸ³å£°ã€è¦–è¦šã€ãŠã‚ˆã³ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¿ã‚¹ã‚¯ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹é«˜ãƒ¬ãƒ™ãƒ«ã®æ¨è«–ã‚¯ãƒ©ã‚¹ã§ã™ã€‚å…¥åŠ›ã®å‰å‡¦ç†ã‚’è¡Œã„ã€é©åˆ‡ãªå‡ºåŠ›ã‚’è¿”ã—ã¾ã™ã€‚\n \n-```python\n->>> from transformers import pipeline\n+ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã—ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ãŸã‚ã€ç°¡å˜ã«å†åˆ©ç”¨ã§ãã¾ã™ã€‚æœ€å¾Œã«ã€ãƒ¢ãƒ‡ãƒ«ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¸¡ã—ã¾ã™ã€‚\n \n-# Allocate a pipeline for sentiment-analysis\n->>> classifier = pipeline('sentiment-analysis')\n->>> classifier('We are very happy to introduce pipeline to the transformers repository.')\n-[{'label': 'POSITIVE', 'score': 0.9996980428695679}]\n-```\n+```py\n+from transformers import pipeline\n \n-2è¡Œç›®ã®ã‚³ãƒ¼ãƒ‰ã§ã¯ã€pipelineã§ä½¿ç”¨ã•ã‚Œã‚‹äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã€3è¡Œç›®ã§ã¯ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã¦ãã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã¾ã™ã€‚ã“ã“ã§ã¯ã€ç­”ãˆã¯99.97%ã®ä¿¡é ¼åº¦ã§ã€Œãƒã‚¸ãƒ†ã‚£ãƒ–ã€ã§ã™ã€‚\n-\n-è‡ªç„¶è¨€èªå‡¦ç†ã ã‘ã§ãªãã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã‚„éŸ³å£°å‡¦ç†ã«ãŠã„ã¦ã‚‚ã€å¤šãã®ã‚¿ã‚¹ã‚¯ã«ã¯ã‚ã‚‰ã‹ã˜ã‚è¨“ç·´ã•ã‚ŒãŸ`pipeline`ãŒç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã€‚ä¾‹ãˆã°ã€ç”»åƒã‹ã‚‰æ¤œå‡ºã•ã‚ŒãŸç‰©ä½“ã‚’ç°¡å˜ã«æŠ½å‡ºã™ã‚‹ã“ã¨ãŒã§ãã‚‹:\n-\n-``` python\n->>> import requests\n->>> from PIL import Image\n->>> from transformers import pipeline\n-\n-# Download an image with cute cats\n->>> url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"\n->>> image_data = requests.get(url, stream=True).raw\n->>> image = Image.open(image_data)\n-\n-# Allocate a pipeline for object detection\n->>> object_detector = pipeline('object-detection')\n->>> object_detector(image)\n-[{'score': 0.9982201457023621,\n-  'label': 'remote',\n-  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}},\n- {'score': 0.9960021376609802,\n-  'label': 'remote',\n-  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}},\n- {'score': 0.9954745173454285,\n-  'label': 'couch',\n-  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}},\n- {'score': 0.9988006353378296,\n-  'label': 'cat',\n-  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}},\n- {'score': 0.9986783862113953,\n-  'label': 'cat',\n-  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]\n+pipeline = pipeline(task=\"text-generation\", model=\"Qwen/Qwen2.5-1.5B\")\n+pipeline(\"the secret to baking a really good cake is \")\n+[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]\n ```\n \n-ã“ã“ã§ã¯ã€ç”»åƒã‹ã‚‰æ¤œå‡ºã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆãŒå¾—ã‚‰ã‚Œã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å›²ã‚€ãƒœãƒƒã‚¯ã‚¹ã¨ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚å·¦å´ãŒå…ƒç”»åƒã€å³å´ãŒäºˆæ¸¬çµæœã‚’è¡¨ç¤ºã—ãŸã‚‚ã®ã§ã™:\n+ãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ£ãƒƒãƒˆã™ã‚‹å ´åˆã‚‚ã€ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯åŒã˜ã§ã™ã€‚å”¯ä¸€ã®é•ã„ã¯ã€ã‚ãªãŸã¨ã‚·ã‚¹ãƒ†ãƒ ã®é–“ã§ãƒãƒ£ãƒƒãƒˆå±¥æ­´ï¼ˆ`Pipeline`ã¸ã®å…¥åŠ›ï¼‰ã‚’æ§‹ç¯‰ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã§ã™ã€‚\n \n-<h3 align=\"center\">\n-    <a><img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\" width=\"400\"></a>\n-    <a><img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample_post_processed.png\" width=\"400\"></a>\n-</h3>\n+> [!TIP]\n+> ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‹ã‚‰ç›´æ¥ãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ£ãƒƒãƒˆã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n+> ```shell\n+> transformers chat Qwen/Qwen2.5-0.5B-Instruct\n+> ```\n \n-[ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/transformers/task_summary)ã§ã¯ã€`pipeline`APIã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ã„ã¾ã™ã€‚\n+```py\n+import torch\n+from transformers import pipeline\n \n-`pipeline`ã«åŠ ãˆã¦ã€ä¸ãˆã‚‰ã‚ŒãŸã‚¿ã‚¹ã‚¯ã«å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ç”¨ã™ã‚‹ãŸã‚ã«å¿…è¦ãªã®ã¯ã€3è¡Œã®ã‚³ãƒ¼ãƒ‰ã ã‘ã§ã™ã€‚ä»¥ä¸‹ã¯PyTorchã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã™:\n-```python\n->>> from transformers import AutoTokenizer, AutoModel\n+chat = [\n+    {\"role\": \"system\", \"content\": \"You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986.\"},\n+    {\"role\": \"user\", \"content\": \"Hey, can you tell me any fun things to do in New York?\"}\n+]\n \n->>> tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n->>> model = AutoModel.from_pretrained(\"google-bert/bert-base-uncased\")\n+pipeline = pipeline(task=\"text-generation\", model=\"meta-llama/Meta-Llama-3-8B-Instruct\", dtype=torch.bfloat16, device_map=\"auto\")\n+response = pipeline(chat, max_new_tokens=512)\n+print(response[0][\"generated_text\"][-1][\"content\"])\n+```\n+\n+ä»¥ä¸‹ã®ä¾‹ã‚’å±•é–‹ã—ã¦ã€ã•ã¾ã–ã¾ãªãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚„ã‚¿ã‚¹ã‚¯ã§`Pipeline`ãŒã©ã®ã‚ˆã†ã«æ©Ÿèƒ½ã™ã‚‹ã‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n+\n+<details>\n+<summary>è‡ªå‹•éŸ³å£°èªè­˜</summary>\n+\n+```py\n+from transformers import pipeline\n \n->>> inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n->>> outputs = model(**inputs)\n+pipeline = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-large-v3\")\n+pipeline(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n+{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}\n ```\n \n-ãã—ã¦ã“ã¡ã‚‰ã¯TensorFlowã¨åŒç­‰ã®ã‚³ãƒ¼ãƒ‰ã¨ãªã‚Šã¾ã™:\n-```python\n->>> from transformers import AutoTokenizer, TFAutoModel\n+</details>\n \n->>> tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n->>> model = TFAutoModel.from_pretrained(\"google-bert/bert-base-uncased\")\n+<details>\n+<summary>ç”»åƒåˆ†é¡</summary>\n \n->>> inputs = tokenizer(\"Hello world!\", return_tensors=\"tf\")\n->>> outputs = model(**inputs)\n+<h3 align=\"center\">\n+    <a><img src=\"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png\"></a>\n+</h3>\n+\n+```py\n+from transformers import pipeline\n+\n+pipeline = pipeline(task=\"image-classification\", model=\"facebook/dinov2-small-imagenet1k-1-layer\")\n+pipeline(\"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png\")\n+[{'label': 'macaw', 'score': 0.997848391532898},\n+ {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',\n+  'score': 0.0016551691805943847},\n+ {'label': 'lorikeet', 'score': 0.00018523589824326336},\n+ {'label': 'African grey, African gray, Psittacus erithacus',\n+  'score': 7.85409429227002e-05},\n+ {'label': 'quail', 'score': 5.502637941390276e-05}]\n ```\n \n-ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¯å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹ã™ã¹ã¦ã®å‰å‡¦ç†ã‚’æ‹…å½“ã—ã€å˜ä¸€ã®æ–‡å­—åˆ— (ä¸Šè¨˜ã®ä¾‹ã®ã‚ˆã†ã«) ã¾ãŸã¯ãƒªã‚¹ãƒˆã«å¯¾ã—ã¦ç›´æ¥å‘¼ã³å‡ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã¯ä¸‹æµã®ã‚³ãƒ¼ãƒ‰ã§ä½¿ç”¨ã§ãã‚‹è¾æ›¸ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚ã¾ãŸã€å˜ç´”ã« ** å¼•æ•°å±•é–‹æ¼”ç®—å­ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã«ç›´æ¥æ¸¡ã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n+</details>\n+\n+<details>\n+<summary>è¦–è¦šçš„è³ªå•å¿œç­”</summary>\n \n-ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã¯é€šå¸¸ã®[Pytorch `nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) ã¾ãŸã¯ [TensorFlow `tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) (ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ã‚ˆã£ã¦ç•°ãªã‚‹)ã§ã€é€šå¸¸é€šã‚Šä½¿ç”¨ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚[ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/transformers/training)ã§ã¯ã€ã“ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã‚’å¾“æ¥ã®PyTorchã‚„TensorFlowã®å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã«çµ±åˆã™ã‚‹æ–¹æ³•ã‚„ã€ç§ãŸã¡ã®`Trainer`APIã‚’ä½¿ã£ã¦æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ç´ æ—©ãå¾®èª¿æ•´ã‚’è¡Œã†æ–¹æ³•ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚\n+<h3 align=\"center\">\n+    <a><img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg\"></a>\n+</h3>\n+\n+```py\n+from transformers import pipeline\n+\n+pipeline = pipeline(task=\"visual-question-answering\", model=\"Salesforce/blip-vqa-base\")\n+pipeline(\n+    image=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg\",\n+    question=\"What is in the image?\",\n+)\n+[{'answer': 'statue of liberty'}]\n+```\n+\n+</details>\n \n ## ãªãœtransformersã‚’ä½¿ã†å¿…è¦ãŒã‚ã‚‹ã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ\n \n-1. ä½¿ã„ã‚„ã™ã„æœ€æ–°ãƒ¢ãƒ‡ãƒ«:\n-    - è‡ªç„¶è¨€èªç†è§£ãƒ»ç”Ÿæˆã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã€ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã®å„ã‚¿ã‚¹ã‚¯ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™ã€‚\n-    - æ•™è‚²è€…ã€å®Ÿå‹™è€…ã«ã¨ã£ã¦ã®ä½ã„å‚å…¥éšœå£ã€‚\n+1. ä½¿ã„ã‚„ã™ã„æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«:\n+    - è‡ªç„¶è¨€èªç†è§£ãƒ»ç”Ÿæˆã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã€éŸ³å£°ã€å‹•ç”»ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¿ã‚¹ã‚¯ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™ã€‚\n+    - ç ”ç©¶è€…ã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€é–‹ç™ºè€…ã«ã¨ã£ã¦ã®ä½ã„å‚å…¥éšœå£ã€‚\n     - å­¦ç¿’ã™ã‚‹ã‚¯ãƒ©ã‚¹ã¯3ã¤ã ã‘ã§ã€ãƒ¦ãƒ¼ã‚¶ãŒç›´é¢ã™ã‚‹æŠ½è±¡åŒ–ã¯ã»ã¨ã‚“ã©ã‚ã‚Šã¾ã›ã‚“ã€‚\n-    - å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã®çµ±ä¸€ã•ã‚ŒãŸAPIã€‚\n+    - ã™ã¹ã¦ã®äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã®çµ±ä¸€ã•ã‚ŒãŸAPIã€‚\n \n 1. ä½ã„è¨ˆç®—ã‚³ã‚¹ãƒˆã€å°‘ãªã„ã‚«ãƒ¼ãƒœãƒ³ãƒ•ãƒƒãƒˆãƒ—ãƒªãƒ³ãƒˆ:\n-    - ç ”ç©¶è€…ã¯ã€å¸¸ã«å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã®ã§ã¯ãªãã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å…±æœ‰ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n-    - å®Ÿå‹™å®¶ã¯ã€è¨ˆç®—æ™‚é–“ã‚„ç”Ÿç”£ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n-    - ã™ã¹ã¦ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«ãŠã„ã¦ã€60,000ä»¥ä¸Šã®äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’æŒã¤æ•°å¤šãã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æä¾›ã—ã¾ã™ã€‚\n+    - ã‚¼ãƒ­ã‹ã‚‰å­¦ç¿’ã™ã‚‹ã®ã§ã¯ãªãã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’å…±æœ‰ã§ãã¾ã™ã€‚\n+    - è¨ˆç®—æ™‚é–“ã‚„ç”Ÿç”£ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã§ãã¾ã™ã€‚\n+    - ã™ã¹ã¦ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«ãŠã„ã¦ã€100ä¸‡ä»¥ä¸Šã®äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æŒã¤å¤šæ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æä¾›ã—ã¾ã™ã€‚\n \n-1. ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ã‚¤ãƒ•ã‚¿ã‚¤ãƒ ã®ã‚ã‚‰ã‚†ã‚‹éƒ¨åˆ†ã§é©åˆ‡ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é¸æŠå¯èƒ½:\n-    - 3è¡Œã®ã‚³ãƒ¼ãƒ‰ã§æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€‚\n-    - TF2.0/PyTorch/JAXãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é–“ã§1ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªåœ¨ã«ç§»å‹•ã•ã›ã‚‹ã€‚\n-    - å­¦ç¿’ã€è©•ä¾¡ã€ç”Ÿç”£ã«é©ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«é¸æŠã§ãã¾ã™ã€‚\n+1. ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã®ã‚ã‚‰ã‚†ã‚‹éƒ¨åˆ†ã§é©åˆ‡ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é¸æŠå¯èƒ½:\n+    - 3è¡Œã®ã‚³ãƒ¼ãƒ‰ã§æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã€‚\n+    - PyTorch/JAX/TF2.0ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é–“ã§1ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªåœ¨ã«ç§»å‹•å¯èƒ½ã€‚\n+    - å­¦ç¿’ã€è©•ä¾¡ã€æœ¬ç•ªç’°å¢ƒã«é©ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é¸æŠã§ãã¾ã™ã€‚\n \n-1. ãƒ¢ãƒ‡ãƒ«ã‚„ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒ‹ãƒ¼ã‚ºã«åˆã‚ã›ã¦ç°¡å˜ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½:\n+1. ãƒ¢ãƒ‡ãƒ«ã‚„ä¾‹ã‚’ãƒ‹ãƒ¼ã‚ºã«åˆã‚ã›ã¦ç°¡å˜ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½:\n     - åŸè‘—è€…ãŒç™ºè¡¨ã—ãŸçµæœã‚’å†ç¾ã™ã‚‹ãŸã‚ã«ã€å„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ä¾‹ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚\n     - ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã¯å¯èƒ½ãªé™ã‚Šä¸€è²«ã—ã¦å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚\n     - ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã¯ç‹¬ç«‹ã—ã¦åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã€è¿…é€Ÿãªå®Ÿé¨“ãŒå¯èƒ½ã§ã™ã€‚\n \n+<a target=\"_blank\" href=\"https://huggingface.co/enterprise\">\n+    <img alt=\"Hugging Face Enterprise Hub\" src=\"https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925\">\n+</a><br>\n+\n ## ãªãœtransformersã‚’ä½¿ã£ã¦ã¯ã„ã‘ãªã„ã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ\n \n - ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®ãŸã‚ã®ãƒ“ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å¼ãƒ„ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ç ”ç©¶è€…ãŒè¿½åŠ ã®æŠ½è±¡åŒ–/ãƒ•ã‚¡ã‚¤ãƒ«ã«é£›ã³è¾¼ã‚€ã“ã¨ãªãã€å„ãƒ¢ãƒ‡ãƒ«ã‚’ç´ æ—©ãåå¾©ã§ãã‚‹ã‚ˆã†ã«ã€æ„å›³çš„ã«è¿½åŠ ã®æŠ½è±¡åŒ–ã§ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n-- å­¦ç¿’APIã¯ã©ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã§ã‚‚å‹•ä½œã™ã‚‹ã‚ã‘ã§ã¯ãªãã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæä¾›ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã§å‹•ä½œã™ã‚‹ã‚ˆã†ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚ä¸€èˆ¬çš„ãªæ©Ÿæ¢°å­¦ç¿’ã®ãƒ«ãƒ¼ãƒ—ã«ã¯ã€åˆ¥ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª(ãŠãã‚‰ã[Accelerate](https://huggingface.co/docs/accelerate))ã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n-- ç§ãŸã¡ã¯ã§ãã‚‹ã ã‘å¤šãã®ä½¿ç”¨ä¾‹ã‚’ç´¹ä»‹ã™ã‚‹ã‚ˆã†åŠªåŠ›ã—ã¦ã„ã¾ã™ãŒã€[examples ãƒ•ã‚©ãƒ«ãƒ€](https://github.com/huggingface/transformers/tree/main/examples) ã«ã‚ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã‚ãã¾ã§ä¾‹ã§ã™ã€‚ã‚ãªãŸã®ç‰¹å®šã®å•é¡Œã«å¯¾ã—ã¦ã™ãã«å‹•ä½œã™ã‚‹ã‚ã‘ã§ã¯ãªãã€ã‚ãªãŸã®ãƒ‹ãƒ¼ã‚ºã«åˆã‚ã›ã‚‹ãŸã‚ã«æ•°è¡Œã®ã‚³ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ãŒäºˆæƒ³ã•ã‚Œã¾ã™ã€‚\n+- å­¦ç¿’APIã¯TransformersãŒæä¾›ã™ã‚‹PyTorchãƒ¢ãƒ‡ãƒ«ã§å‹•ä½œã™ã‚‹ã‚ˆã†ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚ä¸€èˆ¬çš„ãªæ©Ÿæ¢°å­¦ç¿’ã®ãƒ«ãƒ¼ãƒ—ã«ã¯ã€[Accelerate](https://huggingface.co/docs/accelerate)ã®ã‚ˆã†ãªåˆ¥ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n+- [example scripts](https://github.com/huggingface/transformers/tree/main/examples)ã«ã‚ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã‚ãã¾ã§*ä¾‹*ã§ã™ã€‚ã‚ãªãŸã®ç‰¹å®šã®å•é¡Œã«å¯¾ã—ã¦ã™ãã«å‹•ä½œã™ã‚‹ã‚ã‘ã§ã¯ãªãã€ã‚ãªãŸã®ãƒ‹ãƒ¼ã‚ºã«åˆã‚ã›ã‚‹ãŸã‚ã«ã‚³ãƒ¼ãƒ‰ã‚’é©å¿œã•ã›ã‚‹å¿…è¦ãŒã‚ã‚‹ã§ã—ã‚‡ã†ã€‚\n \n-## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n-\n-### pipã«ã¦\n-\n-ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ã€Python 3.9+, Flax 0.4.1+, PyTorch 2.1+, TensorFlow 2.6+ ã§ãƒ†ã‚¹ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n-\n-ğŸ¤—Transformersã¯[ä»®æƒ³ç’°å¢ƒ](https://docs.python.org/3/library/venv.html)ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Pythonã®ä»®æƒ³ç’°å¢ƒã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€[ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¬ã‚¤ãƒ‰](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n+## Transformersã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹100ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ\n \n-ã¾ãšã€ä½¿ç”¨ã™ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®Pythonã§ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆã—ã¾ã™ã€‚\n+Transformersã¯äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆä»¥ä¸Šã®ã‚‚ã®ã§ã‚ã‚Šã€ãã‚Œã¨Hugging Face Hubã‚’ä¸­å¿ƒã«æ§‹ç¯‰ã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã§ã™ã€‚ç§ãŸã¡ã¯ã€é–‹ç™ºè€…ã€ç ”ç©¶è€…ã€å­¦ç”Ÿã€æ•™æˆã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€ãã—ã¦ãã®ä»–ã®èª°ã‚‚ãŒå¤¢ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æ§‹ç¯‰ã§ãã‚‹ã‚ˆã†ã«Transformersã‚’æä¾›ã—ãŸã„ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚\n \n-ãã®å¾Œã€Flax, PyTorch, TensorFlowã®ã†ã¡å°‘ãªãã¨ã‚‚1ã¤ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n-[TensorFlowã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒšãƒ¼ã‚¸](https://www.tensorflow.org/install/)ã€[PyTorchã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒšãƒ¼ã‚¸](https://pytorch.org/get-started/locally/#start-locally)ã€[Flax](https://github.com/google/flax#quick-install)ã€[Jax](https://github.com/google/jax#installation)ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒšãƒ¼ã‚¸ã§ã€ãŠä½¿ã„ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚³ãƒãƒ³ãƒ‰ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n+Transformersã®10ä¸‡ã‚¹ã‚¿ãƒ¼ã‚’è¨˜å¿µã—ã¦ã€Transformersã§æ§‹ç¯‰ã•ã‚ŒãŸ100ã®ç´ æ™´ã‚‰ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ãŸ[awesome-transformers](./awesome-transformers.md)ãƒšãƒ¼ã‚¸ã§ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ã‚¹ãƒãƒƒãƒˆãƒ©ã‚¤ãƒˆã‚’å½“ã¦ãŸã„ã¨è€ƒãˆã¾ã—ãŸã€‚\n \n-ã“ã‚Œã‚‰ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ã„ãšã‚Œã‹ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å ´åˆã€ğŸ¤—Transformersã¯ä»¥ä¸‹ã®ã‚ˆã†ã«pipã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™:\n+ã‚‚ã—ã‚ãªãŸãŒãƒªã‚¹ãƒˆã«åŠ ãˆã‚‹ã¹ãã ã¨æ€ã†ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æ‰€æœ‰ã¾ãŸã¯ä½¿ç”¨ã—ã¦ã„ã‚‹ãªã‚‰ã€ãœã²PRã‚’é–‹ã„ã¦è¿½åŠ ã—ã¦ãã ã•ã„ï¼\n \n-```bash\n-pip install transformers\n-```\n-\n-ã‚‚ã—ã‚µãƒ³ãƒ—ãƒ«ã‚’è©¦ã—ãŸã„ã€ã¾ãŸã¯ã‚³ãƒ¼ãƒ‰ã®æœ€å…ˆç«¯ãŒå¿…è¦ã§ã€æ–°ã—ã„ãƒªãƒªãƒ¼ã‚¹ã‚’å¾…ã¦ãªã„å ´åˆã¯ã€[ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«](https://huggingface.co/docs/transformers/installation#installing-from-source)ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n+## ãƒ¢ãƒ‡ãƒ«ã®ä¾‹\n \n-### condaã«ã¦\n+[Hubã®ãƒ¢ãƒ‡ãƒ«ãƒšãƒ¼ã‚¸](https://huggingface.co/models)ã§ã€ã»ã¨ã‚“ã©ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç›´æ¥ãƒ†ã‚¹ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n \n-ğŸ¤—Transformersã¯ä»¥ä¸‹ã®ã‚ˆã†ã«condaã‚’ä½¿ã£ã¦è¨­ç½®ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™:\n-\n-```shell script\n-conda install conda-forge::transformers\n-```\n+ä»¥ä¸‹ã®å„ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’å±•é–‹ã—ã¦ã€ã•ã¾ã–ã¾ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ä¾‹ã‚’ã„ãã¤ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n \n-> **_æ³¨æ„:_**  `huggingface` ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰ `transformers` ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã¯éæ¨å¥¨ã§ã™ã€‚\n+<details>\n+<summary>éŸ³å£°</summary>\n \n-Flaxã€PyTorchã€TensorFlowã‚’condaã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹æ–¹æ³•ã¯ã€ãã‚Œãã‚Œã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒšãƒ¼ã‚¸ã«å¾“ã£ã¦ãã ã•ã„ã€‚\n+- [Whisper](https://huggingface.co/openai/whisper-large-v3-turbo)ã«ã‚ˆã‚‹éŸ³å£°åˆ†é¡\n+- [Moonshine](https://huggingface.co/UsefulSensors/moonshine)ã«ã‚ˆã‚‹è‡ªå‹•éŸ³å£°èªè­˜\n+- [Wav2Vec2](https://huggingface.co/superb/wav2vec2-base-superb-ks)ã«ã‚ˆã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¹ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°\n+- [Moshi](https://huggingface.co/kyutai/moshiko-pytorch-bf16)ã«ã‚ˆã‚‹éŸ³å£°å¯¾éŸ³å£°ç”Ÿæˆ\n+- [MusicGen](https://huggingface.co/facebook/musicgen-large)ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆå¯¾éŸ³å£°\n+- [Bark](https://huggingface.co/suno/bark)ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’\n \n-> **_æ³¨æ„:_**  Windowsã§ã¯ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ©æµã‚’å—ã‘ã‚‹ãŸã‚ã«ã€ãƒ‡ãƒ™ãƒ­ãƒƒãƒ‘ãƒ¼ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‚ˆã†ä¿ƒã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ã‚ˆã†ãªå ´åˆã¯ã€[ã“ã®issue](https://github.com/huggingface/huggingface_hub/issues/1062)ã§ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚\n+</details>\n \n-## ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n+<details>\n+<summary>ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³</summary>\n \n-ğŸ¤—TransformersãŒæä¾›ã™ã‚‹ **[å…¨ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ](https://huggingface.co/models)** ã¯ã€[ãƒ¦ãƒ¼ã‚¶ãƒ¼](https://huggingface.co/users)ã‚„[çµ„ç¹”](https://huggingface.co/organizations)ã«ã‚ˆã£ã¦ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹huggingface.co [model hub](https://huggingface.co)ã‹ã‚‰ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n+- [SAM](https://huggingface.co/facebook/sam-vit-base)ã«ã‚ˆã‚‹è‡ªå‹•ãƒã‚¹ã‚¯ç”Ÿæˆ\n+- [DepthPro](https://huggingface.co/apple/DepthPro-hf)ã«ã‚ˆã‚‹æ·±åº¦æ¨å®š\n+- [DINO v2](https://huggingface.co/facebook/dinov2-base)ã«ã‚ˆã‚‹ç”»åƒåˆ†é¡\n+- [SuperPoint](https://huggingface.co/magic-leap-community/superpoint)ã«ã‚ˆã‚‹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡º\n+- [SuperGlue](https://huggingface.co/magic-leap-community/superglue_outdoor)ã«ã‚ˆã‚‹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒãƒƒãƒãƒ³ã‚°\n+- [RT-DETRv2](https://huggingface.co/PekingU/rtdetr_v2_r50vd)ã«ã‚ˆã‚‹ç‰©ä½“æ¤œå‡º\n+- [VitPose](https://huggingface.co/usyd-community/vitpose-base-simple)ã«ã‚ˆã‚‹å§¿å‹¢æ¨å®š\n+- [OneFormer](https://huggingface.co/shi-labs/oneformer_ade20k_swin_large)ã«ã‚ˆã‚‹ãƒ¦ãƒ‹ãƒãƒ¼ã‚µãƒ«ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³\n+- [VideoMAE](https://huggingface.co/MCG-NJU/videomae-large)ã«ã‚ˆã‚‹å‹•ç”»åˆ†é¡\n \n-ç¾åœ¨ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ•°: ![](https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen)\n+</details>\n \n-ğŸ¤—Transformersã¯ç¾åœ¨ã€ä»¥ä¸‹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æä¾›ã—ã¦ã„ã¾ã™: ãã‚Œãã‚Œã®ãƒã‚¤ãƒ¬ãƒ™ãƒ«ãªè¦ç´„ã¯[ã“ã¡ã‚‰](https://huggingface.co/docs/transformers/model_summary)ã‚’å‚ç…§ã—ã¦ãã ã•ã„.\n+<details>\n+<summary>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«</summary>\n \n-å„ãƒ¢ãƒ‡ãƒ«ãŒFlaxã€PyTorchã€TensorFlowã§å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã‹ã€ğŸ¤—Tokenizersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«æ”¯ãˆã‚‰ã‚ŒãŸé–¢é€£ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’æŒã£ã¦ã„ã‚‹ã‹ã¯ã€[ã“ã®è¡¨](https://huggingface.co/docs/transformers/index#supported-frameworks)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n+- [Qwen2-Audio](https://huggingface.co/Qwen/Qwen2-Audio-7B)ã«ã‚ˆã‚‹éŸ³å£°ã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆå¯¾ãƒ†ã‚­ã‚¹ãƒˆ\n+- [LayoutLMv3](https://huggingface.co/microsoft/layoutlmv3-base)ã«ã‚ˆã‚‹æ–‡æ›¸è³ªå•å¿œç­”\n+- [Qwen-VL](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct)ã«ã‚ˆã‚‹ç”»åƒã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆå¯¾ãƒ†ã‚­ã‚¹ãƒˆ\n+- [BLIP-2](https://huggingface.co/Salesforce/blip2-opt-2.7b)ã«ã‚ˆã‚‹ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³\n+- [GOT-OCR2](https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf)ã«ã‚ˆã‚‹OCRãƒ™ãƒ¼ã‚¹ã®æ–‡æ›¸ç†è§£\n+- [TAPAS](https://huggingface.co/google/tapas-base)ã«ã‚ˆã‚‹è¡¨è³ªå•å¿œç­”\n+- [Emu3](https://huggingface.co/BAAI/Emu3-Gen)ã«ã‚ˆã‚‹çµ±ä¸€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç†è§£ã¨ç”Ÿæˆ\n+- [Llava-OneVision](https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf)ã«ã‚ˆã‚‹è¦–è¦šå¯¾ãƒ†ã‚­ã‚¹ãƒˆ\n+- [Llava](https://huggingface.co/llava-hf/llava-1.5-7b-hf)ã«ã‚ˆã‚‹è¦–è¦šçš„è³ªå•å¿œç­”\n+- [Kosmos-2](https://huggingface.co/microsoft/kosmos-2-patch14-224)ã«ã‚ˆã‚‹è¦–è¦šçš„å‚ç…§è¡¨ç¾ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³\n \n-ã“ã‚Œã‚‰ã®å®Ÿè£…ã¯ã„ãã¤ã‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ†ã‚¹ãƒˆã•ã‚Œã¦ãŠã‚Š(ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å‚ç…§)ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®å®Ÿè£…ã®æ€§èƒ½ã¨ä¸€è‡´ã™ã‚‹ã¯ãšã§ã‚ã‚‹ã€‚æ€§èƒ½ã®è©³ç´°ã¯[documentation](https://github.com/huggingface/transformers/tree/main/examples)ã®Examplesã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§è¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n+</details>\n \n+<details>\n+<summary>è‡ªç„¶è¨€èªå‡¦ç† (NLP)</summary>\n \n-## ã•ã‚‰ã«è©³ã—ã\n+- [ModernBERT](https://huggingface.co/answerdotai/ModernBERT-base)ã«ã‚ˆã‚‹ãƒã‚¹ã‚¯å˜èªè£œå®Œ\n+- [Gemma](https://huggingface.co/google/gemma-2-2b)ã«ã‚ˆã‚‹å›ºæœ‰è¡¨ç¾èªè­˜\n+- [Mixtral](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)ã«ã‚ˆã‚‹è³ªå•å¿œç­”\n+- [BART](https://huggingface.co/facebook/bart-large-cnn)ã«ã‚ˆã‚‹è¦ç´„\n+- [T5](https://huggingface.co/google-t5/t5-base)ã«ã‚ˆã‚‹ç¿»è¨³\n+- [Llama](https://huggingface.co/meta-llama/Llama-3.2-1B)ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ\n+- [Qwen](https://huggingface.co/Qwen/Qwen2.5-0.5B)ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡\n \n-| ã‚»ã‚¯ã‚·ãƒ§ãƒ³ | æ¦‚è¦ |\n-|-|-|\n-| [ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://huggingface.co/docs/transformers/) | å®Œå…¨ãªAPIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ« |\n-| [ã‚¿ã‚¹ã‚¯æ¦‚è¦](https://huggingface.co/docs/transformers/task_summary) | ğŸ¤—TransformersãŒã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚¿ã‚¹ã‚¯ |\n-| [å‰å‡¦ç†ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/transformers/preprocessing) | ãƒ¢ãƒ‡ãƒ«ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã™ã‚‹ãŸã‚ã«`Tokenizer`ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ |\n-| [ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å¾®èª¿æ•´](https://huggingface.co/docs/transformers/training) | PyTorch/TensorFlowã®å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã¨`Trainer`APIã§ğŸ¤—TransformersãŒæä¾›ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ |\n-| [ã‚¯ã‚¤ãƒƒã‚¯ãƒ„ã‚¢ãƒ¼: å¾®èª¿æ•´/ä½¿ç”¨æ–¹æ³•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ](https://github.com/huggingface/transformers/tree/main/examples) | æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã§ãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã‚’è¡Œã†ãŸã‚ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ |\n-| [ãƒ¢ãƒ‡ãƒ«ã®å…±æœ‰ã¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰](https://huggingface.co/docs/transformers/model_sharing) | å¾®èª¿æ•´ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã§å…±æœ‰ã™ã‚‹ |\n-| [ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³](https://huggingface.co/docs/transformers/migration) | `pytorch-transformers`ã¾ãŸã¯`pytorch-pretrained-bert`ã‹ã‚‰ğŸ¤—Transformers ã«ç§»è¡Œã™ã‚‹ |\n+</details>\n \n ## å¼•ç”¨\n \n-ğŸ¤— ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«å¼•ç”¨ã§ãã‚‹[è«–æ–‡](https://www.aclweb.org/anthology/2020.emnlp-demos.6/)ãŒå‡ºæ¥ã¾ã—ãŸ:\n+ğŸ¤— Transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã¤ã„ã¦å¼•ç”¨ã§ãã‚‹[è«–æ–‡](https://www.aclweb.org/anthology/2020.emnlp-demos.6/)ãŒã§ãã¾ã—ãŸ:\n ```bibtex\n @inproceedings{wolf-etal-2020-transformers,\n     title = \"Transformers: State-of-the-Art Natural Language Processing\","
        }
    ],
    "stats": {
        "total": 337,
        "additions": 181,
        "deletions": 156
    }
}