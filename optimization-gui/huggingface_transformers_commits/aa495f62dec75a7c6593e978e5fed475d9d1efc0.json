{
    "author": "remi-or",
    "message": "Fixes for the failures of AMD CI (#42718)\n\n* Bump timm requirement\n\n* Add sync to avoid params not transfered\n\n* Multi-device BLT error\n\n* Multi-device EfficientNet error\n\n* Multi-device Ernie error\n\n* Multi-device Mimi error\n\n* Makes\n\n* Stop using .to and use no_split_modules instead\n\n* Restore no_split to Ernie",
    "sha": "aa495f62dec75a7c6593e978e5fed475d9d1efc0",
    "files": [
        {
            "sha": "8e3a0b9f8f36fe21fd380e54f3d2857875d9e448",
            "filename": "setup.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/aa495f62dec75a7c6593e978e5fed475d9d1efc0/setup.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aa495f62dec75a7c6593e978e5fed475d9d1efc0/setup.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/setup.py?ref=aa495f62dec75a7c6593e978e5fed475d9d1efc0",
            "patch": "@@ -140,7 +140,7 @@\n     \"tensorboard\",\n     \"timeout-decorator\",\n     \"tiktoken\",\n-    \"timm<=1.0.19,!=1.0.18\",\n+    \"timm>=1.0.20\",\n     \"tokenizers>=0.22.0,<=0.23.0\",\n     \"torch>=2.2\",\n     \"torchaudio\","
        },
        {
            "sha": "032304041f738e3c0359cceb27550f8654fe92b5",
            "filename": "src/transformers/dependency_versions_table.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fdependency_versions_table.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fdependency_versions_table.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdependency_versions_table.py?ref=aa495f62dec75a7c6593e978e5fed475d9d1efc0",
            "patch": "@@ -75,7 +75,7 @@\n     \"tensorboard\": \"tensorboard\",\n     \"timeout-decorator\": \"timeout-decorator\",\n     \"tiktoken\": \"tiktoken\",\n-    \"timm\": \"timm<=1.0.19,!=1.0.18\",\n+    \"timm\": \"timm>=1.0.20\",\n     \"tokenizers\": \"tokenizers>=0.22.0,<=0.23.0\",\n     \"torch\": \"torch>=2.2\",\n     \"torchaudio\": \"torchaudio\","
        },
        {
            "sha": "472dafa6e1e27be90e325078e320baf5ec7d5e95",
            "filename": "src/transformers/models/align/modeling_align.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fmodels%2Falign%2Fmodeling_align.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fmodels%2Falign%2Fmodeling_align.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Falign%2Fmodeling_align.py?ref=aa495f62dec75a7c6593e978e5fed475d9d1efc0",
            "patch": "@@ -976,6 +976,7 @@ class AlignVisionModel(AlignPreTrainedModel):\n     main_input_name = \"pixel_values\"\n     input_modalities = (\"image\",)\n     supports_gradient_checkpointing = False\n+    _no_split_modules = [\"AlignVisionBlock\"]\n \n     def __init__(self, config: AlignVisionConfig):\n         super().__init__(config)"
        },
        {
            "sha": "a11a1773c7b100fa07eaf628b32220e77c0e182c",
            "filename": "src/transformers/models/blt/modeling_blt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fmodels%2Fblt%2Fmodeling_blt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fmodels%2Fblt%2Fmodeling_blt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblt%2Fmodeling_blt.py?ref=aa495f62dec75a7c6593e978e5fed475d9d1efc0",
            "patch": "@@ -952,7 +952,7 @@ def compute_hash_embeddings(\n             hash_ids = byte_group_hash_function(local_encoder_tokens, group_size, prime, encoder_hash_byte_group_vocab)\n             # Apply offset to get the correct slice of the fused embedding\n             offset_hash_ids = hash_ids + embedding_idx * encoder_hash_byte_group_vocab\n-            embeddings += encoder_hash_tok_embedding(offset_hash_ids)\n+            embeddings += encoder_hash_tok_embedding(offset_hash_ids).to(embeddings.device)\n             embedding_idx += 1\n \n     return embeddings"
        },
        {
            "sha": "9a308ca7f328bc9adc527bafeff2ad7323973138",
            "filename": "src/transformers/models/blt/modular_blt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fmodels%2Fblt%2Fmodular_blt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fmodels%2Fblt%2Fmodular_blt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblt%2Fmodular_blt.py?ref=aa495f62dec75a7c6593e978e5fed475d9d1efc0",
            "patch": "@@ -133,7 +133,7 @@ def compute_hash_embeddings(\n             hash_ids = byte_group_hash_function(local_encoder_tokens, group_size, prime, encoder_hash_byte_group_vocab)\n             # Apply offset to get the correct slice of the fused embedding\n             offset_hash_ids = hash_ids + embedding_idx * encoder_hash_byte_group_vocab\n-            embeddings += encoder_hash_tok_embedding(offset_hash_ids)\n+            embeddings += encoder_hash_tok_embedding(offset_hash_ids).to(embeddings.device)\n             embedding_idx += 1\n \n     return embeddings"
        },
        {
            "sha": "35abe383dbdf0441b13a32749a4690a9366cfbfd",
            "filename": "src/transformers/models/efficientnet/modeling_efficientnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fmodeling_efficientnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fmodeling_efficientnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fmodeling_efficientnet.py?ref=aa495f62dec75a7c6593e978e5fed475d9d1efc0",
            "patch": "@@ -435,7 +435,7 @@ class EfficientNetPreTrainedModel(PreTrainedModel):\n     base_model_prefix = \"efficientnet\"\n     main_input_name = \"pixel_values\"\n     input_modalities = (\"image\",)\n-    _no_split_modules = []\n+    _no_split_modules = [\"EfficientNetBlock\"]\n \n     @torch.no_grad()\n     def _init_weights(self, module: nn.Module):"
        },
        {
            "sha": "5324dcac4fa6bccd77756e148933c39aaeb6184d",
            "filename": "src/transformers/models/ernie/modeling_ernie.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fmodels%2Fernie%2Fmodeling_ernie.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fmodels%2Fernie%2Fmodeling_ernie.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie%2Fmodeling_ernie.py?ref=aa495f62dec75a7c6593e978e5fed475d9d1efc0",
            "patch": "@@ -113,6 +113,9 @@ def forward(\n         if inputs_embeds is None:\n             inputs_embeds = self.word_embeddings(input_ids)\n         token_type_embeddings = self.token_type_embeddings(token_type_ids)\n+\n+        # .to is better than using _no_split_modules on ErnieEmbeddings as it's the first module and >1/2 the model size\n+        inputs_embeds = inputs_embeds.to(token_type_embeddings.device)\n         embeddings = inputs_embeds + token_type_embeddings\n \n         position_embeddings = self.position_embeddings(position_ids)"
        },
        {
            "sha": "6db1fffeb2d274c4e29ad8ef8f80a7a8119d4d91",
            "filename": "src/transformers/models/ernie/modular_ernie.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fmodels%2Fernie%2Fmodular_ernie.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fmodels%2Fernie%2Fmodular_ernie.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie%2Fmodular_ernie.py?ref=aa495f62dec75a7c6593e978e5fed475d9d1efc0",
            "patch": "@@ -107,6 +107,9 @@ def forward(\n         if inputs_embeds is None:\n             inputs_embeds = self.word_embeddings(input_ids)\n         token_type_embeddings = self.token_type_embeddings(token_type_ids)\n+\n+        # .to is better than using _no_split_modules on ErnieEmbeddings as it's the first module and >1/2 the model size\n+        inputs_embeds = inputs_embeds.to(token_type_embeddings.device)\n         embeddings = inputs_embeds + token_type_embeddings\n \n         position_embeddings = self.position_embeddings(position_ids)"
        },
        {
            "sha": "598dfbc68970870bdde28460c10444d0deeb3c6c",
            "filename": "src/transformers/models/mimi/modeling_mimi.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fmodels%2Fmimi%2Fmodeling_mimi.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aa495f62dec75a7c6593e978e5fed475d9d1efc0/src%2Ftransformers%2Fmodels%2Fmimi%2Fmodeling_mimi.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmimi%2Fmodeling_mimi.py?ref=aa495f62dec75a7c6593e978e5fed475d9d1efc0",
            "patch": "@@ -1380,7 +1380,7 @@ class MimiPreTrainedModel(PreTrainedModel):\n     main_input_name = \"input_values\"\n     input_modalities = \"audio\"\n     supports_gradient_checkpointing = True\n-    _no_split_modules = [\"MimiDecoderLayer\"]\n+    _no_split_modules = [\"MimiResidualVectorQuantizer\", \"MimiTransformerLayer\"]\n     _skip_keys_device_placement = \"past_key_values\"\n     _supports_flash_attn = True\n     _supports_sdpa = True"
        },
        {
            "sha": "04b73559c94c1fbf8913a0ceb018302398a7f5d9",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/aa495f62dec75a7c6593e978e5fed475d9d1efc0/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aa495f62dec75a7c6593e978e5fed475d9d1efc0/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=aa495f62dec75a7c6593e978e5fed475d9d1efc0",
            "patch": "@@ -2342,6 +2342,7 @@ def test_multi_gpu_data_parallel_forward(self):\n \n             # Wrap model in nn.DataParallel\n             model = nn.DataParallel(model)\n+            torch.cuda.synchronize()  # otherwise the transfer might not be complete\n             with torch.no_grad():\n                 _ = model(**self._prepare_for_class(inputs_dict, model_class))\n "
        }
    ],
    "stats": {
        "total": 20,
        "additions": 14,
        "deletions": 6
    }
}