{
    "author": "ydshieh",
    "message": "Fix flaky `test_assisted_decoding_matches_greedy_search` (#35951)\n\nfix\r\n\r\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "cf90404807658b140909b2a2be4865906e7abd09",
    "files": [
        {
            "sha": "3aaa16704ebfc324ff8c8a3e0153964f091a7965",
            "filename": "tests/generation/test_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cf90404807658b140909b2a2be4865906e7abd09/tests%2Fgeneration%2Ftest_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cf90404807658b140909b2a2be4865906e7abd09/tests%2Fgeneration%2Ftest_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fgeneration%2Ftest_utils.py?ref=cf90404807658b140909b2a2be4865906e7abd09",
            "patch": "@@ -1185,7 +1185,9 @@ def test_assisted_decoding_matches_greedy_search(self, assistant_type):\n                 \"return_dict_in_generate\": True,\n                 \"use_cache\": True,\n             }\n-            output_greedy = model.generate(**generation_kwargs, **inputs_dict)\n+            logits_processor_kwargs = self._get_logits_processor_kwargs(config=model.config)\n+\n+            output_greedy = model.generate(**generation_kwargs, **inputs_dict, **logits_processor_kwargs)\n \n             # test with the same assistant model or randomly init one\n             # in the first case all candidate tokens are accepted, in the second none is accepted\n@@ -1197,7 +1199,7 @@ def test_assisted_decoding_matches_greedy_search(self, assistant_type):\n             assistant_model.generation_config.num_assistant_tokens = 2  # see b)\n             assistant_model.generation_config.num_assistant_tokens_schedule = \"constant\"  # see b)\n             generation_kwargs.update({\"assistant_model\": assistant_model})\n-            output_assisted = model.generate(**generation_kwargs, **inputs_dict)\n+            output_assisted = model.generate(**generation_kwargs, **inputs_dict, **logits_processor_kwargs)\n \n             # The two outputs must match and their shape must be as expected\n             self._check_similar_generate_outputs(output_greedy, output_assisted)"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 4,
        "deletions": 2
    }
}