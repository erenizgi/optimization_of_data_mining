{
    "author": "simonreise",
    "message": "Add an alternative scenario to EoMT `post_process_semantic_segmentation` in case `path_offsets` is None (#42716)\n\n* Add an alternative scenario in case patch_offsets is None\n\n* Fixup\n\n* Fix an error\n\n* Simplified the function\n\n---------\n\nCo-authored-by: Yoni Gozlan <74535834+yonigozlan@users.noreply.github.com>",
    "sha": "5b4d72c5061a2be587598bb3b44c140abdad2914",
    "files": [
        {
            "sha": "814f672bce621be79896ae4e640773e0b23cc4b1",
            "filename": "src/transformers/models/eomt/image_processing_eomt.py",
            "status": "modified",
            "additions": 13,
            "deletions": 1,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/5b4d72c5061a2be587598bb3b44c140abdad2914/src%2Ftransformers%2Fmodels%2Feomt%2Fimage_processing_eomt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5b4d72c5061a2be587598bb3b44c140abdad2914/src%2Ftransformers%2Fmodels%2Feomt%2Fimage_processing_eomt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Feomt%2Fimage_processing_eomt.py?ref=5b4d72c5061a2be587598bb3b44c140abdad2914",
            "patch": "@@ -815,7 +815,19 @@ def post_process_semantic_segmentation(\n \n         segmentation_logits = torch.einsum(\"bqc, bqhw -> bchw\", masks_classes, masks_probs)\n \n-        output_logits = self.merge_image_patches(segmentation_logits, patch_offsets, target_sizes, size)\n+        if patch_offsets:\n+            output_logits = self.merge_image_patches(segmentation_logits, patch_offsets, target_sizes, size)\n+        else:\n+            output_logits = []\n+\n+            for idx in range(len(segmentation_logits)):\n+                resized_logits = torch.nn.functional.interpolate(\n+                    segmentation_logits[idx].unsqueeze(dim=0),\n+                    size=target_sizes[idx],\n+                    mode=\"bilinear\",\n+                    align_corners=False,\n+                )\n+                output_logits.append(resized_logits[0])\n \n         preds = [logit.argmax(dim=0) for logit in output_logits]\n         return preds"
        },
        {
            "sha": "b6bf7f3aa13ee25265b9958bba0424f7038c3312",
            "filename": "src/transformers/models/eomt/image_processing_eomt_fast.py",
            "status": "modified",
            "additions": 13,
            "deletions": 1,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/5b4d72c5061a2be587598bb3b44c140abdad2914/src%2Ftransformers%2Fmodels%2Feomt%2Fimage_processing_eomt_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5b4d72c5061a2be587598bb3b44c140abdad2914/src%2Ftransformers%2Fmodels%2Feomt%2Fimage_processing_eomt_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Feomt%2Fimage_processing_eomt_fast.py?ref=5b4d72c5061a2be587598bb3b44c140abdad2914",
            "patch": "@@ -385,7 +385,19 @@ def post_process_semantic_segmentation(\n \n         segmentation_logits = torch.einsum(\"bqc, bqhw -> bchw\", masks_classes, masks_probs)\n \n-        output_logits = self.merge_image_patches(segmentation_logits, patch_offsets, target_sizes, size)\n+        if patch_offsets:\n+            output_logits = self.merge_image_patches(segmentation_logits, patch_offsets, target_sizes, size)\n+        else:\n+            output_logits = []\n+\n+            for idx in range(len(segmentation_logits)):\n+                resized_logits = torch.nn.functional.interpolate(\n+                    segmentation_logits[idx].unsqueeze(dim=0),\n+                    size=target_sizes[idx],\n+                    mode=\"bilinear\",\n+                    align_corners=False,\n+                )\n+                output_logits.append(resized_logits[0])\n \n         preds = [logit.argmax(dim=0) for logit in output_logits]\n         return preds"
        }
    ],
    "stats": {
        "total": 28,
        "additions": 26,
        "deletions": 2
    }
}