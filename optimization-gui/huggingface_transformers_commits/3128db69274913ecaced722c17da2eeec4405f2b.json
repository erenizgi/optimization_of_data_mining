{
    "author": "MilkClouds",
    "message": "chore: fix typo in `find_executable_batch_size` to match new 0.9 ratio (#40206)",
    "sha": "3128db69274913ecaced722c17da2eeec4405f2b",
    "files": [
        {
            "sha": "8f09617dc8bfdfd5407b0b8c056d87301813187d",
            "filename": "src/transformers/trainer_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/3128db69274913ecaced722c17da2eeec4405f2b/src%2Ftransformers%2Ftrainer_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3128db69274913ecaced722c17da2eeec4405f2b/src%2Ftransformers%2Ftrainer_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer_utils.py?ref=3128db69274913ecaced722c17da2eeec4405f2b",
            "patch": "@@ -797,7 +797,7 @@ def find_executable_batch_size(\n     \"\"\"\n     Args:\n     A basic decorator that will try to execute `function`. If it fails from exceptions related to out-of-memory or\n-    CUDNN, the batch size is cut in half and passed to `function`. `function` must take in a `batch_size` parameter as\n+    CUDNN, the batch size is multiplied by 0.9 and passed to `function`. `function` must take in a `batch_size` parameter as\n     its first argument.\n         function (`callable`, *optional*)\n             A function to wrap"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}