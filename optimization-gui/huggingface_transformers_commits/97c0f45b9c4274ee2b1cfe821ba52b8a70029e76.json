{
    "author": "gante",
    "message": "Generate: fix assistant in different device (#33257)",
    "sha": "97c0f45b9c4274ee2b1cfe821ba52b8a70029e76",
    "files": [
        {
            "sha": "79105667dbe0c7d7e195615acf30584124ed1e89",
            "filename": "src/transformers/generation/utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/97c0f45b9c4274ee2b1cfe821ba52b8a70029e76/src%2Ftransformers%2Fgeneration%2Futils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/97c0f45b9c4274ee2b1cfe821ba52b8a70029e76/src%2Ftransformers%2Fgeneration%2Futils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Futils.py?ref=97c0f45b9c4274ee2b1cfe821ba52b8a70029e76",
            "patch": "@@ -3964,6 +3964,7 @@ def _assisted_decoding(\n \n             #  1. Fetch candidate sequences from a `CandidateGenerator`\n             candidate_input_ids, candidate_logits = candidate_generator.get_candidates(input_ids)\n+            candidate_input_ids = candidate_input_ids.to(self.device)\n             if candidate_logits is not None:\n                 candidate_logits = candidate_logits.to(self.device)\n "
        },
        {
            "sha": "3a33f7cd704e240dc102098fb23eed643a6a318c",
            "filename": "tests/generation/test_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/97c0f45b9c4274ee2b1cfe821ba52b8a70029e76/tests%2Fgeneration%2Ftest_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/97c0f45b9c4274ee2b1cfe821ba52b8a70029e76/tests%2Fgeneration%2Ftest_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fgeneration%2Ftest_utils.py?ref=97c0f45b9c4274ee2b1cfe821ba52b8a70029e76",
            "patch": "@@ -3323,7 +3323,7 @@ def test_assisted_decoding_in_different_gpu(self):\n \n     @slow\n     @require_torch_gpu\n-    def test_assisted_decoding_in_gpu_cpu(self):\n+    def test_assisted_decoding_model_in_gpu_assistant_in_cpu(self):\n         # PT-only test: TF doesn't support assisted decoding yet.\n         model = AutoModelForCausalLM.from_pretrained(\"hf-internal-testing/tiny-random-MistralForCausalLM\").to(\"cuda\")\n         assistant = AutoModelForCausalLM.from_pretrained(\"hf-internal-testing/tiny-random-MistralForCausalLM\").to("
        }
    ],
    "stats": {
        "total": 3,
        "additions": 2,
        "deletions": 1
    }
}