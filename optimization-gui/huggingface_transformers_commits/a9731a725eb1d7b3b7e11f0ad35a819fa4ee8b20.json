{
    "author": "Judy-Choi",
    "message": "ğŸŒ [i18n-KO] Translated `chat_extras.md` to Korean (#39863)\n\n* docs: ko: chat_extras.md\n\n* feat: nmt draft\n\n* fix: manual edits\n\n* Apply suggestions from code review\n\n* Apply suggestions from code review\n\n* Update docs/source/ko/chat_extras.md",
    "sha": "a9731a725eb1d7b3b7e11f0ad35a819fa4ee8b20",
    "files": [
        {
            "sha": "cb462a83ed292687a7e7fdd4c403fba43533d401",
            "filename": "docs/source/ko/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/a9731a725eb1d7b3b7e11f0ad35a819fa4ee8b20/docs%2Fsource%2Fko%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/a9731a725eb1d7b3b7e11f0ad35a819fa4ee8b20/docs%2Fsource%2Fko%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2F_toctree.yml?ref=a9731a725eb1d7b3b7e11f0ad35a819fa4ee8b20",
            "patch": "@@ -84,6 +84,8 @@\n       title: Transformersë¡œ ì±„íŒ…í•˜ê¸°\n     - local: chat_templating\n       title: ì±—ë´‡ í…œí”Œë¦¿ ìµíˆê¸°\n+    - local: chat_extras\n+      title: Tools ì™€ RAG\n     - local: in_translation\n       title: (ë²ˆì—­ì¤‘) Multimodal templates\n     - local: in_translation"
        },
        {
            "sha": "9c5b29b58a617659a77e1ad51ff87aefe79497e3",
            "filename": "docs/source/ko/chat_extras.md",
            "status": "added",
            "additions": 299,
            "deletions": 0,
            "changes": 299,
            "blob_url": "https://github.com/huggingface/transformers/blob/a9731a725eb1d7b3b7e11f0ad35a819fa4ee8b20/docs%2Fsource%2Fko%2Fchat_extras.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/a9731a725eb1d7b3b7e11f0ad35a819fa4ee8b20/docs%2Fsource%2Fko%2Fchat_extras.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fchat_extras.md?ref=a9731a725eb1d7b3b7e11f0ad35a819fa4ee8b20",
            "patch": "@@ -0,0 +1,299 @@\n+<!--Copyright 2024 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n+\n+âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+\n+# ë„êµ¬ì™€ RAG[[Tools-and-RAG]]\n+\n+[`~PreTrainedTokenizerBase.apply_chat_template`] ë©”ì†Œë“œëŠ” ì±„íŒ… ë©”ì‹œì§€ ì™¸ì—ë„ ë¬¸ìì—´, ë¦¬ìŠ¤íŠ¸, ë”•ì…”ë„ˆë¦¬ ë“± ê±°ì˜ ëª¨ë“  ì¢…ë¥˜ì˜ ì¶”ê°€ ì¸ìˆ˜ íƒ€ì…ì„ ì§€ì›í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì‚¬ìš© ìƒí™©ì—ì„œ ì±„íŒ… í…œí”Œë¦¿ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+ì´ ê°€ì´ë“œì—ì„œëŠ” ë„êµ¬ ë° ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG)ê³¼ í•¨ê»˜ ì±„íŒ… í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.\n+\n+## ë„êµ¬[[Tools]]\n+\n+ë„êµ¬ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì´ íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. ì´ëŠ” ì‹¤ì‹œê°„ ì •ë³´, ê³„ì‚° ë„êµ¬ ë˜ëŠ” ëŒ€ê·œëª¨ ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼ ë“±ì„ í†µí•´ ëŒ€í™”í˜• ì—ì´ì „íŠ¸ì˜ ê¸°ëŠ¥ì„ í™•ì¥í•˜ëŠ” ê°•ë ¥í•œ ë°©ë²•ì…ë‹ˆë‹¤.\n+\n+ë„êµ¬ë¥¼ ë§Œë“¤ ë•ŒëŠ” ì•„ë˜ ê·œì¹™ì„ ë”°ë¥´ì„¸ìš”.\n+\n+1. í•¨ìˆ˜ëŠ” ê¸°ëŠ¥ì„ ì˜ ì„¤ëª…í•˜ëŠ” ì´ë¦„ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.\n+2. í•¨ìˆ˜ì˜ ì¸ìˆ˜ëŠ” í•¨ìˆ˜ í—¤ë”ì— íƒ€ì… íŒíŠ¸ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤(`Args` ë¸”ë¡ì—ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”).\n+3. í•¨ìˆ˜ì—ëŠ” [Google ìŠ¤íƒ€ì¼](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings) ì˜ ë…ìŠ¤íŠ¸ë§(docstring)ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n+4. í•¨ìˆ˜ì— ë°˜í™˜ íƒ€ì…ê³¼ `Returns` ë¸”ë¡ì„ í¬í•¨í•  ìˆ˜ ìˆì§€ë§Œ, ë„êµ¬ë¥¼ í™œìš©í•˜ëŠ” ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì—ì„œ ì´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ë¬´ì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+ì£¼ì–´ì§„ ìœ„ì¹˜ì˜ í˜„ì¬ ì˜¨ë„ì™€ í’ì†ì„ ê°€ì ¸ì˜¤ëŠ” ë„êµ¬ì˜ ì˜ˆì‹œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n+\n+```py\n+def get_current_temperature(location: str, unit: str) -> float:\n+    \"\"\"\n+    ì£¼ì–´ì§„ ìœ„ì¹˜ì˜ í˜„ì¬ ì˜¨ë„ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n+    \n+    Args:\n+        location: ì˜¨ë„ë¥¼ ê°€ì ¸ì˜¬ ìœ„ì¹˜, \"ë„ì‹œ, êµ­ê°€\" í˜•ì‹\n+        unit: ì˜¨ë„ë¥¼ ë°˜í™˜í•  ë‹¨ìœ„. (ì„ íƒì§€: [\"celsius(ì„­ì”¨)\", \"fahrenheit(í™”ì”¨)\"])\n+    Returns:\n+        ì£¼ì–´ì§„ ìœ„ì¹˜ì˜ ì§€ì •ëœ ë‹¨ìœ„ë¡œ í‘œì‹œëœ í˜„ì¬ ì˜¨ë„(float ìë£Œí˜•).\n+    \"\"\"\n+    return 22.  # ì‹¤ì œ í•¨ìˆ˜ë¼ë©´ ì•„ë§ˆ ì§„ì§œë¡œ ê¸°ì˜¨ì„ ê°€ì ¸ì™€ì•¼ê² ì£ !\n+\n+def get_current_wind_speed(location: str) -> float:\n+    \"\"\"\n+    ì£¼ì–´ì§„ ìœ„ì¹˜ì˜ í˜„ì¬ í’ì†ì„ km/h ë‹¨ìœ„ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n+    \n+    Args:\n+        location: ì˜¨ë„ë¥¼ ê°€ì ¸ì˜¬ ìœ„ì¹˜, \"ë„ì‹œ, êµ­ê°€\" í˜•ì‹\n+    Returns:\n+        ì£¼ì–´ì§„ ìœ„ì¹˜ì˜ í˜„ì¬ í’ì†(km/h, float ìë£Œí˜•).\n+    \"\"\"\n+    return 6.  # ì‹¤ì œ í•¨ìˆ˜ë¼ë©´ ì•„ë§ˆ ì§„ì§œë¡œ í’ì†ì„ ê°€ì ¸ì™€ì•¼ê² ì£ !\n+\n+tools = [get_current_temperature, get_current_wind_speed]\n+```\n+\n+[NousResearch/Hermes-2-Pro-Llama-3-8B](https://hf.co/NousResearch/Hermes-2-Pro-Llama-3-8B)ì™€ ê°™ì´ ë„êµ¬ ì‚¬ìš©ì„ ì§€ì›í•˜ëŠ” ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”. í•˜ë“œì›¨ì–´ê°€ ì§€ì›ëœë‹¤ë©´ [Command-R](./model_doc/cohere)ì´ë‚˜ [Mixtral-8x22B](./model_doc/mixtral)ì™€ ê°™ì€ ë” í° ëª¨ë¸ë„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+```py\n+import torch\n+from transformers import AutoModelForCausalLM, AutoTokenizer\n+\n+tokenizer = AutoTokenizer.from_pretrained( \"NousResearch/Hermes-2-Pro-Llama-3-8B\")\n+tokenizer = AutoTokenizer.from_pretrained( \"NousResearch/Hermes-2-Pro-Llama-3-8B\")\n+model = AutoModelForCausalLM.from_pretrained( \"NousResearch/Hermes-2-Pro-Llama-3-8B\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n+```\n+\n+ì±„íŒ… ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n+\n+```py\n+messages = [\n+  {\"role\": \"system\", \"content\": \"You are a bot that responds to weather queries. You should reply with the unit used in the queried location.\"},\n+  {\"role\": \"user\", \"content\": \"Hey, what's the temperature in Paris right now?\"}\n+]\n+```\n+\n+`messages`ì™€ ë„êµ¬ ëª©ë¡ `tools`ë¥¼ [`~PreTrainedTokenizerBase.apply_chat_template`]ì— ì „ë‹¬í•œ ë’¤, ì´ë¥¼ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+```py\n+inputs = tokenizer.apply_chat_template(messages, tools=tools, add_generation_prompt=True, return_dict=True, return_tensors=\"pt\")\n+inputs = {k: v for k, v in inputs.items()}\n+outputs = model.generate(**inputs, max_new_tokens=128)\n+print(tokenizer.decode(outputs[0][len(inputs[\"input_ids\"][0]):]))\n+```\n+\n+```txt\n+<tool_call>\n+{\"arguments\": {\"location\": \"Paris, France\", \"unit\": \"celsius\"}, \"name\": \"get_current_temperature\"}\n+</tool_call><|im_end|>\n+```\n+\n+ì±„íŒ… ëª¨ë¸ì€ ë…ìŠ¤íŠ¸ë§(docstring)ì— ì •ì˜ëœ í˜•ì‹ì— ë”°ë¼ `get_current_temperature` í•¨ìˆ˜ì— ì˜¬ë°”ë¥¸ ë§¤ê°œë³€ìˆ˜ë¥¼ ì „ë‹¬í•´ í˜¸ì¶œí–ˆìŠµë‹ˆë‹¤. íŒŒë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìœ„ì¹˜ë¥¼ í”„ë‘ìŠ¤ë¡œ ì¶”ë¡ í–ˆìœ¼ë©°, ì˜¨ë„ ë‹¨ìœ„ëŠ” ì„­ì”¨ë¥¼ ì‚¬ìš©í•´ì•¼ í•œë‹¤ê³  íŒë‹¨í–ˆìŠµë‹ˆë‹¤.\n+\n+ì´ì œ `get_current_temperature` í•¨ìˆ˜ì™€ í•´ë‹¹ ì¸ìˆ˜ë“¤ì„ `tool_call` ë”•ì…”ë„ˆë¦¬ì— ë‹´ì•„ ì±„íŒ… ë©”ì‹œì§€ì— ì¶”ê°€í•©ë‹ˆë‹¤. `tool_call` ë”•ì…”ë„ˆë¦¬ëŠ” `system`ì´ë‚˜ `user`ê°€ ì•„ë‹Œ `assistant` ì—­í• ë¡œ ì œê³µë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n+\n+> [!WARNING]\n+> OpenAI APIëŠ” `tool_call` í˜•ì‹ìœ¼ë¡œ JSON ë¬¸ìì—´ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. Transformersì—ì„œ ì‚¬ìš©í•  ê²½ìš° ë”•ì…”ë„ˆë¦¬ë¥¼ ìš”êµ¬í•˜ê¸° ë•Œë¬¸ì—, ì˜¤ë¥˜ê°€ ë°œìƒí•˜ê±°ë‚˜ ëª¨ë¸ì´ ì´ìƒí•˜ê²Œ ë™ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+<hfoptions id=\"tool-call\">\n+<hfoption id=\"Llama\">\n+\n+```py\n+tool_call = {\"name\": \"get_current_temperature\", \"arguments\": {\"location\": \"Paris, France\", \"unit\": \"celsius\"}}\n+messages.append({\"role\": \"assistant\", \"tool_calls\": [{\"type\": \"function\", \"function\": tool_call}]})\n+```\n+\n+ì–´ì‹œìŠ¤í„´íŠ¸ê°€ í•¨ìˆ˜ ì¶œë ¥ì„ ì½ê³  ì‚¬ìš©ìì™€ ì±„íŒ…í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n+\n+```py\n+inputs = tokenizer.apply_chat_template(messages, tools=tools, add_generation_prompt=True, return_dict=True, return_tensors=\"pt\")\n+inputs = {k: v for k, v in inputs.items()}\n+out = model.generate(**inputs, max_new_tokens=128)\n+print(tokenizer.decode(out[0][len(inputs[\"input_ids\"][0]):]))\n+```\n+\n+```txt\n+The temperature in Paris, France right now is approximately 12Â°C (53.6Â°F).<|im_end|>\n+```\n+\n+</hfoption>\n+<hfoption id=\"Mistral/Mixtral\">\n+\n+[Mistral](./model_doc/mistral) ë° [Mixtral](./model_doc/mixtral) ëª¨ë¸ì˜ ê²½ìš° ì¶”ê°€ì ìœ¼ë¡œ `tool_call_id`ê°€ í•„ìš”í•©ë‹ˆë‹¤. `tool_call_id`ëŠ” 9ìë¦¬ ì˜ìˆ«ì ë¬¸ìì—´ë¡œ ìƒì„±ë˜ì–´ `tool_call` ë”•ì…”ë„ˆë¦¬ì˜ `id` í‚¤ì— í• ë‹¹ë©ë‹ˆë‹¤.\n+\n+```py\n+tool_call_id = \"9Ae3bDc2F\"\n+tool_call = {\"name\": \"get_current_temperature\", \"arguments\": {\"location\": \"Paris, France\", \"unit\": \"celsius\"}}\n+messages.append({\"role\": \"assistant\", \"tool_calls\": [{\"type\": \"function\", \"id\": tool_call_id, \"function\": tool_call}]})\n+```\n+\n+```py\n+inputs = tokenizer.apply_chat_template(messages, tools=tools, add_generation_prompt=True, return_dict=True, return_tensors=\"pt\")\n+inputs = {k: v for k, v in inputs.items()}\n+out = model.generate(**inputs, max_new_tokens=128)\n+print(tokenizer.decode(out[0][len(inputs[\"input_ids\"][0]):]))\n+```\n+\n+</hfoption>\n+</hfoptions>\n+\n+## ìŠ¤í‚¤ë§ˆ[[Schema]]\n+\n+[`~PreTrainedTokenizerBase.apply_chat_template`]ì€ í•¨ìˆ˜ë¥¼ [JSON ìŠ¤í‚¤ë§ˆ](https://json-schema.org/learn/getting-started-step-by-step)ë¡œ ë³€í™˜í•˜ì—¬ ì±„íŒ… í…œí”Œë¦¿ì— ì „ë‹¬í•©ë‹ˆë‹¤. LLMì€ í•¨ìˆ˜ ë‚´ë¶€ì˜ ì½”ë“œë¥¼ ë³´ì§€ ëª»í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´, LLMì€ í•¨ìˆ˜ê°€ ê¸°ìˆ ì ìœ¼ë¡œ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ëŠ” ì‹ ê²½ ì“°ì§€ ì•Šê³ , í•¨ìˆ˜ì˜ **ì •ì˜**ì™€ **ì¸ìˆ˜**ë§Œ ì°¸ì¡°í•©ë‹ˆë‹¤.\n+\n+í•¨ìˆ˜ê°€ ì•ì„œ ë‚˜ì—´ëœ ê·œì¹™ì„ ë”°ë¥´ë©´, ë‚´ë¶€ì—ì„œ JSON ìŠ¤í‚¤ë§ˆê°€ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤. í•˜ì§€ë§Œ ë” ë‚˜ì€ ê°€ë…ì„±ì´ë‚˜ ë””ë²„ê¹…ì„ ìœ„í•´ [get_json_schema](https://github.com/huggingface/transformers/blob/14561209291255e51c55260306c7d00c159381a5/src/transformers/utils/chat_template_utils.py#L205)ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤í‚¤ë§ˆë¥¼ ìˆ˜ë™ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+```py\n+from transformers.utils import get_json_schema\n+\n+def multiply(a: float, b: float):\n+    \"\"\"\n+    ë‘ ìˆ«ìë¥¼ ê³±í•˜ëŠ” í•¨ìˆ˜\n+    \n+    Args:\n+        a: ê³±í•  ì²« ë²ˆì§¸ ìˆ«ì\n+        b: ê³±í•  ë‘ ë²ˆì§¸ ìˆ«ì\n+    \"\"\"\n+    return a * b\n+\n+schema = get_json_schema(multiply)\n+print(schema)\n+```\n+\n+```json\n+{\n+  \"type\": \"function\", \n+  \"function\": {\n+    \"name\": \"multiply\", \n+    \"description\": \"A function that multiplies two numbers\", \n+    \"parameters\": {\n+      \"type\": \"object\", \n+      \"properties\": {\n+        \"a\": {\n+          \"type\": \"number\", \n+          \"description\": \"The first number to multiply\"\n+        }, \n+        \"b\": {\n+          \"type\": \"number\",\n+          \"description\": \"The second number to multiply\"\n+        }\n+      }, \n+      \"required\": [\"a\", \"b\"]\n+    }\n+  }\n+}\n+```\n+\n+ìŠ¤í‚¤ë§ˆë¥¼ í¸ì§‘í•˜ê±°ë‚˜ ì²˜ìŒë¶€í„° ì§ì ‘ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë” ë³µì¡í•œ í•¨ìˆ˜ì— ëŒ€í•œ ì •í™•í•œ ìŠ¤í‚¤ë§ˆë¥¼ ìœ ì—°í•˜ê²Œ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+> [!WARNING]\n+> í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ë¥¼ ë‹¨ìˆœí•˜ê²Œ ìœ ì§€í•˜ê³  ì¸ìˆ˜ë¥¼ ìµœì†Œí•œìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”. ì´ëŸ¬í•œ í•¨ìˆ˜ëŠ” ì¤‘ì²©ëœ ì¸ìˆ˜ë¥¼ ê°€ì§„ ë³µì¡í•œ í•¨ìˆ˜ì— ë¹„í•´ ëª¨ë¸ì´ ë” ì‰½ê²Œ ì´í•´í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+ì•„ë˜ ì˜ˆì‹œëŠ” ìŠ¤í‚¤ë§ˆë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì‘ì„±í•œ ë‹¤ìŒ [`~PreTrainedTokenizerBase.apply_chat_template`]ì— ì „ë‹¬í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n+\n+```py\n+# ì¸ìˆ˜ë¥¼ ë°›ì§€ ì•ŠëŠ” ê°„ë‹¨í•œ í•¨ìˆ˜\n+current_time = {\n+  \"type\": \"function\", \n+  \"function\": {\n+    \"name\": \"current_time\",\n+    \"description\": \"Get the current local time as a string.\",\n+    \"parameters\": {\n+      'type': 'object',\n+      'properties': {}\n+    }\n+  }\n+}\n+\n+# ë‘ ê°œì˜ ìˆ«ì ì¸ìˆ˜ë¥¼ ë°›ëŠ” ë” ì™„ì „í•œ í•¨ìˆ˜\n+multiply = {\n+  'type': 'function',\n+  'function': {\n+    'name': 'multiply',\n+    'description': 'A function that multiplies two numbers', \n+    'parameters': {\n+      'type': 'object', \n+      'properties': {\n+        'a': {\n+          'type': 'number',\n+          'description': 'The first number to multiply'\n+        }, \n+        'b': {\n+          'type': 'number', 'description': 'The second number to multiply'\n+        }\n+      }, \n+      'required': ['a', 'b']\n+    }\n+  }\n+}\n+\n+model_input = tokenizer.apply_chat_template(\n+    messages,\n+    tools = [current_time, multiply]\n+)\n+```\n+\n+## RAG[[RAG]]\n+\n+ê²€ìƒ‰ ì¦ê°• ìƒì„±(Retrieval-augmented generation, RAG) ëª¨ë¸ì€ ì¿¼ë¦¬ë¥¼ ë°˜í™˜í•˜ê¸° ì „ì— ë¬¸ì„œë¥¼ ê²€ìƒ‰í•´ ì¶”ê°€ ì •ë³´ë¥¼ ì–»ì–´ ëª¨ë¸ì´ ê¸°ì¡´ì— ê°€ì§€ê³  ìˆë˜ ì§€ì‹ì„ í™•ì¥ì‹œí‚µë‹ˆë‹¤. RAG ëª¨ë¸ì˜ ê²½ìš°, [`~PreTrainedTokenizerBase.apply_chat_template`]ì— `documents` ë§¤ê°œë³€ìˆ˜ë¥¼ ì¶”ê°€í•˜ì„¸ìš”. ì´ `documents` ë§¤ê°œë³€ìˆ˜ëŠ” ë¬¸ì„œ ëª©ë¡ì´ì–´ì•¼ í•˜ë©°, ê° ë¬¸ì„œëŠ” `title`ê³¼ `content` í‚¤ë¥¼ ê°€ì§„ ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤.\n+\n+> [!TIP]\n+> RAGë¥¼ ìœ„í•œ `documents` ë§¤ê°œë³€ìˆ˜ëŠ” í­ë„“ê²Œ ì§€ì›ë˜ì§€ ì•Šìœ¼ë©° ë§ì€ ëª¨ë¸ë“¤ì´ `documents`ë¥¼ ë¬´ì‹œí•˜ëŠ” ì±„íŒ… í…œí”Œë¦¿ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ì´ `documents`ë¥¼ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ëª¨ë¸ ì¹´ë“œë¥¼ ì½ê±°ë‚˜ `print(tokenizer.chat_template)`ë¥¼ ì‹¤í–‰í•˜ì—¬ `documents` í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. [Command-R](https://hf.co/CohereForAI/c4ai-command-r-08-2024)ê³¼ [Command-R+](https://hf.co/CohereForAI/c4ai-command-r-plus-08-2024)ëŠ” ëª¨ë‘ RAG ì±„íŒ… í…œí”Œë¦¿ì—ì„œ `documents`ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n+\n+ëª¨ë¸ì— ì „ë‹¬í•  ë¬¸ì„œ ëª©ë¡ì„ ìƒì„±í•˜ì„¸ìš”.\n+\n+```py\n+documents = [\n+    {\n+        \"title\": \"The Moon: Our Age-Old Foe\", \n+        \"text\": \"Man has always dreamed of destroying the moon. In this essay, I shall...\"\n+    },\n+    {\n+        \"title\": \"The Sun: Our Age-Old Friend\",\n+        \"text\": \"Although often underappreciated, the sun provides several notable benefits...\"\n+    }\n+]\n+```\n+\n+[`~PreTrainedTokenizerBase.apply_chat_template`]ì—ì„œ `chat_template=\"rag\"`ë¥¼ ì„¤ì •í•˜ê³  ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.\n+\n+```py\n+from transformers import AutoTokenizer, AutoModelForCausalLM\n+\n+# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n+tokenizer = AutoTokenizer.from_pretrained(\"CohereForAI/c4ai-command-r-v01-4bit\")\n+model = AutoModelForCausalLM.from_pretrained(\"CohereForAI/c4ai-command-r-v01-4bit\", device_map=\"auto\")\n+device = model.device # ëª¨ë¸ì„ ê°€ì ¸ì˜¨ ì¥ì¹˜ í™•ì¸\n+\n+# ëŒ€í™” ì…ë ¥ ì •ì˜\n+conversation = [\n+    {\"role\": \"user\", \"content\": \"What has Man always dreamed of?\"}\n+]\n+\n+input_ids = tokenizer.apply_chat_template(\n+    conversation=conversation,\n+    documents=documents,\n+    chat_template=\"rag\",\n+    tokenize=True,\n+    add_generation_prompt=True,\n+    return_tensors=\"pt\").to(device)\n+\n+# ì‘ë‹µ ìƒì„±\n+generated_tokens = model.generate(\n+    input_ids,\n+    max_new_tokens=100,\n+    do_sample=True,\n+    temperature=0.3,\n+    )\n+\n+# ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ ë””ì½”ë”©í•˜ê³  ìƒì„± í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜ ì¶œë ¥\n+generated_text = tokenizer.decode(generated_tokens[0])\n+print(generated_text)\n+```"
        }
    ],
    "stats": {
        "total": 301,
        "additions": 301,
        "deletions": 0
    }
}