{
    "author": "Nik-Kras",
    "message": "Fix missing `sequences_scores` in the Whisper beam search output  (#32970)\n\n* added sequences_scores to the output\r\n\r\n* added beam_indices to output\r\n\r\n* added test to check for beam_indices, sequences_scores and their shape\r\n\r\n* removed redundant whitespaces\r\n\r\n* make fixup",
    "sha": "c29a8694b0bd35b773bf3fa87e0370bf840d2fe5",
    "files": [
        {
            "sha": "8012c3c1bbfcfb2d78c7a33344b4ed13fee0ef65",
            "filename": "src/transformers/models/whisper/generation_whisper.py",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/c29a8694b0bd35b773bf3fa87e0370bf840d2fe5/src%2Ftransformers%2Fmodels%2Fwhisper%2Fgeneration_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c29a8694b0bd35b773bf3fa87e0370bf840d2fe5/src%2Ftransformers%2Fmodels%2Fwhisper%2Fgeneration_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Fgeneration_whisper.py?ref=c29a8694b0bd35b773bf3fa87e0370bf840d2fe5",
            "patch": "@@ -1000,21 +1000,23 @@ def _stack_split_outputs(self, seek_outputs, model_output_type, device, kwargs):\n         # Stack back seek_outputs tensors after splitting them with the split_by_batch_index method\n         outputs = {}\n         for key in seek_outputs[0].keys():\n-            if key == \"sequences\":\n+            if key in [\"sequences\", \"beam_indices\"]:\n                 outputs[key] = torch.stack([v[key] for v in seek_outputs], dim=0).to(device)\n-            if key in [\"scores\", \"encoder_attentions\", \"encoder_hidden_states\", \"logits\"]:\n+            elif key in [\"scores\", \"encoder_attentions\", \"encoder_hidden_states\", \"logits\"]:\n                 outputs[key] = tuple(\n                     torch.stack([v[key][i] for v in seek_outputs]).to(device) for i in range(len(seek_outputs[0][key]))\n                 )\n-            if key in [\"decoder_attentions\", \"decoder_hidden_states\", \"cross_attentions\"]:\n+            elif key == \"sequences_scores\":\n+                outputs[key] = torch.stack([v[key] for v in seek_outputs], dim=0).to(device)\n+            elif key in [\"decoder_attentions\", \"decoder_hidden_states\", \"cross_attentions\"]:\n                 outputs[key] = tuple(\n                     tuple(\n                         torch.stack([v[key][i][j] for v in seek_outputs]).squeeze(1).to(device)\n                         for j in range(len(seek_outputs[0][key][0]))\n                     )\n                     for i in range(len(seek_outputs[0][key]))\n                 )\n-            if key == \"past_key_values\":\n+            elif key == \"past_key_values\":\n                 past_key_value_type = kwargs.get(\"past_key_values\")\n                 if seek_outputs[0][key] is not None:\n                     outputs[key] = tuple("
        },
        {
            "sha": "f7ac2bc12eb252df5988f49596cdaccebc50462c",
            "filename": "tests/models/whisper/test_modeling_whisper.py",
            "status": "modified",
            "additions": 19,
            "deletions": 0,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/c29a8694b0bd35b773bf3fa87e0370bf840d2fe5/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c29a8694b0bd35b773bf3fa87e0370bf840d2fe5/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py?ref=c29a8694b0bd35b773bf3fa87e0370bf840d2fe5",
            "patch": "@@ -529,6 +529,25 @@ def test_inputs_embeds(self):\n             with torch.no_grad():\n                 model(**inputs)[0]\n \n+    def test_beam_search_output(self):\n+        config, input_dict = self.model_tester.prepare_config_and_inputs()\n+        model = WhisperForConditionalGeneration(config).to(torch_device).eval()\n+\n+        input_features = input_dict[\"input_features\"]\n+\n+        # Perform beam search\n+        output = model.generate(\n+            input_features, num_beams=3, num_return_sequences=3, return_dict_in_generate=True, output_scores=True\n+        )\n+\n+        # Check if beam_indices and sequences_scores are in the output\n+        self.assertIn(\"beam_indices\", output, \"beam_indices not found in the output\")\n+        self.assertIn(\"sequences_scores\", output, \"sequences_scores not found in the output\")\n+\n+        # Validate the shapes of the beam_indices and sequences_scores\n+        self.assertEqual(output.beam_indices.shape[0], input_features.shape[0] * 3)\n+        self.assertEqual(output.sequences_scores.shape[0], input_features.shape[0] * 3)\n+\n     # training is not supported yet\n     @unittest.skip(reason=\"Training is not supported yet\")\n     def test_training(self):"
        }
    ],
    "stats": {
        "total": 29,
        "additions": 25,
        "deletions": 4
    }
}