{
    "author": "ydshieh",
    "message": "update `require_read_token` (#38093)\n\n* update require_read_token\n\n* new repo\n\n* fix\n\n* fix\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "3ad35d0bcaf5520f2b25441a50f205300a07f3d0",
    "files": [
        {
            "sha": "5ab348377da0fd63332d3ea6419e6e2fd6b0ebc2",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 28,
            "deletions": 9,
            "changes": 37,
            "blob_url": "https://github.com/huggingface/transformers/blob/3ad35d0bcaf5520f2b25441a50f205300a07f3d0/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3ad35d0bcaf5520f2b25441a50f205300a07f3d0/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=3ad35d0bcaf5520f2b25441a50f205300a07f3d0",
            "patch": "@@ -31,6 +31,7 @@\n import tempfile\n import threading\n import time\n+import types\n import unittest\n from collections import UserDict, defaultdict\n from collections.abc import Generator, Iterable, Iterator, Mapping\n@@ -560,21 +561,39 @@ def require_torch_sdpa(test_case):\n     return unittest.skipUnless(is_torch_sdpa_available(), \"test requires PyTorch SDPA\")(test_case)\n \n \n-def require_read_token(fn):\n+def require_read_token(test_case):\n     \"\"\"\n     A decorator that loads the HF token for tests that require to load gated models.\n     \"\"\"\n     token = os.getenv(\"HF_HUB_READ_TOKEN\")\n \n-    @wraps(fn)\n-    def _inner(*args, **kwargs):\n-        if token is not None:\n-            with patch(\"huggingface_hub.utils._headers.get_token\", return_value=token):\n-                return fn(*args, **kwargs)\n-        else:  # Allow running locally with the default token env variable\n-            return fn(*args, **kwargs)\n+    if isinstance(test_case, type):\n+        for attr_name in dir(test_case):\n+            attr = getattr(test_case, attr_name)\n+            if isinstance(attr, types.FunctionType):\n+                if getattr(attr, \"__require_read_token__\", False):\n+                    continue\n+                wrapped = require_read_token(attr)\n+                setattr(test_case, attr_name, wrapped)\n+        return test_case\n+    else:\n+        if getattr(test_case, \"__require_read_token__\", False):\n+            return test_case\n \n-    return _inner\n+        @functools.wraps(test_case)\n+        def wrapper(*args, **kwargs):\n+            if token is not None:\n+                with patch(\"huggingface_hub.utils._headers.get_token\", return_value=token):\n+                    return test_case(*args, **kwargs)\n+            else:  # Allow running locally with the default token env variable\n+                # dealing with static/class methods and called by `self.xxx`\n+                if \"staticmethod\" in inspect.getsource(test_case).strip():\n+                    if len(args) > 0 and isinstance(args[0], unittest.TestCase):\n+                        return test_case(*args[1:], **kwargs)\n+                return test_case(*args, **kwargs)\n+\n+        wrapper.__require_read_token__ = True\n+        return wrapper\n \n \n def require_peft(test_case):"
        },
        {
            "sha": "e0983d489e2b1b3a2efe9e90adb6101281de19d0",
            "filename": "tests/models/aya_vision/test_processor_aya_vision.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/3ad35d0bcaf5520f2b25441a50f205300a07f3d0/tests%2Fmodels%2Faya_vision%2Ftest_processor_aya_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3ad35d0bcaf5520f2b25441a50f205300a07f3d0/tests%2Fmodels%2Faya_vision%2Ftest_processor_aya_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faya_vision%2Ftest_processor_aya_vision.py?ref=3ad35d0bcaf5520f2b25441a50f205300a07f3d0",
            "patch": "@@ -51,10 +51,12 @@ def setUpClass(cls):\n             image_std=[0.229, 0.224, 0.225],\n             do_convert_rgb=True,\n         )\n-        tokenizer = AutoTokenizer.from_pretrained(\"CohereForAI/aya-vision-8b\", padding_side=\"left\")\n+        tokenizer = AutoTokenizer.from_pretrained(\n+            \"hf-internal-testing/namespace-CohereForAI-repo_name_aya-vision-8b\", padding_side=\"left\"\n+        )\n         processor_kwargs = cls.prepare_processor_dict()\n         processor = AyaVisionProcessor.from_pretrained(\n-            \"CohereForAI/aya-vision-8b\",\n+            \"hf-internal-testing/namespace-CohereForAI-repo_name_aya-vision-8b\",\n             image_processor=image_processor,\n             tokenizer=tokenizer,\n             **processor_kwargs,"
        }
    ],
    "stats": {
        "total": 43,
        "additions": 32,
        "deletions": 11
    }
}