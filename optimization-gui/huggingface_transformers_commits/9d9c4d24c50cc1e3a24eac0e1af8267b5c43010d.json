{
    "author": "ydshieh",
    "message": "Make `EfficientLoFTRModelTest` faster (#41000)\n\n* fix\n\n* fix\n\n* fix\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "9d9c4d24c50cc1e3a24eac0e1af8267b5c43010d",
    "files": [
        {
            "sha": "4ea8a4d823c5ea109460986de9b9694ca71896eb",
            "filename": "tests/models/efficientloftr/test_modeling_efficientloftr.py",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/9d9c4d24c50cc1e3a24eac0e1af8267b5c43010d/tests%2Fmodels%2Fefficientloftr%2Ftest_modeling_efficientloftr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9d9c4d24c50cc1e3a24eac0e1af8267b5c43010d/tests%2Fmodels%2Fefficientloftr%2Ftest_modeling_efficientloftr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fefficientloftr%2Ftest_modeling_efficientloftr.py?ref=9d9c4d24c50cc1e3a24eac0e1af8267b5c43010d",
            "patch": "@@ -46,18 +46,18 @@ def __init__(\n         self,\n         parent,\n         batch_size=2,\n-        image_width=80,\n-        image_height=60,\n-        stage_num_blocks: list[int] = [1, 1, 1],\n-        out_features: list[int] = [32, 32, 128],\n-        stage_stride: list[int] = [2, 1, 2],\n+        image_width=6,  # need to be a multiple of `stage_stride[0] * stage_stride[1]`\n+        image_height=4,  # need to be a multiple of `stage_stride[0] * stage_stride[1]`\n+        stage_num_blocks: list[int] = [1, 1],\n+        out_features: list[int] = [16, 16],  # need to be >= 2 to make `config.fine_fusion_dims > 0`\n+        stage_stride: list[int] = [2, 1],\n         q_aggregation_kernel_size: int = 1,\n         kv_aggregation_kernel_size: int = 1,\n         q_aggregation_stride: int = 1,\n         kv_aggregation_stride: int = 1,\n         num_attention_layers: int = 2,\n         num_attention_heads: int = 8,\n-        hidden_size: int = 128,\n+        hidden_size: int = 16,\n         coarse_matching_threshold: float = 0.0,\n         fine_kernel_size: int = 2,\n         coarse_matching_border_removal: int = 0,"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 6,
        "deletions": 6
    }
}