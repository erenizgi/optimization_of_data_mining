{
    "author": "kashif",
    "message": "[TimesFM] use the main revison instead of revision for integration test (#37558)\n\n* use the main revison instead of revision\n\n* test prediction\n\n* check larger time steps",
    "sha": "dc06e7cecd5dc98681566e5201481b42583c4382",
    "files": [
        {
            "sha": "25ed42fc2064bbfaf4b652f807296d8f8d1801e9",
            "filename": "src/transformers/models/timesfm/convert_timesfm_orignal_to_hf.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/dc06e7cecd5dc98681566e5201481b42583c4382/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fconvert_timesfm_orignal_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dc06e7cecd5dc98681566e5201481b42583c4382/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fconvert_timesfm_orignal_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fconvert_timesfm_orignal_to_hf.py?ref=dc06e7cecd5dc98681566e5201481b42583c4382",
            "patch": "@@ -48,6 +48,7 @@ def write_model(model_path, safe_serialization=True, huggingface_repo_id=\"google\n             num_layers=50,\n             model_dims=1280,\n             use_positional_embedding=False,\n+            context_len=2048,\n         ),\n         checkpoint=timesfm.TimesFmCheckpoint(huggingface_repo_id=huggingface_repo_id),\n     )\n@@ -159,6 +160,7 @@ def check_outputs(model_path, huggingface_repo_id):\n             input_patch_len=32,\n             output_patch_len=128,\n             num_layers=50,\n+            context_len=2048,\n             model_dims=1280,\n             use_positional_embedding=False,\n             point_forecast_mode=\"mean\","
        },
        {
            "sha": "47615ab843c58eb054c4841eedb5f1b14f5973f2",
            "filename": "tests/models/timesfm/test_modeling_timesfm.py",
            "status": "modified",
            "additions": 18,
            "deletions": 13,
            "changes": 31,
            "blob_url": "https://github.com/huggingface/transformers/blob/dc06e7cecd5dc98681566e5201481b42583c4382/tests%2Fmodels%2Ftimesfm%2Ftest_modeling_timesfm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dc06e7cecd5dc98681566e5201481b42583c4382/tests%2Fmodels%2Ftimesfm%2Ftest_modeling_timesfm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ftimesfm%2Ftest_modeling_timesfm.py?ref=dc06e7cecd5dc98681566e5201481b42583c4382",
            "patch": "@@ -171,10 +171,8 @@ def test_model_main_input_name(self):\n @require_torch\n @slow\n class TimesFmModelIntegrationTests(unittest.TestCase):\n-    def test_inference_no_head(self):\n-        model = TimesFmModelForPrediction.from_pretrained(\"google/timesfm-2.0-500m-pytorch\", revision=\"refs/pr/7\").to(\n-            torch_device\n-        )\n+    def test_inference(self):\n+        model = TimesFmModelForPrediction.from_pretrained(\"google/timesfm-2.0-500m-pytorch\").to(torch_device)\n         forecast_input = [\n             np.sin(np.linspace(0, 20, 100)),\n             np.sin(np.linspace(0, 20, 200)),\n@@ -184,14 +182,21 @@ def test_inference_no_head(self):\n         frequency_input = [0, 1, 2]\n \n         with torch.no_grad():\n-            output = model(past_values=forecast_input_tensor, freq=frequency_input).last_hidden_state\n+            output = model(past_values=forecast_input_tensor, freq=frequency_input)\n \n-        self.assertEqual(\n-            output.shape,\n-            torch.Size([3, model.config.context_length // model.config.patch_length, model.config.hidden_size]),\n-        )\n+        mean_predictions = output.mean_predictions\n+        self.assertEqual(mean_predictions.shape, torch.Size([3, model.config.horizon_length]))\n+        # fmt: off\n         expected_slice = torch.tensor(\n-            [[-0.4267, -0.7273, -0.3932], [-0.4267, -0.7273, -0.3932], [-0.4267, -0.7273, -0.3932]],\n-            device=torch_device,\n-        )\n-        self.assertTrue(torch.allclose(output[0, :3, :3], expected_slice, atol=TOLERANCE))\n+            [ 0.9813,  1.0086,  0.9985,  0.9432,  0.8505,  0.7203,  0.5596,  0.3788,\n+              0.1796, -0.0264, -0.2307, -0.4255, -0.5978, -0.7642, -0.8772, -0.9670,\n+             -1.0110, -1.0162, -0.9848, -0.9151, -0.8016, -0.6511, -0.4707, -0.2842,\n+             -0.0787,  0.1260,  0.3293,  0.5104,  0.6818,  0.8155,  0.9172,  0.9843,\n+              1.0101,  1.0025,  0.9529,  0.8588,  0.7384,  0.5885,  0.4022,  0.2099,\n+             -0.0035, -0.2104, -0.4146, -0.6033, -0.7661, -0.8818, -0.9725, -1.0191,\n+             -1.0190, -0.9874, -0.9137, -0.8069, -0.6683, -0.4939, -0.3086, -0.1106,\n+              0.0846,  0.2927,  0.4832,  0.6612,  0.8031,  0.9051,  0.9772,  1.0064\n+            ],\n+            device=torch_device)\n+        # fmt: on\n+        self.assertTrue(torch.allclose(mean_predictions[0, :64], expected_slice, atol=TOLERANCE))"
        }
    ],
    "stats": {
        "total": 33,
        "additions": 20,
        "deletions": 13
    }
}