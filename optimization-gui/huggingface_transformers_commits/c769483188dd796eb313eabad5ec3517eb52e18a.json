{
    "author": "gante",
    "message": "[chat] improvements for thinking models and reduce default verbosity (#38322)\n\nmisc improvements",
    "sha": "c769483188dd796eb313eabad5ec3517eb52e18a",
    "files": [
        {
            "sha": "0c6b4702a433e450752f11d1c1770b1b1b483d00",
            "filename": "src/transformers/commands/chat.py",
            "status": "modified",
            "additions": 22,
            "deletions": 5,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/c769483188dd796eb313eabad5ec3517eb52e18a/src%2Ftransformers%2Fcommands%2Fchat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c769483188dd796eb313eabad5ec3517eb52e18a/src%2Ftransformers%2Fcommands%2Fchat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fchat.py?ref=c769483188dd796eb313eabad5ec3517eb52e18a",
            "patch": "@@ -16,6 +16,7 @@\n import json\n import os\n import platform\n+import re\n import string\n import time\n import warnings\n@@ -25,8 +26,9 @@\n from typing import Optional\n \n import yaml\n+from huggingface_hub.utils import disable_progress_bars\n \n-from transformers import AutoTokenizer, GenerationConfig, TextIteratorStreamer\n+from transformers import AutoTokenizer, GenerationConfig, TextIteratorStreamer, logging\n from transformers.utils import is_rich_available, is_torch_available\n \n from . import BaseTransformersCLICommand\n@@ -63,6 +65,7 @@\n     \"numbers\": {\"text\": \"Count to 10 but skip every number ending with an 'e'\"},\n     \"birds\": {\"text\": \"Why aren't birds real?\"},\n     \"socks\": {\"text\": \"Why is it important to eat socks after meditating?\"},\n+    \"numbers2\": {\"text\": \"Which number is larger, 9.9 or 9.11?\"},\n }\n \n # Printed at the start of a chat session\n@@ -71,7 +74,7 @@\n **TRANSFORMERS CHAT INTERFACE**\n \n Chat interface to try out a model. Besides chatting with the model, here are some basic commands:\n-- **!help**: shows all available commands\n+- **!help**: shows all available commands (set generation settings, save chat, etc.)\n - **!status**: shows the current status of the model and generation settings\n - **!clear**: clears the current conversation and starts a new one\n - **!exit**: closes the interface\n@@ -135,6 +138,9 @@ def stream_output(self, output_stream: TextIteratorStreamer) -> str:\n             for i, outputs in enumerate(output_stream):\n                 if not outputs or i == 0:\n                     continue\n+                # Escapes single words encased in <>, e.g. <think> -> \\<think\\>, for proper rendering in Markdown.\n+                # It only escapes single words that may have `_`, optionally following a `/` (e.g. </think>)\n+                outputs = re.sub(r\"<(/*)(\\w*)>\", r\"\\<\\1\\2\\>\", outputs)\n                 text += outputs\n                 # Render the accumulated text as Markdown\n                 # NOTE: this is a workaround for the rendering \"unstandard markdown\"\n@@ -219,6 +225,7 @@ class ChatArguments:\n     system_prompt: Optional[str] = field(default=None, metadata={\"help\": \"System prompt.\"})\n     save_folder: str = field(default=\"./chat_history/\", metadata={\"help\": \"Folder to save chat history.\"})\n     examples_path: Optional[str] = field(default=None, metadata={\"help\": \"Path to a yaml file with examples.\"})\n+    verbose: bool = field(default=False, metadata={\"help\": \"Whether to show runtime warnings in the chat interface.\"})\n \n     # Generation settings\n     generation_config: Optional[str] = field(\n@@ -426,6 +433,9 @@ def parse_generate_flags(self, generate_flags: list[str]) -> dict:\n \n         # 2. b. strings should be quoted\n         def is_number(s: str) -> bool:\n+            # handle negative numbers\n+            if s.startswith(\"-\"):\n+                s = s[1:]\n             return s.replace(\".\", \"\", 1).isdigit()\n \n         generate_flags_as_dict = {k: f'\"{v}\"' if not is_number(v) else v for k, v in generate_flags_as_dict.items()}\n@@ -583,6 +593,7 @@ def handle_non_exit_user_commands(\n         Handles all user commands except for `!exit`. May update the chat history (e.g. reset it) or the\n         generation config (e.g. set a new flag).\n         \"\"\"\n+        valid_command = True\n \n         if user_input == \"!clear\":\n             chat = self.clear_chat_history(args.system_prompt)\n@@ -644,10 +655,11 @@ def handle_non_exit_user_commands(\n             )\n \n         else:\n+            valid_command = False\n             interface.print_color(text=f\"'{user_input}' is not a valid command. Showing help message.\", color=\"red\")\n             interface.print_help()\n \n-        return chat, generation_config, model_kwargs\n+        return chat, valid_command, generation_config, model_kwargs\n \n     # -----------------------------------------------------------------------------------------------------------------\n     # Main logic\n@@ -673,6 +685,11 @@ def run(self):\n         generation_streamer = TextIteratorStreamer(tokenizer, skip_special_tokens=True, skip_prompt=True)\n         generation_config, model_kwargs = self.get_generation_parameterization(args, tokenizer)\n \n+        # if not verbose -> disable warnings, progress bars, etc in the chat interface\n+        if not args.verbose:\n+            logging.set_verbosity_error()\n+            disable_progress_bars()\n+\n         interface = RichInterface(model_name=args.model_name_or_path_positional, user_name=user)\n         interface.clear()\n         chat = self.clear_chat_history(args.system_prompt)\n@@ -689,7 +706,7 @@ def run(self):\n                     if user_input == \"!exit\":\n                         break\n                     else:\n-                        chat, generation_config, model_kwargs = self.handle_non_exit_user_commands(\n+                        chat, valid_command, generation_config, model_kwargs = self.handle_non_exit_user_commands(\n                             user_input=user_input,\n                             args=args,\n                             interface=interface,\n@@ -699,7 +716,7 @@ def run(self):\n                             chat=chat,\n                         )\n                     # `!example` sends a user message to the model\n-                    if not user_input.startswith(\"!example\"):\n+                    if not valid_command or not user_input.startswith(\"!example\"):\n                         continue\n                 else:\n                     chat.append({\"role\": \"user\", \"content\": user_input})"
        },
        {
            "sha": "99239b760d40a4e0d67be8301aa79eb01beff520",
            "filename": "src/transformers/generation/configuration_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/c769483188dd796eb313eabad5ec3517eb52e18a/src%2Ftransformers%2Fgeneration%2Fconfiguration_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c769483188dd796eb313eabad5ec3517eb52e18a/src%2Ftransformers%2Fgeneration%2Fconfiguration_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Fconfiguration_utils.py?ref=c769483188dd796eb313eabad5ec3517eb52e18a",
            "patch": "@@ -821,7 +821,7 @@ def validate(self, strict=False):\n                 warning_message = (\n                     f\"The following generation flags are not valid and may be ignored: {attributes_with_issues}.\"\n                 )\n-                if logger.getEffectiveLevel() >= logging.WARNING:\n+                if logging.get_verbosity() >= logging.WARNING:\n                     warning_message += \" Set `TRANSFORMERS_VERBOSITY=info` for more details.\"\n                 logger.warning(warning_message)\n                 logger.info(info_message)"
        }
    ],
    "stats": {
        "total": 29,
        "additions": 23,
        "deletions": 6
    }
}