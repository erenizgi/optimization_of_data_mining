{
    "author": "jla524",
    "message": "Fix typos in Translated Audio Classification Docs (#35287)\n\n* fix: qwen2 model ids\n\n* fix: line\n\n* fix: more format\n\n* update: reformat\n\n* fix: doc typos",
    "sha": "22834eeba1c2bf8d632e22fca238ab7c15d1b904",
    "files": [
        {
            "sha": "3b33d1b6043d782137c4ba0ec45b5acf2fd343ca",
            "filename": "docs/source/ja/tasks/audio_classification.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/22834eeba1c2bf8d632e22fca238ab7c15d1b904/docs%2Fsource%2Fja%2Ftasks%2Faudio_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/22834eeba1c2bf8d632e22fca238ab7c15d1b904/docs%2Fsource%2Fja%2Ftasks%2Faudio_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Ftasks%2Faudio_classification.md?ref=22834eeba1c2bf8d632e22fca238ab7c15d1b904",
            "patch": "@@ -128,7 +128,7 @@ DatasetDict({\n >>> feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n ```\n \n-MInDS-14 データセットのサンプリング レートは 8000khz です (この情報は [データセット カード](https://huggingface.co/datasets/PolyAI/minds14) で確認できます)。つまり、データセットを再サンプリングする必要があります。事前トレーニングされた Wav2Vec2 モデルを使用するには、16000kHz に設定します。\n+MInDS-14 データセットのサンプリング レートは 8khz です (この情報は [データセット カード](https://huggingface.co/datasets/PolyAI/minds14) で確認できます)。つまり、データセットを再サンプリングする必要があります。事前トレーニングされた Wav2Vec2 モデルを使用するには、16kHz に設定します。\n \n ```py\n >>> minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))"
        },
        {
            "sha": "2defa691edef75ffaefb7a66a3d8ebfc3a95ae5e",
            "filename": "docs/source/ko/tasks/audio_classification.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/22834eeba1c2bf8d632e22fca238ab7c15d1b904/docs%2Fsource%2Fko%2Ftasks%2Faudio_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/22834eeba1c2bf8d632e22fca238ab7c15d1b904/docs%2Fsource%2Fko%2Ftasks%2Faudio_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Faudio_classification.md?ref=22834eeba1c2bf8d632e22fca238ab7c15d1b904",
            "patch": "@@ -128,7 +128,7 @@ DatasetDict({\n >>> feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n ```\n \n-MinDS-14 데이터 세트의 샘플링 속도는 8000khz이므로(이 정보는 [데이터세트 카드](https://huggingface.co/datasets/PolyAI/minds14)에서 확인할 수 있습니다), 사전 훈련된 Wav2Vec2 모델을 사용하려면 데이터 세트를 16000kHz로 리샘플링해야 합니다:\n+MinDS-14 데이터 세트의 샘플링 속도는 8khz이므로(이 정보는 [데이터세트 카드](https://huggingface.co/datasets/PolyAI/minds14)에서 확인할 수 있습니다), 사전 훈련된 Wav2Vec2 모델을 사용하려면 데이터 세트를 16kHz로 리샘플링해야 합니다:\n \n ```py\n >>> minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}