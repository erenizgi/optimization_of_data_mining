{
    "author": "ArthurZucker",
    "message": "add setter for trainer processor (#33911)\n\n* add setter for trainer processor\r\n\r\n* Update src/transformers/trainer.py\r\n\r\nCo-authored-by: Quentin Gallouédec <45557362+qgallouedec@users.noreply.github.com>\r\n\r\n---------\r\n\r\nCo-authored-by: Quentin Gallouédec <45557362+qgallouedec@users.noreply.github.com>",
    "sha": "a220c5b99f9c512ba0c4b143807a7dba621c1f0c",
    "files": [
        {
            "sha": "cc5d1ee0c366195d08dd3b7367e5166b961cd172",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/a220c5b99f9c512ba0c4b143807a7dba621c1f0c/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a220c5b99f9c512ba0c4b143807a7dba621c1f0c/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=a220c5b99f9c512ba0c4b143807a7dba621c1f0c",
            "patch": "@@ -742,6 +742,13 @@ def tokenizer(self) -> Optional[PreTrainedTokenizerBase]:\n         logger.warning(\"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\")\n         return self.processing_class\n \n+    @tokenizer.setter\n+    def tokenizer(self, processing_class) -> None:\n+        logger.warning(\n+            \"Trainer.tokenizer is now deprecated. You should use `Trainer.processing_class = processing_class` instead.\"\n+        )\n+        self.processing_class = processing_class\n+\n     def _activate_neftune(self, model):\n         r\"\"\"\n         Activates the neftune as presented in this code: https://github.com/neelsjain/NEFTune and paper:"
        }
    ],
    "stats": {
        "total": 7,
        "additions": 7,
        "deletions": 0
    }
}