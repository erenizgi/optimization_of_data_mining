{
    "author": "eustlb",
    "message": "[voxtral] language detection + skipping lang:xx (#41225)\n\n* proc + doc update\n\n* improve doc\n\n* add lang:xx in decode\n\n* update voxtral test\n\n* nit\n\n* nit\n\n* update test value\n\n* use regex",
    "sha": "c5094a4f977527923fd3c969201d716139d47418",
    "files": [
        {
            "sha": "5d37e76660368fbaa275220303e9f6c4f00ab43b",
            "filename": "docs/source/en/model_doc/voxtral.md",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/c5094a4f977527923fd3c969201d716139d47418/docs%2Fsource%2Fen%2Fmodel_doc%2Fvoxtral.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c5094a4f977527923fd3c969201d716139d47418/docs%2Fsource%2Fen%2Fmodel_doc%2Fvoxtral.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fvoxtral.md?ref=c5094a4f977527923fd3c969201d716139d47418",
            "patch": "@@ -315,7 +315,8 @@ for decoded_output in decoded_outputs:\n \n ### Transcription Mode\n \n-Use the model to transcribe audio (supports English, Spanish, French, Portuguese, Hindi, German, Dutch, Italian)!\n+Use the model to transcribe audio (state-of-the-art performance in English, Spanish, French, Portuguese, Hindi, German, Dutch, Italian)!\n+It also support automatic language detection.\n \n ```python\n import torch\n@@ -328,9 +329,13 @@ repo_id = \"mistralai/Voxtral-Mini-3B-2507\"\n processor = AutoProcessor.from_pretrained(repo_id)\n model = VoxtralForConditionalGeneration.from_pretrained(repo_id, dtype=torch.bfloat16, device_map=device)\n \n+# set the language is already know for better accuracy\n inputs = processor.apply_transcription_request(language=\"en\", audio=\"https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/obama.mp3\", model_id=repo_id)\n-inputs = inputs.to(device, dtype=torch.bfloat16)\n \n+# # but you can also let the model detect the language automatically\n+# inputs = processor.apply_transcription_request(audio=\"https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/obama.mp3\", model_id=repo_id) \n+\n+inputs = inputs.to(device, dtype=torch.bfloat16)\n outputs = model.generate(**inputs, max_new_tokens=500)\n decoded_outputs = processor.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)\n "
        },
        {
            "sha": "47fe00bf3e9fd30e69f07e9c0ae55611338e0d4d",
            "filename": "src/transformers/models/voxtral/processing_voxtral.py",
            "status": "modified",
            "additions": 13,
            "deletions": 5,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/c5094a4f977527923fd3c969201d716139d47418/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fprocessing_voxtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c5094a4f977527923fd3c969201d716139d47418/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fprocessing_voxtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fprocessing_voxtral.py?ref=c5094a4f977527923fd3c969201d716139d47418",
            "patch": "@@ -277,9 +277,9 @@ def __call__(\n     # TODO: @eustlb, this should be moved to mistral_common + testing\n     def apply_transcription_request(\n         self,\n-        language: Union[str, list[str]],\n         audio: Union[str, list[str], AudioInput],\n         model_id: str,\n+        language: Optional[Union[str, list[Union[str, None]]]] = None,\n         sampling_rate: Optional[int] = None,\n         format: Optional[Union[str, list[str]]] = None,\n         **kwargs: Unpack[VoxtralProcessorKwargs],\n@@ -297,17 +297,24 @@ def apply_transcription_request(\n         language = \"en\"\n         audio = \"https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/obama.mp3\"\n \n+        # set the language is already know for better accuracy\n         inputs = processor.apply_transcription_request(language=language, audio=audio, model_id=model_id)\n+\n+        # but you can also let the model detect the language automatically\n+        inputs = processor.apply_transcription_request(audio=audio, model_id=model_id)\n         ```\n \n         Args:\n-            language (`str`, `list[str]`):\n-                The language or languages of the audio. If provided as a string, will be applied uniformly to all audio.\n-                If provided as a list, will be applied to each audio individually with a one-to-one mapping.\n             audio (`str`, `list[str]`, `np.ndarray`, `torch.Tensor`, `list[np.ndarray]`, `list[torch.Tensor]`):\n                 The audio or batch of audio to be prepared. If provided as a string, it should correspond to the path or url of the audio file.\n             model_id (`str`:\n                 The hub model id of the model to use for transcription.\n+            language (`str`, `list[Union[str, None]]`, *optional*):\n+                The language or languages of the audio.\n+                If not provided or None, automatic language detection will be used for all audio.\n+                If provided as a string (a language code in the [ISO 639-1 alpha-2 format](https://en.wikipedia.org/wiki/ISO_639-1) e.g. `\"en\"`), it will be applied uniformly to all audio.\n+                If provided as a list of strings/ None values, e.g. `[\"en\", None, \"fr\"]`, will be applied to each audio individually with a one-to-one mapping,\n+                with a None value indicating automatic language detection for that audio.\n             sampling_rate (`int`, *optional*):\n                 The sampling rate of the audio. Necessary if it is provided as `np.ndarray`, `torch.Tensor`, `list[np.ndarray]`, `list[torch.Tensor]`.\n                 Used to avoid silent errors when passing audio that is not in the expected sampling rate.\n@@ -377,7 +384,8 @@ def apply_transcription_request(\n         n_audio = len(audio)\n         if isinstance(language, str):\n             language = [language] * n_audio\n-\n+        elif language is None:\n+            language = [None] * n_audio\n         if len(language) != n_audio:\n             raise ValueError(\n                 f\"When passed as a list of languages, the length ({len(language)}) must match the number of audio ({n_audio})\""
        },
        {
            "sha": "8c3bf0ac788dced79a45b0d34a78c0d8cd2f440f",
            "filename": "src/transformers/tokenization_mistral_common.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/c5094a4f977527923fd3c969201d716139d47418/src%2Ftransformers%2Ftokenization_mistral_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c5094a4f977527923fd3c969201d716139d47418/src%2Ftransformers%2Ftokenization_mistral_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_mistral_common.py?ref=c5094a4f977527923fd3c969201d716139d47418",
            "patch": "@@ -13,6 +13,7 @@\n # limitations under the License.\n \n import os\n+import re\n import shutil\n import warnings\n from collections.abc import Callable, Mapping, Sized\n@@ -471,6 +472,12 @@ def decode(\n         if clean_up_tokenization_spaces:\n             decoded_string = PreTrainedTokenizerBase.clean_up_tokenization(decoded_string)\n \n+        # in the specific case of Voxtral, the added f\"lang:xx\" (always a two char language code since it follows ISO 639-1 alpha-2 format)\n+        # is not considered as a special token by mistral-common and is encoded/ decoded as normal text.\n+        # Nevertheless we should remove it to ease users life.\n+        if skip_special_tokens:\n+            decoded_string = re.sub(r\"^lang:[a-z]{2}\", \"\", decoded_string)\n+\n         return decoded_string\n \n     def batch_decode("
        },
        {
            "sha": "7b884578904ddc1d36e59f69cd7c3edbb8051680",
            "filename": "tests/models/voxtral/test_modeling_voxtral.py",
            "status": "modified",
            "additions": 18,
            "deletions": 2,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/c5094a4f977527923fd3c969201d716139d47418/tests%2Fmodels%2Fvoxtral%2Ftest_modeling_voxtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c5094a4f977527923fd3c969201d716139d47418/tests%2Fmodels%2Fvoxtral%2Ftest_modeling_voxtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvoxtral%2Ftest_modeling_voxtral.py?ref=c5094a4f977527923fd3c969201d716139d47418",
            "patch": "@@ -264,7 +264,7 @@ def test_mini_single_turn_audio_only(self):\n         outputs = model.generate(**inputs, do_sample=False, max_new_tokens=500)\n         decoded_outputs = self.processor.batch_decode(outputs, skip_special_tokens=True)\n         EXPECTED_OUTPUT = [\n-            'The audio is a humorous exchange between two individuals, likely friends or acquaintances, about tattoos. Here\\'s a breakdown:\\n\\n1. **Initial Reaction**: One person (let\\'s call him A) is surprised to see the other person (let\\'s call him B) has a tattoo.\\n2. **Curiosity**: A asks B what his tattoo says, and B responds with \"sweet.\"\\n3. **Repetition**: This exchange is repeated multiple times, with A asking about B\\'s tattoo and B responding with \"sweet.\"\\n4. **Clarification**: Eventually, B clarifies that A\\'s tattoo says \"dude\" and A\\'s says \"sweet.\"\\n5. **Final Insult**: B calls A an \"idiot\" for not understanding the joke.\\n\\nThe humor comes from the repetition of the word \"sweet\" and the confusion about the tattoos\\' meanings. The final insult adds a touch of frustration to the exchange.'\n+            'The audio is a humorous exchange between two individuals, likely friends or acquaintances, about tattoos. Here\\'s a breakdown:\\n\\n1. **Initial Reaction**: One person (let\\'s call him A) is surprised to see the other person (let\\'s call him B) has a tattoo. A asks if B has a tattoo, and B confirms.\\n\\n2. **Tattoo Description**: B then asks A what his tattoo says, and A responds with \"sweet.\" This exchange is repeated multiple times, with B asking A what his tattoo says, and A always responding with \"sweet.\"\\n\\n3. **Misunderstanding**: B seems to be genuinely curious about the meaning of the tattoo, but A is either not paying attention or not understanding the question. This leads to a series of repetitive responses from A.\\n\\n4. **Clarification**: Eventually, B clarifies that he wants to know what A\\'s tattoo says, not what A thinks B\\'s tattoo says. A then realizes his mistake and apologizes.\\n\\n5. **Final Answer**: B then asks A what his tattoo says, and A finally responds with \"dude,\" which is the actual meaning of his tattoo.\\n\\n6. **Final Joke**: B then jokes that A\\'s tattoo says \"sweet,\" which is a play on words, as \"sweet\" can also mean \"good\" or \"nice.\"\\n\\nThroughout the conversation, there\\'s a lot of repetition and misunderstanding, which adds to the humor. The final joke about the tattoo saying \"sweet\" is a clever twist on the initial confusion.'\n         ]\n         self.assertEqual(decoded_outputs, EXPECTED_OUTPUT)\n \n@@ -487,6 +487,7 @@ def test_transcribe_mode_audio_input(self):\n         see https://github.com/huggingface/transformers/pull/39429 PR's descrition.\n         disclaimer: Perfect token matching cannot be achieved due to floating-point arithmetic differences between vLLM and Transformers implementations.\n         \"\"\"\n+        # test without language detection\n         model = VoxtralForConditionalGeneration.from_pretrained(\n             self.checkpoint_name, dtype=self.dtype, device_map=torch_device\n         )\n@@ -501,6 +502,21 @@ def test_transcribe_mode_audio_input(self):\n         decoded_outputs = self.processor.batch_decode(outputs, skip_special_tokens=True)\n \n         EXPECTED_OUTPUT = [\n-            \"lang:enThis week, I traveled to Chicago to deliver my final farewell address to the nation, following in the tradition of presidents before me. It was an opportunity to say thank you. Whether we've seen eye-to-eye or rarely agreed at all, my conversations with you, the American people, in living rooms and schools, at farms and on factory floors, at diners and on distant military outposts, All these conversations are what have kept me honest, kept me inspired, and kept me going. Every day, I learned from you. You made me a better president, and you made me a better man. Over the course of these eight years, I've seen the goodness, the resilience, and the hope of the American people. I've seen neighbors looking out for each other as we rescued our economy from the worst crisis of our lifetimes. I've hugged cancer survivors who finally know the security of affordable health care. I've seen communities like Joplin rebuild from disaster, and cities like Boston show the world that no terrorist will ever break the American spirit. I've seen the hopeful faces of young graduates and our newest military officers. I've mourned with grieving families searching for answers, and I found grace in a Charleston church. I've seen our scientists help a paralyzed man regain his sense of touch, and our wounded warriors walk again. I've seen our doctors and volunteers rebuild after earthquakes and stop pandemics in their tracks. I've learned from students who are building robots and curing diseases and who will change the world in ways we can't even imagine. I've seen the youngest of children remind us of our obligations to care for our refugees, to work in peace, and above all, to look out for each other. That's what's possible when we come together in the slow, hard, sometimes frustrating, but always vital work of self-government. But we can't take our democracy for granted. All of us, regardless of party, should throw ourselves into the work of citizenship. Not just when there's an election. Not just when our own narrow interest is at stake. But over the full span of a lifetime. If you're tired of arguing with strangers on the Internet, try to talk with one in real life. If something needs fixing, lace up your shoes and do some organizing. If you're disappointed by your elected officials, then grab a clipboard, get some signatures, and run for office yourself. Our success depends on our\"\n+            \"This week, I traveled to Chicago to deliver my final farewell address to the nation, following in the tradition of presidents before me. It was an opportunity to say thank you. Whether we've seen eye-to-eye or rarely agreed at all, my conversations with you, the American people, in living rooms and schools, at farms and on factory floors, at diners and on distant military outposts, All these conversations are what have kept me honest, kept me inspired, and kept me going. Every day, I learned from you. You made me a better president, and you made me a better man. Over the course of these eight years, I've seen the goodness, the resilience, and the hope of the American people. I've seen neighbors looking out for each other as we rescued our economy from the worst crisis of our lifetimes. I've hugged cancer survivors who finally know the security of affordable health care. I've seen communities like Joplin rebuild from disaster, and cities like Boston show the world that no terrorist will ever break the American spirit. I've seen the hopeful faces of young graduates and our newest military officers. I've mourned with grieving families searching for answers, and I found grace in a Charleston church. I've seen our scientists help a paralyzed man regain his sense of touch, and our wounded warriors walk again. I've seen our doctors and volunteers rebuild after earthquakes and stop pandemics in their tracks. I've learned from students who are building robots and curing diseases and who will change the world in ways we can't even imagine. I've seen the youngest of children remind us of our obligations to care for our refugees, to work in peace, and above all, to look out for each other. That's what's possible when we come together in the slow, hard, sometimes frustrating, but always vital work of self-government. But we can't take our democracy for granted. All of us, regardless of party, should throw ourselves into the work of citizenship. Not just when there's an election. Not just when our own narrow interest is at stake. But over the full span of a lifetime. If you're tired of arguing with strangers on the Internet, try to talk with one in real life. If something needs fixing, lace up your shoes and do some organizing. If you're disappointed by your elected officials, then grab a clipboard, get some signatures, and run for office yourself. Our success depends on our\"\n+        ]\n+        self.assertEqual(decoded_outputs, EXPECTED_OUTPUT)\n+\n+        # test with language detection, i.e. language=None\n+        inputs = self.processor.apply_transcription_request(\n+            audio=\"https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/obama.mp3\",\n+            model_id=self.checkpoint_name,\n+        )\n+        inputs = inputs.to(torch_device, dtype=self.dtype)\n+        outputs = model.generate(**inputs, do_sample=False, max_new_tokens=500)\n+\n+        decoded_outputs = self.processor.batch_decode(outputs, skip_special_tokens=True)\n+\n+        EXPECTED_OUTPUT = [\n+            \"This week, I traveled to Chicago to deliver my final farewell address to the nation, following in the tradition of presidents before me. It was an opportunity to say thank you. Whether we've seen eye-to-eye or rarely agreed at all, my conversations with you, the American people, in living rooms and schools, at farms and on factory floors, at diners and on distant military outposts, All these conversations are what have kept me honest, kept me inspired, and kept me going. Every day, I learned from you. You made me a better president, and you made me a better man. Over the course of these eight years, I've seen the goodness, the resilience, and the hope of the American people. I've seen neighbors looking out for each other as we rescued our economy from the worst crisis of our lifetimes. I've hugged cancer survivors who finally know the security of affordable health care. I've seen communities like Joplin rebuild from disaster, and cities like Boston show the world that no terrorist will ever break the American spirit. I've seen the hopeful faces of young graduates and our newest military officers. I've mourned with grieving families searching for answers, and I found grace in a Charleston church. I've seen our scientists help a paralyzed man regain his sense of touch, and our wounded warriors walk again. I've seen our doctors and volunteers rebuild after earthquakes and stop pandemics in their tracks. I've learned from students who are building robots and curing diseases and who will change the world in ways we can't even imagine. I've seen the youngest of children remind us of our obligations to care for our refugees, to work in peace, and above all, to look out for each other. That's what's possible when we come together in the slow, hard, sometimes frustrating, but always vital work of self-government. But we can't take our democracy for granted. All of us, regardless of party, should throw ourselves into the work of citizenship. Not just when there's an election. Not just when our own narrow interest is at stake. But over the full span of a lifetime. If you're tired of arguing with strangers on the Internet, try to talk with one in real life. If something needs fixing, lace up your shoes and do some organizing. If you're disappointed by your elected officials, then grab a clipboard, get some signatures, and run for office yourself. Our success depends on our\"\n         ]\n         self.assertEqual(decoded_outputs, EXPECTED_OUTPUT)"
        },
        {
            "sha": "3943185894ebe92604bc46185bfdfc5f9a0ee36f",
            "filename": "tests/test_tokenization_mistral_common.py",
            "status": "modified",
            "additions": 29,
            "deletions": 1,
            "changes": 30,
            "blob_url": "https://github.com/huggingface/transformers/blob/c5094a4f977527923fd3c969201d716139d47418/tests%2Ftest_tokenization_mistral_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c5094a4f977527923fd3c969201d716139d47418/tests%2Ftest_tokenization_mistral_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_tokenization_mistral_common.py?ref=c5094a4f977527923fd3c969201d716139d47418",
            "patch": "@@ -12,7 +12,9 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n+import base64\n import gc\n+import io\n import tempfile\n import unittest\n \n@@ -31,6 +33,7 @@\n     import mistral_common.tokens.tokenizers\n     from mistral_common.exceptions import InvalidMessageStructureException\n     from mistral_common.protocol.instruct.request import ChatCompletionRequest\n+    from mistral_common.protocol.transcription.request import TranscriptionRequest\n     from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n     from mistral_common.tokens.tokenizers.utils import list_local_hf_repo_files\n \n@@ -259,6 +262,31 @@ def test_decode(self):\n         ):\n             self.tokenizer.decode(tokens_ids, skip_special_tokens=False, unk_args=\"\")\n \n+    def test_decode_transcription_mode(self):\n+        # in the specific case of Voxtral, the added f\"lang:xx\" (always a two char language code since it follows ISO 639-1 alpha-2 format)\n+        # is not considered as a special token by mistral-common and is encoded/ decoded as normal text.\n+        # we made the explicit choice of skipping \"lang:xx\" it to ease users life, see `[~MistralCommonTokenizer.decode]`\n+        expected_string = \"lang:en[TRANSCRIBE]\"\n+\n+        openai_transcription_request = {\n+            \"model\": None,\n+            \"language\": \"en\",\n+            \"file\": io.BytesIO(base64.b64decode(AUDIO_BASE_64)),\n+        }\n+        transcription_request = TranscriptionRequest.from_openai(openai_transcription_request)\n+        tokenized_transcription_request = self.ref_tokenizer_audio.encode_transcription(transcription_request)\n+\n+        # without skip_special_tokens\n+        self.assertEqual(\n+            self.tokenizer_audio.decode(tokenized_transcription_request.tokens, skip_special_tokens=False)[\n+                -len(expected_string) :\n+            ],\n+            expected_string,\n+        )\n+\n+        # with skip_special_tokens\n+        self.assertEqual(self.tokenizer.decode(tokenized_transcription_request.tokens, skip_special_tokens=True), \"\")\n+\n     def test_batch_decode(self):\n         string = \"Hello, world!\"\n         string_with_space = \"Hello, world !\"\n@@ -919,7 +947,7 @@ def test_apply_chat_template_with_audio(self):\n                 conversation, tokenize=True, return_dict=True, return_tensors=\"pt\"\n             )\n \n-    def test_appsly_chat_template_with_truncation(self):\n+    def test_apply_chat_template_with_truncation(self):\n         conversation = [\n             {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n             {\"role\": \"user\", \"content\": \"Hi!\"},"
        }
    ],
    "stats": {
        "total": 84,
        "additions": 74,
        "deletions": 10
    }
}