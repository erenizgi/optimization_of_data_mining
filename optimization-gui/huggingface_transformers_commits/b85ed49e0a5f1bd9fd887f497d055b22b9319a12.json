{
    "author": "renet10",
    "message": "Corrections to PR #38642 and enhancements to Wav2Vec2Processor __call__ and pad docstrings (#38822)\n\n* Correcting PR #38642.  The PR removed references to the deprecated method \"as_target_processor()\" in the\n__call__ and pad method docstrings, which is correct, but also removed all references to PreTrainedTokenizer,\nwhich is incorrect.  This commit adds back the reference to PreTrainedTokenizer and also takes the\nopportunity to enhance the docstrings with the invocation procedure post removal of \"as_target_processor()\"\nand adds information on return values.\n\n* Update src/transformers/models/wav2vec2/processing_wav2vec2.py\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update src/transformers/models/wav2vec2/processing_wav2vec2.py\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update src/transformers/models/wav2vec2/processing_wav2vec2.py\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update src/transformers/models/wav2vec2/processing_wav2vec2.py\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update src/transformers/models/wav2vec2/processing_wav2vec2.py\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update src/transformers/models/wav2vec2/processing_wav2vec2.py\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update src/transformers/models/wav2vec2/processing_wav2vec2.py\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update src/transformers/models/wav2vec2/processing_wav2vec2.py\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update src/transformers/models/wav2vec2/processing_wav2vec2.py\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update src/transformers/models/wav2vec2/processing_wav2vec2.py\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update src/transformers/models/wav2vec2/processing_wav2vec2.py\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update src/transformers/models/wav2vec2/processing_wav2vec2.py\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update src/transformers/models/wav2vec2/processing_wav2vec2.py\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update src/transformers/models/wav2vec2/processing_wav2vec2.py\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n---------\n\nCo-authored-by: Ren√© Tio <tor@Jammer.local>\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
    "sha": "b85ed49e0a5f1bd9fd887f497d055b22b9319a12",
    "files": [
        {
            "sha": "8e9024995d0eb63587f9e01e1d88ce7da59e2448",
            "filename": "src/transformers/models/wav2vec2/processing_wav2vec2.py",
            "status": "modified",
            "additions": 23,
            "deletions": 5,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/b85ed49e0a5f1bd9fd887f497d055b22b9319a12/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fprocessing_wav2vec2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b85ed49e0a5f1bd9fd887f497d055b22b9319a12/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fprocessing_wav2vec2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fprocessing_wav2vec2.py?ref=b85ed49e0a5f1bd9fd887f497d055b22b9319a12",
            "patch": "@@ -81,10 +81,19 @@ def __call__(\n         **kwargs: Unpack[Wav2Vec2ProcessorKwargs],\n     ):\n         \"\"\"\n-        This method forwards all its arguments to Wav2Vec2FeatureExtractor's\n-        [`~Wav2Vec2FeatureExtractor.__call__`] and returns its output.\n-        \"\"\"\n+        This method forwards all arguments to [`Wav2Vec2FeatureExtractor.__call__`] and/or\n+        [`PreTrainedTokenizer.__call__`] depending on the input modality and returns their outputs. If both modalities are passed, [`Wav2Vec2FeatureExtractor.__call__`] and [`PreTrainedTokenizer.__call__`] are called.\n+\n+        Args:\n+            audio (`np.ndarray`, `torch.Tensor`, `List[np.ndarray]`, `List[torch.Tensor]`, *optional*):\n+                An audio input is passed to [`Wav2Vec2FeatureExtractor.__call__`].\n+            text (`str`, `List[str]`, *optional*):\n+                A text input is passed to [`PreTrainedTokenizer.__call__`].\n+\n \n+        Returns:\n+            This method returns the results of each `call` method. If both are used, the output is a dictionary containing the results of both.\n+        \"\"\"\n         if \"raw_speech\" in kwargs:\n             warnings.warn(\"Using `raw_speech` as a keyword argument is deprecated. Use `audio` instead.\")\n             audio = kwargs.pop(\"raw_speech\")\n@@ -121,8 +130,17 @@ def __call__(\n \n     def pad(self, *args, **kwargs):\n         \"\"\"\n-        This method forwards all its arguments to Wav2Vec2FeatureExtractor's\n-        [`~Wav2Vec2FeatureExtractor.pad`] and returns its output.\n+        This method operates on batches of extracted features and/or tokenized text. It forwards all arguments to\n+        [`Wav2Vec2FeatureExtractor.pad`] and/or [`PreTrainedTokenizer.pad`] depending on the input modality and returns their outputs. If both modalities are passed, [`Wav2Vec2FeatureExtractor.pad`] and [`PreTrainedTokenizer.pad`] are called.\n+\n+        Args:\n+            input_features:\n+                When the first argument is a dictionary containing a batch of tensors, or the `input_features` argument is present, it is passed to [`Wav2Vec2FeatureExtractor.pad`].\n+            labels:\n+                When the `label` argument is present, it is passed to [`PreTrainedTokenizer.pad`].\n+\n+        Returns:\n+            This method returns the results of each `pad` method. If both are used, the output is a dictionary containing the results of both.\n         \"\"\"\n         # For backward compatibility\n         if self._in_target_context_manager:"
        }
    ],
    "stats": {
        "total": 28,
        "additions": 23,
        "deletions": 5
    }
}