{
    "author": "mynameismon",
    "message": "Fix typo in LLaVa documentation (#38618)\n\n* Fix typo in LLaVa documentation\n\nIn exactly one section, LlavaImageProcessor was spelt wrongly as LLavaImageProcessor, which throws off copy-pasting the section.\n\n* Fix LlavaImageProcessor url to make it valid (and copypaste-able)\n\nEarlier, the URL contained the entire HF prefix. This commit removes that to ensure that the code block can be copied and run as is.",
    "sha": "c75bf2c36e871dfde468dcd98c3df22f3cda2679",
    "files": [
        {
            "sha": "d4cc90d2ec6c3cbda11e387c534dc6f5c0b169aa",
            "filename": "docs/source/en/model_doc/llava.md",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/c75bf2c36e871dfde468dcd98c3df22f3cda2679/docs%2Fsource%2Fen%2Fmodel_doc%2Fllava.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c75bf2c36e871dfde468dcd98c3df22f3cda2679/docs%2Fsource%2Fen%2Fmodel_doc%2Fllava.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fllava.md?ref=c75bf2c36e871dfde468dcd98c3df22f3cda2679",
            "patch": "@@ -216,12 +216,12 @@ processor.batch_decode(generate_ids, skip_special_tokens=True)\n \n ## Note regarding reproducing original implementation\n \n-In order to match the logits of the [original implementation](https://github.com/haotian-liu/LLaVA/tree/main), one needs to additionally specify `do_pad=True` when instantiating `LLavaImageProcessor`:\n+In order to match the logits of the [original implementation](https://github.com/haotian-liu/LLaVA/tree/main), one needs to additionally specify `do_pad=True` when instantiating `LlavaImageProcessor`:\n \n ```python\n-from transformers import LLavaImageProcessor\n+from transformers import LlavaImageProcessor\n \n-image_processor = LLavaImageProcessor.from_pretrained(\"https://huggingface.co/llava-hf/llava-1.5-7b-hf\", do_pad=True)\n+image_processor = LlavaImageProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\", do_pad=True)\n ```\n \n ### Using Flash Attention 2"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 3,
        "deletions": 3
    }
}