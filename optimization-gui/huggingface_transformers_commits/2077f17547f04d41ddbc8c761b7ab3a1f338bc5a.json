{
    "author": "McPatate",
    "message": "feat: err when unsupported attn impl is set w/ `--continuous_batching` (#40618)\n\n* feat: err when unsupported attn impl is set w/ `--continuous_batching`\n\n* refactor: move defaults and support list to CB code\n\n* feat: add action item in error msg\n\n* fix(serve): add default attn implementation\n\n* feat(serve): add log when `attn_implementation` is `None`\n\n* feat: raise Exception when attn_implementation is not supported by CB",
    "sha": "2077f17547f04d41ddbc8c761b7ab3a1f338bc5a",
    "files": [
        {
            "sha": "6c5bbed3cfa455397dfa5f185eff1e29f30342b3",
            "filename": "src/transformers/commands/serving.py",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/2077f17547f04d41ddbc8c761b7ab3a1f338bc5a/src%2Ftransformers%2Fcommands%2Fserving.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2077f17547f04d41ddbc8c761b7ab3a1f338bc5a/src%2Ftransformers%2Fcommands%2Fserving.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fserving.py?ref=2077f17547f04d41ddbc8c761b7ab3a1f338bc5a",
            "patch": "@@ -483,6 +483,19 @@ def __init__(self, args: ServeArguments):\n         # Store and process input arguments\n         self.args = args\n         self.use_continuous_batching = self.args.continuous_batching\n+        if self.use_continuous_batching:\n+            default_attn_impl = ContinuousBatchingManager.default_attention_implementation()\n+            # checking if attn_implementation is supported by continuous batching\n+            if self.args.attn_implementation is None:\n+                self.args.attn_implementation = default_attn_impl  # default to sdpa_paged\n+                logger.info(f\"No attn_implementation passed, defaulting to {default_attn_impl}\")\n+            supported_attn_impl = ContinuousBatchingManager.supported_attention_implementations()\n+            if self.args.attn_implementation not in supported_attn_impl:\n+                raise ValueError(\n+                    f\"Continuous batching only supports {supported_attn_impl} as attn_implementation, got \"\n+                    f\"{self.args.attn_implementation}\"\n+                    f\"Try setting `--attn_implementation={default_attn_impl}`\"\n+                )\n         self.enable_cors = self.args.enable_cors\n \n         if self.args.default_seed is not None:"
        },
        {
            "sha": "48a10e13b0e9eda52756eb3a64ee84fccb3f0c8c",
            "filename": "src/transformers/generation/continuous_batching/continuous_api.py",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/2077f17547f04d41ddbc8c761b7ab3a1f338bc5a/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching%2Fcontinuous_api.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2077f17547f04d41ddbc8c761b7ab3a1f338bc5a/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching%2Fcontinuous_api.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching%2Fcontinuous_api.py?ref=2077f17547f04d41ddbc8c761b7ab3a1f338bc5a",
            "patch": "@@ -595,6 +595,14 @@ def request_id_iter(self, request_id):\n             if self.batch_processor is not None:\n                 request_cancelled = self.batch_processor.scheduler.request_is_cancelled(request_id)\n \n+    @staticmethod\n+    def supported_attention_implementations() -> set[str]:\n+        return {\"eager_paged\", \"sdpa_paged\", \"flash_attention_2\"}\n+\n+    @staticmethod\n+    def default_attention_implementation() -> str:\n+        return \"sdpa_paged\"\n+\n     @traced\n     def warmup(self, batch_processor):\n         stream = torch.cuda.Stream(device=self.model.device)"
        }
    ],
    "stats": {
        "total": 21,
        "additions": 21,
        "deletions": 0
    }
}