{
    "author": "techkang",
    "message": "fix TrainerState doc because num_input_tokens_seen is unused by defauâ€¦ (#34593)\n\nfix TrainerState doc because num_input_tokens_seen is unused by default config\r\n\r\nCo-authored-by: kangsheng <kangsheng@meituan.com>",
    "sha": "bfa021be055661e572ee20ca619979c27a551537",
    "files": [
        {
            "sha": "7b711f65701d44e6ddfec089aefa2a35992531d6",
            "filename": "src/transformers/trainer_callback.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/bfa021be055661e572ee20ca619979c27a551537/src%2Ftransformers%2Ftrainer_callback.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bfa021be055661e572ee20ca619979c27a551537/src%2Ftransformers%2Ftrainer_callback.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer_callback.py?ref=bfa021be055661e572ee20ca619979c27a551537",
            "patch": "@@ -64,7 +64,8 @@ class TrainerState:\n             The batch size for the training dataloader. Only needed when\n             `auto_find_batch_size` has been used.\n         num_input_tokens_seen (`int`, *optional*, defaults to 0):\n-            The number of tokens seen during training (number of input tokens, not the number of prediction tokens).\n+            When tracking the inputs tokens, the number of tokens seen during training (number of input tokens, not the\n+            number of prediction tokens).\n         total_flos (`float`, *optional*, defaults to 0):\n             The total number of floating operations done by the model since the beginning of training (stored as floats\n             to avoid overflow)."
        }
    ],
    "stats": {
        "total": 3,
        "additions": 2,
        "deletions": 1
    }
}