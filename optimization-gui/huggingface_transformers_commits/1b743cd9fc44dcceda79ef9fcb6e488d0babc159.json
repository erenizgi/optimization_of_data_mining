{
    "author": "lukepayyapilli",
    "message": "ðŸš¨ Fix EfficientNet image processor default interpolation to BICUBIC (#42956)\n\nFix EfficientNet image processor default interpolation to BICUBIC\n\nThe original EfficientNet implementation uses BICUBIC interpolation for image\npreprocessing, but both EfficientNetImageProcessor and EfficientNetImageProcessorFast\ndefaulted to NEAREST. This change aligns the default with the original implementation.\n\nReference: https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/preprocessing.py\n\nFixes part of #28180",
    "sha": "1b743cd9fc44dcceda79ef9fcb6e488d0babc159",
    "files": [
        {
            "sha": "478cd2817411c52823e344e753ba7dde72254acd",
            "filename": "src/transformers/models/efficientnet/image_processing_efficientnet.py",
            "status": "modified",
            "additions": 5,
            "deletions": 6,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/1b743cd9fc44dcceda79ef9fcb6e488d0babc159/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fimage_processing_efficientnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1b743cd9fc44dcceda79ef9fcb6e488d0babc159/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fimage_processing_efficientnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fimage_processing_efficientnet.py?ref=1b743cd9fc44dcceda79ef9fcb6e488d0babc159",
            "patch": "@@ -66,7 +66,7 @@ class EfficientNetImageProcessor(BaseImageProcessor):\n             `do_resize` in `preprocess`.\n         size (`dict[str, int]` *optional*, defaults to `{\"height\": 346, \"width\": 346}`):\n             Size of the image after `resize`. Can be overridden by `size` in `preprocess`.\n-        resample (`PILImageResampling` filter, *optional*, defaults to 0):\n+        resample (`PILImageResampling` filter, *optional*, defaults to `Resampling.BICUBIC`):\n             Resampling filter to use if resizing the image. Can be overridden by `resample` in `preprocess`.\n         do_center_crop (`bool`, *optional*, defaults to `False`):\n             Whether to center crop the image. If the input size is smaller than `crop_size` along any edge, the image\n@@ -102,7 +102,7 @@ def __init__(\n         self,\n         do_resize: bool = True,\n         size: Optional[dict[str, int]] = None,\n-        resample: PILImageResampling = PIL.Image.NEAREST,\n+        resample: PILImageResampling = PILImageResampling.BICUBIC,\n         do_center_crop: bool = False,\n         crop_size: Optional[dict[str, int]] = None,\n         rescale_factor: Union[int, float] = 1 / 255,\n@@ -133,12 +133,11 @@ def __init__(\n         self.image_std = image_std if image_std is not None else IMAGENET_STANDARD_STD\n         self.include_top = include_top\n \n-    # Copied from transformers.models.vit.image_processing_vit.ViTImageProcessor.resize with PILImageResampling.BILINEAR->PILImageResampling.NEAREST\n     def resize(\n         self,\n         image: np.ndarray,\n         size: dict[str, int],\n-        resample: PILImageResampling = PILImageResampling.NEAREST,\n+        resample: PILImageResampling = PILImageResampling.BICUBIC,\n         data_format: Optional[Union[str, ChannelDimension]] = None,\n         input_data_format: Optional[Union[str, ChannelDimension]] = None,\n         **kwargs,\n@@ -151,8 +150,8 @@ def resize(\n                 Image to resize.\n             size (`dict[str, int]`):\n                 Dictionary in the format `{\"height\": int, \"width\": int}` specifying the size of the output image.\n-            resample (`PILImageResampling`, *optional*, defaults to `PILImageResampling.NEAREST`):\n-                `PILImageResampling` filter to use when resizing the image e.g. `PILImageResampling.NEAREST`.\n+            resample (`PILImageResampling`, *optional*, defaults to `PILImageResampling.BICUBIC`):\n+                `PILImageResampling` filter to use when resizing the image e.g. `PILImageResampling.BICUBIC`.\n             data_format (`ChannelDimension` or `str`, *optional*):\n                 The channel dimension format for the output image. If unset, the channel dimension format of the input\n                 image is used. Can be one of:"
        },
        {
            "sha": "4d29b8adf0e39a595f7f443dbb705f092d89746e",
            "filename": "src/transformers/models/efficientnet/image_processing_efficientnet_fast.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/1b743cd9fc44dcceda79ef9fcb6e488d0babc159/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fimage_processing_efficientnet_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1b743cd9fc44dcceda79ef9fcb6e488d0babc159/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fimage_processing_efficientnet_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fimage_processing_efficientnet_fast.py?ref=1b743cd9fc44dcceda79ef9fcb6e488d0babc159",
            "patch": "@@ -33,7 +33,7 @@\n \n @auto_docstring\n class EfficientNetImageProcessorFast(BaseImageProcessorFast):\n-    resample = PILImageResampling.NEAREST\n+    resample = PILImageResampling.BICUBIC\n     image_mean = IMAGENET_STANDARD_MEAN\n     image_std = IMAGENET_STANDARD_STD\n     size = {\"height\": 346, \"width\": 346}"
        }
    ],
    "stats": {
        "total": 13,
        "additions": 6,
        "deletions": 7
    }
}