{
    "author": "ydshieh",
    "message": "Cleanup workflow - part 1 (#42023)\n\n* part 1\n\n* part 2\n\n* part 3\n\n* part 4\n\n* part 5\n\n* fix 1\n\n* check 1\n\n* part 6\n\n* part 7\n\n* part 8\n\n* part 9\n\n* part 10: rename file\n\n* OK: new_model_pr_merged_notification.yml\n\n* part 11\n\n* fix 2\n\n* revert check\n\n* fix\n\n* fix\n\n* fix\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "57bdb4a680b2f82ad739ef741996be04e3764eea",
    "files": [
        {
            "sha": "c7f2271983646b2e8c7c42c5c417cacea529e2bb",
            "filename": ".github/workflows/check_failed_tests.yml",
            "status": "modified",
            "additions": 39,
            "deletions": 16,
            "changes": 55,
            "blob_url": "https://github.com/huggingface/transformers/blob/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fcheck_failed_tests.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fcheck_failed_tests.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fcheck_failed_tests.yml?ref=57bdb4a680b2f82ad739ef741996be04e3764eea",
            "patch": "@@ -64,13 +64,15 @@ jobs:\n       - name: Check file\n         id: check_file\n         working-directory: /transformers\n+        env:\n+          job: ${{ inputs.job }}\n         run: |\n-          if [ -f ci_results_${{ inputs.job }}/new_failures.json ]; then\n-            echo \"`ci_results_${{ inputs.job }}/new_failures.json` exists, continue ...\"\n+          if [ -f \"ci_results_${job}/new_failures.json\" ]; then\n+            echo \"\\`ci_results_${job}/new_failures.json\\` exists, continue ...\"\n             echo \"process=true\" >> $GITHUB_ENV\n             echo \"process=true\" >> $GITHUB_OUTPUT\n           else\n-            echo \"`ci_results_${{ inputs.job }}/new_failures.json` doesn't exist, abort.\"\n+            echo \"\\`ci_results_${job}/new_failures.json\\` doesn't exist, abort.\"\n             echo \"process=false\" >> $GITHUB_ENV\n             echo \"process=false\" >> $GITHUB_OUTPUT\n           fi\n@@ -94,15 +96,18 @@ jobs:\n       - name: Update clone\n         working-directory: /transformers\n         if: ${{ env.process == 'true' }}\n+        env:\n+          commit_sha: ${{ inputs.commit_sha || github.sha }}\n         run: |\n-          git fetch origin ${{ inputs.commit_sha || github.sha }}\n-          git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n+          git fetch origin \"$commit_sha\" && git checkout \"$commit_sha\"\n \n       - name: Get `START_SHA`\n         working-directory: /transformers/utils\n         if: ${{ env.process == 'true' }}\n+        env:\n+          commit_sha: ${{ inputs.commit_sha || github.sha }}\n         run: |\n-          echo \"START_SHA=${{ inputs.commit_sha || github.sha }}\" >> $GITHUB_ENV\n+          echo \"START_SHA=$commit_sha\" >> $GITHUB_ENV\n \n       # This is used if the CI is triggered from a pull request `self-comment-ci.yml` (after security check is verified)\n       - name: Extract the base commit on `main` (of the merge commit created by Github) if it is a PR\n@@ -130,16 +135,20 @@ jobs:\n       - name: Get `END_SHA` from previous CI runs of the same workflow\n         working-directory: /transformers/utils\n         if: ${{ env.process == 'true' && inputs.pr_number == '' }}\n+        env:\n+          ACCESS_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n         run: |\n-          echo \"END_SHA=$(TOKEN=${{ secrets.ACCESS_REPO_INFO_TOKEN }} python3 -c 'import os; from get_previous_daily_ci import get_last_daily_ci_run_commit; commit=get_last_daily_ci_run_commit(token=os.environ[\"TOKEN\"], workflow_run_id=os.environ[\"PREV_WORKFLOW_RUN_ID\"]); print(commit)')\" >> $GITHUB_ENV\n+          echo \"END_SHA=$(TOKEN=\"$ACCESS_TOKEN\" python3 -c 'import os; from get_previous_daily_ci import get_last_daily_ci_run_commit; commit=get_last_daily_ci_run_commit(token=os.environ[\"TOKEN\"], workflow_run_id=os.environ[\"PREV_WORKFLOW_RUN_ID\"]); print(commit)')\" >> $GITHUB_ENV\n \n       # However, for workflow runs triggered by `issue_comment` (for pull requests), we want to check against the\n       # parent commit (on `main`) of the `merge_commit` (dynamically created by GitHub). In this case, the goal is to\n       # see if a reported failing test is actually ONLY failing on the `merge_commit`.\n       - name: Set `END_SHA`\n         if: ${{ env.process == 'true' && inputs.pr_number != '' }}\n+        env:\n+          merge_commit_base_sha: ${{ steps.pr_info.outputs.merge_commit_base_sha }}\n         run: |\n-          echo \"END_SHA=${{ steps.pr_info.outputs.merge_commit_base_sha }}\" >> $GITHUB_ENV\n+          echo \"END_SHA=$merge_commit_base_sha\" >> $GITHUB_ENV\n \n       - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n         working-directory: /transformers\n@@ -169,14 +178,20 @@ jobs:\n       - name: Check failed tests\n         working-directory: /transformers\n         if: ${{ env.process == 'true' }}\n-        run: python3 utils/check_bad_commit.py --start_commit ${{ env.START_SHA }} --end_commit ${{ env.END_SHA }} --file ci_results_${{ inputs.job }}/new_failures.json --output_file new_failures_with_bad_commit_${{ inputs.job }}_${{ matrix.run_idx }}.json\n+        env:\n+          job: ${{ inputs.job }}\n+          run_idx: ${{ matrix.run_idx }}\n+        run: python3 utils/check_bad_commit.py --start_commit \"$START_SHA\" --end_commit \"$END_SHA\" --file \"ci_results_${job}/new_failures.json\" --output_file \"new_failures_with_bad_commit_${job}_${run_idx}.json\"\n \n       - name: Show results\n         working-directory: /transformers\n         if: ${{ env.process == 'true' }}\n+        env:\n+          job: ${{ inputs.job }}\n+          run_idx: ${{ matrix.run_idx }}\n         run: |\n-          ls -l new_failures_with_bad_commit_${{ inputs.job }}_${{ matrix.run_idx }}.json\n-          cat new_failures_with_bad_commit_${{ inputs.job }}_${{ matrix.run_idx }}.json\n+          ls -l \"new_failures_with_bad_commit_${job}_${run_idx}.json\"\n+          cat \"new_failures_with_bad_commit_${job}_${run_idx}.json\"\n \n       - name: Upload artifacts\n         uses: actions/upload-artifact@v4\n@@ -209,23 +224,28 @@ jobs:\n \n       - name: Check files\n         working-directory: /transformers\n+        env:\n+          job: ${{ inputs.job }}\n         run: |\n           ls -la /transformers\n-          ls -la /transformers/new_failures_with_bad_commit_${{ inputs.job }}\n+          ls -la \"/transformers/new_failures_with_bad_commit_${job}\"\n \n       # Currently, we only run with a single runner by using `run_idx: [1]`. We might try to run with multiple runners\n       # to further reduce the false positive caused by flaky tests, which requires further processing to merge reports.\n       - name: Merge files\n         shell: bash\n         working-directory: /transformers\n+        env:\n+          job: ${{ inputs.job }}\n         run: |\n-          cp /transformers/new_failures_with_bad_commit_${{ inputs.job }}/new_failures_with_bad_commit_${{ inputs.job }}_1.json new_failures_with_bad_commit.json\n+          cp \"/transformers/new_failures_with_bad_commit_${job}/new_failures_with_bad_commit_${job}_1.json\" new_failures_with_bad_commit.json\n \n       - name: Update clone\n         working-directory: /transformers\n+        env:\n+          commit_sha: ${{ inputs.commit_sha || github.sha }}\n         run: |\n-          git fetch origin ${{ inputs.commit_sha || github.sha }}\n-          git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n+          git fetch origin \"$commit_sha\" && git checkout \"$commit_sha\"\n \n       - name: Process report\n         shell: bash\n@@ -267,9 +287,12 @@ jobs:\n \n       - name: Prepare Slack report title\n         working-directory: /transformers\n+        env:\n+          ci_event: ${{ inputs.ci_event }}\n+          job: ${{ inputs.job }}\n         run: |\n           pip install slack_sdk\n-          echo \"title=$(python3 -c 'import sys; sys.path.append(\"utils\"); from utils.notification_service import job_to_test_map; ci_event = \"${{ inputs.ci_event }}\"; job = \"${{ inputs.job }}\"; test_name = job_to_test_map[job]; title = f\"New failed tests of {ci_event}\" + \":\" + f\" {test_name}\"; print(title)')\" >> $GITHUB_ENV\n+          echo \"title=$(python3 -c 'import sys; import os; sys.path.append(\"utils\"); from utils.notification_service import job_to_test_map; ci_event = os.environ[\"ci_event\"]; job = os.environ[\"job\"]; test_name = job_to_test_map[job]; title = f\"New failed tests of {ci_event}\" + \":\" + f\" {test_name}\"; print(title)')\" >> $GITHUB_ENV\n \n       - name: Send processed report\n         if: ${{ !endsWith(env.REPORT_TEXT, '{}') }}"
        },
        {
            "sha": "749459ce78254d18a566bf99f893646484aa7910",
            "filename": ".github/workflows/get-pr-info.yml",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fget-pr-info.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fget-pr-info.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fget-pr-info.yml?ref=57bdb4a680b2f82ad739ef741996be04e3764eea",
            "patch": "@@ -153,14 +153,15 @@ jobs:\n \n       - name: Convert dates to timestamps\n         id: get_timestamps\n+        env:\n+          head_commit_date: ${{ steps.pr_info.outputs.head_commit_date }}\n+          merge_commit_date: ${{ steps.pr_info.outputs.merge_commit_date }}\n         run: |\n-          head_commit_date=${{ steps.pr_info.outputs.head_commit_date }}\n-          merge_commit_date=${{ steps.pr_info.outputs.merge_commit_date }}\n-          echo $head_commit_date\n-          echo $merge_commit_date\n+          echo \"$head_commit_date\"\n+          echo \"$merge_commit_date\"\n           head_commit_timestamp=$(date -d \"$head_commit_date\" +%s)\n           merge_commit_timestamp=$(date -d \"$merge_commit_date\" +%s)\n-          echo $head_commit_timestamp\n-          echo $merge_commit_timestamp\n+          echo \"$head_commit_timestamp\"\n+          echo \"$merge_commit_timestamp\"\n           echo \"head_commit_timestamp=$head_commit_timestamp\" >> $GITHUB_OUTPUT\n-          echo \"merge_commit_timestamp=$merge_commit_timestamp\" >> $GITHUB_OUTPUT\n+          echo \"merge_commit_timestamp=$merge_commit_timestamp\" >> $GITHUB_OUTPUT\n\\ No newline at end of file"
        },
        {
            "sha": "f9962925b7e150d49496344a27a81eaab3530676",
            "filename": ".github/workflows/get-pr-number.yml",
            "status": "modified",
            "additions": 14,
            "deletions": 8,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fget-pr-number.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fget-pr-number.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fget-pr-number.yml?ref=57bdb4a680b2f82ad739ef741996be04e3764eea",
            "patch": "@@ -15,22 +15,28 @@ jobs:\n     steps:\n       - name: Get PR number\n         shell: bash\n+        env:\n+          issue_number: ${{ github.event.issue.number }}\n+          is_pull_request_issue: ${{ github.event.issue.pull_request != null }}\n+          pr_number: ${{ github.event.pull_request.number }}\n+          is_pull_request: ${{ github.event.pull_request != null }}\n+          event_number: ${{ github.event.number }}\n         run: |\n-          if [[ \"${{ github.event.issue.number }}\" != \"\" && \"${{ github.event.issue.pull_request }}\" != \"\" ]]; then\n-            echo \"PR_NUMBER=${{ github.event.issue.number }}\" >> $GITHUB_ENV\n-          elif [[ \"${{ github.event.pull_request.number }}\" != \"\" ]]; then\n-            echo \"PR_NUMBER=${{ github.event.pull_request.number }}\" >> $GITHUB_ENV\n-          elif [[ \"${{ github.event.pull_request }}\" != \"\" ]]; then\n-            echo \"PR_NUMBER=${{ github.event.number }}\" >> $GITHUB_ENV\n+          if [[ \"$issue_number\" != \"\" && \"$is_pull_request_issue\" == \"true\" ]]; then\n+            echo \"PR_NUMBER=$issue_number\" >> $GITHUB_ENV\n+          elif [[ \"$pr_number\" != \"\" ]]; then\n+            echo \"PR_NUMBER=$pr_number\" >> $GITHUB_ENV\n+          elif [[ \"$is_pull_request\" == \"true\" ]]; then\n+            echo \"PR_NUMBER=$event_number\" >> $GITHUB_ENV\n           else\n             echo \"PR_NUMBER=\" >> $GITHUB_ENV\n           fi\n \n       - name: Check PR number\n         shell: bash\n         run: |\n-          echo \"${{ env.PR_NUMBER }}\"\n+          echo \"$PR_NUMBER\"\n \n       - name: Set PR number\n         id: set_pr_number\n-        run: echo \"PR_NUMBER=${{ env.PR_NUMBER }}\" >> \"$GITHUB_OUTPUT\"\n+        run: echo \"PR_NUMBER=$PR_NUMBER\" >> \"$GITHUB_OUTPUT\""
        },
        {
            "sha": "8e732e54ec9eca355a5fba4c5be5a6f5b5db7f94",
            "filename": ".github/workflows/model_jobs.yml",
            "status": "modified",
            "additions": 39,
            "deletions": 19,
            "changes": 58,
            "blob_url": "https://github.com/huggingface/transformers/blob/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fmodel_jobs.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fmodel_jobs.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fmodel_jobs.yml?ref=57bdb4a680b2f82ad739ef741996be04e3764eea",
            "patch": "@@ -62,27 +62,33 @@ jobs:\n     steps:\n       - name: Echo input and matrix info\n         shell: bash\n+        env:\n+          folder_slices: ${{ inputs.folder_slices }}\n+          matrix_folders: ${{ matrix.folders }}\n+          slice_data: ${{ toJson(fromJson(inputs.folder_slices)[inputs.slice_id]) }}\n         run: |\n-          echo \"${{ inputs.folder_slices }}\"\n-          echo \"${{ matrix.folders }}\"\n-          echo \"${{ toJson(fromJson(inputs.folder_slices)[inputs.slice_id]) }}\"\n+          echo \"$folder_slices\"\n+          echo \"$matrix_folders\"\n+          echo \"$slice_data\"\n \n       - name: Echo folder ${{ matrix.folders }}\n         shell: bash\n         # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n         # set the artifact folder names (because the character `/` is not allowed).\n+        env:\n+          matrix_folders_raw: ${{ matrix.folders }}\n         run: |\n-          echo \"${{ matrix.folders }}\"\n-          matrix_folders=${{ matrix.folders }}\n-          matrix_folders=${matrix_folders/'models/'/'models_'}\n+          echo \"$matrix_folders_raw\"\n+          matrix_folders=\"${matrix_folders_raw/'models/'/'models_'}\"\n           echo \"$matrix_folders\"\n           echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n \n       - name: Update clone\n         working-directory: /transformers\n+        env:\n+          commit_sha: ${{ inputs.commit_sha || github.sha }}\n         run: |\n-          git fetch origin ${{ inputs.commit_sha || github.sha }}\n-          git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n+          git fetch origin \"$commit_sha\" && git checkout \"$commit_sha\"\n \n       - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n         working-directory: /transformers\n@@ -117,15 +123,17 @@ jobs:\n         id: set_machine_type\n         working-directory: /transformers\n         shell: bash\n+        env:\n+          input_machine_type: ${{ inputs.machine_type }}\n         run: |\n-          echo \"${{ inputs.machine_type }}\"\n+          echo \"$input_machine_type\"\n \n-          if [ \"${{ inputs.machine_type }}\" = \"aws-g5-4xlarge-cache\" ]; then\n+          if [ \"$input_machine_type\" = \"aws-g5-4xlarge-cache\" ]; then\n             machine_type=single-gpu\n-          elif [ \"${{ inputs.machine_type }}\" = \"aws-g5-12xlarge-cache\" ]; then\n+          elif [ \"$input_machine_type\" = \"aws-g5-12xlarge-cache\" ]; then\n             machine_type=multi-gpu\n           else\n-            machine_type=${{ inputs.machine_type }}\n+            machine_type=\"$input_machine_type\"\n           fi\n \n           echo \"$machine_type\"\n@@ -134,15 +142,21 @@ jobs:\n \n       - name: Create report directory if it doesn't exist\n         shell: bash\n+        env:\n+          report_name_prefix: ${{ inputs.report_name_prefix }}\n         run: |\n-          mkdir -p /transformers/reports/${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports\n-          echo \"dummy\" > /transformers/reports/${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports/dummy.txt\n-          ls -la /transformers/reports/${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports\n+          mkdir -p \"/transformers/reports/${machine_type}_${report_name_prefix}_${matrix_folders}_test_reports\"\n+          echo \"dummy\" > \"/transformers/reports/${machine_type}_${report_name_prefix}_${matrix_folders}_test_reports/dummy.txt\"\n+          ls -la \"/transformers/reports/${machine_type}_${report_name_prefix}_${matrix_folders}_test_reports\"\n \n       - name: Run all tests on GPU\n         working-directory: /transformers\n+        env:\n+          report_name_prefix: ${{ inputs.report_name_prefix }}\n+          pytest_marker: ${{ inputs.pytest_marker }}\n+          model: ${{ matrix.folders }}\n         run: |\n-          script -q -c \"PATCH_TESTING_METHODS_TO_COLLECT_OUTPUTS=yes _PATCHED_TESTING_METHODS_OUTPUT_DIR=/transformers/reports/${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports python3 -m pytest -rsfE -v -m '${{ inputs.pytest_marker }}' --make-reports=${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports tests/${{ matrix.folders }}\" test_outputs.txt\n+          script -q -c \"PATCH_TESTING_METHODS_TO_COLLECT_OUTPUTS=yes _PATCHED_TESTING_METHODS_OUTPUT_DIR=/transformers/reports/${machine_type}_${report_name_prefix}_${matrix_folders}_test_reports python3 -m pytest -rsfE -v -m '${pytest_marker}' --make-reports=${machine_type}_${report_name_prefix}_${matrix_folders}_test_reports tests/${model}\" test_outputs.txt\n           ls -la\n           # Extract the exit code from the output file\n           EXIT_CODE=$(tail -1 test_outputs.txt | grep -o 'COMMAND_EXIT_CODE=\"[0-9]*\"' | cut -d'\"' -f2)\n@@ -153,19 +167,25 @@ jobs:\n         # This step is only to show information on Github Actions log.\n         # Always mark this step as successful, even if the report directory or the file `failures_short.txt` in it doesn't exist\n         continue-on-error: true\n-        run: cat /transformers/reports/${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports/failures_short.txt\n+        env:\n+          report_name_prefix: ${{ inputs.report_name_prefix }}\n+        run: cat \"/transformers/reports/${machine_type}_${report_name_prefix}_${matrix_folders}_test_reports/failures_short.txt\"\n \n       - name: Captured information\n         if: ${{ failure() }}\n         continue-on-error: true\n+        env:\n+          report_name_prefix: ${{ inputs.report_name_prefix }}\n         run: |\n-          cat /transformers/reports/${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports/captured_info.txt\n+          cat \"/transformers/reports/${machine_type}_${report_name_prefix}_${matrix_folders}_test_reports/captured_info.txt\"\n \n       - name: Copy test_outputs.txt\n         if: ${{ always() }}\n         continue-on-error: true\n+        env:\n+          report_name_prefix: ${{ inputs.report_name_prefix }}\n         run: |\n-          cp /transformers/test_outputs.txt /transformers/reports/${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports\n+          cp /transformers/test_outputs.txt \"/transformers/reports/${machine_type}_${report_name_prefix}_${matrix_folders}_test_reports\"\n \n       - name: \"Test suite reports artifacts: ${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports\"\n         if: ${{ always() }}"
        },
        {
            "sha": "db4c325be82f684d879e8278aaf7a615594a45d9",
            "filename": ".github/workflows/pr_slow_ci_suggestion.yml",
            "status": "renamed",
            "additions": 17,
            "deletions": 9,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fpr_slow_ci_suggestion.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fpr_slow_ci_suggestion.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fpr_slow_ci_suggestion.yml?ref=57bdb4a680b2f82ad739ef741996be04e3764eea",
            "patch": "@@ -1,4 +1,4 @@\n-name: PR slow CI\n+name: PR slow CI - Suggestion\n on:\n   pull_request_target:\n     types: [opened, synchronize, reopened]\n@@ -59,27 +59,35 @@ jobs:\n           fetch-depth: \"0\"\n \n       - name: Write pr_files file\n+        env:\n+          PR_FILES: ${{ needs.get-pr-info.outputs.PR_FILES }}\n         run: |\n-          cat > pr_files.txt << 'EOF'\n-          ${{ needs.get-pr-info.outputs.PR_FILES }}\n+          cat > pr_files.txt << EOF\n+          $PR_FILES\n           EOF\n \n       - name: Write tests_dir file\n+        env:\n+          tests_dir: ${{ steps.repo_content.outputs.tests_dir }}\n         run: |\n-          cat > tests_dir.txt << 'EOF'\n-          ${{ steps.repo_content.outputs.tests_dir }}\n+          cat > tests_dir.txt << EOF\n+          $tests_dir\n           EOF\n \n       - name: Write tests_models_dir file\n+        env:\n+          tests_models_dir: ${{ steps.repo_content.outputs.tests_models_dir }}\n         run: |\n-          cat > tests_models_dir.txt << 'EOF'\n-          ${{ steps.repo_content.outputs.tests_models_dir }}\n+          cat > tests_models_dir.txt << EOF\n+          $tests_models_dir\n           EOF\n \n       - name: Write tests_quantization_dir file\n+        env:\n+          tests_quantization_dir: ${{ steps.repo_content.outputs.tests_quantization_dir }}\n         run: |\n-          cat > tests_quantization_dir.txt << 'EOF'\n-          ${{ steps.repo_content.outputs.tests_quantization_dir }}\n+          cat > tests_quantization_dir.txt << EOF\n+          $tests_quantization_dir\n           EOF\n \n       - name: Run script to get jobs to run",
            "previous_filename": ".github/workflows/pr_run_slow_ci.yml"
        },
        {
            "sha": "ae31d2956f1e238319657c2951c736828bd86d72",
            "filename": ".github/workflows/self-comment-ci.yml",
            "status": "modified",
            "additions": 33,
            "deletions": 17,
            "changes": 50,
            "blob_url": "https://github.com/huggingface/transformers/blob/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fself-comment-ci.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fself-comment-ci.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-comment-ci.yml?ref=57bdb4a680b2f82ad739ef741996be04e3764eea",
            "patch": "@@ -88,17 +88,17 @@ jobs:\n         run: |\n           python -m pip install GitPython\n           python utils/pr_slow_ci_models.py --message \"$PR_COMMENT\" | tee output.txt\n-          echo 'models=$(tail -n 1 output.txt)' >> $GITHUB_ENV\n+          echo \"models=$(tail -n 1 output.txt)\" >> $GITHUB_ENV\n           python utils/pr_slow_ci_models.py --message \"$PR_COMMENT\" --quantization | tee output2.txt\n-          echo 'quantizations=$(tail -n 1 output2.txt)' >> $GITHUB_ENV\n+          echo \"quantizations=$(tail -n 1 output2.txt)\" >> $GITHUB_ENV\n \n       - name: Show models to test\n         id: models_to_run\n         run: |\n-          echo \"${{ env.models }}\"\n-          echo \"models=${{ env.models }}\" >> $GITHUB_OUTPUT\n-          echo \"${{ env.quantizations }}\"\n-          echo \"quantizations=${{ env.quantizations }}\" >> $GITHUB_OUTPUT\n+          echo \"$models\"\n+          echo \"models=$models\" >> $GITHUB_OUTPUT\n+          echo \"$quantizations\"\n+          echo \"quantizations=$quantizations\" >> $GITHUB_OUTPUT\n \n   # Report back if we are not able to get the tests (for example, security check is failing)\n   report_error_earlier:\n@@ -113,12 +113,14 @@ jobs:\n         env:\n           GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n           GITHUB_RUN_URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\n+          github_repository: ${{ github.repository }}\n+          pr_number: ${{ needs.get-pr-number.outputs.PR_NUMBER }}\n         run: |\n           gh api \\\n             --method POST \\\n             -H \"Accept: application/vnd.github+json\" \\\n             -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n-            repos/${{ github.repository }}/issues/${{ needs.get-pr-number.outputs.PR_NUMBER }}/comments \\\n+            \"repos/${github_repository}/issues/${pr_number}/comments\" \\\n             -f body=\"ðŸ’” This comment contains \\`run-slow\\`, but unknown error occurred and [the workflow run]($GITHUB_RUN_URL) aborted!\"\n \n   reply_to_comment:\n@@ -133,13 +135,15 @@ jobs:\n         env:\n           GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n           BODY: '\\n\\nmodels: ${{ needs.get-tests.outputs.models }}\\nquantizations: ${{ needs.get-tests.outputs.quantizations }}'\n+          github_repository: ${{ github.repository }}\n+          pr_number: ${{ needs.get-pr-number.outputs.PR_NUMBER }}\n         run: |\n           gh api \\\n             --method POST \\\n             -H \"Accept: application/vnd.github+json\" \\\n             -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n-            repos/${{ github.repository }}/issues/${{ needs.get-pr-number.outputs.PR_NUMBER }}/comments \\\n-            -f body=\"This comment contains \\`run-slow\\`, running the specified jobs: $(echo -e '${{ env.BODY }}')\"\n+            \"repos/${github_repository}/issues/${pr_number}/comments\" \\\n+            -f body=\"This comment contains \\`run-slow\\`, running the specified jobs: $(echo -e \"$BODY\")\"\n \n   create_run:\n     name: Create run\n@@ -155,12 +159,14 @@ jobs:\n           # Create a commit status (pending) for a run of this workflow. The status has to be updated later in `update_run_status`.\n           # See https://docs.github.com/en/rest/commits/statuses?apiVersion=2022-11-28#create-a-commit-status\n           GITHUB_RUN_URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\n+          github_repository: ${{ github.repository }}\n+          pr_head_sha: ${{ needs.check-timestamps.outputs.PR_HEAD_SHA }}\n         run: |\n           gh api \\\n             --method POST \\\n             -H \"Accept: application/vnd.github+json\" \\\n             -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n-            repos/${{ github.repository }}/statuses/${{ needs.check-timestamps.outputs.PR_HEAD_SHA }} \\\n+            \"repos/${github_repository}/statuses/${pr_head_sha}\" \\\n             -f \"target_url=$GITHUB_RUN_URL\" -f \"state=pending\" -f \"description=Slow CI job\" -f \"context=pytest/custom-tests\"\n \n   model-ci:\n@@ -205,9 +211,12 @@ jobs:\n     runs-on: ubuntu-22.04\n     steps:\n       - name: Show reports from jobs\n+        env:\n+          MODEL_REPORT: ${{ needs.model-ci.outputs.report }}\n+          QUANT_REPORT: ${{ needs.quantization-ci.outputs.report }}\n         run: |\n-          echo \"${{ needs.model-ci.outputs.report }}\"\n-          echo \"${{ needs.quantization-ci.outputs.report }}\"\n+          echo \"$MODEL_REPORT\"\n+          echo \"$QUANT_REPORT\"\n \n       - name: Process and filter reports\n         env:\n@@ -277,15 +286,19 @@ jobs:\n         env:\n           GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n           GITHUB_RUN_URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\n+          github_repository: ${{ github.repository }}\n+          pr_number: ${{ needs.get-pr-number.outputs.PR_NUMBER }}\n+          model_ci_result: ${{ needs.model-ci.result }}\n+          quantization_ci_result: ${{ needs.quantization-ci.result }}\n         run: |\n           {\n             echo '## CI Results'\n             echo \"[Workflow Run âš™ï¸]($GITHUB_RUN_URL)\"\n             echo ''\n \n             # Check if both jobs were skipped or cancelled\n-            if [[ \"${{ needs.model-ci.result }}\" == \"skipped\" || \"${{ needs.model-ci.result }}\" == \"cancelled\" ]] && \\\n-               [[ \"${{ needs.quantization-ci.result }}\" == \"skipped\" || \"${{ needs.quantization-ci.result }}\" == \"cancelled\" ]]; then\n+            if [[ \"$model_ci_result\" == \"skipped\" || \"$model_ci_result\" == \"cancelled\" ]] && \\\n+               [[ \"$quantization_ci_result\" == \"skipped\" || \"$quantization_ci_result\" == \"cancelled\" ]]; then\n               echo 'âš ï¸ No test being reported (jobs are skipped or cancelled)!'\n               echo \"STATUS=error\" >> $GITHUB_ENV\n \n@@ -322,17 +335,20 @@ jobs:\n             --method POST \\\n             -H \"Accept: application/vnd.github+json\" \\\n             -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n-            repos/${{ github.repository }}/issues/${{ needs.get-pr-number.outputs.PR_NUMBER }}/comments \\\n+            \"repos/${github_repository}/issues/${pr_number}/comments\" \\\n             -F body=@comment_body.txt\n \n       - name: Update PR commit statuses\n         env:\n           GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n           GITHUB_RUN_URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\n+          github_repository: ${{ github.repository }}\n+          pr_head_sha: ${{ needs.check-timestamps.outputs.PR_HEAD_SHA }}\n+        # The env. variable `STATUS` used here is set in the previous step\n         run: |\n           gh api \\\n             --method POST \\\n             -H \"Accept: application/vnd.github+json\" \\\n             -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n-            repos/${{ github.repository }}/statuses/${{ needs.check-timestamps.outputs.PR_HEAD_SHA }} \\\n-            -f \"target_url=$GITHUB_RUN_URL\" -f \"state=${{ env.STATUS }}\" -f \"description=Slow CI job\" -f \"context=pytest/custom-tests\"\n+            \"repos/${github_repository}/statuses/${pr_head_sha}\" \\\n+            -f \"target_url=$GITHUB_RUN_URL\" -f \"state=$STATUS\" -f \"description=Slow CI job\" -f \"context=pytest/custom-tests\""
        },
        {
            "sha": "4d1bb593a4fedb06caba04877f32a3c667df170e",
            "filename": ".github/workflows/self-scheduled-caller.yml",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fself-scheduled-caller.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fself-scheduled-caller.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-scheduled-caller.yml?ref=57bdb4a680b2f82ad739ef741996be04e3764eea",
            "patch": "@@ -33,10 +33,13 @@ jobs:\n     runs-on: ubuntu-22.04\n     steps:\n       - name: Setup\n+        env:\n+          prev_workflow_run_id: ${{ inputs.prev_workflow_run_id || env.prev_workflow_run_id }}\n+          other_workflow_run_id: ${{ inputs.other_workflow_run_id || env.other_workflow_run_id }}\n         run: |\n           mkdir \"setup_values\"\n-          echo \"${{ inputs.prev_workflow_run_id || env.prev_workflow_run_id }}\" > \"setup_values/prev_workflow_run_id.txt\"\n-          echo \"${{ inputs.other_workflow_run_id || env.other_workflow_run_id }}\" > \"setup_values/other_workflow_run_id.txt\"\n+          echo \"$prev_workflow_run_id\" > \"setup_values/prev_workflow_run_id.txt\"\n+          echo \"$other_workflow_run_id\" > \"setup_values/other_workflow_run_id.txt\"\n \n       - name: Upload artifacts\n         uses: actions/upload-artifact@v4"
        },
        {
            "sha": "ff14e6fdb8f78ae8f8b347fdddfa92ad69a6f350",
            "filename": ".github/workflows/self-scheduled.yml",
            "status": "modified",
            "additions": 87,
            "deletions": 46,
            "changes": 133,
            "blob_url": "https://github.com/huggingface/transformers/blob/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fself-scheduled.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fself-scheduled.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-scheduled.yml?ref=57bdb4a680b2f82ad739ef741996be04e3764eea",
            "patch": "@@ -60,7 +60,6 @@ env:\n   HF_HUB_READ_TOKEN: ${{ secrets.HF_HUB_READ_TOKEN }}\n   TF_FORCE_GPU_ALLOW_GROWTH: true\n   CUDA_VISIBLE_DEVICES: 0,1\n-  NUM_SLICES: 2\n \n jobs:\n   setup:\n@@ -81,9 +80,11 @@ jobs:\n     steps:\n       - name: Update clone\n         working-directory: /transformers\n+        env:\n+          commit_sha: ${{ inputs.commit_sha || github.sha }}\n         run: |\n-          git fetch origin ${{ inputs.commit_sha || github.sha }}\n-          git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n+          git fetch origin $commit_sha\n+          git fetch && git checkout $commit_sha\n \n       - name: Cleanup\n         working-directory: /transformers\n@@ -100,13 +101,17 @@ jobs:\n         if: contains(fromJSON('[\"run_models_gpu\", \"run_trainer_and_fsdp_gpu\"]'), inputs.job)\n         name: Identify models to test\n         working-directory: /transformers/tests\n+        env:\n+          job: ${{ inputs.job }}\n+          subdirs: ${{ inputs.subdirs }}\n+          NUM_SLICES: 2\n         run: |\n-          if [ \"${{ inputs.job }}\" = \"run_models_gpu\" ]; then\n-            python3 ../utils/split_model_tests.py --subdirs '${{ inputs.subdirs }}' --num_splits ${{ env.NUM_SLICES }} > folder_slices.txt\n+          if [ \"$job\" = \"run_models_gpu\" ]; then\n+            python3 ../utils/split_model_tests.py --subdirs \"$subdirs\" --num_splits \"$NUM_SLICES\" > folder_slices.txt\n             echo \"folder_slices=$(cat folder_slices.txt)\" >> $GITHUB_OUTPUT\n             python3 -c \"import ast; folder_slices = ast.literal_eval(open('folder_slices.txt').read()); open('slice_ids.txt', 'w').write(str(list(range(len(folder_slices)))))\"\n             echo \"slice_ids=$(cat slice_ids.txt)\" >> $GITHUB_OUTPUT\n-          elif [ \"${{ inputs.job }}\" = \"run_trainer_and_fsdp_gpu\" ]; then\n+          elif [ \"$job\" = \"run_trainer_and_fsdp_gpu\" ]; then\n             echo \"folder_slices=[['trainer'], ['fsdp']]\" >> $GITHUB_OUTPUT\n             echo \"slice_ids=[0, 1]\" >> $GITHUB_OUTPUT\n           fi\n@@ -115,8 +120,10 @@ jobs:\n         if: ${{ inputs.job == 'run_quantization_torch_gpu' }}\n         name: Identify quantization method to test\n         working-directory: /transformers/tests\n+        env:\n+          subdirs: ${{ inputs.subdirs || 'None' }}\n         run: |\n-          echo \"quantization_matrix=$(python3 -c 'import ast; import os; tests = os.getcwd(); quantization_tests = os.listdir(os.path.join(tests, \"quantization\")); subdirs = ast.literal_eval(${{ inputs.subdirs || '\"None\"' }}); quantization_tests = [x.removeprefix(\"quantization/\") for x in subdirs] if subdirs is not None else quantization_tests; d = sorted(list(filter(os.path.isdir, [f\"quantization/{x}\" for x in quantization_tests]))) ;  print(d)')\" >> $GITHUB_OUTPUT\n+          echo \"quantization_matrix=$(python3 -c 'import ast; import os; tests = os.getcwd(); quantization_tests = os.listdir(os.path.join(tests, \"quantization\")); subdirs = ast.literal_eval(os.environ[\"subdirs\"]); quantization_tests = [x.removeprefix(\"quantization/\") for x in subdirs] if subdirs is not None else quantization_tests; d = sorted(list(filter(os.path.isdir, [f\"quantization/{x}\" for x in quantization_tests]))); print(d)')\" >> $GITHUB_OUTPUT\n \n       - name: NVIDIA-SMI\n         run: |\n@@ -179,7 +186,9 @@ jobs:\n     steps:\n       - name: Update clone\n         working-directory: /transformers\n-        run: git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n+        env:\n+          commit_sha: ${{ inputs.commit_sha || github.sha }}\n+        run: git fetch && git checkout \"$commit_sha\"\n \n       - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n         working-directory: /transformers\n@@ -201,15 +210,17 @@ jobs:\n       - name: Set `machine_type` for report and artifact names\n         working-directory: /transformers\n         shell: bash\n+        env:\n+          matrix_machine_type: ${{ matrix.machine_type }}\n         run: |\n-          echo \"${{ matrix.machine_type }}\"\n+          echo \"$matrix_machine_type\"\n \n-          if [ \"${{ matrix.machine_type }}\" = \"aws-g5-4xlarge-cache\" ]; then\n+          if [ \"$matrix_machine_type\" = \"aws-g5-4xlarge-cache\" ]; then\n             machine_type=single-gpu\n-          elif [ \"${{ matrix.machine_type }}\" = \"aws-g5-12xlarge-cache\" ]; then\n+          elif [ \"$matrix_machine_type\" = \"aws-g5-12xlarge-cache\" ]; then\n             machine_type=multi-gpu\n           else\n-            machine_type=${{ matrix.machine_type }}\n+            machine_type=\"$matrix_machine_type\"\n           fi\n \n           echo \"$machine_type\"\n@@ -218,12 +229,12 @@ jobs:\n       - name: Run all pipeline tests on GPU\n         working-directory: /transformers\n         run: |\n-          python3 -m pytest -n 1 -v --dist=loadfile --make-reports=${{ env.machine_type }}_run_pipelines_torch_gpu_test_reports tests/pipelines\n+          python3 -m pytest -n 1 -v --dist=loadfile --make-reports=\"${machine_type}_run_pipelines_torch_gpu_test_reports\" tests/pipelines\n \n       - name: Failure short reports\n         if: ${{ failure() }}\n         continue-on-error: true\n-        run: cat /transformers/reports/${{ env.machine_type }}_run_pipelines_torch_gpu_test_reports/failures_short.txt\n+        run: cat \"/transformers/reports/${machine_type}_run_pipelines_torch_gpu_test_reports/failures_short.txt\"\n \n       - name: \"Test suite reports artifacts: ${{ env.machine_type }}_run_pipelines_torch_gpu_test_reports\"\n         if: ${{ always() }}\n@@ -247,7 +258,9 @@ jobs:\n     steps:\n       - name: Update clone\n         working-directory: /transformers\n-        run: git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n+        env:\n+          commit_sha: ${{ inputs.commit_sha || github.sha }}\n+        run: git fetch && git checkout \"$commit_sha\"\n \n       - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n         working-directory: /transformers\n@@ -269,15 +282,17 @@ jobs:\n       - name: Set `machine_type` for report and artifact names\n         working-directory: /transformers\n         shell: bash\n+        env:\n+          matrix_machine_type: ${{ matrix.machine_type }}\n         run: |\n-          echo \"${{ matrix.machine_type }}\"\n+          echo \"$matrix_machine_type\"\n \n-          if [ \"${{ matrix.machine_type }}\" = \"aws-g5-4xlarge-cache\" ]; then\n+          if [ \"$matrix_machine_type\" = \"aws-g5-4xlarge-cache\" ]; then\n             machine_type=single-gpu\n-          elif [ \"${{ matrix.machine_type }}\" = \"aws-g5-12xlarge-cache\" ]; then\n+          elif [ \"$matrix_machine_type\" = \"aws-g5-12xlarge-cache\" ]; then\n             machine_type=multi-gpu\n           else\n-            machine_type=${{ matrix.machine_type }}\n+            machine_type=\"$matrix_machine_type\"\n           fi\n \n           echo \"$machine_type\"\n@@ -287,12 +302,12 @@ jobs:\n         working-directory: /transformers\n         run: |\n           pip install -r examples/pytorch/_tests_requirements.txt\n-          python3 -m pytest -v --make-reports=${{ env.machine_type }}_run_examples_gpu_test_reports examples/pytorch\n+          python3 -m pytest -v --make-reports=\"${machine_type}_run_examples_gpu_test_reports\" examples/pytorch\n \n       - name: Failure short reports\n         if: ${{ failure() }}\n         continue-on-error: true\n-        run: cat /transformers/reports/${{ env.machine_type }}_run_examples_gpu_test_reports/failures_short.txt\n+        run: cat \"/transformers/reports/${machine_type}_run_examples_gpu_test_reports/failures_short.txt\"\n \n       - name: \"Test suite reports artifacts: ${{ env.machine_type }}_run_examples_gpu_test_reports\"\n         if: ${{ always() }}\n@@ -316,7 +331,9 @@ jobs:\n     steps:\n       - name: Update clone\n         working-directory: ${{ inputs.working-directory-prefix }}/transformers\n-        run: git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n+        env:\n+          commit_sha: ${{ inputs.commit_sha || github.sha }}\n+        run: git fetch && git checkout \"$commit_sha\"\n \n       - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n         working-directory: ${{ inputs.working-directory-prefix }}/transformers\n@@ -366,15 +383,17 @@ jobs:\n       - name: Set `machine_type` for report and artifact names\n         working-directory: ${{ inputs.working-directory-prefix }}/transformers\n         shell: bash\n+        env:\n+          matrix_machine_type: ${{ matrix.machine_type }}\n         run: |\n-          echo \"${{ matrix.machine_type }}\"\n+          echo \"$matrix_machine_type\"\n \n-          if [ \"${{ matrix.machine_type }}\" = \"aws-g5-4xlarge-cache\" ]; then\n+          if [ \"$matrix_machine_type\" = \"aws-g5-4xlarge-cache\" ]; then\n             machine_type=single-gpu\n-          elif [ \"${{ matrix.machine_type }}\" = \"aws-g5-12xlarge-cache\" ]; then\n+          elif [ \"$matrix_machine_type\" = \"aws-g5-12xlarge-cache\" ]; then\n             machine_type=multi-gpu\n           else\n-            machine_type=${{ matrix.machine_type }}\n+            machine_type=\"$matrix_machine_type\"\n           fi\n \n           echo \"$machine_type\"\n@@ -383,12 +402,14 @@ jobs:\n       - name: Run all tests on GPU\n         working-directory: ${{ inputs.working-directory-prefix }}/transformers\n         run: |\n-          python3 -m pytest -v --make-reports=${{ env.machine_type }}_run_torch_cuda_extensions_gpu_test_reports tests/deepspeed tests/extended\n+          python3 -m pytest -v --make-reports=\"${machine_type}_run_torch_cuda_extensions_gpu_test_reports\" tests/deepspeed tests/extended\n \n       - name: Failure short reports\n         if: ${{ failure() }}\n         continue-on-error: true\n-        run: cat ${{ inputs.working-directory-prefix }}/transformers/reports/${{ env.machine_type }}_run_torch_cuda_extensions_gpu_test_reports/failures_short.txt\n+        env:\n+          working_directory_prefix: ${{ inputs.working-directory-prefix }}\n+        run: cat \"${working_directory_prefix}/transformers/reports/${machine_type}_run_torch_cuda_extensions_gpu_test_reports/failures_short.txt\"\n \n       - name: \"Test suite reports artifacts: ${{ env.machine_type }}_run_torch_cuda_extensions_gpu_test_reports\"\n         if: ${{ always() }}\n@@ -415,16 +436,19 @@ jobs:\n     steps:\n       - name: Echo folder ${{ matrix.folders }}\n         shell: bash\n+        env:\n+          matrix_folders_raw: ${{ matrix.folders }}\n         run: |\n-          echo \"${{ matrix.folders }}\"\n-          matrix_folders=${{ matrix.folders }}\n-          matrix_folders=${matrix_folders/'quantization/'/'quantization_'}\n+          echo \"$matrix_folders_raw\"\n+          matrix_folders=\"${matrix_folders_raw/'quantization/'/'quantization_'}\"\n           echo \"$matrix_folders\"\n           echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n \n       - name: Update clone\n         working-directory: /transformers\n-        run: git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n+        env:\n+          commit_sha: ${{ inputs.commit_sha || github.sha }}\n+        run: git fetch && git checkout \"$commit_sha\"\n \n       - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n         working-directory: /transformers\n@@ -446,36 +470,40 @@ jobs:\n       - name: Set `machine_type` for report and artifact names\n         working-directory: /transformers\n         shell: bash\n+        env:\n+          matrix_machine_type: ${{ matrix.machine_type }}\n         run: |\n-          echo \"${{ matrix.machine_type }}\"\n+          echo \"$matrix_machine_type\"\n \n-          if [ \"${{ matrix.machine_type }}\" = \"aws-g5-4xlarge-cache\" ]; then\n+          if [ \"$matrix_machine_type\" = \"aws-g5-4xlarge-cache\" ]; then\n             machine_type=single-gpu\n-          elif [ \"${{ matrix.machine_type }}\" = \"aws-g5-12xlarge-cache\" ]; then\n+          elif [ \"$matrix_machine_type\" = \"aws-g5-12xlarge-cache\" ]; then\n             machine_type=multi-gpu\n           else\n-            machine_type=${{ matrix.machine_type }}\n+            machine_type=\"$matrix_machine_type\"\n           fi\n \n           echo \"$machine_type\"\n           echo \"machine_type=$machine_type\" >> $GITHUB_ENV\n \n       - name: Run quantization tests on GPU\n         working-directory: /transformers\n+        env:\n+          folders: ${{ matrix.folders }}\n         run: |\n-          python3 -m pytest -v --make-reports=${{ env.machine_type }}_run_quantization_torch_gpu_${{ matrix.folders }}_test_reports tests/${{ matrix.folders }}\n+          python3 -m pytest -v --make-reports=\"${machine_type}_run_quantization_torch_gpu_${matrix_folders}_test_reports\" tests/${folders}\n \n       - name: Failure short reports\n         if: ${{ failure() }}\n         continue-on-error: true\n-        run: cat /transformers/reports/${{ env.machine_type }}_run_quantization_torch_gpu_${{ matrix.folders }}_test_reports/failures_short.txt\n+        run: cat \"/transformers/reports/${machine_type}_run_quantization_torch_gpu_${matrix_folders}_test_reports/failures_short.txt\"\n \n       - name: \"Test suite reports artifacts: ${{ env.machine_type }}_run_quantization_torch_gpu_${{ env.matrix_folders }}_test_reports\"\n         if: ${{ always() }}\n         uses: actions/upload-artifact@v4\n         with:\n           name: ${{ env.machine_type }}_run_quantization_torch_gpu_${{ env.matrix_folders }}_test_reports\n-          path: /transformers/reports/${{ env.machine_type }}_run_quantization_torch_gpu_${{ matrix.folders }}_test_reports\n+          path: /transformers/reports/${{ env.machine_type }}_run_quantization_torch_gpu_${{ env.matrix_folders }}_test_reports\n \n   run_kernels_gpu:\n     if: ${{ inputs.job == 'run_kernels_gpu' }}\n@@ -492,7 +520,9 @@ jobs:\n     steps:\n       - name: Update clone\n         working-directory: /transformers\n-        run: git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n+        env:\n+          commit_sha: ${{ inputs.commit_sha || github.sha }}\n+        run: git fetch && git checkout \"$commit_sha\"\n \n       - name: Reinstall transformers in edit mode\n         working-directory: /transformers\n@@ -516,23 +546,31 @@ jobs:\n       - name: Set `machine_type` for report and artifact names\n         working-directory: /transformers\n         shell: bash\n+        env:\n+          matrix_machine_type: ${{ matrix.machine_type }}\n         run: |\n-          if [ \"${{ matrix.machine_type }}\" = \"aws-g5-4xlarge-cache\" ]; then\n+          echo \"$matrix_machine_type\"\n+\n+          if [ \"$matrix_machine_type\" = \"aws-g5-4xlarge-cache\" ]; then\n             machine_type=single-gpu\n+          elif [ \"$matrix_machine_type\" = \"aws-g5-12xlarge-cache\" ]; then\n+            machine_type=multi-gpu\n           else\n-            machine_type=${{ matrix.machine_type }}\n+            machine_type=\"$matrix_machine_type\"\n           fi\n+\n+          echo \"$machine_type\"\n           echo \"machine_type=$machine_type\" >> $GITHUB_ENV\n     \n       - name: Run kernel tests on GPU\n         working-directory: /transformers\n         run: |\n-          python3 -m pytest -v --make-reports=${{ env.machine_type }}_run_kernels_gpu_test_reports tests/kernels/test_kernels.py\n+          python3 -m pytest -v --make-reports=\"${machine_type}_run_kernels_gpu_test_reports\" tests/kernels/test_kernels.py\n \n       - name: Failure short reports\n         if: ${{ failure() }}\n         continue-on-error: true\n-        run: cat /transformers/reports/${{ env.machine_type }}_run_kernels_gpu_test_reports/failures_short.txt\n+        run: cat \"/transformers/reports/${machine_type}_run_kernels_gpu_test_reports/failures_short.txt\"\n \n       - name: \"Test suite reports artifacts: ${{ env.machine_type }}_run_kernels_gpu_test_reports\"\n         if: ${{ always() }}\n@@ -572,9 +610,12 @@ jobs:\n         working-directory: warnings_in_ci\n \n       - name: Extract warnings in CI artifacts\n+        env:\n+          github_run_id: ${{ github.run_id }}\n+          access_token: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n         run: |\n-          python3 utils/extract_warnings.py --workflow_run_id ${{ github.run_id }} --output_dir warnings_in_ci --token ${{ secrets.ACCESS_REPO_INFO_TOKEN }} --from_gh\n-          echo \"$(python3 -c 'import os; import json; fp = open(\"warnings_in_ci/selected_warnings.json\"); d = json.load(fp); d = \"\\n\".join(d) ;print(d)')\"\n+          python3 utils/extract_warnings.py --workflow_run_id \"$github_run_id\" --output_dir warnings_in_ci --token \"$access_token\" --from_gh\n+          echo \"$(python3 -c 'import os; import json; fp = open(\"warnings_in_ci/selected_warnings.json\"); d = json.load(fp); d = \"\\n\".join(d); print(d)')\"\n \n       - name: Upload artifact\n         if: ${{ always() }}"
        },
        {
            "sha": "3596020fd9cab664360129bd881d746aeef6b67b",
            "filename": ".github/workflows/slack-report.yml",
            "status": "modified",
            "additions": 8,
            "deletions": 4,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fslack-report.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fslack-report.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fslack-report.yml?ref=57bdb4a680b2f82ad739ef741996be04e3764eea",
            "patch": "@@ -41,8 +41,10 @@ jobs:\n       - name: Preliminary job status\n         shell: bash\n         # For the meaning of these environment variables, see the job `Setup`\n+        env:\n+          setup_status: ${{ inputs.setup_status }}\n         run: |\n-          echo \"Setup status: ${{ inputs.setup_status }}\"\n+          echo \"Setup status: $setup_status\"\n \n       - uses: actions/checkout@v4\n         with:\n@@ -81,6 +83,8 @@ jobs:\n           CI_TEST_JOB: ${{ inputs.job }}\n           SETUP_STATUS: ${{ inputs.setup_status }}\n           REPORT_REPO_ID: ${{ inputs.report_repo_id }}\n+          quantization_matrix: ${{ inputs.quantization_matrix }}\n+          folder_slices: ${{ inputs.folder_slices }}\n         # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n         # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n         # For a job that doesn't depend on (i.e. `needs`) `setup`, the value for `inputs.folder_slices` would be an\n@@ -89,10 +93,10 @@ jobs:\n           pip install huggingface_hub\n           pip install slack_sdk\n           pip show slack_sdk\n-          if [ \"${{ inputs.quantization_matrix }}\" != \"\" ]; then\n-            python utils/notification_service.py \"${{ inputs.quantization_matrix }}\"\n+          if [ \"$quantization_matrix\" != \"\" ]; then\n+            python utils/notification_service.py \"$quantization_matrix\"\n           else\n-            python utils/notification_service.py \"${{ inputs.folder_slices }}\"\n+            python utils/notification_service.py \"$folder_slices\"\n           fi\n \n       # Upload complete failure tables, as they might be big and only truncated versions could be sent to Slack."
        },
        {
            "sha": "c109370a178cad4b4ace2258bb65c970c53f76cb",
            "filename": ".github/workflows/ssh-runner.yml",
            "status": "modified",
            "additions": 12,
            "deletions": 7,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fssh-runner.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/57bdb4a680b2f82ad739ef741996be04e3764eea/.github%2Fworkflows%2Fssh-runner.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fssh-runner.yml?ref=57bdb4a680b2f82ad739ef741996be04e3764eea",
            "patch": "@@ -47,8 +47,8 @@ jobs:\n       - name: Set runner to use\n         id: set_runner\n         run: |\n-          echo ${{ env.RUNNER }}\n-          echo \"RUNNER=${{ env.RUNNER }}\" >> $GITHUB_OUTPUT\n+          echo \"$RUNNER\"\n+          echo \"RUNNER=$RUNNER\" >> $GITHUB_OUTPUT\n \n   ssh_runner:\n     name: \"SSH\"\n@@ -60,8 +60,10 @@ jobs:\n     steps:\n       - name: Update clone\n         working-directory: /transformers\n+        env:\n+          commit_sha: ${{ github.sha }}\n         run: |\n-          git fetch && git checkout ${{ github.sha }}\n+          git fetch && git checkout \"$commit_sha\"\n \n       - name: Cleanup\n         working-directory: /transformers\n@@ -93,12 +95,15 @@ jobs:\n       - name: Store Slack infos\n         #because the SSH can be enabled dynamically if the workflow failed, so we need to store slack infos to be able to retrieve them during the waitforssh step\n         shell: bash\n+        env:\n+          user_slack_id: ${{ secrets[format('{0}_{1}', env.github_actor, 'SLACK_ID')] }}\n+          default_slack_channel: ${{ secrets.SLACK_CIFEEDBACK_CHANNEL }}\n         run: |\n-          echo \"${{ env.github_actor }}\"\n-          if [ \"${{ secrets[format('{0}_{1}', env.github_actor, 'SLACK_ID')] }}\" != \"\" ]; then\n-            echo \"SLACKCHANNEL=${{ secrets[format('{0}_{1}', env.github_actor, 'SLACK_ID')] }}\" >> $GITHUB_ENV\n+          echo \"$github_actor\"\n+          if [ \"$user_slack_id\" != \"\" ]; then\n+            echo \"SLACKCHANNEL=$user_slack_id\" >> $GITHUB_ENV\n           else\n-            echo \"SLACKCHANNEL=${{ secrets.SLACK_CIFEEDBACK_CHANNEL }}\" >> $GITHUB_ENV\n+            echo \"SLACKCHANNEL=$default_slack_channel\" >> $GITHUB_ENV\n           fi\n         \n       - name: Tailscale # In order to be able to SSH when a test fails"
        }
    ],
    "stats": {
        "total": 397,
        "additions": 262,
        "deletions": 135
    }
}