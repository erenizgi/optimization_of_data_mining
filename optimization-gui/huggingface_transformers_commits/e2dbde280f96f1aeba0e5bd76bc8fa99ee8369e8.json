{
    "author": "Cyrilvallez",
    "message": "Remove [[autodoc]] refs to TF/Flax objects (#40996)\n\n* remove refs\n\n* more",
    "sha": "e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
    "files": [
        {
            "sha": "eb88a63b3e4281eb4a0187835007c4b06532db02",
            "filename": "docs/source/ja/internal/generation_utils.md",
            "status": "modified",
            "additions": 0,
            "deletions": 117,
            "changes": 117,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Finternal%2Fgeneration_utils.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Finternal%2Fgeneration_utils.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Finternal%2Fgeneration_utils.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -75,36 +75,6 @@ generation_output[:2]\n \n [[autodoc]] generation.GenerateBeamEncoderDecoderOutput\n \n-### TensorFlow\n-\n-[[autodoc]] generation.TFGreedySearchEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFGreedySearchDecoderOnlyOutput\n-\n-[[autodoc]] generation.TFSampleEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFSampleDecoderOnlyOutput\n-\n-[[autodoc]] generation.TFBeamSearchEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFBeamSearchDecoderOnlyOutput\n-\n-[[autodoc]] generation.TFBeamSampleEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFBeamSampleDecoderOnlyOutput\n-\n-[[autodoc]] generation.TFContrastiveSearchEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFContrastiveSearchDecoderOnlyOutput\n-\n-### FLAX\n-\n-[[autodoc]] generation.FlaxSampleOutput\n-\n-[[autodoc]] generation.FlaxGreedySearchOutput\n-\n-[[autodoc]] generation.FlaxBeamSearchOutput\n-\n ## LogitsProcessor\n \n [`LogitsProcessor`] を使用して、言語モデルのヘッドの予測スコアを変更できます。\n@@ -196,93 +166,6 @@ generation_output[:2]\n [[autodoc]] WhisperTimeStampLogitsProcessor\n     - __call__\n \n-### TensorFlow\n-\n-[[autodoc]] TFForcedBOSTokenLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFForcedEOSTokenLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFForceTokensLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFLogitsProcessorList\n-    - __call__\n-\n-[[autodoc]] TFLogitsWarper\n-    - __call__\n-\n-[[autodoc]] TFMinLengthLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFNoBadWordsLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFNoRepeatNGramLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFRepetitionPenaltyLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFSuppressTokensAtBeginLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFSuppressTokensLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFTemperatureLogitsWarper\n-    - __call__\n-\n-[[autodoc]] TFTopKLogitsWarper\n-    - __call__\n-\n-[[autodoc]] TFTopPLogitsWarper\n-    - __call__\n-\n-### FLAX\n-\n-[[autodoc]] FlaxForcedBOSTokenLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxForcedEOSTokenLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxForceTokensLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxLogitsProcessorList\n-    - __call__\n-\n-[[autodoc]] FlaxLogitsWarper\n-    - __call__\n-\n-[[autodoc]] FlaxMinLengthLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxSuppressTokensAtBeginLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxSuppressTokensLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxTemperatureLogitsWarper\n-    - __call__\n-\n-[[autodoc]] FlaxTopKLogitsWarper\n-    - __call__\n-\n-[[autodoc]] FlaxTopPLogitsWarper\n-    - __call__\n-\n-[[autodoc]] FlaxWhisperTimeStampLogitsProcessor\n-    - __call__\n \n ## StoppingCriteria\n "
        },
        {
            "sha": "7e906e87d7f9a0cae77a2072d5d75ed3fd2d22af",
            "filename": "docs/source/ja/internal/modeling_utils.md",
            "status": "modified",
            "additions": 0,
            "deletions": 27,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Finternal%2Fmodeling_utils.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Finternal%2Fmodeling_utils.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Finternal%2Fmodeling_utils.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -37,30 +37,3 @@ rendered properly in your Markdown viewer.\n \n [[autodoc]] pytorch_utils.prune_linear_layer\n \n-## TensorFlow custom layers\n-\n-[[autodoc]] modeling_tf_utils.TFConv1D\n-\n-[[autodoc]] modeling_tf_utils.TFSequenceSummary\n-\n-## TensorFlow loss functions\n-\n-[[autodoc]] modeling_tf_utils.TFCausalLanguageModelingLoss\n-\n-[[autodoc]] modeling_tf_utils.TFMaskedLanguageModelingLoss\n-\n-[[autodoc]] modeling_tf_utils.TFMultipleChoiceLoss\n-\n-[[autodoc]] modeling_tf_utils.TFQuestionAnsweringLoss\n-\n-[[autodoc]] modeling_tf_utils.TFSequenceClassificationLoss\n-\n-[[autodoc]] modeling_tf_utils.TFTokenClassificationLoss\n-\n-## TensorFlow Helper Functions\n-\n-[[autodoc]] modeling_tf_utils.get_initializer\n-\n-[[autodoc]] modeling_tf_utils.keras_serializable\n-\n-[[autodoc]] modeling_tf_utils.shape_list"
        },
        {
            "sha": "21b3b077782371f7232fa9bad2a96260ceab645c",
            "filename": "docs/source/ja/main_classes/model.md",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmain_classes%2Fmodel.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmain_classes%2Fmodel.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmain_classes%2Fmodel.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -124,22 +124,6 @@ Pytorch の設計により、この機能は浮動小数点 dtype でのみ使\n \n [[autodoc]] modeling_utils.ModuleUtilsMixin\n \n-## TFPreTrainedModel\n-\n-[[autodoc]] TFPreTrainedModel\n-    - push_to_hub\n-    - all\n-\n-## TFModelUtilsMixin\n-\n-[[autodoc]] modeling_tf_utils.TFModelUtilsMixin\n-\n-## FlaxPreTrainedModel\n-\n-[[autodoc]] FlaxPreTrainedModel\n-    - push_to_hub\n-    - all\n-\n ## Pushing to the Hub\n \n [[autodoc]] utils.PushToHubMixin"
        },
        {
            "sha": "b42ed844c65d82629ffb358702b2dbfae3d34e20",
            "filename": "docs/source/ja/main_classes/output.md",
            "status": "modified",
            "additions": 0,
            "deletions": 132,
            "changes": 132,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmain_classes%2Foutput.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmain_classes%2Foutput.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmain_classes%2Foutput.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -187,135 +187,3 @@ outputs[:2]\n ## SampleTSPredictionOutput\n \n [[autodoc]] modeling_outputs.SampleTSPredictionOutput\n-\n-## TFBaseModelOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutput\n-\n-## TFBaseModelOutputWithPooling\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutputWithPooling\n-\n-## TFBaseModelOutputWithPoolingAndCrossAttentions\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions\n-\n-## TFBaseModelOutputWithPast\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutputWithPast\n-\n-## TFBaseModelOutputWithPastAndCrossAttentions\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutputWithPastAndCrossAttentions\n-\n-## TFSeq2SeqModelOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFSeq2SeqModelOutput\n-\n-## TFCausalLMOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFCausalLMOutput\n-\n-## TFCausalLMOutputWithCrossAttentions\n-\n-[[autodoc]] modeling_tf_outputs.TFCausalLMOutputWithCrossAttentions\n-\n-## TFCausalLMOutputWithPast\n-\n-[[autodoc]] modeling_tf_outputs.TFCausalLMOutputWithPast\n-\n-## TFMaskedLMOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFMaskedLMOutput\n-\n-## TFSeq2SeqLMOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFSeq2SeqLMOutput\n-\n-## TFNextSentencePredictorOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFNextSentencePredictorOutput\n-\n-## TFSequenceClassifierOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFSequenceClassifierOutput\n-\n-## TFSeq2SeqSequenceClassifierOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFSeq2SeqSequenceClassifierOutput\n-\n-## TFMultipleChoiceModelOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFMultipleChoiceModelOutput\n-\n-## TFTokenClassifierOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFTokenClassifierOutput\n-\n-## TFQuestionAnsweringModelOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFQuestionAnsweringModelOutput\n-\n-## TFSeq2SeqQuestionAnsweringModelOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFSeq2SeqQuestionAnsweringModelOutput\n-\n-## FlaxBaseModelOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxBaseModelOutput\n-\n-## FlaxBaseModelOutputWithPast\n-\n-[[autodoc]] modeling_flax_outputs.FlaxBaseModelOutputWithPast\n-\n-## FlaxBaseModelOutputWithPooling\n-\n-[[autodoc]] modeling_flax_outputs.FlaxBaseModelOutputWithPooling\n-\n-## FlaxBaseModelOutputWithPastAndCrossAttentions\n-\n-[[autodoc]] modeling_flax_outputs.FlaxBaseModelOutputWithPastAndCrossAttentions\n-\n-## FlaxSeq2SeqModelOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSeq2SeqModelOutput\n-\n-## FlaxCausalLMOutputWithCrossAttentions\n-\n-[[autodoc]] modeling_flax_outputs.FlaxCausalLMOutputWithCrossAttentions\n-\n-## FlaxMaskedLMOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxMaskedLMOutput\n-\n-## FlaxSeq2SeqLMOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSeq2SeqLMOutput\n-\n-## FlaxNextSentencePredictorOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxNextSentencePredictorOutput\n-\n-## FlaxSequenceClassifierOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSequenceClassifierOutput\n-\n-## FlaxSeq2SeqSequenceClassifierOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSeq2SeqSequenceClassifierOutput\n-\n-## FlaxMultipleChoiceModelOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxMultipleChoiceModelOutput\n-\n-## FlaxTokenClassifierOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxTokenClassifierOutput\n-\n-## FlaxQuestionAnsweringModelOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxQuestionAnsweringModelOutput\n-\n-## FlaxSeq2SeqQuestionAnsweringModelOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSeq2SeqQuestionAnsweringModelOutput"
        },
        {
            "sha": "570f0659c90c85889c92b3540aaca6865c6fbadb",
            "filename": "docs/source/ja/main_classes/text_generation.md",
            "status": "modified",
            "additions": 0,
            "deletions": 11,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmain_classes%2Ftext_generation.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmain_classes%2Ftext_generation.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmain_classes%2Ftext_generation.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -43,14 +43,3 @@ rendered properly in your Markdown viewer.\n [[autodoc]] generation.GenerationMixin\n \t- generate\n \t- compute_transition_scores\n-\n-## TFGenerationMixin\n-\n-[[autodoc]] generation.TFGenerationMixin\n-\t- generate\n-\t- compute_transition_scores\n-\n-## FlaxGenerationMixin\n-\n-[[autodoc]] generation.FlaxGenerationMixin\n-\t- generate"
        },
        {
            "sha": "b81723f1910dc01e6a69cc67f055b5e60a9cf952",
            "filename": "docs/source/ja/model_doc/albert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 80,
            "changes": 80,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Falbert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Falbert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Falbert.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -73,8 +73,6 @@ ALBERTモデルは、「[ALBERT: A Lite BERT for Self-supervised Learning of Lan\n \n [[autodoc]] models.albert.modeling_albert.AlbertForPreTrainingOutput\n \n-[[autodoc]] models.albert.modeling_tf_albert.TFAlbertForPreTrainingOutput\n-\n <frameworkcontent>\n <pt>\n \n@@ -113,81 +111,3 @@ ALBERTモデルは、「[ALBERT: A Lite BERT for Self-supervised Learning of Lan\n     - forward\n \n </pt>\n-\n-<tf>\n-\n-## TFAlbertModel\n-\n-[[autodoc]] TFAlbertModel\n-    - call\n-\n-## TFAlbertForPreTraining\n-\n-[[autodoc]] TFAlbertForPreTraining\n-    - call\n-\n-## TFAlbertForMaskedLM\n-\n-[[autodoc]] TFAlbertForMaskedLM\n-    - call\n-\n-## TFAlbertForSequenceClassification\n-\n-[[autodoc]] TFAlbertForSequenceClassification\n-    - call\n-\n-## TFAlbertForMultipleChoice\n-\n-[[autodoc]] TFAlbertForMultipleChoice\n-    - call\n-\n-## TFAlbertForTokenClassification\n-\n-[[autodoc]] TFAlbertForTokenClassification\n-    - call\n-\n-## TFAlbertForQuestionAnswering\n-\n-[[autodoc]] TFAlbertForQuestionAnswering\n-    - call\n-\n-</tf>\n-<jax>\n-\n-## FlaxAlbertModel\n-\n-[[autodoc]] FlaxAlbertModel\n-    - __call__\n-\n-## FlaxAlbertForPreTraining\n-\n-[[autodoc]] FlaxAlbertForPreTraining\n-    - __call__\n-\n-## FlaxAlbertForMaskedLM\n-\n-[[autodoc]] FlaxAlbertForMaskedLM\n-    - __call__\n-\n-## FlaxAlbertForSequenceClassification\n-\n-[[autodoc]] FlaxAlbertForSequenceClassification\n-    - __call__\n-\n-## FlaxAlbertForMultipleChoice\n-\n-[[autodoc]] FlaxAlbertForMultipleChoice\n-    - __call__\n-\n-## FlaxAlbertForTokenClassification\n-\n-[[autodoc]] FlaxAlbertForTokenClassification\n-    - __call__\n-\n-## FlaxAlbertForQuestionAnswering\n-\n-[[autodoc]] FlaxAlbertForQuestionAnswering\n-    - __call__\n-\n-</jax>\n-</frameworkcontent>"
        },
        {
            "sha": "1a36d2c9bb1264a3d5d7b8cbc58b7537de2e07b1",
            "filename": "docs/source/ja/model_doc/auto.md",
            "status": "modified",
            "additions": 0,
            "deletions": 134,
            "changes": 134,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fauto.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fauto.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fauto.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -77,14 +77,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModel\n \n-### TFAutoModel\n-\n-[[autodoc]] TFAutoModel\n-\n-### FlaxAutoModel\n-\n-[[autodoc]] FlaxAutoModel\n-\n ## Generic pretraining classes\n \n 以下の自動クラスは、事前学習ヘッドを持つモデルをインスタンス化するために利用可能です。\n@@ -93,14 +85,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForPreTraining\n \n-### TFAutoModelForPreTraining\n-\n-[[autodoc]] TFAutoModelForPreTraining\n-\n-### FlaxAutoModelForPreTraining\n-\n-[[autodoc]] FlaxAutoModelForPreTraining\n-\n ## Natural Language Processing\n \n 以下の自動クラスは、次の自然言語処理タスクに利用可能です。\n@@ -109,114 +93,43 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForCausalLM\n \n-### TFAutoModelForCausalLM\n-\n-[[autodoc]] TFAutoModelForCausalLM\n-\n-### FlaxAutoModelForCausalLM\n-\n-[[autodoc]] FlaxAutoModelForCausalLM\n-\n ### AutoModelForMaskedLM\n \n [[autodoc]] AutoModelForMaskedLM\n \n-### TFAutoModelForMaskedLM\n-\n-[[autodoc]] TFAutoModelForMaskedLM\n-\n-### FlaxAutoModelForMaskedLM\n-\n-[[autodoc]] FlaxAutoModelForMaskedLM\n \n ### AutoModelForMaskGeneration\n \n [[autodoc]] AutoModelForMaskGeneration\n \n-### TFAutoModelForMaskGeneration\n-\n-[[autodoc]] TFAutoModelForMaskGeneration\n-\n ### AutoModelForSeq2SeqLM\n \n [[autodoc]] AutoModelForSeq2SeqLM\n \n-### TFAutoModelForSeq2SeqLM\n-\n-[[autodoc]] TFAutoModelForSeq2SeqLM\n-\n-### FlaxAutoModelForSeq2SeqLM\n-\n-[[autodoc]] FlaxAutoModelForSeq2SeqLM\n-\n ### AutoModelForSequenceClassification\n \n [[autodoc]] AutoModelForSequenceClassification\n \n-### TFAutoModelForSequenceClassification\n-\n-[[autodoc]] TFAutoModelForSequenceClassification\n-\n-### FlaxAutoModelForSequenceClassification\n-\n-[[autodoc]] FlaxAutoModelForSequenceClassification\n-\n ### AutoModelForMultipleChoice\n \n [[autodoc]] AutoModelForMultipleChoice\n \n-### TFAutoModelForMultipleChoice\n-\n-[[autodoc]] TFAutoModelForMultipleChoice\n-\n-### FlaxAutoModelForMultipleChoice\n-\n-[[autodoc]] FlaxAutoModelForMultipleChoice\n-\n ### AutoModelForNextSentencePrediction\n \n [[autodoc]] AutoModelForNextSentencePrediction\n \n-### TFAutoModelForNextSentencePrediction\n-\n-[[autodoc]] TFAutoModelForNextSentencePrediction\n-\n-### FlaxAutoModelForNextSentencePrediction\n-\n-[[autodoc]] FlaxAutoModelForNextSentencePrediction\n-\n ### AutoModelForTokenClassification\n \n [[autodoc]] AutoModelForTokenClassification\n \n-### TFAutoModelForTokenClassification\n-\n-[[autodoc]] TFAutoModelForTokenClassification\n-\n-### FlaxAutoModelForTokenClassification\n-\n-[[autodoc]] FlaxAutoModelForTokenClassification\n-\n ### AutoModelForQuestionAnswering\n \n [[autodoc]] AutoModelForQuestionAnswering\n \n-### TFAutoModelForQuestionAnswering\n-\n-[[autodoc]] TFAutoModelForQuestionAnswering\n-\n-### FlaxAutoModelForQuestionAnswering\n-\n-[[autodoc]] FlaxAutoModelForQuestionAnswering\n-\n ### AutoModelForTextEncoding\n \n [[autodoc]] AutoModelForTextEncoding\n \n-### TFAutoModelForTextEncoding\n-\n-[[autodoc]] TFAutoModelForTextEncoding\n-\n ## Computer vision\n \n 以下の自動クラスは、次のコンピュータービジョンタスクに利用可能です。\n@@ -229,14 +142,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForImageClassification\n \n-### TFAutoModelForImageClassification\n-\n-[[autodoc]] TFAutoModelForImageClassification\n-\n-### FlaxAutoModelForImageClassification\n-\n-[[autodoc]] FlaxAutoModelForImageClassification\n-\n ### AutoModelForVideoClassification\n \n [[autodoc]] AutoModelForVideoClassification\n@@ -245,10 +150,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForMaskedImageModeling\n \n-### TFAutoModelForMaskedImageModeling\n-\n-[[autodoc]] TFAutoModelForMaskedImageModeling\n-\n ### AutoModelForObjectDetection\n \n [[autodoc]] AutoModelForObjectDetection\n@@ -265,10 +166,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForSemanticSegmentation\n \n-### TFAutoModelForSemanticSegmentation\n-\n-[[autodoc]] TFAutoModelForSemanticSegmentation\n-\n ### AutoModelForInstanceSegmentation\n \n [[autodoc]] AutoModelForInstanceSegmentation\n@@ -281,10 +178,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForZeroShotImageClassification\n \n-### TFAutoModelForZeroShotImageClassification\n-\n-[[autodoc]] TFAutoModelForZeroShotImageClassification\n-\n ### AutoModelForZeroShotObjectDetection\n \n [[autodoc]] AutoModelForZeroShotObjectDetection\n@@ -299,10 +192,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n ### AutoModelForAudioFrameClassification\n \n-[[autodoc]] TFAutoModelForAudioClassification\n-\n-### TFAutoModelForAudioFrameClassification\n-\n [[autodoc]] AutoModelForAudioFrameClassification\n \n ### AutoModelForCTC\n@@ -313,14 +202,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForSpeechSeq2Seq\n \n-### TFAutoModelForSpeechSeq2Seq\n-\n-[[autodoc]] TFAutoModelForSpeechSeq2Seq\n-\n-### FlaxAutoModelForSpeechSeq2Seq\n-\n-[[autodoc]] FlaxAutoModelForSpeechSeq2Seq\n-\n ### AutoModelForAudioXVector\n \n [[autodoc]] AutoModelForAudioXVector\n@@ -341,18 +222,10 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForTableQuestionAnswering\n \n-### TFAutoModelForTableQuestionAnswering\n-\n-[[autodoc]] TFAutoModelForTableQuestionAnswering\n-\n ### AutoModelForDocumentQuestionAnswering\n \n [[autodoc]] AutoModelForDocumentQuestionAnswering\n \n-### TFAutoModelForDocumentQuestionAnswering\n-\n-[[autodoc]] TFAutoModelForDocumentQuestionAnswering\n-\n ### AutoModelForVisualQuestionAnswering\n \n [[autodoc]] AutoModelForVisualQuestionAnswering\n@@ -361,13 +234,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForVision2Seq\n \n-### TFAutoModelForVision2Seq\n-\n-[[autodoc]] TFAutoModelForVision2Seq\n-\n-### FlaxAutoModelForVision2Seq\n-\n-[[autodoc]] FlaxAutoModelForVision2Seq\n \n ### AutoModelForImageTextToText\n "
        },
        {
            "sha": "ee584b8013e0d2f9706b4fda841f8073db14eafd",
            "filename": "docs/source/ja/model_doc/bart.md",
            "status": "modified",
            "additions": 0,
            "deletions": 48,
            "changes": 48,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fbart.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fbart.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fbart.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -173,51 +173,3 @@ BART を始めるのに役立つ公式 Hugging Face およびコミュニティ\n \n [[autodoc]] BartForCausalLM\n     - forward\n-\n-## TFBartModel\n-\n-[[autodoc]] TFBartModel\n-    - call\n-\n-## TFBartForConditionalGeneration\n-\n-[[autodoc]] TFBartForConditionalGeneration\n-    - call\n-\n-## TFBartForSequenceClassification\n-\n-[[autodoc]] TFBartForSequenceClassification\n-    - call\n-\n-## FlaxBartModel\n-\n-[[autodoc]] FlaxBartModel\n-    - __call__\n-    - encode\n-    - decode\n-\n-## FlaxBartForConditionalGeneration\n-\n-[[autodoc]] FlaxBartForConditionalGeneration\n-    - __call__\n-    - encode\n-    - decode\n-\n-## FlaxBartForSequenceClassification\n-\n-[[autodoc]] FlaxBartForSequenceClassification\n-    - __call__\n-    - encode\n-    - decode\n-\n-## FlaxBartForQuestionAnswering\n-\n-[[autodoc]] FlaxBartForQuestionAnswering\n-    - __call__\n-    - encode\n-    - decode\n-\n-## FlaxBartForCausalLM\n-\n-[[autodoc]] FlaxBartForCausalLM\n-    - __call__"
        },
        {
            "sha": "cd92b041c8b1aa9e7a9fbacae26999f1345c14b0",
            "filename": "docs/source/ja/model_doc/beit.md",
            "status": "modified",
            "additions": 0,
            "deletions": 17,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fbeit.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fbeit.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fbeit.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -89,8 +89,6 @@ BEiT の使用を開始するのに役立つ公式 Hugging Face およびコミ\n \n [[autodoc]] models.beit.modeling_beit.BeitModelOutputWithPooling\n \n-[[autodoc]] models.beit.modeling_flax_beit.FlaxBeitModelOutputWithPooling\n-\n ## BeitConfig\n \n [[autodoc]] BeitConfig\n@@ -132,18 +130,3 @@ BEiT の使用を開始するのに役立つ公式 Hugging Face およびコミ\n \n [[autodoc]] BeitForSemanticSegmentation\n     - forward\n-\n-## FlaxBeitModel\n-\n-[[autodoc]] FlaxBeitModel\n-    - __call__\n-\n-## FlaxBeitForMaskedImageModeling\n-\n-[[autodoc]] FlaxBeitForMaskedImageModeling\n-    - __call__\n-\n-## FlaxBeitForImageClassification\n-\n-[[autodoc]] FlaxBeitForImageClassification\n-    - __call__"
        },
        {
            "sha": "306b894db2194fed6bbb39ddce7f3a1ce384b38f",
            "filename": "docs/source/ja/model_doc/bert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 108,
            "changes": 108,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fbert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fbert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fbert.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -146,23 +146,12 @@ BERT を始めるのに役立つ公式 Hugging Face およびコミュニティ\n [[autodoc]] BertTokenizerFast\n \n </pt>\n-<tf>\n-\n-## TFBertTokenizer\n-\n-[[autodoc]] TFBertTokenizer\n-\n-</tf>\n </frameworkcontent>\n \n ## Bert specific outputs\n \n [[autodoc]] models.bert.modeling_bert.BertForPreTrainingOutput\n \n-[[autodoc]] models.bert.modeling_tf_bert.TFBertForPreTrainingOutput\n-\n-[[autodoc]] models.bert.modeling_flax_bert.FlaxBertForPreTrainingOutput\n-\n <frameworkcontent>\n <pt>\n \n@@ -212,101 +201,4 @@ BERT を始めるのに役立つ公式 Hugging Face およびコミュニティ\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFBertModel\n-\n-[[autodoc]] TFBertModel\n-    - call\n-\n-## TFBertForPreTraining\n-\n-[[autodoc]] TFBertForPreTraining\n-    - call\n-\n-## TFBertModelLMHeadModel\n-\n-[[autodoc]] TFBertLMHeadModel\n-    - call\n-\n-## TFBertForMaskedLM\n-\n-[[autodoc]] TFBertForMaskedLM\n-    - call\n-\n-## TFBertForNextSentencePrediction\n-\n-[[autodoc]] TFBertForNextSentencePrediction\n-    - call\n-\n-## TFBertForSequenceClassification\n-\n-[[autodoc]] TFBertForSequenceClassification\n-    - call\n-\n-## TFBertForMultipleChoice\n-\n-[[autodoc]] TFBertForMultipleChoice\n-    - call\n-\n-## TFBertForTokenClassification\n-\n-[[autodoc]] TFBertForTokenClassification\n-    - call\n-\n-## TFBertForQuestionAnswering\n-\n-[[autodoc]] TFBertForQuestionAnswering\n-    - call\n-\n-</tf>\n-<jax>\n-\n-\n-## FlaxBertModel\n-\n-[[autodoc]] FlaxBertModel\n-    - __call__\n-\n-## FlaxBertForPreTraining\n-\n-[[autodoc]] FlaxBertForPreTraining\n-    - __call__\n-\n-## FlaxBertForCausalLM\n-\n-[[autodoc]] FlaxBertForCausalLM\n-    - __call__\n-\n-## FlaxBertForMaskedLM\n-\n-[[autodoc]] FlaxBertForMaskedLM\n-    - __call__\n-\n-## FlaxBertForNextSentencePrediction\n-\n-[[autodoc]] FlaxBertForNextSentencePrediction\n-    - __call__\n-\n-## FlaxBertForSequenceClassification\n-\n-[[autodoc]] FlaxBertForSequenceClassification\n-    - __call__\n-\n-## FlaxBertForMultipleChoice\n-\n-[[autodoc]] FlaxBertForMultipleChoice\n-    - __call__\n-\n-## FlaxBertForTokenClassification\n-\n-[[autodoc]] FlaxBertForTokenClassification\n-    - __call__\n-\n-## FlaxBertForQuestionAnswering\n-\n-[[autodoc]] FlaxBertForQuestionAnswering\n-    - __call__\n-\n-</jax>\n </frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "cec7cdf5f319be4f97dfa9cf6833caef44d5fb30",
            "filename": "docs/source/ja/model_doc/big_bird.md",
            "status": "modified",
            "additions": 0,
            "deletions": 43,
            "changes": 43,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fbig_bird.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fbig_bird.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fbig_bird.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -129,48 +129,5 @@ BigBird は、質問応答や要約などのさまざまな NLP タスクのパ\n     - forward\n \n </pt>\n-<jax>\n-\n-## FlaxBigBirdModel\n-\n-[[autodoc]] FlaxBigBirdModel\n-    - __call__\n-\n-## FlaxBigBirdForPreTraining\n-\n-[[autodoc]] FlaxBigBirdForPreTraining\n-    - __call__\n-\n-## FlaxBigBirdForCausalLM\n-\n-[[autodoc]] FlaxBigBirdForCausalLM\n-    - __call__\n-\n-## FlaxBigBirdForMaskedLM\n-\n-[[autodoc]] FlaxBigBirdForMaskedLM\n-    - __call__\n-\n-## FlaxBigBirdForSequenceClassification\n-\n-[[autodoc]] FlaxBigBirdForSequenceClassification\n-    - __call__\n-\n-## FlaxBigBirdForMultipleChoice\n-\n-[[autodoc]] FlaxBigBirdForMultipleChoice\n-    - __call__\n-\n-## FlaxBigBirdForTokenClassification\n-\n-[[autodoc]] FlaxBigBirdForTokenClassification\n-    - __call__\n-\n-## FlaxBigBirdForQuestionAnswering\n-\n-[[autodoc]] FlaxBigBirdForQuestionAnswering\n-    - __call__\n-\n-</jax>\n </frameworkcontent>\n "
        },
        {
            "sha": "cdfad5272f59062a559d1c289ae380c759299c73",
            "filename": "docs/source/ja/model_doc/blenderbot-small.md",
            "status": "modified",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fblenderbot-small.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fblenderbot-small.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fblenderbot-small.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -84,27 +84,3 @@ Blender チャットボット モデルは、[Recipes for building an open-domai\n \n [[autodoc]] BlenderbotSmallForCausalLM\n     - forward\n-\n-## TFBlenderbotSmallModel\n-\n-[[autodoc]] TFBlenderbotSmallModel\n-    - call\n-\n-## TFBlenderbotSmallForConditionalGeneration\n-\n-[[autodoc]] TFBlenderbotSmallForConditionalGeneration\n-    - call\n-\n-## FlaxBlenderbotSmallModel\n-\n-[[autodoc]] FlaxBlenderbotSmallModel\n-    - __call__\n-    - encode\n-    - decode\n-\n-## FlaxBlenderbotForConditionalGeneration\n-\n-[[autodoc]] FlaxBlenderbotSmallForConditionalGeneration\n-    - __call__\n-    - encode\n-    - decode"
        },
        {
            "sha": "5c7aef5a5240d5e265d925e16fd450cc4bfb44a5",
            "filename": "docs/source/ja/model_doc/blenderbot.md",
            "status": "modified",
            "additions": 0,
            "deletions": 23,
            "changes": 23,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fblenderbot.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fblenderbot.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fblenderbot.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -107,26 +107,3 @@ Blender チャットボット モデルは、[Recipes for building an open-domai\n [[autodoc]] BlenderbotForCausalLM\n     - forward\n \n-## TFBlenderbotModel\n-\n-[[autodoc]] TFBlenderbotModel\n-    - call\n-\n-## TFBlenderbotForConditionalGeneration\n-\n-[[autodoc]] TFBlenderbotForConditionalGeneration\n-    - call\n-\n-## FlaxBlenderbotModel\n-\n-[[autodoc]] FlaxBlenderbotModel\n-    - __call__\n-    - encode\n-    - decode\n-\n-## FlaxBlenderbotForConditionalGeneration\n-\n-[[autodoc]] FlaxBlenderbotForConditionalGeneration\n-    - __call__\n-    - encode\n-    - decode"
        },
        {
            "sha": "4cba6d0c936b17d77d36cba70e8efb78481ef415",
            "filename": "docs/source/ja/model_doc/blip.md",
            "status": "modified",
            "additions": 0,
            "deletions": 34,
            "changes": 34,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fblip.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fblip.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fblip.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -102,38 +102,4 @@ BLIP は、次のようなさまざまなマルチモーダル タスクを実\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFBlipModel\n-\n-[[autodoc]] TFBlipModel\n-    - call\n-    - get_text_features\n-    - get_image_features\n-\n-## TFBlipTextModel\n-\n-[[autodoc]] TFBlipTextModel\n-    - call\n-\n-## TFBlipVisionModel\n-\n-[[autodoc]] TFBlipVisionModel\n-    - call\n-\n-## TFBlipForConditionalGeneration\n-\n-[[autodoc]] TFBlipForConditionalGeneration\n-    - call\n-\n-## TFBlipForImageTextRetrieval\n-\n-[[autodoc]] TFBlipForImageTextRetrieval\n-    - call\n-\n-## TFBlipForQuestionAnswering\n-\n-[[autodoc]] TFBlipForQuestionAnswering\n-    - call\n-</tf>\n </frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "1598028824674682323127a7323e478f21a2b8e7",
            "filename": "docs/source/ja/model_doc/bloom.md",
            "status": "modified",
            "additions": 0,
            "deletions": 13,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fbloom.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fbloom.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fbloom.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -91,17 +91,4 @@ BLOOM を使い始めるのに役立つ公式 Hugging Face およびコミュニ\n     - forward\n \n </pt>\n-<jax>\n-\n-## FlaxBloomModel\n-\n-[[autodoc]] FlaxBloomModel\n-    - __call__\n-\n-## FlaxBloomForCausalLM\n-\n-[[autodoc]] FlaxBloomForCausalLM\n-    - __call__\n-\n-</jax>\n </frameworkcontent>"
        },
        {
            "sha": "c0d6a4fdb7f0e3aebcf8c4eee5ac9dbcfa3b57f1",
            "filename": "docs/source/ja/model_doc/camembert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 31,
            "changes": 31,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fcamembert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fcamembert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fcamembert.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -101,35 +101,4 @@ Bi-direction Encoders for Transformers (BERT) のフランス語版である Cam\n [[autodoc]] CamembertForQuestionAnswering\n \n </pt>\n-<tf>\n-\n-## TFCamembertModel\n-\n-[[autodoc]] TFCamembertModel\n-\n-## TFCamembertForCasualLM\n-\n-[[autodoc]] TFCamembertForCausalLM\n-\n-## TFCamembertForMaskedLM\n-\n-[[autodoc]] TFCamembertForMaskedLM\n-\n-## TFCamembertForSequenceClassification\n-\n-[[autodoc]] TFCamembertForSequenceClassification\n-\n-## TFCamembertForMultipleChoice\n-\n-[[autodoc]] TFCamembertForMultipleChoice\n-\n-## TFCamembertForTokenClassification\n-\n-[[autodoc]] TFCamembertForTokenClassification\n-\n-## TFCamembertForQuestionAnswering\n-\n-[[autodoc]] TFCamembertForQuestionAnswering\n-\n-</tf>\n </frameworkcontent>"
        },
        {
            "sha": "3e785a2b310e18938487fb16fd61b5aaf7930aef",
            "filename": "docs/source/ja/model_doc/clip.md",
            "status": "modified",
            "additions": 0,
            "deletions": 45,
            "changes": 45,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fclip.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fclip.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fclip.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -177,49 +177,4 @@ CLIP を使い始めるのに役立つ公式 Hugging Face およびコミュニ\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFCLIPModel\n-\n-[[autodoc]] TFCLIPModel\n-    - call\n-    - get_text_features\n-    - get_image_features\n-\n-## TFCLIPTextModel\n-\n-[[autodoc]] TFCLIPTextModel\n-    - call\n-\n-## TFCLIPVisionModel\n-\n-[[autodoc]] TFCLIPVisionModel\n-    - call\n-\n-</tf>\n-<jax>\n-\n-## FlaxCLIPModel\n-\n-[[autodoc]] FlaxCLIPModel\n-    - __call__\n-    - get_text_features\n-    - get_image_features\n-\n-## FlaxCLIPTextModel\n-\n-[[autodoc]] FlaxCLIPTextModel\n-    - __call__\n-\n-## FlaxCLIPTextModelWithProjection\n-\n-[[autodoc]] FlaxCLIPTextModelWithProjection\n-    - __call__\n-\n-## FlaxCLIPVisionModel\n-\n-[[autodoc]] FlaxCLIPVisionModel\n-    - __call__\n-\n-</jax>\n </frameworkcontent>"
        },
        {
            "sha": "5112a64366ff91b27dd55a8fce413e6cc580a181",
            "filename": "docs/source/ja/model_doc/convbert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 33,
            "changes": 33,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvbert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvbert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvbert.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -109,37 +109,4 @@ ConvBERT トレーニングのヒントは BERT のヒントと似ています\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFConvBertModel\n-\n-[[autodoc]] TFConvBertModel\n-    - call\n-\n-## TFConvBertForMaskedLM\n-\n-[[autodoc]] TFConvBertForMaskedLM\n-    - call\n-\n-## TFConvBertForSequenceClassification\n-\n-[[autodoc]] TFConvBertForSequenceClassification\n-    - call\n-\n-## TFConvBertForMultipleChoice\n-\n-[[autodoc]] TFConvBertForMultipleChoice\n-    - call\n-\n-## TFConvBertForTokenClassification\n-\n-[[autodoc]] TFConvBertForTokenClassification\n-    - call\n-\n-## TFConvBertForQuestionAnswering\n-\n-[[autodoc]] TFConvBertForQuestionAnswering\n-    - call\n-\n-</tf>\n </frameworkcontent>"
        },
        {
            "sha": "a733b0923c29ce550597649110c5bba94210670c",
            "filename": "docs/source/ja/model_doc/convnext.md",
            "status": "modified",
            "additions": 0,
            "deletions": 13,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvnext.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvnext.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvnext.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -83,17 +83,4 @@ ConvNeXT の使用を開始するのに役立つ公式 Hugging Face およびコ\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFConvNextModel\n-\n-[[autodoc]] TFConvNextModel\n-    - call\n-\n-## TFConvNextForImageClassification\n-\n-[[autodoc]] TFConvNextForImageClassification\n-    - call\n-\n-</tf>\n </frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "cf80bcd63bbfb04742753911b136fee75d232f66",
            "filename": "docs/source/ja/model_doc/convnextv2.md",
            "status": "modified",
            "additions": 0,
            "deletions": 11,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvnextv2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvnextv2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvnextv2.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -55,14 +55,3 @@ ConvNeXt V2 の使用を開始するのに役立つ公式 Hugging Face および\n \n [[autodoc]] ConvNextV2ForImageClassification\n     - forward\n-\n-## TFConvNextV2Model\n-\n-[[autodoc]] TFConvNextV2Model\n-    - call\n-\n-\n-## TFConvNextV2ForImageClassification\n-\n-[[autodoc]] TFConvNextV2ForImageClassification\n-    - call"
        },
        {
            "sha": "260649ef01a349f1c8e6f0748260a1793c4772c4",
            "filename": "docs/source/ja/model_doc/ctrl.md",
            "status": "modified",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fctrl.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fctrl.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fctrl.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -92,22 +92,4 @@ CTRL モデルは、Nitish Shirish Keskar*、Bryan McCann*、Lav R. Varshney、C\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFCTRLModel\n-\n-[[autodoc]] TFCTRLModel\n-    - call\n-\n-## TFCTRLLMHeadModel\n-\n-[[autodoc]] TFCTRLLMHeadModel\n-    - call\n-\n-## TFCTRLForSequenceClassification\n-\n-[[autodoc]] TFCTRLForSequenceClassification\n-    - call\n-\n-</tf>\n </frameworkcontent>"
        },
        {
            "sha": "86f54afafee9a39a2e0896da723f278609f81cdf",
            "filename": "docs/source/ja/model_doc/cvt.md",
            "status": "modified",
            "additions": 0,
            "deletions": 13,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fcvt.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fcvt.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fcvt.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -71,18 +71,5 @@ CvT を始めるのに役立つ公式 Hugging Face およびコミュニティ (\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFCvtModel\n-\n-[[autodoc]] TFCvtModel\n-    - call\n-\n-## TFCvtForImageClassification\n-\n-[[autodoc]] TFCvtForImageClassification\n-    - call\n-\n-</tf>\n </frameworkcontent>\n "
        },
        {
            "sha": "53f389223d1f179849e7ae0f1ae0e6876bda7389",
            "filename": "docs/source/ja/model_doc/data2vec.md",
            "status": "modified",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fdata2vec.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fdata2vec.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fdata2vec.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -166,22 +166,4 @@ Data2Vec の使用を開始するのに役立つ公式 Hugging Face およびコ\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFData2VecVisionModel\n-\n-[[autodoc]] TFData2VecVisionModel\n-    - call\n-\n-## TFData2VecVisionForImageClassification\n-\n-[[autodoc]] TFData2VecVisionForImageClassification\n-    - call\n-\n-## TFData2VecVisionForSemanticSegmentation\n-\n-[[autodoc]] TFData2VecVisionForSemanticSegmentation\n-    - call\n-\n-</tf>\n </frameworkcontent>"
        },
        {
            "sha": "0054b6ad3dbfb2fcda57135c3942dd6d89404fc1",
            "filename": "docs/source/ja/model_doc/deberta-v2.md",
            "status": "modified",
            "additions": 0,
            "deletions": 38,
            "changes": 38,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeberta-v2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeberta-v2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeberta-v2.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -124,44 +124,6 @@ v2 の新機能:\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFDebertaV2Model\n-\n-[[autodoc]] TFDebertaV2Model\n-    - call\n-\n-## TFDebertaV2PreTrainedModel\n-\n-[[autodoc]] TFDebertaV2PreTrainedModel\n-    - call\n-\n-## TFDebertaV2ForMaskedLM\n-\n-[[autodoc]] TFDebertaV2ForMaskedLM\n-    - call\n-\n-## TFDebertaV2ForSequenceClassification\n-\n-[[autodoc]] TFDebertaV2ForSequenceClassification\n-    - call\n-\n-## TFDebertaV2ForTokenClassification\n-\n-[[autodoc]] TFDebertaV2ForTokenClassification\n-    - call\n-\n-## TFDebertaV2ForQuestionAnswering\n-\n-[[autodoc]] TFDebertaV2ForQuestionAnswering\n-    - call\n-\n-## TFDebertaV2ForMultipleChoice\n-\n-[[autodoc]] TFDebertaV2ForMultipleChoice\n-    - call\n-\n-</tf>\n </frameworkcontent>\n \n "
        },
        {
            "sha": "1a7ae534911a32313674076f14c88701842da071",
            "filename": "docs/source/ja/model_doc/deberta.md",
            "status": "modified",
            "additions": 0,
            "deletions": 33,
            "changes": 33,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeberta.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeberta.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeberta.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -127,38 +127,5 @@ DeBERTa を使い始めるのに役立つ公式 Hugging Face およびコミュ\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFDebertaModel\n-\n-[[autodoc]] TFDebertaModel\n-    - call\n-\n-## TFDebertaPreTrainedModel\n-\n-[[autodoc]] TFDebertaPreTrainedModel\n-    - call\n-\n-## TFDebertaForMaskedLM\n-\n-[[autodoc]] TFDebertaForMaskedLM\n-    - call\n-\n-## TFDebertaForSequenceClassification\n-\n-[[autodoc]] TFDebertaForSequenceClassification\n-    - call\n-\n-## TFDebertaForTokenClassification\n-\n-[[autodoc]] TFDebertaForTokenClassification\n-    - call\n-\n-## TFDebertaForQuestionAnswering\n-\n-[[autodoc]] TFDebertaForQuestionAnswering\n-    - call\n-\n-</tf>\n </frameworkcontent>\n "
        },
        {
            "sha": "3332d3f16738212ab5c92514702585fcd1d67181",
            "filename": "docs/source/ja/model_doc/deit.md",
            "status": "modified",
            "additions": 0,
            "deletions": 23,
            "changes": 23,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeit.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeit.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeit.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -127,27 +127,4 @@ DeiT を始めるのに役立つ公式 Hugging Face およびコミュニティ\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFDeiTModel\n-\n-[[autodoc]] TFDeiTModel\n-    - call\n-\n-## TFDeiTForMaskedImageModeling\n-\n-[[autodoc]] TFDeiTForMaskedImageModeling\n-    - call\n-\n-## TFDeiTForImageClassification\n-\n-[[autodoc]] TFDeiTForImageClassification\n-    - call\n-\n-## TFDeiTForImageClassificationWithTeacher\n-\n-[[autodoc]] TFDeiTForImageClassificationWithTeacher\n-    - call\n-\n-</tf>\n </frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "01a9e6f2b9358a9a27d533973f444c8e93381cc2",
            "filename": "docs/source/ko/internal/generation_utils.md",
            "status": "modified",
            "additions": 0,
            "deletions": 119,
            "changes": 119,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Finternal%2Fgeneration_utils.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Finternal%2Fgeneration_utils.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Finternal%2Fgeneration_utils.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -68,36 +68,6 @@ generation_output[:2]\n \n [[autodoc]] generation.GenerateBeamEncoderDecoderOutput\n \n-### TensorFlow [[transformers.generation.TFGreedySearchEncoderDecoderOutput]]\n-\n-[[autodoc]] generation.TFGreedySearchEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFGreedySearchDecoderOnlyOutput\n-\n-[[autodoc]] generation.TFSampleEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFSampleDecoderOnlyOutput\n-\n-[[autodoc]] generation.TFBeamSearchEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFBeamSearchDecoderOnlyOutput\n-\n-[[autodoc]] generation.TFBeamSampleEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFBeamSampleDecoderOnlyOutput\n-\n-[[autodoc]] generation.TFContrastiveSearchEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFContrastiveSearchDecoderOnlyOutput\n-\n-### FLAX [[transformers.generation.FlaxSampleOutput]]\n-\n-[[autodoc]] generation.FlaxSampleOutput\n-\n-[[autodoc]] generation.FlaxGreedySearchOutput\n-\n-[[autodoc]] generation.FlaxBeamSearchOutput\n-\n ## LogitsProcessor [[logitsprocessor]]\n \n [`LogitsProcessor`]는 생성 중 언어 모델 헤드의 예측 점수를 수정하는 데 사용됩니다.\n@@ -194,95 +164,6 @@ generation_output[:2]\n [[autodoc]] WatermarkLogitsProcessor\n     - __call__\n \n-\n-### TensorFlow [[transformers.TFForcedBOSTokenLogitsProcessor]]\n-\n-[[autodoc]] TFForcedBOSTokenLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFForcedEOSTokenLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFForceTokensLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFLogitsProcessorList\n-    - __call__\n-\n-[[autodoc]] TFLogitsWarper\n-    - __call__\n-\n-[[autodoc]] TFMinLengthLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFNoBadWordsLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFNoRepeatNGramLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFRepetitionPenaltyLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFSuppressTokensAtBeginLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFSuppressTokensLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFTemperatureLogitsWarper\n-    - __call__\n-\n-[[autodoc]] TFTopKLogitsWarper\n-    - __call__\n-\n-[[autodoc]] TFTopPLogitsWarper\n-    - __call__\n-\n-### FLAX [[transformers.FlaxForcedBOSTokenLogitsProcessor]]\n-\n-[[autodoc]] FlaxForcedBOSTokenLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxForcedEOSTokenLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxForceTokensLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxLogitsProcessorList\n-    - __call__\n-\n-[[autodoc]] FlaxLogitsWarper\n-    - __call__\n-\n-[[autodoc]] FlaxMinLengthLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxSuppressTokensAtBeginLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxSuppressTokensLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxTemperatureLogitsWarper\n-    - __call__\n-\n-[[autodoc]] FlaxTopKLogitsWarper\n-    - __call__\n-\n-[[autodoc]] FlaxTopPLogitsWarper\n-    - __call__\n-\n-[[autodoc]] FlaxWhisperTimeStampLogitsProcessor\n-    - __call__\n-\n ## StoppingCriteria [[transformers.StoppingCriteria]]\n \n [`StoppingCriteria`]는 생성이 언제 멈출지를 결정하는 데 사용됩니다 (EOS 토큰 외). 이 기능은 PyTorch 구현에만 제공됩니다."
        },
        {
            "sha": "d51408ae2bad1eccb7e3abed9db14bcc38f0f7b1",
            "filename": "docs/source/ko/internal/modeling_utils.md",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Finternal%2Fmodeling_utils.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Finternal%2Fmodeling_utils.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Finternal%2Fmodeling_utils.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -36,31 +36,3 @@ rendered properly in your Markdown viewer.\n [[autodoc]] pytorch_utils.prune_conv1d_layer\n \n [[autodoc]] pytorch_utils.prune_linear_layer\n-\n-## TensorFlow 사용자 정의 레이어 [[transformers.modeling_tf_utils.TFConv1D]]\n-\n-[[autodoc]] modeling_tf_utils.TFConv1D\n-\n-[[autodoc]] modeling_tf_utils.TFSequenceSummary\n-\n-## TensorFlow 손실 함수 [[transformers.modeling_tf_utils.TFCausalLanguageModelingLoss]]\n-\n-[[autodoc]] modeling_tf_utils.TFCausalLanguageModelingLoss\n-\n-[[autodoc]] modeling_tf_utils.TFMaskedLanguageModelingLoss\n-\n-[[autodoc]] modeling_tf_utils.TFMultipleChoiceLoss\n-\n-[[autodoc]] modeling_tf_utils.TFQuestionAnsweringLoss\n-\n-[[autodoc]] modeling_tf_utils.TFSequenceClassificationLoss\n-\n-[[autodoc]] modeling_tf_utils.TFTokenClassificationLoss\n-\n-## TensorFlow 도우미 함수 [[transformers.modeling_tf_utils.get_initializer]]\n-\n-[[autodoc]] modeling_tf_utils.get_initializer\n-\n-[[autodoc]] modeling_tf_utils.keras_serializable\n-\n-[[autodoc]] modeling_tf_utils.shape_list"
        },
        {
            "sha": "67a8ba535fdaf998925cfd1c707580f93b19602a",
            "filename": "docs/source/ko/main_classes/model.md",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmain_classes%2Fmodel.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmain_classes%2Fmodel.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmain_classes%2Fmodel.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -43,22 +43,6 @@ rendered properly in your Markdown viewer.\n \n [[autodoc]] modeling_utils.ModuleUtilsMixin\n \n-## TFPreTrainedModel\n-\n-[[autodoc]] TFPreTrainedModel\n-    - push_to_hub\n-    - all\n-\n-## TFModelUtilsMixin\n-\n-[[autodoc]] modeling_tf_utils.TFModelUtilsMixin\n-\n-## FlaxPreTrainedModel\n-\n-[[autodoc]] FlaxPreTrainedModel\n-    - push_to_hub\n-    - all\n-\n ## 허브에 저장하기\n \n [[autodoc]] utils.PushToHubMixin"
        },
        {
            "sha": "c383a522a1aabdd1bcaf4cdef3c87e8b62fdc623",
            "filename": "docs/source/ko/main_classes/output.md",
            "status": "modified",
            "additions": 0,
            "deletions": 131,
            "changes": 131,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmain_classes%2Foutput.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmain_classes%2Foutput.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmain_classes%2Foutput.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -181,134 +181,3 @@ outputs[:2]\n \n [[autodoc]] modeling_outputs.SampleTSPredictionOutput\n \n-## TFBaseModelOutput[[transformers.modeling_outputs.TFBaseModelOutput]]\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutput\n-\n-## TFBaseModelOutputWithPooling[[transformers.modeling_tf_outputs.TFBaseModelOutputWithPooling]]\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutputWithPooling\n-\n-## TFBaseModelOutputWithPoolingAndCrossAttentions[[transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions]]\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions\n-\n-## TFBaseModelOutputWithPast[[transformers.modeling_tf_outputs.TFBaseModelOutputWithPast]]\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutputWithPast\n-\n-## TFBaseModelOutputWithPastAndCrossAttentions[[transformers.modeling_tf_outputs.TFBaseModelOutputWithPastAndCrossAttentions]]\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutputWithPastAndCrossAttentions\n-\n-## TFSeq2SeqModelOutput[[transformers.modeling_tf_outputs.TFSeq2SeqModelOutput]]\n-\n-[[autodoc]] modeling_tf_outputs.TFSeq2SeqModelOutput\n-\n-## TFCausalLMOutput[[transformers.modeling_tf_outputs.TFCausalLMOutput]]\n-\n-[[autodoc]] modeling_tf_outputs.TFCausalLMOutput\n-\n-## TFCausalLMOutputWithCrossAttentions[[transformers.modeling_tf_outputs.TFCausalLMOutputWithCrossAttentions]]\n-\n-[[autodoc]] modeling_tf_outputs.TFCausalLMOutputWithCrossAttentions\n-\n-## TFCausalLMOutputWithPast[[transformers.modeling_tf_outputs.TFCausalLMOutputWithPast]]\n-\n-[[autodoc]] modeling_tf_outputs.TFCausalLMOutputWithPast\n-\n-## TFMaskedLMOutput[[transformers.modeling_tf_outputs.TFMaskedLMOutput]]\n-\n-[[autodoc]] modeling_tf_outputs.TFMaskedLMOutput\n-\n-## TFSeq2SeqLMOutput[[transformers.modeling_tf_outputs.TFSeq2SeqLMOutput]]\n-\n-[[autodoc]] modeling_tf_outputs.TFSeq2SeqLMOutput\n-\n-## TFNextSentencePredictorOutput[[transformers.modeling_tf_outputs.TFNextSentencePredictorOutput]]\n-\n-[[autodoc]] modeling_tf_outputs.TFNextSentencePredictorOutput\n-\n-## TFSequenceClassifierOutput[[transformers.modeling_tf_outputs.TFSequenceClassifierOutput]]\n-\n-[[autodoc]] modeling_tf_outputs.TFSequenceClassifierOutput\n-\n-## TFSeq2SeqSequenceClassifierOutput[[transformers.modeling_tf_outputs.TFSeq2SeqSequenceClassifierOutput]]\n-\n-[[autodoc]] modeling_tf_outputs.TFSeq2SeqSequenceClassifierOutput\n-\n-## TFMultipleChoiceModelOutput[[transformers.modeling_tf_outputs.TFMultipleChoiceModelOutput]]\n-\n-[[autodoc]] modeling_tf_outputs.TFMultipleChoiceModelOutput\n-\n-## TFTokenClassifierOutput[[transformers.modeling_tf_outputs.TFTokenClassifierOutput]]\n-\n-[[autodoc]] modeling_tf_outputs.TFTokenClassifierOutput\n-\n-## TFQuestionAnsweringModelOutput[[transformers.modeling_tf_outputs.TFQuestionAnsweringModelOutput]]\n-\n-[[autodoc]] modeling_tf_outputs.TFQuestionAnsweringModelOutput\n-\n-## TFSeq2SeqQuestionAnsweringModelOutput[[transformers.modeling_tf_outputs.TFSeq2SeqQuestionAnsweringModelOutput]]\n-\n-[[autodoc]] modeling_tf_outputs.TFSeq2SeqQuestionAnsweringModelOutput\n-\n-## FlaxBaseModelOutput[[transformers.modeling_flax_outputs.FlaxBaseModelOutput]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxBaseModelOutput\n-\n-## FlaxBaseModelOutputWithPast[[transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPast]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxBaseModelOutputWithPast\n-\n-## FlaxBaseModelOutputWithPooling[[transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPooling]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxBaseModelOutputWithPooling\n-\n-## FlaxBaseModelOutputWithPastAndCrossAttentions[[transformers.modeling_flax_outputs.FlaxBaseModelOutputWithPastAndCrossAttentions]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxBaseModelOutputWithPastAndCrossAttentions\n-\n-## FlaxSeq2SeqModelOutput[[transformers.modeling_flax_outputs.FlaxSeq2SeqModelOutput]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSeq2SeqModelOutput\n-\n-## FlaxCausalLMOutputWithCrossAttentions[[transformers.modeling_flax_outputs.FlaxCausalLMOutputWithCrossAttentions]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxCausalLMOutputWithCrossAttentions\n-\n-## FlaxMaskedLMOutput[[transformers.modeling_flax_outputs.FlaxMaskedLMOutput]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxMaskedLMOutput\n-\n-## FlaxSeq2SeqLMOutput[[transformers.modeling_flax_outputs.FlaxSeq2SeqLMOutput]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSeq2SeqLMOutput\n-\n-## FlaxNextSentencePredictorOutput[[transformers.modeling_flax_outputs.FlaxNextSentencePredictorOutput]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxNextSentencePredictorOutput\n-\n-## FlaxSequenceClassifierOutput[[transformers.modeling_flax_outputs.FlaxSequenceClassifierOutput]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSequenceClassifierOutput\n-\n-## FlaxSeq2SeqSequenceClassifierOutput[[transformers.modeling_flax_outputs.FlaxSeq2SeqSequenceClassifierOutput]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSeq2SeqSequenceClassifierOutput\n-\n-## FlaxMultipleChoiceModelOutput[[transformers.modeling_flax_outputs.FlaxMultipleChoiceModelOutput]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxMultipleChoiceModelOutput\n-\n-## FlaxTokenClassifierOutput[[transformers.modeling_flax_outputs.FlaxTokenClassifierOutput]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxTokenClassifierOutput\n-\n-## FlaxQuestionAnsweringModelOutput[[transformers.modeling_flax_outputs.FlaxQuestionAnsweringModelOutput]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxQuestionAnsweringModelOutput\n-\n-## FlaxSeq2SeqQuestionAnsweringModelOutput[[transformers.modeling_flax_outputs.FlaxSeq2SeqQuestionAnsweringModelOutput]]\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSeq2SeqQuestionAnsweringModelOutput"
        },
        {
            "sha": "f220939b0daf0de0f52321b50ea6201cbaab0e84",
            "filename": "docs/source/ko/main_classes/text_generation.md",
            "status": "modified",
            "additions": 0,
            "deletions": 10,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmain_classes%2Ftext_generation.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmain_classes%2Ftext_generation.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmain_classes%2Ftext_generation.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -44,13 +44,3 @@ rendered properly in your Markdown viewer.\n \t- generate\n \t- compute_transition_scores\n \n-## TFGenerationMixin [[transformers.TFGenerationMixin]]\n-\n-[[autodoc]] generation.TFGenerationMixin\n-\t- generate\n-\t- compute_transition_scores\n-\n-## FlaxGenerationMixin [[transformers.FlaxGenerationMixin]]\n-\n-[[autodoc]] generation.FlaxGenerationMixin\n-\t- generate"
        },
        {
            "sha": "2ca79a721d604688a67533376a68acbb65843f28",
            "filename": "docs/source/ko/model_doc/albert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 65,
            "changes": 65,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Falbert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Falbert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Falbert.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -163,8 +163,6 @@ echo -e \"Plants create [MASK] through a process known as photosynthesis.\" | tran\n \n [[autodoc]] models.albert.modeling_albert.AlbertForPreTrainingOutput\n \n-[[autodoc]] models.albert.modeling_tf_albert.TFAlbertForPreTrainingOutput\n-\n <frameworkcontent>\n <pt>\n \n@@ -197,67 +195,4 @@ echo -e \"Plants create [MASK] through a process known as photosynthesis.\" | tran\n [[autodoc]] AlbertForQuestionAnswering - forward\n \n </pt>\n-\n-<tf>\n-\n-## TFAlbertModel[[tfalbertmodel]]\n-\n-[[autodoc]] TFAlbertModel - call\n-\n-## TFAlbertForPreTraining[[tfalbertforpretraining]]\n-\n-[[autodoc]] TFAlbertForPreTraining - call\n-\n-## TFAlbertForMaskedLM[[tfalbertformaskedlm]]\n-\n-[[autodoc]] TFAlbertForMaskedLM - call\n-\n-## TFAlbertForSequenceClassification[[tfalbertforsequenceclassification]]\n-\n-[[autodoc]] TFAlbertForSequenceClassification - call\n-\n-## TFAlbertForMultipleChoice[[tfalbertformultiplechoice]]\n-\n-[[autodoc]] TFAlbertForMultipleChoice - call\n-\n-## TFAlbertForTokenClassification[[tfalbertfortokenclassification]]\n-\n-[[autodoc]] TFAlbertForTokenClassification - call\n-\n-## TFAlbertForQuestionAnswering[[tfalbertforquestionanswering]]\n-\n-[[autodoc]] TFAlbertForQuestionAnswering - call\n-\n-</tf>\n-<jax>\n-\n-## FlaxAlbertModel[[flaxalbertmodel]]\n-\n-[[autodoc]] FlaxAlbertModel - **call**\n-\n-## FlaxAlbertForPreTraining[[flaxalbertforpretraining]]\n-\n-[[autodoc]] FlaxAlbertForPreTraining - **call**\n-\n-## FlaxAlbertForMaskedLM[[flaxalbertformaskedlm]]\n-\n-[[autodoc]] FlaxAlbertForMaskedLM - **call**\n-\n-## FlaxAlbertForSequenceClassification[[flaxalbertforsequenceclassification]]\n-\n-[[autodoc]] FlaxAlbertForSequenceClassification - **call**\n-\n-## FlaxAlbertForMultipleChoice[[flaxalbertformultiplechoice]]\n-\n-[[autodoc]] FlaxAlbertForMultipleChoice - **call**\n-\n-## FlaxAlbertForTokenClassification[[flaxalbertfortokenclassification]]\n-\n-[[autodoc]] FlaxAlbertForTokenClassification - **call**\n-\n-## FlaxAlbertForQuestionAnswering[[flaxalbertforquestionanswering]]\n-\n-[[autodoc]] FlaxAlbertForQuestionAnswering - **call**\n-\n-</jax>\n </frameworkcontent>"
        },
        {
            "sha": "f928b19045532cee6715962e304dd112e1d7e53a",
            "filename": "docs/source/ko/model_doc/auto.md",
            "status": "modified",
            "additions": 0,
            "deletions": 136,
            "changes": 136,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fauto.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fauto.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fauto.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -78,14 +78,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModel\n \n-### TFAutoModel[[transformers.TFAutoModel]]\n-\n-[[autodoc]] TFAutoModel\n-\n-### FlaxAutoModel[[transformers.FlaxAutoModel]]\n-\n-[[autodoc]] FlaxAutoModel\n-\n ## 일반적인 사전 학습 클래스[[generic-pretraining-classes]]\n \n 다음 자동 클래스들은 사전 훈련 헤드가 포함된 모델을 인스턴스화하는 데 사용할 수 있습니다.\n@@ -94,14 +86,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForPreTraining\n \n-### TFAutoModelForPreTraining[[transformers.TFAutoModelForPreTraining]]\n-\n-[[autodoc]] TFAutoModelForPreTraining\n-\n-### FlaxAutoModelForPreTraining[[transformers.FlaxAutoModelForPreTraining]]\n-\n-[[autodoc]] FlaxAutoModelForPreTraining\n-\n ## 자연어 처리[[natural-language-processing]]\n \n 다음 자동 클래스들은 아래의 자연어 처리 작업에 사용할 수 있습니다.\n@@ -110,114 +94,42 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForCausalLM\n \n-### TFAutoModelForCausalLM[[transformers.TFAutoModelForCausalLM]]\n-\n-[[autodoc]] TFAutoModelForCausalLM\n-\n-### FlaxAutoModelForCausalLM[[transformers.FlaxAutoModelForCausalLM]]\n-\n-[[autodoc]] FlaxAutoModelForCausalLM\n-\n ### AutoModelForMaskedLM[[transformers.AutoModelForMaskedLM]]\n \n [[autodoc]] AutoModelForMaskedLM\n \n-### TFAutoModelForMaskedLM[[transformers.TFAutoModelForMaskedLM]]\n-\n-[[autodoc]] TFAutoModelForMaskedLM\n-\n-### FlaxAutoModelForMaskedLM[[transformers.FlaxAutoModelForMaskedLM]]\n-\n-[[autodoc]] FlaxAutoModelForMaskedLM\n-\n ### AutoModelForMaskGeneration[[transformers.AutoModelForMaskGeneration]]\n \n [[autodoc]] AutoModelForMaskGeneration\n \n-### TFAutoModelForMaskGeneration[[transformers.TFAutoModelForMaskGeneration]]\n-\n-[[autodoc]] TFAutoModelForMaskGeneration\n-\n ### AutoModelForSeq2SeqLM[[transformers.AutoModelForSeq2SeqLM]]\n \n [[autodoc]] AutoModelForSeq2SeqLM\n \n-### TFAutoModelForSeq2SeqLM[[transformers.TFAutoModelForSeq2SeqLM]]\n-\n-[[autodoc]] TFAutoModelForSeq2SeqLM\n-\n-### FlaxAutoModelForSeq2SeqLM[[transformers.FlaxAutoModelForSeq2SeqLM]]\n-\n-[[autodoc]] FlaxAutoModelForSeq2SeqLM\n-\n ### AutoModelForSequenceClassification[[transformers.AutoModelForSequenceClassification]]\n \n [[autodoc]] AutoModelForSequenceClassification\n \n-### TFAutoModelForSequenceClassification[[transformers.TFAutoModelForSequenceClassification]]\n-\n-[[autodoc]] TFAutoModelForSequenceClassification\n-\n-### FlaxAutoModelForSequenceClassification[[transformers.FlaxAutoModelForSequenceClassification]]\n-\n-[[autodoc]] FlaxAutoModelForSequenceClassification\n-\n ### AutoModelForMultipleChoice[[transformers.AutoModelForMultipleChoice]]\n \n [[autodoc]] AutoModelForMultipleChoice\n \n-### TFAutoModelForMultipleChoice[[transformers.TFAutoModelForMultipleChoice]]\n-\n-[[autodoc]] TFAutoModelForMultipleChoice\n-\n-### FlaxAutoModelForMultipleChoice[[transformers.FlaxAutoModelForMultipleChoice]]\n-\n-[[autodoc]] FlaxAutoModelForMultipleChoice\n-\n ### AutoModelForNextSentencePrediction[[transformers.AutoModelForNextSentencePrediction]]\n \n [[autodoc]] AutoModelForNextSentencePrediction\n \n-### TFAutoModelForNextSentencePrediction[[transformers.TFAutoModelForNextSentencePrediction]]\n-\n-[[autodoc]] TFAutoModelForNextSentencePrediction\n-\n-### FlaxAutoModelForNextSentencePrediction[[transformers.FlaxAutoModelForNextSentencePrediction]]\n-\n-[[autodoc]] FlaxAutoModelForNextSentencePrediction\n-\n ### AutoModelForTokenClassification[[transformers.AutoModelForTokenClassification]]\n \n [[autodoc]] AutoModelForTokenClassification\n \n-### TFAutoModelForTokenClassification[[transformers.TFAutoModelForTokenClassification]]\n-\n-[[autodoc]] TFAutoModelForTokenClassification\n-\n-### FlaxAutoModelForTokenClassification[[transformers.FlaxAutoModelForTokenClassification]]\n-\n-[[autodoc]] FlaxAutoModelForTokenClassification\n-\n ### AutoModelForQuestionAnswering[[transformers.AutoModelForQuestionAnswering]]\n \n [[autodoc]] AutoModelForQuestionAnswering\n \n-### TFAutoModelForQuestionAnswering[[transformers.TFAutoModelForQuestionAnswering]]\n-\n-[[autodoc]] TFAutoModelForQuestionAnswering\n-\n-### FlaxAutoModelForQuestionAnswering[[transformers.FlaxAutoModelForQuestionAnswering]]\n-\n-[[autodoc]] FlaxAutoModelForQuestionAnswering\n-\n ### AutoModelForTextEncoding[[transformers.AutoModelForTextEncoding]]\n \n [[autodoc]] AutoModelForTextEncoding\n \n-### TFAutoModelForTextEncoding[[transformers.TFAutoModelForTextEncoding]]\n-\n-[[autodoc]] TFAutoModelForTextEncoding\n-\n ## 컴퓨터 비전[[computer-vision]]\n \n 다음 자동 클래스들은 아래의 컴퓨터 비전 작업에 사용할 수 있습니다.\n@@ -230,14 +142,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForImageClassification\n \n-### TFAutoModelForImageClassification[[transformers.TFAutoModelForImageClassification]]\n-\n-[[autodoc]] TFAutoModelForImageClassification\n-\n-### FlaxAutoModelForImageClassification[[transformers.FlaxAutoModelForImageClassification]]\n-\n-[[autodoc]] FlaxAutoModelForImageClassification\n-\n ### AutoModelForVideoClassification[[transformers.AutoModelForVideoClassification]]\n \n [[autodoc]] AutoModelForVideoClassification\n@@ -250,10 +154,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForMaskedImageModeling\n \n-### TFAutoModelForMaskedImageModeling[[transformers.TFAutoModelForMaskedImageModeling]]\n-\n-[[autodoc]] TFAutoModelForMaskedImageModeling\n-\n ### AutoModelForObjectDetection[[transformers.AutoModelForObjectDetection]]\n \n [[autodoc]] AutoModelForObjectDetection\n@@ -270,10 +170,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForSemanticSegmentation\n \n-### TFAutoModelForSemanticSegmentation[[transformers.TFAutoModelForSemanticSegmentation]]\n-\n-[[autodoc]] TFAutoModelForSemanticSegmentation\n-\n ### AutoModelForInstanceSegmentation[[transformers.AutoModelForInstanceSegmentation]]\n \n [[autodoc]] AutoModelForInstanceSegmentation\n@@ -286,10 +182,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForZeroShotImageClassification\n \n-### TFAutoModelForZeroShotImageClassification[[transformers.TFAutoModelForZeroShotImageClassification]]\n-\n-[[autodoc]] TFAutoModelForZeroShotImageClassification\n-\n ### AutoModelForZeroShotObjectDetection[[transformers.AutoModelForZeroShotObjectDetection]]\n \n [[autodoc]] AutoModelForZeroShotObjectDetection\n@@ -302,10 +194,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForAudioClassification\n \n-### TFAutoModelForAudioClassification[[transformers.TFAutoModelForAudioClassification]]\n-\n-[[autodoc]] TFAutoModelForAudioClassification\n-\n ### AutoModelForAudioFrameClassification[[transformers.AutoModelForAudioFrameClassification]]\n \n [[autodoc]] AutoModelForAudioFrameClassification\n@@ -318,14 +206,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForSpeechSeq2Seq\n \n-### TFAutoModelForSpeechSeq2Seq[[transformers.TFAutoModelForSpeechSeq2Seq]]\n-\n-[[autodoc]] TFAutoModelForSpeechSeq2Seq\n-\n-### FlaxAutoModelForSpeechSeq2Seq[[transformers.FlaxAutoModelForSpeechSeq2Seq]]\n-\n-[[autodoc]] FlaxAutoModelForSpeechSeq2Seq\n-\n ### AutoModelForAudioXVector[[transformers.AutoModelForAudioXVector]]\n \n [[autodoc]] AutoModelForAudioXVector\n@@ -346,18 +226,10 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForTableQuestionAnswering\n \n-### TFAutoModelForTableQuestionAnswering[[transformers.TFAutoModelForTableQuestionAnswering]]\n-\n-[[autodoc]] TFAutoModelForTableQuestionAnswering\n-\n ### AutoModelForDocumentQuestionAnswering[[transformers.AutoModelForDocumentQuestionAnswering]]\n \n [[autodoc]] AutoModelForDocumentQuestionAnswering\n \n-### TFAutoModelForDocumentQuestionAnswering[[transformers.TFAutoModelForDocumentQuestionAnswering]]\n-\n-[[autodoc]] TFAutoModelForDocumentQuestionAnswering\n-\n ### AutoModelForVisualQuestionAnswering[[transformers.AutoModelForVisualQuestionAnswering]]\n \n [[autodoc]] AutoModelForVisualQuestionAnswering\n@@ -366,14 +238,6 @@ AutoModel.register(NewModelConfig, NewModel)\n \n [[autodoc]] AutoModelForVision2Seq\n \n-### TFAutoModelForVision2Seq[[transformers.TFAutoModelForVision2Seq]]\n-\n-[[autodoc]] TFAutoModelForVision2Seq\n-\n-### FlaxAutoModelForVision2Seq[[transformers.FlaxAutoModelForVision2Seq]]\n-\n-[[autodoc]] FlaxAutoModelForVision2Seq\n-\n ## Time Series\n \n ### AutoModelForTimeSeriesPrediction[[transformers.AutoModelForTimeSeriesPrediction]]"
        },
        {
            "sha": "6e76a78484e3d596741173008ddfffbb34ea6457",
            "filename": "docs/source/ko/model_doc/bart.md",
            "status": "modified",
            "additions": 0,
            "deletions": 53,
            "changes": 53,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fbart.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fbart.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fbart.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -158,59 +158,6 @@ BART를 시작하는 데 도움이 되는 Hugging Face와 community 자료 목\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFBartModel[[transformers.TFBartModel]]\n-\n-[[autodoc]] TFBartModel\n-    - call\n-\n-## TFBartForConditionalGeneration[[transformers.TFBartForConditionalGeneration]]\n-\n-[[autodoc]] TFBartForConditionalGeneration\n-    - call\n-\n-## TFBartForSequenceClassification[[transformers.TFBartForSequenceClassification]]\n-\n-[[autodoc]] TFBartForSequenceClassification\n-    - call\n-\n-</tf>\n-<jax>\n-\n-## FlaxBartModel[[transformers.FlaxBartModel]]\n-\n-[[autodoc]] FlaxBartModel\n-    - __call__\n-    - encode\n-    - decode\n-\n-## FlaxBartForConditionalGeneration[[transformers.FlaxBartForConditionalGeneration]]\n-\n-[[autodoc]] FlaxBartForConditionalGeneration\n-    - __call__\n-    - encode\n-    - decode\n-\n-## FlaxBartForSequenceClassification[[transformers.FlaxBartForSequenceClassification]]\n-\n-[[autodoc]] FlaxBartForSequenceClassification\n-    - __call__\n-    - encode\n-    - decode\n-\n-## FlaxBartForQuestionAnswering[[transformers.FlaxBartForQuestionAnswering]]\n-\n-[[autodoc]] FlaxBartForQuestionAnswering\n-    - __call__\n-    - encode\n-    - decode\n-\n-## FlaxBartForCausalLM[[transformers.FlaxBartForCausalLM]]\n-\n-[[autodoc]] FlaxBartForCausalLM\n-    - __call__\n-</jax>\n </frameworkcontent>\n \n "
        },
        {
            "sha": "b08c81459a0238051b2bc5836d8af0fc9bd0ad40",
            "filename": "docs/source/ko/model_doc/bert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 108,
            "changes": 108,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fbert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fbert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fbert.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -172,24 +172,12 @@ BERT를 시작하는 데 도움이 되는 Hugging Face와 community 자료 목\n [[autodoc]] BertTokenizerFast\n \n </pt>\n-<tf>\n-\n-## TFBertTokenizer\n-\n-[[autodoc]] TFBertTokenizer\n-\n-</tf>\n </frameworkcontent>\n \n ## Bert specific outputs\n \n [[autodoc]] models.bert.modeling_bert.BertForPreTrainingOutput\n \n-[[autodoc]] models.bert.modeling_tf_bert.TFBertForPreTrainingOutput\n-\n-[[autodoc]] models.bert.modeling_flax_bert.FlaxBertForPreTrainingOutput\n-\n-\n <frameworkcontent>\n <pt>\n \n@@ -239,102 +227,6 @@ BERT를 시작하는 데 도움이 되는 Hugging Face와 community 자료 목\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFBertModel\n-\n-[[autodoc]] TFBertModel\n-    - call\n-\n-## TFBertForPreTraining\n-\n-[[autodoc]] TFBertForPreTraining\n-    - call\n-\n-## TFBertModelLMHeadModel\n-\n-[[autodoc]] TFBertLMHeadModel\n-    - call\n-\n-## TFBertForMaskedLM\n-\n-[[autodoc]] TFBertForMaskedLM\n-    - call\n-\n-## TFBertForNextSentencePrediction\n-\n-[[autodoc]] TFBertForNextSentencePrediction\n-    - call\n-\n-## TFBertForSequenceClassification\n-\n-[[autodoc]] TFBertForSequenceClassification\n-    - call\n-\n-## TFBertForMultipleChoice\n-\n-[[autodoc]] TFBertForMultipleChoice\n-    - call\n-\n-## TFBertForTokenClassification\n-\n-[[autodoc]] TFBertForTokenClassification\n-    - call\n-\n-## TFBertForQuestionAnswering\n-\n-[[autodoc]] TFBertForQuestionAnswering\n-    - call\n-\n-</tf>\n-<jax>\n-\n-## FlaxBertModel\n-\n-[[autodoc]] FlaxBertModel\n-    - __call__\n-\n-## FlaxBertForPreTraining\n-\n-[[autodoc]] FlaxBertForPreTraining\n-    - __call__\n-\n-## FlaxBertForCausalLM\n-\n-[[autodoc]] FlaxBertForCausalLM\n-    - __call__\n-\n-## FlaxBertForMaskedLM\n-\n-[[autodoc]] FlaxBertForMaskedLM\n-    - __call__\n-\n-## FlaxBertForNextSentencePrediction\n-\n-[[autodoc]] FlaxBertForNextSentencePrediction\n-    - __call__\n-\n-## FlaxBertForSequenceClassification\n-\n-[[autodoc]] FlaxBertForSequenceClassification\n-    - __call__\n-\n-## FlaxBertForMultipleChoice\n-\n-[[autodoc]] FlaxBertForMultipleChoice\n-    - __call__\n-\n-## FlaxBertForTokenClassification\n-\n-[[autodoc]] FlaxBertForTokenClassification\n-    - __call__\n-\n-## FlaxBertForQuestionAnswering\n-\n-[[autodoc]] FlaxBertForQuestionAnswering\n-    - __call__\n-\n-</jax>\n </frameworkcontent>\n \n "
        },
        {
            "sha": "8e88884a793aa72447a0f10f958e33efb707731e",
            "filename": "docs/source/ko/model_doc/blip.md",
            "status": "modified",
            "additions": 0,
            "deletions": 34,
            "changes": 34,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fblip.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fblip.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fblip.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -99,38 +99,4 @@ BLIP은 여러 멀티모달 작업을 수행할 수 있는 모델입니다:\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFBlipModel[[transformers.TFBlipModel]]\n-\n-[[autodoc]] TFBlipModel\n-    - call\n-    - get_text_features\n-    - get_image_features\n-\n-## TFBlipTextModel[[transformers.TFBlipTextModel]]\n-\n-[[autodoc]] TFBlipTextModel\n-    - call\n-\n-## TFBlipVisionModel[[transformers.TFBlipVisionModel]]\n-\n-[[autodoc]] TFBlipVisionModel\n-    - call\n-\n-## TFBlipForConditionalGeneration[[transformers.TFBlipForConditionalGeneration]]\n-\n-[[autodoc]] TFBlipForConditionalGeneration\n-    - call\n-\n-## TFBlipForImageTextRetrieval[[transformers.TFBlipForImageTextRetrieval]]\n-\n-[[autodoc]] TFBlipForImageTextRetrieval\n-    - call\n-\n-## TFBlipForQuestionAnswering[[transformers.TFBlipForQuestionAnswering]]\n-\n-[[autodoc]] TFBlipForQuestionAnswering\n-    - call\n-</tf>\n </frameworkcontent>"
        },
        {
            "sha": "b9517cea17df42f58d96f04e73fdc7d18241a62a",
            "filename": "docs/source/ko/model_doc/clip.md",
            "status": "modified",
            "additions": 0,
            "deletions": 45,
            "changes": 45,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fclip.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fclip.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fclip.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -270,49 +270,4 @@ CLIP을 시작하는 데 도움이 되는 Hugging Face와 community 자료 목\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFCLIPModel[[transformers.TFCLIPModel]]\n-\n-[[autodoc]] TFCLIPModel\n-    - call\n-    - get_text_features\n-    - get_image_features\n-\n-## TFCLIPTextModel[[transformers.TFCLIPTextModel]]\n-\n-[[autodoc]] TFCLIPTextModel\n-    - call\n-\n-## TFCLIPVisionModel[[transformers.TFCLIPVisionModel]]\n-\n-[[autodoc]] TFCLIPVisionModel\n-    - call\n-\n-</tf>\n-<jax>\n-\n-## FlaxCLIPModel[[transformers.FlaxCLIPModel]]\n-\n-[[autodoc]] FlaxCLIPModel\n-    - __call__\n-    - get_text_features\n-    - get_image_features\n-\n-## FlaxCLIPTextModel[[transformers.FlaxCLIPTextModel]]\n-\n-[[autodoc]] FlaxCLIPTextModel\n-    - __call__\n-\n-## FlaxCLIPTextModelWithProjection[[transformers.FlaxCLIPTextModelWithProjection]]\n-\n-[[autodoc]] FlaxCLIPTextModelWithProjection\n-    - __call__\n-\n-## FlaxCLIPVisionModel[[transformers.FlaxCLIPVisionModel]]\n-\n-[[autodoc]] FlaxCLIPVisionModel\n-    - __call__\n-\n-</jax>\n </frameworkcontent>"
        },
        {
            "sha": "6bbac5b4227203b99f6e0273a26fe94e44133cb5",
            "filename": "docs/source/ko/model_doc/convbert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 33,
            "changes": 33,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fconvbert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fconvbert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fconvbert.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -99,37 +99,4 @@ ConvBERT 훈련 팁은 BERT와 유사합니다. 사용 팁은 [BERT 문서](bert\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFConvBertModel [[transformers.TFConvBertModel]]\n-\n-[[autodoc]] TFConvBertModel\n-    - call\n-\n-## TFConvBertForMaskedLM [[transformers.TFConvBertForMaskedLM]]\n-\n-[[autodoc]] TFConvBertForMaskedLM \n-    - call\n-\n-## TFConvBertForSequenceClassification [[transformers.TFConvBertForSequenceClassification]]\n-\n-[[autodoc]] TFConvBertForSequenceClassification\n-    - call\n-\n-## TFConvBertForMultipleChoice [[transformers.TFConvBertForMultipleChoice]]\n-\n-[[autodoc]] TFConvBertForMultipleChoice\n-    - call\n-\n-## TFConvBertForTokenClassification [[transformers.TFConvBertForTokenClassification]]\n-\n-[[autodoc]] TFConvBertForTokenClassification\n-    - call\n-\n-## TFConvBertForQuestionAnswering [[transformers.TFConvBertForQuestionAnswering]]\n-\n-[[autodoc]] TFConvBertForQuestionAnswering\n-    - call\n-\n-</tf>\n </frameworkcontent>"
        },
        {
            "sha": "254b183a57364619a4fddbe70a49d6f6fd905bdf",
            "filename": "docs/source/ko/model_doc/deberta-v2.md",
            "status": "modified",
            "additions": 0,
            "deletions": 38,
            "changes": 38,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fdeberta-v2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fdeberta-v2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fdeberta-v2.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -106,42 +106,4 @@ v2의 새로운 점:\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFDebertaV2Model\n-\n-[[autodoc]] TFDebertaV2Model\n-    - call\n-\n-## TFDebertaV2PreTrainedModel\n-\n-[[autodoc]] TFDebertaV2PreTrainedModel\n-    - call\n-\n-## TFDebertaV2ForMaskedLM\n-\n-[[autodoc]] TFDebertaV2ForMaskedLM\n-    - call\n-\n-## TFDebertaV2ForSequenceClassification\n-\n-[[autodoc]] TFDebertaV2ForSequenceClassification\n-    - call\n-\n-## TFDebertaV2ForTokenClassification\n-\n-[[autodoc]] TFDebertaV2ForTokenClassification\n-    - call\n-\n-## TFDebertaV2ForQuestionAnswering\n-\n-[[autodoc]] TFDebertaV2ForQuestionAnswering\n-    - call\n-\n-## TFDebertaV2ForMultipleChoice\n-\n-[[autodoc]] TFDebertaV2ForMultipleChoice\n-    - call\n-\n-</tf>\n </frameworkcontent>"
        },
        {
            "sha": "b76912197f1ee4a3da1f5e64ec673553d2106adf",
            "filename": "docs/source/ko/model_doc/deberta.md",
            "status": "modified",
            "additions": 0,
            "deletions": 33,
            "changes": 33,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fdeberta.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fdeberta.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fdeberta.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -115,38 +115,5 @@ DeBERTa를 시작하는 데 도움이 되는 Hugging Face와 community 자료 \n     - forward\n \n </pt>\n-<tf>\n-\n-## TFDebertaModel[[transformers.TFDebertaModel]]\n-\n-[[autodoc]] TFDebertaModel\n-    - call\n-\n-## TFDebertaPreTrainedModel[[transformers.TFDebertaPreTrainedModel]]\n-\n-[[autodoc]] TFDebertaPreTrainedModel\n-    - call\n-\n-## TFDebertaForMaskedLM[[transformers.TFDebertaForMaskedLM]]\n-\n-[[autodoc]] TFDebertaForMaskedLM\n-    - call\n-\n-## TFDebertaForSequenceClassification[[transformers.TFDebertaForSequenceClassification]]\n-\n-[[autodoc]] TFDebertaForSequenceClassification\n-    - call\n-\n-## TFDebertaForTokenClassification[[transformers.TFDebertaForTokenClassification]]\n-\n-[[autodoc]] TFDebertaForTokenClassification\n-    - call\n-\n-## TFDebertaForQuestionAnswering[[transformers.TFDebertaForQuestionAnswering]]\n-\n-[[autodoc]] TFDebertaForQuestionAnswering\n-    - call\n-\n-</tf>\n </frameworkcontent>\n "
        },
        {
            "sha": "e9e1879e13dc7917910a0c8551946fa96b459f4b",
            "filename": "docs/source/ko/model_doc/electra.md",
            "status": "modified",
            "additions": 0,
            "deletions": 83,
            "changes": 83,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Felectra.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Felectra.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Felectra.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -66,8 +66,6 @@ Generators](https://openreview.net/pdf?id=r1xMH1BtvB) 논문에서 제안되었\n \n [[autodoc]] models.electra.modeling_electra.ElectraForPreTrainingOutput\n \n-[[autodoc]] models.electra.modeling_tf_electra.TFElectraForPreTrainingOutput\n-\n <frameworkcontent>\n <pt>\n \n@@ -112,85 +110,4 @@ Generators](https://openreview.net/pdf?id=r1xMH1BtvB) 논문에서 제안되었\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFElectraModel\n-\n-[[autodoc]] TFElectraModel\n-    - call\n-\n-## TFElectraForPreTraining\n-\n-[[autodoc]] TFElectraForPreTraining\n-    - call\n-\n-## TFElectraForMaskedLM\n-\n-[[autodoc]] TFElectraForMaskedLM\n-    - call\n-\n-## TFElectraForSequenceClassification\n-\n-[[autodoc]] TFElectraForSequenceClassification\n-    - call\n-\n-## TFElectraForMultipleChoice\n-\n-[[autodoc]] TFElectraForMultipleChoice\n-    - call\n-\n-## TFElectraForTokenClassification\n-\n-[[autodoc]] TFElectraForTokenClassification\n-    - call\n-\n-## TFElectraForQuestionAnswering\n-\n-[[autodoc]] TFElectraForQuestionAnswering\n-    - call\n-\n-</tf>\n-<jax>\n-\n-## FlaxElectraModel\n-\n-[[autodoc]] FlaxElectraModel\n-    - __call__\n-\n-## FlaxElectraForPreTraining\n-\n-[[autodoc]] FlaxElectraForPreTraining\n-    - __call__\n-\n-## FlaxElectraForCausalLM\n-\n-[[autodoc]] FlaxElectraForCausalLM\n-    - __call__\n-\n-## FlaxElectraForMaskedLM\n-\n-[[autodoc]] FlaxElectraForMaskedLM\n-    - __call__\n-\n-## FlaxElectraForSequenceClassification\n-\n-[[autodoc]] FlaxElectraForSequenceClassification\n-    - __call__\n-\n-## FlaxElectraForMultipleChoice\n-\n-[[autodoc]] FlaxElectraForMultipleChoice\n-    - __call__\n-\n-## FlaxElectraForTokenClassification\n-\n-[[autodoc]] FlaxElectraForTokenClassification\n-    - __call__\n-\n-## FlaxElectraForQuestionAnswering\n-\n-[[autodoc]] FlaxElectraForQuestionAnswering\n-    - __call__\n-\n-</jax>\n </frameworkcontent>"
        },
        {
            "sha": "9cea74aac10c2ce63038c2473b4a321179543295",
            "filename": "docs/source/ko/model_doc/encoder-decoder.md",
            "status": "modified",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fencoder-decoder.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fencoder-decoder.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fencoder-decoder.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -146,22 +146,4 @@ nearly 800 thousand customers were affected by the shutoffs. the aim is to reduc\n     - from_encoder_decoder_pretrained\n \n </pt>\n-<tf>\n-\n-## TFEncoderDecoderModel\n-\n-[[autodoc]] TFEncoderDecoderModel\n-    - call\n-    - from_encoder_decoder_pretrained\n-\n-</tf>\n-<jax>\n-\n-## FlaxEncoderDecoderModel\n-\n-[[autodoc]] FlaxEncoderDecoderModel\n-    - __call__\n-    - from_encoder_decoder_pretrained\n-\n-</jax>\n </frameworkcontent>"
        },
        {
            "sha": "89640d1366c4e5b25eea7fc321c192a5fe7bce64",
            "filename": "docs/source/ko/model_doc/esm.md",
            "status": "modified",
            "additions": 0,
            "deletions": 23,
            "changes": 23,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fesm.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fesm.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fesm.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -89,27 +89,4 @@ ESMFold는 [Matt](https://huggingface.co/Rocketknight1)와 [Sylvain](https://hug\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFEsmModel [[transformers.TFEsmModel]]\n-\n-[[autodoc]] TFEsmModel\n-    - call\n-\n-## TFEsmForMaskedLM [[transformers.TFEsmForMaskedLM]]\n-\n-[[autodoc]] TFEsmForMaskedLM\n-    - call\n-\n-## TFEsmForSequenceClassification [[transformers.TFEsmForSequenceClassification]]\n-\n-[[autodoc]] TFEsmForSequenceClassification\n-    - call\n-\n-## TFEsmForTokenClassification [[transformers.TFEsmForTokenClassification]]\n-\n-[[autodoc]] TFEsmForTokenClassification\n-    - call\n-\n-</tf>\n </frameworkcontent>"
        },
        {
            "sha": "2b2297eea56ff57e9d5255d876ac4de2eb89f0cf",
            "filename": "docs/source/ko/model_doc/gemma.md",
            "status": "modified",
            "additions": 0,
            "deletions": 10,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fgemma.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fgemma.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fgemma.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -64,13 +64,3 @@ Gemma 모델은 6조 토큰으로 학습되었으며, 2b와 7b의 두 가지 버\n \n [[autodoc]] GemmaForTokenClassification\n     - forward\n-\n-## FlaxGemmaModel [[transformers.FlaxGemmaModel]]\n-\n-[[autodoc]] FlaxGemmaModel\n-    - __call__\n-\n-## FlaxGemmaForCausalLM [[transformers.FlaxGemmaForCausalLM]]\n-\n-[[autodoc]] FlaxGemmaForCausalLM\n-    - __call__"
        },
        {
            "sha": "56650243f9faa5c0b9f95277d212068ee60321b7",
            "filename": "docs/source/ko/model_doc/gpt2.md",
            "status": "modified",
            "additions": 0,
            "deletions": 46,
            "changes": 46,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fgpt2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fgpt2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fgpt2.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -136,8 +136,6 @@ print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n \n [[autodoc]] models.gpt2.modeling_gpt2.GPT2DoubleHeadsModelOutput\n \n-[[autodoc]] models.gpt2.modeling_tf_gpt2.TFGPT2DoubleHeadsModelOutput\n-\n <frameworkcontent>\n <pt>\n \n@@ -172,48 +170,4 @@ print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFGPT2Model\n-\n-[[autodoc]] TFGPT2Model\n-    - call\n-\n-## TFGPT2LMHeadModel\n-\n-[[autodoc]] TFGPT2LMHeadModel\n-    - call\n-\n-## TFGPT2DoubleHeadsModel\n-\n-[[autodoc]] TFGPT2DoubleHeadsModel\n-    - call\n-\n-## TFGPT2ForSequenceClassification\n-\n-[[autodoc]] TFGPT2ForSequenceClassification\n-    - call\n-\n-## TFSequenceClassifierOutputWithPast\n-\n-[[autodoc]] modeling_tf_outputs.TFSequenceClassifierOutputWithPast\n-\n-## TFGPT2Tokenizer\n-\n-[[autodoc]] TFGPT2Tokenizer\n-\n-</tf>\n-<jax>\n-\n-## FlaxGPT2Model\n-\n-[[autodoc]] FlaxGPT2Model\n-    - __call__\n-\n-## FlaxGPT2LMHeadModel\n-\n-[[autodoc]] FlaxGPT2LMHeadModel\n-    - __call__\n-\n-</jax>\n </frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "c978e2df6df07c7fbd9fc841061b23eef1fb86a7",
            "filename": "docs/source/ko/model_doc/marian.md",
            "status": "modified",
            "additions": 0,
            "deletions": 26,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fmarian.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fmarian.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fmarian.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -188,30 +188,4 @@ GROUP_MEMBERS = {\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFMarianModel\n-\n-[[autodoc]] TFMarianModel\n-    - call\n-\n-## TFMarianMTModel\n-\n-[[autodoc]] TFMarianMTModel\n-    - call\n-\n-</tf>\n-<jax>\n-\n-## FlaxMarianModel\n-\n-[[autodoc]] FlaxMarianModel\n-    - __call__\n-\n-## FlaxMarianMTModel\n-\n-[[autodoc]] FlaxMarianMTModel\n-    - __call__\n-\n-</jax>\n </frameworkcontent>"
        },
        {
            "sha": "74de49f5df791bf9ecf693922146033f05cc5a08",
            "filename": "docs/source/ko/model_doc/mistral.md",
            "status": "modified",
            "additions": 0,
            "deletions": 25,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fmistral.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fmistral.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fmistral.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -206,28 +206,3 @@ pip install -U flash-attn --no-build-isolation\n \n [[autodoc]] MistralForTokenClassification\n     - forward\n-\n-## FlaxMistralModel[[transformers.FlaxMistralModel]]\n-\n-[[autodoc]] FlaxMistralModel\n-    - __call__\n-\n-## FlaxMistralForCausalLM[[transformers.FlaxMistralForCausalLM]]\n-\n-[[autodoc]] FlaxMistralForCausalLM\n-    - __call__\n-\n-## TFMistralModel[[transformers.TFMistralModel]]\n-\n-[[autodoc]] TFMistralModel\n-    - call\n-\n-## TFMistralForCausalLM[[transformers.TFMistralForCausalLM]]\n-\n-[[autodoc]] TFMistralForCausalLM\n-    - call\n-\n-## TFMistralForSequenceClassification[[transformers.TFMistralForSequenceClassification]]\n-\n-[[autodoc]] TFMistralForSequenceClassification\n-    - call"
        },
        {
            "sha": "679bf0783c81414efe34c5104c9d669c6103abca",
            "filename": "docs/source/ko/model_doc/openai-gpt.md",
            "status": "modified",
            "additions": 0,
            "deletions": 25,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fopenai-gpt.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fopenai-gpt.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fopenai-gpt.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -97,8 +97,6 @@ OpenAI GPT를 시작하는 데 도움이 되는 공식 Hugging Face 및 커뮤\n \n [[autodoc]] models.openai.modeling_openai.OpenAIGPTDoubleHeadsModelOutput\n \n-[[autodoc]] models.openai.modeling_tf_openai.TFOpenAIGPTDoubleHeadsModelOutput\n-\n <frameworkcontent>\n <pt>\n \n@@ -123,27 +121,4 @@ OpenAI GPT를 시작하는 데 도움이 되는 공식 Hugging Face 및 커뮤\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFOpenAIGPTModel [[transformers.TFOpenAIGPTModel]]\n-\n-[[autodoc]] TFOpenAIGPTModel\n-    - call\n-\n-## TFOpenAIGPTLMHeadModel [[transformers.TFOpenAIGPTLMHeadModel]]\n-\n-[[autodoc]] TFOpenAIGPTLMHeadModel\n-    - call\n-\n-## TFOpenAIGPTDoubleHeadsModel [[transformers.TFOpenAIGPTDoubleHeadsModel]]\n-\n-[[autodoc]] TFOpenAIGPTDoubleHeadsModel\n-    - call\n-\n-## TFOpenAIGPTForSequenceClassification [[transformers.TFOpenAIGPTForSequenceClassification]]\n-\n-[[autodoc]] TFOpenAIGPTForSequenceClassification\n-    - call\n-\n-</tf>\n </frameworkcontent>"
        },
        {
            "sha": "cb670a54ee9a0eb798612a4354a8de99ca959316",
            "filename": "docs/source/ko/model_doc/rag.md",
            "status": "modified",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Frag.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Frag.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Frag.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -77,24 +77,4 @@ rendered properly in your Markdown viewer.\n     - generate\n \n </pt>\n-<tf>\n-\n-## TFRagModel [[transformers.TFRagModel]]\n-\n-[[autodoc]] TFRagModel\n-    - call\n-\n-## TFRagSequenceForGeneration [[transformers.TFRagSequenceForGeneration]]\n-\n-[[autodoc]] TFRagSequenceForGeneration\n-    - call\n-    - generate\n-\n-## TFRagTokenForGeneration [[transformers.TFRagTokenForGeneration]]\n-\n-[[autodoc]] TFRagTokenForGeneration\n-    - call\n-    - generate\n-\n-</tf>\n </frameworkcontent>"
        },
        {
            "sha": "6588ff62e264de56bd0996c7b08a1d563b168646",
            "filename": "docs/source/ko/model_doc/roberta.md",
            "status": "modified",
            "additions": 0,
            "deletions": 76,
            "changes": 76,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Froberta.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Froberta.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Froberta.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -151,80 +151,4 @@ RoBERTa를 처음 다룰 때 도움이 되는 Hugging Face 공식 자료와 커\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFRobertaModel\n-\n-[[autodoc]] TFRobertaModel\n-    - call\n-\n-## TFRobertaForCausalLM\n-\n-[[autodoc]] TFRobertaForCausalLM\n-    - call\n-\n-## TFRobertaForMaskedLM\n-\n-[[autodoc]] TFRobertaForMaskedLM\n-    - call\n-\n-## TFRobertaForSequenceClassification\n-\n-[[autodoc]] TFRobertaForSequenceClassification\n-    - call\n-\n-## TFRobertaForMultipleChoice\n-\n-[[autodoc]] TFRobertaForMultipleChoice\n-    - call\n-\n-## TFRobertaForTokenClassification\n-\n-[[autodoc]] TFRobertaForTokenClassification\n-    - call\n-\n-## TFRobertaForQuestionAnswering\n-\n-[[autodoc]] TFRobertaForQuestionAnswering\n-    - call\n-\n-</tf>\n-<jax>\n-\n-## FlaxRobertaModel\n-\n-[[autodoc]] FlaxRobertaModel\n-    - __call__\n-\n-## FlaxRobertaForCausalLM\n-\n-[[autodoc]] FlaxRobertaForCausalLM\n-    - __call__\n-\n-## FlaxRobertaForMaskedLM\n-\n-[[autodoc]] FlaxRobertaForMaskedLM\n-    - __call__\n-\n-## FlaxRobertaForSequenceClassification\n-\n-[[autodoc]] FlaxRobertaForSequenceClassification\n-    - __call__\n-\n-## FlaxRobertaForMultipleChoice\n-\n-[[autodoc]] FlaxRobertaForMultipleChoice\n-    - __call__\n-\n-## FlaxRobertaForTokenClassification\n-\n-[[autodoc]] FlaxRobertaForTokenClassification\n-    - __call__\n-\n-## FlaxRobertaForQuestionAnswering\n-\n-[[autodoc]] FlaxRobertaForQuestionAnswering\n-    - __call__\n-\n-</jax>\n </frameworkcontent>"
        },
        {
            "sha": "48ffdcc9cb2b343c9979befb5e9e7aaec35f8315",
            "filename": "docs/source/ko/model_doc/swin.md",
            "status": "modified",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fswin.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fswin.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fswin.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -74,22 +74,4 @@ Swin Transformer의 사용을 도울 수 있는 Hugging Face 및 커뮤니티(\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFSwinModel [[transformers.TFSwinModel]]\n-\n-[[autodoc]] TFSwinModel\n-    - call\n-\n-## TFSwinForMaskedImageModeling [[transformers.TFSwinForMaskedImageModeling]]\n-\n-[[autodoc]] TFSwinForMaskedImageModeling\n-    - call\n-\n-## TFSwinForImageClassification [[transformers.TFSwinForImageClassification]]\n-\n-[[autodoc]] transformers.TFSwinForImageClassification\n-    - call\n-\n-</tf>\n </frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "7d6d54093a668cc2f837b79f12a17bd71e65d877",
            "filename": "docs/source/ko/model_doc/vit.md",
            "status": "modified",
            "additions": 0,
            "deletions": 26,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fvit.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fvit.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fvit.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -143,30 +143,4 @@ ViT의 추론 및 커스텀 데이터에 대한 미세 조정과 관련된 데\n     - forward\n \n </pt>\n-<tf>\n-\n-## TFViTModel [[transformers.TFViTModel]]\n-\n-[[autodoc]] TFViTModel\n-    - call\n-\n-## TFViTForImageClassification [[transformers.TFViTForImageClassification]]\n-\n-[[autodoc]] TFViTForImageClassification\n-    - call\n-\n-</tf>\n-<jax>\n-\n-## FlaxVitModel [[transformers.FlaxViTModel]]\n-\n-[[autodoc]] FlaxViTModel\n-    - __call__\n-\n-## FlaxViTForImageClassification [[transformers.FlaxViTForImageClassification]]\n-\n-[[autodoc]] FlaxViTForImageClassification\n-    - __call__\n-\n-</jax>\n </frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "fc3fb51f51a6b721fbd0f5a039bca51c1cdd44e4",
            "filename": "docs/source/ko/model_doc/whisper.md",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fwhisper.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fko%2Fmodel_doc%2Fwhisper.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fwhisper.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -98,31 +98,3 @@ python src/transformers/models/whisper/convert_openai_to_hf.py --checkpoint_path\n [[autodoc]] WhisperForAudioClassification\n     - forward\n \n-\n-\n-## TFWhisperModel [[tfwhispermodel]]\n-\n-[[autodoc]] TFWhisperModel\n-    - call\n-\n-## TFWhisperForConditionalGeneration [[tfwhisperforconditionalgeneration]]\n-\n-[[autodoc]] TFWhisperForConditionalGeneration\n-    - call\n-\n-\n-## FlaxWhisperModel [[flaxwhispermodel]]\n-\n-[[autodoc]] FlaxWhisperModel\n-    - __call__\n-\n-## FlaxWhisperForConditionalGeneration [[flaxwhisperforconditionalgeneration]]\n-\n-[[autodoc]] FlaxWhisperForConditionalGeneration\n-    - __call__\n-\n-## FlaxWhisperForAudioClassification [[flaxwhisperforaudioclassification]]\n-\n-[[autodoc]] FlaxWhisperForAudioClassification\n-    - __call__\n-"
        },
        {
            "sha": "282202cb79e16246fd50d36d41e8fd30c6724b15",
            "filename": "docs/source/zh/internal/generation_utils.md",
            "status": "modified",
            "additions": 0,
            "deletions": 118,
            "changes": 118,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fzh%2Finternal%2Fgeneration_utils.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fzh%2Finternal%2Fgeneration_utils.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Finternal%2Fgeneration_utils.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -69,36 +69,6 @@ generation_output[:2]\n \n [[autodoc]] generation.GenerateBeamEncoderDecoderOutput\n \n-### TensorFlow\n-\n-[[autodoc]] generation.TFGreedySearchEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFGreedySearchDecoderOnlyOutput\n-\n-[[autodoc]] generation.TFSampleEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFSampleDecoderOnlyOutput\n-\n-[[autodoc]] generation.TFBeamSearchEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFBeamSearchDecoderOnlyOutput\n-\n-[[autodoc]] generation.TFBeamSampleEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFBeamSampleDecoderOnlyOutput\n-\n-[[autodoc]] generation.TFContrastiveSearchEncoderDecoderOutput\n-\n-[[autodoc]] generation.TFContrastiveSearchDecoderOnlyOutput\n-\n-### FLAX\n-\n-[[autodoc]] generation.FlaxSampleOutput\n-\n-[[autodoc]] generation.FlaxGreedySearchOutput\n-\n-[[autodoc]] generation.FlaxBeamSearchOutput\n-\n ## LogitsProcessor\n \n [`LogitsProcessor`] 可以用于修改语言模型头的预测分数以进行生成\n@@ -190,94 +160,6 @@ generation_output[:2]\n [[autodoc]] WhisperTimeStampLogitsProcessor\n     - __call__\n \n-### TensorFlow\n-\n-[[autodoc]] TFForcedBOSTokenLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFForcedEOSTokenLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFForceTokensLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFLogitsProcessorList\n-    - __call__\n-\n-[[autodoc]] TFLogitsWarper\n-    - __call__\n-\n-[[autodoc]] TFMinLengthLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFNoBadWordsLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFNoRepeatNGramLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFRepetitionPenaltyLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFSuppressTokensAtBeginLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFSuppressTokensLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] TFTemperatureLogitsWarper\n-    - __call__\n-\n-[[autodoc]] TFTopKLogitsWarper\n-    - __call__\n-\n-[[autodoc]] TFTopPLogitsWarper\n-    - __call__\n-\n-### FLAX\n-\n-[[autodoc]] FlaxForcedBOSTokenLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxForcedEOSTokenLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxForceTokensLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxLogitsProcessorList\n-    - __call__\n-\n-[[autodoc]] FlaxLogitsWarper\n-    - __call__\n-\n-[[autodoc]] FlaxMinLengthLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxSuppressTokensAtBeginLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxSuppressTokensLogitsProcessor\n-    - __call__\n-\n-[[autodoc]] FlaxTemperatureLogitsWarper\n-    - __call__\n-\n-[[autodoc]] FlaxTopKLogitsWarper\n-    - __call__\n-\n-[[autodoc]] FlaxTopPLogitsWarper\n-    - __call__\n-\n-[[autodoc]] FlaxWhisperTimeStampLogitsProcessor\n-    - __call__\n-\n ## StoppingCriteria\n \n 可以使用[`StoppingCriteria`]来更改停止生成的时间（除了EOS token以外的方法）。请注意，这仅适用于我们的PyTorch实现。"
        },
        {
            "sha": "d83df64dff33d7ab440b410800291159c43f4d83",
            "filename": "docs/source/zh/internal/modeling_utils.md",
            "status": "modified",
            "additions": 0,
            "deletions": 27,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fzh%2Finternal%2Fmodeling_utils.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fzh%2Finternal%2Fmodeling_utils.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Finternal%2Fmodeling_utils.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -37,30 +37,3 @@ rendered properly in your Markdown viewer.\n \n [[autodoc]] pytorch_utils.prune_linear_layer\n \n-## TensorFlow自定义层\n-\n-[[autodoc]] modeling_tf_utils.TFConv1D\n-\n-[[autodoc]] modeling_tf_utils.TFSequenceSummary\n-\n-## TensorFlow loss 函数\n-\n-[[autodoc]] modeling_tf_utils.TFCausalLanguageModelingLoss\n-\n-[[autodoc]] modeling_tf_utils.TFMaskedLanguageModelingLoss\n-\n-[[autodoc]] modeling_tf_utils.TFMultipleChoiceLoss\n-\n-[[autodoc]] modeling_tf_utils.TFQuestionAnsweringLoss\n-\n-[[autodoc]] modeling_tf_utils.TFSequenceClassificationLoss\n-\n-[[autodoc]] modeling_tf_utils.TFTokenClassificationLoss\n-\n-## TensorFlow帮助函数\n-\n-[[autodoc]] modeling_tf_utils.get_initializer\n-\n-[[autodoc]] modeling_tf_utils.keras_serializable\n-\n-[[autodoc]] modeling_tf_utils.shape_list"
        },
        {
            "sha": "323b534640c15086392204c676a312a92717ac1e",
            "filename": "docs/source/zh/main_classes/model.md",
            "status": "modified",
            "additions": 0,
            "deletions": 13,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fzh%2Fmain_classes%2Fmodel.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fzh%2Fmain_classes%2Fmodel.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fmain_classes%2Fmodel.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -107,19 +107,6 @@ model = AutoModel.from_config(config)\n \n [[autodoc]] modeling_utils.ModuleUtilsMixin\n \n-TFPreTrainedModel\n-[[autodoc]] TFPreTrainedModel\n-    - push_to_hub\n-    - all\n-\n-## TFModelUtilsMixin\n-[[autodoc]] modeling_tf_utils.TFModelUtilsMixin\n-\n-FlaxPreTrainedModel\n-[[autodoc]] FlaxPreTrainedModel\n-    - push_to_hub\n-    - all\n-\n ## 推送到 Hub\n [[autodoc]] utils.PushToHubMixin\n "
        },
        {
            "sha": "23af6da6fbee4183b8374c4aa7f40a76b238fcfc",
            "filename": "docs/source/zh/main_classes/output.md",
            "status": "modified",
            "additions": 1,
            "deletions": 133,
            "changes": 134,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fzh%2Fmain_classes%2Foutput.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fzh%2Fmain_classes%2Foutput.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fmain_classes%2Foutput.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -174,136 +174,4 @@ outputs[:2]\n \n ## SampleTSPredictionOutput\n \n-[[autodoc]] modeling_outputs.SampleTSPredictionOutput\n-\n-## TFBaseModelOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutput\n-\n-## TFBaseModelOutputWithPooling\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutputWithPooling\n-\n-## TFBaseModelOutputWithPoolingAndCrossAttentions\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions\n-\n-## TFBaseModelOutputWithPast\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutputWithPast\n-\n-## TFBaseModelOutputWithPastAndCrossAttentions\n-\n-[[autodoc]] modeling_tf_outputs.TFBaseModelOutputWithPastAndCrossAttentions\n-\n-## TFSeq2SeqModelOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFSeq2SeqModelOutput\n-\n-## TFCausalLMOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFCausalLMOutput\n-\n-## TFCausalLMOutputWithCrossAttentions\n-\n-[[autodoc]] modeling_tf_outputs.TFCausalLMOutputWithCrossAttentions\n-\n-## TFCausalLMOutputWithPast\n-\n-[[autodoc]] modeling_tf_outputs.TFCausalLMOutputWithPast\n-\n-## TFMaskedLMOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFMaskedLMOutput\n-\n-## TFSeq2SeqLMOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFSeq2SeqLMOutput\n-\n-## TFNextSentencePredictorOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFNextSentencePredictorOutput\n-\n-## TFSequenceClassifierOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFSequenceClassifierOutput\n-\n-## TFSeq2SeqSequenceClassifierOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFSeq2SeqSequenceClassifierOutput\n-\n-## TFMultipleChoiceModelOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFMultipleChoiceModelOutput\n-\n-## TFTokenClassifierOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFTokenClassifierOutput\n-\n-## TFQuestionAnsweringModelOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFQuestionAnsweringModelOutput\n-\n-## TFSeq2SeqQuestionAnsweringModelOutput\n-\n-[[autodoc]] modeling_tf_outputs.TFSeq2SeqQuestionAnsweringModelOutput\n-\n-## FlaxBaseModelOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxBaseModelOutput\n-\n-## FlaxBaseModelOutputWithPast\n-\n-[[autodoc]] modeling_flax_outputs.FlaxBaseModelOutputWithPast\n-\n-## FlaxBaseModelOutputWithPooling\n-\n-[[autodoc]] modeling_flax_outputs.FlaxBaseModelOutputWithPooling\n-\n-## FlaxBaseModelOutputWithPastAndCrossAttentions\n-\n-[[autodoc]] modeling_flax_outputs.FlaxBaseModelOutputWithPastAndCrossAttentions\n-\n-## FlaxSeq2SeqModelOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSeq2SeqModelOutput\n-\n-## FlaxCausalLMOutputWithCrossAttentions\n-\n-[[autodoc]] modeling_flax_outputs.FlaxCausalLMOutputWithCrossAttentions\n-\n-## FlaxMaskedLMOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxMaskedLMOutput\n-\n-## FlaxSeq2SeqLMOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSeq2SeqLMOutput\n-\n-## FlaxNextSentencePredictorOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxNextSentencePredictorOutput\n-\n-## FlaxSequenceClassifierOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSequenceClassifierOutput\n-\n-## FlaxSeq2SeqSequenceClassifierOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSeq2SeqSequenceClassifierOutput\n-\n-## FlaxMultipleChoiceModelOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxMultipleChoiceModelOutput\n-\n-## FlaxTokenClassifierOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxTokenClassifierOutput\n-\n-## FlaxQuestionAnsweringModelOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxQuestionAnsweringModelOutput\n-\n-## FlaxSeq2SeqQuestionAnsweringModelOutput\n-\n-[[autodoc]] modeling_flax_outputs.FlaxSeq2SeqQuestionAnsweringModelOutput\n+[[autodoc]] modeling_outputs.SampleTSPredictionOutput\n\\ No newline at end of file"
        },
        {
            "sha": "5e7426fa8441916a0e67f4a70e34acab4c5bfa61",
            "filename": "docs/source/zh/main_classes/text_generation.md",
            "status": "modified",
            "additions": 1,
            "deletions": 12,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fzh%2Fmain_classes%2Ftext_generation.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fzh%2Fmain_classes%2Ftext_generation.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fmain_classes%2Ftext_generation.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -37,15 +37,4 @@ rendered properly in your Markdown viewer.\n \n [[autodoc]] generation.GenerationMixin\n \t- generate\n-\t- compute_transition_scores\n-\n-## TFGenerationMixin\n-\n-[[autodoc]] generation.TFGenerationMixin\n-\t- generate\n-\t- compute_transition_scores\n-\n-## FlaxGenerationMixin\n-\n-[[autodoc]] generation.FlaxGenerationMixin\n-\t- generate\n+\t- compute_transition_scores\n\\ No newline at end of file"
        },
        {
            "sha": "3877fcafe4de20931bda00d15977e3db6eda8d60",
            "filename": "docs/source/zh/model_doc/bert.md",
            "status": "modified",
            "additions": 1,
            "deletions": 99,
            "changes": 100,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fzh%2Fmodel_doc%2Fbert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8/docs%2Fsource%2Fzh%2Fmodel_doc%2Fbert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fmodel_doc%2Fbert.md?ref=e2dbde280f96f1aeba0e5bd76bc8fa99ee8369e8",
            "patch": "@@ -155,104 +155,6 @@ echo -e \"Plants create [MASK] through a process known as photosynthesis.\" | tran\n [[autodoc]] BertForQuestionAnswering\n     - forward\n \n-## TFBertTokenizer\n-\n-[[autodoc]] TFBertTokenizer\n-\n-## TFBertModel\n-\n-[[autodoc]] TFBertModel\n-    - call\n-\n-## TFBertForPreTraining\n-\n-[[autodoc]] TFBertForPreTraining\n-    - call\n-\n-## TFBertModelLMHeadModel\n-\n-[[autodoc]] TFBertLMHeadModel\n-    - call\n-\n-## TFBertForMaskedLM\n-\n-[[autodoc]] TFBertForMaskedLM\n-    - call\n-\n-## TFBertForNextSentencePrediction\n-\n-[[autodoc]] TFBertForNextSentencePrediction\n-    - call\n-\n-## TFBertForSequenceClassification\n-\n-[[autodoc]] TFBertForSequenceClassification\n-    - call\n-\n-## TFBertForMultipleChoice\n-\n-[[autodoc]] TFBertForMultipleChoice\n-    - call\n-\n-## TFBertForTokenClassification\n-\n-[[autodoc]] TFBertForTokenClassification\n-    - call\n-\n-## TFBertForQuestionAnswering\n-\n-[[autodoc]] TFBertForQuestionAnswering\n-    - call\n-\n-## FlaxBertModel\n-\n-[[autodoc]] FlaxBertModel\n-    - __call__\n-\n-## FlaxBertForPreTraining\n-\n-[[autodoc]] FlaxBertForPreTraining\n-    - __call__\n-\n-## FlaxBertForCausalLM\n-\n-[[autodoc]] FlaxBertForCausalLM\n-    - __call__\n-\n-## FlaxBertForMaskedLM\n-\n-[[autodoc]] FlaxBertForMaskedLM\n-    - __call__\n-\n-## FlaxBertForNextSentencePrediction\n-\n-[[autodoc]] FlaxBertForNextSentencePrediction\n-    - __call__\n-\n-## FlaxBertForSequenceClassification\n-\n-[[autodoc]] FlaxBertForSequenceClassification\n-    - __call__\n-\n-## FlaxBertForMultipleChoice\n-\n-[[autodoc]] FlaxBertForMultipleChoice\n-    - __call__\n-\n-## FlaxBertForTokenClassification\n-\n-[[autodoc]] FlaxBertForTokenClassification\n-    - __call__\n-\n-## FlaxBertForQuestionAnswering\n-\n-[[autodoc]] FlaxBertForQuestionAnswering\n-    - __call__\n-\n ## Bert specific outputs\n \n-[[autodoc]] models.bert.modeling_bert.BertForPreTrainingOutput\n-\n-[[autodoc]] models.bert.modeling_tf_bert.TFBertForPreTrainingOutput\n-\n-[[autodoc]] models.bert.modeling_flax_bert.FlaxBertForPreTrainingOutput\n\\ No newline at end of file\n+[[autodoc]] models.bert.modeling_bert.BertForPreTrainingOutput\n\\ No newline at end of file"
        }
    ],
    "stats": {
        "total": 2781,
        "additions": 3,
        "deletions": 2778
    }
}