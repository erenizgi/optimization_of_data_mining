{
    "author": "baoyf4244",
    "message": "fix apply_chat_template() padding choice (#35828)\n\nfix apply_chat_template() padding choice to bool, str, PaddingStrategy and the docstring of pad()",
    "sha": "328e2ae4c0ca0919ef0db68bfea3a8f4517d30b4",
    "files": [
        {
            "sha": "1e0d76ad5c5609920f1f66d0dd1a234d6fdfba9e",
            "filename": "src/transformers/tokenization_utils_base.py",
            "status": "modified",
            "additions": 13,
            "deletions": 5,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/328e2ae4c0ca0919ef0db68bfea3a8f4517d30b4/src%2Ftransformers%2Ftokenization_utils_base.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/328e2ae4c0ca0919ef0db68bfea3a8f4517d30b4/src%2Ftransformers%2Ftokenization_utils_base.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_utils_base.py?ref=328e2ae4c0ca0919ef0db68bfea3a8f4517d30b4",
            "patch": "@@ -1533,7 +1533,7 @@ def apply_chat_template(\n         add_generation_prompt: bool = False,\n         continue_final_message: bool = False,\n         tokenize: bool = True,\n-        padding: bool = False,\n+        padding: Union[bool, str, PaddingStrategy] = False,\n         truncation: bool = False,\n         max_length: Optional[int] = None,\n         return_tensors: Optional[Union[str, TensorType]] = None,\n@@ -1577,8 +1577,16 @@ def apply_chat_template(\n                 the model's response for it. Cannot be used at the same time as `add_generation_prompt`.\n             tokenize (`bool`, defaults to `True`):\n                 Whether to tokenize the output. If `False`, the output will be a string.\n-            padding (`bool`, defaults to `False`):\n-                Whether to pad sequences to the maximum length. Has no effect if tokenize is `False`.\n+            padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `False`):\n+                 Select a strategy to pad the returned sequences (according to the model's padding side and padding\n+                 index) among:\n+\n+                - `True` or `'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n+                  sequence if provided).\n+                - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n+                  acceptable input length for the model if that argument is not provided.\n+                - `False` or `'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of different\n+                  lengths).\n             truncation (`bool`, defaults to `False`):\n                 Whether to truncate sequences at the maximum length. Has no effect if tokenize is `False`.\n             max_length (`int`, *optional*):\n@@ -3249,11 +3257,11 @@ def pad(\n                  Select a strategy to pad the returned sequences (according to the model's padding side and padding\n                  index) among:\n \n-                - `True` or `'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n+                - `True` or `'longest'` (default): Pad to the longest sequence in the batch (or no padding if only a single\n                   sequence if provided).\n                 - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n                   acceptable input length for the model if that argument is not provided.\n-                - `False` or `'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of different\n+                - `False` or `'do_not_pad'`: No padding (i.e., can output a batch with sequences of different\n                   lengths).\n             max_length (`int`, *optional*):\n                 Maximum length of the returned list and optionally padding length (see above)."
        }
    ],
    "stats": {
        "total": 18,
        "additions": 13,
        "deletions": 5
    }
}