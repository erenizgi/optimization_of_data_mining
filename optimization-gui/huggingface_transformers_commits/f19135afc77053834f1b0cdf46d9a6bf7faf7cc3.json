{
    "author": "jiqing-feng",
    "message": "fix low-precision audio classification pipeline (#35435)\n\n* fix low-precision audio classification pipeline\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\r\n\r\n* add test\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\r\n\r\n* fix format\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\r\n\r\n* fix torch import\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\r\n\r\n* fix torch import\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\r\n\r\n* fix format\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\r\n\r\n---------\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>",
    "sha": "f19135afc77053834f1b0cdf46d9a6bf7faf7cc3",
    "files": [
        {
            "sha": "4febb09e95ab3bcf9834099fb6061dafc9939495",
            "filename": "src/transformers/pipelines/audio_classification.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f19135afc77053834f1b0cdf46d9a6bf7faf7cc3/src%2Ftransformers%2Fpipelines%2Faudio_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f19135afc77053834f1b0cdf46d9a6bf7faf7cc3/src%2Ftransformers%2Fpipelines%2Faudio_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Faudio_classification.py?ref=f19135afc77053834f1b0cdf46d9a6bf7faf7cc3",
            "patch": "@@ -212,6 +212,8 @@ def preprocess(self, inputs):\n         processed = self.feature_extractor(\n             inputs, sampling_rate=self.feature_extractor.sampling_rate, return_tensors=\"pt\"\n         )\n+        if self.torch_dtype is not None:\n+            processed = processed.to(dtype=self.torch_dtype)\n         return processed\n \n     def _forward(self, model_inputs):"
        },
        {
            "sha": "73534598d7d0071831e7234b7cdee3c8c5c91119",
            "filename": "tests/pipelines/test_pipelines_audio_classification.py",
            "status": "modified",
            "additions": 36,
            "deletions": 1,
            "changes": 37,
            "blob_url": "https://github.com/huggingface/transformers/blob/f19135afc77053834f1b0cdf46d9a6bf7faf7cc3/tests%2Fpipelines%2Ftest_pipelines_audio_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f19135afc77053834f1b0cdf46d9a6bf7faf7cc3/tests%2Fpipelines%2Ftest_pipelines_audio_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_audio_classification.py?ref=f19135afc77053834f1b0cdf46d9a6bf7faf7cc3",
            "patch": "@@ -17,7 +17,11 @@\n import numpy as np\n from huggingface_hub import AudioClassificationOutputElement\n \n-from transformers import MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING, TF_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING\n+from transformers import (\n+    MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING,\n+    TF_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING,\n+    is_torch_available,\n+)\n from transformers.pipelines import AudioClassificationPipeline, pipeline\n from transformers.testing_utils import (\n     compare_pipeline_output_to_hub_spec,\n@@ -32,6 +36,10 @@\n from .test_pipelines_common import ANY\n \n \n+if is_torch_available():\n+    import torch\n+\n+\n @is_pipeline_test\n class AudioClassificationPipelineTests(unittest.TestCase):\n     model_mapping = MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING\n@@ -127,6 +135,33 @@ def test_small_model_pt(self):\n         output = audio_classifier(audio_dict, top_k=4)\n         self.assertIn(nested_simplify(output, decimals=4), [EXPECTED_OUTPUT, EXPECTED_OUTPUT_PT_2])\n \n+    @require_torch\n+    def test_small_model_pt_fp16(self):\n+        model = \"anton-l/wav2vec2-random-tiny-classifier\"\n+\n+        audio_classifier = pipeline(\"audio-classification\", model=model, torch_dtype=torch.float16)\n+\n+        audio = np.ones((8000,))\n+        output = audio_classifier(audio, top_k=4)\n+\n+        EXPECTED_OUTPUT = [\n+            {\"score\": 0.0839, \"label\": \"no\"},\n+            {\"score\": 0.0837, \"label\": \"go\"},\n+            {\"score\": 0.0836, \"label\": \"yes\"},\n+            {\"score\": 0.0835, \"label\": \"right\"},\n+        ]\n+        EXPECTED_OUTPUT_PT_2 = [\n+            {\"score\": 0.0845, \"label\": \"stop\"},\n+            {\"score\": 0.0844, \"label\": \"on\"},\n+            {\"score\": 0.0841, \"label\": \"right\"},\n+            {\"score\": 0.0834, \"label\": \"left\"},\n+        ]\n+        self.assertIn(nested_simplify(output, decimals=4), [EXPECTED_OUTPUT, EXPECTED_OUTPUT_PT_2])\n+\n+        audio_dict = {\"array\": np.ones((8000,)), \"sampling_rate\": audio_classifier.feature_extractor.sampling_rate}\n+        output = audio_classifier(audio_dict, top_k=4)\n+        self.assertIn(nested_simplify(output, decimals=4), [EXPECTED_OUTPUT, EXPECTED_OUTPUT_PT_2])\n+\n     @require_torch\n     @slow\n     def test_large_model_pt(self):"
        }
    ],
    "stats": {
        "total": 39,
        "additions": 38,
        "deletions": 1
    }
}