{
    "author": "cyyever",
    "message": "Use math.log2 (#41241)\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>",
    "sha": "1c4d9982d36dd9a565d695e949907979242f72fc",
    "files": [
        {
            "sha": "a735fcee001a0d94215c7c101ecad523b4fee3fd",
            "filename": "src/transformers/models/esm/openfold_utils/chunk_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/1c4d9982d36dd9a565d695e949907979242f72fc/src%2Ftransformers%2Fmodels%2Fesm%2Fopenfold_utils%2Fchunk_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1c4d9982d36dd9a565d695e949907979242f72fc/src%2Ftransformers%2Fmodels%2Fesm%2Fopenfold_utils%2Fchunk_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fesm%2Fopenfold_utils%2Fchunk_utils.py?ref=1c4d9982d36dd9a565d695e949907979242f72fc",
            "patch": "@@ -329,7 +329,7 @@ def _determine_favorable_chunk_size(self, fn: Callable, args: tuple, min_chunk_s\n         if min_chunk_size >= self.max_chunk_size:\n             return min_chunk_size\n \n-        candidates: list[int] = [2**l for l in range(int(math.log(self.max_chunk_size, 2)) + 1)]\n+        candidates: list[int] = [2**l for l in range(int(math.log2(self.max_chunk_size)) + 1)]\n         candidates = [c for c in candidates if c > min_chunk_size]\n         candidates = [min_chunk_size] + candidates\n         candidates[-1] += 4"
        },
        {
            "sha": "df9e09c481b0eec9a9c43c6bb35ace5cbecb3869",
            "filename": "src/transformers/models/phi4_multimodal/configuration_phi4_multimodal.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/1c4d9982d36dd9a565d695e949907979242f72fc/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fconfiguration_phi4_multimodal.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1c4d9982d36dd9a565d695e949907979242f72fc/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fconfiguration_phi4_multimodal.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fconfiguration_phi4_multimodal.py?ref=1c4d9982d36dd9a565d695e949907979242f72fc",
            "patch": "@@ -236,7 +236,7 @@ def __init__(\n         if time_reduction % 2 != 0:\n             raise ValueError(\"`time_reduction` should be a multiple of 2!\")\n         length = input_size\n-        for _ in range(int(math.log(time_reduction, 2))):\n+        for _ in range(int(math.log2(time_reduction))):\n             length = math.floor((length - 1) / 2 + 1)\n         self.nemo_final_size = length\n "
        },
        {
            "sha": "bb495642c7102ef25b8a28c59a76b7b84348ae89",
            "filename": "src/transformers/models/phi4_multimodal/modeling_phi4_multimodal.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/1c4d9982d36dd9a565d695e949907979242f72fc/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodeling_phi4_multimodal.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1c4d9982d36dd9a565d695e949907979242f72fc/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodeling_phi4_multimodal.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodeling_phi4_multimodal.py?ref=1c4d9982d36dd9a565d695e949907979242f72fc",
            "patch": "@@ -844,7 +844,7 @@ class Phi4MultimodalAudioNemoConvSubsampling(torch.nn.Module):\n     def __init__(self, config: Phi4MultimodalAudioConfig):\n         super().__init__()\n         self.subsampling_factor = config.time_reduction\n-        self.sampling_num = int(math.log(self.subsampling_factor, 2))\n+        self.sampling_num = int(math.log2(self.subsampling_factor))\n         self.act_fn = ACT2FN[config.nemo_activation]\n         conv_channels = config.nemo_conv_channels\n "
        },
        {
            "sha": "bea02eef03c04531c37d3aa2172fb79c5860e85a",
            "filename": "src/transformers/models/phi4_multimodal/modular_phi4_multimodal.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/1c4d9982d36dd9a565d695e949907979242f72fc/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodular_phi4_multimodal.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1c4d9982d36dd9a565d695e949907979242f72fc/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodular_phi4_multimodal.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodular_phi4_multimodal.py?ref=1c4d9982d36dd9a565d695e949907979242f72fc",
            "patch": "@@ -273,7 +273,7 @@ def __init__(\n         if time_reduction % 2 != 0:\n             raise ValueError(\"`time_reduction` should be a multiple of 2!\")\n         length = input_size\n-        for _ in range(int(math.log(time_reduction, 2))):\n+        for _ in range(int(math.log2(time_reduction))):\n             length = math.floor((length - 1) / 2 + 1)\n         self.nemo_final_size = length\n \n@@ -1028,7 +1028,7 @@ class Phi4MultimodalAudioNemoConvSubsampling(torch.nn.Module):\n     def __init__(self, config: Phi4MultimodalAudioConfig):\n         super().__init__()\n         self.subsampling_factor = config.time_reduction\n-        self.sampling_num = int(math.log(self.subsampling_factor, 2))\n+        self.sampling_num = int(math.log2(self.subsampling_factor))\n         self.act_fn = ACT2FN[config.nemo_activation]\n         conv_channels = config.nemo_conv_channels\n "
        },
        {
            "sha": "4dfb5b4f743ea45a51afe899ad96f7ce07513ca6",
            "filename": "src/transformers/models/swin2sr/modeling_swin2sr.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/1c4d9982d36dd9a565d695e949907979242f72fc/src%2Ftransformers%2Fmodels%2Fswin2sr%2Fmodeling_swin2sr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1c4d9982d36dd9a565d695e949907979242f72fc/src%2Ftransformers%2Fmodels%2Fswin2sr%2Fmodeling_swin2sr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fswin2sr%2Fmodeling_swin2sr.py?ref=1c4d9982d36dd9a565d695e949907979242f72fc",
            "patch": "@@ -835,7 +835,7 @@ def __init__(self, scale, num_features):\n         self.scale = scale\n         if (scale & (scale - 1)) == 0:\n             # scale = 2^n\n-            for i in range(int(math.log(scale, 2))):\n+            for i in range(int(math.log2(scale))):\n                 self.add_module(f\"convolution_{i}\", nn.Conv2d(num_features, 4 * num_features, 3, 1, 1))\n                 self.add_module(f\"pixelshuffle_{i}\", nn.PixelShuffle(2))\n         elif scale == 3:\n@@ -846,7 +846,7 @@ def __init__(self, scale, num_features):\n \n     def forward(self, hidden_state):\n         if (self.scale & (self.scale - 1)) == 0:\n-            for i in range(int(math.log(self.scale, 2))):\n+            for i in range(int(math.log2(self.scale))):\n                 hidden_state = self.__getattr__(f\"convolution_{i}\")(hidden_state)\n                 hidden_state = self.__getattr__(f\"pixelshuffle_{i}\")(hidden_state)\n "
        }
    ],
    "stats": {
        "total": 14,
        "additions": 7,
        "deletions": 7
    }
}