{
    "author": "juliendenize",
    "message": "Add missing quotes in modeling_llava_next_video.py (#33214)",
    "sha": "e259d6d1e0d2acfa3c2f84b11c9bfa97e64b984d",
    "files": [
        {
            "sha": "4c2fdf914a4bc0248c4c862dc669774917d13573",
            "filename": "src/transformers/models/llava_next_video/modeling_llava_next_video.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e259d6d1e0d2acfa3c2f84b11c9bfa97e64b984d/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fmodeling_llava_next_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e259d6d1e0d2acfa3c2f84b11c9bfa97e64b984d/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fmodeling_llava_next_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fmodeling_llava_next_video.py?ref=e259d6d1e0d2acfa3c2f84b11c9bfa97e64b984d",
            "patch": "@@ -809,7 +809,7 @@ def forward(\n         ...             frames.append(frame)\n         ...     return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n \n-        >>> model = LlavaNextVideoForConditionalGeneration.from_pretrained(\"llava-hf/LLaVA-NeXT-Video-7B-hf\", device_map=\"auto)\n+        >>> model = LlavaNextVideoForConditionalGeneration.from_pretrained(\"llava-hf/LLaVA-NeXT-Video-7B-hf\", device_map=\"auto\")\n         >>> processor = AutoProcessor.from_pretrained(\"llava-hf/LLaVA-NeXT-Video-7B-hf\")\n \n         >>> prompt = \"USER: <video>\\nWhy is this video funny? ASSISTANT:\""
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}