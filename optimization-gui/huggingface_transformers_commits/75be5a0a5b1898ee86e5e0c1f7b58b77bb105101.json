{
    "author": "eustlb",
    "message": "[Whisper] fix docstrings typo (#35319)\n\ntypos docstring",
    "sha": "75be5a0a5b1898ee86e5e0c1f7b58b77bb105101",
    "files": [
        {
            "sha": "360c0c0b687bab0c38262b34781778ca4b9eaf00",
            "filename": "src/transformers/models/whisper/generation_whisper.py",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/75be5a0a5b1898ee86e5e0c1f7b58b77bb105101/src%2Ftransformers%2Fmodels%2Fwhisper%2Fgeneration_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/75be5a0a5b1898ee86e5e0c1f7b58b77bb105101/src%2Ftransformers%2Fmodels%2Fwhisper%2Fgeneration_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Fgeneration_whisper.py?ref=75be5a0a5b1898ee86e5e0c1f7b58b77bb105101",
            "patch": "@@ -382,7 +382,7 @@ def generate(\n                 the soundfile library (`pip install soundfile`). To prepare the array into `input_features`, the\n                 [`AutoFeatureExtractor`] should be used for extracting the mel features, padding and conversion into a\n                 tensor of type `torch.FloatTensor`. See [`~WhisperFeatureExtractor.__call__`] for details.\n-            generation_config (`~generation.GenerationConfig`, *optional*):\n+            generation_config ([`~generation.GenerationConfig`], *optional*):\n                 The generation configuration to be used as base parametrization for the generation call. `**kwargs`\n                 passed to generate matching the attributes of `generation_config` will override them. If\n                 `generation_config` is not provided, the default will be used, which had the following loading\n@@ -480,8 +480,8 @@ def generate(\n                 `return_segments` is set True. In this case the generation outputs of each segment is added to each\n                 segment.\n             force_unique_generate_call (`bool`, *optional*):\n-                Whether to force a unique call to the underlying GenerationMixin's generate method. This is useful for assisted decoding and testing purposes to ensure\n-                that only one call to generate is made and therefore decoder input token ids and eos token ids are returned.\n+                Whether to force a unique call to the underlying GenerationMixin's [~generation.GenerationMixin.generate] method. This is useful for assisted decoding and testing purposes to ensure\n+                that only one call to [~generation.GenerationMixin.generate] is made and therefore decoder input token ids and eos token ids are returned.\n             kwargs (`Dict[str, Any]`, *optional*):\n                 Ad hoc parametrization of `generate_config` and/or additional model-specific kwargs that will be\n                 forwarded to the `forward` function of the model. If the model is an encoder-decoder model, encoder\n@@ -495,18 +495,18 @@ def generate(\n                 - `torch.LongTensor` in all other cases, excluding the decoder input ids and end of sequence id.\n \n                 The possible [`~utils.ModelOutput`] types are:\n-                - [`~utils.GenerateEncoderDecoderOutput`]\n-                - [`~utils.GenerateBeamEncoderDecoderOutput`]\n+                - [`~generation.GenerateEncoderDecoderOutput`]\n+                - [`~generation.GenerateBeamEncoderDecoderOutput`]\n \n                 `segments` is a list of lists (one list per batch element) of `segment`.\n                 A `segment` is a dictionary with keys `start`, `end`, `tokens`, `idxs`, and `result`.\n                 - `start`: the start timestamp of the segment.\n                 - `end`: the end timestamp of the segment.\n                 - `tokens`: the tokens of the segment, excluding the decoder input ids and end of sequence id.\n-                - `idxs`: the start (included) and end (excluded) indices of the `tokens` of the segment in the underlying call to GenerationMixin's `generate` (present in `result`).\n-                - `result`: the result of the underlying call to GenerationMixin's `generate`.\n+                - `idxs`: the start (included) and end (excluded) indices of the `tokens` of the segment in the underlying call to GenerationMixin's [~generation.GenerationMixin.generate] (present in `result`).\n+                - `result`: the result of the underlying call to GenerationMixin's [~generation.GenerationMixin.generate].\n \n-                When `return_timestamps=True`, `return_dict_in_generate=True` applies to each call of the underlying GenerationMixin's `generate`, with outputs stored in `result` of each `segment`.\n+                When `return_timestamps=True`, `return_dict_in_generate=True` applies to each call of the underlying GenerationMixin's [~generation.GenerationMixin.generate], with outputs stored in `result` of each `segment`.\n \n         Example:\n \n@@ -543,7 +543,7 @@ def generate(\n         ```\n \n         - *Shortform transcription*: If passed mel input features are <= 30 seconds, there are two possibilities:\n-            - `return_timestamps=False`: the whole audio will be transcribed with a single call to GenerationMixin's generate.\n+            - `return_timestamps=False`: the whole audio will be transcribed with a single call to GenerationMixin's [~generation.GenerationMixin.generate].\n             - `return_timestamps=True`: the audio will be transcribed using the same logic as long-form transcription.\n \n         ```python"
        }
    ],
    "stats": {
        "total": 18,
        "additions": 9,
        "deletions": 9
    }
}