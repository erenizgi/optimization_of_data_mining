{
    "author": "cyyever",
    "message": "Use OSError (#38712)\n\nSigned-off-by: cyy <cyyever@outlook.com>",
    "sha": "8340e8746e7d27cce05253ec0f2845aeb0313884",
    "files": [
        {
            "sha": "c886b51cf58c0eee15e3574c6407b70d95b7cbe9",
            "filename": "src/transformers/generation/configuration_utils.py",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fgeneration%2Fconfiguration_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fgeneration%2Fconfiguration_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Fconfiguration_utils.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -1049,13 +1049,13 @@ def from_pretrained(\n                     _commit_hash=commit_hash,\n                 )\n                 commit_hash = extract_commit_hash(resolved_config_file, commit_hash)\n-            except EnvironmentError:\n+            except OSError:\n                 # Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\n                 # the original exception.\n                 raise\n             except Exception:\n                 # For any other exception, we throw a generic error.\n-                raise EnvironmentError(\n+                raise OSError(\n                     f\"Can't load the configuration of '{pretrained_model_name}'. If you were trying to load it\"\n                     \" from 'https://huggingface.co/models', make sure you don't have a local directory with the same\"\n                     f\" name. Otherwise, make sure '{pretrained_model_name}' is the correct path to a directory\"\n@@ -1067,9 +1067,7 @@ def from_pretrained(\n             config_dict = cls._dict_from_json_file(resolved_config_file)\n             config_dict[\"_commit_hash\"] = commit_hash\n         except (json.JSONDecodeError, UnicodeDecodeError):\n-            raise EnvironmentError(\n-                f\"It looks like the config file at '{resolved_config_file}' is not a valid JSON file.\"\n-            )\n+            raise OSError(f\"It looks like the config file at '{resolved_config_file}' is not a valid JSON file.\")\n \n         if is_local:\n             logger.info(f\"loading configuration file {resolved_config_file}\")"
        },
        {
            "sha": "1c743dcf909799161fc2ff3a7b09cc092ad1d635",
            "filename": "src/transformers/integrations/integration_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fintegrations%2Fintegration_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fintegrations%2Fintegration_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Fintegration_utils.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -1623,7 +1623,7 @@ def _log_model_checkpoint(self, source_directory: str, checkpoint: str):\n                 copy_path = os.path.join(consistent_checkpoint_path, cpkt_path)\n                 shutil.copytree(relative_path, copy_path)\n                 target_path = consistent_checkpoint_path\n-            except IOError as e:\n+            except OSError as e:\n                 logger.warning(\n                     \"NeptuneCallback was unable to made a copy of checkpoint due to I/O exception: '{}'. \"\n                     \"Could fail trying to upload.\".format(e)"
        },
        {
            "sha": "b0946ee771678d7a15c2fcbf08083b99f8b591df",
            "filename": "src/transformers/integrations/tensor_parallel.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fintegrations%2Ftensor_parallel.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fintegrations%2Ftensor_parallel.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Ftensor_parallel.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -48,7 +48,7 @@ def initialize_tensor_parallelism(tp_plan, tp_size=None):\n         return None, None, None\n \n     if not is_torch_greater_or_equal(\"2.5\"):\n-        raise EnvironmentError(\"Tensor parallel is only supported for `torch>=2.5`.\")\n+        raise OSError(\"Tensor parallel is only supported for `torch>=2.5`.\")\n \n     # Detect the accelerator on the machine. If no accelerator is available, it returns CPU.\n     device_type = torch._C._get_accelerator().type\n@@ -70,7 +70,7 @@ def initialize_tensor_parallelism(tp_plan, tp_size=None):\n                 current_device.set_device(local_rank)\n \n         except Exception as e:\n-            raise EnvironmentError(\n+            raise OSError(\n                 \"We tried to initialize torch.distributed for you, but it failed. Make \"\n                 \"sure you init torch distributed in your script to use `tp_plan='auto'`.\"\n             ) from e"
        },
        {
            "sha": "b35e49246072ef0aee4525355b56da4689233a17",
            "filename": "src/transformers/modeling_flax_pytorch_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodeling_flax_pytorch_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodeling_flax_pytorch_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_flax_pytorch_utils.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -347,7 +347,7 @@ def load_flax_checkpoint_in_pytorch_model(model, flax_checkpoint_path):\n             try:\n                 flax_state_dict = from_bytes(flax_cls, state_f.read())\n             except UnpicklingError:\n-                raise EnvironmentError(f\"Unable to convert {flax_checkpoint_path} to Flax deserializable object. \")\n+                raise OSError(f\"Unable to convert {flax_checkpoint_path} to Flax deserializable object. \")\n \n     return load_flax_weights_in_pytorch_model(model, flax_state_dict)\n "
        },
        {
            "sha": "7697294d6a52581658d1bb5e9462de0b01989054",
            "filename": "src/transformers/modeling_flax_utils.py",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodeling_flax_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodeling_flax_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_flax_utils.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -435,7 +435,7 @@ def load_flax_weights(cls, resolved_archive_file):\n                     else:\n                         raise ValueError from e\n             except (UnicodeDecodeError, ValueError):\n-                raise EnvironmentError(f\"Unable to convert {resolved_archive_file} to Flax deserializable object. \")\n+                raise OSError(f\"Unable to convert {resolved_archive_file} to Flax deserializable object. \")\n \n         return state\n \n@@ -476,7 +476,7 @@ def load_flax_sharded_weights(cls, shard_files):\n                     else:\n                         raise ValueError from e\n             except (UnicodeDecodeError, ValueError):\n-                raise EnvironmentError(f\"Unable to convert {shard_file} to Flax deserializable object. \")\n+                raise OSError(f\"Unable to convert {shard_file} to Flax deserializable object. \")\n \n             state = flatten_dict(state, sep=\"/\")\n             state_sharded_dict.update(state)\n@@ -738,13 +738,13 @@ def from_pretrained(\n                     is_sharded = True\n                     raise NotImplementedError(\"Support for sharded checkpoints using safetensors is coming soon!\")\n                 elif os.path.isfile(os.path.join(pretrained_model_name_or_path, subfolder, WEIGHTS_NAME)):\n-                    raise EnvironmentError(\n+                    raise OSError(\n                         f\"Error no file named {FLAX_WEIGHTS_NAME} found in directory {pretrained_model_name_or_path} \"\n                         \"but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those \"\n                         \"weights.\"\n                     )\n                 else:\n-                    raise EnvironmentError(\n+                    raise OSError(\n                         f\"Error no file named {FLAX_WEIGHTS_NAME} or {WEIGHTS_NAME} found in directory \"\n                         f\"{pretrained_model_name_or_path}.\"\n                     )\n@@ -820,29 +820,29 @@ def from_pretrained(\n                                 \"Support for sharded checkpoints using safetensors is coming soon!\"\n                             )\n                         elif has_file(pretrained_model_name_or_path, WEIGHTS_NAME, **has_file_kwargs):\n-                            raise EnvironmentError(\n+                            raise OSError(\n                                 f\"{pretrained_model_name_or_path} does not appear to have a file named\"\n                                 f\" {FLAX_WEIGHTS_NAME} but there is a file for PyTorch weights. Use `from_pt=True` to\"\n                                 \" load this model from those weights.\"\n                             )\n                         elif has_file(pretrained_model_name_or_path, WEIGHTS_INDEX_NAME, **has_file_kwargs):\n-                            raise EnvironmentError(\n+                            raise OSError(\n                                 f\"{pretrained_model_name_or_path} does not appear to have a file named\"\n                                 f\" {FLAX_WEIGHTS_INDEX_NAME} but there is a sharded file for PyTorch weights. Use\"\n                                 \" `from_pt=True` to load this model from those weights.\"\n                             )\n                         else:\n-                            raise EnvironmentError(\n+                            raise OSError(\n                                 f\"{pretrained_model_name_or_path} does not appear to have a file named\"\n                                 f\" {FLAX_WEIGHTS_NAME} or {WEIGHTS_NAME}.\"\n                             )\n-                except EnvironmentError:\n+                except OSError:\n                     # Raise any environment error raise by `cached_file`. It will have a helpful error message adapted\n                     # to the original exception.\n                     raise\n                 except Exception:\n                     # For any other exception, we throw a generic error.\n-                    raise EnvironmentError(\n+                    raise OSError(\n                         f\"Can't load the model for '{pretrained_model_name_or_path}'. If you were trying to load it\"\n                         \" from 'https://huggingface.co/models', make sure you don't have a local directory with the\"\n                         f\" same name. Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a\""
        },
        {
            "sha": "af436be20f9b11ea9f1e9e5d659027ea3c0c11a2",
            "filename": "src/transformers/modeling_tf_utils.py",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodeling_tf_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodeling_tf_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_tf_utils.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -2760,21 +2760,21 @@ def from_pretrained(\n \n                 # At this stage we don't have a weight file so we will raise an error.\n                 elif use_safetensors:\n-                    raise EnvironmentError(\n+                    raise OSError(\n                         f\"Error no file named {SAFE_WEIGHTS_NAME} or {SAFE_WEIGHTS_INDEX_NAME} found in directory {pretrained_model_name_or_path}. \"\n                         f\"Please make sure that the model has been saved with `safe_serialization=True` or do not \"\n                         f\"set `use_safetensors=True`.\"\n                     )\n                 elif os.path.isfile(os.path.join(pretrained_model_name_or_path, WEIGHTS_NAME)) or os.path.isfile(\n                     os.path.join(pretrained_model_name_or_path, WEIGHTS_INDEX_NAME)\n                 ):\n-                    raise EnvironmentError(\n+                    raise OSError(\n                         f\"Error no file named {TF2_WEIGHTS_NAME} or {SAFE_WEIGHTS_NAME} found in directory {pretrained_model_name_or_path} \"\n                         \"but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those \"\n                         \"weights.\"\n                     )\n                 else:\n-                    raise EnvironmentError(\n+                    raise OSError(\n                         f\"Error no file named {TF2_WEIGHTS_NAME}, {SAFE_WEIGHTS_NAME} or {WEIGHTS_NAME} found in directory \"\n                         f\"{pretrained_model_name_or_path}.\"\n                     )\n@@ -2850,25 +2850,25 @@ def from_pretrained(\n                         if has_file(pretrained_model_name_or_path, SAFE_WEIGHTS_INDEX_NAME, **has_file_kwargs):\n                             is_sharded = True\n                         elif has_file(pretrained_model_name_or_path, WEIGHTS_NAME, **has_file_kwargs):\n-                            raise EnvironmentError(\n+                            raise OSError(\n                                 f\"{pretrained_model_name_or_path} does not appear to have a file named\"\n                                 f\" {TF2_WEIGHTS_NAME} but there is a file for PyTorch weights. Use `from_pt=True` to\"\n                                 \" load this model from those weights.\"\n                             )\n                         else:\n-                            raise EnvironmentError(\n+                            raise OSError(\n                                 f\"{pretrained_model_name_or_path} does not appear to have a file named {WEIGHTS_NAME},\"\n                                 f\" {TF2_WEIGHTS_NAME} or {TF_WEIGHTS_NAME}\"\n                             )\n \n-                except EnvironmentError:\n+                except OSError:\n                     # Raise any environment error raise by `cached_file`. It will have a helpful error message adapted\n                     # to the original exception.\n                     raise\n                 except Exception:\n                     # For any other exception, we throw a generic error.\n \n-                    raise EnvironmentError(\n+                    raise OSError(\n                         f\"Can't load the model for '{pretrained_model_name_or_path}'. If you were trying to load it\"\n                         \" from 'https://huggingface.co/models', make sure you don't have a local directory with the\"\n                         f\" same name. Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a\""
        },
        {
            "sha": "64d5737545c79e8a83d4b08b25d5d42067b0a104",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 11,
            "deletions": 11,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -1069,26 +1069,26 @@ def _get_resolved_checkpoint_files(\n                 os.path.isfile(os.path.join(pretrained_model_name_or_path, subfolder, TF_WEIGHTS_NAME + \".index\"))\n                 or os.path.isfile(os.path.join(pretrained_model_name_or_path, subfolder, TF2_WEIGHTS_NAME))\n             ):\n-                raise EnvironmentError(\n+                raise OSError(\n                     f\"Error no file named {_add_variant(WEIGHTS_NAME, variant)} found in directory\"\n                     f\" {pretrained_model_name_or_path} but there is a file for TensorFlow weights. Use\"\n                     \" `from_tf=True` to load this model from those weights.\"\n                 )\n             elif not use_safetensors and os.path.isfile(\n                 os.path.join(pretrained_model_name_or_path, subfolder, FLAX_WEIGHTS_NAME)\n             ):\n-                raise EnvironmentError(\n+                raise OSError(\n                     f\"Error no file named {_add_variant(WEIGHTS_NAME, variant)} found in directory\"\n                     f\" {pretrained_model_name_or_path} but there is a file for Flax weights. Use `from_flax=True`\"\n                     \" to load this model from those weights.\"\n                 )\n             elif use_safetensors:\n-                raise EnvironmentError(\n+                raise OSError(\n                     f\"Error no file named {_add_variant(SAFE_WEIGHTS_NAME, variant)} found in directory\"\n                     f\" {pretrained_model_name_or_path}.\"\n                 )\n             else:\n-                raise EnvironmentError(\n+                raise OSError(\n                     f\"Error no file named {_add_variant(WEIGHTS_NAME, variant)}, {_add_variant(SAFE_WEIGHTS_NAME, variant)},\"\n                     f\" {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME + '.index'} or {FLAX_WEIGHTS_NAME} found in directory\"\n                     f\" {pretrained_model_name_or_path}.\"\n@@ -1156,7 +1156,7 @@ def _get_resolved_checkpoint_files(\n                             )\n                         cached_file_kwargs[\"revision\"] = revision\n                         if resolved_archive_file is None:\n-                            raise EnvironmentError(\n+                            raise OSError(\n                                 f\"{pretrained_model_name_or_path} does not appear to have a file named\"\n                                 f\" {_add_variant(SAFE_WEIGHTS_NAME, variant)} or {_add_variant(SAFE_WEIGHTS_INDEX_NAME, variant)} \"\n                                 \"and thus cannot be loaded with `safetensors`. Please make sure that the model has \"\n@@ -1222,39 +1222,39 @@ def _get_resolved_checkpoint_files(\n                             \"local_files_only\": local_files_only,\n                         }\n                         if has_file(pretrained_model_name_or_path, TF2_WEIGHTS_NAME, **has_file_kwargs):\n-                            raise EnvironmentError(\n+                            raise OSError(\n                                 f\"{pretrained_model_name_or_path} does not appear to have a file named\"\n                                 f\" {_add_variant(WEIGHTS_NAME, variant)} but there is a file for TensorFlow weights.\"\n                                 \" Use `from_tf=True` to load this model from those weights.\"\n                             )\n                         elif has_file(pretrained_model_name_or_path, FLAX_WEIGHTS_NAME, **has_file_kwargs):\n-                            raise EnvironmentError(\n+                            raise OSError(\n                                 f\"{pretrained_model_name_or_path} does not appear to have a file named\"\n                                 f\" {_add_variant(WEIGHTS_NAME, variant)} but there is a file for Flax weights. Use\"\n                                 \" `from_flax=True` to load this model from those weights.\"\n                             )\n                         elif variant is not None and has_file(\n                             pretrained_model_name_or_path, WEIGHTS_NAME, **has_file_kwargs\n                         ):\n-                            raise EnvironmentError(\n+                            raise OSError(\n                                 f\"{pretrained_model_name_or_path} does not appear to have a file named\"\n                                 f\" {_add_variant(WEIGHTS_NAME, variant)} but there is a file without the variant\"\n                                 f\" {variant}. Use `variant=None` to load this model from those weights.\"\n                             )\n                         else:\n-                            raise EnvironmentError(\n+                            raise OSError(\n                                 f\"{pretrained_model_name_or_path} does not appear to have a file named\"\n                                 f\" {_add_variant(WEIGHTS_NAME, variant)}, {_add_variant(SAFE_WEIGHTS_NAME, variant)},\"\n                                 f\" {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME} or {FLAX_WEIGHTS_NAME}.\"\n                             )\n \n-            except EnvironmentError:\n+            except OSError:\n                 # Raise any environment error raise by `cached_file`. It will have a helpful error message adapted\n                 # to the original exception.\n                 raise\n             except Exception as e:\n                 # For any other exception, we throw a generic error.\n-                raise EnvironmentError(\n+                raise OSError(\n                     f\"Can't load the model for '{pretrained_model_name_or_path}'. If you were trying to load it\"\n                     \" from 'https://huggingface.co/models', make sure you don't have a local directory with the\"\n                     f\" same name. Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a\""
        },
        {
            "sha": "00c2986096127a008e01165e892d4474dc5a1334",
            "filename": "src/transformers/models/auto/auto_factory.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fauto%2Fauto_factory.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fauto%2Fauto_factory.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fauto_factory.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -415,7 +415,7 @@ class _BaseAutoModelClass:\n     _model_mapping = None\n \n     def __init__(self, *args, **kwargs) -> None:\n-        raise EnvironmentError(\n+        raise OSError(\n             f\"{self.__class__.__name__} is designed to be instantiated \"\n             f\"using the `{self.__class__.__name__}.from_pretrained(pretrained_model_name_or_path)` or \"\n             f\"`{self.__class__.__name__}.from_config(config)` methods.\""
        },
        {
            "sha": "da55432dfd1090632836752adaa0ff79f5a55827",
            "filename": "src/transformers/models/auto/configuration_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fauto%2Fconfiguration_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fauto%2Fconfiguration_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fconfiguration_auto.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -1047,7 +1047,7 @@ class AutoConfig:\n     \"\"\"\n \n     def __init__(self) -> None:\n-        raise EnvironmentError(\n+        raise OSError(\n             \"AutoConfig is designed to be instantiated \"\n             \"using the `AutoConfig.from_pretrained(pretrained_model_name_or_path)` method.\"\n         )"
        },
        {
            "sha": "dc94a15c7ef212c0e6c9a78f09359f916dce0914",
            "filename": "src/transformers/models/auto/feature_extraction_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fauto%2Ffeature_extraction_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fauto%2Ffeature_extraction_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Ffeature_extraction_auto.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -255,7 +255,7 @@ class AutoFeatureExtractor:\n     \"\"\"\n \n     def __init__(self):\n-        raise EnvironmentError(\n+        raise OSError(\n             \"AutoFeatureExtractor is designed to be instantiated \"\n             \"using the `AutoFeatureExtractor.from_pretrained(pretrained_model_name_or_path)` method.\"\n         )"
        },
        {
            "sha": "2faabea5fe835ba4fc256a8f883660f541fab3a3",
            "filename": "src/transformers/models/auto/image_processing_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -338,7 +338,7 @@ class AutoImageProcessor:\n     \"\"\"\n \n     def __init__(self):\n-        raise EnvironmentError(\n+        raise OSError(\n             \"AutoImageProcessor is designed to be instantiated \"\n             \"using the `AutoImageProcessor.from_pretrained(pretrained_model_name_or_path)` method.\"\n         )"
        },
        {
            "sha": "7eb850cfe4384f9b7e205f28bc9783c84a488ef4",
            "filename": "src/transformers/models/auto/processing_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fauto%2Fprocessing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fauto%2Fprocessing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fprocessing_auto.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -176,7 +176,7 @@ class AutoProcessor:\n     \"\"\"\n \n     def __init__(self):\n-        raise EnvironmentError(\n+        raise OSError(\n             \"AutoProcessor is designed to be instantiated \"\n             \"using the `AutoProcessor.from_pretrained(pretrained_model_name_or_path)` method.\"\n         )"
        },
        {
            "sha": "315c2e51682d5fd44f3c8534a56e14535daf792e",
            "filename": "src/transformers/models/auto/tokenization_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -819,7 +819,7 @@ class AutoTokenizer:\n     \"\"\"\n \n     def __init__(self):\n-        raise EnvironmentError(\n+        raise OSError(\n             \"AutoTokenizer is designed to be instantiated \"\n             \"using the `AutoTokenizer.from_pretrained(pretrained_model_name_or_path)` method.\"\n         )"
        },
        {
            "sha": "1688b7fbebff0b892f40f235e73fbb69451a95e4",
            "filename": "src/transformers/models/auto/video_processing_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fauto%2Fvideo_processing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fauto%2Fvideo_processing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fvideo_processing_auto.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -205,7 +205,7 @@ class AutoVideoProcessor:\n     \"\"\"\n \n     def __init__(self):\n-        raise EnvironmentError(\n+        raise OSError(\n             \"AutoVideoProcessor is designed to be instantiated \"\n             \"using the `AutoVideoProcessor.from_pretrained(pretrained_model_name_or_path)` method.\"\n         )"
        },
        {
            "sha": "44a3c85addf95f6243178c86e07d3058324fcf1a",
            "filename": "src/transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftransfo_xl%2Ftokenization_transfo_xl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftransfo_xl%2Ftokenization_transfo_xl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftransfo_xl%2Ftokenization_transfo_xl.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -693,7 +693,7 @@ def from_pretrained(cls, pretrained_model_name_or_path, cache_dir=None, *inputs,\n         # redirect to the cache, if necessary\n         try:\n             resolved_corpus_file = cached_file(pretrained_model_name_or_path, CORPUS_NAME, cache_dir=cache_dir)\n-        except EnvironmentError:\n+        except OSError:\n             logger.error(\n                 f\"Corpus '{pretrained_model_name_or_path}' was not found in corpus list\"\n                 f\" ({', '.join(PRETRAINED_CORPUS_ARCHIVE_MAP.keys())}. We assumed '{pretrained_model_name_or_path}'\""
        },
        {
            "sha": "355b131be507cdfd6abe1b3549dc34520e669c38",
            "filename": "src/transformers/models/rag/retrieval_rag.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Frag%2Fretrieval_rag.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Frag%2Fretrieval_rag.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frag%2Fretrieval_rag.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -117,13 +117,13 @@ def _resolve_path(self, index_path, filename):\n         try:\n             # Load from URL or cache if already cached\n             resolved_archive_file = cached_file(index_path, filename)\n-        except EnvironmentError:\n+        except OSError:\n             msg = (\n                 f\"Can't load '{filename}'. Make sure that:\\n\\n\"\n                 f\"- '{index_path}' is a correct remote path to a directory containing a file named {filename}\\n\\n\"\n                 f\"- or '{index_path}' is the correct path to a directory containing a file named {filename}.\\n\\n\"\n             )\n-            raise EnvironmentError(msg)\n+            raise OSError(msg)\n         if is_local:\n             logger.info(f\"loading file {resolved_archive_file}\")\n         else:"
        },
        {
            "sha": "6a66a21eece7ac14d28265f48b2893eb74a4db38",
            "filename": "src/transformers/models/wav2vec2/modeling_wav2vec2.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fmodeling_wav2vec2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fmodeling_wav2vec2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fmodeling_wav2vec2.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -1322,7 +1322,7 @@ def load_adapter(self, target_lang: str, force_load=True, **kwargs):\n \n                 state_dict = safe_load_file(weight_path)\n \n-            except EnvironmentError:\n+            except OSError:\n                 if use_safetensors:\n                     # Raise any environment error raise by `cached_file`. It will have a helpful error message adapted\n                     # to the original exception.\n@@ -1331,7 +1331,7 @@ def load_adapter(self, target_lang: str, force_load=True, **kwargs):\n             except Exception:\n                 # For any other exception, we throw a generic error.\n                 if use_safetensors:\n-                    raise EnvironmentError(\n+                    raise OSError(\n                         f\"Can't load the model for '{model_path_or_id}'. If you were trying to load it\"\n                         \" from 'https://huggingface.co/models', make sure you don't have a local directory with the\"\n                         f\" same name. Otherwise, make sure '{model_path_or_id}' is the correct path to a\"\n@@ -1362,7 +1362,7 @@ def load_adapter(self, target_lang: str, force_load=True, **kwargs):\n                     weights_only=True,\n                 )\n \n-            except EnvironmentError:\n+            except OSError:\n                 # Raise any environment error raise by `cached_file`. It will have a helpful error message adapted\n                 # to the original exception.\n                 raise\n@@ -1372,7 +1372,7 @@ def load_adapter(self, target_lang: str, force_load=True, **kwargs):\n \n             except Exception:\n                 # For any other exception, we throw a generic error.\n-                raise EnvironmentError(\n+                raise OSError(\n                     f\"Can't load the model for '{model_path_or_id}'. If you were trying to load it\"\n                     \" from 'https://huggingface.co/models', make sure you don't have a local directory with the\"\n                     f\" same name. Otherwise, make sure '{model_path_or_id}' is the correct path to a\""
        },
        {
            "sha": "5bd61d3cb58cee609b1e16f01cd6e739d486fb4a",
            "filename": "src/transformers/onnx/features.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fonnx%2Ffeatures.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fonnx%2Ffeatures.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fonnx%2Ffeatures.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -669,7 +669,7 @@ def determine_framework(model: str, framework: Optional[str] = None) -> str:\n             elif is_tf_available():\n                 framework = \"tf\"\n             else:\n-                raise EnvironmentError(\"Neither PyTorch nor TensorFlow found in environment. Cannot export to ONNX.\")\n+                raise OSError(\"Neither PyTorch nor TensorFlow found in environment. Cannot export to ONNX.\")\n \n         logger.info(f\"Framework not requested. Using {exporter_map[framework]} to export to ONNX.\")\n "
        },
        {
            "sha": "3a9852452bd4acff3a5fbcab4a57c9effe50e652",
            "filename": "src/transformers/utils/hub.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Futils%2Fhub.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Futils%2Fhub.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fhub.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -570,7 +570,7 @@ def cached_files(\n         msg = (\n             f\"a file named {missing_entries[0]}\" if len(missing_entries) == 1 else f\"files named {(*missing_entries,)}\"\n         )\n-        raise EnvironmentError(\n+        raise OSError(\n             f\"{path_or_repo_id} does not appear to have {msg}. Checkout 'https://huggingface.co/{path_or_repo_id}/tree/{revision_}'\"\n             \" for available files.\"\n         )"
        },
        {
            "sha": "8a599d4737e32438cabce7adc1b67df975f4c11a",
            "filename": "src/transformers/video_processing_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fvideo_processing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8340e8746e7d27cce05253ec0f2845aeb0313884/src%2Ftransformers%2Fvideo_processing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fvideo_processing_utils.py?ref=8340e8746e7d27cce05253ec0f2845aeb0313884",
            "patch": "@@ -579,7 +579,7 @@ def get_video_processor_dict(\n                     revision=revision,\n                     subfolder=subfolder,\n                 )\n-            except EnvironmentError:\n+            except OSError:\n                 video_processor_file = \"preprocessor_config.json\"\n                 resolved_video_processor_file = cached_file(\n                     pretrained_model_name_or_path,\n@@ -600,13 +600,13 @@ def get_video_processor_dict(\n                     \"the file or load and save the processor back which renames it automatically. \"\n                     \"Loading from `preprocessor.json` will be removed in v5.0.\"\n                 )\n-            except EnvironmentError:\n+            except OSError:\n                 # Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\n                 # the original exception.\n                 raise\n             except Exception:\n                 # For any other exception, we throw a generic error.\n-                raise EnvironmentError(\n+                raise OSError(\n                     f\"Can't load video processor for '{pretrained_model_name_or_path}'. If you were trying to load\"\n                     \" it from 'https://huggingface.co/models', make sure you don't have a local directory with the\"\n                     f\" same name. Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a\"\n@@ -620,7 +620,7 @@ def get_video_processor_dict(\n             video_processor_dict = json.loads(text)\n \n         except json.JSONDecodeError:\n-            raise EnvironmentError(\n+            raise OSError(\n                 f\"It looks like the config file at '{resolved_video_processor_file}' is not a valid JSON file.\"\n             )\n "
        }
    ],
    "stats": {
        "total": 110,
        "additions": 54,
        "deletions": 56
    }
}