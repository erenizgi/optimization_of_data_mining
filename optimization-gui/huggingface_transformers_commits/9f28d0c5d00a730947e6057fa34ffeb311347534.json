{
    "author": "yonigozlan",
    "message": "Fix torchvision interpolation CI (#34539)\n\nfix-torch-interpolation-ci",
    "sha": "9f28d0c5d00a730947e6057fa34ffeb311347534",
    "files": [
        {
            "sha": "b414b4224e683c759948d02d7433ed58fc81f70c",
            "filename": "src/transformers/models/detr/image_processing_detr_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/9f28d0c5d00a730947e6057fa34ffeb311347534/src%2Ftransformers%2Fmodels%2Fdetr%2Fimage_processing_detr_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9f28d0c5d00a730947e6057fa34ffeb311347534/src%2Ftransformers%2Fmodels%2Fdetr%2Fimage_processing_detr_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdetr%2Fimage_processing_detr_fast.py?ref=9f28d0c5d00a730947e6057fa34ffeb311347534",
            "patch": "@@ -347,7 +347,7 @@ def __init__(\n         format: Union[str, AnnotationFormat] = AnnotationFormat.COCO_DETECTION,\n         do_resize: bool = True,\n         size: Dict[str, int] = None,\n-        resample: [Union[PILImageResampling, F.InterpolationMode]] = PILImageResampling.BILINEAR,\n+        resample: Union[PILImageResampling, \"F.InterpolationMode\"] = PILImageResampling.BILINEAR,\n         do_rescale: bool = True,\n         rescale_factor: Union[int, float] = 1 / 255,\n         do_normalize: bool = True,\n@@ -462,7 +462,7 @@ def resize(\n         self,\n         image: torch.Tensor,\n         size: SizeDict,\n-        interpolation: F.InterpolationMode = F.InterpolationMode.BILINEAR,\n+        interpolation: \"F.InterpolationMode\" = None,\n         **kwargs,\n     ) -> torch.Tensor:\n         \"\"\"\n@@ -485,6 +485,7 @@ def resize(\n             interpolation (`InterpolationMode`, *optional*, defaults to `InterpolationMode.BILINEAR`):\n                 Resampling filter to use if resizing the image.\n         \"\"\"\n+        interpolation = interpolation if interpolation is not None else F.InterpolationMode.BILINEAR\n         if size.shortest_edge and size.longest_edge:\n             # Resize the image so that the shortest edge or the longest edge is of the given size\n             # while maintaining the aspect ratio of the original image.\n@@ -517,7 +518,7 @@ def resize_annotation(\n         orig_size: Tuple[int, int],\n         target_size: Tuple[int, int],\n         threshold: float = 0.5,\n-        interpolation: F.InterpolationMode = F.InterpolationMode.NEAREST,\n+        interpolation: \"F.InterpolationMode\" = None,\n     ):\n         \"\"\"\n         Resizes an annotation to a target size.\n@@ -534,6 +535,7 @@ def resize_annotation(\n             resample (`InterpolationMode`, defaults to `InterpolationMode.NEAREST`):\n                 The resampling filter to use when resizing the masks.\n         \"\"\"\n+        interpolation = interpolation if interpolation is not None else F.InterpolationMode.NEAREST\n         ratio_height, ratio_width = [target / orig for target, orig in zip(target_size, orig_size)]\n \n         new_annotation = {}\n@@ -680,7 +682,7 @@ def preprocess(\n         masks_path: Optional[Union[str, pathlib.Path]] = None,\n         do_resize: Optional[bool] = None,\n         size: Optional[Dict[str, int]] = None,\n-        resample: Optional[Union[PILImageResampling, F.InterpolationMode]] = None,\n+        resample: Optional[Union[PILImageResampling, \"F.InterpolationMode\"]] = None,\n         do_rescale: Optional[bool] = None,\n         rescale_factor: Optional[Union[int, float]] = None,\n         do_normalize: Optional[bool] = None,"
        },
        {
            "sha": "0470352d38f456086aa77d00e86a33bce95586be",
            "filename": "src/transformers/models/rt_detr/image_processing_rt_detr_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/9f28d0c5d00a730947e6057fa34ffeb311347534/src%2Ftransformers%2Fmodels%2Frt_detr%2Fimage_processing_rt_detr_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9f28d0c5d00a730947e6057fa34ffeb311347534/src%2Ftransformers%2Fmodels%2Frt_detr%2Fimage_processing_rt_detr_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frt_detr%2Fimage_processing_rt_detr_fast.py?ref=9f28d0c5d00a730947e6057fa34ffeb311347534",
            "patch": "@@ -43,7 +43,6 @@\n     get_image_type,\n     infer_channel_dimension_format,\n     make_list_of_images,\n-    pil_torch_interpolation_mapping,\n     validate_annotations,\n )\n from ...utils import (\n@@ -197,7 +196,7 @@ def __init__(\n         format: Union[str, AnnotationFormat] = AnnotationFormat.COCO_DETECTION,\n         do_resize: bool = True,\n         size: Dict[str, int] = None,\n-        resample: Union[PILImageResampling, F.InterpolationMode] = PILImageResampling.BILINEAR,\n+        resample: Union[PILImageResampling, \"F.InterpolationMode\"] = PILImageResampling.BILINEAR,\n         do_rescale: bool = True,\n         rescale_factor: Union[int, float] = 1 / 255,\n         do_normalize: bool = False,\n@@ -256,7 +255,7 @@ def resize(\n         self,\n         image: torch.Tensor,\n         size: SizeDict,\n-        interpolation: F.InterpolationMode = F.InterpolationMode.BILINEAR,\n+        interpolation: \"F.InterpolationMode\" = None,\n         **kwargs,\n     ) -> torch.Tensor:\n         \"\"\"\n@@ -279,6 +278,7 @@ def resize(\n             interpolation (`InterpolationMode`, *optional*, defaults to `InterpolationMode.BILINEAR`):\n                 Resampling filter to use if resizing the image.\n         \"\"\"\n+        interpolation = interpolation if interpolation is not None else F.InterpolationMode.BILINEAR\n         if size.shortest_edge and size.longest_edge:\n             # Resize the image so that the shortest edge or the longest edge is of the given size\n             # while maintaining the aspect ratio of the original image.\n@@ -312,7 +312,7 @@ def resize_annotation(\n         orig_size: Tuple[int, int],\n         target_size: Tuple[int, int],\n         threshold: float = 0.5,\n-        interpolation: F.InterpolationMode = F.InterpolationMode.NEAREST,\n+        interpolation: \"F.InterpolationMode\" = None,\n     ):\n         \"\"\"\n         Resizes an annotation to a target size.\n@@ -329,6 +329,7 @@ def resize_annotation(\n             resample (`InterpolationMode`, defaults to `InterpolationMode.NEAREST`):\n                 The resampling filter to use when resizing the masks.\n         \"\"\"\n+        interpolation = interpolation if interpolation is not None else F.InterpolationMode.NEAREST\n         ratio_height, ratio_width = [target / orig for target, orig in zip(target_size, orig_size)]\n \n         new_annotation = {}\n@@ -480,7 +481,7 @@ def preprocess(\n         masks_path: Optional[Union[str, pathlib.Path]] = None,\n         do_resize: Optional[bool] = None,\n         size: Optional[Dict[str, int]] = None,\n-        resample: Optional[Union[PILImageResampling, F.InterpolationMode]] = None,\n+        resample: Optional[Union[PILImageResampling, \"F.InterpolationMode\"]] = None,\n         do_rescale: Optional[bool] = None,\n         rescale_factor: Optional[Union[int, float]] = None,\n         do_normalize: Optional[bool] = None,"
        }
    ],
    "stats": {
        "total": 21,
        "additions": 12,
        "deletions": 9
    }
}