{
    "author": "mario-koddenbrock",
    "message": "Adjust device logging level and add minor fixes (#41636)\n\nThis commit addresses a noisy warning and improves the robustness of the base pipeline implementation.\n\n- The device placement message in the pipeline base class has been changed from a `warning` to a `debug` log. This reduces log noise for users who are aware of their device setup, while still providing the information for debugging purposes.\n\n- Additionally, potential `UnboundLocalError` exceptions in the `_pad` and `check_model_type` functions have been prevented by initializing variables before their conditional assignment.",
    "sha": "35dc8f0a2e07239633e5d44147af5014a67e43c4",
    "files": [
        {
            "sha": "c6af61e2d473367ff035be2b06d5e094e3587fe1",
            "filename": "src/transformers/pipelines/base.py",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/35dc8f0a2e07239633e5d44147af5014a67e43c4/src%2Ftransformers%2Fpipelines%2Fbase.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/35dc8f0a2e07239633e5d44147af5014a67e43c4/src%2Ftransformers%2Fpipelines%2Fbase.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fbase.py?ref=35dc8f0a2e07239633e5d44147af5014a67e43c4",
            "patch": "@@ -94,6 +94,7 @@ def _pad(items, key, padding_value, padding_side):\n         min_length = min(item[key].shape[1] for item in items)\n         dtype = items[0][key].dtype\n \n+        tensor = None\n         if dim == 2:\n             if max_length == min_length:\n                 # Bypass for `ImageGPT` which doesn't provide a padding value, yet\n@@ -105,6 +106,9 @@ def _pad(items, key, padding_value, padding_side):\n         elif dim == 4:\n             tensor = torch.zeros((batch_size, max_length, shape[-2], shape[-1]), dtype=dtype) + padding_value\n \n+        if tensor is None:\n+            raise ValueError(f\"Unable to create tensor for padding from {key} with dimension {dim}\")\n+\n         for i, item in enumerate(items):\n             if dim == 2:\n                 if padding_side == \"left\":\n@@ -866,7 +870,7 @@ def __init__(\n \n         if torch.distributed.is_available() and torch.distributed.is_initialized():\n             self.device = self.model.device\n-        logger.warning(f\"Device set to use {self.device}\")\n+        logger.debug(f\"Device set to use {self.device}\")\n \n         self.binary_output = binary_output\n \n@@ -1127,6 +1131,7 @@ def check_model_type(self, supported_models: Union[list[str], dict]):\n             if self.task in SUPPORTED_PEFT_TASKS:\n                 supported_models_names.extend(SUPPORTED_PEFT_TASKS[self.task])\n \n+            model_name = None\n             for model_name in supported_models.values():\n                 # Mapping can now contain tuples of models for the same configuration.\n                 if isinstance(model_name, tuple):"
        }
    ],
    "stats": {
        "total": 7,
        "additions": 6,
        "deletions": 1
    }
}