{
    "author": "pramodith",
    "message": "Trainer: Pass `num_items_in_batch` to `compute_loss` in `prediction_step` (#41183)\n\n* Add num_items_in_batch computation to predict_step.\n\n* address comments.\n\n* Fix test cases.\n\n* fixup\n\n---------\n\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>",
    "sha": "3edd8048b01c51f1d1e721baa991cad5f77d6625",
    "files": [
        {
            "sha": "d03b30ee2990d071c0a63c3baf24c037534cf767",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 28,
            "deletions": 14,
            "changes": 42,
            "blob_url": "https://github.com/huggingface/transformers/blob/3edd8048b01c51f1d1e721baa991cad5f77d6625/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3edd8048b01c51f1d1e721baa991cad5f77d6625/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=3edd8048b01c51f1d1e721baa991cad5f77d6625",
            "patch": "@@ -4844,7 +4844,10 @@ def prediction_step(\n             else:\n                 if has_labels or loss_without_labels:\n                     with self.compute_loss_context_manager():\n-                        loss, outputs = self.compute_loss(model, inputs, return_outputs=True)\n+                        num_items_in_batch = self._get_num_items_in_batch([inputs], self.args.device)\n+                        loss, outputs = self.compute_loss(\n+                            model, inputs, return_outputs=True, num_items_in_batch=num_items_in_batch\n+                        )\n                     loss = loss.detach().mean()\n \n                     if isinstance(outputs, dict):\n@@ -5533,21 +5536,16 @@ def _fsdp_qlora_plugin_updates(self):\n                     self.model.hf_quantizer.quantization_config.bnb_4bit_quant_storage, override=True\n                 )\n \n-    def get_batch_samples(\n-        self, epoch_iterator: Iterator, num_batches: int, device: torch.device\n-    ) -> tuple[list, Optional[Union[torch.Tensor, int]]]:\n+    def _get_num_items_in_batch(self, batch_samples: list, device: torch.device) -> int | None:\n         \"\"\"\n-        Collects a specified number of batches from the epoch iterator and optionally counts the number of items in the batches to properly scale the loss.\n+        Counts the number of items in the batches to properly scale the loss.\n+        Args:\n+            batch_samples (`list`): List of batches\n+            device (`torch.device`): The device on which the number of items in the batch should be.\n+        Returns:\n+            None if the number of items in the batch doesn't need to be computed else the number of items in the batch\n         \"\"\"\n-        batch_samples = []\n         num_items_in_batch = None\n-\n-        for _ in range(num_batches):\n-            try:\n-                batch_samples.append(next(epoch_iterator))\n-            except StopIteration:\n-                break\n-\n         count_num_items_in_batch = (\n             len(batch_samples) > 0\n             and \"labels\" in batch_samples[0]\n@@ -5562,7 +5560,6 @@ def get_batch_samples(\n                 # https://github.com/huggingface/transformers/blob/v4.49.0/src/transformers/trainer.py#L3790\n             )\n         )\n-\n         if count_num_items_in_batch:\n             # For now we don't support object detection\n             try:\n@@ -5588,6 +5585,23 @@ def get_batch_samples(\n                 if pc := getattr(self.accelerator, \"parallelism_config\", None):\n                     num_items_in_batch = num_items_in_batch // pc.non_data_parallel_size\n \n+        return num_items_in_batch\n+\n+    def get_batch_samples(\n+        self, epoch_iterator: Iterator, num_batches: int, device: torch.device\n+    ) -> tuple[list, Optional[Union[torch.Tensor, int]]]:\n+        \"\"\"\n+        Collects a specified number of batches from the epoch iterator and optionally counts the number of items in the batches to properly scale the loss.\n+        \"\"\"\n+        batch_samples = []\n+\n+        for _ in range(num_batches):\n+            try:\n+                batch_samples.append(next(epoch_iterator))\n+            except StopIteration:\n+                break\n+\n+        num_items_in_batch = self._get_num_items_in_batch(batch_samples, device)\n         return batch_samples, num_items_in_batch\n \n     def set_initial_training_values("
        },
        {
            "sha": "6e41388cd3cfbdf8f35f4da44747b3d152b68685",
            "filename": "tests/trainer/test_trainer.py",
            "status": "modified",
            "additions": 45,
            "deletions": 0,
            "changes": 45,
            "blob_url": "https://github.com/huggingface/transformers/blob/3edd8048b01c51f1d1e721baa991cad5f77d6625/tests%2Ftrainer%2Ftest_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3edd8048b01c51f1d1e721baa991cad5f77d6625/tests%2Ftrainer%2Ftest_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_trainer.py?ref=3edd8048b01c51f1d1e721baa991cad5f77d6625",
            "patch": "@@ -2872,6 +2872,9 @@ def test_evaluate_with_jit(self):\n             trainer = get_regression_trainer(\n                 a=1.5, b=2.5, compute_metrics=AlmostAccuracy(), jit_mode_eval=True, output_dir=tmp_dir\n             )\n+            # Make sure the trainer doesn't pass num_items_in_batch to the model's forward method,\n+            # since it's not in the model forward's signature when using JIT\n+            trainer.model_accepts_loss_kwargs = False\n             results = trainer.evaluate()\n \n             x, y = trainer.eval_dataset.x, trainer.eval_dataset.ys[0]\n@@ -2885,6 +2888,7 @@ def test_evaluate_with_jit(self):\n             trainer = get_regression_trainer(\n                 a=1.5, b=2.5, eval_len=66, compute_metrics=AlmostAccuracy(), jit_mode_eval=True, output_dir=tmp_dir\n             )\n+            trainer.model_accepts_loss_kwargs = False\n             results = trainer.evaluate()\n \n             x, y = trainer.eval_dataset.x, trainer.eval_dataset.ys[0]\n@@ -2903,6 +2907,7 @@ def test_evaluate_with_jit(self):\n                 jit_mode_eval=True,\n                 output_dir=tmp_dir,\n             )\n+            trainer.model_accepts_loss_kwargs = False\n             results = trainer.evaluate()\n \n             x, y = trainer.eval_dataset.x, trainer.eval_dataset.ys[0]\n@@ -2947,6 +2952,40 @@ def test_predict(self):\n             self.assertTrue(np.array_equal(labels[0], trainer.eval_dataset.ys[0]))\n             self.assertTrue(np.array_equal(labels[1], trainer.eval_dataset.ys[1]))\n \n+    def test_train_and_predict_loss_parity(self):\n+        \"\"\"\n+        Tests that the loss computed during a training_step is the same as the one computed during prediction_step.\n+        for the same inputs\n+        \"\"\"\n+        model = AutoModelForCausalLM.from_pretrained(\"hf-internal-testing/tiny-random-LlamaForCausalLM\")\n+        # Create a dummy batch of inputs\n+        inputs = {}\n+        inputs[\"input_ids\"] = []\n+        for row_ind in range(4):\n+            seq_len = torch.randint(32, 64, (1,)).item()\n+            x = torch.randint(1, 100, (seq_len,))\n+            inputs[\"input_ids\"].append(x)\n+        inputs[\"input_ids\"] = torch.nn.utils.rnn.pad_sequence(inputs[\"input_ids\"], batch_first=True, padding_value=0)\n+        inputs[\"labels\"] = inputs[\"input_ids\"].clone()\n+        inputs[\"labels\"][inputs[\"input_ids\"] == 0] = -100\n+        num_items_in_batch = inputs[\"labels\"].ne(-100).sum().item()\n+\n+        def custom_loss_func(outputs, labels, num_items_in_batch=None):\n+            logits = outputs[\"logits\"]\n+            loss_fct = torch.nn.CrossEntropyLoss()\n+            loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n+            if num_items_in_batch is not None:\n+                return loss / num_items_in_batch  # multiply by number of items to get the sum\n+            return loss\n+\n+        trainer = Trainer(model, train_dataset=None, compute_loss_func=custom_loss_func)\n+\n+        # creating log history of trainer, results don't matter\n+        train_loss = trainer.training_step(model, inputs, num_items_in_batch)\n+        predict_loss = trainer.prediction_step(model, inputs, prediction_loss_only=True)[0]\n+\n+        torch.testing.assert_close(train_loss, predict_loss, atol=1e-6, rtol=0)\n+\n     def test_predict_with_batch_eval_metrics(self):\n         with tempfile.TemporaryDirectory() as tmp_dir:\n             trainer = get_regression_trainer(\n@@ -3014,18 +3053,23 @@ def test_predict_with_batch_eval_metrics(self):\n     def test_predict_with_jit(self):\n         with tempfile.TemporaryDirectory() as tmp_dir:\n             trainer = get_regression_trainer(a=1.5, b=2.5, jit_mode_eval=True, output_dir=tmp_dir)\n+            # Make sure the trainer doesn't pass num_items_in_batch to the model's forward method,\n+            # since it's not in the model forward's signature when using JIT\n+            trainer.model_accepts_loss_kwargs = False\n             preds = trainer.predict(trainer.eval_dataset).predictions\n             x = trainer.eval_dataset.x\n             self.assertTrue(np.allclose(preds, 1.5 * x + 2.5))\n \n             # With a number of elements not a round multiple of the batch size\n             trainer = get_regression_trainer(a=1.5, b=2.5, eval_len=66, jit_mode_eval=True, output_dir=tmp_dir)\n+            trainer.model_accepts_loss_kwargs = False\n             preds = trainer.predict(trainer.eval_dataset).predictions\n             x = trainer.eval_dataset.x\n             self.assertTrue(np.allclose(preds, 1.5 * x + 2.5))\n \n             # With more than one output of the model\n             trainer = get_regression_trainer(a=1.5, b=2.5, double_output=True, jit_mode_eval=True, output_dir=tmp_dir)\n+            trainer.model_accepts_loss_kwargs = False\n             preds = trainer.predict(trainer.eval_dataset).predictions\n             x = trainer.eval_dataset.x\n             self.assertEqual(len(preds), 2)\n@@ -3041,6 +3085,7 @@ def test_predict_with_jit(self):\n                 jit_mode_eval=True,\n                 output_dir=tmp_dir,\n             )\n+            trainer.model_accepts_loss_kwargs = False\n             outputs = trainer.predict(trainer.eval_dataset)\n             preds = outputs.predictions\n             labels = outputs.label_ids"
        }
    ],
    "stats": {
        "total": 87,
        "additions": 73,
        "deletions": 14
    }
}