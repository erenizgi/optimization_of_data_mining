{
    "author": "gante",
    "message": "[CI] fix update metadata job (#36850)\n\nfix updata_metadata job",
    "sha": "ecd60d01c3fee6811db40b3a5f9a8eb5977d75ba",
    "files": [
        {
            "sha": "d55b6e336c096709620cecfdc92f19c185038979",
            "filename": ".github/workflows/update_metdata.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ecd60d01c3fee6811db40b3a5f9a8eb5977d75ba/.github%2Fworkflows%2Fupdate_metdata.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/ecd60d01c3fee6811db40b3a5f9a8eb5977d75ba/.github%2Fworkflows%2Fupdate_metdata.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fupdate_metdata.yml?ref=ecd60d01c3fee6811db40b3a5f9a8eb5977d75ba",
            "patch": "@@ -19,7 +19,7 @@ jobs:\n       - name: Setup environment\n         run: |\n           pip install --upgrade pip\n-          pip install datasets pandas==2.0.3\n+          pip install datasets pandas\n           pip install .[torch,tf,flax]\n \n       - name: Update metadata"
        },
        {
            "sha": "5c65157d77856ef7bbff9126c101ffc9a606f9bf",
            "filename": "src/transformers/cache_utils.py",
            "status": "modified",
            "additions": 11,
            "deletions": 9,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/ecd60d01c3fee6811db40b3a5f9a8eb5977d75ba/src%2Ftransformers%2Fcache_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ecd60d01c3fee6811db40b3a5f9a8eb5977d75ba/src%2Ftransformers%2Fcache_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcache_utils.py?ref=ecd60d01c3fee6811db40b3a5f9a8eb5977d75ba",
            "patch": "@@ -537,6 +537,7 @@ def batch_select_indices(self, indices: torch.Tensor):\n             self.value_cache[layer_idx] = self.value_cache[layer_idx][indices, ...]\n \n \n+# Utilities for `DynamicCache` <> torch.export support\n def _flatten_dynamic_cache(\n     dynamic_cache: DynamicCache,\n ):\n@@ -584,15 +585,16 @@ def _flatten_dynamic_cache_for_fx(cache, spec):\n     return torch.utils._pytree.tree_flatten(dictionary)[0]\n \n \n-torch.utils._pytree.register_pytree_node(\n-    DynamicCache,\n-    _flatten_dynamic_cache,\n-    _unflatten_dynamic_cache,\n-    serialized_type_name=f\"{DynamicCache.__module__}.{DynamicCache.__name__}\",\n-    flatten_with_keys_fn=_flatten_with_keys_dynamic_cache,\n-)\n-# TODO (tmanlaibaatar) This won't be needed in torch 2.7.\n-torch.fx._pytree.register_pytree_flatten_spec(DynamicCache, _flatten_dynamic_cache_for_fx)\n+if is_torch_greater_or_equal(\"2.2\"):\n+    torch.utils._pytree.register_pytree_node(\n+        DynamicCache,\n+        _flatten_dynamic_cache,\n+        _unflatten_dynamic_cache,\n+        serialized_type_name=f\"{DynamicCache.__module__}.{DynamicCache.__name__}\",\n+        flatten_with_keys_fn=_flatten_with_keys_dynamic_cache,\n+    )\n+    # TODO (tmanlaibaatar) This won't be needed in torch 2.7.\n+    torch.fx._pytree.register_pytree_flatten_spec(DynamicCache, _flatten_dynamic_cache_for_fx)\n \n \n class OffloadedCache(DynamicCache):"
        }
    ],
    "stats": {
        "total": 22,
        "additions": 12,
        "deletions": 10
    }
}