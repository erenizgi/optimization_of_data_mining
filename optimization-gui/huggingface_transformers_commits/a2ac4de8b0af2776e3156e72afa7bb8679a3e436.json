{
    "author": "yonigozlan",
    "message": "Remove nested import logic for torchvision (#40940)\n\n* remove nested import logic for torchvision\n\n* remove unnecessary protected imports\n\n* remove unnecessarry protected import in modular (and modeling)\n\n* fix wrongly remove protected imports",
    "sha": "a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
    "files": [
        {
            "sha": "983fd4e169535128c995cc7d6cfb60ed95b0f825",
            "filename": "src/transformers/image_processing_utils_fast.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fimage_processing_utils_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fimage_processing_utils_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fimage_processing_utils_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -61,14 +61,14 @@\n \n if is_torchvision_available():\n     from .image_utils import pil_torch_interpolation_mapping\n-\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n else:\n     pil_torch_interpolation_mapping = None\n \n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+elif is_torchvision_available():\n+    from torchvision.transforms import functional as F\n+\n logger = logging.get_logger(__name__)\n \n "
        },
        {
            "sha": "7303ca2e9c50ab1a1c0f2ad706488bfcdfd24f38",
            "filename": "src/transformers/models/aria/modeling_aria.py",
            "status": "modified",
            "additions": 3,
            "deletions": 6,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -21,6 +21,9 @@\n from dataclasses import dataclass\n from typing import Callable, Optional, Union\n \n+import torch\n+from torch import nn\n+\n from ...activations import ACT2FN\n from ...cache_utils import Cache, DynamicCache\n from ...generation import GenerationMixin\n@@ -35,16 +38,10 @@\n from ...utils import TransformersKwargs, auto_docstring, can_return_tuple\n from ...utils.deprecation import deprecate_kwarg\n from ...utils.generic import check_model_inputs\n-from ...utils.import_utils import is_torch_available\n from ..auto import AutoModel\n from .configuration_aria import AriaConfig, AriaTextConfig\n \n \n-if is_torch_available():\n-    import torch\n-    from torch import nn\n-\n-\n @use_kernel_forward_from_hub(\"RMSNorm\")\n class AriaTextRMSNorm(nn.Module):\n     def __init__(self, hidden_size, eps=1e-6):"
        },
        {
            "sha": "a626d2cd4b823562650224124b0c996c23b70b26",
            "filename": "src/transformers/models/aria/modular_aria.py",
            "status": "modified",
            "additions": 2,
            "deletions": 5,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Faria%2Fmodular_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Faria%2Fmodular_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faria%2Fmodular_aria.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n from typing import Optional, Union\n \n import numpy as np\n+import torch\n+from torch import nn\n \n from ...activations import ACT2FN\n from ...cache_utils import Cache\n@@ -39,7 +41,6 @@\n from ...processing_utils import MultiModalData, ProcessingKwargs, ProcessorMixin, Unpack\n from ...tokenization_utils import PreTokenizedInput, TextInput\n from ...utils import TensorType, TransformersKwargs, auto_docstring, can_return_tuple, logging\n-from ...utils.import_utils import is_torch_available\n from ..auto import CONFIG_MAPPING, AutoConfig, AutoTokenizer\n from ..llama.configuration_llama import LlamaConfig\n from ..llama.modeling_llama import (\n@@ -62,10 +63,6 @@\n \n logger = logging.get_logger(__name__)\n \n-if is_torch_available():\n-    import torch\n-    from torch import nn\n-\n \n def sequential_experts_gemm(token_states, expert_weights, tokens_per_expert):\n     \"\"\""
        },
        {
            "sha": "e10dc552cf37bf12d70e2aa4048853b0c000e1d1",
            "filename": "src/transformers/models/beit/image_processing_beit_fast.py",
            "status": "modified",
            "additions": 3,
            "deletions": 6,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fbeit%2Fimage_processing_beit_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fbeit%2Fimage_processing_beit_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbeit%2Fimage_processing_beit_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -36,18 +38,13 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n if is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "44da5d4486e777cfb0af74d0764665cea0211e31",
            "filename": "src/transformers/models/bridgetower/image_processing_bridgetower_fast.py",
            "status": "modified",
            "additions": 7,
            "deletions": 9,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fimage_processing_bridgetower_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fimage_processing_bridgetower_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fimage_processing_bridgetower_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -17,6 +17,8 @@\n from collections.abc import Iterable\n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n     BatchFeature,\n@@ -29,17 +31,13 @@\n     reorder_images,\n )\n from ...image_utils import OPENAI_CLIP_MEAN, OPENAI_CLIP_STD, PILImageResampling\n-from ...utils import auto_docstring, is_torch_available, is_torchvision_available, is_torchvision_v2_available\n-\n+from ...utils import auto_docstring, is_torchvision_v2_available\n \n-if is_torch_available():\n-    import torch\n \n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n def make_pixel_mask("
        },
        {
            "sha": "39aa4ec87b009ccb3f0d8fa4783a9bf37a28dfbe",
            "filename": "src/transformers/models/chameleon/image_processing_chameleon_fast.py",
            "status": "modified",
            "additions": 9,
            "deletions": 19,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fchameleon%2Fimage_processing_chameleon_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fchameleon%2Fimage_processing_chameleon_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchameleon%2Fimage_processing_chameleon_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -17,28 +17,18 @@\n from typing import Optional\n \n import numpy as np\n+import PIL\n+import torch\n \n from ...image_processing_utils_fast import BaseImageProcessorFast\n from ...image_utils import ImageInput, PILImageResampling, SizeDict\n-from ...utils import (\n-    auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n-    is_torchvision_v2_available,\n-    is_vision_available,\n-    logging,\n-)\n-\n-\n-if is_vision_available():\n-    import PIL\n-if is_torch_available():\n-    import torch\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+from ...utils import auto_docstring, is_torchvision_v2_available, logging\n+\n+\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n logger = logging.get_logger(__name__)\n "
        },
        {
            "sha": "7ef20305b99e6e6bd68bf02a7e67cd642e2c9ca1",
            "filename": "src/transformers/models/cohere2_vision/modular_cohere2_vision.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodular_cohere2_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodular_cohere2_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fmodular_cohere2_vision.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -32,11 +32,7 @@\n from ...cache_utils import Cache\n from ...modeling_flash_attention_utils import FlashAttentionKwargs\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TransformersKwargs,\n-    auto_docstring,\n-    logging,\n-)\n+from ...utils import TransformersKwargs, auto_docstring, logging\n from ...utils.generic import check_model_inputs\n from .configuration_cohere2_vision import Cohere2VisionConfig\n "
        },
        {
            "sha": "cf28475f4b3cd9298b958277678489f91c6b5c4d",
            "filename": "src/transformers/models/colpali/modular_colpali.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fcolpali%2Fmodular_colpali.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fcolpali%2Fmodular_colpali.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcolpali%2Fmodular_colpali.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -28,7 +28,6 @@\n if is_torch_available():\n     import torch\n \n-\n logger = logging.get_logger(__name__)\n \n "
        },
        {
            "sha": "f3ae79abf6fa2e3825a84b5c65e6e6fc416caa1d",
            "filename": "src/transformers/models/colqwen2/modular_colqwen2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fcolqwen2%2Fmodular_colqwen2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fcolqwen2%2Fmodular_colqwen2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcolqwen2%2Fmodular_colqwen2.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -30,7 +30,6 @@\n if is_torch_available():\n     import torch\n \n-\n logger = logging.get_logger(__name__)\n \n "
        },
        {
            "sha": "5b9fe632551706f1d209d615161e621471080df4",
            "filename": "src/transformers/models/conditional_detr/image_processing_conditional_detr_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 20,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fconditional_detr%2Fimage_processing_conditional_detr_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fconditional_detr%2Fimage_processing_conditional_detr_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fconditional_detr%2Fimage_processing_conditional_detr_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -7,6 +7,10 @@\n import pathlib\n from typing import Any, Optional, Union\n \n+import torch\n+from torch import nn\n+from torchvision.io import read_image\n+\n from ...image_processing_utils import BatchFeature, get_size_dict\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -29,14 +33,7 @@\n     validate_annotations,\n )\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TensorType,\n-    auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n-    is_torchvision_v2_available,\n-    logging,\n-)\n+from ...utils import TensorType, auto_docstring, is_torchvision_v2_available, logging\n from ...utils.import_utils import requires\n from .image_processing_conditional_detr import (\n     compute_segments,\n@@ -46,20 +43,9 @@\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-\n-if is_torch_available():\n-    from torch import nn\n-\n-\n if is_torchvision_v2_available():\n-    from torchvision.io import read_image\n     from torchvision.transforms.v2 import functional as F\n-\n-elif is_torchvision_available():\n-    from torchvision.io import read_image\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "9d0faf2c4b9ed19352bf28755206a82fbcd9a701",
            "filename": "src/transformers/models/conditional_detr/modular_conditional_detr.py",
            "status": "modified",
            "additions": 2,
            "deletions": 5,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fconditional_detr%2Fmodular_conditional_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fconditional_detr%2Fmodular_conditional_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fconditional_detr%2Fmodular_conditional_detr.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -1,21 +1,18 @@\n from typing import Union\n \n+import torch\n+\n from transformers.models.detr.image_processing_detr_fast import DetrImageProcessorFast\n \n from ...image_transforms import (\n     center_to_corners_format,\n )\n from ...utils import (\n     TensorType,\n-    is_torch_available,\n     logging,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-\n logger = logging.get_logger(__name__)\n \n "
        },
        {
            "sha": "a1002d9503999bde2cfbb9f9a3ca287c57e77e93",
            "filename": "src/transformers/models/convnext/image_processing_convnext_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fconvnext%2Fimage_processing_convnext_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fconvnext%2Fimage_processing_convnext_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fconvnext%2Fimage_processing_convnext_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -35,20 +37,14 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n class ConvNextFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "b3abae5af0a7f7613432e71ef13a1c3b9774176c",
            "filename": "src/transformers/models/deepseek_vl/configuration_deepseek_vl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeepseek_vl%2Fconfiguration_deepseek_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeepseek_vl%2Fconfiguration_deepseek_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_vl%2Fconfiguration_deepseek_vl.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -21,9 +21,7 @@\n from typing import Optional\n \n from ...configuration_utils import PretrainedConfig\n-from ...utils import (\n-    logging,\n-)\n+from ...utils import logging\n from ..auto import CONFIG_MAPPING, AutoConfig\n \n "
        },
        {
            "sha": "896e91f0692c13f99d53ca475ddbebb60dd8affe",
            "filename": "src/transformers/models/deepseek_vl/image_processing_deepseek_vl_fast.py",
            "status": "modified",
            "additions": 2,
            "deletions": 9,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeepseek_vl%2Fimage_processing_deepseek_vl_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeepseek_vl%2Fimage_processing_deepseek_vl_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_vl%2Fimage_processing_deepseek_vl_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -20,6 +20,7 @@\n \n from typing import Optional, Union\n \n+import torch\n import torch.nn.functional as F\n \n from ...image_processing_utils import BatchFeature\n@@ -31,15 +32,7 @@\n )\n from ...image_utils import OPENAI_CLIP_MEAN, OPENAI_CLIP_STD, PILImageResampling, SizeDict\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TensorType,\n-    auto_docstring,\n-    is_torch_available,\n-)\n-\n-\n-if is_torch_available():\n-    import torch\n+from ...utils import TensorType, auto_docstring\n \n \n class DeepseekVLFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "22d8e0928a6e7abb997173de92801ccfda3bdc2c",
            "filename": "src/transformers/models/deepseek_vl/modeling_deepseek_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 6,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeepseek_vl%2Fmodeling_deepseek_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeepseek_vl%2Fmodeling_deepseek_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_vl%2Fmodeling_deepseek_vl.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -21,6 +21,9 @@\n from dataclasses import dataclass\n from typing import Optional, Union\n \n+import torch\n+import torch.nn as nn\n+\n from ...cache_utils import Cache\n from ...generation import GenerationMixin\n from ...modeling_outputs import ModelOutput\n@@ -30,17 +33,11 @@\n     TransformersKwargs,\n     auto_docstring,\n     can_return_tuple,\n-    is_torch_available,\n )\n from ..auto import AutoModel\n from .configuration_deepseek_vl import DeepseekVLConfig\n \n \n-if is_torch_available():\n-    import torch\n-    import torch.nn as nn\n-\n-\n @dataclass\n @auto_docstring(\n     custom_intro=\"\"\""
        },
        {
            "sha": "5bfc0ae7d74c3b48f9a009edcc7daba60ccc3382",
            "filename": "src/transformers/models/deepseek_vl/modular_deepseek_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeepseek_vl%2Fmodular_deepseek_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeepseek_vl%2Fmodular_deepseek_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_vl%2Fmodular_deepseek_vl.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -14,6 +14,9 @@\n \n from typing import Optional, Union\n \n+import torch\n+import torch.nn as nn\n+\n from ...configuration_utils import PretrainedConfig\n from ...image_processing_utils import BatchFeature\n from ...image_utils import ImageInput\n@@ -24,7 +27,6 @@\n )\n from ...utils import (\n     auto_docstring,\n-    is_torch_available,\n     logging,\n )\n from ..auto import CONFIG_MAPPING, AutoConfig, AutoModel\n@@ -34,10 +36,6 @@\n from ..janus.modeling_janus import JanusForConditionalGeneration, JanusModel, JanusPreTrainedModel\n \n \n-if is_torch_available():\n-    import torch\n-    import torch.nn as nn\n-\n logger = logging.get_logger(__name__)\n \n "
        },
        {
            "sha": "e8c6e2df6ea31b295fa4fd277a9e7257e976ca8f",
            "filename": "src/transformers/models/deepseek_vl_hybrid/configuration_deepseek_vl_hybrid.py",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeepseek_vl_hybrid%2Fconfiguration_deepseek_vl_hybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeepseek_vl_hybrid%2Fconfiguration_deepseek_vl_hybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_vl_hybrid%2Fconfiguration_deepseek_vl_hybrid.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -21,9 +21,7 @@\n from typing import Optional\n \n from ...configuration_utils import PretrainedConfig\n-from ...utils import (\n-    logging,\n-)\n+from ...utils import logging\n from ..auto import CONFIG_MAPPING, AutoConfig\n \n "
        },
        {
            "sha": "db9c9ad987c16fca0ebc7a864c7db4f03e668537",
            "filename": "src/transformers/models/deepseek_vl_hybrid/image_processing_deepseek_vl_hybrid_fast.py",
            "status": "modified",
            "additions": 10,
            "deletions": 12,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeepseek_vl_hybrid%2Fimage_processing_deepseek_vl_hybrid_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeepseek_vl_hybrid%2Fimage_processing_deepseek_vl_hybrid_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_vl_hybrid%2Fimage_processing_deepseek_vl_hybrid_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -30,25 +30,23 @@\n     group_images_by_shape,\n     reorder_images,\n )\n-from ...image_utils import OPENAI_CLIP_MEAN, OPENAI_CLIP_STD, ChannelDimension, PILImageResampling, SizeDict\n-from ...processing_utils import Unpack\n-from ...utils import (\n-    TensorType,\n-    auto_docstring,\n-    is_torchvision_available,\n-    is_torchvision_v2_available,\n+from ...image_utils import (\n+    OPENAI_CLIP_MEAN,\n+    OPENAI_CLIP_STD,\n+    ChannelDimension,\n+    PILImageResampling,\n+    SizeDict,\n+    pil_torch_interpolation_mapping,\n )\n+from ...processing_utils import Unpack\n+from ...utils import TensorType, auto_docstring, is_torchvision_v2_available\n \n \n if is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-\n-    from ...image_utils import pil_torch_interpolation_mapping\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n-    from ...image_utils import pil_torch_interpolation_mapping\n-\n \n class DeepseekVLHybridFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):\n     r\"\"\""
        },
        {
            "sha": "d97b00f7fbd2d9619453f73b1cd7cc549eb897d6",
            "filename": "src/transformers/models/deepseek_vl_hybrid/modular_deepseek_vl_hybrid.py",
            "status": "modified",
            "additions": 2,
            "deletions": 6,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeepseek_vl_hybrid%2Fmodular_deepseek_vl_hybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeepseek_vl_hybrid%2Fmodular_deepseek_vl_hybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_vl_hybrid%2Fmodular_deepseek_vl_hybrid.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -37,6 +37,7 @@\n     infer_channel_dimension_format,\n     is_scaled_image,\n     make_flat_list_of_images,\n+    pil_torch_interpolation_mapping,\n     to_numpy_array,\n     valid_images,\n     validate_preprocess_arguments,\n@@ -52,7 +53,6 @@\n     auto_docstring,\n     can_return_tuple,\n     filter_out_non_signature_kwargs,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n )\n@@ -72,13 +72,9 @@\n \n if is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-\n-    from ...image_utils import pil_torch_interpolation_mapping\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n-    from ...image_utils import pil_torch_interpolation_mapping\n-\n \n logger = logging.get_logger(__name__)\n "
        },
        {
            "sha": "cd07f8db350b18a8013d12cbd732ad4a10ab6e3a",
            "filename": "src/transformers/models/deformable_detr/image_processing_deformable_detr_fast.py",
            "status": "modified",
            "additions": 5,
            "deletions": 16,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fimage_processing_deformable_detr_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fimage_processing_deformable_detr_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fimage_processing_deformable_detr_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -7,6 +7,9 @@\n import pathlib\n from typing import Any, Optional, Union\n \n+import torch\n+from torchvision.io import read_image\n+\n from ...image_processing_utils import BatchFeature, get_size_dict\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -29,28 +32,14 @@\n     validate_annotations,\n )\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TensorType,\n-    auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n-    is_torchvision_v2_available,\n-    logging,\n-)\n+from ...utils import TensorType, auto_docstring, is_torchvision_v2_available, logging\n from ...utils.import_utils import requires\n from .image_processing_deformable_detr import get_size_with_aspect_ratio\n \n \n-if is_torch_available():\n-    import torch\n-\n-\n if is_torchvision_v2_available():\n-    from torchvision.io import read_image\n     from torchvision.transforms.v2 import functional as F\n-\n-elif is_torchvision_available():\n-    from torchvision.io import read_image\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "2e38df7845a2b656475b9b20b12c9198cc1a9ca6",
            "filename": "src/transformers/models/deformable_detr/modular_deformable_detr.py",
            "status": "modified",
            "additions": 2,
            "deletions": 5,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fmodular_deformable_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fmodular_deformable_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fmodular_deformable_detr.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -1,19 +1,16 @@\n from typing import Union\n \n+import torch\n+\n from transformers.models.detr.image_processing_detr_fast import DetrImageProcessorFast\n \n from ...image_transforms import center_to_corners_format\n from ...utils import (\n     TensorType,\n-    is_torch_available,\n     logging,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-\n logger = logging.get_logger(__name__)\n \n "
        },
        {
            "sha": "76c1a53e007359615175a9ea35b8e55a16de15a0",
            "filename": "src/transformers/models/depth_pro/image_processing_depth_pro_fast.py",
            "status": "modified",
            "additions": 14,
            "deletions": 14,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdepth_pro%2Fimage_processing_depth_pro_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdepth_pro%2Fimage_processing_depth_pro_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdepth_pro%2Fimage_processing_depth_pro_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,14 +16,20 @@\n \n from typing import TYPE_CHECKING, Optional, Union\n \n+import torch\n+\n from ...image_processing_base import BatchFeature\n from ...image_processing_utils_fast import BaseImageProcessorFast, group_images_by_shape, reorder_images\n-from ...image_utils import IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD, PILImageResampling, SizeDict\n+from ...image_utils import (\n+    IMAGENET_STANDARD_MEAN,\n+    IMAGENET_STANDARD_STD,\n+    PILImageResampling,\n+    SizeDict,\n+    pil_torch_interpolation_mapping,\n+)\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n     requires_backends,\n@@ -34,20 +40,14 @@\n if TYPE_CHECKING:\n     from .modeling_depth_pro import DepthProDepthEstimatorOutput\n \n-logger = logging.get_logger(__name__)\n-\n-\n-if is_torch_available():\n-    import torch\n \n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n-if is_torchvision_available():\n-    from ...image_utils import pil_torch_interpolation_mapping\n \n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+logger = logging.get_logger(__name__)\n \n \n @auto_docstring"
        },
        {
            "sha": "96a89a98074cb1cd56a7624401e9da72b94fbe85",
            "filename": "src/transformers/models/detr/image_processing_detr_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 15,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdetr%2Fimage_processing_detr_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdetr%2Fimage_processing_detr_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdetr%2Fimage_processing_detr_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -19,6 +19,11 @@\n from collections import defaultdict\n from typing import Any, Optional, Union\n \n+import PIL\n+import torch\n+from torch import nn\n+from torchvision.io import read_image\n+\n from ...image_processing_utils import BatchFeature, get_size_dict\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -44,10 +49,7 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n-    is_vision_available,\n     logging,\n )\n from ...utils.import_utils import requires\n@@ -59,20 +61,9 @@\n )\n \n \n-if is_torch_available():\n-    import torch\n-    from torch import nn\n-\n-if is_vision_available():\n-    import PIL\n-\n-\n if is_torchvision_v2_available():\n-    from torchvision.io import read_image\n     from torchvision.transforms.v2 import functional as F\n-\n-elif is_torchvision_available():\n-    from torchvision.io import read_image\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "cdb68044bfc420bb0ceb029179a2bbfc9b3e2a4b",
            "filename": "src/transformers/models/dinov3_vit/image_processing_dinov3_vit_fast.py",
            "status": "modified",
            "additions": 5,
            "deletions": 9,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fimage_processing_dinov3_vit_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fimage_processing_dinov3_vit_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fimage_processing_dinov3_vit_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,31 +16,27 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from transformers.image_processing_base import BatchFeature\n from transformers.image_processing_utils_fast import BaseImageProcessorFast, group_images_by_shape, reorder_images\n from transformers.image_utils import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, PILImageResampling, SizeDict\n from transformers.utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n )\n from transformers.utils.import_utils import requires\n \n \n-logger = logging.get_logger(__name__)\n-\n-\n-if is_torch_available():\n-    import torch\n-\n if is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n+logger = logging.get_logger(__name__)\n+\n \n @auto_docstring\n @requires(backends=(\"torchvision\", \"torch\"))"
        },
        {
            "sha": "7c808ab60cd49603db7c55841b300b0a4581c5c7",
            "filename": "src/transformers/models/donut/image_processing_donut_fast.py",
            "status": "modified",
            "additions": 7,
            "deletions": 11,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdonut%2Fimage_processing_donut_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdonut%2Fimage_processing_donut_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdonut%2Fimage_processing_donut_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,30 +16,26 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils_fast import BaseImageProcessorFast, BatchFeature, DefaultFastImageProcessorKwargs\n from ...image_transforms import group_images_by_shape, reorder_images\n from ...image_utils import IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD, ImageInput, PILImageResampling, SizeDict\n from ...processing_utils import Unpack\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n )\n \n \n-logger = logging.get_logger(__name__)\n-\n-if is_torch_available():\n-    import torch\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+logger = logging.get_logger(__name__)\n \n \n class DonutFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "d4848c50653c1bcbb1176df178d53de476200b6e",
            "filename": "src/transformers/models/dpt/image_processing_dpt_fast.py",
            "status": "modified",
            "additions": 4,
            "deletions": 12,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdpt%2Fimage_processing_dpt_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdpt%2Fimage_processing_dpt_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdpt%2Fimage_processing_dpt_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -24,6 +24,8 @@\n from collections.abc import Iterable\n from typing import TYPE_CHECKING, Optional, Union\n \n+import torch\n+\n from ...image_processing_base import BatchFeature\n from ...image_processing_utils_fast import BaseImageProcessorFast, DefaultFastImageProcessorKwargs\n from ...image_transforms import group_images_by_shape, reorder_images\n@@ -37,25 +39,15 @@\n     is_torch_tensor,\n )\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TensorType,\n-    auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n-    is_torchvision_v2_available,\n-    requires_backends,\n-)\n+from ...utils import TensorType, auto_docstring, is_torchvision_v2_available, requires_backends\n \n \n if TYPE_CHECKING:\n     from ...modeling_outputs import DepthEstimatorOutput\n \n-if is_torch_available():\n-    import torch\n-\n if is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "32ca94a2d43f5b57890d69c0015438775aaf0d35",
            "filename": "src/transformers/models/dpt/modular_dpt.py",
            "status": "modified",
            "additions": 3,
            "deletions": 6,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodular_dpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodular_dpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodular_dpt.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -18,6 +18,8 @@\n from collections.abc import Iterable\n from typing import TYPE_CHECKING, Optional, Union\n \n+import torch\n+\n from ...image_processing_base import BatchFeature\n from ...image_processing_utils_fast import BaseImageProcessorFast, DefaultFastImageProcessorKwargs\n from ...image_transforms import group_images_by_shape, reorder_images\n@@ -30,8 +32,6 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     requires_backends,\n )\n@@ -41,12 +41,9 @@\n if TYPE_CHECKING:\n     from ...modeling_outputs import DepthEstimatorOutput\n \n-if is_torch_available():\n-    import torch\n-\n if is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "5f7437c45b2e542556623ae93798f125971d1a97",
            "filename": "src/transformers/models/efficientloftr/image_processing_efficientloftr_fast.py",
            "status": "modified",
            "additions": 2,
            "deletions": 10,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fefficientloftr%2Fimage_processing_efficientloftr_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fefficientloftr%2Fimage_processing_efficientloftr_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fefficientloftr%2Fimage_processing_efficientloftr_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -17,6 +17,7 @@\n from typing import TYPE_CHECKING, Optional, Union\n \n import torch\n+from PIL import Image, ImageDraw\n \n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n@@ -38,27 +39,18 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n-    is_vision_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n if TYPE_CHECKING:\n     from .modeling_efficientloftr import KeypointMatchingOutput\n \n if is_torchvision_v2_available():\n     import torchvision.transforms.v2.functional as F\n-elif is_torchvision_available():\n+else:\n     import torchvision.transforms.functional as F\n \n-if is_vision_available():\n-    from PIL import Image, ImageDraw\n-\n \n def _is_valid_image(image):\n     return is_pil_image(image) or ("
        },
        {
            "sha": "3544d927c146dba23405b85b2ffd55befc1940ba",
            "filename": "src/transformers/models/efficientnet/image_processing_efficientnet_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fimage_processing_efficientnet_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fimage_processing_efficientnet_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fimage_processing_efficientnet_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -17,27 +17,23 @@\n from functools import lru_cache\n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils_fast import BaseImageProcessorFast, BatchFeature, DefaultFastImageProcessorKwargs\n from ...image_transforms import group_images_by_shape, reorder_images\n from ...image_utils import IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD, ImageInput, PILImageResampling, SizeDict\n from ...processing_utils import Unpack\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n class EfficientNetFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "97a13a0745eb0cd53eedae5084e4c02a5f1a2da2",
            "filename": "src/transformers/models/eomt/image_processing_eomt_fast.py",
            "status": "modified",
            "additions": 5,
            "deletions": 10,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Feomt%2Fimage_processing_eomt_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Feomt%2Fimage_processing_eomt_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Feomt%2Fimage_processing_eomt_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -18,6 +18,7 @@\n from typing import Optional, Union\n \n import numpy as np\n+import torch\n \n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n@@ -39,8 +40,6 @@\n     TensorType,\n     auto_docstring,\n     filter_out_non_signature_kwargs,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n from .image_processing_eomt import (\n@@ -51,14 +50,10 @@\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n class EomtImageProcessorFastKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "97409ddd57eda43de96ceba2f06e8d818896a16c",
            "filename": "src/transformers/models/flava/image_processing_flava_fast.py",
            "status": "modified",
            "additions": 7,
            "deletions": 13,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fflava%2Fimage_processing_flava_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fflava%2Fimage_processing_flava_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflava%2Fimage_processing_flava_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -20,20 +20,20 @@\n from functools import lru_cache\n from typing import Any, Optional, Union\n \n+import torch\n+\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n     BatchFeature,\n     DefaultFastImageProcessorKwargs,\n     get_size_dict,\n )\n from ...image_transforms import ChannelDimension, group_images_by_shape, reorder_images\n-from ...image_utils import ImageInput, PILImageResampling, SizeDict\n+from ...image_utils import ImageInput, PILImageResampling, SizeDict, pil_torch_interpolation_mapping\n from ...processing_utils import Unpack\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n from .image_processing_flava import (\n@@ -45,16 +45,10 @@\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    from ...image_utils import pil_torch_interpolation_mapping\n-\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n class FlavaMaskingGenerator:"
        },
        {
            "sha": "763756faf73f6b9172238ff95ab18285f465c28d",
            "filename": "src/transformers/models/florence2/modeling_florence2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodeling_florence2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodeling_florence2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodeling_florence2.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -22,6 +22,9 @@\n from dataclasses import dataclass\n from typing import Any, Callable, Optional, Union\n \n+import torch.nn as nn\n+import torch.nn.functional as F\n+\n from ...activations import ACT2FN\n from ...cache_utils import Cache\n from ...generation import GenerationMixin\n@@ -41,8 +44,6 @@\n \n if is_torch_available():\n     import torch\n-    import torch.nn as nn\n-    import torch.nn.functional as F\n \n \n logger = logging.get_logger(__name__)"
        },
        {
            "sha": "f8732257f10249a847f39fc94630d2f40718cfc9",
            "filename": "src/transformers/models/florence2/modular_florence2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 10,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodular_florence2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodular_florence2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodular_florence2.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -18,6 +18,8 @@\n from typing import Any, Callable, Optional, Union\n \n import numpy as np\n+import torch.nn as nn\n+import torch.nn.functional as F\n \n from ...activations import ACT2FN\n from ...cache_utils import Cache\n@@ -28,13 +30,7 @@\n from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n from ...processing_utils import MultiModalData, ProcessorMixin, Unpack\n from ...tokenization_utils_base import PreTokenizedInput, TextInput\n-from ...utils import (\n-    TransformersKwargs,\n-    auto_docstring,\n-    can_return_tuple,\n-    is_torch_available,\n-    logging,\n-)\n+from ...utils import TransformersKwargs, auto_docstring, can_return_tuple, is_torch_available, logging\n from ..auto import CONFIG_MAPPING, AutoConfig\n from ..bart.modeling_bart import eager_attention_forward, shift_tokens_right\n from ..beit.modeling_beit import BeitDropPath\n@@ -45,9 +41,6 @@\n \n if is_torch_available():\n     import torch\n-    import torch.nn as nn\n-    import torch.nn.functional as F\n-\n \n logger = logging.get_logger(__name__)\n "
        },
        {
            "sha": "91b63e9da7db8495ff9172f67a8fbd7597156a20",
            "filename": "src/transformers/models/florence2/processing_florence2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fflorence2%2Fprocessing_florence2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fflorence2%2Fprocessing_florence2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflorence2%2Fprocessing_florence2.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -33,7 +33,6 @@\n if is_torch_available():\n     import torch\n \n-\n logger = logging.get_logger(__name__)\n \n "
        },
        {
            "sha": "eb828a89643d2871c8e3e8b59e3c43f4a6a39b2a",
            "filename": "src/transformers/models/gemma3/image_processing_gemma3_fast.py",
            "status": "modified",
            "additions": 7,
            "deletions": 15,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fgemma3%2Fimage_processing_gemma3_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fgemma3%2Fimage_processing_gemma3_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma3%2Fimage_processing_gemma3_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -18,37 +18,29 @@\n import math\n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n     BatchFeature,\n     DefaultFastImageProcessorKwargs,\n     group_images_by_shape,\n     reorder_images,\n )\n-from ...image_utils import IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD, ImageInput, SizeDict\n+from ...image_utils import IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD, ImageInput, PILImageResampling, SizeDict\n from ...processing_utils import Unpack\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n-    is_vision_available,\n     logging,\n )\n \n \n-if is_vision_available():\n-    from ...image_utils import PILImageResampling\n-\n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n logger = logging.get_logger(__name__)\n "
        },
        {
            "sha": "fbf4aebaac6ae54c25b2852030eb428a081e666e",
            "filename": "src/transformers/models/glm4v/image_processing_glm4v_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fglm4v%2Fimage_processing_glm4v_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fglm4v%2Fimage_processing_glm4v_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v%2Fimage_processing_glm4v_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import (\n     BatchFeature,\n )\n@@ -36,22 +38,16 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n )\n from .image_processing_glm4v import smart_resize\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n logger = logging.get_logger(__name__)\n "
        },
        {
            "sha": "5277f1c4e13bcf9c7ef0a57e79a093916777cf77",
            "filename": "src/transformers/models/got_ocr2/image_processing_got_ocr2_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fimage_processing_got_ocr2_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fimage_processing_got_ocr2_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fimage_processing_got_ocr2_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -28,21 +30,15 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n from .image_processing_got_ocr2 import get_optimal_tiled_canvas\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n class GotOcr2FastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "66528519eef8c111a1e49b0a9043fa756d4268c3",
            "filename": "src/transformers/models/grounding_dino/image_processing_grounding_dino_fast.py",
            "status": "modified",
            "additions": 5,
            "deletions": 15,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fgrounding_dino%2Fimage_processing_grounding_dino_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fgrounding_dino%2Fimage_processing_grounding_dino_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgrounding_dino%2Fimage_processing_grounding_dino_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -7,6 +7,9 @@\n import pathlib\n from typing import TYPE_CHECKING, Any, Optional, Union\n \n+import torch\n+from torchvision.io import read_image\n+\n from ...image_processing_utils import BatchFeature, get_size_dict\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -29,31 +32,18 @@\n     validate_annotations,\n )\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TensorType,\n-    auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n-    is_torchvision_v2_available,\n-    logging,\n-)\n+from ...utils import TensorType, auto_docstring, is_torchvision_v2_available, logging\n from ...utils.import_utils import requires\n from .image_processing_grounding_dino import get_size_with_aspect_ratio\n \n \n if TYPE_CHECKING:\n     from .modeling_grounding_dino import GroundingDinoObjectDetectionOutput\n \n-if is_torch_available():\n-    import torch\n-\n \n if is_torchvision_v2_available():\n-    from torchvision.io import read_image\n     from torchvision.transforms.v2 import functional as F\n-\n-elif is_torchvision_available():\n-    from torchvision.io import read_image\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "a7b9c570e7b0add68209f6b2933be7b813269327",
            "filename": "src/transformers/models/grounding_dino/modular_grounding_dino.py",
            "status": "modified",
            "additions": 2,
            "deletions": 4,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fgrounding_dino%2Fmodular_grounding_dino.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fgrounding_dino%2Fmodular_grounding_dino.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgrounding_dino%2Fmodular_grounding_dino.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -1,21 +1,19 @@\n from typing import TYPE_CHECKING, Optional, Union\n \n+import torch\n+\n from transformers.models.detr.image_processing_detr_fast import DetrImageProcessorFast\n \n from ...image_transforms import center_to_corners_format\n from ...utils import (\n     TensorType,\n-    is_torch_available,\n     logging,\n )\n \n \n if TYPE_CHECKING:\n     from .modeling_grounding_dino import GroundingDinoObjectDetectionOutput\n \n-if is_torch_available():\n-    import torch\n-\n \n logger = logging.get_logger(__name__)\n "
        },
        {
            "sha": "ddfee7c757fe8d30bde5d9364b0b4cd2c50c9b83",
            "filename": "src/transformers/models/imagegpt/image_processing_imagegpt_fast.py",
            "status": "modified",
            "additions": 5,
            "deletions": 10,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fimagegpt%2Fimage_processing_imagegpt_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fimagegpt%2Fimage_processing_imagegpt_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fimagegpt%2Fimage_processing_imagegpt_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -17,6 +17,7 @@\n from typing import Optional, Union\n \n import numpy as np\n+import torch\n \n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n@@ -29,20 +30,14 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n def squared_euclidean_distance_torch(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:"
        },
        {
            "sha": "9ed2732fb3d0a9dfe2be524e94015dce6039b166",
            "filename": "src/transformers/models/janus/image_processing_janus_fast.py",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fjanus%2Fimage_processing_janus_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fjanus%2Fimage_processing_janus_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjanus%2Fimage_processing_janus_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -34,17 +36,13 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n if is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "94e1c6288bd3559069abdbd4a2d1f54309505013",
            "filename": "src/transformers/models/janus/modeling_janus.py",
            "status": "modified",
            "additions": 2,
            "deletions": 12,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -24,6 +24,7 @@\n from typing import Callable, Optional, Union\n \n import torch\n+import torch.nn.functional as F\n from torch import nn\n \n from ...activations import ACT2FN\n@@ -34,23 +35,12 @@\n from ...modeling_outputs import BaseModelOutput, BaseModelOutputWithPooling, ModelOutput\n from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TransformersKwargs,\n-    auto_docstring,\n-    can_return_tuple,\n-    is_torch_available,\n-    logging,\n-    torch_int,\n-)\n+from ...utils import TransformersKwargs, auto_docstring, can_return_tuple, logging, torch_int\n from ...utils.generic import check_model_inputs\n from ..auto import AutoModel\n from .configuration_janus import JanusConfig, JanusVisionConfig, JanusVQVAEConfig\n \n \n-if is_torch_available():\n-    import torch.nn.functional as F\n-\n-\n logger = logging.get_logger(__name__)\n \n "
        },
        {
            "sha": "dcd5c1e1e730e070974c87a8f3790eed7f497019",
            "filename": "src/transformers/models/janus/modular_janus.py",
            "status": "modified",
            "additions": 4,
            "deletions": 12,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodular_janus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodular_janus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodular_janus.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -20,12 +20,15 @@\n \n import numpy as np\n import torch\n+import torch.nn.functional as F\n+import torch.utils.checkpoint\n from torch import nn\n \n from transformers.models.blip.image_processing_blip import BlipImageProcessor\n \n from ...activations import ACT2FN\n from ...cache_utils import Cache\n+from ...configuration_utils import PretrainedConfig\n from ...generation import ClassifierFreeGuidanceLogitsProcessor, GenerationMixin, GenerationMode, LogitsProcessorList\n from ...generation.utils import GenerateDecoderOnlyOutput\n from ...image_processing_utils import BatchFeature, get_size_dict\n@@ -51,11 +54,10 @@\n     auto_docstring,\n     can_return_tuple,\n     filter_out_non_signature_kwargs,\n-    is_torch_available,\n     is_vision_available,\n     logging,\n )\n-from ..auto import AutoModel\n+from ..auto import CONFIG_MAPPING, AutoConfig, AutoModel\n from ..blip_2.modeling_blip_2 import Blip2VisionModel\n from ..chameleon.configuration_chameleon import ChameleonVQVAEConfig\n from ..chameleon.modeling_chameleon import (\n@@ -71,19 +73,9 @@\n from ..siglip.modeling_siglip import SiglipEncoder, SiglipEncoderLayer, SiglipVisionEmbeddings\n \n \n-if is_torch_available():\n-    import torch\n-    import torch.nn as nn\n-    import torch.nn.functional as F\n-\n-\n if is_vision_available():\n     import PIL\n \n-from ...configuration_utils import PretrainedConfig\n-from ..auto import CONFIG_MAPPING, AutoConfig\n-\n-\n logger = logging.get_logger(__name__)\n \n # General docstring"
        },
        {
            "sha": "c6d8b1b1edf5c48f14bfa89f5bd2f4b09225a486",
            "filename": "src/transformers/models/kosmos2_5/image_processing_kosmos2_5_fast.py",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fkosmos2_5%2Fimage_processing_kosmos2_5_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fkosmos2_5%2Fimage_processing_kosmos2_5_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fkosmos2_5%2Fimage_processing_kosmos2_5_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -17,6 +17,8 @@\n import math\n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -26,11 +28,7 @@\n )\n from ...image_utils import ChannelDimension, ImageInput, get_image_size\n from ...processing_utils import Unpack\n-from ...utils import TensorType, auto_docstring, is_torch_available\n-\n-\n-if is_torch_available():\n-    import torch\n+from ...utils import TensorType, auto_docstring\n \n \n # Similar to transformers.models.pix2struct.image_processing_pix2struct.torch_extract_patches but dealing with a batch of images directly."
        },
        {
            "sha": "723687d5821986900f21be50d2f5447c1e75f984",
            "filename": "src/transformers/models/layoutlmv2/image_processing_layoutlmv2_fast.py",
            "status": "modified",
            "additions": 7,
            "deletions": 11,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fimage_processing_layoutlmv2_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fimage_processing_layoutlmv2_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fimage_processing_layoutlmv2_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,32 +16,28 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils_fast import BaseImageProcessorFast, BatchFeature, DefaultFastImageProcessorKwargs\n from ...image_transforms import ChannelDimension, group_images_by_shape, reorder_images\n from ...image_utils import ImageInput, PILImageResampling, SizeDict\n from ...processing_utils import Unpack\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n     requires_backends,\n )\n from .image_processing_layoutlmv2 import apply_tesseract\n \n \n-logger = logging.get_logger(__name__)\n-\n-if is_torch_available():\n-    import torch\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+logger = logging.get_logger(__name__)\n \n \n class LayoutLMv2FastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "2ab8f8dd48ccb69d43ee44bde37bc5ee2e2a424a",
            "filename": "src/transformers/models/layoutlmv3/image_processing_layoutlmv3_fast.py",
            "status": "modified",
            "additions": 7,
            "deletions": 11,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Flayoutlmv3%2Fimage_processing_layoutlmv3_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Flayoutlmv3%2Fimage_processing_layoutlmv3_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flayoutlmv3%2Fimage_processing_layoutlmv3_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,32 +16,28 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils_fast import BaseImageProcessorFast, BatchFeature, DefaultFastImageProcessorKwargs\n from ...image_transforms import ChannelDimension, group_images_by_shape, reorder_images\n from ...image_utils import IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD, ImageInput, PILImageResampling, SizeDict\n from ...processing_utils import Unpack\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n     requires_backends,\n )\n from .image_processing_layoutlmv3 import apply_tesseract\n \n \n-logger = logging.get_logger(__name__)\n-\n-if is_torch_available():\n-    import torch\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+logger = logging.get_logger(__name__)\n \n \n class LayoutLMv3FastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "e452894d6e2e70a9d2f2f94bcf6a70c505428083",
            "filename": "src/transformers/models/levit/image_processing_levit_fast.py",
            "status": "modified",
            "additions": 7,
            "deletions": 9,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Flevit%2Fimage_processing_levit_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Flevit%2Fimage_processing_levit_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flevit%2Fimage_processing_levit_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,23 +16,21 @@\n \n from typing import Optional\n \n+import torch\n+\n from ...image_processing_utils_fast import BaseImageProcessorFast, SizeDict\n from ...image_transforms import (\n     ChannelDimension,\n     get_resize_output_image_size,\n )\n from ...image_utils import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, PILImageResampling\n-from ...utils import auto_docstring, is_torch_available, is_torchvision_available, is_torchvision_v2_available\n-\n+from ...utils import auto_docstring, is_torchvision_v2_available\n \n-if is_torch_available():\n-    import torch\n \n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n @auto_docstring"
        },
        {
            "sha": "946fdde0a64307026851ce61ecc7e2e1bb6f8d8f",
            "filename": "src/transformers/models/llama4/image_processing_llama4_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fllama4%2Fimage_processing_llama4_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fllama4%2Fimage_processing_llama4_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllama4%2Fimage_processing_llama4_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -19,6 +19,8 @@\n from functools import lru_cache\n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -31,20 +33,14 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n def get_factors(dividend: int) -> set[int]:"
        },
        {
            "sha": "41bb94f5b7e046f895d3cbd26ba9a306c450280b",
            "filename": "src/transformers/models/llava/image_processing_llava_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 14,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fllava%2Fimage_processing_llava_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fllava%2Fimage_processing_llava_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava%2Fimage_processing_llava_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -36,24 +38,14 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n-    is_vision_available,\n )\n \n \n-if is_vision_available():\n-    from ...image_utils import PILImageResampling\n-\n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n class LlavaFastImageProcessorKwargs(DefaultFastImageProcessorKwargs): ..."
        },
        {
            "sha": "b502d98d6ac3e4c320d7504c91dc3e377bac9bf8",
            "filename": "src/transformers/models/llava_next/image_processing_llava_next_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fllava_next%2Fimage_processing_llava_next_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fllava_next%2Fimage_processing_llava_next_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_next%2Fimage_processing_llava_next_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature, get_patch_output_size, select_best_resolution\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -37,20 +39,14 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n class LlavaNextFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "eae6e3046f94bc2ee78a917b3e3e630e43b5a3f6",
            "filename": "src/transformers/models/llava_onevision/modeling_llava_onevision.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodeling_llava_onevision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodeling_llava_onevision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodeling_llava_onevision.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -35,11 +35,7 @@\n from ...modeling_outputs import BaseModelOutputWithPast, ModelOutput\n from ...modeling_utils import PreTrainedModel\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TransformersKwargs,\n-    auto_docstring,\n-    can_return_tuple,\n-)\n+from ...utils import TransformersKwargs, auto_docstring, can_return_tuple\n from ..auto import AutoModel\n from .configuration_llava_onevision import LlavaOnevisionConfig\n "
        },
        {
            "sha": "21688e7763bfb8ff8fec42ca50bf2bc2251ff751",
            "filename": "src/transformers/models/llava_onevision/modular_llava_onevision.py",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodular_llava_onevision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodular_llava_onevision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodular_llava_onevision.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -50,18 +50,15 @@\n     TensorType,\n     auto_docstring,\n     can_return_tuple,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n )\n \n \n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n-\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n logger = logging.get_logger(__name__)\n "
        },
        {
            "sha": "a5d66228811928a4ede0cc1a4275c6a794991428",
            "filename": "src/transformers/models/mask2former/image_processing_mask2former_fast.py",
            "status": "modified",
            "additions": 5,
            "deletions": 16,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fmask2former%2Fimage_processing_mask2former_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fmask2former%2Fimage_processing_mask2former_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmask2former%2Fimage_processing_mask2former_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -21,6 +21,9 @@\n import math\n from typing import Any, Optional, Union\n \n+import torch\n+from torch import nn\n+\n from ...image_processing_utils import BatchFeature, get_size_dict\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -39,14 +42,7 @@\n     PILImageResampling,\n )\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TensorType,\n-    auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n-    is_torchvision_v2_available,\n-    logging,\n-)\n+from ...utils import TensorType, auto_docstring, is_torchvision_v2_available, logging\n from .image_processing_mask2former import (\n     compute_segments,\n     convert_segmentation_to_rle,\n@@ -55,18 +51,11 @@\n )\n \n \n-if is_torch_available():\n-    import torch\n-    from torch import nn\n-\n-\n if is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n-\n logger = logging.get_logger(__name__)\n \n "
        },
        {
            "sha": "c5f3f58fedbb08849995de3f702762392756f1b8",
            "filename": "src/transformers/models/mask2former/modular_mask2former.py",
            "status": "modified",
            "additions": 3,
            "deletions": 6,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fmask2former%2Fmodular_mask2former.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fmask2former%2Fmodular_mask2former.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmask2former%2Fmodular_mask2former.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -14,11 +14,13 @@\n # limitations under the License.\n from typing import Optional\n \n+import torch\n+from torch import nn\n+\n from transformers.models.maskformer.image_processing_maskformer_fast import MaskFormerImageProcessorFast\n \n from ...utils import (\n     TensorType,\n-    is_torch_available,\n     logging,\n )\n from .image_processing_mask2former import (\n@@ -28,11 +30,6 @@\n )\n \n \n-if is_torch_available():\n-    import torch\n-    from torch import nn\n-\n-\n logger = logging.get_logger(__name__)\n \n "
        },
        {
            "sha": "ab6411f1bb3fe56c6c5ac4848fa8a9de20fd6f77",
            "filename": "src/transformers/models/maskformer/image_processing_maskformer_fast.py",
            "status": "modified",
            "additions": 8,
            "deletions": 14,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fimage_processing_maskformer_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fimage_processing_maskformer_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fimage_processing_maskformer_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -18,6 +18,9 @@\n import warnings\n from typing import TYPE_CHECKING, Any, Optional, Union\n \n+import torch\n+from torch import nn\n+\n from ...image_processing_utils import BatchFeature, get_size_dict\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -39,8 +42,6 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n )\n@@ -52,25 +53,18 @@\n )\n \n \n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n+\n logger = logging.get_logger(__name__)\n \n \n if TYPE_CHECKING:\n     from transformers import MaskFormerForInstanceSegmentationOutput\n \n \n-if is_torch_available():\n-    import torch\n-    from torch import nn\n-\n-\n-if is_torchvision_v2_available():\n-    from torchvision.transforms.v2 import functional as F\n-\n-elif is_torchvision_available():\n-    from torchvision.transforms import functional as F\n-\n-\n def convert_segmentation_map_to_binary_masks_fast(\n     segmentation_map: \"torch.Tensor\",\n     instance_id_to_semantic_id: Optional[dict[int, int]] = None,"
        },
        {
            "sha": "97ca39da78bf074eef67f753ed9731290472c1e2",
            "filename": "src/transformers/models/mobilenet_v2/image_processing_mobilenet_v2_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fmobilenet_v2%2Fimage_processing_mobilenet_v2_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fmobilenet_v2%2Fimage_processing_mobilenet_v2_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilenet_v2%2Fimage_processing_mobilenet_v2_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -36,20 +38,14 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n class MobileNetV2FastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "71c8ababba36cec7203369925d0bedafed83fa82",
            "filename": "src/transformers/models/mobilevit/image_processing_mobilevit_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fimage_processing_mobilevit_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fimage_processing_mobilevit_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fimage_processing_mobilevit_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -34,20 +36,14 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n class MobileVitFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "d6579029e4f5b70ab4a2d0fdc39750804e126ebc",
            "filename": "src/transformers/models/nougat/image_processing_nougat_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fnougat%2Fimage_processing_nougat_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fnougat%2Fimage_processing_nougat_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fnougat%2Fimage_processing_nougat_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -38,20 +40,14 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n class NougatFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "20b34bb7fd39aa769a157bc820b90d693aef2626",
            "filename": "src/transformers/models/oneformer/image_processing_oneformer_fast.py",
            "status": "modified",
            "additions": 8,
            "deletions": 12,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Foneformer%2Fimage_processing_oneformer_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Foneformer%2Fimage_processing_oneformer_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Foneformer%2Fimage_processing_oneformer_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,9 @@\n \n from typing import Optional, Union\n \n+import torch\n+from torch import nn\n+\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n     BatchFeature,\n@@ -36,25 +39,18 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n )\n from .image_processing_oneformer import load_metadata, prepare_metadata\n \n \n-logger = logging.get_logger(__name__)\n-\n-if is_torch_available():\n-    import torch\n-    from torch import nn\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+logger = logging.get_logger(__name__)\n \n \n def make_pixel_mask(image: \"torch.Tensor\", output_size: tuple[int, int]) -> \"torch.Tensor\":"
        },
        {
            "sha": "07fbf82f9fbeaf208b48bd2ffec1e0a3c4947d09",
            "filename": "src/transformers/models/ovis2/image_processing_ovis2_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fovis2%2Fimage_processing_ovis2_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fovis2%2Fimage_processing_ovis2_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fovis2%2Fimage_processing_ovis2_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -15,6 +15,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -33,21 +35,15 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n from .image_processing_ovis2 import get_min_tile_covering_grid, get_optimal_tiled_canvas\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n class Ovis2ImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "70441feba3c21746c623d651268e0de18e082a2c",
            "filename": "src/transformers/models/owlv2/image_processing_owlv2_fast.py",
            "status": "modified",
            "additions": 5,
            "deletions": 16,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fowlv2%2Fimage_processing_owlv2_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fowlv2%2Fimage_processing_owlv2_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fowlv2%2Fimage_processing_owlv2_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -22,6 +22,8 @@\n import warnings\n from typing import TYPE_CHECKING, Optional, Union\n \n+import torch\n+\n from ...image_processing_utils_fast import BaseImageProcessorFast, BatchFeature, DefaultFastImageProcessorKwargs\n from ...image_transforms import center_to_corners_format, group_images_by_shape, reorder_images\n from ...image_utils import (\n@@ -33,33 +35,20 @@\n     SizeDict,\n )\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TensorType,\n-    auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n-    is_torchvision_v2_available,\n-)\n-\n-\n-if is_torch_available():\n-    import torch\n+from ...utils import TensorType, auto_docstring, is_torchvision_v2_available\n+from .image_processing_owlv2 import _scale_boxes, box_iou\n \n \n if is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n \n if TYPE_CHECKING:\n     from .modeling_owlv2 import Owlv2ObjectDetectionOutput\n \n \n-if is_torch_available():\n-    from .image_processing_owlv2 import _scale_boxes, box_iou\n-\n-\n class Owlv2FastImageProcessorKwargs(DefaultFastImageProcessorKwargs): ...\n \n "
        },
        {
            "sha": "2e6d917a791adffb1692db20e97c4650469033de",
            "filename": "src/transformers/models/owlv2/modular_owlv2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 7,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fowlv2%2Fmodular_owlv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fowlv2%2Fmodular_owlv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fowlv2%2Fmodular_owlv2.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -17,6 +17,8 @@\n import warnings\n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n     BatchFeature,\n@@ -35,20 +37,14 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n from ..owlvit.image_processing_owlvit_fast import OwlViTImageProcessorFast\n \n \n-if is_torch_available():\n-    import torch\n-\n-\n if is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "1e458f964a04cd9bf12712f82f4691be374d497d",
            "filename": "src/transformers/models/owlvit/image_processing_owlvit_fast.py",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fowlvit%2Fimage_processing_owlvit_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fowlvit%2Fimage_processing_owlvit_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fowlvit%2Fimage_processing_owlvit_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -17,22 +17,19 @@\n import warnings\n from typing import TYPE_CHECKING, Optional, Union\n \n+import torch\n+\n from ...image_processing_utils_fast import BaseImageProcessorFast\n from ...image_transforms import center_to_corners_format\n from ...image_utils import OPENAI_CLIP_MEAN, OPENAI_CLIP_STD, PILImageResampling\n-from ...utils import TensorType, auto_docstring, is_torch_available, logging\n+from ...utils import TensorType, auto_docstring, logging\n+from .image_processing_owlvit import _scale_boxes, box_iou\n \n \n if TYPE_CHECKING:\n     from .modeling_owlvit import OwlViTObjectDetectionOutput\n \n \n-if is_torch_available():\n-    import torch\n-\n-    from .image_processing_owlvit import _scale_boxes, box_iou\n-\n-\n logger = logging.get_logger(__name__)\n \n "
        },
        {
            "sha": "82c1bcd9d319233d6232780336970acc92a16afb",
            "filename": "src/transformers/models/perceiver/image_processing_perceiver_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fperceiver%2Fimage_processing_perceiver_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fperceiver%2Fimage_processing_perceiver_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fperceiver%2Fimage_processing_perceiver_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,26 +16,22 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils_fast import BaseImageProcessorFast, BatchFeature\n from ...image_transforms import group_images_by_shape, reorder_images\n from ...image_utils import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, PILImageResampling, SizeDict\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n @auto_docstring"
        },
        {
            "sha": "be55c39572d5836bb9283ec29819e21192a3da71",
            "filename": "src/transformers/models/perception_lm/image_processing_perception_lm_fast.py",
            "status": "modified",
            "additions": 3,
            "deletions": 13,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fimage_processing_perception_lm_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fimage_processing_perception_lm_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fimage_processing_perception_lm_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -17,6 +17,8 @@\n from typing import Optional, Union\n \n import numpy as np\n+import torch\n+from torchvision.transforms import functional as F\n \n from ...image_processing_utils import (\n     BatchFeature,\n@@ -35,19 +37,7 @@\n     PILImageResampling,\n )\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TensorType,\n-    auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n-)\n-\n-\n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    from torchvision.transforms import functional as F\n+from ...utils import TensorType, auto_docstring\n \n \n class PerceptionLMFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "532136f8108ed75616a3551ce2d6c87d8cd3cd97",
            "filename": "src/transformers/models/phi4_multimodal/image_processing_phi4_multimodal_fast.py",
            "status": "modified",
            "additions": 5,
            "deletions": 10,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fimage_processing_phi4_multimodal_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fimage_processing_phi4_multimodal_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fimage_processing_phi4_multimodal_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -23,24 +23,19 @@\n     DefaultFastImageProcessorKwargs,\n     Unpack,\n )\n-from ...image_utils import ImageInput, SizeDict\n+from ...image_utils import ImageInput, PILImageResampling, SizeDict\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n-    is_vision_available,\n     logging,\n )\n \n \n-if is_vision_available():\n-    from ...image_utils import PILImageResampling\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n logger = logging.get_logger(__name__)\n "
        },
        {
            "sha": "db3e757603187099ae2357e7454cd6a505ec6673",
            "filename": "src/transformers/models/pixtral/image_processing_pixtral_fast.py",
            "status": "modified",
            "additions": 7,
            "deletions": 15,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fpixtral%2Fimage_processing_pixtral_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fpixtral%2Fimage_processing_pixtral_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpixtral%2Fimage_processing_pixtral_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature, get_size_dict\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -28,28 +30,18 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n-    is_vision_available,\n     logging,\n )\n from .image_processing_pixtral import get_resize_output_image_size\n \n \n-logger = logging.get_logger(__name__)\n-\n-if is_torch_available():\n-    import torch\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n-if is_torchvision_available():\n-    if is_vision_available():\n-        pass\n-\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+logger = logging.get_logger(__name__)\n \n \n class PixtralFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "70c6ed55bc8af13b4a78e68de73f216c1e2caebf",
            "filename": "src/transformers/models/poolformer/image_processing_poolformer_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fpoolformer%2Fimage_processing_poolformer_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fpoolformer%2Fimage_processing_poolformer_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpoolformer%2Fimage_processing_poolformer_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils_fast import BaseImageProcessorFast, BatchFeature, DefaultFastImageProcessorKwargs\n from ...image_transforms import (\n     ChannelDimension,\n@@ -36,20 +38,14 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n class PoolFormerFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "763fd613c218b1ebfe8de557e05641a81f743ffc",
            "filename": "src/transformers/models/prompt_depth_anything/image_processing_prompt_depth_anything_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fprompt_depth_anything%2Fimage_processing_prompt_depth_anything_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fprompt_depth_anything%2Fimage_processing_prompt_depth_anything_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fprompt_depth_anything%2Fimage_processing_prompt_depth_anything_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -23,6 +23,8 @@\n \n if TYPE_CHECKING:\n     from ...modeling_outputs import DepthEstimatorOutput\n+import torch\n+\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n     DefaultFastImageProcessorKwargs,\n@@ -40,21 +42,15 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     requires_backends,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n def _constrain_to_multiple_of(val, multiple, min_val=0, max_val=None):"
        },
        {
            "sha": "80242a331ace4a20b29379c70cd49d25261c5635",
            "filename": "src/transformers/models/qwen2_vl/image_processing_qwen2_vl_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 11,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fimage_processing_qwen2_vl_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fimage_processing_qwen2_vl_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fimage_processing_qwen2_vl_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -21,6 +21,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -40,24 +42,17 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n )\n from ...video_utils import VideoInput, make_batched_videos\n from .image_processing_qwen2_vl import smart_resize\n \n \n-if is_torch_available():\n-    import torch\n-\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n logger = logging.get_logger(__name__)\n "
        },
        {
            "sha": "68c5497b0205710b7961b7bb033d4214cff4267f",
            "filename": "src/transformers/models/rt_detr/image_processing_rt_detr_fast.py",
            "status": "modified",
            "additions": 4,
            "deletions": 13,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Frt_detr%2Fimage_processing_rt_detr_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Frt_detr%2Fimage_processing_rt_detr_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frt_detr%2Fimage_processing_rt_detr_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -7,6 +7,8 @@\n import pathlib\n from typing import Any, Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -29,25 +31,14 @@\n     validate_annotations,\n )\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TensorType,\n-    auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n-    is_torchvision_v2_available,\n-    requires_backends,\n-)\n+from ...utils import TensorType, auto_docstring, is_torchvision_v2_available, requires_backends\n from ...utils.import_utils import requires\n from .image_processing_rt_detr import get_size_with_aspect_ratio\n \n \n-if is_torch_available():\n-    import torch\n-\n-\n if is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "760e4a6675cf95494014b93cc178644d2eaced00",
            "filename": "src/transformers/models/rt_detr/modular_rt_detr.py",
            "status": "modified",
            "additions": 3,
            "deletions": 7,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Frt_detr%2Fmodular_rt_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Frt_detr%2Fmodular_rt_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frt_detr%2Fmodular_rt_detr.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -1,6 +1,8 @@\n import pathlib\n from typing import Optional, Union\n \n+import torch\n+\n from transformers.models.detr.image_processing_detr_fast import DetrFastImageProcessorKwargs, DetrImageProcessorFast\n \n from ...image_processing_utils import BatchFeature\n@@ -20,21 +22,15 @@\n from ...processing_utils import Unpack\n from ...utils import (\n     TensorType,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n     requires_backends,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-\n if is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "ba75e73c8680ade0ab5b640cc5db3f7f75da024f",
            "filename": "src/transformers/models/sam/image_processing_sam_fast.py",
            "status": "modified",
            "additions": 4,
            "deletions": 13,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsam%2Fimage_processing_sam_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsam%2Fimage_processing_sam_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam%2Fimage_processing_sam_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -21,6 +21,8 @@\n \n import numpy as np\n import torch\n+from torch.nn import functional as F\n+from torchvision.ops.boxes import batched_nms\n \n from ...image_processing_utils import BatchFeature, get_size_dict\n from ...image_processing_utils_fast import (\n@@ -37,23 +39,12 @@\n     pil_torch_interpolation_mapping,\n )\n from ...processing_utils import Unpack\n-from ...utils import (\n-    auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n-    is_torchvision_v2_available,\n-)\n-\n+from ...utils import auto_docstring, is_torchvision_v2_available\n \n-if is_torch_available():\n-    import torch\n-    from torch.nn import functional as F\n \n if is_torchvision_v2_available():\n-    from torchvision.ops.boxes import batched_nms\n     from torchvision.transforms.v2 import functional as F_t\n-elif is_torchvision_available():\n-    from torchvision.ops.boxes import batched_nms\n+else:\n     from torchvision.transforms import functional as F_t\n \n "
        },
        {
            "sha": "a55188f4e786f0e743f5d31e4fc4628b93fe6e3e",
            "filename": "src/transformers/models/sam2/image_processing_sam2_fast.py",
            "status": "modified",
            "additions": 1,
            "deletions": 8,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsam2%2Fimage_processing_sam2_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsam2%2Fimage_processing_sam2_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2%2Fimage_processing_sam2_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -26,6 +26,7 @@\n import numpy as np\n import torch\n import torch.nn.functional as F\n+from torchvision.ops.boxes import batched_nms\n \n from ...image_processing_utils import BatchFeature, get_size_dict\n from ...image_processing_utils_fast import BaseImageProcessorFast, DefaultFastImageProcessorKwargs\n@@ -42,17 +43,9 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torchvision_available,\n-    is_torchvision_v2_available,\n )\n \n \n-if is_torchvision_v2_available():\n-    from torchvision.ops.boxes import batched_nms\n-elif is_torchvision_available():\n-    from torchvision.ops.boxes import batched_nms\n-\n-\n class Sam2FastImageProcessorKwargs(DefaultFastImageProcessorKwargs):\n     r\"\"\"\n     mask_size (`dict[str, int]`, *optional*):"
        },
        {
            "sha": "daab10855512ec2a226848db7f0dbd33e251c097",
            "filename": "src/transformers/models/sam2/modular_sam2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -41,7 +41,6 @@\n     ModelOutput,\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n     logging,\n )\n from ...utils.generic import TransformersKwargs, check_model_inputs\n@@ -68,11 +67,6 @@\n )\n \n \n-if is_torch_available():\n-    import torch\n-    from torch.nn import functional as F\n-\n-\n logger = logging.get_logger(__name__)\n \n "
        },
        {
            "sha": "c0c9b3e1ef7aa5b36b8ba0154889ef5f586ee6e3",
            "filename": "src/transformers/models/sam2_video/modular_sam2_video.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodular_sam2_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodular_sam2_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodular_sam2_video.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -36,7 +36,6 @@\n from ...utils import (\n     ModelOutput,\n     auto_docstring,\n-    is_torch_available,\n     is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n@@ -60,12 +59,9 @@\n from ..sam2.processing_sam2 import Sam2Processor\n \n \n-if is_torch_available():\n-    import torch\n-\n if is_torchvision_available() and is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "da4bef3e9ee8d3153925fcdc5b0a423fc60ef6b3",
            "filename": "src/transformers/models/segformer/image_processing_segformer_fast.py",
            "status": "modified",
            "additions": 4,
            "deletions": 11,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsegformer%2Fimage_processing_segformer_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsegformer%2Fimage_processing_segformer_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsegformer%2Fimage_processing_segformer_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -21,6 +21,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -38,21 +40,12 @@\n     is_torch_tensor,\n )\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TensorType,\n-    auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n-    is_torchvision_v2_available,\n-)\n-\n+from ...utils import TensorType, auto_docstring, is_torchvision_v2_available\n \n-if is_torch_available():\n-    import torch\n \n if is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "341e6949d8b74d4b4094d35501a1e53ddcf70926",
            "filename": "src/transformers/models/segformer/modular_segformer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 6,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsegformer%2Fmodular_segformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsegformer%2Fmodular_segformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsegformer%2Fmodular_segformer.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from transformers.models.beit.image_processing_beit_fast import BeitFastImageProcessorKwargs, BeitImageProcessorFast\n \n from ...image_processing_utils import BatchFeature\n@@ -34,18 +36,13 @@\n from ...processing_utils import Unpack\n from ...utils import (\n     TensorType,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n if is_torchvision_v2_available():\n     from torchvision.transforms.v2 import functional as F\n-elif is_torchvision_available():\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "64dcfa1ad566b39848856dbb3e1c2457be3d85ee",
            "filename": "src/transformers/models/siglip2/image_processing_siglip2_fast.py",
            "status": "modified",
            "additions": 4,
            "deletions": 11,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsiglip2%2Fimage_processing_siglip2_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsiglip2%2Fimage_processing_siglip2_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsiglip2%2Fimage_processing_siglip2_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -32,23 +32,16 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n )\n from .image_processing_siglip2 import get_image_size_for_max_num_patches\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n-\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n logger = logging.get_logger(__name__)\n "
        },
        {
            "sha": "7e8e544b8fc76a7788114e29ffaf12ce31f08b83",
            "filename": "src/transformers/models/smolvlm/video_processing_smolvlm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fvideo_processing_smolvlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fvideo_processing_smolvlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fvideo_processing_smolvlm.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -21,7 +21,7 @@\n from ...image_processing_utils import BatchFeature, get_size_dict\n from ...image_utils import IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD, PILImageResampling, SizeDict\n from ...processing_utils import Unpack, VideosKwargs\n-from ...utils import TensorType, is_torchvision_v2_available\n+from ...utils import TensorType, is_torchvision_v2_available, logging\n from ...video_processing_utils import BaseVideoProcessor\n from ...video_utils import VideoMetadata, group_videos_by_shape, reorder_videos\n \n@@ -31,8 +31,6 @@\n else:\n     from torchvision.transforms import functional as F\n \n-from ...utils import logging\n-\n \n logger = logging.get_logger(__name__)\n "
        },
        {
            "sha": "a752e08ac5f0afce12802248cd7942d2d1ba6a94",
            "filename": "src/transformers/models/superpoint/image_processing_superpoint_fast.py",
            "status": "modified",
            "additions": 3,
            "deletions": 6,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsuperpoint%2Fimage_processing_superpoint_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fsuperpoint%2Fimage_processing_superpoint_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsuperpoint%2Fimage_processing_superpoint_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import TYPE_CHECKING, Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -31,21 +33,16 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n if TYPE_CHECKING:\n     from .modeling_superpoint import SuperPointKeypointDescriptionOutput\n \n if is_torchvision_v2_available():\n     import torchvision.transforms.v2.functional as F\n-elif is_torchvision_available():\n+else:\n     import torchvision.transforms.functional as F\n \n "
        },
        {
            "sha": "c10bd5081754572103c495cb600e06f1ed3cef11",
            "filename": "src/transformers/models/swin2sr/image_processing_swin2sr_fast.py",
            "status": "modified",
            "additions": 7,
            "deletions": 11,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fswin2sr%2Fimage_processing_swin2sr_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fswin2sr%2Fimage_processing_swin2sr_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fswin2sr%2Fimage_processing_swin2sr_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature, ChannelDimension, get_image_size\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -28,24 +30,18 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n )\n from ...utils.deprecation import deprecate_kwarg\n \n \n-logger = logging.get_logger(__name__)\n-\n-if is_torch_available():\n-    import torch\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+logger = logging.get_logger(__name__)\n \n \n class Swin2SRFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "2f5ef22ef5e3791ecd8669cbd5aa34acdf99af52",
            "filename": "src/transformers/models/textnet/image_processing_textnet_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Ftextnet%2Fimage_processing_textnet_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Ftextnet%2Fimage_processing_textnet_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftextnet%2Fimage_processing_textnet_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import BaseImageProcessorFast, DefaultFastImageProcessorKwargs\n from ...image_transforms import (\n@@ -35,20 +37,14 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n class TextNetFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "e7fe7e621d8c94b987c8831e1829d810d56097c3",
            "filename": "src/transformers/models/tvp/image_processing_tvp_fast.py",
            "status": "modified",
            "additions": 7,
            "deletions": 15,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Ftvp%2Fimage_processing_tvp_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Ftvp%2Fimage_processing_tvp_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftvp%2Fimage_processing_tvp_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -32,23 +34,13 @@\n     make_nested_list_of_images,\n )\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TensorType,\n-    auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n-    is_torchvision_v2_available,\n-)\n-\n+from ...utils import TensorType, auto_docstring, is_torchvision_v2_available\n \n-if is_torch_available():\n-    import torch\n \n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n class TvpFastImageProcessorKwargs(DefaultFastImageProcessorKwargs):"
        },
        {
            "sha": "79e601648c55d3dbe100c837f61be2ca349bb19f",
            "filename": "src/transformers/models/vilt/image_processing_vilt_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fvilt%2Fimage_processing_vilt_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fvilt%2Fimage_processing_vilt_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvilt%2Fimage_processing_vilt_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -28,20 +30,14 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n # Set maximum size based on the typical aspect ratio of the COCO dataset\n MAX_LONGER_EDGE = 1333"
        },
        {
            "sha": "ae8797789df8c766b332009a4a086046f230acbb",
            "filename": "src/transformers/models/vitmatte/image_processing_vitmatte_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 11,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fvitmatte%2Fimage_processing_vitmatte_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fvitmatte%2Fimage_processing_vitmatte_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvitmatte%2Fimage_processing_vitmatte_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -16,6 +16,8 @@\n \n from typing import Optional, Union\n \n+import torch\n+\n from ...image_processing_utils import BatchFeature\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -35,22 +37,15 @@\n     TensorType,\n     auto_docstring,\n     filter_out_non_signature_kwargs,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n-\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n logger = logging.get_logger(__name__)\n "
        },
        {
            "sha": "fda06dfc522a0242cfd3c67fca0c29fb2551f92f",
            "filename": "src/transformers/models/yolos/image_processing_yolos_fast.py",
            "status": "modified",
            "additions": 5,
            "deletions": 16,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fyolos%2Fimage_processing_yolos_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fyolos%2Fimage_processing_yolos_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fyolos%2Fimage_processing_yolos_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -7,6 +7,9 @@\n import pathlib\n from typing import Any, Optional, Union\n \n+import torch\n+from torchvision.io import read_image\n+\n from ...image_processing_utils import BatchFeature, get_size_dict\n from ...image_processing_utils_fast import (\n     BaseImageProcessorFast,\n@@ -29,27 +32,13 @@\n     validate_annotations,\n )\n from ...processing_utils import Unpack\n-from ...utils import (\n-    TensorType,\n-    auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n-    is_torchvision_v2_available,\n-    logging,\n-)\n+from ...utils import TensorType, auto_docstring, is_torchvision_v2_available, logging\n from ...utils.import_utils import requires\n \n \n-if is_torch_available():\n-    import torch\n-\n-\n if is_torchvision_v2_available():\n-    from torchvision.io import read_image\n     from torchvision.transforms.v2 import functional as F\n-\n-elif is_torchvision_available():\n-    from torchvision.io import read_image\n+else:\n     from torchvision.transforms import functional as F\n \n "
        },
        {
            "sha": "13f3db41b6755d44e16982c60651bb1828c6a8ce",
            "filename": "src/transformers/models/yolos/modular_yolos.py",
            "status": "modified",
            "additions": 2,
            "deletions": 5,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fyolos%2Fmodular_yolos.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fyolos%2Fmodular_yolos.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fyolos%2Fmodular_yolos.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -1,19 +1,16 @@\n from typing import Optional, Union\n \n+import torch\n+\n from transformers.models.detr.image_processing_detr_fast import DetrImageProcessorFast\n \n from ...image_transforms import center_to_corners_format\n from ...utils import (\n     TensorType,\n-    is_torch_available,\n     logging,\n )\n \n \n-if is_torch_available():\n-    import torch\n-\n-\n logger = logging.get_logger(__name__)\n \n "
        },
        {
            "sha": "7967932729e560c7106abecb3dba3c00e3ce4f7f",
            "filename": "src/transformers/models/zoedepth/image_processing_zoedepth_fast.py",
            "status": "modified",
            "additions": 7,
            "deletions": 14,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fzoedepth%2Fimage_processing_zoedepth_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fmodels%2Fzoedepth%2Fimage_processing_zoedepth_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fzoedepth%2Fimage_processing_zoedepth_fast.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -20,6 +20,7 @@\n )\n \n import numpy as np\n+import torch\n \n from ...image_processing_utils import (\n     BatchFeature,\n@@ -43,8 +44,6 @@\n from ...utils import (\n     TensorType,\n     auto_docstring,\n-    is_torch_available,\n-    is_torchvision_available,\n     is_torchvision_v2_available,\n     logging,\n     requires_backends,\n@@ -53,16 +52,10 @@\n from .modeling_zoedepth import ZoeDepthDepthEstimatorOutput\n \n \n-if is_torch_available():\n-    import torch\n-\n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n-\n-    from torchvision.transforms import InterpolationMode\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+else:\n+    from torchvision.transforms import functional as F\n \n \n logger = logging.get_logger(__name__)\n@@ -296,7 +289,7 @@ def post_process_depth_estimation(\n                 depth = F.resize(\n                     depth,\n                     size=[source_size[0] + 2 * pad_h, source_size[1] + 2 * pad_w],\n-                    interpolation=InterpolationMode.BICUBIC,\n+                    interpolation=F.InterpolationMode.BICUBIC,\n                     antialias=False,\n                 )\n \n@@ -310,7 +303,7 @@ def post_process_depth_estimation(\n                 depth = F.resize(\n                     depth,\n                     size=target_size,\n-                    interpolation=InterpolationMode.BICUBIC,\n+                    interpolation=F.InterpolationMode.BICUBIC,\n                     antialias=False,\n                 )\n             depth = depth.squeeze(0)"
        },
        {
            "sha": "4d0e9c58f3149a4e42525dde0df06f46541bcc45",
            "filename": "src/transformers/video_processing_utils.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fvideo_processing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a2ac4de8b0af2776e3156e72afa7bb8679a3e436/src%2Ftransformers%2Fvideo_processing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fvideo_processing_utils.py?ref=a2ac4de8b0af2776e3156e72afa7bb8679a3e436",
            "patch": "@@ -68,11 +68,11 @@\n if is_torch_available():\n     import torch\n \n-if is_torchvision_available():\n-    if is_torchvision_v2_available():\n-        from torchvision.transforms.v2 import functional as F\n-    else:\n-        from torchvision.transforms import functional as F\n+if is_torchvision_v2_available():\n+    from torchvision.transforms.v2 import functional as F\n+elif is_torchvision_available():\n+    from torchvision.transforms import functional as F\n+\n \n logger = logging.get_logger(__name__)\n "
        }
    ],
    "stats": {
        "total": 1241,
        "additions": 403,
        "deletions": 838
    }
}