{
    "author": "ylacombe",
    "message": "Fix seamless TTS generate (#34968)\n\n* fix seamless tts generate\r\n\r\n* apply same fix for v2\r\n\r\n* [run-slow] seamless_m4t, seamless_m4t_v2\r\n\r\n* remove TODO\r\n\r\n* [run-slow] seamless_m4t, seamless_m4t_v2\r\n\r\n* [run-slow] seamless_m4t, seamless_m4t_v2\r\n\r\n* ignore failing test on multigpus\r\n\r\n* [run-slow] seamless_m4t, seamless_m4t_v2\r\n\r\n* [run-slow] seamless_m4t, seamless_m4t_v2",
    "sha": "6181c6b095e85ba3c807fd18c90b8c27df4becd9",
    "files": [
        {
            "sha": "6aa967416d5477bfd07ce708f837bf0384371037",
            "filename": "src/transformers/models/seamless_m4t/modeling_seamless_m4t.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/6181c6b095e85ba3c807fd18c90b8c27df4becd9/src%2Ftransformers%2Fmodels%2Fseamless_m4t%2Fmodeling_seamless_m4t.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6181c6b095e85ba3c807fd18c90b8c27df4becd9/src%2Ftransformers%2Fmodels%2Fseamless_m4t%2Fmodeling_seamless_m4t.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fseamless_m4t%2Fmodeling_seamless_m4t.py?ref=6181c6b095e85ba3c807fd18c90b8c27df4becd9",
            "patch": "@@ -293,6 +293,8 @@ def format_speech_generation_kwargs(kwargs):\n         elif key.startswith(\"speech_\"):\n             key = key[len(\"speech_\") :]\n             kwargs_speech[key] = value\n+        elif key == \"generation_config\":\n+            kwargs_text[key] = value\n         else:\n             # If the key is already in a specific config, then it's been set with a\n             # submodules specific value and we don't override"
        },
        {
            "sha": "978000086e2c3bfe667e0c5c4afd072083870ddf",
            "filename": "src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/6181c6b095e85ba3c807fd18c90b8c27df4becd9/src%2Ftransformers%2Fmodels%2Fseamless_m4t_v2%2Fmodeling_seamless_m4t_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6181c6b095e85ba3c807fd18c90b8c27df4becd9/src%2Ftransformers%2Fmodels%2Fseamless_m4t_v2%2Fmodeling_seamless_m4t_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fseamless_m4t_v2%2Fmodeling_seamless_m4t_v2.py?ref=6181c6b095e85ba3c807fd18c90b8c27df4becd9",
            "patch": "@@ -421,6 +421,8 @@ def format_speech_generation_kwargs(kwargs):\n         elif key.startswith(\"speech_\"):\n             key = key[len(\"speech_\") :]\n             kwargs_speech[key] = value\n+        elif key == \"generation_config\":\n+            kwargs_text[key] = value\n         else:\n             # If the key is already in a specific config, then it's been set with a\n             # submodules specific value and we don't override"
        },
        {
            "sha": "15f1219556cd0f58179121b3354486b11d8e9710",
            "filename": "tests/models/seamless_m4t_v2/test_modeling_seamless_m4t_v2.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/6181c6b095e85ba3c807fd18c90b8c27df4becd9/tests%2Fmodels%2Fseamless_m4t_v2%2Ftest_modeling_seamless_m4t_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6181c6b095e85ba3c807fd18c90b8c27df4becd9/tests%2Fmodels%2Fseamless_m4t_v2%2Ftest_modeling_seamless_m4t_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fseamless_m4t_v2%2Ftest_modeling_seamless_m4t_v2.py?ref=6181c6b095e85ba3c807fd18c90b8c27df4becd9",
            "patch": "@@ -589,6 +589,11 @@ def test_attention_outputs(self):\n                 [self.model_tester.num_attention_heads, encoder_seq_length, encoder_key_length],\n             )\n \n+    # TODO: @ydshieh: refer to #34968\n+    @unittest.skip(reason=\"Failing on multi-gpu runner\")\n+    def test_retain_grad_hidden_states_attentions(self):\n+        pass\n+\n \n @require_torch\n class SeamlessM4Tv2ModelWithTextInputTest(ModelTesterMixin, GenerationTesterMixin, unittest.TestCase):"
        },
        {
            "sha": "e07e2ad392a3e6242f257ed7e3fc28f9dd9e8960",
            "filename": "tests/pipelines/test_pipelines_text_to_audio.py",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/6181c6b095e85ba3c807fd18c90b8c27df4becd9/tests%2Fpipelines%2Ftest_pipelines_text_to_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6181c6b095e85ba3c807fd18c90b8c27df4becd9/tests%2Fpipelines%2Ftest_pipelines_text_to_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_text_to_audio.py?ref=6181c6b095e85ba3c807fd18c90b8c27df4becd9",
            "patch": "@@ -27,7 +27,6 @@\n     require_torch,\n     require_torch_accelerator,\n     require_torch_or_tf,\n-    run_test_using_subprocess,\n     slow,\n     torch_device,\n )\n@@ -67,10 +66,8 @@ def test_small_musicgen_pt(self):\n         audio = [output[\"audio\"] for output in outputs]\n         self.assertEqual([ANY(np.ndarray), ANY(np.ndarray)], audio)\n \n-    # TODO: @ylacombe: `SeamlessM4TForTextToSpeech.generate` has issue with `generation_config`. See issue #34811\n     @slow\n     @require_torch\n-    @run_test_using_subprocess\n     def test_medium_seamless_m4t_pt(self):\n         speech_generator = pipeline(task=\"text-to-audio\", model=\"facebook/hf-seamless-m4t-medium\", framework=\"pt\")\n "
        }
    ],
    "stats": {
        "total": 12,
        "additions": 9,
        "deletions": 3
    }
}