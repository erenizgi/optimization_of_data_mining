{
    "author": "faaany",
    "message": "[docs] add the missing tokenizer when pushing models to huggingface hub (#33428)\n\n* add tokenizer\r\n\r\n* typo",
    "sha": "cea9ec086a14da1320940c5e48d7bd5dbcf32734",
    "files": [
        {
            "sha": "119026cd03f366ecd33253d4696ecff536cb8ebd",
            "filename": "docs/source/en/tasks/language_modeling.md",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/cea9ec086a14da1320940c5e48d7bd5dbcf32734/docs%2Fsource%2Fen%2Ftasks%2Flanguage_modeling.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/cea9ec086a14da1320940c5e48d7bd5dbcf32734/docs%2Fsource%2Fen%2Ftasks%2Flanguage_modeling.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftasks%2Flanguage_modeling.md?ref=cea9ec086a14da1320940c5e48d7bd5dbcf32734",
            "patch": "@@ -253,6 +253,7 @@ At this point, only three steps remain:\n ...     train_dataset=lm_dataset[\"train\"],\n ...     eval_dataset=lm_dataset[\"test\"],\n ...     data_collator=data_collator,\n+...     tokenizer=tokenizer,\n ... )\n \n >>> trainer.train()"
        },
        {
            "sha": "469b1d7fcb99f63b0746cbba82dd5e8657cae7a3",
            "filename": "docs/source/en/tasks/masked_language_modeling.md",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/cea9ec086a14da1320940c5e48d7bd5dbcf32734/docs%2Fsource%2Fen%2Ftasks%2Fmasked_language_modeling.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/cea9ec086a14da1320940c5e48d7bd5dbcf32734/docs%2Fsource%2Fen%2Ftasks%2Fmasked_language_modeling.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftasks%2Fmasked_language_modeling.md?ref=cea9ec086a14da1320940c5e48d7bd5dbcf32734",
            "patch": "@@ -245,6 +245,7 @@ At this point, only three steps remain:\n ...     train_dataset=lm_dataset[\"train\"],\n ...     eval_dataset=lm_dataset[\"test\"],\n ...     data_collator=data_collator,\n+...     tokenizer=tokenizer,\n ... )\n \n >>> trainer.train()"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 2,
        "deletions": 0
    }
}