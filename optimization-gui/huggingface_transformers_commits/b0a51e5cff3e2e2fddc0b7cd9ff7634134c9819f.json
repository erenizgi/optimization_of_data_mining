{
    "author": "ydshieh",
    "message": "Fix flaky Hub CI (`test_trainer.py`) (#35062)\n\n* fix\r\n\r\n* Update src/transformers/testing_utils.py\r\n\r\nCo-authored-by: Lucain <lucainp@gmail.com>\r\n\r\n* fix\r\n\r\n* fix\r\n\r\n* fix\r\n\r\n* fix\r\n\r\n* fix\r\n\r\n* fix\r\n\r\n* fix\r\n\r\n* fix\r\n\r\n* check\r\n\r\n* check\r\n\r\n* check\r\n\r\n* check\r\n\r\n* check\r\n\r\n* check\r\n\r\n* Update src/transformers/testing_utils.py\r\n\r\nCo-authored-by: Lucain <lucainp@gmail.com>\r\n\r\n* Update src/transformers/testing_utils.py\r\n\r\nCo-authored-by: Lucain <lucainp@gmail.com>\r\n\r\n* check\r\n\r\n* check\r\n\r\n* check\r\n\r\n* Final space\r\n\r\n* Final adjustment\r\n\r\n---------\r\n\r\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>\r\nCo-authored-by: Lucain <lucainp@gmail.com>",
    "sha": "b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f",
    "files": [
        {
            "sha": "30f7b5a68fb2c0ffe28c634a2038328eeddf885b",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f",
            "patch": "@@ -40,7 +40,9 @@\n from unittest import mock\n from unittest.mock import patch\n \n+import huggingface_hub.utils\n import urllib3\n+from huggingface_hub import delete_repo\n \n from transformers import logging as transformers_logging\n \n@@ -1570,6 +1572,38 @@ def LoggingLevel(level):\n         transformers_logging.set_verbosity(orig_level)\n \n \n+class TemporaryHubRepo:\n+    \"\"\"Create a temporary Hub repository and return its `RepoUrl` object. This is similar to\n+    `tempfile.TemporaryDirectory` and can be used as a context manager. For example:\n+\n+        with TemporaryHubRepo(token=self._token) as temp_repo:\n+            ...\n+\n+    Upon exiting the context, the repository and everything contained in it are removed.\n+\n+    Example:\n+\n+    ```python\n+    with TemporaryHubRepo(token=self._token) as temp_repo:\n+        model.push_to_hub(tmp_repo.repo_id, token=self._token)\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, namespace: Optional[str] = None, token: Optional[str] = None) -> None:\n+        self.token = token\n+        with tempfile.TemporaryDirectory() as tmp_dir:\n+            repo_id = Path(tmp_dir).name\n+            if namespace is not None:\n+                repo_id = f\"{namespace}/{repo_id}\"\n+            self.repo_url = huggingface_hub.create_repo(repo_id, token=self.token)\n+\n+    def __enter__(self):\n+        return self.repo_url\n+\n+    def __exit__(self, exc, value, tb):\n+        delete_repo(repo_id=self.repo_url.repo_id, token=self.token, missing_ok=True)\n+\n+\n @contextlib.contextmanager\n # adapted from https://stackoverflow.com/a/64789046/9201239\n def ExtendSysPath(path: Union[str, os.PathLike]) -> Iterator[None]:"
        },
        {
            "sha": "24fea85a900d672dbc312095e93dd1ee68e7b6d2",
            "filename": "tests/generation/test_configuration_utils.py",
            "status": "modified",
            "additions": 72,
            "deletions": 105,
            "changes": 177,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Fgeneration%2Ftest_configuration_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Fgeneration%2Ftest_configuration_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fgeneration%2Ftest_configuration_utils.py?ref=b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f",
            "patch": "@@ -18,9 +18,8 @@\n import tempfile\n import unittest\n import warnings\n-from pathlib import Path\n \n-from huggingface_hub import HfFolder, create_pull_request, create_repo, delete_repo\n+from huggingface_hub import HfFolder, create_pull_request\n from parameterized import parameterized\n \n from transformers import AutoConfig, GenerationConfig, WatermarkingConfig, is_torch_available\n@@ -57,7 +56,7 @@\n     UnbatchedClassifierFreeGuidanceLogitsProcessor,\n     WatermarkLogitsProcessor,\n )\n-from transformers.testing_utils import TOKEN, USER, is_staging_test, torch_device\n+from transformers.testing_utils import TOKEN, TemporaryHubRepo, is_staging_test, torch_device\n \n \n class GenerationConfigTest(unittest.TestCase):\n@@ -679,114 +678,82 @@ def setUpClass(cls):\n         cls._token = TOKEN\n         HfFolder.save_token(TOKEN)\n \n-    @staticmethod\n-    def _try_delete_repo(repo_id, token):\n-        try:\n-            # Reset repo\n-            delete_repo(repo_id=repo_id, token=token)\n-        except:  # noqa E722\n-            pass\n-\n     def test_push_to_hub(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-generation-config-{Path(tmp_dir).name}\"\n-                config = GenerationConfig(\n-                    do_sample=True,\n-                    temperature=0.7,\n-                    length_penalty=1.0,\n-                )\n-                config.push_to_hub(tmp_repo, token=self._token)\n-\n-                new_config = GenerationConfig.from_pretrained(tmp_repo)\n-                for k, v in config.to_dict().items():\n-                    if k != \"transformers_version\":\n-                        self.assertEqual(v, getattr(new_config, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            config = GenerationConfig(\n+                do_sample=True,\n+                temperature=0.7,\n+                length_penalty=1.0,\n+            )\n+            config.push_to_hub(tmp_repo.repo_id, token=self._token)\n+\n+            new_config = GenerationConfig.from_pretrained(tmp_repo.repo_id)\n+            for k, v in config.to_dict().items():\n+                if k != \"transformers_version\":\n+                    self.assertEqual(v, getattr(new_config, k))\n \n     def test_push_to_hub_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-generation-config-{Path(tmp_dir).name}\"\n-                config = GenerationConfig(\n-                    do_sample=True,\n-                    temperature=0.7,\n-                    length_penalty=1.0,\n-                )\n-                # Push to hub via save_pretrained\n-                config.save_pretrained(tmp_dir, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n-\n-                new_config = GenerationConfig.from_pretrained(tmp_repo)\n-                for k, v in config.to_dict().items():\n-                    if k != \"transformers_version\":\n-                        self.assertEqual(v, getattr(new_config, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            config = GenerationConfig(\n+                do_sample=True,\n+                temperature=0.7,\n+                length_penalty=1.0,\n+            )\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                config.save_pretrained(tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token)\n+\n+            new_config = GenerationConfig.from_pretrained(tmp_repo.repo_id)\n+            for k, v in config.to_dict().items():\n+                if k != \"transformers_version\":\n+                    self.assertEqual(v, getattr(new_config, k))\n \n     def test_push_to_hub_in_organization(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-generation-config-org-{Path(tmp_dir).name}\"\n-                config = GenerationConfig(\n-                    do_sample=True,\n-                    temperature=0.7,\n-                    length_penalty=1.0,\n-                )\n-                config.push_to_hub(tmp_repo, token=self._token)\n-\n-                new_config = GenerationConfig.from_pretrained(tmp_repo)\n-                for k, v in config.to_dict().items():\n-                    if k != \"transformers_version\":\n-                        self.assertEqual(v, getattr(new_config, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            config = GenerationConfig(\n+                do_sample=True,\n+                temperature=0.7,\n+                length_penalty=1.0,\n+            )\n+            config.push_to_hub(tmp_repo.repo_id, token=self._token)\n+\n+            new_config = GenerationConfig.from_pretrained(tmp_repo.repo_id)\n+            for k, v in config.to_dict().items():\n+                if k != \"transformers_version\":\n+                    self.assertEqual(v, getattr(new_config, k))\n \n     def test_push_to_hub_in_organization_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-generation-config-org-{Path(tmp_dir).name}\"\n-                config = GenerationConfig(\n-                    do_sample=True,\n-                    temperature=0.7,\n-                    length_penalty=1.0,\n-                )\n-                # Push to hub via save_pretrained\n-                config.save_pretrained(tmp_dir, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n-\n-                new_config = GenerationConfig.from_pretrained(tmp_repo)\n-                for k, v in config.to_dict().items():\n-                    if k != \"transformers_version\":\n-                        self.assertEqual(v, getattr(new_config, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            config = GenerationConfig(\n+                do_sample=True,\n+                temperature=0.7,\n+                length_penalty=1.0,\n+            )\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                config.save_pretrained(tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token)\n+\n+            new_config = GenerationConfig.from_pretrained(tmp_repo.repo_id)\n+            for k, v in config.to_dict().items():\n+                if k != \"transformers_version\":\n+                    self.assertEqual(v, getattr(new_config, k))\n \n     def test_push_to_hub_on_pr_revision(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                # create a repo and a PR\n-                repo_id = f\"{USER}/test-generation-config-{Path(tmp_dir).name}\"\n-                create_repo(repo_id=repo_id, token=self._token)\n-                pr = create_pull_request(repo_id=repo_id, title=\"Test PR\", token=self._token)\n-                revision = f\"refs/pr/{pr.num}\"\n-\n-                # push to PR ref\n-                config = GenerationConfig(\n-                    do_sample=True,\n-                    temperature=0.7,\n-                    length_penalty=1.0,\n-                )\n-                config.push_to_hub(repo_id, token=self._token, revision=revision)\n-\n-                # load from PR ref\n-                new_config = GenerationConfig.from_pretrained(repo_id, revision=revision)\n-                for k, v in config.to_dict().items():\n-                    if k != \"transformers_version\":\n-                        self.assertEqual(v, getattr(new_config, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=repo_id, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            # create a PR\n+            pr = create_pull_request(repo_id=tmp_repo.repo_id, title=\"Test PR\", token=self._token)\n+            revision = f\"refs/pr/{pr.num}\"\n+\n+            # push to PR ref\n+            config = GenerationConfig(\n+                do_sample=True,\n+                temperature=0.7,\n+                length_penalty=1.0,\n+            )\n+            config.push_to_hub(tmp_repo.repo_id, token=self._token, revision=revision)\n+\n+            # load from PR ref\n+            new_config = GenerationConfig.from_pretrained(tmp_repo.repo_id, revision=revision)\n+            for k, v in config.to_dict().items():\n+                if k != \"transformers_version\":\n+                    self.assertEqual(v, getattr(new_config, k))"
        },
        {
            "sha": "fd361f160f2b9c61ef357220fb95c0ed2753e194",
            "filename": "tests/models/auto/test_processor_auto.py",
            "status": "modified",
            "additions": 34,
            "deletions": 58,
            "changes": 92,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Fmodels%2Fauto%2Ftest_processor_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Fmodels%2Fauto%2Ftest_processor_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fauto%2Ftest_processor_auto.py?ref=b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f",
            "patch": "@@ -21,7 +21,7 @@\n from pathlib import Path\n from shutil import copyfile\n \n-from huggingface_hub import HfFolder, Repository, create_repo, delete_repo\n+from huggingface_hub import HfFolder, Repository\n \n import transformers\n from transformers import (\n@@ -39,7 +39,7 @@\n     Wav2Vec2FeatureExtractor,\n     Wav2Vec2Processor,\n )\n-from transformers.testing_utils import TOKEN, USER, get_tests_dir, is_staging_test\n+from transformers.testing_utils import TOKEN, TemporaryHubRepo, get_tests_dir, is_staging_test\n from transformers.tokenization_utils import TOKENIZER_CONFIG_FILE\n from transformers.utils import FEATURE_EXTRACTOR_NAME, PROCESSOR_NAME, is_tokenizers_available\n \n@@ -372,72 +372,52 @@ def setUpClass(cls):\n         cls._token = TOKEN\n         HfFolder.save_token(TOKEN)\n \n-    @staticmethod\n-    def _try_delete_repo(repo_id, token):\n-        try:\n-            # Reset repo\n-            delete_repo(repo_id=repo_id, token=token)\n-        except:  # noqa E722\n-            pass\n-\n     def test_push_to_hub_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-processor-{Path(tmp_dir).name}\"\n-                processor = Wav2Vec2Processor.from_pretrained(SAMPLE_PROCESSOR_CONFIG_DIR)\n-                # Push to hub via save_pretrained\n-                processor.save_pretrained(tmp_repo, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n-\n-                new_processor = Wav2Vec2Processor.from_pretrained(tmp_repo)\n-                for k, v in processor.feature_extractor.__dict__.items():\n-                    self.assertEqual(v, getattr(new_processor.feature_extractor, k))\n-                self.assertDictEqual(new_processor.tokenizer.get_vocab(), processor.tokenizer.get_vocab())\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            processor = Wav2Vec2Processor.from_pretrained(SAMPLE_PROCESSOR_CONFIG_DIR)\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                processor.save_pretrained(tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token)\n \n-    def test_push_to_hub_in_organization_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-processor-org-{Path(tmp_dir).name}\"\n-                processor = Wav2Vec2Processor.from_pretrained(SAMPLE_PROCESSOR_CONFIG_DIR)\n+            new_processor = Wav2Vec2Processor.from_pretrained(tmp_repo.repo_id)\n+            for k, v in processor.feature_extractor.__dict__.items():\n+                self.assertEqual(v, getattr(new_processor.feature_extractor, k))\n+            self.assertDictEqual(new_processor.tokenizer.get_vocab(), processor.tokenizer.get_vocab())\n \n-                # Push to hub via save_pretrained\n+    def test_push_to_hub_in_organization_via_save_pretrained(self):\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            processor = Wav2Vec2Processor.from_pretrained(SAMPLE_PROCESSOR_CONFIG_DIR)\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n                 processor.save_pretrained(\n                     tmp_dir,\n-                    repo_id=tmp_repo,\n+                    repo_id=tmp_repo.repo_id,\n                     push_to_hub=True,\n                     token=self._token,\n                 )\n \n-                new_processor = Wav2Vec2Processor.from_pretrained(tmp_repo)\n-                for k, v in processor.feature_extractor.__dict__.items():\n-                    self.assertEqual(v, getattr(new_processor.feature_extractor, k))\n-                self.assertDictEqual(new_processor.tokenizer.get_vocab(), processor.tokenizer.get_vocab())\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            new_processor = Wav2Vec2Processor.from_pretrained(tmp_repo.repo_id)\n+            for k, v in processor.feature_extractor.__dict__.items():\n+                self.assertEqual(v, getattr(new_processor.feature_extractor, k))\n+            self.assertDictEqual(new_processor.tokenizer.get_vocab(), processor.tokenizer.get_vocab())\n \n     def test_push_to_hub_dynamic_processor(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-dynamic-processor-{Path(tmp_dir).name}\"\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            CustomFeatureExtractor.register_for_auto_class()\n+            CustomTokenizer.register_for_auto_class()\n+            CustomProcessor.register_for_auto_class()\n \n-                CustomFeatureExtractor.register_for_auto_class()\n-                CustomTokenizer.register_for_auto_class()\n-                CustomProcessor.register_for_auto_class()\n-\n-                feature_extractor = CustomFeatureExtractor.from_pretrained(SAMPLE_PROCESSOR_CONFIG_DIR)\n+            feature_extractor = CustomFeatureExtractor.from_pretrained(SAMPLE_PROCESSOR_CONFIG_DIR)\n \n-                with tempfile.TemporaryDirectory() as tmp_dir:\n-                    vocab_file = os.path.join(tmp_dir, \"vocab.txt\")\n-                    with open(vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n-                        vocab_writer.write(\"\".join([x + \"\\n\" for x in self.vocab_tokens]))\n-                    tokenizer = CustomTokenizer(vocab_file)\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                vocab_file = os.path.join(tmp_dir, \"vocab.txt\")\n+                with open(vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n+                    vocab_writer.write(\"\".join([x + \"\\n\" for x in self.vocab_tokens]))\n+                tokenizer = CustomTokenizer(vocab_file)\n \n-                processor = CustomProcessor(feature_extractor, tokenizer)\n+            processor = CustomProcessor(feature_extractor, tokenizer)\n \n-                create_repo(tmp_repo, token=self._token)\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n                 repo = Repository(tmp_dir, clone_from=tmp_repo, token=self._token)\n                 processor.save_pretrained(tmp_dir)\n \n@@ -468,10 +448,6 @@ def test_push_to_hub_dynamic_processor(self):\n \n                 repo.push_to_hub()\n \n-                new_processor = AutoProcessor.from_pretrained(tmp_repo, trust_remote_code=True)\n+                new_processor = AutoProcessor.from_pretrained(tmp_repo.repo_id, trust_remote_code=True)\n                 # Can't make an isinstance check because the new_processor is from the CustomProcessor class of a dynamic module\n                 self.assertEqual(new_processor.__class__.__name__, \"CustomProcessor\")\n-\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)"
        },
        {
            "sha": "f7b4a8637bff8551b20dac753982921cada60404",
            "filename": "tests/trainer/test_trainer.py",
            "status": "modified",
            "additions": 115,
            "deletions": 120,
            "changes": 235,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Ftrainer%2Ftest_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Ftrainer%2Ftest_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_trainer.py?ref=b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f",
            "patch": "@@ -32,10 +32,9 @@\n from unittest.mock import Mock, patch\n \n import numpy as np\n-from huggingface_hub import HfFolder, ModelCard, create_branch, delete_repo, list_repo_commits, list_repo_files\n+from huggingface_hub import HfFolder, ModelCard, create_branch, list_repo_commits, list_repo_files\n from packaging import version\n from parameterized import parameterized\n-from requests.exceptions import HTTPError\n \n from transformers import (\n     AutoFeatureExtractor,\n@@ -59,6 +58,7 @@\n     USER,\n     CaptureLogger,\n     LoggingLevel,\n+    TemporaryHubRepo,\n     TestCasePlus,\n     backend_device_count,\n     execute_subprocess_async,\n@@ -4152,64 +4152,49 @@ def setUpClass(cls):\n         cls._token = TOKEN\n         HfFolder.save_token(TOKEN)\n \n-    @classmethod\n-    def tearDownClass(cls):\n-        for model in [\n-            \"test-trainer\",\n-            \"test-trainer-epoch\",\n-            \"test-trainer-step\",\n-            \"test-trainer-tensorboard\",\n-            \"test-trainer-tags\",\n-        ]:\n-            try:\n-                delete_repo(token=cls._token, repo_id=model)\n-            except HTTPError:\n-                pass\n-\n-        try:\n-            delete_repo(token=cls._token, repo_id=\"valid_org/test-trainer-org\")\n-        except HTTPError:\n-            pass\n-\n     def test_push_to_hub(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            trainer = get_regression_trainer(\n-                output_dir=os.path.join(tmp_dir, \"test-trainer\"),\n-                push_to_hub=True,\n-                hub_token=self._token,\n-            )\n-            url = trainer.push_to_hub()\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            output_dir_name = tmp_repo.repo_name\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                trainer = get_regression_trainer(\n+                    output_dir=os.path.join(tmp_dir, output_dir_name),\n+                    push_to_hub=True,\n+                    hub_token=self._token,\n+                )\n+                url = trainer.push_to_hub()\n \n             # Extract repo_name from the url\n             re_search = re.search(ENDPOINT_STAGING + r\"/([^/]+/[^/]+)/\", url)\n             self.assertTrue(re_search is not None)\n             repo_name = re_search.groups()[0]\n \n-            self.assertEqual(repo_name, f\"{USER}/test-trainer\")\n+            self.assertEqual(repo_name, f\"{USER}/{output_dir_name}\")\n \n             model = RegressionPreTrainedModel.from_pretrained(repo_name)\n             self.assertEqual(model.a.item(), trainer.model.a.item())\n             self.assertEqual(model.b.item(), trainer.model.b.item())\n \n     def test_push_to_hub_in_organization(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            trainer = get_regression_trainer(output_dir=tmp_dir)\n-            trainer.save_model()\n-            trainer = get_regression_trainer(\n-                output_dir=os.path.join(tmp_dir, \"test-trainer-org\"),\n-                push_to_hub=True,\n-                hub_model_id=\"valid_org/test-trainer-org\",\n-                hub_token=self._token,\n-            )\n-            url = trainer.push_to_hub()\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                trainer = get_regression_trainer(output_dir=tmp_dir)\n+                trainer.save_model()\n+                output_dir_name = tmp_repo.repo_name\n+                trainer = get_regression_trainer(\n+                    output_dir=os.path.join(tmp_dir, output_dir_name),\n+                    push_to_hub=True,\n+                    hub_model_id=f\"valid_org/{output_dir_name}\",\n+                    hub_token=self._token,\n+                )\n+                url = trainer.push_to_hub()\n \n             # Extract repo_name from the url\n             re_search = re.search(ENDPOINT_STAGING + r\"/([^/]+/[^/]+)/\", url)\n             self.assertTrue(re_search is not None)\n             repo_name = re_search.groups()[0]\n-            self.assertEqual(repo_name, \"valid_org/test-trainer-org\")\n+            self.assertEqual(repo_name, f\"valid_org/{output_dir_name}\")\n \n-            model = RegressionPreTrainedModel.from_pretrained(\"valid_org/test-trainer-org\")\n+            model = RegressionPreTrainedModel.from_pretrained(f\"valid_org/{output_dir_name}\")\n             self.assertEqual(model.a.item(), trainer.model.a.item())\n             self.assertEqual(model.b.item(), trainer.model.b.item())\n \n@@ -4226,120 +4211,130 @@ def get_commit_history(self, repo):\n         return [commit.strip() for commit in commits]\n \n     def test_push_to_hub_with_saves_each_epoch(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            with self.assertLogs(level=\"WARNING\") as logs:\n-                trainer = get_regression_trainer(\n-                    output_dir=os.path.join(tmp_dir, \"test-trainer-epoch\"),\n-                    push_to_hub=True,\n-                    hub_token=self._token,\n-                    # To avoid any flakiness if the training goes faster than the uploads.\n-                    hub_always_push=True,\n-                    save_strategy=\"epoch\",\n-                )\n-                trainer.train()\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                with self.assertLogs(level=\"WARNING\") as logs:\n+                    output_dir_name = tmp_repo.repo_name\n+                    trainer = get_regression_trainer(\n+                        output_dir=os.path.join(tmp_dir, output_dir_name),\n+                        push_to_hub=True,\n+                        hub_token=self._token,\n+                        # To avoid any flakiness if the training goes faster than the uploads.\n+                        hub_always_push=True,\n+                        save_strategy=\"epoch\",\n+                    )\n+                    trainer.train()\n \n-        commits = list_repo_commits(f\"{USER}/test-trainer-epoch\", token=self._token)\n-        commits = [c.title for c in commits]\n-        self.assertIn(\"initial commit\", commits)\n-        self.assertIn(\"Training in progress, epoch 1\", commits)\n-        self.assertIn(\"Training in progress, epoch 2\", commits)\n-        # Epochs 3 and 4 are not guaranteed to be present (empty commits)\n-        self.assertTrue(any(\"Skipping to prevent empty commit.\" in record.message for record in logs.records))\n+            commits = list_repo_commits(f\"{USER}/{output_dir_name}\", token=self._token)\n+            commits = [c.title for c in commits]\n+            self.assertIn(\"initial commit\", commits)\n+            self.assertIn(\"Training in progress, epoch 1\", commits)\n+            self.assertIn(\"Training in progress, epoch 2\", commits)\n+            # Epochs 3 and 4 are not guaranteed to be present (empty commits)\n+            self.assertTrue(any(\"Skipping to prevent empty commit.\" in record.message for record in logs.records))\n \n     def test_push_to_hub_with_saves_each_n_steps(self):\n         num_gpus = max(1, backend_device_count(torch_device))\n         if num_gpus > 2:\n             self.skipTest(reason=\"More than 2 GPUs available\")\n \n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            with self.assertLogs(level=\"WARNING\") as logs:\n-                trainer = get_regression_trainer(\n-                    output_dir=os.path.join(tmp_dir, \"test-trainer-step\"),\n-                    push_to_hub=True,\n-                    hub_token=self._token,\n-                    # To avoid any flakiness if the training goes faster than the uploads.\n-                    hub_always_push=True,\n-                    save_strategy=\"steps\",\n-                    save_steps=5,\n-                )\n-                trainer.train()\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                with self.assertLogs(level=\"WARNING\") as logs:\n+                    output_dir_name = tmp_repo.repo_name\n+                    trainer = get_regression_trainer(\n+                        output_dir=os.path.join(tmp_dir, output_dir_name),\n+                        push_to_hub=True,\n+                        hub_token=self._token,\n+                        # To avoid any flakiness if the training goes faster than the uploads.\n+                        hub_always_push=True,\n+                        save_strategy=\"steps\",\n+                        save_steps=5,\n+                    )\n+                    trainer.train()\n \n-        commits = list_repo_commits(f\"{USER}/test-trainer-step\", token=self._token)\n-        commits = [c.title for c in commits]\n-        self.assertIn(\"initial commit\", commits)\n+            commits = list_repo_commits(f\"{USER}/{output_dir_name}\", token=self._token)\n+            commits = [c.title for c in commits]\n+            self.assertIn(\"initial commit\", commits)\n \n-        # Some commits are skipped if nothing has changed\n-        # We expect 1 commit per 5 epochs + 1 commit at the end\n-        nb_empty_commits = len(\n-            [record for record in logs.records if \"Skipping to prevent empty commit.\" in record.message]\n-        )\n-        nb_epoch_commits = len([commit for commit in commits if \"Training in progress, step\" in commit])\n+            # Some commits are skipped if nothing has changed\n+            # We expect 1 commit per 5 epochs + 1 commit at the end\n+            nb_empty_commits = len(\n+                [record for record in logs.records if \"Skipping to prevent empty commit.\" in record.message]\n+            )\n+            nb_epoch_commits = len([commit for commit in commits if \"Training in progress, step\" in commit])\n \n-        # max_steps depend on the number of available GPUs\n-        max_steps = math.ceil(trainer.args.num_train_epochs * len(trainer.get_train_dataloader()))\n-        nb_expected_commits = len(range(5, max_steps, 5))\n+            # max_steps depend on the number of available GPUs\n+            max_steps = math.ceil(trainer.args.num_train_epochs * len(trainer.get_train_dataloader()))\n+            nb_expected_commits = len(range(5, max_steps, 5))\n \n-        # '>=' since final commit might be an empty commit as well (not deterministic)\n-        self.assertGreaterEqual(nb_empty_commits + nb_epoch_commits, nb_expected_commits)\n+            # '>=' since final commit might be an empty commit as well (not deterministic)\n+            self.assertGreaterEqual(nb_empty_commits + nb_epoch_commits, nb_expected_commits)\n \n     @require_tensorboard\n     def test_push_to_hub_with_tensorboard_logs(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            trainer = get_regression_trainer(\n-                output_dir=os.path.join(tmp_dir, \"test-trainer-tensorboard\"),\n-                hub_token=self._token,\n-                save_strategy=\"epoch\",\n-                report_to=[\"tensorboard\"],\n-                keep_report_to=True,\n-            )\n-            trainer.train()\n-            # Push the runs via `push_to_hub()`\n-            trainer.push_to_hub()\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                output_dir_name = tmp_repo.repo_name\n+                trainer = get_regression_trainer(\n+                    output_dir=os.path.join(tmp_dir, output_dir_name),\n+                    hub_token=self._token,\n+                    save_strategy=\"epoch\",\n+                    report_to=[\"tensorboard\"],\n+                    keep_report_to=True,\n+                )\n+                trainer.train()\n+                # Push the runs via `push_to_hub()`\n+                trainer.push_to_hub()\n \n-        files = list_repo_files(f\"{USER}/test-trainer-tensorboard\", token=self._token)\n-        found_log = False\n-        for f in files:\n-            if len(f.split(\"runs\")) > 1 and \"events.out.tfevents\" in f:\n-                found_log = True\n+            files = list_repo_files(f\"{USER}/{output_dir_name}\", token=self._token)\n+            found_log = False\n+            for f in files:\n+                if len(f.split(\"runs\")) > 1 and \"events.out.tfevents\" in f:\n+                    found_log = True\n \n-        assert found_log is True, \"No tensorboard log found in repo\"\n+            assert found_log is True, \"No tensorboard log found in repo\"\n \n     def test_push_to_hub_tags(self):\n         # Checks if `trainer.push_to_hub()` works correctly by adding the desired\n         # tag without having to pass `tags` in `push_to_hub`\n         # see:\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            trainer = get_regression_trainer(\n-                output_dir=os.path.join(tmp_dir, \"test-trainer-tags\"),\n-                push_to_hub=True,\n-                hub_token=self._token,\n-            )\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                output_dir_name = tmp_repo.repo_name\n+                trainer = get_regression_trainer(\n+                    output_dir=os.path.join(tmp_dir, output_dir_name),\n+                    push_to_hub=True,\n+                    hub_token=self._token,\n+                )\n \n-            trainer.model.add_model_tags([\"test-trainer-tags\"])\n+                trainer.model.add_model_tags([\"test-trainer-tags\"])\n \n-            url = trainer.push_to_hub()\n+                url = trainer.push_to_hub()\n \n             # Extract repo_name from the url\n             re_search = re.search(ENDPOINT_STAGING + r\"/([^/]+/[^/]+)/\", url)\n             self.assertTrue(re_search is not None)\n             repo_name = re_search.groups()[0]\n \n-            self.assertEqual(repo_name, f\"{USER}/test-trainer-tags\")\n+            self.assertEqual(repo_name, f\"{USER}/{output_dir_name}\")\n \n             model_card = ModelCard.load(repo_name)\n             self.assertTrue(\"test-trainer-tags\" in model_card.data.tags)\n \n     def test_push_to_hub_with_revision(self):\n         # Checks if `trainer.push_to_hub()` works correctly by adding revision\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            trainer = get_regression_trainer(\n-                output_dir=os.path.join(tmp_dir, \"test-trainer-revision\"),\n-                push_to_hub=True,\n-                hub_token=self._token,\n-            )\n-            branch = \"v1.0\"\n-            create_branch(repo_id=trainer.hub_model_id, branch=branch, token=self._token, exist_ok=True)\n-            url = trainer.push_to_hub(revision=branch)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                output_dir_name = tmp_repo.repo_name\n+                trainer = get_regression_trainer(\n+                    output_dir=os.path.join(tmp_dir, output_dir_name),\n+                    push_to_hub=True,\n+                    hub_token=self._token,\n+                )\n+                branch = \"v1.0\"\n+                create_branch(repo_id=trainer.hub_model_id, branch=branch, token=self._token, exist_ok=True)\n+                url = trainer.push_to_hub(revision=branch)\n \n             # Extract branch from the url\n             re_search = re.search(r\"tree/([^/]+)/\", url)"
        },
        {
            "sha": "a6408928f6196ae12e782ba242d30d4869f73124",
            "filename": "tests/utils/test_configuration_utils.py",
            "status": "modified",
            "additions": 56,
            "deletions": 90,
            "changes": 146,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Futils%2Ftest_configuration_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Futils%2Ftest_configuration_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_configuration_utils.py?ref=b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f",
            "patch": "@@ -22,12 +22,12 @@\n import warnings\n from pathlib import Path\n \n-from huggingface_hub import HfFolder, delete_repo\n+from huggingface_hub import HfFolder\n from requests.exceptions import HTTPError\n \n from transformers import AutoConfig, BertConfig, GPT2Config\n from transformers.configuration_utils import PretrainedConfig\n-from transformers.testing_utils import TOKEN, USER, is_staging_test\n+from transformers.testing_utils import TOKEN, TemporaryHubRepo, is_staging_test\n \n \n sys.path.append(str(Path(__file__).parent.parent.parent / \"utils\"))\n@@ -98,106 +98,72 @@ def setUpClass(cls):\n         cls._token = TOKEN\n         HfFolder.save_token(TOKEN)\n \n-    @staticmethod\n-    def _try_delete_repo(repo_id, token):\n-        try:\n-            # Reset repo\n-            delete_repo(repo_id=repo_id, token=token)\n-        except:  # noqa E722\n-            pass\n-\n     def test_push_to_hub(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-config-{Path(tmp_dir).name}\"\n-\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                config.push_to_hub(tmp_repo, token=self._token)\n-\n-                new_config = BertConfig.from_pretrained(tmp_repo)\n-                for k, v in config.to_dict().items():\n-                    if k != \"transformers_version\":\n-                        self.assertEqual(v, getattr(new_config, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            config.push_to_hub(tmp_repo.repo_id, token=self._token)\n+\n+            new_config = BertConfig.from_pretrained(tmp_repo.repo_id)\n+            for k, v in config.to_dict().items():\n+                if k != \"transformers_version\":\n+                    self.assertEqual(v, getattr(new_config, k))\n \n     def test_push_to_hub_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-config-{Path(tmp_dir).name}\"\n-\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                # Push to hub via save_pretrained\n-                config.save_pretrained(tmp_dir, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n-\n-                new_config = BertConfig.from_pretrained(tmp_repo)\n-                for k, v in config.to_dict().items():\n-                    if k != \"transformers_version\":\n-                        self.assertEqual(v, getattr(new_config, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                config.save_pretrained(tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token)\n+\n+            new_config = BertConfig.from_pretrained(tmp_repo.repo_id)\n+            for k, v in config.to_dict().items():\n+                if k != \"transformers_version\":\n+                    self.assertEqual(v, getattr(new_config, k))\n \n     def test_push_to_hub_in_organization(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-config-org-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                config.push_to_hub(tmp_repo, token=self._token)\n-\n-                new_config = BertConfig.from_pretrained(tmp_repo)\n-                for k, v in config.to_dict().items():\n-                    if k != \"transformers_version\":\n-                        self.assertEqual(v, getattr(new_config, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            config.push_to_hub(tmp_repo.repo_id, token=self._token)\n+\n+            new_config = BertConfig.from_pretrained(tmp_repo.repo_id)\n+            for k, v in config.to_dict().items():\n+                if k != \"transformers_version\":\n+                    self.assertEqual(v, getattr(new_config, k))\n \n     def test_push_to_hub_in_organization_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-config-org-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                # Push to hub via save_pretrained\n-                config.save_pretrained(tmp_dir, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n-\n-                new_config = BertConfig.from_pretrained(tmp_repo)\n-                for k, v in config.to_dict().items():\n-                    if k != \"transformers_version\":\n-                        self.assertEqual(v, getattr(new_config, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                config.save_pretrained(tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token)\n \n-    def test_push_to_hub_dynamic_config(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-dynamic-config-{Path(tmp_dir).name}\"\n+            new_config = BertConfig.from_pretrained(tmp_repo.repo_id)\n+            for k, v in config.to_dict().items():\n+                if k != \"transformers_version\":\n+                    self.assertEqual(v, getattr(new_config, k))\n \n-                CustomConfig.register_for_auto_class()\n-                config = CustomConfig(attribute=42)\n+    def test_push_to_hub_dynamic_config(self):\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            CustomConfig.register_for_auto_class()\n+            config = CustomConfig(attribute=42)\n \n-                config.push_to_hub(tmp_repo, token=self._token)\n+            config.push_to_hub(tmp_repo.repo_id, token=self._token)\n \n-                # This has added the proper auto_map field to the config\n-                self.assertDictEqual(config.auto_map, {\"AutoConfig\": \"custom_configuration.CustomConfig\"})\n+            # This has added the proper auto_map field to the config\n+            self.assertDictEqual(config.auto_map, {\"AutoConfig\": \"custom_configuration.CustomConfig\"})\n \n-                new_config = AutoConfig.from_pretrained(tmp_repo, trust_remote_code=True)\n-                # Can't make an isinstance check because the new_config is from the FakeConfig class of a dynamic module\n-                self.assertEqual(new_config.__class__.__name__, \"CustomConfig\")\n-                self.assertEqual(new_config.attribute, 42)\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            new_config = AutoConfig.from_pretrained(tmp_repo.repo_id, trust_remote_code=True)\n+            # Can't make an isinstance check because the new_config is from the FakeConfig class of a dynamic module\n+            self.assertEqual(new_config.__class__.__name__, \"CustomConfig\")\n+            self.assertEqual(new_config.attribute, 42)\n \n \n class ConfigTestUtils(unittest.TestCase):"
        },
        {
            "sha": "06121dab5d37c5c3a71fcaf8262d2a51a8ff840b",
            "filename": "tests/utils/test_feature_extraction_utils.py",
            "status": "modified",
            "additions": 51,
            "deletions": 79,
            "changes": 130,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Futils%2Ftest_feature_extraction_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Futils%2Ftest_feature_extraction_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_feature_extraction_utils.py?ref=b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f",
            "patch": "@@ -20,11 +20,11 @@\n import unittest.mock as mock\n from pathlib import Path\n \n-from huggingface_hub import HfFolder, delete_repo\n+from huggingface_hub import HfFolder\n from requests.exceptions import HTTPError\n \n from transformers import AutoFeatureExtractor, Wav2Vec2FeatureExtractor\n-from transformers.testing_utils import TOKEN, USER, get_tests_dir, is_staging_test\n+from transformers.testing_utils import TOKEN, TemporaryHubRepo, get_tests_dir, is_staging_test\n \n \n sys.path.append(str(Path(__file__).parent.parent.parent / \"utils\"))\n@@ -60,91 +60,63 @@ def setUpClass(cls):\n         cls._token = TOKEN\n         HfFolder.save_token(TOKEN)\n \n-    @staticmethod\n-    def _try_delete_repo(repo_id, token):\n-        try:\n-            # Reset repo\n-            delete_repo(repo_id=repo_id, token=token)\n-        except:  # noqa E722\n-            pass\n-\n     def test_push_to_hub(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-feature-extractor-{Path(tmp_dir).name}\"\n-\n-                feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(SAMPLE_FEATURE_EXTRACTION_CONFIG_DIR)\n-                feature_extractor.push_to_hub(tmp_repo, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(SAMPLE_FEATURE_EXTRACTION_CONFIG_DIR)\n+            feature_extractor.push_to_hub(tmp_repo.repo_id, token=self._token)\n \n-                new_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(tmp_repo)\n-                for k, v in feature_extractor.__dict__.items():\n-                    self.assertEqual(v, getattr(new_feature_extractor, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            new_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(tmp_repo.repo_id)\n+            for k, v in feature_extractor.__dict__.items():\n+                self.assertEqual(v, getattr(new_feature_extractor, k))\n \n     def test_push_to_hub_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-feature-extractor-{Path(tmp_dir).name}\"\n-                feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(SAMPLE_FEATURE_EXTRACTION_CONFIG_DIR)\n-                # Push to hub via save_pretrained\n-                feature_extractor.save_pretrained(tmp_dir, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n-\n-                new_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(tmp_repo)\n-                for k, v in feature_extractor.__dict__.items():\n-                    self.assertEqual(v, getattr(new_feature_extractor, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(SAMPLE_FEATURE_EXTRACTION_CONFIG_DIR)\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                feature_extractor.save_pretrained(\n+                    tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token\n+                )\n+\n+            new_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(tmp_repo.repo_id)\n+            for k, v in feature_extractor.__dict__.items():\n+                self.assertEqual(v, getattr(new_feature_extractor, k))\n \n     def test_push_to_hub_in_organization(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-feature-extractor-{Path(tmp_dir).name}\"\n-                feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(SAMPLE_FEATURE_EXTRACTION_CONFIG_DIR)\n-                feature_extractor.push_to_hub(tmp_repo, token=self._token)\n-\n-                new_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(tmp_repo)\n-                for k, v in feature_extractor.__dict__.items():\n-                    self.assertEqual(v, getattr(new_feature_extractor, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(SAMPLE_FEATURE_EXTRACTION_CONFIG_DIR)\n+            feature_extractor.push_to_hub(tmp_repo.repo_id, token=self._token)\n+\n+            new_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(tmp_repo.repo_id)\n+            for k, v in feature_extractor.__dict__.items():\n+                self.assertEqual(v, getattr(new_feature_extractor, k))\n \n     def test_push_to_hub_in_organization_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-feature-extractor-{Path(tmp_dir).name}\"\n-                feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(SAMPLE_FEATURE_EXTRACTION_CONFIG_DIR)\n-                # Push to hub via save_pretrained\n-                feature_extractor.save_pretrained(tmp_dir, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n-\n-                new_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(tmp_repo)\n-                for k, v in feature_extractor.__dict__.items():\n-                    self.assertEqual(v, getattr(new_feature_extractor, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(SAMPLE_FEATURE_EXTRACTION_CONFIG_DIR)\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                feature_extractor.save_pretrained(\n+                    tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token\n+                )\n+\n+            new_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(tmp_repo.repo_id)\n+            for k, v in feature_extractor.__dict__.items():\n+                self.assertEqual(v, getattr(new_feature_extractor, k))\n \n     def test_push_to_hub_dynamic_feature_extractor(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-dynamic-feature-extractor-{Path(tmp_dir).name}\"\n-                CustomFeatureExtractor.register_for_auto_class()\n-                feature_extractor = CustomFeatureExtractor.from_pretrained(SAMPLE_FEATURE_EXTRACTION_CONFIG_DIR)\n-\n-                feature_extractor.push_to_hub(tmp_repo, token=self._token)\n-\n-                # This has added the proper auto_map field to the config\n-                self.assertDictEqual(\n-                    feature_extractor.auto_map,\n-                    {\"AutoFeatureExtractor\": \"custom_feature_extraction.CustomFeatureExtractor\"},\n-                )\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            CustomFeatureExtractor.register_for_auto_class()\n+            feature_extractor = CustomFeatureExtractor.from_pretrained(SAMPLE_FEATURE_EXTRACTION_CONFIG_DIR)\n+\n+            feature_extractor.push_to_hub(tmp_repo.repo_id, token=self._token)\n+\n+            # This has added the proper auto_map field to the config\n+            self.assertDictEqual(\n+                feature_extractor.auto_map,\n+                {\"AutoFeatureExtractor\": \"custom_feature_extraction.CustomFeatureExtractor\"},\n+            )\n \n-                new_feature_extractor = AutoFeatureExtractor.from_pretrained(tmp_repo, trust_remote_code=True)\n-                # Can't make an isinstance check because the new_feature_extractor is from the CustomFeatureExtractor class of a dynamic module\n-                self.assertEqual(new_feature_extractor.__class__.__name__, \"CustomFeatureExtractor\")\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            new_feature_extractor = AutoFeatureExtractor.from_pretrained(tmp_repo.repo_id, trust_remote_code=True)\n+            # Can't make an isinstance check because the new_feature_extractor is from the CustomFeatureExtractor class of a dynamic module\n+            self.assertEqual(new_feature_extractor.__class__.__name__, \"CustomFeatureExtractor\")"
        },
        {
            "sha": "2e70d78978ffbfebd2426398bba940267a489cb7",
            "filename": "tests/utils/test_image_processing_utils.py",
            "status": "modified",
            "additions": 49,
            "deletions": 80,
            "changes": 129,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Futils%2Ftest_image_processing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Futils%2Ftest_image_processing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_image_processing_utils.py?ref=b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f",
            "patch": "@@ -19,12 +19,12 @@\n import unittest.mock as mock\n from pathlib import Path\n \n-from huggingface_hub import HfFolder, delete_repo\n+from huggingface_hub import HfFolder\n from requests.exceptions import HTTPError\n \n from transformers import AutoImageProcessor, ViTImageProcessor\n from transformers.image_processing_utils import get_size_dict\n-from transformers.testing_utils import TOKEN, USER, get_tests_dir, is_staging_test\n+from transformers.testing_utils import TOKEN, TemporaryHubRepo, get_tests_dir, is_staging_test\n \n \n sys.path.append(str(Path(__file__).parent.parent.parent / \"utils\"))\n@@ -71,93 +71,62 @@ def setUpClass(cls):\n         cls._token = TOKEN\n         HfFolder.save_token(TOKEN)\n \n-    @staticmethod\n-    def _try_delete_repo(repo_id, token):\n-        try:\n-            # Reset repo\n-            delete_repo(repo_id=repo_id, token=token)\n-        except:  # noqa E722\n-            pass\n-\n     def test_push_to_hub(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-image-processor-{Path(tmp_dir).name}\"\n-                image_processor = ViTImageProcessor.from_pretrained(SAMPLE_IMAGE_PROCESSING_CONFIG_DIR)\n-                image_processor.push_to_hub(tmp_repo, token=self._token)\n-\n-                new_image_processor = ViTImageProcessor.from_pretrained(tmp_repo)\n-                for k, v in image_processor.__dict__.items():\n-                    self.assertEqual(v, getattr(new_image_processor, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            image_processor = ViTImageProcessor.from_pretrained(SAMPLE_IMAGE_PROCESSING_CONFIG_DIR)\n+            image_processor.push_to_hub(tmp_repo.repo_id, token=self._token)\n+\n+            new_image_processor = ViTImageProcessor.from_pretrained(tmp_repo.repo_id)\n+            for k, v in image_processor.__dict__.items():\n+                self.assertEqual(v, getattr(new_image_processor, k))\n \n     def test_push_to_hub_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-image-processor-{Path(tmp_dir).name}\"\n-                image_processor = ViTImageProcessor.from_pretrained(SAMPLE_IMAGE_PROCESSING_CONFIG_DIR)\n-                # Push to hub via save_pretrained\n-                image_processor.save_pretrained(tmp_dir, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n-\n-                new_image_processor = ViTImageProcessor.from_pretrained(tmp_repo)\n-                for k, v in image_processor.__dict__.items():\n-                    self.assertEqual(v, getattr(new_image_processor, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            image_processor = ViTImageProcessor.from_pretrained(SAMPLE_IMAGE_PROCESSING_CONFIG_DIR)\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                image_processor.save_pretrained(tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token)\n+\n+            new_image_processor = ViTImageProcessor.from_pretrained(tmp_repo.repo_id)\n+            for k, v in image_processor.__dict__.items():\n+                self.assertEqual(v, getattr(new_image_processor, k))\n \n     def test_push_to_hub_in_organization(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-image-processor-{Path(tmp_dir).name}\"\n-                image_processor = ViTImageProcessor.from_pretrained(SAMPLE_IMAGE_PROCESSING_CONFIG_DIR)\n-                image_processor.push_to_hub(tmp_repo, token=self._token)\n-\n-                new_image_processor = ViTImageProcessor.from_pretrained(tmp_repo)\n-                for k, v in image_processor.__dict__.items():\n-                    self.assertEqual(v, getattr(new_image_processor, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            image_processor = ViTImageProcessor.from_pretrained(SAMPLE_IMAGE_PROCESSING_CONFIG_DIR)\n+            image_processor.push_to_hub(tmp_repo.repo_id, token=self._token)\n+\n+            new_image_processor = ViTImageProcessor.from_pretrained(tmp_repo.repo_id)\n+            for k, v in image_processor.__dict__.items():\n+                self.assertEqual(v, getattr(new_image_processor, k))\n \n     def test_push_to_hub_in_organization_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-image-processor-{Path(tmp_dir).name}\"\n-                image_processor = ViTImageProcessor.from_pretrained(SAMPLE_IMAGE_PROCESSING_CONFIG_DIR)\n-                # Push to hub via save_pretrained\n-                image_processor.save_pretrained(tmp_dir, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n-\n-                new_image_processor = ViTImageProcessor.from_pretrained(tmp_repo)\n-                for k, v in image_processor.__dict__.items():\n-                    self.assertEqual(v, getattr(new_image_processor, k))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            image_processor = ViTImageProcessor.from_pretrained(SAMPLE_IMAGE_PROCESSING_CONFIG_DIR)\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                image_processor.save_pretrained(tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token)\n+\n+            new_image_processor = ViTImageProcessor.from_pretrained(tmp_repo.repo_id)\n+            for k, v in image_processor.__dict__.items():\n+                self.assertEqual(v, getattr(new_image_processor, k))\n \n     def test_push_to_hub_dynamic_image_processor(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-dynamic-image-processor-{Path(tmp_dir).name}\"\n-                CustomImageProcessor.register_for_auto_class()\n-                image_processor = CustomImageProcessor.from_pretrained(SAMPLE_IMAGE_PROCESSING_CONFIG_DIR)\n-\n-                image_processor.push_to_hub(tmp_repo, token=self._token)\n-\n-                # This has added the proper auto_map field to the config\n-                self.assertDictEqual(\n-                    image_processor.auto_map,\n-                    {\"AutoImageProcessor\": \"custom_image_processing.CustomImageProcessor\"},\n-                )\n-\n-                new_image_processor = AutoImageProcessor.from_pretrained(tmp_repo, trust_remote_code=True)\n-                # Can't make an isinstance check because the new_image_processor is from the CustomImageProcessor class of a dynamic module\n-                self.assertEqual(new_image_processor.__class__.__name__, \"CustomImageProcessor\")\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            CustomImageProcessor.register_for_auto_class()\n+            image_processor = CustomImageProcessor.from_pretrained(SAMPLE_IMAGE_PROCESSING_CONFIG_DIR)\n+\n+            image_processor.push_to_hub(tmp_repo.repo_id, token=self._token)\n+\n+            # This has added the proper auto_map field to the config\n+            self.assertDictEqual(\n+                image_processor.auto_map,\n+                {\"AutoImageProcessor\": \"custom_image_processing.CustomImageProcessor\"},\n+            )\n+\n+            new_image_processor = AutoImageProcessor.from_pretrained(tmp_repo.repo_id, trust_remote_code=True)\n+            # Can't make an isinstance check because the new_image_processor is from the CustomImageProcessor class of a dynamic module\n+            self.assertEqual(new_image_processor.__class__.__name__, \"CustomImageProcessor\")\n \n \n class ImageProcessingUtilsTester(unittest.TestCase):"
        },
        {
            "sha": "7f66944446ab685a320e3e02d64a8ac1376a1c4f",
            "filename": "tests/utils/test_modeling_flax_utils.py",
            "status": "modified",
            "additions": 66,
            "deletions": 93,
            "changes": 159,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Futils%2Ftest_modeling_flax_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Futils%2Ftest_modeling_flax_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_modeling_flax_utils.py?ref=b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f",
            "patch": "@@ -14,16 +14,15 @@\n \n import tempfile\n import unittest\n-from pathlib import Path\n \n import numpy as np\n-from huggingface_hub import HfFolder, delete_repo, snapshot_download\n+from huggingface_hub import HfFolder, snapshot_download\n \n from transformers import BertConfig, BertModel, is_flax_available, is_torch_available\n from transformers.testing_utils import (\n     TOKEN,\n-    USER,\n     CaptureLogger,\n+    TemporaryHubRepo,\n     is_pt_flax_cross_test,\n     is_staging_test,\n     require_flax,\n@@ -55,103 +54,77 @@ def setUpClass(cls):\n         cls._token = TOKEN\n         HfFolder.save_token(TOKEN)\n \n-    @staticmethod\n-    def _try_delete_repo(repo_id, token):\n-        try:\n-            # Reset repo\n-            delete_repo(repo_id=repo_id, token=token)\n-        except:  # noqa E722\n-            pass\n-\n     def test_push_to_hub(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-model-flax-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                model = FlaxBertModel(config)\n-                model.push_to_hub(tmp_repo, token=self._token)\n-\n-                new_model = FlaxBertModel.from_pretrained(tmp_repo)\n-\n-                base_params = flatten_dict(unfreeze(model.params))\n-                new_params = flatten_dict(unfreeze(new_model.params))\n-\n-                for key in base_params.keys():\n-                    max_diff = (base_params[key] - new_params[key]).sum().item()\n-                    self.assertLessEqual(max_diff, 1e-3, msg=f\"{key} not identical\")\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            model = FlaxBertModel(config)\n+            model.push_to_hub(tmp_repo.repo_id, token=self._token)\n+\n+            new_model = FlaxBertModel.from_pretrained(tmp_repo.repo_id)\n+\n+            base_params = flatten_dict(unfreeze(model.params))\n+            new_params = flatten_dict(unfreeze(new_model.params))\n+\n+            for key in base_params.keys():\n+                max_diff = (base_params[key] - new_params[key]).sum().item()\n+                self.assertLessEqual(max_diff, 1e-3, msg=f\"{key} not identical\")\n \n     def test_push_to_hub_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-model-flax-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                model = FlaxBertModel(config)\n-                # Push to hub via save_pretrained\n-                model.save_pretrained(tmp_dir, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n-\n-                new_model = FlaxBertModel.from_pretrained(tmp_repo)\n-\n-                base_params = flatten_dict(unfreeze(model.params))\n-                new_params = flatten_dict(unfreeze(new_model.params))\n-\n-                for key in base_params.keys():\n-                    max_diff = (base_params[key] - new_params[key]).sum().item()\n-                    self.assertLessEqual(max_diff, 1e-3, msg=f\"{key} not identical\")\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            model = FlaxBertModel(config)\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                model.save_pretrained(tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token)\n+\n+            new_model = FlaxBertModel.from_pretrained(tmp_repo.repo_id)\n+\n+            base_params = flatten_dict(unfreeze(model.params))\n+            new_params = flatten_dict(unfreeze(new_model.params))\n+\n+            for key in base_params.keys():\n+                max_diff = (base_params[key] - new_params[key]).sum().item()\n+                self.assertLessEqual(max_diff, 1e-3, msg=f\"{key} not identical\")\n \n     def test_push_to_hub_in_organization(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-model-flax-org-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                model = FlaxBertModel(config)\n-                model.push_to_hub(tmp_repo, token=self._token)\n-\n-                new_model = FlaxBertModel.from_pretrained(tmp_repo)\n-\n-                base_params = flatten_dict(unfreeze(model.params))\n-                new_params = flatten_dict(unfreeze(new_model.params))\n-\n-                for key in base_params.keys():\n-                    max_diff = (base_params[key] - new_params[key]).sum().item()\n-                    self.assertLessEqual(max_diff, 1e-3, msg=f\"{key} not identical\")\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            model = FlaxBertModel(config)\n+            model.push_to_hub(tmp_repo.repo_id, token=self._token)\n+\n+            new_model = FlaxBertModel.from_pretrained(tmp_repo.repo_id)\n+\n+            base_params = flatten_dict(unfreeze(model.params))\n+            new_params = flatten_dict(unfreeze(new_model.params))\n+\n+            for key in base_params.keys():\n+                max_diff = (base_params[key] - new_params[key]).sum().item()\n+                self.assertLessEqual(max_diff, 1e-3, msg=f\"{key} not identical\")\n \n     def test_push_to_hub_in_organization_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-model-flax-org-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                model = FlaxBertModel(config)\n-                # Push to hub via save_pretrained\n-                model.save_pretrained(tmp_dir, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n-\n-                new_model = FlaxBertModel.from_pretrained(tmp_repo)\n-\n-                base_params = flatten_dict(unfreeze(model.params))\n-                new_params = flatten_dict(unfreeze(new_model.params))\n-\n-                for key in base_params.keys():\n-                    max_diff = (base_params[key] - new_params[key]).sum().item()\n-                    self.assertLessEqual(max_diff, 1e-3, msg=f\"{key} not identical\")\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            model = FlaxBertModel(config)\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                model.save_pretrained(tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token)\n+\n+            new_model = FlaxBertModel.from_pretrained(tmp_repo.repo_id)\n+\n+            base_params = flatten_dict(unfreeze(model.params))\n+            new_params = flatten_dict(unfreeze(new_model.params))\n+\n+            for key in base_params.keys():\n+                max_diff = (base_params[key] - new_params[key]).sum().item()\n+                self.assertLessEqual(max_diff, 1e-3, msg=f\"{key} not identical\")\n \n \n def check_models_equal(model1, model2):"
        },
        {
            "sha": "995618a520508f9a7a5e7a46ca030d466d9fd873",
            "filename": "tests/utils/test_modeling_tf_utils.py",
            "status": "modified",
            "additions": 95,
            "deletions": 125,
            "changes": 220,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Futils%2Ftest_modeling_tf_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Futils%2Ftest_modeling_tf_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_modeling_tf_utils.py?ref=b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f",
            "patch": "@@ -23,9 +23,8 @@\n import tempfile\n import unittest\n import unittest.mock as mock\n-from pathlib import Path\n \n-from huggingface_hub import HfFolder, Repository, delete_repo, snapshot_download\n+from huggingface_hub import HfFolder, Repository, snapshot_download\n from requests.exceptions import HTTPError\n \n from transformers import is_tf_available, is_torch_available\n@@ -34,6 +33,7 @@\n     TOKEN,\n     USER,\n     CaptureLogger,\n+    TemporaryHubRepo,\n     _tf_gpu_memory_limit,\n     is_pt_tf_cross_test,\n     is_staging_test,\n@@ -683,149 +683,119 @@ def setUpClass(cls):\n         cls._token = TOKEN\n         HfFolder.save_token(TOKEN)\n \n-    @staticmethod\n-    def _try_delete_repo(repo_id, token):\n-        try:\n-            # Reset repo\n-            delete_repo(repo_id=repo_id, token=token)\n-        except:  # noqa E722\n-            pass\n-\n     def test_push_to_hub(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-model-tf-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                model = TFBertModel(config)\n-                # Make sure model is properly initialized\n-                model.build_in_name_scope()\n-\n-                logging.set_verbosity_info()\n-                logger = logging.get_logger(\"transformers.utils.hub\")\n-                with CaptureLogger(logger) as cl:\n-                    model.push_to_hub(tmp_repo, token=self._token)\n-                logging.set_verbosity_warning()\n-                # Check the model card was created and uploaded.\n-                self.assertIn(\"Uploading the following files to __DUMMY_TRANSFORMERS_USER__/test-model-tf\", cl.out)\n-\n-                new_model = TFBertModel.from_pretrained(tmp_repo)\n-                models_equal = True\n-                for p1, p2 in zip(model.weights, new_model.weights):\n-                    if not tf.math.reduce_all(p1 == p2):\n-                        models_equal = False\n-                        break\n-                self.assertTrue(models_equal)\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            model = TFBertModel(config)\n+            # Make sure model is properly initialized\n+            model.build_in_name_scope()\n+\n+            logging.set_verbosity_info()\n+            logger = logging.get_logger(\"transformers.utils.hub\")\n+            with CaptureLogger(logger) as cl:\n+                model.push_to_hub(tmp_repo.repo_id, token=self._token)\n+            logging.set_verbosity_warning()\n+            # Check the model card was created and uploaded.\n+            self.assertIn(\"Uploading the following files to __DUMMY_TRANSFORMERS_USER__/test-model-tf\", cl.out)\n+\n+            new_model = TFBertModel.from_pretrained(tmp_repo.repo_id)\n+            models_equal = True\n+            for p1, p2 in zip(model.weights, new_model.weights):\n+                if not tf.math.reduce_all(p1 == p2):\n+                    models_equal = False\n+                    break\n+            self.assertTrue(models_equal)\n \n     def test_push_to_hub_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-model-tf-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                model = TFBertModel(config)\n-                # Make sure model is properly initialized\n-                model.build_in_name_scope()\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            model = TFBertModel(config)\n+            # Make sure model is properly initialized\n+            model.build_in_name_scope()\n \n-                # Push to hub via save_pretrained\n-                model.save_pretrained(tmp_dir, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                model.save_pretrained(tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token)\n \n-                new_model = TFBertModel.from_pretrained(tmp_repo)\n-                models_equal = True\n-                for p1, p2 in zip(model.weights, new_model.weights):\n-                    if not tf.math.reduce_all(p1 == p2):\n-                        models_equal = False\n-                        break\n-                self.assertTrue(models_equal)\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            new_model = TFBertModel.from_pretrained(tmp_repo.repo_id)\n+            models_equal = True\n+            for p1, p2 in zip(model.weights, new_model.weights):\n+                if not tf.math.reduce_all(p1 == p2):\n+                    models_equal = False\n+                    break\n+            self.assertTrue(models_equal)\n \n     @is_pt_tf_cross_test\n     def test_push_to_hub_callback(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-model-tf-callback-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                model = TFBertForMaskedLM(config)\n-                model.compile()\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            model = TFBertForMaskedLM(config)\n+            model.compile()\n \n+            with tempfile.TemporaryDirectory() as tmp_dir:\n                 push_to_hub_callback = PushToHubCallback(\n                     output_dir=tmp_dir,\n-                    hub_model_id=tmp_repo,\n+                    hub_model_id=tmp_repo.repo_id,\n                     hub_token=self._token,\n                 )\n                 model.fit(model.dummy_inputs, model.dummy_inputs, epochs=1, callbacks=[push_to_hub_callback])\n \n-                new_model = TFBertForMaskedLM.from_pretrained(tmp_repo)\n-                models_equal = True\n-                for p1, p2 in zip(model.weights, new_model.weights):\n-                    if not tf.math.reduce_all(p1 == p2):\n-                        models_equal = False\n-                        break\n-                self.assertTrue(models_equal)\n-\n-                tf_push_to_hub_params = dict(inspect.signature(TFPreTrainedModel.push_to_hub).parameters)\n-                tf_push_to_hub_params.pop(\"base_model_card_args\")\n-                pt_push_to_hub_params = dict(inspect.signature(PreTrainedModel.push_to_hub).parameters)\n-                pt_push_to_hub_params.pop(\"deprecated_kwargs\")\n-                self.assertDictEaual(tf_push_to_hub_params, pt_push_to_hub_params)\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            new_model = TFBertForMaskedLM.from_pretrained(tmp_repo.repo_id)\n+            models_equal = True\n+            for p1, p2 in zip(model.weights, new_model.weights):\n+                if not tf.math.reduce_all(p1 == p2):\n+                    models_equal = False\n+                    break\n+            self.assertTrue(models_equal)\n+\n+            tf_push_to_hub_params = dict(inspect.signature(TFPreTrainedModel.push_to_hub).parameters)\n+            tf_push_to_hub_params.pop(\"base_model_card_args\")\n+            pt_push_to_hub_params = dict(inspect.signature(PreTrainedModel.push_to_hub).parameters)\n+            pt_push_to_hub_params.pop(\"deprecated_kwargs\")\n+            self.assertDictEaual(tf_push_to_hub_params, pt_push_to_hub_params)\n \n     def test_push_to_hub_in_organization(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-model-tf-org-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                model = TFBertModel(config)\n-                # Make sure model is properly initialized\n-                model.build_in_name_scope()\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            model = TFBertModel(config)\n+            # Make sure model is properly initialized\n+            model.build_in_name_scope()\n \n-                model.push_to_hub(tmp_repo, token=self._token)\n+            model.push_to_hub(tmp_repo.repo_id, token=self._token)\n \n-                new_model = TFBertModel.from_pretrained(tmp_repo)\n-                models_equal = True\n-                for p1, p2 in zip(model.weights, new_model.weights):\n-                    if not tf.math.reduce_all(p1 == p2):\n-                        models_equal = False\n-                        break\n-                self.assertTrue(models_equal)\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            new_model = TFBertModel.from_pretrained(tmp_repo.repo_id)\n+            models_equal = True\n+            for p1, p2 in zip(model.weights, new_model.weights):\n+                if not tf.math.reduce_all(p1 == p2):\n+                    models_equal = False\n+                    break\n+            self.assertTrue(models_equal)\n \n     def test_push_to_hub_in_organization_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-model-tf-org-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                model = TFBertModel(config)\n-                # Make sure model is properly initialized\n-                model.build_in_name_scope()\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            model = TFBertModel(config)\n+            # Make sure model is properly initialized\n+            model.build_in_name_scope()\n \n-                # Push to hub via save_pretrained\n-                model.save_pretrained(tmp_dir, push_to_hub=True, token=self._token, repo_id=tmp_repo)\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                model.save_pretrained(tmp_dir, push_to_hub=True, token=self._token, repo_id=tmp_repo.repo_id)\n \n-                new_model = TFBertModel.from_pretrained(tmp_repo)\n-                models_equal = True\n-                for p1, p2 in zip(model.weights, new_model.weights):\n-                    if not tf.math.reduce_all(p1 == p2):\n-                        models_equal = False\n-                        break\n-                self.assertTrue(models_equal)\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            new_model = TFBertModel.from_pretrained(tmp_repo.repo_id)\n+            models_equal = True\n+            for p1, p2 in zip(model.weights, new_model.weights):\n+                if not tf.math.reduce_all(p1 == p2):\n+                    models_equal = False\n+                    break\n+            self.assertTrue(models_equal)"
        },
        {
            "sha": "458ddeee5ff8be9ce3cd737d351b2d9d83d4f744",
            "filename": "tests/utils/test_modeling_utils.py",
            "status": "modified",
            "additions": 86,
            "deletions": 127,
            "changes": 213,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Futils%2Ftest_modeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Futils%2Ftest_modeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_modeling_utils.py?ref=b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f",
            "patch": "@@ -28,7 +28,7 @@\n from pathlib import Path\n \n import requests\n-from huggingface_hub import HfApi, HfFolder, delete_repo\n+from huggingface_hub import HfApi, HfFolder\n from pytest import mark\n from requests.exceptions import HTTPError\n \n@@ -44,9 +44,9 @@\n )\n from transformers.testing_utils import (\n     TOKEN,\n-    USER,\n     CaptureLogger,\n     LoggingLevel,\n+    TemporaryHubRepo,\n     TestCasePlus,\n     is_staging_test,\n     require_accelerate,\n@@ -2000,168 +2000,127 @@ def setUpClass(cls):\n         cls._token = TOKEN\n         HfFolder.save_token(TOKEN)\n \n-    @staticmethod\n-    def _try_delete_repo(repo_id, token):\n-        try:\n-            # Reset repo\n-            delete_repo(repo_id=repo_id, token=token)\n-        except:  # noqa E722\n-            pass\n-\n     @unittest.skip(reason=\"This test is flaky\")\n     def test_push_to_hub(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-model-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                model = BertModel(config)\n-                model.push_to_hub(tmp_repo, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            model = BertModel(config)\n+            model.push_to_hub(tmp_repo.repo_id, token=self._token)\n \n-                new_model = BertModel.from_pretrained(tmp_repo)\n-                for p1, p2 in zip(model.parameters(), new_model.parameters()):\n-                    self.assertTrue(torch.equal(p1, p2))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            new_model = BertModel.from_pretrained(tmp_repo.repo_id)\n+            for p1, p2 in zip(model.parameters(), new_model.parameters()):\n+                self.assertTrue(torch.equal(p1, p2))\n \n     @unittest.skip(reason=\"This test is flaky\")\n     def test_push_to_hub_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-model-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                model = BertModel(config)\n-                # Push to hub via save_pretrained\n-                model.save_pretrained(tmp_dir, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            model = BertModel(config)\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                model.save_pretrained(tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token)\n \n-                new_model = BertModel.from_pretrained(tmp_repo)\n-                for p1, p2 in zip(model.parameters(), new_model.parameters()):\n-                    self.assertTrue(torch.equal(p1, p2))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            new_model = BertModel.from_pretrained(tmp_repo.repo_id)\n+            for p1, p2 in zip(model.parameters(), new_model.parameters()):\n+                self.assertTrue(torch.equal(p1, p2))\n \n     def test_push_to_hub_with_description(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-model-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                model = BertModel(config)\n-                COMMIT_DESCRIPTION = \"\"\"\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            model = BertModel(config)\n+            COMMIT_DESCRIPTION = \"\"\"\n The commit description supports markdown synthax see:\n ```python\n >>> form transformers import AutoConfig\n >>> config = AutoConfig.from_pretrained(\"google-bert/bert-base-uncased\")\n ```\n \"\"\"\n-                commit_details = model.push_to_hub(\n-                    tmp_repo, use_auth_token=self._token, create_pr=True, commit_description=COMMIT_DESCRIPTION\n-                )\n-                self.assertEqual(commit_details.commit_description, COMMIT_DESCRIPTION)\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            commit_details = model.push_to_hub(\n+                tmp_repo.repo_id, use_auth_token=self._token, create_pr=True, commit_description=COMMIT_DESCRIPTION\n+            )\n+            self.assertEqual(commit_details.commit_description, COMMIT_DESCRIPTION)\n \n     @unittest.skip(reason=\"This test is flaky\")\n     def test_push_to_hub_in_organization(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-model-org-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                model = BertModel(config)\n-                model.push_to_hub(tmp_repo, token=self._token)\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            model = BertModel(config)\n+            model.push_to_hub(tmp_repo.repo_id, token=self._token)\n \n-                new_model = BertModel.from_pretrained(tmp_repo)\n-                for p1, p2 in zip(model.parameters(), new_model.parameters()):\n-                    self.assertTrue(torch.equal(p1, p2))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            new_model = BertModel.from_pretrained(tmp_repo.repo_id)\n+            for p1, p2 in zip(model.parameters(), new_model.parameters()):\n+                self.assertTrue(torch.equal(p1, p2))\n \n     @unittest.skip(reason=\"This test is flaky\")\n     def test_push_to_hub_in_organization_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-model-org-{Path(tmp_dir).name}\"\n-                config = BertConfig(\n-                    vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n-                )\n-                model = BertModel(config)\n-                # Push to hub via save_pretrained\n-                model.save_pretrained(tmp_dir, push_to_hub=True, token=self._token, repo_id=tmp_repo)\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            config = BertConfig(\n+                vocab_size=99, hidden_size=32, num_hidden_layers=5, num_attention_heads=4, intermediate_size=37\n+            )\n+            model = BertModel(config)\n+            # Push to hub via save_pretrained\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n+                model.save_pretrained(tmp_dir, push_to_hub=True, token=self._token, repo_id=tmp_repo.repo_id)\n \n-                new_model = BertModel.from_pretrained(tmp_repo)\n-                for p1, p2 in zip(model.parameters(), new_model.parameters()):\n-                    self.assertTrue(torch.equal(p1, p2))\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            new_model = BertModel.from_pretrained(tmp_repo.repo_id)\n+            for p1, p2 in zip(model.parameters(), new_model.parameters()):\n+                self.assertTrue(torch.equal(p1, p2))\n \n     def test_push_to_hub_dynamic_model(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-dynamic-model-{Path(tmp_dir).name}\"\n-                CustomConfig.register_for_auto_class()\n-                CustomModel.register_for_auto_class()\n-\n-                config = CustomConfig(hidden_size=32)\n-                model = CustomModel(config)\n-\n-                model.push_to_hub(tmp_repo, token=self._token)\n-                # checks\n-                self.assertDictEqual(\n-                    config.auto_map,\n-                    {\"AutoConfig\": \"custom_configuration.CustomConfig\", \"AutoModel\": \"custom_modeling.CustomModel\"},\n-                )\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            CustomConfig.register_for_auto_class()\n+            CustomModel.register_for_auto_class()\n+\n+            config = CustomConfig(hidden_size=32)\n+            model = CustomModel(config)\n+\n+            model.push_to_hub(tmp_repo.repo_id, token=self._token)\n+            # checks\n+            self.assertDictEqual(\n+                config.auto_map,\n+                {\"AutoConfig\": \"custom_configuration.CustomConfig\", \"AutoModel\": \"custom_modeling.CustomModel\"},\n+            )\n \n-                new_model = AutoModel.from_pretrained(tmp_repo, trust_remote_code=True)\n-                # Can't make an isinstance check because the new_model is from the CustomModel class of a dynamic module\n-                self.assertEqual(new_model.__class__.__name__, \"CustomModel\")\n-                for p1, p2 in zip(model.parameters(), new_model.parameters()):\n-                    self.assertTrue(torch.equal(p1, p2))\n+            new_model = AutoModel.from_pretrained(tmp_repo.repo_id, trust_remote_code=True)\n+            # Can't make an isinstance check because the new_model is from the CustomModel class of a dynamic module\n+            self.assertEqual(new_model.__class__.__name__, \"CustomModel\")\n+            for p1, p2 in zip(model.parameters(), new_model.parameters()):\n+                self.assertTrue(torch.equal(p1, p2))\n \n-                config = AutoConfig.from_pretrained(tmp_repo, trust_remote_code=True)\n-                new_model = AutoModel.from_config(config, trust_remote_code=True)\n-                self.assertEqual(new_model.__class__.__name__, \"CustomModel\")\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            config = AutoConfig.from_pretrained(tmp_repo.repo_id, trust_remote_code=True)\n+            new_model = AutoModel.from_config(config, trust_remote_code=True)\n+            self.assertEqual(new_model.__class__.__name__, \"CustomModel\")\n \n     def test_push_to_hub_with_tags(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-dynamic-model-with-tags-{Path(tmp_dir).name}\"\n-                from huggingface_hub import ModelCard\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            from huggingface_hub import ModelCard\n \n-                new_tags = [\"tag-1\", \"tag-2\"]\n+            new_tags = [\"tag-1\", \"tag-2\"]\n \n-                CustomConfig.register_for_auto_class()\n-                CustomModel.register_for_auto_class()\n+            CustomConfig.register_for_auto_class()\n+            CustomModel.register_for_auto_class()\n \n-                config = CustomConfig(hidden_size=32)\n-                model = CustomModel(config)\n+            config = CustomConfig(hidden_size=32)\n+            model = CustomModel(config)\n \n-                self.assertTrue(model.model_tags is None)\n+            self.assertTrue(model.model_tags is None)\n \n-                model.add_model_tags(new_tags)\n+            model.add_model_tags(new_tags)\n \n-                self.assertTrue(model.model_tags == new_tags)\n+            self.assertTrue(model.model_tags == new_tags)\n \n-                model.push_to_hub(tmp_repo, token=self._token)\n+            model.push_to_hub(tmp_repo.repo_id, token=self._token)\n \n-                loaded_model_card = ModelCard.load(tmp_repo)\n-                self.assertEqual(loaded_model_card.data.tags, new_tags)\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            loaded_model_card = ModelCard.load(tmp_repo.repo_id)\n+            self.assertEqual(loaded_model_card.data.tags, new_tags)\n \n \n @require_torch"
        },
        {
            "sha": "0c28f24f4ca2eced61954e1a9af2433c0a31dcb4",
            "filename": "tests/utils/test_tokenization_utils.py",
            "status": "modified",
            "additions": 43,
            "deletions": 76,
            "changes": 119,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Futils%2Ftest_tokenization_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f/tests%2Futils%2Ftest_tokenization_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_tokenization_utils.py?ref=b0a51e5cff3e2e2fddc0b7cd9ff7634134c9819f",
            "patch": "@@ -20,7 +20,7 @@\n import unittest.mock as mock\n from pathlib import Path\n \n-from huggingface_hub import HfFolder, delete_repo\n+from huggingface_hub import HfFolder\n from huggingface_hub.file_download import http_get\n from requests.exceptions import HTTPError\n \n@@ -32,7 +32,7 @@\n     GPT2TokenizerFast,\n     is_tokenizers_available,\n )\n-from transformers.testing_utils import TOKEN, USER, is_staging_test, require_tokenizers\n+from transformers.testing_utils import TOKEN, TemporaryHubRepo, is_staging_test, require_tokenizers\n from transformers.tokenization_utils import ExtensionsTrie, Trie\n \n \n@@ -118,114 +118,84 @@ def setUpClass(cls):\n         cls._token = TOKEN\n         HfFolder.save_token(TOKEN)\n \n-    @staticmethod\n-    def _try_delete_repo(repo_id, token):\n-        try:\n-            # Reset repo\n-            delete_repo(repo_id=repo_id, token=token)\n-        except:  # noqa E722\n-            pass\n-\n     def test_push_to_hub(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-tokenizer-{Path(tmp_dir).name}\"\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n                 vocab_file = os.path.join(tmp_dir, \"vocab.txt\")\n                 with open(vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n                     vocab_writer.write(\"\".join([x + \"\\n\" for x in self.vocab_tokens]))\n                 tokenizer = BertTokenizer(vocab_file)\n \n-                tokenizer.push_to_hub(tmp_repo, token=self._token)\n-                new_tokenizer = BertTokenizer.from_pretrained(tmp_repo)\n-                self.assertDictEqual(new_tokenizer.vocab, tokenizer.vocab)\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            tokenizer.push_to_hub(tmp_repo.repo_id, token=self._token)\n+            new_tokenizer = BertTokenizer.from_pretrained(tmp_repo.repo_id)\n+            self.assertDictEqual(new_tokenizer.vocab, tokenizer.vocab)\n \n     def test_push_to_hub_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-tokenizer-{Path(tmp_dir).name}\"\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n                 vocab_file = os.path.join(tmp_dir, \"vocab.txt\")\n                 with open(vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n                     vocab_writer.write(\"\".join([x + \"\\n\" for x in self.vocab_tokens]))\n                 tokenizer = BertTokenizer(vocab_file)\n \n                 # Push to hub via save_pretrained\n-                tokenizer.save_pretrained(tmp_dir, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n+                tokenizer.save_pretrained(tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token)\n \n-                new_tokenizer = BertTokenizer.from_pretrained(tmp_repo)\n-                self.assertDictEqual(new_tokenizer.vocab, tokenizer.vocab)\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            new_tokenizer = BertTokenizer.from_pretrained(tmp_repo.repo_id)\n+            self.assertDictEqual(new_tokenizer.vocab, tokenizer.vocab)\n \n     def test_push_to_hub_in_organization(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-tokenizer-{Path(tmp_dir).name}\"\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n                 vocab_file = os.path.join(tmp_dir, \"vocab.txt\")\n                 with open(vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n                     vocab_writer.write(\"\".join([x + \"\\n\" for x in self.vocab_tokens]))\n                 tokenizer = BertTokenizer(vocab_file)\n \n-                tokenizer.push_to_hub(tmp_repo, token=self._token)\n-                new_tokenizer = BertTokenizer.from_pretrained(tmp_repo)\n-                self.assertDictEqual(new_tokenizer.vocab, tokenizer.vocab)\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            tokenizer.push_to_hub(tmp_repo.repo_id, token=self._token)\n+            new_tokenizer = BertTokenizer.from_pretrained(tmp_repo.repo_id)\n+            self.assertDictEqual(new_tokenizer.vocab, tokenizer.vocab)\n \n     def test_push_to_hub_in_organization_via_save_pretrained(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"valid_org/test-tokenizer-{Path(tmp_dir).name}\"\n+        with TemporaryHubRepo(namespace=\"valid_org\", token=self._token) as tmp_repo:\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n                 vocab_file = os.path.join(tmp_dir, \"vocab.txt\")\n                 with open(vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n                     vocab_writer.write(\"\".join([x + \"\\n\" for x in self.vocab_tokens]))\n                 tokenizer = BertTokenizer(vocab_file)\n \n                 # Push to hub via save_pretrained\n-                tokenizer.save_pretrained(tmp_dir, repo_id=tmp_repo, push_to_hub=True, token=self._token)\n+                tokenizer.save_pretrained(tmp_dir, repo_id=tmp_repo.repo_id, push_to_hub=True, token=self._token)\n \n-                new_tokenizer = BertTokenizer.from_pretrained(tmp_repo)\n-                self.assertDictEqual(new_tokenizer.vocab, tokenizer.vocab)\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            new_tokenizer = BertTokenizer.from_pretrained(tmp_repo.repo_id)\n+            self.assertDictEqual(new_tokenizer.vocab, tokenizer.vocab)\n \n     @require_tokenizers\n     def test_push_to_hub_dynamic_tokenizer(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-dynamic-tokenizer-{Path(tmp_dir).name}\"\n-                CustomTokenizer.register_for_auto_class()\n-\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            CustomTokenizer.register_for_auto_class()\n+            with tempfile.TemporaryDirectory() as tmp_dir:\n                 vocab_file = os.path.join(tmp_dir, \"vocab.txt\")\n                 with open(vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n                     vocab_writer.write(\"\".join([x + \"\\n\" for x in self.vocab_tokens]))\n                 tokenizer = CustomTokenizer(vocab_file)\n \n-                # No fast custom tokenizer\n-                tokenizer.push_to_hub(tmp_repo, token=self._token)\n+            # No fast custom tokenizer\n+            tokenizer.push_to_hub(tmp_repo.repo_id, token=self._token)\n \n-                tokenizer = AutoTokenizer.from_pretrained(tmp_repo, trust_remote_code=True)\n-                # Can't make an isinstance check because the new_model.config is from the CustomTokenizer class of a dynamic module\n-                self.assertEqual(tokenizer.__class__.__name__, \"CustomTokenizer\")\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            tokenizer = AutoTokenizer.from_pretrained(tmp_repo.repo_id, trust_remote_code=True)\n+            # Can't make an isinstance check because the new_model.config is from the CustomTokenizer class of a dynamic module\n+            self.assertEqual(tokenizer.__class__.__name__, \"CustomTokenizer\")\n \n     @require_tokenizers\n     def test_push_to_hub_dynamic_tokenizer_with_both_slow_and_fast_classes(self):\n-        with tempfile.TemporaryDirectory() as tmp_dir:\n-            try:\n-                tmp_repo = f\"{USER}/test-dynamic-tokenizer-{Path(tmp_dir).name}\"\n-                CustomTokenizer.register_for_auto_class()\n+        with TemporaryHubRepo(token=self._token) as tmp_repo:\n+            CustomTokenizer.register_for_auto_class()\n \n-                # Fast and slow custom tokenizer\n-                CustomTokenizerFast.register_for_auto_class()\n+            # Fast and slow custom tokenizer\n+            CustomTokenizerFast.register_for_auto_class()\n \n+            with tempfile.TemporaryDirectory() as tmp_dir:\n                 vocab_file = os.path.join(tmp_dir, \"vocab.txt\")\n                 with open(vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n                     vocab_writer.write(\"\".join([x + \"\\n\" for x in self.vocab_tokens]))\n@@ -234,17 +204,14 @@ def test_push_to_hub_dynamic_tokenizer_with_both_slow_and_fast_classes(self):\n                 bert_tokenizer.save_pretrained(tmp_dir)\n                 tokenizer = CustomTokenizerFast.from_pretrained(tmp_dir)\n \n-                tokenizer.push_to_hub(tmp_repo, token=self._token)\n-\n-                tokenizer = AutoTokenizer.from_pretrained(tmp_repo, trust_remote_code=True)\n-                # Can't make an isinstance check because the new_model.config is from the FakeConfig class of a dynamic module\n-                self.assertEqual(tokenizer.__class__.__name__, \"CustomTokenizerFast\")\n-                tokenizer = AutoTokenizer.from_pretrained(tmp_repo, use_fast=False, trust_remote_code=True)\n-                # Can't make an isinstance check because the new_model.config is from the FakeConfig class of a dynamic module\n-                self.assertEqual(tokenizer.__class__.__name__, \"CustomTokenizer\")\n-            finally:\n-                # Always (try to) delete the repo.\n-                self._try_delete_repo(repo_id=tmp_repo, token=self._token)\n+            tokenizer.push_to_hub(tmp_repo.repo_id, token=self._token)\n+\n+            tokenizer = AutoTokenizer.from_pretrained(tmp_repo.repo_id, trust_remote_code=True)\n+            # Can't make an isinstance check because the new_model.config is from the FakeConfig class of a dynamic module\n+            self.assertEqual(tokenizer.__class__.__name__, \"CustomTokenizerFast\")\n+            tokenizer = AutoTokenizer.from_pretrained(tmp_repo.repo_id, use_fast=False, trust_remote_code=True)\n+            # Can't make an isinstance check because the new_model.config is from the FakeConfig class of a dynamic module\n+            self.assertEqual(tokenizer.__class__.__name__, \"CustomTokenizer\")\n \n \n class TrieTest(unittest.TestCase):"
        }
    ],
    "stats": {
        "total": 1654,
        "additions": 701,
        "deletions": 953
    }
}