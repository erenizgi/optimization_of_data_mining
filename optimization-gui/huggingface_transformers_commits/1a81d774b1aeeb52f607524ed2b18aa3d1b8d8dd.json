{
    "author": "KarelVesely84",
    "message": "Add dithering to the `Speech2TextFeatureExtractor` API. (#34638)\n\n* Add dithering to the `Speech2TextFeatureExtractor` API.\n\n- in kaldi : https://github.com/kaldi-asr/kaldi/blob/4a8b7f673275597fef8a15b160124bd0985b59bd/src/feat/feature-window.cc#L145\n- with dithering without a seed, the features become non-deterministic due\n  to small Gaussian noise added to the audio (i.e. 2 runs lead to little\n  different outputs)\n\n* update the PR\n\n- add dithering also for WhisperFeatureExtractor\n- not adding to Wav2Vec2FeatureExtractor (no FBANK computation)\n\n* add unit-tests for dithering, fix docstrings\n\n* ruff\n\n* utils/check_copies.py --fix_and_overwrite\n\n* update code, add seed to unit-test\n\n* adding explanation of dithering",
    "sha": "1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd",
    "files": [
        {
            "sha": "5629718a818932e565d5d7d9726f9090f716eff0",
            "filename": "src/transformers/audio_utils.py",
            "status": "modified",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd/src%2Ftransformers%2Faudio_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd/src%2Ftransformers%2Faudio_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Faudio_utils.py?ref=1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd",
            "patch": "@@ -390,6 +390,7 @@ def spectrogram(\n     center: bool = True,\n     pad_mode: str = \"reflect\",\n     onesided: bool = True,\n+    dither: float = 0.0,\n     preemphasis: Optional[float] = None,\n     mel_filters: Optional[np.ndarray] = None,\n     mel_floor: float = 1e-10,\n@@ -460,6 +461,12 @@ def spectrogram(\n         onesided (`bool`, *optional*, defaults to `True`):\n             If True, only computes the positive frequencies and returns a spectrogram containing `fft_length // 2 + 1`\n             frequency bins. If False, also computes the negative frequencies and returns `fft_length` frequency bins.\n+        dither (`float`, *optional*, defaults to 0.0):\n+            Adds dithering. In other words, adds a small Gaussian noise to each frame.\n+            E.g. use 4.0 to add dithering with a normal distribution centered\n+            around 0.0 with standard deviation 4.0, 0.0 means no dithering.\n+            Dithering has similar effect as `mel_floor`. It reduces the high log_mel_fbank\n+            values for signals with hard-zero sections, when VAD cutoff is present in the signal.\n         preemphasis (`float`, *optional*)\n             Coefficient for a low-pass filter that applies pre-emphasis before the DFT.\n         mel_filters (`np.ndarray` of shape `(num_freq_bins, num_mel_filters)`, *optional*):\n@@ -540,6 +547,9 @@ def spectrogram(\n     for frame_idx in range(num_frames):\n         buffer[:frame_length] = waveform[timestep : timestep + frame_length]\n \n+        if dither != 0.0:\n+            buffer[:frame_length] += dither * np.random.randn(frame_length)\n+\n         if remove_dc_offset:\n             buffer[:frame_length] = buffer[:frame_length] - buffer[:frame_length].mean()\n \n@@ -591,6 +601,7 @@ def spectrogram_batch(\n     center: bool = True,\n     pad_mode: str = \"reflect\",\n     onesided: bool = True,\n+    dither: float = 0.0,\n     preemphasis: Optional[float] = None,\n     mel_filters: Optional[np.ndarray] = None,\n     mel_floor: float = 1e-10,\n@@ -653,6 +664,10 @@ def spectrogram_batch(\n             The padding strategy when `center` is `True`.\n         onesided (`bool`, *optional*, defaults to `True`):\n             If True, returns a one-sided spectrogram for real input signals.\n+        dither (`float`, *optional*, defaults to 0.0):\n+            Adds dithering. In other words, adds a small Gaussian noise to each frame.\n+            E.g. use 4.0 to add dithering with a normal distribution centered\n+            around 0.0 with standard deviation 4.0, 0.0 means no dithering.\n         preemphasis (`float`, *optional*):\n             Applies a pre-emphasis filter to each frame.\n         mel_filters (`np.ndarray`, *optional*):\n@@ -741,6 +756,9 @@ def spectrogram_batch(\n         timestep = frame_idx * hop_length\n         buffer[:, :frame_length] = padded_waveform_batch[:, timestep : timestep + frame_length]\n \n+        if dither != 0.0:\n+            buffer[:, :frame_length] += dither * np.random.randn(*buffer[:, :frame_length].shape)\n+\n         if remove_dc_offset:\n             buffer[:, :frame_length] -= buffer[:, :frame_length].mean(axis=1, keepdims=True)\n "
        },
        {
            "sha": "9e460bb2c40412ef961f137cddaf3d04732670d1",
            "filename": "src/transformers/models/speech_to_text/feature_extraction_speech_to_text.py",
            "status": "modified",
            "additions": 16,
            "deletions": 1,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd/src%2Ftransformers%2Fmodels%2Fspeech_to_text%2Ffeature_extraction_speech_to_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd/src%2Ftransformers%2Fmodels%2Fspeech_to_text%2Ffeature_extraction_speech_to_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fspeech_to_text%2Ffeature_extraction_speech_to_text.py?ref=1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd",
            "patch": "@@ -52,6 +52,13 @@ class Speech2TextFeatureExtractor(SequenceFeatureExtractor):\n             Number of Mel-frequency bins.\n         padding_value (`float`, *optional*, defaults to 0.0):\n             The value that is used to fill the padding vectors.\n+        dither (`float`, *optional*, defaults to 0.0):\n+            Adds dithering. In other words, adds a small Gaussian noise to each frame.\n+            E.g. use 4.0 to add dithering with a normal distribution centered\n+            around 0.0 with standard deviation 4.0 (assuming [-32k,+32k] range of kaldi waveform).\n+            The value 0.0 means no dithering.\n+            Dithering has similar effect as `mel_floor`. It reduces the high log_mel_fbank\n+            values for signals with hard-zero sections, when VAD cutoff is present in the signal.\n         do_ceptral_normalize (`bool`, *optional*, defaults to `True`):\n             Whether or not to apply utterance-level cepstral mean and variance normalization to extracted features.\n         normalize_means (`bool`, *optional*, defaults to `True`):\n@@ -68,13 +75,15 @@ def __init__(\n         sampling_rate=16000,\n         num_mel_bins=80,\n         padding_value=0.0,\n+        dither=0.0,\n         do_ceptral_normalize=True,\n         normalize_means=True,\n         normalize_vars=True,\n         **kwargs,\n     ):\n         super().__init__(feature_size=feature_size, sampling_rate=sampling_rate, padding_value=padding_value, **kwargs)\n         self.num_mel_bins = num_mel_bins\n+        self.dither = dither\n         self.do_ceptral_normalize = do_ceptral_normalize\n         self.normalize_means = normalize_means\n         self.normalize_vars = normalize_vars\n@@ -106,7 +115,12 @@ def _extract_fbank_features(\n         waveform = waveform * (2**15)  # Kaldi compliance: 16-bit signed integers\n         if is_speech_available():\n             waveform = torch.from_numpy(waveform).unsqueeze(0)\n-            features = ta_kaldi.fbank(waveform, num_mel_bins=self.num_mel_bins, sample_frequency=self.sampling_rate)\n+            features = ta_kaldi.fbank(\n+                waveform,\n+                dither=self.dither,\n+                num_mel_bins=self.num_mel_bins,\n+                sample_frequency=self.sampling_rate,\n+            )\n             features = features.numpy()\n         else:\n             waveform = np.squeeze(waveform)\n@@ -118,6 +132,7 @@ def _extract_fbank_features(\n                 fft_length=512,\n                 power=2.0,\n                 center=False,\n+                dither=self.dither,\n                 preemphasis=0.97,\n                 mel_filters=self.mel_filters,\n                 log_mel=\"log\","
        },
        {
            "sha": "766071e9bfceaed4d0fa64d2b8f99da85121e6ba",
            "filename": "src/transformers/models/whisper/feature_extraction_whisper.py",
            "status": "modified",
            "additions": 17,
            "deletions": 0,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd/src%2Ftransformers%2Fmodels%2Fwhisper%2Ffeature_extraction_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd/src%2Ftransformers%2Fmodels%2Fwhisper%2Ffeature_extraction_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Ffeature_extraction_whisper.py?ref=1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd",
            "patch": "@@ -57,6 +57,14 @@ class WhisperFeatureExtractor(SequenceFeatureExtractor):\n             Size of the Fourier transform.\n         padding_value (`float`, *optional*, defaults to 0.0):\n             Padding value used to pad the audio. Should correspond to silences.\n+        dither (`float`, *optional*, defaults to 0.0):\n+            Adds dithering. In other words, adds a small Gaussian noise to each frame.\n+            E.g. use 0.0001 to add dithering with a normal distribution centered\n+            around 0.0 with standard deviation 0.0001 (assuming [-1,+1] range of raw_speech).\n+            The value 0.0 means no dithering.\n+            Dithering has similar effect as `spectrogram(mel_floor=...)`. It reduces\n+            the high log_mel_fbank values for signals with hard-zero sections,\n+            when VAD cutoff is present in the signal.\n     \"\"\"\n \n     model_input_names = [\"input_features\"]\n@@ -69,6 +77,7 @@ def __init__(\n         chunk_length=30,\n         n_fft=400,\n         padding_value=0.0,\n+        dither=0.0,\n         return_attention_mask=False,  # pad inputs to max length with silence token (zero) and no attention mask\n         **kwargs,\n     ):\n@@ -85,6 +94,7 @@ def __init__(\n         self.n_samples = chunk_length * sampling_rate\n         self.nb_max_frames = self.n_samples // hop_length\n         self.sampling_rate = sampling_rate\n+        self.dither = dither\n         self.mel_filters = mel_filter_bank(\n             num_frequency_bins=1 + n_fft // 2,\n             num_mel_filters=feature_size,\n@@ -114,6 +124,7 @@ def _np_extract_fbank_features(self, waveform_batch: np.array, device: str) -> n\n                 frame_length=self.n_fft,\n                 hop_length=self.hop_length,\n                 power=2.0,\n+                dither=self.dither,\n                 mel_filters=self.mel_filters,\n                 log_mel=\"log10\",\n             )\n@@ -132,6 +143,12 @@ def _torch_extract_fbank_features(self, waveform: np.array, device: str = \"cpu\")\n         waveform = torch.from_numpy(waveform).to(device, torch.float32)\n         window = torch.hann_window(self.n_fft, device=device)\n \n+        # Note: it would be better to dither the chunked waveform,\n+        # so overlapping signal does not get the same dithering.\n+        # But, chunking is happening inside pytorch, so it is here.\n+        if self.dither != 0.0:\n+            waveform += self.dither * torch.randn(waveform.shape, dtype=waveform.dtype, device=waveform.device)\n+\n         stft = torch.stft(waveform, self.n_fft, self.hop_length, window=window, return_complex=True)\n         magnitudes = stft[..., :-1].abs() ** 2\n "
        },
        {
            "sha": "f6ddbb140b87205fff28d22b4ae0b7872b6e2c9b",
            "filename": "tests/models/speech_to_text/test_feature_extraction_speech_to_text.py",
            "status": "modified",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/huggingface/transformers/blob/1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd/tests%2Fmodels%2Fspeech_to_text%2Ftest_feature_extraction_speech_to_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd/tests%2Fmodels%2Fspeech_to_text%2Ftest_feature_extraction_speech_to_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fspeech_to_text%2Ftest_feature_extraction_speech_to_text.py?ref=1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd",
            "patch": "@@ -144,6 +144,40 @@ def test_call(self):\n         for enc_seq_1, enc_seq_2 in zip(encoded_sequences_1, encoded_sequences_2):\n             self.assertTrue(np.allclose(enc_seq_1, enc_seq_2, atol=1e-3))\n \n+    def test_dither(self):\n+        np.random.seed(42)  # seed the dithering randn()\n+\n+        # Tests that features with and without little dithering are similar, but not the same\n+        dict_no_dither = self.feat_extract_tester.prepare_feat_extract_dict()\n+        dict_no_dither[\"dither\"] = 0.0\n+\n+        dict_dither = self.feat_extract_tester.prepare_feat_extract_dict()\n+        dict_dither[\"dither\"] = 1.0\n+\n+        feature_extractor_no_dither = self.feature_extraction_class(**dict_no_dither)\n+        feature_extractor_dither = self.feature_extraction_class(**dict_dither)\n+\n+        # create three inputs of length 800, 1000, and 1200\n+        speech_inputs = [floats_list((1, x))[0] for x in range(800, 1400, 200)]\n+        np_speech_inputs = [np.asarray(speech_input) for speech_input in speech_inputs]\n+\n+        # compute features\n+        input_features_no_dither = feature_extractor_no_dither(\n+            np_speech_inputs, padding=True, return_tensors=\"np\"\n+        ).input_features\n+        input_features_dither = feature_extractor_dither(\n+            np_speech_inputs, padding=True, return_tensors=\"np\"\n+        ).input_features\n+\n+        # test there is a difference between features (there's added noise to input signal)\n+        diff = input_features_dither - input_features_no_dither\n+\n+        # features are not identical\n+        self.assertTrue(np.abs(diff).mean() > 1e-5)\n+        # features are not too different\n+        self.assertTrue(np.abs(diff).mean() <= 1e-3)\n+        self.assertTrue(np.abs(diff).max() <= 1e-2)\n+\n     def test_cepstral_mean_and_variance_normalization(self):\n         feature_extractor = self.feature_extraction_class(**self.feat_extract_tester.prepare_feat_extract_dict())\n         speech_inputs = [floats_list((1, x))[0] for x in range(800, 1400, 200)]"
        },
        {
            "sha": "d07ef2221c624ff767eb31dca8cc474027cfbf59",
            "filename": "tests/models/whisper/test_feature_extraction_whisper.py",
            "status": "modified",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/huggingface/transformers/blob/1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd/tests%2Fmodels%2Fwhisper%2Ftest_feature_extraction_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd/tests%2Fmodels%2Fwhisper%2Ftest_feature_extraction_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwhisper%2Ftest_feature_extraction_whisper.py?ref=1a81d774b1aeeb52f607524ed2b18aa3d1b8d8dd",
            "patch": "@@ -200,6 +200,40 @@ def test_call(self):\n         for enc_seq_1, enc_seq_2 in zip(encoded_sequences_1, encoded_sequences_2):\n             self.assertTrue(np.allclose(enc_seq_1, enc_seq_2, atol=1e-3))\n \n+    def test_dither(self):\n+        np.random.seed(42)  # seed the dithering randn()\n+\n+        # Tests that features with and without little dithering are similar, but not the same\n+        dict_no_dither = self.feat_extract_tester.prepare_feat_extract_dict()\n+        dict_no_dither[\"dither\"] = 0.0\n+\n+        dict_dither = self.feat_extract_tester.prepare_feat_extract_dict()\n+        dict_dither[\"dither\"] = 0.00003  # approx. 1/32k\n+\n+        feature_extractor_no_dither = self.feature_extraction_class(**dict_no_dither)\n+        feature_extractor_dither = self.feature_extraction_class(**dict_dither)\n+\n+        # create three inputs of length 800, 1000, and 1200\n+        speech_inputs = [floats_list((1, x))[0] for x in range(800, 1400, 200)]\n+        np_speech_inputs = [np.asarray(speech_input) for speech_input in speech_inputs]\n+\n+        # compute features\n+        input_features_no_dither = feature_extractor_no_dither(\n+            np_speech_inputs, padding=True, return_tensors=\"np\"\n+        ).input_features\n+        input_features_dither = feature_extractor_dither(\n+            np_speech_inputs, padding=True, return_tensors=\"np\"\n+        ).input_features\n+\n+        # test there is a difference between features (there's added noise to input signal)\n+        diff = input_features_dither - input_features_no_dither\n+\n+        # features are not identical\n+        self.assertTrue(np.abs(diff).mean() > 1e-6)\n+        # features are not too different\n+        self.assertTrue(np.abs(diff).mean() <= 1e-4)\n+        self.assertTrue(np.abs(diff).max() <= 1e-3)\n+\n     @require_torch\n     def test_double_precision_pad(self):\n         import torch"
        }
    ],
    "stats": {
        "total": 120,
        "additions": 119,
        "deletions": 1
    }
}