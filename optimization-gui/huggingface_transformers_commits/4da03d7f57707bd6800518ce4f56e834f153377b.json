{
    "author": "ydshieh",
    "message": "Reduce more test data fetch (#40595)\n\n* example\n\n* fix\n\n* fix\n\n* add to fetch script\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "4da03d7f57707bd6800518ce4f56e834f153377b",
    "files": [
        {
            "sha": "db445af1c409ffe6f1908e295dac24009c55e65e",
            "filename": "tests/models/aria/test_processing_aria.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Faria%2Ftest_processing_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Faria%2Ftest_processing_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faria%2Ftest_processing_aria.py?ref=4da03d7f57707bd6800518ce4f56e834f153377b",
            "patch": "@@ -25,7 +25,7 @@\n from transformers.testing_utils import require_torch, require_vision\n from transformers.utils import is_vision_available\n \n-from ...test_processing_common import ProcessorTesterMixin\n+from ...test_processing_common import ProcessorTesterMixin, url_to_local_path\n \n \n if is_vision_available():\n@@ -273,7 +273,7 @@ def test_image_chat_template_accepts_processing_kwargs(self):\n \n         # Now test the ability to return dict\n         messages[0][0][\"content\"].append(\n-            {\"type\": \"image\", \"url\": \"https://www.ilankelman.org/stopsigns/australia.jpg\"}\n+            {\"type\": \"image\", \"url\": url_to_local_path(\"https://www.ilankelman.org/stopsigns/australia.jpg\")}\n         )\n         out_dict = processor.apply_chat_template(\n             messages,"
        },
        {
            "sha": "ef77e7355a3b12c71b133ce529f0751e0795283e",
            "filename": "tests/models/aya_vision/test_processing_aya_vision.py",
            "status": "modified",
            "additions": 8,
            "deletions": 4,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Faya_vision%2Ftest_processing_aya_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Faya_vision%2Ftest_processing_aya_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faya_vision%2Ftest_processing_aya_vision.py?ref=4da03d7f57707bd6800518ce4f56e834f153377b",
            "patch": "@@ -20,7 +20,7 @@\n from transformers.testing_utils import require_torch, require_vision\n from transformers.utils import is_torch_available, is_vision_available\n \n-from ...test_processing_common import ProcessorTesterMixin\n+from ...test_processing_common import ProcessorTesterMixin, url_to_local_path\n \n \n if is_torch_available():\n@@ -104,11 +104,15 @@ def test_process_interleaved_images_videos(self):\n                     \"content\": [\n                         {\n                             \"type\": \"image\",\n-                            \"url\": \"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\",\n+                            \"url\": url_to_local_path(\n+                                \"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\"\n+                            ),\n                         },\n                         {\n                             \"type\": \"image\",\n-                            \"url\": \"https://thumbs.dreamstime.com/b/golden-gate-bridge-san-francisco-purple-flowers-california-echium-candicans-36805947.jpg\",\n+                            \"url\": url_to_local_path(\n+                                \"https://thumbs.dreamstime.com/b/golden-gate-bridge-san-francisco-purple-flowers-california-echium-candicans-36805947.jpg\"\n+                            ),\n                         },\n                         {\"type\": \"text\", \"text\": \"What are the differences between these two images?\"},\n                     ],\n@@ -120,7 +124,7 @@ def test_process_interleaved_images_videos(self):\n                     \"content\": [\n                         {\n                             \"type\": \"image\",\n-                            \"url\": \"https://llava-vl.github.io/static/images/view.jpg\",\n+                            \"url\": url_to_local_path(\"https://llava-vl.github.io/static/images/view.jpg\"),\n                         },\n                         {\"type\": \"text\", \"text\": \"Write a haiku for this image\"},\n                     ],"
        },
        {
            "sha": "963deae9feff237e1c4548ee4fd748b18c84a9e7",
            "filename": "tests/models/cohere2_vision/test_processing_cohere2_vision.py",
            "status": "modified",
            "additions": 8,
            "deletions": 4,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Fcohere2_vision%2Ftest_processing_cohere2_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Fcohere2_vision%2Ftest_processing_cohere2_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fcohere2_vision%2Ftest_processing_cohere2_vision.py?ref=4da03d7f57707bd6800518ce4f56e834f153377b",
            "patch": "@@ -20,7 +20,7 @@\n from transformers.testing_utils import require_read_token, require_torch, require_vision\n from transformers.utils import is_torch_available, is_torchvision_available\n \n-from ...test_processing_common import ProcessorTesterMixin\n+from ...test_processing_common import ProcessorTesterMixin, url_to_local_path\n \n \n if is_torch_available():\n@@ -82,11 +82,15 @@ def test_process_interleaved_images_videos(self):\n                     \"content\": [\n                         {\n                             \"type\": \"image\",\n-                            \"url\": \"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\",\n+                            \"url\": url_to_local_path(\n+                                \"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\"\n+                            ),\n                         },\n                         {\n                             \"type\": \"image\",\n-                            \"url\": \"https://thumbs.dreamstime.com/b/golden-gate-bridge-san-francisco-purple-flowers-california-echium-candicans-36805947.jpg\",\n+                            \"url\": url_to_local_path(\n+                                \"https://thumbs.dreamstime.com/b/golden-gate-bridge-san-francisco-purple-flowers-california-echium-candicans-36805947.jpg\"\n+                            ),\n                         },\n                         {\"type\": \"text\", \"text\": \"What are the differences between these two images?\"},\n                     ],\n@@ -98,7 +102,7 @@ def test_process_interleaved_images_videos(self):\n                     \"content\": [\n                         {\n                             \"type\": \"image\",\n-                            \"url\": \"https://llava-vl.github.io/static/images/view.jpg\",\n+                            \"url\": url_to_local_path(\"https://llava-vl.github.io/static/images/view.jpg\"),\n                         },\n                         {\"type\": \"text\", \"text\": \"Write a haiku for this image\"},\n                     ],"
        },
        {
            "sha": "69413b786d7b0e7598e4eb8fb925bc81853d9334",
            "filename": "tests/models/glm4v/test_processor_glm4v.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Fglm4v%2Ftest_processor_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Fglm4v%2Ftest_processor_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fglm4v%2Ftest_processor_glm4v.py?ref=4da03d7f57707bd6800518ce4f56e834f153377b",
            "patch": "@@ -23,7 +23,7 @@\n from transformers.testing_utils import require_av, require_torch, require_vision\n from transformers.utils import is_torch_available, is_vision_available\n \n-from ...test_processing_common import ProcessorTesterMixin\n+from ...test_processing_common import ProcessorTesterMixin, url_to_local_path\n \n \n if is_vision_available():\n@@ -203,7 +203,9 @@ def test_apply_chat_template_video_frame_sampling(self):\n         # Add video URL for return dict and load with `num_frames` arg\n         messages[0][0][\"content\"][0] = {\n             \"type\": \"video\",\n-            \"url\": \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\",\n+            \"url\": url_to_local_path(\n+                \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\"\n+            ),\n         }\n \n         # Load with `video_fps` arg"
        },
        {
            "sha": "ad47927386e706ce4df180461cbe9e7fedfac7ff",
            "filename": "tests/models/internvl/test_processing_internvl.py",
            "status": "modified",
            "additions": 14,
            "deletions": 6,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Finternvl%2Ftest_processing_internvl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Finternvl%2Ftest_processing_internvl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Finternvl%2Ftest_processing_internvl.py?ref=4da03d7f57707bd6800518ce4f56e834f153377b",
            "patch": "@@ -21,7 +21,7 @@\n from transformers.testing_utils import require_av, require_torch, require_vision\n from transformers.utils import is_torch_available, is_vision_available\n \n-from ...test_processing_common import ProcessorTesterMixin\n+from ...test_processing_common import ProcessorTesterMixin, url_to_local_path\n \n \n if is_torch_available():\n@@ -120,11 +120,15 @@ def test_process_interleaved_images_videos(self):\n                     \"content\": [\n                         {\n                             \"type\": \"image\",\n-                            \"url\": \"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\",\n+                            \"url\": url_to_local_path(\n+                                \"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\"\n+                            ),\n                         },\n                         {\n                             \"type\": \"image\",\n-                            \"url\": \"https://thumbs.dreamstime.com/b/golden-gate-bridge-san-francisco-purple-flowers-california-echium-candicans-36805947.jpg\",\n+                            \"url\": url_to_local_path(\n+                                \"https://thumbs.dreamstime.com/b/golden-gate-bridge-san-francisco-purple-flowers-california-echium-candicans-36805947.jpg\"\n+                            ),\n                         },\n                         {\"type\": \"text\", \"text\": \"What are the differences between these two images?\"},\n                     ],\n@@ -136,7 +140,9 @@ def test_process_interleaved_images_videos(self):\n                     \"content\": [\n                         {\n                             \"type\": \"video\",\n-                            \"url\": \"https://huggingface.co/datasets/hf-internal-testing/fixtures_videos/resolve/main/tennis.mp4\",\n+                            \"url\": url_to_local_path(\n+                                \"https://huggingface.co/datasets/hf-internal-testing/fixtures_videos/resolve/main/tennis.mp4\"\n+                            ),\n                         },\n                         {\"type\": \"text\", \"text\": \"What type of shot is the man performing?\"},\n                     ],\n@@ -148,7 +154,7 @@ def test_process_interleaved_images_videos(self):\n                     \"content\": [\n                         {\n                             \"type\": \"image\",\n-                            \"url\": \"https://llava-vl.github.io/static/images/view.jpg\",\n+                            \"url\": url_to_local_path(\"https://llava-vl.github.io/static/images/view.jpg\"),\n                         },\n                         {\"type\": \"text\", \"text\": \"Write a haiku for this image\"},\n                     ],\n@@ -212,7 +218,9 @@ def test_apply_chat_template_video_frame_sampling(self):\n                     \"content\": [\n                         {\n                             \"type\": \"video\",\n-                            \"url\": \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\",\n+                            \"url\": url_to_local_path(\n+                                \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\"\n+                            ),\n                         },\n                         {\"type\": \"text\", \"text\": \"What is shown in this video?\"},\n                     ],"
        },
        {
            "sha": "a8cef7babf4c5a36e20ee82e26eeba0d71ff2aae",
            "filename": "tests/models/mllama/test_processing_mllama.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Fmllama%2Ftest_processing_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Fmllama%2Ftest_processing_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmllama%2Ftest_processing_mllama.py?ref=4da03d7f57707bd6800518ce4f56e834f153377b",
            "patch": "@@ -24,7 +24,7 @@\n from transformers.testing_utils import require_torch, require_vision\n from transformers.utils import is_vision_available\n \n-from ...test_processing_common import ProcessorTesterMixin\n+from ...test_processing_common import ProcessorTesterMixin, url_to_local_path\n \n \n if is_vision_available():\n@@ -172,9 +172,9 @@ def test_apply_chat_template(self):\n                 \"role\": \"user\",\n                 \"content\": [\n                     {\"type\": \"text\", \"text\": \"Describe this image in two sentences\"},\n-                    {\"type\": \"image\", \"url\": \"https://www.ilankelman.org/stopsigns/australia.jpg\"},\n+                    {\"type\": \"image\", \"url\": url_to_local_path(\"https://www.ilankelman.org/stopsigns/australia.jpg\")},\n                     {\"type\": \"text\", \"text\": \" Test sentence   \"},\n-                    {\"type\": \"image\", \"url\": \"https://www.ilankelman.org/stopsigns/australia.jpg\"},\n+                    {\"type\": \"image\", \"url\": url_to_local_path(\"https://www.ilankelman.org/stopsigns/australia.jpg\")},\n                     {\"type\": \"text\", \"text\": \"ok\\n\"},\n                 ],\n             }"
        },
        {
            "sha": "658c67af7cbc78748d85523175096897ad435137",
            "filename": "tests/models/qwen2_5_omni/test_processing_qwen2_5_omni.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_processing_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_processing_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_processing_qwen2_5_omni.py?ref=4da03d7f57707bd6800518ce4f56e834f153377b",
            "patch": "@@ -38,7 +38,7 @@\n )\n from transformers.utils import is_torch_available, is_vision_available\n \n-from ...test_processing_common import ProcessorTesterMixin\n+from ...test_processing_common import ProcessorTesterMixin, url_to_local_path\n \n \n if is_torch_available():\n@@ -456,7 +456,9 @@ def test_apply_chat_template_video_frame_sampling(self):\n         messages[0][0][\"content\"].append(\n             {\n                 \"type\": \"video\",\n-                \"url\": \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\",\n+                \"url\": url_to_local_path(\n+                    \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\"\n+                ),\n             }\n         )\n         num_frames = 3"
        },
        {
            "sha": "02ce2e4c86021f9943327636e383cfba649079a6",
            "filename": "tests/models/qwen2_5_vl/test_processing_qwen2_5_vl.py",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_processing_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_processing_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_processing_qwen2_5_vl.py?ref=4da03d7f57707bd6800518ce4f56e834f153377b",
            "patch": "@@ -24,7 +24,7 @@\n from transformers.testing_utils import require_av, require_torch, require_torchvision, require_vision\n from transformers.utils import is_torch_available, is_vision_available\n \n-from ...test_processing_common import ProcessorTesterMixin\n+from ...test_processing_common import ProcessorTesterMixin, url_to_local_path\n \n \n if is_vision_available():\n@@ -274,7 +274,9 @@ def test_apply_chat_template_video_frame_sampling(self):\n         # Add video URL for return dict and load with `num_frames` arg\n         messages[0][0][\"content\"][0] = {\n             \"type\": \"video\",\n-            \"url\": \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\",\n+            \"url\": url_to_local_path(\n+                \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\"\n+            ),\n         }\n         num_frames = 3\n         out_dict_with_video = processor.apply_chat_template(\n@@ -325,8 +327,8 @@ def test_apply_chat_template_video_frame_sampling(self):\n         messages[0][0][\"content\"][0] = {\n             \"type\": \"video\",\n             \"url\": [\n-                \"https://www.ilankelman.org/stopsigns/australia.jpg\",\n-                \"https://www.ilankelman.org/stopsigns/australia.jpg\",\n+                url_to_local_path(\"https://www.ilankelman.org/stopsigns/australia.jpg\"),\n+                url_to_local_path(\"https://www.ilankelman.org/stopsigns/australia.jpg\"),\n             ],\n         }\n         out_dict_with_video = processor.apply_chat_template("
        },
        {
            "sha": "e2882c2e29df5729ff6ff0cc53e6f0e4c9c57a61",
            "filename": "tests/models/qwen2_vl/test_processing_qwen2_vl.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Fqwen2_vl%2Ftest_processing_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Fqwen2_vl%2Ftest_processing_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_vl%2Ftest_processing_qwen2_vl.py?ref=4da03d7f57707bd6800518ce4f56e834f153377b",
            "patch": "@@ -24,7 +24,7 @@\n from transformers.testing_utils import require_av, require_torch, require_torchvision, require_vision\n from transformers.utils import is_torch_available, is_torchvision_available, is_vision_available\n \n-from ...test_processing_common import ProcessorTesterMixin\n+from ...test_processing_common import ProcessorTesterMixin, url_to_local_path\n \n \n if is_vision_available():\n@@ -274,7 +274,9 @@ def test_apply_chat_template_video_frame_sampling(self):\n         # Add video URL for return dict and load with `num_frames` arg\n         messages[0][0][\"content\"][0] = {\n             \"type\": \"video\",\n-            \"url\": \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\",\n+            \"url\": url_to_local_path(\n+                \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\"\n+            ),\n         }\n         num_frames = 3\n         out_dict_with_video = processor.apply_chat_template("
        },
        {
            "sha": "b373e2bb025a6c45fce3ce3669eb144dd6f41355",
            "filename": "tests/models/smolvlm/test_processing_smolvlm.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Fsmolvlm%2Ftest_processing_smolvlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4da03d7f57707bd6800518ce4f56e834f153377b/tests%2Fmodels%2Fsmolvlm%2Ftest_processing_smolvlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsmolvlm%2Ftest_processing_smolvlm.py?ref=4da03d7f57707bd6800518ce4f56e834f153377b",
            "patch": "@@ -26,7 +26,7 @@\n from transformers.testing_utils import require_av, require_torch, require_vision\n from transformers.utils import is_vision_available\n \n-from ...test_processing_common import ProcessorTesterMixin\n+from ...test_processing_common import ProcessorTesterMixin, url_to_local_path\n \n \n if is_vision_available():\n@@ -397,7 +397,9 @@ def test_apply_chat_template_video_frame_sampling(self):\n                     \"content\": [\n                         {\n                             \"type\": \"video\",\n-                            \"url\": \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\",\n+                            \"url\": url_to_local_path(\n+                                \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\"\n+                            ),\n                         },\n                         {\"type\": \"text\", \"text\": \"What is shown in this video?\"},\n                     ],"
        },
        {
            "sha": "f1dcc5467b4f9f968f63601e4c3e518cb15dad66",
            "filename": "utils/fetch_hub_objects_for_ci.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/4da03d7f57707bd6800518ce4f56e834f153377b/utils%2Ffetch_hub_objects_for_ci.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4da03d7f57707bd6800518ce4f56e834f153377b/utils%2Ffetch_hub_objects_for_ci.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Ffetch_hub_objects_for_ci.py?ref=4da03d7f57707bd6800518ce4f56e834f153377b",
            "patch": "@@ -14,6 +14,10 @@\n     \"https://huggingface.co/datasets/raushan-testing-hf/audio-test/resolve/main/f2641_0_throatclearing.wav\",\n     \"https://www.ilankelman.org/stopsigns/australia.jpg\",\n     \"http://images.cocodataset.org/val2017/000000039769.jpg\",\n+    \"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\",\n+    \"https://thumbs.dreamstime.com/b/golden-gate-bridge-san-francisco-purple-flowers-california-echium-candicans-36805947.jpg\",\n+    \"https://llava-vl.github.io/static/images/view.jpg\",\n+    \"https://huggingface.co/datasets/hf-internal-testing/fixtures_videos/resolve/main/tennis.mp4\",\n ]\n \n "
        }
    ],
    "stats": {
        "total": 92,
        "additions": 61,
        "deletions": 31
    }
}