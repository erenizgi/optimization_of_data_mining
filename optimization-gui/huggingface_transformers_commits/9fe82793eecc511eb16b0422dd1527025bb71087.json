{
    "author": "kashif",
    "message": "[Style] fix E721 warnings (#36474)\n\n* fix E721 warnings\n\n* config.hidden_size is not a tuple\n\n* fix copies\n\n* fix-copies\n\n* not a tuple\n\n* undo\n\n* undo",
    "sha": "9fe82793eecc511eb16b0422dd1527025bb71087",
    "files": [
        {
            "sha": "0c27bd02a7df9fcffe1bd7de20ca2aafd8f10ec5",
            "filename": "examples/research_projects/movement-pruning/Saving_PruneBERT.ipynb",
            "status": "modified",
            "additions": 13,
            "deletions": 13,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/examples%2Fresearch_projects%2Fmovement-pruning%2FSaving_PruneBERT.ipynb",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/examples%2Fresearch_projects%2Fmovement-pruning%2FSaving_PruneBERT.ipynb",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fresearch_projects%2Fmovement-pruning%2FSaving_PruneBERT.ipynb?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -41,7 +41,7 @@\n     \"from scipy import sparse\\n\",\n     \"from torch import nn\\n\",\n     \"\\n\",\n-    \"from transformers import *\\n\",\n+    \"from transformers import BertForQuestionAnswering\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"os.chdir(\\\"../../\\\")\"\n@@ -307,7 +307,7 @@\n     \"            print(f\\\"Skip {name}\\\")\\n\",\n     \"            continue\\n\",\n     \"\\n\",\n-    \"        if type(param) == torch.Tensor:\\n\",\n+    \"        if isinstance(param, torch.Tensor):\\n\",\n     \"            if param.numel() == 1:\\n\",\n     \"                # module scale\\n\",\n     \"                # module zero_point\\n\",\n@@ -319,13 +319,13 @@\n     \"                param = param.detach().numpy()\\n\",\n     \"            hf.create_dataset(name, data=param, compression=\\\"gzip\\\", compression_opts=9)\\n\",\n     \"\\n\",\n-    \"        elif type(param) == float or type(param) == int or type(param) == tuple:\\n\",\n+    \"        elif isinstance(param, (float, int, tuple)):\\n\",\n     \"            # float - tensor _packed_params.weight.scale\\n\",\n     \"            # int   - tensor _packed_params.weight.zero_point\\n\",\n     \"            # tuple - tensor _packed_params.weight.shape\\n\",\n     \"            hf.attrs[name] = param\\n\",\n     \"\\n\",\n-    \"        elif type(param) == torch.dtype:\\n\",\n+    \"        elif isinstance(param, torch.dtype):\\n\",\n     \"            # dtype - tensor _packed_params.dtype\\n\",\n     \"            hf.attrs[name] = dtype_2_str[param]\\n\",\n     \"\\n\",\n@@ -370,7 +370,7 @@\n     \"        #             print(f\\\"Skip {name}\\\")\\n\",\n     \"        #             continue\\n\",\n     \"\\n\",\n-    \"        if type(param) == torch.Tensor:\\n\",\n+    \"        if isinstance(param, torch.Tensor):\\n\",\n     \"            if param.numel() == 1:\\n\",\n     \"                # module scale\\n\",\n     \"                # module zero_point\\n\",\n@@ -382,13 +382,13 @@\n     \"                param = param.detach().numpy()\\n\",\n     \"            hf.create_dataset(name, data=param, compression=\\\"gzip\\\", compression_opts=9)\\n\",\n     \"\\n\",\n-    \"        elif type(param) == float or type(param) == int or type(param) == tuple:\\n\",\n+    \"        elif isinstance(param, (float, int, tuple)):\\n\",\n     \"            # float - tensor _packed_params.weight.scale\\n\",\n     \"            # int   - tensor _packed_params.weight.zero_point\\n\",\n     \"            # tuple - tensor _packed_params.weight.shape\\n\",\n     \"            hf.attrs[name] = param\\n\",\n     \"\\n\",\n-    \"        elif type(param) == torch.dtype:\\n\",\n+    \"        elif isinstance(param, torch.dtype):\\n\",\n     \"            # dtype - tensor _packed_params.dtype\\n\",\n     \"            hf.attrs[name] = dtype_2_str[param]\\n\",\n     \"\\n\",\n@@ -471,10 +471,10 @@\n     \"    assert name in reconstructed_elementary_qtz_st, name\\n\",\n     \"\\n\",\n     \"for name, param in reconstructed_elementary_qtz_st.items():\\n\",\n-    \"    assert type(param) == type(elementary_qtz_st[name]), name\\n\",\n-    \"    if type(param) == torch.Tensor:\\n\",\n+    \"    assert isinstance(param, type(elementary_qtz_st[name])), name\\n\",\n+    \"    if isinstance(param, torch.Tensor):\\n\",\n     \"        assert torch.all(torch.eq(param, elementary_qtz_st[name])), name\\n\",\n-    \"    elif type(param) == np.ndarray:\\n\",\n+    \"    elif isinstance(param, np.ndarray):\\n\",\n     \"        assert (param == elementary_qtz_st[name]).all(), name\\n\",\n     \"    else:\\n\",\n     \"        assert param == elementary_qtz_st[name], name\"\n@@ -532,10 +532,10 @@\n     \"    assert name in reconstructed_qtz_st, name\\n\",\n     \"\\n\",\n     \"for name, param in reconstructed_qtz_st.items():\\n\",\n-    \"    assert type(param) == type(qtz_st[name]), name\\n\",\n-    \"    if type(param) == torch.Tensor:\\n\",\n+    \"    assert isinstance(param, type(qtz_st[name])), name\\n\",\n+    \"    if isinstance(param, torch.Tensor):\\n\",\n     \"        assert torch.all(torch.eq(param, qtz_st[name])), name\\n\",\n-    \"    elif type(param) == np.ndarray:\\n\",\n+    \"    elif isinstance(param, np.ndarray):\\n\",\n     \"        assert (param == qtz_st[name]).all(), name\\n\",\n     \"    else:\\n\",\n     \"        assert param == qtz_st[name], name\""
        },
        {
            "sha": "3d72676774291d4462971ec9390c8f4ceb885fd8",
            "filename": "src/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -114,7 +114,7 @@ def __init__(self, config: ASTConfig) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "b4b116bdfb0fab3622c03a6f312c47398e078059",
            "filename": "src/transformers/models/beit/modeling_beit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fbeit%2Fmodeling_beit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fbeit%2Fmodeling_beit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbeit%2Fmodeling_beit.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -270,7 +270,7 @@ def __init__(self, config: BeitConfig, window_size: Optional[tuple] = None) -> N\n         self.config = config\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {(config.hidden_size,)} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "d37eedea3f4e805fdee885d46c9d2b45fef9d4a0",
            "filename": "src/transformers/models/beit/modeling_flax_beit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fbeit%2Fmodeling_flax_beit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fbeit%2Fmodeling_flax_beit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbeit%2Fmodeling_flax_beit.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -271,7 +271,7 @@ def setup(self):\n             self.config, \"embedding_size\"\n         ):\n             raise ValueError(\n-                f\"The hidden size {self.config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {self.config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {self.config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "c86495cbbe21bdf22fb20f902fefd1746771f5c8",
            "filename": "src/transformers/models/data2vec/modeling_data2vec_vision.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_vision.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -271,7 +271,7 @@ def __init__(self, config: Data2VecVisionConfig, window_size: Optional[tuple] =\n         self.config = config\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {(config.hidden_size,)} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "66a556da818d4a830d4feb20814162603ed1ce5b",
            "filename": "src/transformers/models/deit/modeling_deit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -186,7 +186,7 @@ def __init__(self, config: DeiTConfig) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "aab3d4ff2debef17316acd1374253595fcf2e30a",
            "filename": "src/transformers/models/deprecated/tvlt/modeling_tvlt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftvlt%2Fmodeling_tvlt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftvlt%2Fmodeling_tvlt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftvlt%2Fmodeling_tvlt.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -345,7 +345,7 @@ def __init__(self, config):\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "922d5fab9be9a077fb81c9ca35c289abc1e7c81c",
            "filename": "src/transformers/models/deprecated/vit_hybrid/modeling_vit_hybrid.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvit_hybrid%2Fmodeling_vit_hybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvit_hybrid%2Fmodeling_vit_hybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvit_hybrid%2Fmodeling_vit_hybrid.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -204,7 +204,7 @@ def __init__(self, config: ViTHybridConfig) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "3ba48b7026c65ac393dbe4d197131119491e5e8e",
            "filename": "src/transformers/models/dinov2/modeling_dinov2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -178,7 +178,7 @@ def __init__(self, config: Dinov2Config) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "dae5904b78e7ca2e3e0922471ad081a3d4c309e0",
            "filename": "src/transformers/models/dinov2_with_registers/modeling_dinov2_with_registers.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -190,7 +190,7 @@ def __init__(self, config: Dinov2WithRegistersConfig) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "e4d55603e6310fdddaaffa6b6eaf7f97413cad59",
            "filename": "src/transformers/models/dpt/modeling_dpt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -301,7 +301,7 @@ def __init__(self, config: DPTConfig) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "94395bd27119921313073b488ec38fad10604508",
            "filename": "src/transformers/models/flava/modeling_flava.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fflava%2Fmodeling_flava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fflava%2Fmodeling_flava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflava%2Fmodeling_flava.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -438,7 +438,7 @@ def __init__(self, config: FlavaPossibleConfigs) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "7d4619480c385f82e1e6df81b3e43554804e109c",
            "filename": "src/transformers/models/ijepa/modeling_ijepa.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -194,7 +194,7 @@ def __init__(self, config: IJepaConfig) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "4665ff0f0e5cff951ff294c6015c16a27a450cc4",
            "filename": "src/transformers/models/luke/modeling_luke.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fluke%2Fmodeling_luke.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fluke%2Fmodeling_luke.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fluke%2Fmodeling_luke.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -501,7 +501,7 @@ def __init__(self, config):\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "f41da2bafaf280f5a5596e23344489f78c70f6cc",
            "filename": "src/transformers/models/mobilevit/modeling_mobilevit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fmodeling_mobilevit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fmodeling_mobilevit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fmodeling_mobilevit.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -215,7 +215,7 @@ def __init__(self, config: MobileViTConfig, hidden_size: int) -> None:\n \n         if hidden_size % config.num_attention_heads != 0:\n             raise ValueError(\n-                f\"The hidden size {hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "76397f160b59a02348473a97e0577244481f461b",
            "filename": "src/transformers/models/mobilevit/modeling_tf_mobilevit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fmodeling_tf_mobilevit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fmodeling_tf_mobilevit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fmodeling_tf_mobilevit.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -262,7 +262,7 @@ def __init__(self, config: MobileViTConfig, hidden_size: int, **kwargs) -> None:\n \n         if hidden_size % config.num_attention_heads != 0:\n             raise ValueError(\n-                f\"The hidden size {hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "44f4d9a8a868e4b5274a6e9dae3747e18f4344d3",
            "filename": "src/transformers/models/qwen2_audio/processing_qwen2_audio.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fqwen2_audio%2Fprocessing_qwen2_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fqwen2_audio%2Fprocessing_qwen2_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_audio%2Fprocessing_qwen2_audio.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -112,7 +112,7 @@ def __call__(\n \n         # ensure we have as much audios as audio tokens\n         num_audio_tokens = sum(sample.count(self.audio_token) for sample in text)\n-        num_audios = 1 if type(audios) == np.ndarray else len(audios)\n+        num_audios = 1 if isinstance(audios, np.ndarray) else len(audios)\n         if num_audio_tokens != num_audios:\n             raise ValueError(\n                 f\"Found {num_audio_tokens} {self.audio_token} token{'s' if num_audio_tokens > 1 else ''} in provided text but received {num_audios} audio{'s' if num_audios > 1 else ''}\""
        },
        {
            "sha": "0e51cd988688a4c4a32ddea55893026b3bc6ebec",
            "filename": "src/transformers/models/videomae/modeling_videomae.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fvideomae%2Fmodeling_videomae.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fvideomae%2Fmodeling_videomae.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvideomae%2Fmodeling_videomae.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -201,7 +201,7 @@ def __init__(self, config: VideoMAEConfig) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "07ed544d041c2ec1daf9b7375efa7064b7bb732d",
            "filename": "src/transformers/models/vilt/modeling_vilt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fvilt%2Fmodeling_vilt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fvilt%2Fmodeling_vilt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvilt%2Fmodeling_vilt.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -322,7 +322,7 @@ def __init__(self, config):\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "2fd430c1019baa5af1e9cc4b400efed380983feb",
            "filename": "src/transformers/models/vit/modeling_vit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fvit%2Fmodeling_vit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fvit%2Fmodeling_vit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvit%2Fmodeling_vit.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -189,7 +189,7 @@ def __init__(self, config: ViTConfig) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "86e71155d9c648dd00fbea46a34eaf2d1d5d9332",
            "filename": "src/transformers/models/vit_mae/modeling_vit_mae.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fvit_mae%2Fmodeling_vit_mae.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fvit_mae%2Fmodeling_vit_mae.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvit_mae%2Fmodeling_vit_mae.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -362,7 +362,7 @@ def __init__(self, config: ViTMAEConfig) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "79021a6b8b677b3c2b363871da26d99d7152b6f6",
            "filename": "src/transformers/models/vit_msn/modeling_vit_msn.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fvit_msn%2Fmodeling_vit_msn.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fvit_msn%2Fmodeling_vit_msn.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvit_msn%2Fmodeling_vit_msn.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -179,7 +179,7 @@ def __init__(self, config: ViTMSNConfig) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "b4a1acd3361fb32b1c9dc185d5b2d1c1dd1b4a34",
            "filename": "src/transformers/models/vitpose_backbone/modeling_vitpose_backbone.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fvitpose_backbone%2Fmodeling_vitpose_backbone.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fvitpose_backbone%2Fmodeling_vitpose_backbone.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvitpose_backbone%2Fmodeling_vitpose_backbone.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -109,7 +109,7 @@ def __init__(self, config: VitPoseBackboneConfig) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "4ef0f29bc8453d61d74b5491d016e38d141f9f05",
            "filename": "src/transformers/models/vivit/modeling_vivit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fvivit%2Fmodeling_vivit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fvivit%2Fmodeling_vivit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvivit%2Fmodeling_vivit.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -172,7 +172,7 @@ def __init__(self, config: VivitConfig) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        },
        {
            "sha": "5801e0bca28fc88a3c9b6523029d9a8378cae464",
            "filename": "src/transformers/models/yolos/modeling_yolos.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fyolos%2Fmodeling_yolos.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fe82793eecc511eb16b0422dd1527025bb71087/src%2Ftransformers%2Fmodels%2Fyolos%2Fmodeling_yolos.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fyolos%2Fmodeling_yolos.py?ref=9fe82793eecc511eb16b0422dd1527025bb71087",
            "patch": "@@ -237,7 +237,7 @@ def __init__(self, config: YolosConfig) -> None:\n         super().__init__()\n         if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n             raise ValueError(\n-                f\"The hidden size {config.hidden_size,} is not a multiple of the number of attention \"\n+                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n                 f\"heads {config.num_attention_heads}.\"\n             )\n "
        }
    ],
    "stats": {
        "total": 74,
        "additions": 37,
        "deletions": 37
    }
}