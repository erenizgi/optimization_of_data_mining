{
    "author": "yao-matrix",
    "message": "fix XPU UT error case brough by RNG difference btw XPU and CUDA (#37121)\n\n* fix XPU UT error case brough by RNG difference btw XPU and CUDA\n\nSigned-off-by: YAO Matrix <matrix.yao@intel.com>\n\n* enable tests/models/llama/test_modeling_llama.py::LlamaIntegrationTest::test_model_7b_logits and tests/models/llama/test_modeling_llama.py::LlamaIntegrationTest::test_model_7b_logits_bf16 on xpu\n\nSigned-off-by: YAO Matrix <matrix.yao@intel.com>\n\n* Revert \"enable tests/models/llama/test_modeling_llama.py::LlamaIntegrationTest::test_model_7b_logits and tests/models/llama/test_modeling_llama.py::LlamaIntegrationTest::test_model_7b_logits_bf16 on xpu\"\n\nThis reverts commit 3ef83a4f0204642daa45fda56e8aca1afed24b4f.\n\n---------\n\nSigned-off-by: YAO Matrix <matrix.yao@intel.com>",
    "sha": "24e311f42b54f5f5fab6efcaa0c82eebd5608ba3",
    "files": [
        {
            "sha": "9d7acdfcb5fe1e5edaafe58cf01e681d16bca417",
            "filename": "tests/generation/test_logits_process.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/24e311f42b54f5f5fab6efcaa0c82eebd5608ba3/tests%2Fgeneration%2Ftest_logits_process.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/24e311f42b54f5f5fab6efcaa0c82eebd5608ba3/tests%2Fgeneration%2Ftest_logits_process.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fgeneration%2Ftest_logits_process.py?ref=24e311f42b54f5f5fab6efcaa0c82eebd5608ba3",
            "patch": "@@ -976,7 +976,8 @@ def test_watermarking_processor(self):\n         input_ids[:, -1] = 10\n         scores_wo_bias = scores[:, -1].clone()\n         out = watermark(input_ids=input_ids, scores=scores)\n-        self.assertTrue((out[:, 1] == scores_wo_bias + watermark.bias).all())\n+        greenlist_id = 3 if torch_device == \"xpu\" else 1\n+        self.assertTrue((out[:, greenlist_id] == scores_wo_bias + watermark.bias).all())\n \n     @parameterized.expand([(5, 3, 10000), (10, 5, 1000)])\n     def test_synthidtext_watermarking_processor_bias_uniformity(self, ngram_len, num_layers, vocab_size):"
        }
    ],
    "stats": {
        "total": 3,
        "additions": 2,
        "deletions": 1
    }
}