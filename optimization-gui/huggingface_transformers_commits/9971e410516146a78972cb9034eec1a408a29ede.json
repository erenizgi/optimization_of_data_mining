{
    "author": "molbap",
    "message": "Do not return a tuple in mistral tokenizer Automapping (#42997)\n\n* do not return a tuple\n\n* add a test\n\n* fix test\n\n* improve doc",
    "sha": "9971e410516146a78972cb9034eec1a408a29ede",
    "files": [
        {
            "sha": "1916fbb4ee704813d407ee0969240c8081fcf95c",
            "filename": "src/transformers/models/auto/tokenization_auto.py",
            "status": "modified",
            "additions": 12,
            "deletions": 10,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/9971e410516146a78972cb9034eec1a408a29ede/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9971e410516146a78972cb9034eec1a408a29ede/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py?ref=9971e410516146a78972cb9034eec1a408a29ede",
            "patch": "@@ -218,11 +218,12 @@\n         (\"minimax\", \"GPT2Tokenizer\" if is_tokenizers_available() else None),\n         (\n             \"ministral3\",\n-            (\n-                \"MistralCommonBackend\"\n-                if is_mistral_common_available()\n-                else (\"LlamaTokenizer\" if is_sentencepiece_available() else None),\n-                \"LlamaTokenizer\" if is_tokenizers_available() and not is_mistral_common_available() else None,\n+            \"MistralCommonBackend\"\n+            if is_mistral_common_available()\n+            else (\n+                \"LlamaTokenizer\"\n+                if is_tokenizers_available()\n+                else (\"LlamaTokenizer\" if is_sentencepiece_available() else None)\n             ),\n         ),\n         (\n@@ -233,11 +234,12 @@\n         ),\n         (\n             \"mistral3\",\n-            (\n-                \"MistralCommonBackend\"\n-                if is_mistral_common_available()\n-                else (\"LlamaTokenizer\" if is_sentencepiece_available() else None),\n-                \"LlamaTokenizer\" if is_tokenizers_available() and not is_mistral_common_available() else None,\n+            \"MistralCommonBackend\"\n+            if is_mistral_common_available()\n+            else (\n+                \"LlamaTokenizer\"\n+                if is_tokenizers_available()\n+                else (\"LlamaTokenizer\" if is_sentencepiece_available() else None)\n             ),\n         ),\n         ("
        },
        {
            "sha": "50c642f438ca1aa30735f5c554891eafd3624ae9",
            "filename": "tests/models/auto/test_tokenization_auto.py",
            "status": "modified",
            "additions": 17,
            "deletions": 0,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/9971e410516146a78972cb9034eec1a408a29ede/tests%2Fmodels%2Fauto%2Ftest_tokenization_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9971e410516146a78972cb9034eec1a408a29ede/tests%2Fmodels%2Fauto%2Ftest_tokenization_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fauto%2Ftest_tokenization_auto.py?ref=9971e410516146a78972cb9034eec1a408a29ede",
            "patch": "@@ -44,6 +44,7 @@\n from transformers.models.auto.configuration_auto import CONFIG_MAPPING, AutoConfig\n from transformers.models.auto.tokenization_auto import (\n     TOKENIZER_MAPPING,\n+    TOKENIZER_MAPPING_NAMES,\n     get_tokenizer_config,\n     tokenizer_class_from_name,\n )\n@@ -176,6 +177,22 @@ def test_model_name_edge_cases_in_mappings(self):\n             # must find the right class\n             tokenizer_class_from_name(tokenizer_name)\n \n+    def test_tokenizer_mapping_names_use_single_entries(self):\n+        # this is just to ensure tokenizer mapping names are correct and map to strings!\n+        invalid_entries = [\n+            model_name\n+            for model_name, tokenizer_entry in TOKENIZER_MAPPING_NAMES.items()\n+            if isinstance(tokenizer_entry, (tuple, list))\n+        ]\n+        self.assertListEqual(\n+            invalid_entries,\n+            [],\n+            msg=(\n+                \"TOKENIZER_MAPPING_NAMES should map model types to single tokenizer class names. \"\n+                f\"Found invalid mappings for: {invalid_entries}\"\n+            ),\n+        )\n+\n     @require_tokenizers\n     def test_from_pretrained_use_fast_toggle(self):\n         self.assertIsInstance("
        }
    ],
    "stats": {
        "total": 39,
        "additions": 29,
        "deletions": 10
    }
}