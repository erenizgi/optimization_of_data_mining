{
    "author": "qubvel",
    "message": "Improve `.from_pretrained` type annotations (#34973)\n\n* Fix from_pretrained type annotations\r\n\r\n* Better typing for image processor's `from_pretrained`",
    "sha": "01ad80f820db828ebe68acc0555f177fbf1d4baf",
    "files": [
        {
            "sha": "e73d4a8a56f311028e03122268396f958f57cdfd",
            "filename": "src/transformers/image_processing_base.py",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/01ad80f820db828ebe68acc0555f177fbf1d4baf/src%2Ftransformers%2Fimage_processing_base.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/01ad80f820db828ebe68acc0555f177fbf1d4baf/src%2Ftransformers%2Fimage_processing_base.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fimage_processing_base.py?ref=01ad80f820db828ebe68acc0555f177fbf1d4baf",
            "patch": "@@ -19,7 +19,7 @@\n import os\n import warnings\n from io import BytesIO\n-from typing import Any, Dict, List, Optional, Tuple, Union\n+from typing import Any, Dict, List, Optional, Tuple, Type, TypeVar, Union\n \n import numpy as np\n import requests\n@@ -45,6 +45,9 @@\n     from PIL import Image\n \n \n+ImageProcessorType = TypeVar(\"ImageProcessorType\", bound=\"ImageProcessingMixin\")\n+\n+\n logger = logging.get_logger(__name__)\n \n \n@@ -95,15 +98,15 @@ def _set_processor_class(self, processor_class: str):\n \n     @classmethod\n     def from_pretrained(\n-        cls,\n+        cls: Type[ImageProcessorType],\n         pretrained_model_name_or_path: Union[str, os.PathLike],\n         cache_dir: Optional[Union[str, os.PathLike]] = None,\n         force_download: bool = False,\n         local_files_only: bool = False,\n         token: Optional[Union[str, bool]] = None,\n         revision: str = \"main\",\n         **kwargs,\n-    ):\n+    ) -> ImageProcessorType:\n         r\"\"\"\n         Instantiate a type of [`~image_processing_utils.ImageProcessingMixin`] from an image processor.\n "
        },
        {
            "sha": "0806c318e101524fab12d9f2c178c25db1a10d1b",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 8,
            "deletions": 4,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/01ad80f820db828ebe68acc0555f177fbf1d4baf/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/01ad80f820db828ebe68acc0555f177fbf1d4baf/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=01ad80f820db828ebe68acc0555f177fbf1d4baf",
            "patch": "@@ -30,7 +30,7 @@\n from dataclasses import dataclass\n from functools import partial, wraps\n from multiprocessing import Process\n-from typing import Any, Callable, Dict, List, Optional, Set, Tuple, Union\n+from typing import Any, Callable, Dict, List, Optional, Set, Tuple, Type, TypeVar, Union\n from zipfile import is_zipfile\n \n import torch\n@@ -170,6 +170,10 @@ def is_local_dist_rank_0():\n if is_peft_available():\n     from .utils import find_adapter_config_file\n \n+\n+SpecificPreTrainedModelType = TypeVar(\"SpecificPreTrainedModelType\", bound=\"PreTrainedModel\")\n+\n+\n TORCH_INIT_FUNCTIONS = {\n     \"uniform_\": nn.init.uniform_,\n     \"normal_\": nn.init.normal_,\n@@ -3142,7 +3146,7 @@ def float(self, *args):\n \n     @classmethod\n     def from_pretrained(\n-        cls,\n+        cls: Type[SpecificPreTrainedModelType],\n         pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n         *model_args,\n         config: Optional[Union[PretrainedConfig, str, os.PathLike]] = None,\n@@ -3152,10 +3156,10 @@ def from_pretrained(\n         local_files_only: bool = False,\n         token: Optional[Union[str, bool]] = None,\n         revision: str = \"main\",\n-        use_safetensors: bool = None,\n+        use_safetensors: Optional[bool] = None,\n         weights_only: bool = True,\n         **kwargs,\n-    ) -> \"PreTrainedModel\":\n+    ) -> SpecificPreTrainedModelType:\n         r\"\"\"\n         Instantiate a pretrained pytorch model from a pre-trained model configuration.\n "
        }
    ],
    "stats": {
        "total": 21,
        "additions": 14,
        "deletions": 7
    }
}