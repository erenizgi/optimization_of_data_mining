{
    "author": "ydshieh",
    "message": "Fix `return_dict=False` giving errors in a few VLM models (#38519)\n\nupdate\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "481b953170ca66f7999b1d448cfd2a814dd28c35",
    "files": [
        {
            "sha": "5644f68baa926a34ab3997033393193268fad6a0",
            "filename": "src/transformers/models/chameleon/modeling_chameleon.py",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/481b953170ca66f7999b1d448cfd2a814dd28c35/src%2Ftransformers%2Fmodels%2Fchameleon%2Fmodeling_chameleon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/481b953170ca66f7999b1d448cfd2a814dd28c35/src%2Ftransformers%2Fmodels%2Fchameleon%2Fmodeling_chameleon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchameleon%2Fmodeling_chameleon.py?ref=481b953170ca66f7999b1d448cfd2a814dd28c35",
            "patch": "@@ -1243,7 +1243,6 @@ def forward(\n         use_cache: Optional[bool] = None,\n         output_attentions: Optional[bool] = None,\n         output_hidden_states: Optional[bool] = None,\n-        return_dict: Optional[bool] = None,\n         cache_position: Optional[torch.LongTensor] = None,\n         **kwargs: Unpack[KwargsForCausalLM],\n     ) -> Union[Tuple, CausalLMOutputWithPast]:\n@@ -1277,7 +1276,6 @@ def forward(\n         output_hidden_states = (\n             output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n         )\n-        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n \n         # decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\n         outputs = self.model(\n@@ -1290,7 +1288,7 @@ def forward(\n             use_cache=use_cache,\n             output_attentions=output_attentions,\n             output_hidden_states=output_hidden_states,\n-            return_dict=return_dict,\n+            return_dict=True,\n             cache_position=cache_position,\n             **kwargs,\n         )"
        },
        {
            "sha": "ebf578fedfc5b2b250bee565ed65baa331b20b09",
            "filename": "src/transformers/models/kosmos2/modeling_kosmos2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/481b953170ca66f7999b1d448cfd2a814dd28c35/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fmodeling_kosmos2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/481b953170ca66f7999b1d448cfd2a814dd28c35/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fmodeling_kosmos2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fmodeling_kosmos2.py?ref=481b953170ca66f7999b1d448cfd2a814dd28c35",
            "patch": "@@ -1809,7 +1809,6 @@ def forward(\n         use_cache: Optional[bool] = None,\n         output_attentions: Optional[bool] = None,\n         output_hidden_states: Optional[bool] = None,\n-        return_dict: Optional[bool] = None,\n         **kwargs: Unpack[KwargsForCausalLM],\n     ) -> Union[Tuple, Kosmos2ForConditionalGenerationModelOutput]:\n         r\"\"\"\n@@ -1868,7 +1867,6 @@ def forward(\n         output_hidden_states = (\n             output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n         )\n-        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n \n         vision_model_output = None\n         projection_attentions = None\n@@ -1880,7 +1878,6 @@ def forward(\n                 pixel_values=pixel_values,\n                 output_attentions=output_attentions,\n                 output_hidden_states=output_hidden_states,\n-                return_dict=return_dict,\n             )\n             # The whole `last_hidden_state` through `post_layernorm` instead of just `pooled_output`.\n             image_embeds = self.vision_model.model.post_layernorm(vision_model_output[0])"
        },
        {
            "sha": "e5b597e819edd1ffc258362e9ebc2b5852577434",
            "filename": "src/transformers/models/llava_next/modeling_llava_next.py",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/481b953170ca66f7999b1d448cfd2a814dd28c35/src%2Ftransformers%2Fmodels%2Fllava_next%2Fmodeling_llava_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/481b953170ca66f7999b1d448cfd2a814dd28c35/src%2Ftransformers%2Fmodels%2Fllava_next%2Fmodeling_llava_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_next%2Fmodeling_llava_next.py?ref=481b953170ca66f7999b1d448cfd2a814dd28c35",
            "patch": "@@ -604,7 +604,6 @@ def forward(\n         use_cache: Optional[bool] = None,\n         output_attentions: Optional[bool] = None,\n         output_hidden_states: Optional[bool] = None,\n-        return_dict: Optional[bool] = None,\n         cache_position: Optional[torch.LongTensor] = None,\n         logits_to_keep: Union[int, torch.Tensor] = 0,\n         **kwargs: Unpack[KwargsForCausalLM],\n@@ -645,7 +644,6 @@ def forward(\n         output_hidden_states = (\n             output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n         )\n-        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n         vision_feature_layer = (\n             vision_feature_layer if vision_feature_layer is not None else self.config.vision_feature_layer\n         )\n@@ -668,7 +666,7 @@ def forward(\n             use_cache=use_cache,\n             output_attentions=output_attentions,\n             output_hidden_states=output_hidden_states,\n-            return_dict=return_dict,\n+            return_dict=True,\n             cache_position=cache_position,\n             **kwargs,\n         )"
        },
        {
            "sha": "1b4cfea5b66554410808094dab775007129e1fb9",
            "filename": "src/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 7,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/481b953170ca66f7999b1d448cfd2a814dd28c35/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/481b953170ca66f7999b1d448cfd2a814dd28c35/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py?ref=481b953170ca66f7999b1d448cfd2a814dd28c35",
            "patch": "@@ -1525,7 +1525,6 @@ def forward(\n         use_cache: Optional[bool] = None,\n         output_attentions: Optional[bool] = None,\n         output_hidden_states: Optional[bool] = None,\n-        return_dict: Optional[bool] = None,\n         pixel_values: Optional[torch.Tensor] = None,\n         pixel_values_videos: Optional[torch.FloatTensor] = None,\n         image_grid_thw: Optional[torch.LongTensor] = None,\n@@ -1588,7 +1587,6 @@ def forward(\n         output_hidden_states = (\n             output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n         )\n-        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n \n         outputs = self.model(\n             input_ids=input_ids,\n@@ -1604,7 +1602,7 @@ def forward(\n             use_cache=use_cache,\n             output_attentions=output_attentions,\n             output_hidden_states=output_hidden_states,\n-            return_dict=return_dict,\n+            return_dict=True,\n             cache_position=cache_position,\n             **kwargs,\n         )\n@@ -1616,10 +1614,6 @@ def forward(\n         if labels is not None:\n             loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size)\n \n-        if not return_dict:\n-            output = (logits,) + outputs[1:]\n-            return (loss,) + output if loss is not None else output\n-\n         return Qwen2_5_VLCausalLMOutputWithPast(\n             loss=loss,\n             logits=logits,"
        },
        {
            "sha": "f293f5c769cf06a9b1b6d26dd3de5622c63c9f7a",
            "filename": "src/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 7,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/481b953170ca66f7999b1d448cfd2a814dd28c35/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/481b953170ca66f7999b1d448cfd2a814dd28c35/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py?ref=481b953170ca66f7999b1d448cfd2a814dd28c35",
            "patch": "@@ -770,7 +770,6 @@ def forward(\n         use_cache: Optional[bool] = None,\n         output_attentions: Optional[bool] = None,\n         output_hidden_states: Optional[bool] = None,\n-        return_dict: Optional[bool] = None,\n         pixel_values: Optional[torch.Tensor] = None,\n         pixel_values_videos: Optional[torch.FloatTensor] = None,\n         image_grid_thw: Optional[torch.LongTensor] = None,\n@@ -833,7 +832,6 @@ def forward(\n         output_hidden_states = (\n             output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n         )\n-        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n \n         outputs = self.model(\n             input_ids=input_ids,\n@@ -849,7 +847,7 @@ def forward(\n             use_cache=use_cache,\n             output_attentions=output_attentions,\n             output_hidden_states=output_hidden_states,\n-            return_dict=return_dict,\n+            return_dict=True,\n             cache_position=cache_position,\n             **kwargs,\n         )\n@@ -861,10 +859,6 @@ def forward(\n         if labels is not None:\n             loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size)\n \n-        if not return_dict:\n-            output = (logits,) + outputs[1:]\n-            return (loss,) + output if loss is not None else output\n-\n         return Qwen2_5_VLCausalLMOutputWithPast(\n             loss=loss,\n             logits=logits,"
        },
        {
            "sha": "a995d064b5299efbe4a4f4b80d77100f484baecc",
            "filename": "src/transformers/models/qwen2_vl/modeling_qwen2_vl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/481b953170ca66f7999b1d448cfd2a814dd28c35/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/481b953170ca66f7999b1d448cfd2a814dd28c35/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py?ref=481b953170ca66f7999b1d448cfd2a814dd28c35",
            "patch": "@@ -1409,7 +1409,6 @@ def forward(\n         use_cache: Optional[bool] = None,\n         output_attentions: Optional[bool] = None,\n         output_hidden_states: Optional[bool] = None,\n-        return_dict: Optional[bool] = None,\n         pixel_values: Optional[torch.Tensor] = None,\n         pixel_values_videos: Optional[torch.FloatTensor] = None,\n         image_grid_thw: Optional[torch.LongTensor] = None,\n@@ -1469,7 +1468,6 @@ def forward(\n         output_hidden_states = (\n             output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n         )\n-        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n \n         outputs = self.model(\n             input_ids=input_ids,\n@@ -1484,7 +1482,7 @@ def forward(\n             use_cache=use_cache,\n             output_attentions=output_attentions,\n             output_hidden_states=output_hidden_states,\n-            return_dict=return_dict,\n+            return_dict=True,\n             cache_position=cache_position,\n             **kwargs,\n         )"
        }
    ],
    "stats": {
        "total": 31,
        "additions": 5,
        "deletions": 26
    }
}