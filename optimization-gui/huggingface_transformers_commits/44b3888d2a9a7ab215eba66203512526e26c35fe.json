{
    "author": "Cyrilvallez",
    "message": "Fix order of mask functions when using `and/or_mask_function` (#40753)\n\nfix order",
    "sha": "44b3888d2a9a7ab215eba66203512526e26c35fe",
    "files": [
        {
            "sha": "1899a6de8af8f8b42144d540801e1abd603b93c1",
            "filename": "src/transformers/masking_utils.py",
            "status": "modified",
            "additions": 26,
            "deletions": 20,
            "changes": 46,
            "blob_url": "https://github.com/huggingface/transformers/blob/44b3888d2a9a7ab215eba66203512526e26c35fe/src%2Ftransformers%2Fmasking_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/44b3888d2a9a7ab215eba66203512526e26c35fe/src%2Ftransformers%2Fmasking_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmasking_utils.py?ref=44b3888d2a9a7ab215eba66203512526e26c35fe",
            "patch": "@@ -799,14 +799,11 @@ def create_causal_mask(\n     if _is_torch_xpu_available:\n         allow_is_causal_skip = True\n     else:\n-        allow_is_causal_skip = not past_key_values.is_compileable if past_key_values is not None else True\n-\n-    # If we detected packing format\n-    if packed_sequence_mask is not None and _is_torch_greater_or_equal_than_2_6:\n-        mask_factory_function = and_masks(mask_factory_function, packed_sequence_mask_function(packed_sequence_mask))\n-        allow_is_causal_skip = False\n+        allow_is_causal_skip = not getattr(past_key_values, \"is_compileable\", False)\n \n     # Allow slight deviations from causal mask\n+    # Note that it is very important to apply this before any other deviations of the mask (such as packed sequence mask,\n+    # padding mask, etc) as the resulting mask may otherwise not be correct!\n     if or_mask_function is not None:\n         if not _is_torch_greater_or_equal_than_2_6:\n             raise ValueError(\"Using `or_mask_function` or `and_mask_function` arguments require torch>=2.6\")\n@@ -818,6 +815,11 @@ def create_causal_mask(\n         mask_factory_function = and_masks(mask_factory_function, and_mask_function)\n         allow_is_causal_skip = False\n \n+    # If we detected packing format\n+    if packed_sequence_mask is not None and _is_torch_greater_or_equal_than_2_6:\n+        mask_factory_function = and_masks(mask_factory_function, packed_sequence_mask_function(packed_sequence_mask))\n+        allow_is_causal_skip = False\n+\n     # We now create the mask\n     causal_mask = mask_interface(\n         batch_size=batch_size,\n@@ -893,14 +895,11 @@ def create_sliding_window_causal_mask(\n \n     # Do not allow skip if we are compiling (this is to match BC)\n     # TODO: cyril -> probably revisit and remove this, but a lot of tests rely on it\n-    allow_is_causal_skip = not past_key_values.is_compileable if past_key_values is not None else True\n-\n-    # If we detected packing format\n-    if packed_sequence_mask is not None and _is_torch_greater_or_equal_than_2_6:\n-        mask_factory_function = and_masks(mask_factory_function, packed_sequence_mask_function(packed_sequence_mask))\n-        allow_is_causal_skip = False\n+    allow_is_causal_skip = not getattr(past_key_values, \"is_compileable\", False)\n \n-    # Allow slight deviations from sliding causal mask\n+    # Allow slight deviations from causal mask\n+    # Note that it is very important to apply this before any other deviations of the mask (such as packed sequence mask,\n+    # padding mask, etc) as the resulting mask may otherwise not be correct!\n     if or_mask_function is not None:\n         if not _is_torch_greater_or_equal_than_2_6:\n             raise ValueError(\"Using `or_mask_function` or `and_mask_function` arguments require torch>=2.6\")\n@@ -912,6 +911,11 @@ def create_sliding_window_causal_mask(\n         mask_factory_function = and_masks(mask_factory_function, and_mask_function)\n         allow_is_causal_skip = False\n \n+    # If we detected packing format\n+    if packed_sequence_mask is not None and _is_torch_greater_or_equal_than_2_6:\n+        mask_factory_function = and_masks(mask_factory_function, packed_sequence_mask_function(packed_sequence_mask))\n+        allow_is_causal_skip = False\n+\n     # We now create the mask\n     causal_mask = mask_interface(\n         batch_size=batch_size,\n@@ -1013,14 +1017,11 @@ def create_chunked_causal_mask(\n \n     # Do not allow skip if we are compiling (this is to match BC)\n     # TODO: cyril -> probably revisit and remove this, but a lot of tests rely on it\n-    allow_is_causal_skip = not past_key_values.is_compileable if past_key_values is not None else True\n-\n-    # If we detected packing format\n-    if packed_sequence_mask is not None and _is_torch_greater_or_equal_than_2_6:\n-        mask_factory_function = and_masks(mask_factory_function, packed_sequence_mask_function(packed_sequence_mask))\n-        allow_is_causal_skip = False\n+    allow_is_causal_skip = not getattr(past_key_values, \"is_compileable\", False)\n \n-    # Allow slight deviations from chunked causal mask\n+    # Allow slight deviations from causal mask\n+    # Note that it is very important to apply this before any other deviations of the mask (such as packed sequence mask,\n+    # padding mask, etc) as the resulting mask may otherwise not be correct!\n     if or_mask_function is not None:\n         if not _is_torch_greater_or_equal_than_2_6:\n             raise ValueError(\"Using `or_mask_function` or `and_mask_function` arguments require torch>=2.6\")\n@@ -1032,6 +1033,11 @@ def create_chunked_causal_mask(\n         mask_factory_function = and_masks(mask_factory_function, and_mask_function)\n         allow_is_causal_skip = False\n \n+    # If we detected packing format\n+    if packed_sequence_mask is not None and _is_torch_greater_or_equal_than_2_6:\n+        mask_factory_function = and_masks(mask_factory_function, packed_sequence_mask_function(packed_sequence_mask))\n+        allow_is_causal_skip = False\n+\n     # We now create the mask\n     causal_mask = mask_interface(\n         batch_size=batch_size,"
        }
    ],
    "stats": {
        "total": 46,
        "additions": 26,
        "deletions": 20
    }
}