{
    "author": "gante",
    "message": "Gemma2: eager attention by default (#32865)",
    "sha": "975b988bfe6e7ebb47390cd9a1556c6888804883",
    "files": [
        {
            "sha": "398ba4abefe11e1b44cdfbcbdf9c21b1d774fb75",
            "filename": "src/transformers/models/gemma2/modeling_gemma2.py",
            "status": "modified",
            "additions": 14,
            "deletions": 0,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/975b988bfe6e7ebb47390cd9a1556c6888804883/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/975b988bfe6e7ebb47390cd9a1556c6888804883/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py?ref=975b988bfe6e7ebb47390cd9a1556c6888804883",
            "patch": "@@ -656,6 +656,20 @@ def _init_weights(self, module):\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n \n+    @classmethod\n+    def _check_and_enable_sdpa(cls, config, hard_check_only: bool = False):\n+        \"\"\"\n+        Overloads `PreTrainedModel._check_and_enable_sdpa` so as to DISABLE torch SDPA by default on Gemma2 models.\n+        SDPA reduces the model performance on Gemma2 because of the logits softcapping.\n+        \"\"\"\n+        config = super()._check_and_enable_sdpa(config, hard_check_only=hard_check_only)\n+\n+        # if using the default path -> swap sdpa by eager\n+        if not hard_check_only and config._attn_implementation == \"sdpa\":\n+            config._attn_implementation = \"eager\"\n+\n+        return config\n+\n \n _CONFIG_FOR_DOC = \"Gemma2Config\"\n "
        },
        {
            "sha": "433bcd5da9a45fcc514db6858d63c8fc12cff9c4",
            "filename": "tests/models/gemma2/test_modeling_gemma2.py",
            "status": "modified",
            "additions": 19,
            "deletions": 2,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/975b988bfe6e7ebb47390cd9a1556c6888804883/tests%2Fmodels%2Fgemma2%2Ftest_modeling_gemma2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/975b988bfe6e7ebb47390cd9a1556c6888804883/tests%2Fmodels%2Fgemma2%2Ftest_modeling_gemma2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgemma2%2Ftest_modeling_gemma2.py?ref=975b988bfe6e7ebb47390cd9a1556c6888804883",
            "patch": "@@ -81,14 +81,31 @@ def setUp(self):\n         self.model_tester = Gemma2ModelTester(self)\n         self.config_tester = ConfigTester(self, config_class=Gemma2Config, hidden_size=37)\n \n-    @unittest.skip(\"Eager and SDPA do not produce the same outputs, thus this test fails\")\n+    @unittest.skip(\"Failing because of unique cache (HybridCache)\")\n     def test_model_outputs_equivalence(self, **kwargs):\n         pass\n \n-    @unittest.skip(\"Gemma2's outputs are expected to be different\")\n+    @unittest.skip(\"Gemma2's eager attn/sdpa attn outputs are expected to be different\")\n     def test_eager_matches_sdpa_inference(self):\n         pass\n \n+    @unittest.skip(\"Gemma2's eager attn/sdpa attn outputs are expected to be different\")\n+    def test_sdpa_equivalence(self):\n+        pass\n+\n+    def test_eager_attention_loaded_by_default(self):\n+        \"\"\"Gemma 2 + SDPA = inferior results, because of the logit softcapping. Eager is the default.\"\"\"\n+        config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n+\n+        # Usually we enable SDPA by default, but not for Gemma2\n+        model = Gemma2Model(config)\n+        self.assertTrue(model.config._attn_implementation == \"eager\")\n+\n+        # We can still force SDPA\n+        config._attn_implementation = \"sdpa\"\n+        model = Gemma2Model(config)\n+        self.assertTrue(model.config._attn_implementation == \"sdpa\")\n+\n \n @slow\n @require_torch_gpu"
        }
    ],
    "stats": {
        "total": 35,
        "additions": 33,
        "deletions": 2
    }
}