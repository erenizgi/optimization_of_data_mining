{
    "author": "3outeille",
    "message": "test tensor parallel: make tests for dense model more robust (#41968)\n\n* make test forward and backward more robust\n\n* refactor compile part of test tensor parallel\n\n* linting\n\n* pass rank around instead of calling it over and over\n\n* Run slow v2 (#41914)\n\n* Super\n\n* Super\n\n* Super\n\n* Super\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>\n\n* Fix `detectron2` installation in docker files (#41975)\n\n* detectron2 - part 1\n\n* detectron2 - part 2\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>\n\n* Fix `autoawq[kernels]` installation in quantization docker file (#41978)\n\nfix autoawq[kernels]\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>\n\n* add support for saving encoder only so any parakeet model can be loaded for inference (#41969)\n\n* add support for saving encoder only so any decoder model can be loaded\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* use convolution_bias\n\n* convert modular\n\n* convolution_bias in convertion script\n\n---------\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\nCo-authored-by: Eustache Le Bihan <eulebihan@gmail.com>\nCo-authored-by: eustlb <94853470+eustlb@users.noreply.github.com>\n\n---------\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\nCo-authored-by: Yih-Dar <2521628+ydshieh@users.noreply.github.com>\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Eustache Le Bihan <eulebihan@gmail.com>\nCo-authored-by: eustlb <94853470+eustlb@users.noreply.github.com>",
    "sha": "b433ec8b505118a6c89ac92bdb82a643860e94f7",
    "files": [
        {
            "sha": "05ec7e1a8d07c1c5d413b340a3ce1e83fb5813ec",
            "filename": "tests/tensor_parallel/test_tensor_parallel.py",
            "status": "modified",
            "additions": 169,
            "deletions": 72,
            "changes": 241,
            "blob_url": "https://github.com/huggingface/transformers/blob/b433ec8b505118a6c89ac92bdb82a643860e94f7/tests%2Ftensor_parallel%2Ftest_tensor_parallel.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b433ec8b505118a6c89ac92bdb82a643860e94f7/tests%2Ftensor_parallel%2Ftest_tensor_parallel.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftensor_parallel%2Ftest_tensor_parallel.py?ref=b433ec8b505118a6c89ac92bdb82a643860e94f7",
            "patch": "@@ -15,16 +15,16 @@\n # Run all tests: RUN_SLOW=1 pytest -v tests/tensor_parallel/test_tensor_parallel.py\n # Run specific config: RUN_SLOW=1 pytest -v tests/tensor_parallel/test_tensor_parallel.py -k \"2Proc\"\n # Run multiple configs: RUN_SLOW=1 pytest -v tests/tensor_parallel/test_tensor_parallel.py -k \"2Proc or 4Proc\"\n-# Run spefic test: RUN_SLOW=1 pytest -v tests/tensor_parallel/test_tensor_parallel.py::TestTensorParallel2Proc::test_model_forward\n-\n+# Run spefic test: RUN_SLOW=1 pytest -v tests/tensor_parallel/test_tensor_parallel.py::TestTensorParallel2Proc::test_model_dense_forward_train\n+# Run tests with a specific prefix: RUN_SLOW=1 pytest -v tests/tensor_parallel/test_tensor_parallel.py::TestTensorParallel2Proc -k \"forward\"\n import os\n import tempfile\n import warnings\n \n from safetensors import safe_open\n \n from transformers import AutoModelForCausalLM, AutoTokenizer, is_torch_available\n-from transformers.integrations.tensor_parallel import get_packed_weights, repack_weights\n+from transformers.integrations.tensor_parallel import get_packed_weights, get_tensor_shard, repack_weights\n from transformers.testing_utils import (\n     TestCasePlus,\n     backend_device_count,\n@@ -37,6 +37,7 @@\n \n if is_torch_available():\n     import torch\n+    import torch.distributed as dist\n     import torch.multiprocessing as mp\n \n \n@@ -53,14 +54,14 @@ def setup_dist_env(rank, world_size, port):\n \n     if torch.cuda.is_available():\n         torch.cuda.set_device(rank)\n-        torch.distributed.init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n+        dist.init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n     else:\n-        torch.distributed.init_process_group(backend=\"gloo\", rank=rank, world_size=world_size)\n+        dist.init_process_group(backend=\"gloo\", rank=rank, world_size=world_size)\n \n     func(rank, *func_args, **func_kwargs)\n \n-    torch.distributed.barrier()\n-    torch.distributed.destroy_process_group()\n+    dist.barrier()\n+    dist.destroy_process_group()\n \n \n def init_distributed(tp: int):\n@@ -211,95 +212,169 @@ def test_tp_plan_none_handling(self):\n \n \n # ====== TEST FUNCTIONS ======\n-def _test_model_forward_impl(rank):\n-    \"\"\"Implementation of test_model_forward for distributed execution.\"\"\"\n+def _test_model_dense_forward_impl(rank, mode):\n+    \"\"\"Implementation for comparing TP and non-TP model outputs.\"\"\"\n     model_id = \"JackFram/llama-68m\"\n \n-    int(os.environ[\"RANK\"])\n-    int(os.environ[\"WORLD_SIZE\"])\n-    model = AutoModelForCausalLM.from_pretrained(model_id, dtype=\"auto\", tp_plan=\"auto\")\n-    torch.distributed.barrier()\n-\n-    has_dtensor = 0\n-    for name, parameter in model.named_parameters():\n-        if isinstance(parameter.data, torch.distributed.tensor.DTensor):\n-            has_dtensor = 1\n-            break\n-\n-    assert has_dtensor == 1, \"TP model must has DTensor\"\n+    # Ensure same random seed for reproducibility\n+    torch.manual_seed(0)\n \n+    # Load tokenizer and prepare inputs - same for both models\n     tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=False)\n     prompt = \"Can I help\"\n+    inputs = tokenizer(prompt, return_tensors=\"pt\")\n+\n+    # Load TP model first to determine device\n+    model_tp = AutoModelForCausalLM.from_pretrained(model_id, dtype=\"auto\", tp_plan=\"auto\")\n+    dist.barrier()\n+    if mode == \"eval\":\n+        model_tp.eval()\n+    else:\n+        model_tp.train()\n+\n+    # Load non-TP model and move to same device as TP model\n+    device = model_tp.device\n+    model = AutoModelForCausalLM.from_pretrained(model_id, dtype=\"auto\")\n+    model = model.to(device)\n+\n+    if mode == \"eval\":\n+        model.eval()\n+    else:\n+        model.train()\n+\n+    # Prepare inputs on the same device\n+    input_ids = inputs.input_ids.to(device)\n+\n+    # Run forward pass on both models\n+    with torch.no_grad():\n+        # Non-TP model output\n+        outputs = model(input_ids)\n+        logits = outputs.logits\n+\n+        # TP model output\n+        outputs_tp = model_tp(input_ids)\n+        logits_tp = outputs_tp.logits\n \n-    inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n-    outputs = model(inputs)\n+    # Compare outputs - they should match\n+    assert torch.allclose(logits, logits_tp, atol=1e-5, rtol=1e-5), (\n+        f\"TP and non-TP model outputs differ. Max diff: {(logits - logits_tp).abs().max().item()} | Min diff: {(logits - logits_tp).abs().min().item()}\"\n+    )\n \n-    next_token_logits = outputs[0][:, -1, :]\n-    next_token = torch.argmax(next_token_logits, dim=-1)\n-    response = tokenizer.decode(next_token)\n-    assert response == \"with\"\n-    print(\"response:\", response)\n-    torch.distributed.barrier()\n+    dist.barrier()\n \n \n-def _test_model_backward_pass_impl(rank):\n-    \"\"\"Implementation of test_model_backward_pass for distributed execution.\"\"\"\n+def _test_model_dense_backward_pass_impl(rank):\n+    \"\"\"Implementation for comparing TP and non-TP model backward passes.\"\"\"\n     model_id = \"JackFram/llama-68m\"\n \n-    model = AutoModelForCausalLM.from_pretrained(model_id, dtype=torch.float32, tp_plan=\"auto\")\n-    torch.distributed.barrier()\n+    torch.manual_seed(0)\n \n-    # Dummy forward and backward pass\n-    # Note that loss.backward() will fail if there is a bug in the TP implementation\n-    inputs = torch.randint(0, model.config.vocab_size, (2, 10), device=model.device)\n-    labels = torch.randint(0, model.config.vocab_size, (2, 10), device=model.device)\n-    loss = model(inputs, labels=labels).loss\n+    model_tp = AutoModelForCausalLM.from_pretrained(model_id, dtype=torch.float32, tp_plan=\"auto\")\n+    dist.barrier()\n+    model_tp.train()\n+\n+    device = model_tp.device\n+    model = AutoModelForCausalLM.from_pretrained(model_id, dtype=torch.float32)\n+    model = model.to(device)\n+    model.train()\n+\n+    batch_size, seq_length = 2, 10\n+    torch.manual_seed(42)  # Different seed for inputs to ensure they're deterministic\n+    input_ids = torch.randint(0, model.config.vocab_size, (batch_size, seq_length), device=device)\n+    labels = torch.randint(0, model.config.vocab_size, (batch_size, seq_length), device=device)\n+\n+    outputs = model(input_ids, labels=labels)\n+    loss = outputs.loss\n     loss.backward()\n \n-    torch.distributed.barrier()\n+    outputs_tp = model_tp(input_ids, labels=labels)\n+    loss_tp = outputs_tp.loss\n+    loss_tp.backward()\n \n+    assert torch.allclose(loss, loss_tp, atol=1e-5, rtol=1e-5), (\n+        f\"TP and non-TP model losses differ. Non-TP loss: {loss.item()}, TP loss: {loss_tp.item()}, Diff: {(loss - loss_tp).abs().item()}\"\n+    )\n \n-def _test_model_generate_impl(rank):\n-    \"\"\"Implementation of test_model_generate for distributed execution.\"\"\"\n-    model_id = \"JackFram/llama-68m\"\n+    # Compare gradients for matching parameters\n+    # Note: TP model may have sharded parameters (DTensors), so we slice the reference gradient to match\n+    for (name, param), (name_tp, param_tp) in zip(model.named_parameters(), model_tp.named_parameters()):\n+        if param.grad is not None and param_tp.grad is not None:\n+            grad = param.grad\n+            grad_tp = param_tp.grad\n \n-    int(os.environ[\"RANK\"])\n-    int(os.environ[\"WORLD_SIZE\"])\n+            if isinstance(param_tp.data, dist.tensor.DTensor):\n+                placement = param_tp.data.placements[0]\n+                if hasattr(placement, \"dim\") and placement.dim is not None:\n+                    grad_shard = get_tensor_shard(grad, grad, param_tp.data.device_mesh, rank, placement.dim)\n+                else:\n+                    grad_shard = grad\n+            else:\n+                grad_shard = grad\n \n-    model = AutoModelForCausalLM.from_pretrained(model_id, dtype=\"auto\", tp_plan=\"auto\")\n-    torch.distributed.barrier()\n+            grad_tp_local = grad_tp.to_local() if isinstance(grad_tp, dist.tensor.DTensor) else grad_tp\n \n-    model.forward = torch.compile(model.forward)\n+            assert torch.allclose(grad_shard.cpu(), grad_tp_local.cpu(), atol=1e-5, rtol=1e-5), (\n+                f\"Gradients differ for parameter {name}. Max diff: {(grad_shard.cpu() - grad_tp_local.cpu()).abs().max().item()} | Min diff: {(grad_shard.cpu() - grad_tp_local.cpu()).abs().min().item()}\"\n+            )\n \n-    has_dtensor = 0\n-    for name, parameter in model.named_parameters():\n-        if isinstance(parameter.data, torch.distributed.tensor.DTensor):\n-            has_dtensor = 1\n-            break\n+    dist.barrier()\n \n-    assert has_dtensor == 1, \"TP model must has DTensor\"\n \n-    tokenizer = AutoTokenizer.from_pretrained(model_id)\n+def _test_model_dense_forward_compile_impl(rank, mode):\n+    \"\"\"Implementation for comparing TP and non-TP model outputs with torch.compile.\"\"\"\n+    model_id = \"JackFram/llama-68m\"\n+\n+    torch.manual_seed(0)\n+\n+    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=False)\n     prompt = \"Can I help\"\n+    inputs = tokenizer(prompt, return_tensors=\"pt\")\n \n-    inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n-    outputs = model.generate(inputs, max_new_tokens=10, cache_implementation=\"static\")\n+    model_tp = AutoModelForCausalLM.from_pretrained(model_id, dtype=\"auto\", tp_plan=\"auto\")\n+    dist.barrier()\n+    if mode == \"eval\":\n+        model_tp.eval()\n+    else:\n+        model_tp.train()\n \n-    output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n-    assert output_text[0].startswith(prompt), f\"Expected output to start with '{prompt}', got '{output_text[0]}'\"\n+    device = model_tp.device\n+    model = AutoModelForCausalLM.from_pretrained(model_id, dtype=\"auto\")\n+    model = model.to(device)\n \n-    torch.distributed.barrier()\n+    if mode == \"eval\":\n+        model.eval()\n+    else:\n+        model.train()\n \n+    # Compile both models\n+    model.forward = torch.compile(model.forward)\n+    model_tp.forward = torch.compile(model_tp.forward)\n+\n+    input_ids = inputs.input_ids.to(device)\n+\n+    with torch.no_grad():\n+        outputs = model(input_ids)\n+        logits = outputs.logits\n+\n+        outputs_tp = model_tp(input_ids)\n+        logits_tp = outputs_tp.logits\n+\n+    assert torch.allclose(logits, logits_tp, atol=1e-5, rtol=1e-5), (\n+        f\"TP and non-TP model outputs differ. Max diff: {(logits - logits_tp).abs().max().item()} | Min diff: {(logits - logits_tp).abs().min().item()}\"\n+    )\n+\n+    dist.barrier()\n \n-def _test_model_save_impl(rank, tmp_dir, is_torchrun):\n+\n+def _test_model_dense_save_impl(rank, tmp_dir):\n     \"\"\"Implementation of test_model_save for distributed execution.\"\"\"\n     model_id = \"JackFram/llama-68m\"\n-    kwargs = {}\n \n-    if os.environ.get(\"RANK\", None) is not None:\n-        kwargs[\"tp_plan\"] = \"auto\"\n+    if dist.is_initialized():\n+        kwargs = {\"tp_plan\": \"auto\"}\n         result_dir = f\"{tmp_dir}/tp\"\n     else:\n+        kwargs = {}\n         result_dir = f\"{tmp_dir}/nontp\"\n \n     model = AutoModelForCausalLM.from_pretrained(model_id, **kwargs)\n@@ -312,46 +387,68 @@ class TestTensorParallelBase(TestCasePlus):\n     nproc_per_node = None\n \n     @require_torch_multi_accelerator\n-    def test_model_forward(self):\n+    def test_model_dense_forward_eval(self):\n+        \"\"\"Test that TP and non-TP models produce the same outputs in eval mode.\"\"\"\n+        if self.nproc_per_node is None:\n+            self.skipTest(\"nproc_per_node not set\")\n+        if backend_device_count(torch_device) < self.nproc_per_node:\n+            self.skipTest(f\"Need at least {self.nproc_per_node} devices, have {backend_device_count(torch_device)}\")\n+\n+        init_distributed(tp=self.nproc_per_node)(_test_model_dense_forward_impl)(\"eval\")\n+\n+    @require_torch_multi_accelerator\n+    def test_model_dense_forward_train(self):\n+        \"\"\"Test that TP and non-TP models produce the same outputs in train mode.\"\"\"\n+        if self.nproc_per_node is None:\n+            self.skipTest(\"nproc_per_node not set\")\n+        if backend_device_count(torch_device) < self.nproc_per_node:\n+            self.skipTest(f\"Need at least {self.nproc_per_node} devices, have {backend_device_count(torch_device)}\")\n+\n+        init_distributed(tp=self.nproc_per_node)(_test_model_dense_forward_impl)(\"train\")\n+\n+    @require_torch_multi_accelerator\n+    def test_model_dense_backward_pass(self):\n         if self.nproc_per_node is None:\n             self.skipTest(\"nproc_per_node not set\")\n         if backend_device_count(torch_device) < self.nproc_per_node:\n             self.skipTest(f\"Need at least {self.nproc_per_node} devices, have {backend_device_count(torch_device)}\")\n \n-        init_distributed(tp=self.nproc_per_node)(_test_model_forward_impl)()\n+        init_distributed(tp=self.nproc_per_node)(_test_model_dense_backward_pass_impl)()\n \n     @require_torch_multi_accelerator\n-    def test_model_backward_pass(self):\n+    def test_model_dense_forward_compile_eval(self):\n+        \"\"\"Test that TP and non-TP models produce the same outputs with torch.compile in eval mode.\"\"\"\n         if self.nproc_per_node is None:\n             self.skipTest(\"nproc_per_node not set\")\n         if backend_device_count(torch_device) < self.nproc_per_node:\n             self.skipTest(f\"Need at least {self.nproc_per_node} devices, have {backend_device_count(torch_device)}\")\n \n-        init_distributed(tp=self.nproc_per_node)(_test_model_backward_pass_impl)()\n+        init_distributed(tp=self.nproc_per_node)(_test_model_dense_forward_compile_impl)(\"eval\")\n \n     @require_torch_multi_accelerator\n-    def test_model_generate(self):\n+    def test_model_dense_forward_compile_train(self):\n+        \"\"\"Test that TP and non-TP models produce the same outputs with torch.compile in train mode.\"\"\"\n         if self.nproc_per_node is None:\n             self.skipTest(\"nproc_per_node not set\")\n         if backend_device_count(torch_device) < self.nproc_per_node:\n             self.skipTest(f\"Need at least {self.nproc_per_node} devices, have {backend_device_count(torch_device)}\")\n \n-        init_distributed(tp=self.nproc_per_node)(_test_model_generate_impl)()\n+        init_distributed(tp=self.nproc_per_node)(_test_model_dense_forward_compile_impl)(\"train\")\n \n     @require_huggingface_hub_greater_or_equal(\"0.31.4\")\n     @require_torch_multi_accelerator\n-    def test_model_save(self):\n+    def test_model_dense_save(self):\n         if self.nproc_per_node is None:\n             self.skipTest(\"nproc_per_node not set\")\n         if backend_device_count(torch_device) < self.nproc_per_node:\n             self.skipTest(f\"Need at least {self.nproc_per_node} devices, have {backend_device_count(torch_device)}\")\n \n         with tempfile.TemporaryDirectory() as tmp_dir:\n             # First run with TP (distributed)\n-            init_distributed(tp=self.nproc_per_node)(_test_model_save_impl)(tmp_dir, True)\n+            init_distributed(tp=self.nproc_per_node)(_test_model_dense_save_impl)(tmp_dir)\n \n             # Then run without TP (non-distributed)\n-            _test_model_save_impl(0, tmp_dir, False)\n+            _test_model_dense_save_impl(0, tmp_dir)\n \n             non_tp_model_path = os.path.join(tmp_dir, \"nontp\")\n             tp_model_path = os.path.join(tmp_dir, \"tp\")"
        }
    ],
    "stats": {
        "total": 241,
        "additions": 169,
        "deletions": 72
    }
}