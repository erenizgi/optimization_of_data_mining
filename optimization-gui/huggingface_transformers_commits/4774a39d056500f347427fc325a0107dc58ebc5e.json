{
    "author": "Yann-CV",
    "message": "Add ImageProcessorFast to BiT processor (#37180)\n\n* Add ImageProcessorFast to BiT processor\n\n* propose a fast processor and add tests\n\n* all tests pass except one\n\n* run make\n\n* remove useless print\n\n* use same test as clip\n\n* apply make\n\n* Update src/transformers/models/bit/image_processing_bit_fast.py\n\nCo-authored-by: Yoni Gozlan <74535834+yonigozlan@users.noreply.github.com>\n\n* Update setup.py\n\nCo-authored-by: Yoni Gozlan <74535834+yonigozlan@users.noreply.github.com>\n\n* Update src/transformers/models/bit/image_processing_bit_fast.py\n\nCo-authored-by: Yoni Gozlan <74535834+yonigozlan@users.noreply.github.com>\n\n* apply review comment\n\n---------\n\nCo-authored-by: Yoni Gozlan <74535834+yonigozlan@users.noreply.github.com>",
    "sha": "4774a39d056500f347427fc325a0107dc58ebc5e",
    "files": [
        {
            "sha": "0813b67af9e992adb46f8a8484d1413f47d8a472",
            "filename": "docs/source/en/model_doc/bit.md",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/4774a39d056500f347427fc325a0107dc58ebc5e/docs%2Fsource%2Fen%2Fmodel_doc%2Fbit.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/4774a39d056500f347427fc325a0107dc58ebc5e/docs%2Fsource%2Fen%2Fmodel_doc%2Fbit.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fbit.md?ref=4774a39d056500f347427fc325a0107dc58ebc5e",
            "patch": "@@ -58,6 +58,11 @@ If you're interested in submitting a resource to be included here, please feel f\n [[autodoc]] BitImageProcessor\n     - preprocess\n \n+## BitImageProcessorFast\n+\n+[[autodoc]] BitImageProcessorFast\n+    - preprocess\n+\n ## BitModel\n \n [[autodoc]] BitModel"
        },
        {
            "sha": "ab0a7a4c685ab343592610dd23c8eb1179e898d5",
            "filename": "docs/source/ja/model_doc/bit.md",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/4774a39d056500f347427fc325a0107dc58ebc5e/docs%2Fsource%2Fja%2Fmodel_doc%2Fbit.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/4774a39d056500f347427fc325a0107dc58ebc5e/docs%2Fsource%2Fja%2Fmodel_doc%2Fbit.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fbit.md?ref=4774a39d056500f347427fc325a0107dc58ebc5e",
            "patch": "@@ -54,6 +54,11 @@ BiT を始めるのに役立つ公式 Hugging Face およびコミュニティ (\n [[autodoc]] BitImageProcessor\n     - preprocess\n \n+## BitImageProcessorFast\n+\n+[[autodoc]] BitImageProcessorFast\n+    - preprocess\n+\n ## BitModel\n \n [[autodoc]] BitModel"
        },
        {
            "sha": "5e8dae8326ef4d2fbbead28547ef5a1de47e0ef7",
            "filename": "src/transformers/models/auto/image_processing_auto.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/4774a39d056500f347427fc325a0107dc58ebc5e/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4774a39d056500f347427fc325a0107dc58ebc5e/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py?ref=4774a39d056500f347427fc325a0107dc58ebc5e",
            "patch": "@@ -59,7 +59,7 @@\n             (\"align\", (\"EfficientNetImageProcessor\",)),\n             (\"aria\", (\"AriaImageProcessor\",)),\n             (\"beit\", (\"BeitImageProcessor\",)),\n-            (\"bit\", (\"BitImageProcessor\",)),\n+            (\"bit\", (\"BitImageProcessor\", \"BitImageProcessorFast\")),\n             (\"blip\", (\"BlipImageProcessor\", \"BlipImageProcessorFast\")),\n             (\"blip-2\", (\"BlipImageProcessor\", \"BlipImageProcessorFast\")),\n             (\"bridgetower\", (\"BridgeTowerImageProcessor\",)),\n@@ -79,21 +79,21 @@\n             (\"deta\", (\"DetaImageProcessor\",)),\n             (\"detr\", (\"DetrImageProcessor\", \"DetrImageProcessorFast\")),\n             (\"dinat\", (\"ViTImageProcessor\", \"ViTImageProcessorFast\")),\n-            (\"dinov2\", (\"BitImageProcessor\",)),\n+            (\"dinov2\", (\"BitImageProcessor\", \"BitImageProcessorFast\")),\n             (\"donut-swin\", (\"DonutImageProcessor\", \"DonutImageProcessorFast\")),\n             (\"dpt\", (\"DPTImageProcessor\",)),\n             (\"efficientformer\", (\"EfficientFormerImageProcessor\",)),\n             (\"efficientnet\", (\"EfficientNetImageProcessor\",)),\n             (\"flava\", (\"FlavaImageProcessor\", \"FlavaImageProcessorFast\")),\n-            (\"focalnet\", (\"BitImageProcessor\",)),\n+            (\"focalnet\", (\"BitImageProcessor\", \"BitImageProcessorFast\")),\n             (\"fuyu\", (\"FuyuImageProcessor\",)),\n             (\"gemma3\", (\"Gemma3ImageProcessor\", \"Gemma3ImageProcessorFast\")),\n             (\"git\", (\"CLIPImageProcessor\", \"CLIPImageProcessorFast\")),\n             (\"glpn\", (\"GLPNImageProcessor\",)),\n             (\"got_ocr2\", (\"GotOcr2ImageProcessor\", \"GotOcr2ImageProcessorFast\")),\n             (\"grounding-dino\", (\"GroundingDinoImageProcessor\",)),\n             (\"groupvit\", (\"CLIPImageProcessor\", \"CLIPImageProcessorFast\")),\n-            (\"hiera\", (\"BitImageProcessor\",)),\n+            (\"hiera\", (\"BitImageProcessor\", \"BitImageProcessorFast\")),\n             (\"idefics\", (\"IdeficsImageProcessor\",)),\n             (\"idefics2\", (\"Idefics2ImageProcessor\",)),\n             (\"idefics3\", (\"Idefics3ImageProcessor\",)),"
        },
        {
            "sha": "edfeb4dbe75bb53c011719d6c550b245ac814b28",
            "filename": "src/transformers/models/bit/__init__.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/4774a39d056500f347427fc325a0107dc58ebc5e/src%2Ftransformers%2Fmodels%2Fbit%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4774a39d056500f347427fc325a0107dc58ebc5e/src%2Ftransformers%2Fmodels%2Fbit%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbit%2F__init__.py?ref=4774a39d056500f347427fc325a0107dc58ebc5e",
            "patch": "@@ -20,6 +20,7 @@\n if TYPE_CHECKING:\n     from .configuration_bit import *\n     from .image_processing_bit import *\n+    from .image_processing_bit_fast import *\n     from .modeling_bit import *\n else:\n     import sys"
        },
        {
            "sha": "19b3fbfd32b3ae77fd6bda46587ac07bf4319515",
            "filename": "src/transformers/models/bit/image_processing_bit_fast.py",
            "status": "added",
            "additions": 44,
            "deletions": 0,
            "changes": 44,
            "blob_url": "https://github.com/huggingface/transformers/blob/4774a39d056500f347427fc325a0107dc58ebc5e/src%2Ftransformers%2Fmodels%2Fbit%2Fimage_processing_bit_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4774a39d056500f347427fc325a0107dc58ebc5e/src%2Ftransformers%2Fmodels%2Fbit%2Fimage_processing_bit_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbit%2Fimage_processing_bit_fast.py?ref=4774a39d056500f347427fc325a0107dc58ebc5e",
            "patch": "@@ -0,0 +1,44 @@\n+# coding=utf-8\n+# Copyright 2025 The HuggingFace Inc. team. All rights reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\"\"\"Fast Image processor class for BiT.\"\"\"\n+\n+from ...image_processing_utils_fast import (\n+    BASE_IMAGE_PROCESSOR_FAST_DOCSTRING,\n+    BaseImageProcessorFast,\n+)\n+from ...image_utils import OPENAI_CLIP_MEAN, OPENAI_CLIP_STD, PILImageResampling\n+from ...utils import add_start_docstrings\n+\n+\n+@add_start_docstrings(\n+    \"Constructs a fast Bit image processor.\",\n+    BASE_IMAGE_PROCESSOR_FAST_DOCSTRING,\n+)\n+class BitImageProcessorFast(BaseImageProcessorFast):\n+    resample = PILImageResampling.BICUBIC\n+    image_mean = OPENAI_CLIP_MEAN\n+    image_std = OPENAI_CLIP_STD\n+    size = {\"shortest_edge\": 224}\n+    default_to_square = False\n+    crop_size = {\"height\": 224, \"width\": 224}\n+    rescale_factor = 1 / 255\n+    do_resize = True\n+    do_center_crop = True\n+    do_rescale = True\n+    do_normalize = True\n+    do_convert_rgb = True\n+\n+\n+__all__ = [\"BitImageProcessorFast\"]"
        },
        {
            "sha": "8ad72a4c5b948c416eb1a99d031342d8e99e5a17",
            "filename": "tests/models/bit/test_image_processing_bit.py",
            "status": "added",
            "additions": 128,
            "deletions": 0,
            "changes": 128,
            "blob_url": "https://github.com/huggingface/transformers/blob/4774a39d056500f347427fc325a0107dc58ebc5e/tests%2Fmodels%2Fbit%2Ftest_image_processing_bit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4774a39d056500f347427fc325a0107dc58ebc5e/tests%2Fmodels%2Fbit%2Ftest_image_processing_bit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbit%2Ftest_image_processing_bit.py?ref=4774a39d056500f347427fc325a0107dc58ebc5e",
            "patch": "@@ -0,0 +1,128 @@\n+# coding=utf-8\n+# Copyright 2024 The HuggingFace Inc. team. All rights reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import unittest\n+\n+from transformers.testing_utils import require_torch, require_vision\n+from transformers.utils import is_torchvision_available, is_vision_available\n+\n+from ...test_image_processing_common import ImageProcessingTestMixin, prepare_image_inputs\n+\n+\n+if is_vision_available():\n+    from transformers import BitImageProcessor\n+\n+    if is_torchvision_available():\n+        from transformers import BitImageProcessorFast\n+\n+\n+class BitImageProcessingTester:\n+    def __init__(\n+        self,\n+        parent,\n+        batch_size=7,\n+        num_channels=3,\n+        image_size=18,\n+        min_resolution=30,\n+        max_resolution=400,\n+        do_resize=True,\n+        size=None,\n+        do_center_crop=True,\n+        crop_size=None,\n+        do_normalize=True,\n+        image_mean=[0.48145466, 0.4578275, 0.40821073],\n+        image_std=[0.26862954, 0.26130258, 0.27577711],\n+        do_convert_rgb=True,\n+    ):\n+        super().__init__()\n+        size = size if size is not None else {\"shortest_edge\": 20}\n+        crop_size = crop_size if crop_size is not None else {\"height\": 18, \"width\": 18}\n+        self.parent = parent\n+        self.batch_size = batch_size\n+        self.num_channels = num_channels\n+        self.image_size = image_size\n+        self.min_resolution = min_resolution\n+        self.max_resolution = max_resolution\n+        self.do_resize = do_resize\n+        self.size = size\n+        self.do_center_crop = do_center_crop\n+        self.crop_size = crop_size\n+        self.do_normalize = do_normalize\n+        self.image_mean = image_mean\n+        self.image_std = image_std\n+        self.do_convert_rgb = do_convert_rgb\n+\n+    def prepare_image_processor_dict(self):\n+        return {\n+            \"do_resize\": self.do_resize,\n+            \"size\": self.size,\n+            \"do_center_crop\": self.do_center_crop,\n+            \"crop_size\": self.crop_size,\n+            \"do_normalize\": self.do_normalize,\n+            \"image_mean\": self.image_mean,\n+            \"image_std\": self.image_std,\n+            \"do_convert_rgb\": self.do_convert_rgb,\n+        }\n+\n+    def expected_output_image_shape(self, images):\n+        return self.num_channels, self.crop_size[\"height\"], self.crop_size[\"width\"]\n+\n+    def prepare_image_inputs(self, equal_resolution=False, numpify=False, torchify=False):\n+        return prepare_image_inputs(\n+            batch_size=self.batch_size,\n+            num_channels=self.num_channels,\n+            min_resolution=self.min_resolution,\n+            max_resolution=self.max_resolution,\n+            equal_resolution=equal_resolution,\n+            numpify=numpify,\n+            torchify=torchify,\n+        )\n+\n+\n+@require_torch\n+@require_vision\n+class BitImageProcessingTest(ImageProcessingTestMixin, unittest.TestCase):\n+    image_processing_class = BitImageProcessor if is_vision_available() else None\n+    fast_image_processing_class = BitImageProcessorFast if is_torchvision_available() else None\n+\n+    def setUp(self):\n+        super().setUp()\n+        self.image_processor_tester = BitImageProcessingTester(self)\n+\n+    @property\n+    def image_processor_dict(self):\n+        return self.image_processor_tester.prepare_image_processor_dict()\n+\n+    def test_image_processor_properties(self):\n+        for image_processing_class in self.image_processor_list:\n+            image_processing = image_processing_class(**self.image_processor_dict)\n+            self.assertTrue(hasattr(image_processing, \"do_resize\"))\n+            self.assertTrue(hasattr(image_processing, \"size\"))\n+            self.assertTrue(hasattr(image_processing, \"do_center_crop\"))\n+            self.assertTrue(hasattr(image_processing, \"center_crop\"))\n+            self.assertTrue(hasattr(image_processing, \"do_normalize\"))\n+            self.assertTrue(hasattr(image_processing, \"image_mean\"))\n+            self.assertTrue(hasattr(image_processing, \"image_std\"))\n+            self.assertTrue(hasattr(image_processing, \"do_convert_rgb\"))\n+\n+    def test_image_processor_from_dict_with_kwargs(self):\n+        for image_processing_class in self.image_processor_list:\n+            image_processor = image_processing_class.from_dict(self.image_processor_dict)\n+            self.assertEqual(image_processor.size, {\"shortest_edge\": 20})\n+            self.assertEqual(image_processor.crop_size, {\"height\": 18, \"width\": 18})\n+\n+            image_processor = image_processing_class.from_dict(self.image_processor_dict, size=42, crop_size=84)\n+            self.assertEqual(image_processor.size, {\"shortest_edge\": 42})\n+            self.assertEqual(image_processor.crop_size, {\"height\": 84, \"width\": 84})"
        }
    ],
    "stats": {
        "total": 191,
        "additions": 187,
        "deletions": 4
    }
}