{
    "author": "BenjaminBossan",
    "message": "TST PEFT integration tests with pipeline generate (#39086)\n\nSome PEFT integration tests involving text generation pipelines were\nfailing since #38129 because the base model is too small to generate\nlonger sequences. Setting max_new_tokens fixes this.",
    "sha": "0c35280e58ea4a297c1a62f22523bc454301276b",
    "files": [
        {
            "sha": "523137d53a47c08eaa2452bb7cb3fb320cd6c8fd",
            "filename": "tests/peft_integration/test_peft_integration.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/0c35280e58ea4a297c1a62f22523bc454301276b/tests%2Fpeft_integration%2Ftest_peft_integration.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0c35280e58ea4a297c1a62f22523bc454301276b/tests%2Fpeft_integration%2Ftest_peft_integration.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpeft_integration%2Ftest_peft_integration.py?ref=0c35280e58ea4a297c1a62f22523bc454301276b",
            "patch": "@@ -531,7 +531,7 @@ def test_peft_pipeline(self):\n             peft_params = list(peft_pipe.model.parameters())\n             base_params = list(base_pipe.model.parameters())\n             self.assertNotEqual(len(peft_params), len(base_params))  # Assert we actually loaded the adapter too\n-            _ = peft_pipe(\"Hello\")\n+            _ = peft_pipe(\"Hello\", max_new_tokens=20)\n \n     def test_peft_add_adapter_with_state_dict(self):\n         \"\"\"\n@@ -858,4 +858,4 @@ def test_peft_pipeline_no_warning(self):\n             )\n \n             # Generate text to verify pipeline works\n-            _ = lora_generator(text)\n+            _ = lora_generator(text, max_new_tokens=20)"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}