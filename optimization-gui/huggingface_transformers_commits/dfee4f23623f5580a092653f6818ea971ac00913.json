{
    "author": "bruno-hays",
    "message": "Update WhisperTokenizer Doc: Timestamps and Previous Tokens Behaviour (#33390)\n\n* added doc explaining behaviour regarding tokens timestamps and previous tokens\r\n\r\n* copied changes to faster tokenizer\r\n\r\n---------\r\n\r\nCo-authored-by: Bruno Hays <bruno.hays@illuin.tech>",
    "sha": "dfee4f23623f5580a092653f6818ea971ac00913",
    "files": [
        {
            "sha": "823a11c3ec99715755c0da2128cab332648049c9",
            "filename": "src/transformers/models/whisper/tokenization_whisper.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/dfee4f23623f5580a092653f6818ea971ac00913/src%2Ftransformers%2Fmodels%2Fwhisper%2Ftokenization_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dfee4f23623f5580a092653f6818ea971ac00913/src%2Ftransformers%2Fmodels%2Fwhisper%2Ftokenization_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Ftokenization_whisper.py?ref=dfee4f23623f5580a092653f6818ea971ac00913",
            "patch": "@@ -673,13 +673,15 @@ def decode(\n             token_ids (`Union[int, List[int], np.ndarray, torch.Tensor, tf.Tensor]`):\n                 List of tokenized input ids. Can be obtained using the `__call__` method.\n             skip_special_tokens (`bool`, *optional*, defaults to `False`):\n-                Whether or not to remove special tokens in the decoding.\n+                Whether or not to remove special tokens in the decoding. Will remove the previous tokens (pre-prompt)\n+                if present.\n             clean_up_tokenization_spaces (`bool`, *optional*):\n                 Whether or not to clean up the tokenization spaces. If `None`, will default to\n                 `self.clean_up_tokenization_spaces` (available in the `tokenizer_config`).\n             output_offsets (`bool`, *optional*, defaults to `False`):\n                 Whether or not to output the offsets of the tokens. This should only be set if the model predicted\n-                timestamps.\n+                timestamps. If there are previous tokens (pre-prompt) to decode, they will only appear in the decoded\n+                text if they contain timestamp tokens.\n             time_precision (`float`, *optional*, defaults to 0.02):\n                 The time ratio to convert from token to time.\n             decode_with_timestamps (`bool`, *optional*, defaults to `False`):"
        },
        {
            "sha": "11c2b465671193104b7e02d311656a884f9497e7",
            "filename": "src/transformers/models/whisper/tokenization_whisper_fast.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/dfee4f23623f5580a092653f6818ea971ac00913/src%2Ftransformers%2Fmodels%2Fwhisper%2Ftokenization_whisper_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dfee4f23623f5580a092653f6818ea971ac00913/src%2Ftransformers%2Fmodels%2Fwhisper%2Ftokenization_whisper_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Ftokenization_whisper_fast.py?ref=dfee4f23623f5580a092653f6818ea971ac00913",
            "patch": "@@ -319,13 +319,15 @@ def decode(\n             token_ids (`Union[int, List[int], np.ndarray, torch.Tensor, tf.Tensor]`):\n                 List of tokenized input ids. Can be obtained using the `__call__` method.\n             skip_special_tokens (`bool`, *optional*, defaults to `False`):\n-                Whether or not to remove special tokens in the decoding.\n+                Whether or not to remove special tokens in the decoding. Will remove the previous tokens (pre-prompt)\n+                if present.\n             clean_up_tokenization_spaces (`bool`, *optional*):\n                 Whether or not to clean up the tokenization spaces. If `None`, will default to\n                 `self.clean_up_tokenization_spaces` (available in the `tokenizer_config`).\n             output_offsets (`bool`, *optional*, defaults to `False`):\n                 Whether or not to output the offsets of the tokens. This should only be set if the model predicted\n-                timestamps.\n+                timestamps. If there are previous tokens (pre-prompt) to decode, they will only appear in the decoded\n+                text if they contain timestamp tokens.\n             time_precision (`float`, *optional*, defaults to 0.02):\n                 The time ratio to convert from token to time.\n             decode_with_timestamps (`bool`, *optional*, defaults to `False`):"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 8,
        "deletions": 4
    }
}