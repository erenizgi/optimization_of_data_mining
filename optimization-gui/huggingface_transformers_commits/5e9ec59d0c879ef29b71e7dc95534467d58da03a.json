{
    "author": "Cyrilvallez",
    "message": "Fix modular consistency (#40883)\n\n* reapply modular\n\n* add missing one",
    "sha": "5e9ec59d0c879ef29b71e7dc95534467d58da03a",
    "files": [
        {
            "sha": "d3bc3b6b044f3beb7c1c40cd1ccd55fb5a2d5c77",
            "filename": "src/transformers/models/qwen3_vl/modeling_qwen3_vl.py",
            "status": "modified",
            "additions": 5,
            "deletions": 7,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/5e9ec59d0c879ef29b71e7dc95534467d58da03a/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodeling_qwen3_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5e9ec59d0c879ef29b71e7dc95534467d58da03a/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodeling_qwen3_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodeling_qwen3_vl.py?ref=5e9ec59d0c879ef29b71e7dc95534467d58da03a",
            "patch": "@@ -528,8 +528,7 @@ def forward(\n class Qwen3VLModelOutputWithPast(ModelOutput):\n     r\"\"\"\n     past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-        Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-        `(batch_size, num_heads, sequence_length, embed_size_per_head)`)\n+        It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n         Contains pre-computed hidden-states (key and values in the self-attention blocks) that can be used (see\n         `past_key_values` input) to speed up sequential decoding.\n@@ -538,7 +537,7 @@ class Qwen3VLModelOutputWithPast(ModelOutput):\n     \"\"\"\n \n     last_hidden_state: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[list[torch.FloatTensor]] = None\n+    past_key_values: Optional[Cache] = None\n     hidden_states: Optional[tuple[torch.FloatTensor]] = None\n     attentions: Optional[tuple[torch.FloatTensor]] = None\n     rope_deltas: Optional[torch.LongTensor] = None\n@@ -1255,8 +1254,7 @@ class Qwen3VLCausalLMOutputWithPast(ModelOutput):\n     logits (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`):\n         Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n     past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-        Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-        `(batch_size, num_heads, sequence_length, embed_size_per_head)`)\n+        It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n         Contains pre-computed hidden-states (key and values in the self-attention blocks) that can be used (see\n         `past_key_values` input) to speed up sequential decoding.\n@@ -1266,7 +1264,7 @@ class Qwen3VLCausalLMOutputWithPast(ModelOutput):\n \n     loss: Optional[torch.FloatTensor] = None\n     logits: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[list[torch.FloatTensor]] = None\n+    past_key_values: Optional[Cache] = None\n     hidden_states: Optional[tuple[torch.FloatTensor]] = None\n     attentions: Optional[tuple[torch.FloatTensor]] = None\n     rope_deltas: Optional[torch.LongTensor] = None\n@@ -1322,7 +1320,7 @@ def forward(\n         input_ids: torch.LongTensor = None,\n         attention_mask: Optional[torch.Tensor] = None,\n         position_ids: Optional[torch.LongTensor] = None,\n-        past_key_values: Optional[list[torch.FloatTensor]] = None,\n+        past_key_values: Optional[Cache] = None,\n         inputs_embeds: Optional[torch.FloatTensor] = None,\n         labels: Optional[torch.LongTensor] = None,\n         pixel_values: Optional[torch.Tensor] = None,"
        },
        {
            "sha": "7a2fa852739e633e74d1e2528347b706b3d9d557",
            "filename": "src/transformers/models/qwen3_vl/modular_qwen3_vl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/5e9ec59d0c879ef29b71e7dc95534467d58da03a/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodular_qwen3_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5e9ec59d0c879ef29b71e7dc95534467d58da03a/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodular_qwen3_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_vl%2Fmodular_qwen3_vl.py?ref=5e9ec59d0c879ef29b71e7dc95534467d58da03a",
            "patch": "@@ -1156,7 +1156,7 @@ def forward(\n         input_ids: torch.LongTensor = None,\n         attention_mask: Optional[torch.Tensor] = None,\n         position_ids: Optional[torch.LongTensor] = None,\n-        past_key_values: Optional[list[torch.FloatTensor]] = None,\n+        past_key_values: Optional[Cache] = None,\n         inputs_embeds: Optional[torch.FloatTensor] = None,\n         labels: Optional[torch.LongTensor] = None,\n         pixel_values: Optional[torch.Tensor] = None,"
        },
        {
            "sha": "08c647ea50ac013badb9e21a4ecbf94286a35ea8",
            "filename": "src/transformers/models/qwen3_vl_moe/modeling_qwen3_vl_moe.py",
            "status": "modified",
            "additions": 7,
            "deletions": 9,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/5e9ec59d0c879ef29b71e7dc95534467d58da03a/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodeling_qwen3_vl_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5e9ec59d0c879ef29b71e7dc95534467d58da03a/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodeling_qwen3_vl_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_vl_moe%2Fmodeling_qwen3_vl_moe.py?ref=5e9ec59d0c879ef29b71e7dc95534467d58da03a",
            "patch": "@@ -348,7 +348,7 @@ def forward(\n         position_embeddings: tuple[torch.Tensor, torch.Tensor],\n         attention_mask: Optional[torch.Tensor] = None,\n         position_ids: Optional[torch.LongTensor] = None,\n-        past_key_values: Optional[tuple[torch.Tensor]] = None,\n+        past_key_values: Optional[Cache] = None,\n         cache_position: Optional[torch.LongTensor] = None,\n         **kwargs: Unpack[FlashAttentionKwargs],\n     ) -> torch.FloatTensor:\n@@ -366,7 +366,7 @@ def forward(\n             use_cache (`bool`, *optional*):\n                 If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding\n                 (see `past_key_values`).\n-            past_key_values (`Tuple(torch.FloatTensor)`, *optional*): cached past key and value projection states\n+            past_key_values (`Cache`, *optional*): cached past key and value projection states\n             cache_position (`torch.LongTensor` of shape `(sequence_length)`, *optional*):\n                 Indices depicting the position of the input sequence tokens in the sequence.\n             position_embeddings (`tuple[torch.FloatTensor, torch.FloatTensor]`, *optional*):\n@@ -1011,8 +1011,7 @@ def _deepstack_process(\n class Qwen3VLMoeModelOutputWithPast(ModelOutput):\n     r\"\"\"\n     past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-        Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-        `(batch_size, num_heads, sequence_length, embed_size_per_head)`)\n+        It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n         Contains pre-computed hidden-states (key and values in the self-attention blocks) that can be used (see\n         `past_key_values` input) to speed up sequential decoding.\n@@ -1021,7 +1020,7 @@ class Qwen3VLMoeModelOutputWithPast(ModelOutput):\n     \"\"\"\n \n     last_hidden_state: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[list[torch.FloatTensor]] = None\n+    past_key_values: Optional[Cache] = None\n     hidden_states: Optional[tuple[torch.FloatTensor]] = None\n     attentions: Optional[tuple[torch.FloatTensor]] = None\n     rope_deltas: Optional[torch.LongTensor] = None\n@@ -1398,8 +1397,7 @@ class Qwen3VLMoeCausalLMOutputWithPast(ModelOutput):\n     logits (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`):\n         Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n     past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-        Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-        `(batch_size, num_heads, sequence_length, embed_size_per_head)`)\n+        It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n         Contains pre-computed hidden-states (key and values in the self-attention blocks) that can be used (see\n         `past_key_values` input) to speed up sequential decoding.\n@@ -1409,7 +1407,7 @@ class Qwen3VLMoeCausalLMOutputWithPast(ModelOutput):\n \n     loss: Optional[torch.FloatTensor] = None\n     logits: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[list[torch.FloatTensor]] = None\n+    past_key_values: Optional[Cache] = None\n     hidden_states: Optional[tuple[torch.FloatTensor]] = None\n     attentions: Optional[tuple[torch.FloatTensor]] = None\n     rope_deltas: Optional[torch.LongTensor] = None\n@@ -1465,7 +1463,7 @@ def forward(\n         input_ids: torch.LongTensor = None,\n         attention_mask: Optional[torch.Tensor] = None,\n         position_ids: Optional[torch.LongTensor] = None,\n-        past_key_values: Optional[list[torch.FloatTensor]] = None,\n+        past_key_values: Optional[Cache] = None,\n         inputs_embeds: Optional[torch.FloatTensor] = None,\n         labels: Optional[torch.LongTensor] = None,\n         pixel_values: Optional[torch.Tensor] = None,"
        }
    ],
    "stats": {
        "total": 30,
        "additions": 13,
        "deletions": 17
    }
}