{
    "author": "ahadnagy",
    "message": "Add AMD test expectations to DETR model (#39539)\n\n* Add AMD test expectations to DETR model\n\n* Fix baseline expectation\n\n* Address review comments\n\n* Make formatting a bit more consistent",
    "sha": "ef99537f37f640d1cc945b8ffa0af948e31ece01",
    "files": [
        {
            "sha": "38bc54b3017b5c7ae497d1c9354d88be1334ae33",
            "filename": "tests/models/detr/test_modeling_detr.py",
            "status": "modified",
            "additions": 103,
            "deletions": 35,
            "changes": 138,
            "blob_url": "https://github.com/huggingface/transformers/blob/ef99537f37f640d1cc945b8ffa0af948e31ece01/tests%2Fmodels%2Fdetr%2Ftest_modeling_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ef99537f37f640d1cc945b8ffa0af948e31ece01/tests%2Fmodels%2Fdetr%2Ftest_modeling_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdetr%2Ftest_modeling_detr.py?ref=ef99537f37f640d1cc945b8ffa0af948e31ece01",
            "patch": "@@ -18,7 +18,7 @@\n import unittest\n \n from transformers import DetrConfig, ResNetConfig, is_torch_available, is_vision_available\n-from transformers.testing_utils import require_timm, require_torch, require_vision, slow, torch_device\n+from transformers.testing_utils import Expectations, require_timm, require_torch, require_vision, slow, torch_device\n from transformers.utils import cached_property\n \n from ...test_configuration_common import ConfigTester\n@@ -585,13 +585,23 @@ def test_inference_no_head(self):\n \n         expected_shape = torch.Size((1, 100, 256))\n         assert outputs.last_hidden_state.shape == expected_shape\n-        expected_slice = torch.tensor(\n-            [\n-                [0.0622, -0.5142, -0.4034],\n-                [-0.7628, -0.4935, -1.7153],\n-                [-0.4751, -0.6386, -0.7818],\n-            ]\n-        ).to(torch_device)\n+        expected_slices = Expectations(\n+            {\n+                (None, None):\n+                    [\n+                        [0.0622, -0.5142, -0.4034],\n+                        [-0.7628, -0.4935, -1.7153],\n+                        [-0.4751, -0.6386, -0.7818],\n+                    ],\n+                (\"rocm\", (9, 5)):\n+                    [\n+                        [ 0.0616, -0.5146, -0.4032],\n+                        [-0.7629, -0.4934, -1.7153],\n+                        [-0.4768, -0.6403, -0.7826],\n+                    ],\n+            }\n+        )  # fmt: skip\n+        expected_slice = torch.tensor(expected_slices.get_expectation(), device=torch_device)\n         torch.testing.assert_close(outputs.last_hidden_state[0, :3, :3], expected_slice, rtol=2e-4, atol=2e-4)\n \n     def test_inference_object_detection_head(self):\n@@ -609,13 +619,23 @@ def test_inference_object_detection_head(self):\n         # verify outputs\n         expected_shape_logits = torch.Size((1, model.config.num_queries, model.config.num_labels + 1))\n         self.assertEqual(outputs.logits.shape, expected_shape_logits)\n-        expected_slice_logits = torch.tensor(\n-            [\n-                [-19.1211, -0.0881, -11.0188],\n-                [-17.3641, -1.8045, -14.0229],\n-                [-20.0415, -0.5833, -11.1005],\n-            ]\n-        ).to(torch_device)\n+        expected_slices = Expectations(\n+            {\n+                (None, None):\n+                    [\n+                        [-19.1211, -0.0881, -11.0188],\n+                        [-17.3641, -1.8045, -14.0229],\n+                        [-20.0415, -0.5833, -11.1005],\n+                    ],\n+                (\"rocm\", (9, 5)):\n+                    [\n+                        [-19.1194,  -0.0893, -11.0154],\n+                        [-17.3640,  -1.8035, -14.0219],\n+                        [-20.0461,  -0.5837, -11.1060],\n+                    ],\n+            }\n+        )  # fmt: skip\n+        expected_slice_logits = torch.tensor(expected_slices.get_expectation(), device=torch_device)\n         torch.testing.assert_close(outputs.logits[0, :3, :3], expected_slice_logits, rtol=2e-4, atol=2e-4)\n \n         expected_shape_boxes = torch.Size((1, model.config.num_queries, 4))\n@@ -657,27 +677,65 @@ def test_inference_panoptic_segmentation_head(self):\n         # verify outputs\n         expected_shape_logits = torch.Size((1, model.config.num_queries, model.config.num_labels + 1))\n         self.assertEqual(outputs.logits.shape, expected_shape_logits)\n-        expected_slice_logits = torch.tensor(\n-            [\n-                [-18.1523, -1.7592, -13.5019],\n-                [-16.8866, -1.4139, -14.1025],\n-                [-17.5735, -2.5090, -11.8666],\n-            ]\n-        ).to(torch_device)\n+        expected_slices = Expectations(\n+            {\n+                (None, None):\n+                    [\n+                        [-18.1523, -1.7592, -13.5019],\n+                        [-16.8866, -1.4139, -14.1025],\n+                        [-17.5735, -2.5090, -11.8666],\n+                    ],\n+                (\"rocm\", (9, 5)):\n+                    [\n+                        [-18.1565,  -1.7568, -13.5029],\n+                        [-16.8888,  -1.4138, -14.1028],\n+                        [-17.5709,  -2.5080, -11.8654],\n+                    ],\n+            }\n+        )  # fmt: skip\n+        expected_slice_logits = torch.tensor(expected_slices.get_expectation(), device=torch_device)\n         torch.testing.assert_close(outputs.logits[0, :3, :3], expected_slice_logits, rtol=2e-4, atol=2e-4)\n \n         expected_shape_boxes = torch.Size((1, model.config.num_queries, 4))\n         self.assertEqual(outputs.pred_boxes.shape, expected_shape_boxes)\n-        expected_slice_boxes = torch.tensor(\n-            [[0.5344, 0.1790, 0.9284], [0.4421, 0.0571, 0.0875], [0.6632, 0.6886, 0.1015]]\n-        ).to(torch_device)\n+        expected_slices = Expectations(\n+            {\n+                (None, None):\n+                    [\n+                        [0.5344, 0.1790, 0.9284],\n+                        [0.4421, 0.0571, 0.0875],\n+                        [0.6632, 0.6886, 0.1015]\n+                    ],\n+                (\"rocm\", (9, 5)):\n+                    [\n+                        [0.5344, 0.1789, 0.9285],\n+                        [0.4420, 0.0572, 0.0875],\n+                        [0.6630, 0.6887, 0.1017],\n+                    ],\n+            }\n+        )  # fmt: skip\n+        expected_slice_boxes = torch.tensor(expected_slices.get_expectation(), device=torch_device)\n         torch.testing.assert_close(outputs.pred_boxes[0, :3, :3], expected_slice_boxes, rtol=2e-4, atol=2e-4)\n \n         expected_shape_masks = torch.Size((1, model.config.num_queries, 200, 267))\n         self.assertEqual(outputs.pred_masks.shape, expected_shape_masks)\n-        expected_slice_masks = torch.tensor(\n-            [[-7.8408, -11.0104, -12.1279], [-12.0299, -16.6498, -17.9806], [-14.8995, -19.9940, -20.5646]]\n-        ).to(torch_device)\n+        expected_slices = Expectations(\n+            {\n+                (None, None):\n+                    [\n+                        [-7.8408, -11.0104, -12.1279],\n+                        [-12.0299, -16.6498, -17.9806],\n+                        [-14.8995, -19.9940, -20.5646],\n+                    ],\n+                (\"rocm\", (9, 5)):\n+                    [\n+                        [ -7.7558, -10.8789, -11.9798],\n+                        [-11.8882, -16.4330, -17.7452],\n+                        [-14.7317, -19.7384, -20.3005],\n+                    ],\n+            }\n+        )  # fmt: skip\n+        expected_slice_masks = torch.tensor(expected_slices.get_expectation(), device=torch_device)\n         torch.testing.assert_close(outputs.pred_masks[0, 0, :3, :3], expected_slice_masks, rtol=2e-3, atol=2e-3)\n \n         # verify postprocessing\n@@ -731,11 +789,21 @@ def test_inference_no_head(self):\n \n         expected_shape = torch.Size((1, 100, 256))\n         assert outputs.last_hidden_state.shape == expected_shape\n-        expected_slice = torch.tensor(\n-            [\n-                [0.0622, -0.5142, -0.4034],\n-                [-0.7628, -0.4935, -1.7153],\n-                [-0.4751, -0.6386, -0.7818],\n-            ]\n-        ).to(torch_device)\n+        expected_slices = Expectations(\n+            {\n+                (None, None):\n+                    [\n+                        [0.0622, -0.5142, -0.4034],\n+                        [-0.7628, -0.4935, -1.7153],\n+                        [-0.4751, -0.6386, -0.7818],\n+                    ],\n+                (\"rocm\", (9, 5)):\n+                    [\n+                        [ 0.0616, -0.5146, -0.4032],\n+                        [-0.7629, -0.4934, -1.7153],\n+                        [-0.4768, -0.6403, -0.7826]\n+                    ],\n+            }\n+        )  # fmt: skip\n+        expected_slice = torch.tensor(expected_slices.get_expectation(), device=torch_device)\n         torch.testing.assert_close(outputs.last_hidden_state[0, :3, :3], expected_slice, rtol=1e-4, atol=1e-4)"
        }
    ],
    "stats": {
        "total": 138,
        "additions": 103,
        "deletions": 35
    }
}