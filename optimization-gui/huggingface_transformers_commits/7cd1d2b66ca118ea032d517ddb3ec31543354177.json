{
    "author": "zucchini-nlp",
    "message": "[v5] Delete legacy chat template saving (#41648)\n\n* delete lagcy chat template saving\n\n* fix tests\n\n* fix qwen audio",
    "sha": "7cd1d2b66ca118ea032d517ddb3ec31543354177",
    "files": [
        {
            "sha": "a70018c6cf2e306231a81aa2a0e82bdb559f4689",
            "filename": "src/transformers/processing_utils.py",
            "status": "modified",
            "additions": 23,
            "deletions": 48,
            "changes": 71,
            "blob_url": "https://github.com/huggingface/transformers/blob/7cd1d2b66ca118ea032d517ddb3ec31543354177/src%2Ftransformers%2Fprocessing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7cd1d2b66ca118ea032d517ddb3ec31543354177/src%2Ftransformers%2Fprocessing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fprocessing_utils.py?ref=7cd1d2b66ca118ea032d517ddb3ec31543354177",
            "patch": "@@ -772,8 +772,6 @@ def save_pretrained(self, save_directory, push_to_hub: bool = False, **kwargs):\n             kwargs (`dict[str, Any]`, *optional*):\n                 Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.\n         \"\"\"\n-        save_jinja_files = kwargs.pop(\"save_jinja_files\", True)\n-\n         os.makedirs(save_directory, exist_ok=True)\n \n         if push_to_hub:\n@@ -796,8 +794,7 @@ def save_pretrained(self, save_directory, push_to_hub: bool = False, **kwargs):\n \n             # Save the tokenizer in its own vocab file. The other attributes are saved as part of `processor_config.json`\n             if attribute_name == \"tokenizer\":\n-                # Propagate save_jinja_files to tokenizer to ensure we don't get conflicts\n-                attribute.save_pretrained(save_directory, save_jinja_files=save_jinja_files)\n+                attribute.save_pretrained(save_directory)\n             elif attribute._auto_class is not None:\n                 custom_object_save(attribute, save_directory, config=attribute)\n \n@@ -812,47 +809,29 @@ def save_pretrained(self, save_directory, push_to_hub: bool = False, **kwargs):\n         # plus we save chat_template in its own file\n         output_processor_file = os.path.join(save_directory, PROCESSOR_NAME)\n         output_chat_template_file_jinja = os.path.join(save_directory, CHAT_TEMPLATE_FILE)\n-        output_chat_template_file_legacy = os.path.join(save_directory, LEGACY_PROCESSOR_CHAT_TEMPLATE_FILE)\n         chat_template_dir = os.path.join(save_directory, CHAT_TEMPLATE_DIR)\n \n         # Save `chat_template` in its own file. We can't get it from `processor_dict` as we popped it in `to_dict`\n         # to avoid serializing chat template in json config file. So let's get it from `self` directly\n-        if self.chat_template is not None:\n-            is_single_template = isinstance(self.chat_template, str)\n-            if save_jinja_files and is_single_template:\n-                # New format for single templates is to save them as chat_template.jinja\n-                with open(output_chat_template_file_jinja, \"w\", encoding=\"utf-8\") as f:\n-                    f.write(self.chat_template)\n-                logger.info(f\"chat template saved in {output_chat_template_file_jinja}\")\n-            elif save_jinja_files and not is_single_template:\n-                # New format for multiple templates is to save the default as chat_template.jinja\n-                # and the other templates in the chat_templates/ directory\n-                for template_name, template in self.chat_template.items():\n-                    if template_name == \"default\":\n-                        with open(output_chat_template_file_jinja, \"w\", encoding=\"utf-8\") as f:\n-                            f.write(self.chat_template[\"default\"])\n-                        logger.info(f\"chat template saved in {output_chat_template_file_jinja}\")\n-                    else:\n-                        os.makedirs(chat_template_dir, exist_ok=True)\n-                        template_filepath = os.path.join(chat_template_dir, f\"{template_name}.jinja\")\n-                        with open(template_filepath, \"w\", encoding=\"utf-8\") as f:\n-                            f.write(template)\n-                        logger.info(f\"chat template saved in {template_filepath}\")\n-            elif is_single_template:\n-                # Legacy format for single templates: Put them in chat_template.json\n-                chat_template_json_string = (\n-                    json.dumps({\"chat_template\": self.chat_template}, indent=2, sort_keys=True) + \"\\n\"\n-                )\n-                with open(output_chat_template_file_legacy, \"w\", encoding=\"utf-8\") as writer:\n-                    writer.write(chat_template_json_string)\n-                logger.info(f\"chat template saved in {output_chat_template_file_legacy}\")\n-            elif self.chat_template is not None:\n-                # At this point we have multiple templates in the legacy format, which is not supported\n-                # chat template dicts are saved to chat_template.json as lists of dicts with fixed key names.\n-                raise ValueError(\n-                    \"Multiple chat templates are not supported in the legacy format. Please save them as \"\n-                    \"separate files using the `save_jinja_files` argument.\"\n-                )\n+        if isinstance(self.chat_template, str):\n+            # New format for single templates is to save them as chat_template.jinja\n+            with open(output_chat_template_file_jinja, \"w\", encoding=\"utf-8\") as f:\n+                f.write(self.chat_template)\n+            logger.info(f\"chat template saved in {output_chat_template_file_jinja}\")\n+        elif isinstance(self.chat_template, dict):\n+            # New format for multiple templates is to save the default as chat_template.jinja\n+            # and the other templates in the chat_templates/ directory\n+            for template_name, template in self.chat_template.items():\n+                if template_name == \"default\":\n+                    with open(output_chat_template_file_jinja, \"w\", encoding=\"utf-8\") as f:\n+                        f.write(self.chat_template[\"default\"])\n+                    logger.info(f\"chat template saved in {output_chat_template_file_jinja}\")\n+                else:\n+                    os.makedirs(chat_template_dir, exist_ok=True)\n+                    template_filepath = os.path.join(chat_template_dir, f\"{template_name}.jinja\")\n+                    with open(template_filepath, \"w\", encoding=\"utf-8\") as f:\n+                        f.write(template)\n+                    logger.info(f\"chat template saved in {template_filepath}\")\n \n         # Create a unified `preprocessor_config.json` and save all attributes as a composite config, except for tokenizers\n         self.to_json_file(output_processor_file)\n@@ -1066,9 +1045,6 @@ def get_processor_dict(\n         if isinstance(chat_templates, dict) and \"default\" in chat_templates and len(chat_templates) == 1:\n             chat_templates = chat_templates[\"default\"]  # Flatten when we just have a single template/file\n \n-        if chat_templates:\n-            kwargs[\"chat_template\"] = chat_templates\n-\n         # Existing processors on the Hub created before #27761 being merged don't have `processor_config.json` (if not\n         # updated afterward), and we need to keep `from_pretrained` work. So here it fallbacks to the empty dict.\n         # (`cached_file` called using `_raise_exceptions_for_missing_entries=False` to avoid exception)\n@@ -1093,14 +1069,13 @@ def get_processor_dict(\n         else:\n             logger.info(f\"loading configuration file {processor_file} from cache at {resolved_processor_file}\")\n \n-        if \"chat_template\" in processor_dict and processor_dict[\"chat_template\"] is not None:\n+        if processor_dict.get(\"chat_template\") is not None:\n             logger.warning_once(\n                 \"Chat templates should be in a 'chat_template.jinja' file but found key='chat_template' \"\n                 \"in the processor's config. Make sure to move your template to its own file.\"\n             )\n-\n-        if \"chat_template\" in kwargs:\n-            processor_dict[\"chat_template\"] = kwargs.pop(\"chat_template\")\n+        elif chat_templates:\n+            processor_dict[\"chat_template\"] = chat_templates\n \n         # Audio tokenizer needs to load the model checkpoint first, because the saved\n         # json file contains only references to the model path and repo id"
        },
        {
            "sha": "3eae0a6f6878849489e66d6c1d395d3de8bac0be",
            "filename": "src/transformers/tokenization_mistral_common.py",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/7cd1d2b66ca118ea032d517ddb3ec31543354177/src%2Ftransformers%2Ftokenization_mistral_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7cd1d2b66ca118ea032d517ddb3ec31543354177/src%2Ftransformers%2Ftokenization_mistral_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_mistral_common.py?ref=7cd1d2b66ca118ea032d517ddb3ec31543354177",
            "patch": "@@ -1864,8 +1864,6 @@ def save_pretrained(\n         Returns:\n             A tuple of `str`: The files saved.\n         \"\"\"\n-        # `save_jinja_files`` must be skipped to be able to save from a processor\n-        kwargs.pop(\"save_jinja_files\", None)\n         if kwargs:\n             raise ValueError(\n                 f\"Kwargs {list(kwargs.keys())} are not supported by `MistralCommonTokenizer.save_pretrained`.\""
        },
        {
            "sha": "68ec49fa1b87d60b83c7ce8b85c62e33dc0724a4",
            "filename": "src/transformers/tokenization_utils_base.py",
            "status": "modified",
            "additions": 5,
            "deletions": 15,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/7cd1d2b66ca118ea032d517ddb3ec31543354177/src%2Ftransformers%2Ftokenization_utils_base.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7cd1d2b66ca118ea032d517ddb3ec31543354177/src%2Ftransformers%2Ftokenization_utils_base.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_utils_base.py?ref=7cd1d2b66ca118ea032d517ddb3ec31543354177",
            "patch": "@@ -2431,7 +2431,6 @@ def save_chat_templates(\n         save_directory: Union[str, os.PathLike],\n         tokenizer_config: dict,\n         filename_prefix: Optional[str],\n-        save_jinja_files: bool,\n     ):\n         \"\"\"\n         Writes chat templates out to the save directory if we're using the new format, and removes them from\n@@ -2446,15 +2445,15 @@ def save_chat_templates(\n         )\n \n         saved_raw_chat_template_files = []\n-        if save_jinja_files and isinstance(self.chat_template, str):\n+        if isinstance(self.chat_template, str):\n             # New format for single templates is to save them as chat_template.jinja\n             with open(chat_template_file, \"w\", encoding=\"utf-8\") as f:\n                 f.write(self.chat_template)\n             logger.info(f\"chat template saved in {chat_template_file}\")\n             saved_raw_chat_template_files.append(chat_template_file)\n             if \"chat_template\" in tokenizer_config:\n                 tokenizer_config.pop(\"chat_template\")  # To ensure it doesn't somehow end up in the config too\n-        elif save_jinja_files and isinstance(self.chat_template, dict):\n+        elif isinstance(self.chat_template, dict):\n             # New format for multiple templates is to save the default as chat_template.jinja\n             # and the other templates in the chat_templates/ directory\n             for template_name, template in self.chat_template.items():\n@@ -2470,15 +2469,8 @@ def save_chat_templates(\n                         f.write(template)\n                     logger.info(f\"chat template saved in {template_filepath}\")\n                     saved_raw_chat_template_files.append(template_filepath)\n-            if \"chat_template\" in tokenizer_config:\n-                tokenizer_config.pop(\"chat_template\")  # To ensure it doesn't somehow end up in the config too\n-        elif isinstance(self.chat_template, dict):\n-            # Legacy format for multiple templates:\n-            # chat template dicts are saved to the config as lists of dicts with fixed key names.\n-            tokenizer_config[\"chat_template\"] = [{\"name\": k, \"template\": v} for k, v in self.chat_template.items()]\n-        elif self.chat_template is not None:\n-            # Legacy format for single templates: Just make them a key in tokenizer_config.json\n-            tokenizer_config[\"chat_template\"] = self.chat_template\n+        if \"chat_template\" in tokenizer_config:\n+            tokenizer_config.pop(\"chat_template\")  # To ensure it doesn't somehow end up in the config too\n         return tokenizer_config, saved_raw_chat_template_files\n \n     def save_pretrained(\n@@ -2524,8 +2516,6 @@ def save_pretrained(\n         Returns:\n             A tuple of `str`: The files saved.\n         \"\"\"\n-        save_jinja_files = kwargs.pop(\"save_jinja_files\", True)\n-\n         if os.path.isfile(save_directory):\n             logger.error(f\"Provided path ({save_directory}) should be a directory, not a file\")\n             return\n@@ -2563,7 +2553,7 @@ def save_pretrained(\n             tokenizer_config.update(self.extra_special_tokens)\n \n         tokenizer_config, saved_raw_chat_template_files = self.save_chat_templates(\n-            save_directory, tokenizer_config, filename_prefix, save_jinja_files\n+            save_directory, tokenizer_config, filename_prefix\n         )\n         if getattr(self, \"response_schema\", None) is not None:\n             tokenizer_config[\"response_schema\"] = self.response_schema"
        },
        {
            "sha": "e7a66f9520f8fdd288065f6e711618533c5be6c1",
            "filename": "src/transformers/utils/hub.py",
            "status": "modified",
            "additions": 5,
            "deletions": 13,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/7cd1d2b66ca118ea032d517ddb3ec31543354177/src%2Ftransformers%2Futils%2Fhub.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7cd1d2b66ca118ea032d517ddb3ec31543354177/src%2Ftransformers%2Futils%2Fhub.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fhub.py?ref=7cd1d2b66ca118ea032d517ddb3ec31543354177",
            "patch": "@@ -882,10 +882,6 @@ def push_to_hub(\n         ```\n         \"\"\"\n         ignore_metadata_errors = deprecated_kwargs.pop(\"ignore_metadata_errors\", False)\n-        save_jinja_files = deprecated_kwargs.pop(\n-            \"save_jinja_files\", None\n-        )  # TODO: This is only used for testing and should be removed once save_jinja_files becomes the default\n-\n         repo_path_or_name = deprecated_kwargs.pop(\"repo_path_or_name\", None)\n         if repo_path_or_name is not None:\n             # Should use `repo_id` instead of `repo_path_or_name`. When using `repo_path_or_name`, we try to infer\n@@ -931,15 +927,11 @@ def push_to_hub(\n             files_timestamps = self._get_files_timestamps(work_dir)\n \n             # Save all files.\n-            if save_jinja_files:\n-                self.save_pretrained(\n-                    work_dir,\n-                    max_shard_size=max_shard_size,\n-                    safe_serialization=safe_serialization,\n-                    save_jinja_files=True,\n-                )\n-            else:\n-                self.save_pretrained(work_dir, max_shard_size=max_shard_size, safe_serialization=safe_serialization)\n+            self.save_pretrained(\n+                work_dir,\n+                max_shard_size=max_shard_size,\n+                safe_serialization=safe_serialization,\n+            )\n \n             # Update model card if needed:\n             model_card.save(os.path.join(work_dir, \"README.md\"))"
        },
        {
            "sha": "9d2b34be79b324cd8bc0e68bdd4e2932f8c5407c",
            "filename": "tests/models/auto/test_processor_auto.py",
            "status": "modified",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/7cd1d2b66ca118ea032d517ddb3ec31543354177/tests%2Fmodels%2Fauto%2Ftest_processor_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7cd1d2b66ca118ea032d517ddb3ec31543354177/tests%2Fmodels%2Fauto%2Ftest_processor_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fauto%2Ftest_processor_auto.py?ref=7cd1d2b66ca118ea032d517ddb3ec31543354177",
            "patch": "@@ -476,20 +476,6 @@ def test_push_to_hub_with_chat_templates(self):\n                 tokenizer=tokenizer, image_processor=image_processor, chat_template=chat_template\n             )\n             self.assertEqual(processor.chat_template, chat_template)\n-\n-            existing_tokenizer_template = getattr(processor.tokenizer, \"chat_template\", None)\n-            with TemporaryHubRepo(token=self._token) as tmp_repo:\n-                processor.save_pretrained(\n-                    tmp_dir, repo_id=tmp_repo.repo_id, token=self._token, push_to_hub=True, save_jinja_files=False\n-                )\n-                reloaded_processor = LlavaProcessor.from_pretrained(tmp_repo.repo_id)\n-                self.assertEqual(processor.chat_template, reloaded_processor.chat_template)\n-                # When we don't use single-file chat template saving, processor and tokenizer chat templates\n-                # should remain separate\n-                self.assertEqual(\n-                    getattr(reloaded_processor.tokenizer, \"chat_template\", None), existing_tokenizer_template\n-                )\n-\n             with TemporaryHubRepo(token=self._token) as tmp_repo:\n                 processor.save_pretrained(tmp_dir, repo_id=tmp_repo.repo_id, token=self._token, push_to_hub=True)\n                 reloaded_processor = LlavaProcessor.from_pretrained(tmp_repo.repo_id)"
        },
        {
            "sha": "00dee48c4ae46db992fbb1ba5ad87521080d6624",
            "filename": "tests/test_processing_common.py",
            "status": "modified",
            "additions": 6,
            "deletions": 13,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/7cd1d2b66ca118ea032d517ddb3ec31543354177/tests%2Ftest_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7cd1d2b66ca118ea032d517ddb3ec31543354177/tests%2Ftest_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_processing_common.py?ref=7cd1d2b66ca118ea032d517ddb3ec31543354177",
            "patch": "@@ -15,6 +15,7 @@\n \n import inspect\n import json\n+import os\n import random\n import sys\n import tempfile\n@@ -942,17 +943,15 @@ def test_chat_template_save_loading(self):\n         if \"chat_template\" not in {*signature.parameters.keys()}:\n             self.skipTest(\"Processor doesn't accept chat templates at input\")\n \n-        existing_tokenizer_template = getattr(processor.tokenizer, \"chat_template\", None)\n         processor.chat_template = \"test template\"\n         with tempfile.TemporaryDirectory() as tmpdirname:\n-            processor.save_pretrained(tmpdirname, save_jinja_files=False)\n-            self.assertTrue(Path(tmpdirname, \"chat_template.json\").is_file())\n-            self.assertFalse(Path(tmpdirname, \"chat_template.jinja\").is_file())\n+            processor.save_pretrained(tmpdirname)\n+            with open(Path(tmpdirname, \"chat_template.json\"), \"w\") as fp:\n+                json.dump({\"chat_template\": processor.chat_template}, fp)\n+            os.remove(Path(tmpdirname, \"chat_template.jinja\"))\n+\n             reloaded_processor = self.processor_class.from_pretrained(tmpdirname)\n             self.assertEqual(processor.chat_template, reloaded_processor.chat_template)\n-            # When we don't use single-file chat template saving, processor and tokenizer chat templates\n-            # should remain separate\n-            self.assertEqual(getattr(reloaded_processor.tokenizer, \"chat_template\", None), existing_tokenizer_template)\n \n         with tempfile.TemporaryDirectory() as tmpdirname:\n             processor.save_pretrained(tmpdirname)\n@@ -977,12 +976,6 @@ def test_chat_template_save_loading(self):\n             # the reloaded tokenizer should get the chat template as well\n             self.assertEqual(reloaded_processor.chat_template, reloaded_processor.tokenizer.chat_template)\n \n-        with self.assertRaises(ValueError):\n-            # Saving multiple templates in the legacy format is not permitted\n-            with tempfile.TemporaryDirectory() as tmpdirname:\n-                processor.chat_template = {\"default\": \"a\", \"secondary\": \"b\"}\n-                processor.save_pretrained(tmpdirname, save_jinja_files=False)\n-\n     @require_torch\n     def _test_apply_chat_template(\n         self,"
        },
        {
            "sha": "fe968836215908e31be80a4f8b696b593e130f00",
            "filename": "tests/test_tokenization_common.py",
            "status": "modified",
            "additions": 38,
            "deletions": 34,
            "changes": 72,
            "blob_url": "https://github.com/huggingface/transformers/blob/7cd1d2b66ca118ea032d517ddb3ec31543354177/tests%2Ftest_tokenization_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7cd1d2b66ca118ea032d517ddb3ec31543354177/tests%2Ftest_tokenization_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_tokenization_common.py?ref=7cd1d2b66ca118ea032d517ddb3ec31543354177",
            "patch": "@@ -1093,9 +1093,13 @@ def test_chat_template(self):\n                 tokenizer.apply_chat_template(dummy_conversation, tokenize=True, return_dict=False)\n \n                 with tempfile.TemporaryDirectory() as tmp_dir_name:\n-                    save_files = tokenizer.save_pretrained(tmp_dir_name, save_jinja_files=False)\n-                    # Check we aren't saving a chat_template.jinja file\n-                    self.assertFalse(any(file.endswith(\"chat_template.jinja\") for file in save_files))\n+                    save_files = tokenizer.save_pretrained(tmp_dir_name)\n+                    with open(Path(tmp_dir_name, \"tokenizer_config.json\"), \"r\") as fp:\n+                        tokenizer_config = json.load(fp)\n+                        tokenizer_config[\"chat_template\"] = tokenizer.chat_template\n+                    with open(Path(tmp_dir_name, \"tokenizer_config.json\"), \"w\") as fp:\n+                        json.dump(tokenizer_config, fp)\n+                    os.remove(Path(tmp_dir_name, \"chat_template.jinja\"))\n                     new_tokenizer = tokenizer.from_pretrained(tmp_dir_name)\n \n                 self.assertEqual(new_tokenizer.chat_template, dummy_template)  # Test template has persisted\n@@ -1155,10 +1159,16 @@ def test_chat_template_save_loading(self):\n \n             with tempfile.TemporaryDirectory() as tmpdirname:\n                 tokenizer.chat_template = {\"default\": \"a\", \"secondary\": \"b\"}\n-                tokenizer.save_pretrained(tmpdirname, save_jinja_files=False)\n-                self.assertFalse(Path(tmpdirname, \"chat_template.jinja\").is_file())\n-                self.assertFalse(Path(tmpdirname, \"chat_template.json\").is_file())\n-                self.assertFalse(Path(tmpdirname, \"additional_chat_templates\").is_dir())\n+                tokenizer.save_pretrained(tmpdirname)\n+                with open(Path(tmpdirname, \"tokenizer_config.json\"), \"r\") as fp:\n+                    tokenizer_config = json.load(fp)\n+                    tokenizer_config[\"chat_template\"] = [\n+                        {\"name\": k, \"template\": v} for k, v in tokenizer.chat_template\n+                    ]\n+                with open(Path(tmpdirname, \"tokenizer_config.json\"), \"w\") as fp:\n+                    json.dump(tokenizer_config, fp)\n+                os.remove(Path(tmpdirname, \"chat_template.jinja\"))\n+                os.remove(Path(tmpdirname, \"additional_chat_templates\"))\n                 reloaded_tokenizer = self.tokenizer_class.from_pretrained(tmpdirname)\n                 self.assertEqual(tokenizer.chat_template, reloaded_tokenizer.chat_template)\n                 # When we save as single files, tokenizers and tokenizers share a chat template, which means\n@@ -1652,32 +1662,19 @@ def test_chat_template_dict_saving(self):\n         tokenizers = self.get_tokenizers()\n         for tokenizer in tokenizers:\n             with self.subTest(f\"{tokenizer.__class__.__name__}\"):\n-                for save_jinja_files in (True, False):\n-                    tokenizer.chat_template = {\"default\": dummy_template_1, \"template2\": dummy_template_2}\n-                    with tempfile.TemporaryDirectory() as tmp_dir_name:\n-                        # Test that save_jinja_files is ignored when there's a dict of multiple templates\n-                        tokenizer.save_pretrained(tmp_dir_name, save_jinja_files=save_jinja_files)\n-                        if save_jinja_files:\n-                            config_dict = json.load(open(os.path.join(tmp_dir_name, \"tokenizer_config.json\")))\n-                            self.assertNotIn(\"chat_template\", config_dict)\n-                            self.assertTrue(os.path.exists(os.path.join(tmp_dir_name, \"chat_template.jinja\")))\n-                            self.assertTrue(\n-                                os.path.exists(os.path.join(tmp_dir_name, \"additional_chat_templates/template2.jinja\"))\n-                            )\n-                        else:\n-                            config_dict = json.load(open(os.path.join(tmp_dir_name, \"tokenizer_config.json\")))\n-                            # Assert that chat templates are correctly serialized as lists of dictionaries\n-                            self.assertEqual(\n-                                config_dict[\"chat_template\"],\n-                                [\n-                                    {\"name\": \"default\", \"template\": \"{{'a'}}\"},\n-                                    {\"name\": \"template2\", \"template\": \"{{'b'}}\"},\n-                                ],\n-                            )\n-                            self.assertFalse(os.path.exists(os.path.join(tmp_dir_name, \"chat_template.jinja\")))\n-                        new_tokenizer = tokenizer.from_pretrained(tmp_dir_name)\n-                    # Assert that the serialized list is correctly reconstructed as a single dict\n-                    self.assertEqual(new_tokenizer.chat_template, tokenizer.chat_template)\n+                tokenizer.chat_template = {\"default\": dummy_template_1, \"template2\": dummy_template_2}\n+                with tempfile.TemporaryDirectory() as tmp_dir_name:\n+                    # Test that a dict of multiple templates can be serialized and loaded back\n+                    tokenizer.save_pretrained(tmp_dir_name)\n+                    config_dict = json.load(open(os.path.join(tmp_dir_name, \"tokenizer_config.json\")))\n+                    self.assertNotIn(\"chat_template\", config_dict)\n+                    self.assertTrue(os.path.exists(os.path.join(tmp_dir_name, \"chat_template.jinja\")))\n+                    self.assertTrue(\n+                        os.path.exists(os.path.join(tmp_dir_name, \"additional_chat_templates/template2.jinja\"))\n+                    )\n+                    new_tokenizer = tokenizer.from_pretrained(tmp_dir_name)\n+                # Assert that the serialized list is correctly reconstructed as a single dict\n+                self.assertEqual(new_tokenizer.chat_template, tokenizer.chat_template)\n \n     @require_jinja\n     def test_chat_template_file_priority(self):\n@@ -1688,7 +1685,14 @@ def test_chat_template_file_priority(self):\n             with self.subTest(f\"{tokenizer.__class__.__name__}\"):\n                 with tempfile.TemporaryDirectory() as tmp_dir_name:\n                     tokenizer.chat_template = dummy_template1\n-                    tokenizer.save_pretrained(tmp_dir_name, save_jinja_files=False)\n+                    tokenizer.save_pretrained(tmp_dir_name)\n+                    # Save first template in tokenizer config and second template in jinja file\n+                    # Priority should be given to jinja when loading\n+                    with open(Path(tmp_dir_name, \"tokenizer_config.json\"), \"r\") as fp:\n+                        tokenizer_config = json.load(fp)\n+                        tokenizer_config[\"chat_template\"] = tokenizer.chat_template\n+                    with open(Path(tmp_dir_name, \"tokenizer_config.json\"), \"w\") as fp:\n+                        json.dump(tokenizer_config, fp)\n                     with Path(tmp_dir_name, \"chat_template.jinja\").open(\"w\") as f:\n                         f.write(dummy_template2)\n                     new_tokenizer = tokenizer.from_pretrained(tmp_dir_name)"
        },
        {
            "sha": "1cb872a3c2166b9486464662ef006b8af3dee90c",
            "filename": "tests/utils/test_tokenization_utils.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/7cd1d2b66ca118ea032d517ddb3ec31543354177/tests%2Futils%2Ftest_tokenization_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7cd1d2b66ca118ea032d517ddb3ec31543354177/tests%2Futils%2Ftest_tokenization_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_tokenization_utils.py?ref=7cd1d2b66ca118ea032d517ddb3ec31543354177",
            "patch": "@@ -138,14 +138,6 @@ def test_push_to_hub_chat_templates(self):\n                 vocab_writer.write(\"\".join([x + \"\\n\" for x in self.vocab_tokens]))\n             tokenizer = BertTokenizer(vocab_file)\n             tokenizer.chat_template = \"test template\"\n-\n-            with TemporaryHubRepo(token=self._token) as tmp_repo:\n-                tokenizer.save_pretrained(\n-                    tmp_repo.repo_id, token=self._token, push_to_hub=True, save_jinja_files=False\n-                )\n-                reloaded_tokenizer = BertTokenizer.from_pretrained(tmp_repo.repo_id)\n-                self.assertEqual(tokenizer.chat_template, reloaded_tokenizer.chat_template)\n-\n             with TemporaryHubRepo(token=self._token) as tmp_repo:\n                 tokenizer.save_pretrained(tmp_repo.repo_id, token=self._token, push_to_hub=True)\n                 reloaded_tokenizer = BertTokenizer.from_pretrained(tmp_repo.repo_id)"
        }
    ],
    "stats": {
        "total": 224,
        "additions": 77,
        "deletions": 147
    }
}