{
    "author": "johngrahamreynolds",
    "message": "Update data collator docstrings to accurately reference Nvidia tensor core compute capability version (#35188)\n\nupdate data collator docs to reflect correct tensor core compute capability\r\n\r\nCo-authored-by: John Graham Reynolds <john.graham.reynolds@vumc.org>",
    "sha": "e8508924fdfe1ad96e35d23e795eb7f7beec836a",
    "files": [
        {
            "sha": "e84c9d0ef3ce2e7191f6ba7c6d5da209d559b91d",
            "filename": "src/transformers/data/data_collator.py",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/e8508924fdfe1ad96e35d23e795eb7f7beec836a/src%2Ftransformers%2Fdata%2Fdata_collator.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e8508924fdfe1ad96e35d23e795eb7f7beec836a/src%2Ftransformers%2Fdata%2Fdata_collator.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdata%2Fdata_collator.py?ref=e8508924fdfe1ad96e35d23e795eb7f7beec836a",
            "patch": "@@ -256,7 +256,7 @@ class DataCollatorWithPadding:\n             If set will pad the sequence to a multiple of the provided value.\n \n             This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n-            7.5 (Volta).\n+            7.0 (Volta).\n         return_tensors (`str`, *optional*, defaults to `\"pt\"`):\n             The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n     \"\"\"\n@@ -308,7 +308,7 @@ class DataCollatorForTokenClassification(DataCollatorMixin):\n             If set will pad the sequence to a multiple of the provided value.\n \n             This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n-            7.5 (Volta).\n+            7.0 (Volta).\n         label_pad_token_id (`int`, *optional*, defaults to -100):\n             The id to use when padding the labels (-100 will be automatically ignore by PyTorch loss functions).\n         return_tensors (`str`, *optional*, defaults to `\"pt\"`):\n@@ -568,7 +568,7 @@ class DataCollatorForSeq2Seq:\n             If set will pad the sequence to a multiple of the provided value.\n \n             This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n-            7.5 (Volta).\n+            7.0 (Volta).\n         label_pad_token_id (`int`, *optional*, defaults to -100):\n             The id to use when padding the labels (-100 will be automatically ignored by PyTorch loss functions).\n         return_tensors (`str`, *optional*, defaults to `\"pt\"`):\n@@ -693,6 +693,9 @@ class DataCollatorForLanguageModeling(DataCollatorMixin):\n             The probability with which to (randomly) mask tokens in the input, when `mlm` is set to `True`.\n         pad_to_multiple_of (`int`, *optional*):\n             If set will pad the sequence to a multiple of the provided value.\n+\n+            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n+            7.0 (Volta).\n         return_tensors (`str`):\n             The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n "
        }
    ],
    "stats": {
        "total": 9,
        "additions": 6,
        "deletions": 3
    }
}