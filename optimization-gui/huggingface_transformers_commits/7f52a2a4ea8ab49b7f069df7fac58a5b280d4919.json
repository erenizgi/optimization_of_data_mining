{
    "author": "abidlabs",
    "message": "Add `.on_push_begin()` callback to Trainer and implement for `TrackioCallback` (#42850)\n\n* changes\n\n* changes\n\n* Update src/transformers/integrations/integration_utils.py\n\nCo-authored-by: Quentin Gallouédec <45557362+qgallouedec@users.noreply.github.com>\n\n* changes\n\n* changes\n\n* changes\n\n* changes\n\n* changes\n\n* changes\n\n* changes\n\n---------\n\nCo-authored-by: Quentin Gallouédec <45557362+qgallouedec@users.noreply.github.com>",
    "sha": "7f52a2a4ea8ab49b7f069df7fac58a5b280d4919",
    "files": [
        {
            "sha": "8b4e18dc2b668a7f918352d66b1f534536e092f8",
            "filename": "src/transformers/integrations/integration_utils.py",
            "status": "modified",
            "additions": 35,
            "deletions": 0,
            "changes": 35,
            "blob_url": "https://github.com/huggingface/transformers/blob/7f52a2a4ea8ab49b7f069df7fac58a5b280d4919/src%2Ftransformers%2Fintegrations%2Fintegration_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7f52a2a4ea8ab49b7f069df7fac58a5b280d4919/src%2Ftransformers%2Fintegrations%2Fintegration_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Fintegration_utils.py?ref=7f52a2a4ea8ab49b7f069df7fac58a5b280d4919",
            "patch": "@@ -940,6 +940,8 @@ class TrackioCallback(TrainerCallback):\n     ```\n     \"\"\"\n \n+    SPACE_URL = \"https://huggingface.co/spaces/{space_id}\"\n+\n     def __init__(self):\n         has_trackio = is_trackio_available()\n         if not has_trackio:\n@@ -1058,6 +1060,39 @@ def on_predict(self, args, state, control, metrics, **kwargs):\n             metrics = rewrite_logs(metrics)\n             self._trackio.log(metrics)\n \n+    def on_push_begin(self, args, state, control, model, **kwargs):\n+        if not state.is_world_process_zero or self._trackio is None:\n+            return\n+        if (current_project := self._trackio.context_vars.current_project.get()) is None:\n+            return\n+        trackio_version = packaging.version.parse(self._trackio.__version__)\n+        if trackio_version < packaging.version.parse(\"0.13.0\"):\n+            warnings.warn(\n+                \"The version of `trackio` that is installed is <=0.13.0, so \"\n+                \"the local Trackio project will not be pushed to Hugging Face. Run \"\n+                \"`pip install --upgrade trackio` to fix this.\"\n+            )\n+            return\n+\n+        space_id = self._trackio.context_vars.current_space_id.get()\n+        if space_id is None:\n+            space_id = self._trackio.sync(current_project, force=True)\n+        space_url = self.SPACE_URL.format(space_id=space_id)\n+\n+        badge_markdown = (\n+            f'<a href=\"{space_url}\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/gradio-app/trackio/refs/heads/main/trackio/assets/badge.png\" alt=\"Visualize in Trackio\"'\n+            ' title=\"Visualize in Trackio\" style=\"height: 40px;\"/></a>'\n+        )\n+        if badge_markdown not in modelcard.AUTOGENERATED_TRAINER_COMMENT:\n+            modelcard.AUTOGENERATED_TRAINER_COMMENT += f\"\\n{badge_markdown}\"\n+\n+        if getattr(model, \"model_tags\", None) is not None:\n+            if \"trackio\" not in model.model_tags:\n+                model.model_tags.append(\"trackio\")\n+                model.model_tags.append(f\"trackio::{space_url}\")\n+        else:\n+            model.model_tags = [\"trackio\", f\"trackio:{space_url}\"]\n+\n \n class CometCallback(TrainerCallback):\n     \"\"\""
        },
        {
            "sha": "86639c7de3a8c1ddca76900aff1886922e66be94",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7f52a2a4ea8ab49b7f069df7fac58a5b280d4919/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7f52a2a4ea8ab49b7f069df7fac58a5b280d4919/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=7f52a2a4ea8ab49b7f069df7fac58a5b280d4919",
            "patch": "@@ -4827,6 +4827,7 @@ def _push_from_checkpoint(self, checkpoint_folder):\n         if not self.args.hub_always_push and self.push_in_progress is not None and not self.push_in_progress.is_done():\n             return\n \n+        self.callback_handler.on_push_begin(self.args, self.state, self.control)\n         output_dir = self.args.output_dir\n         # To avoid a new synchronization of all model weights, we just copy the file from the checkpoint folder\n         modeling_files = [CONFIG_NAME, GENERATION_CONFIG_NAME, WEIGHTS_NAME, SAFE_WEIGHTS_NAME]\n@@ -4921,6 +4922,8 @@ def push_to_hub(\n             The URL of the repository where the model was pushed if `blocking=False`, or a `Future` object tracking the\n             progress of the commit if `blocking=True`.\n         \"\"\"\n+        self.callback_handler.on_push_begin(self.args, self.state, self.control)\n+\n         model_name = kwargs.pop(\"model_name\", None)\n         if model_name is None and self.args.should_save:\n             if self.args.hub_model_id is None:"
        },
        {
            "sha": "92d61eba1ca27f942e925679f5b57b1d40735759",
            "filename": "src/transformers/trainer_callback.py",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/7f52a2a4ea8ab49b7f069df7fac58a5b280d4919/src%2Ftransformers%2Ftrainer_callback.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7f52a2a4ea8ab49b7f069df7fac58a5b280d4919/src%2Ftransformers%2Ftrainer_callback.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer_callback.py?ref=7f52a2a4ea8ab49b7f069df7fac58a5b280d4919",
            "patch": "@@ -420,6 +420,11 @@ def on_prediction_step(self, args: TrainingArguments, state: TrainerState, contr\n         Event called after a prediction step.\n         \"\"\"\n \n+    def on_push_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n+        \"\"\"\n+        Event called before pushing the model to the hub, at the beginning of Trainer.push_to_hub and Trainer._push_from_checkpoint.\n+        \"\"\"\n+\n \n class CallbackHandler(TrainerCallback):\n     \"\"\"Internal class that just calls the list of callbacks in order.\"\"\"\n@@ -532,6 +537,9 @@ def on_log(self, args: TrainingArguments, state: TrainerState, control: TrainerC\n     def on_prediction_step(self, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n         return self.call_event(\"on_prediction_step\", args, state, control)\n \n+    def on_push_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n+        return self.call_event(\"on_push_begin\", args, state, control, **kwargs)\n+\n     def call_event(self, event, args, state, control, **kwargs):\n         for callback in self.callbacks:\n             result = getattr(callback, event)("
        },
        {
            "sha": "aabbf46b8a21180c7825b960195aa75d0403dfa9",
            "filename": "tests/trainer/test_trainer_callback.py",
            "status": "modified",
            "additions": 14,
            "deletions": 0,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/7f52a2a4ea8ab49b7f069df7fac58a5b280d4919/tests%2Ftrainer%2Ftest_trainer_callback.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7f52a2a4ea8ab49b7f069df7fac58a5b280d4919/tests%2Ftrainer%2Ftest_trainer_callback.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_trainer_callback.py?ref=7f52a2a4ea8ab49b7f069df7fac58a5b280d4919",
            "patch": "@@ -102,6 +102,9 @@ def on_log(self, args, state, control, **kwargs):\n     def on_prediction_step(self, args, state, control, **kwargs):\n         self.events.append(\"on_prediction_step\")\n \n+    def on_push_begin(self, args, state, control, **kwargs):\n+        self.events.append(\"on_push_begin\")\n+\n \n @require_torch\n class TrainerCallbackTest(unittest.TestCase):\n@@ -443,3 +446,14 @@ def on_epoch_end(self, args: TrainingArguments, state: TrainerState, control, **\n         trainer = self.get_trainer(max_steps=2, save_strategy=\"epoch\", callbacks=[OnEndCallback])\n         trainer.train()\n         assert times_saved == 1\n+\n+    def test_on_push_begin(self):\n+        trainer = self.get_trainer(callbacks=[MyTestTrainerCallback], max_steps=1)\n+        trainer.train()\n+        callback = [cb for cb in trainer.callback_handler.callbacks if isinstance(cb, MyTestTrainerCallback)][0]\n+        initial_event_count = len(callback.events)\n+\n+        trainer.callback_handler.on_push_begin(trainer.args, trainer.state, trainer.control)\n+        assert \"on_push_begin\" in callback.events\n+        assert callback.events.count(\"on_push_begin\") == 1\n+        assert len(callback.events) == initial_event_count + 1"
        }
    ],
    "stats": {
        "total": 60,
        "additions": 60,
        "deletions": 0
    }
}