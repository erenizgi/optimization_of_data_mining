{
    "author": "TopCoder2K",
    "message": "Fixed the docstring for `WhisperFeatureExtractor` (#42286)\n\nFixed the docstring",
    "sha": "52cbf3913cad3afcae7cfbb19d4405478160edd5",
    "files": [
        {
            "sha": "fcda9acdefcee7b1267f8042b94485ef5b734dc7",
            "filename": "src/transformers/models/whisper/feature_extraction_whisper.py",
            "status": "modified",
            "additions": 22,
            "deletions": 11,
            "changes": 33,
            "blob_url": "https://github.com/huggingface/transformers/blob/52cbf3913cad3afcae7cfbb19d4405478160edd5/src%2Ftransformers%2Fmodels%2Fwhisper%2Ffeature_extraction_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/52cbf3913cad3afcae7cfbb19d4405478160edd5/src%2Ftransformers%2Fmodels%2Fwhisper%2Ffeature_extraction_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Ffeature_extraction_whisper.py?ref=52cbf3913cad3afcae7cfbb19d4405478160edd5",
            "patch": "@@ -204,9 +204,8 @@ def __call__(\n         return_token_timestamps: Optional[bool] = None,\n         **kwargs,\n     ) -> BatchFeature:\n-        \"\"\"\n-        Main method to featurize and prepare for the model one or several sequence(s). Implementation uses PyTorch for\n-        the STFT computation if available, otherwise a slower NumPy based one.\n+        \"\"\"Main method to featurize and prepare for the model one or several sequence(s). Implementation uses PyTorch\n+        for the STFT computation if available, otherwise a slower NumPy based one.\n \n         Args:\n             raw_speech (`np.ndarray`, `list[float]`, `list[np.ndarray]`, `list[list[float]]`):\n@@ -220,6 +219,11 @@ def __call__(\n \n                 This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability\n                 `>= 7.5` (Volta), or on TPUs which benefit from having sequence lengths be a multiple of 128.\n+            return_tensors (`str` or [`~utils.TensorType`], *optional*):\n+                If set, will return tensors instead of list of python integers. Acceptable values are:\n+\n+                - `'pt'`: Return PyTorch `torch.Tensor` objects.\n+                - `'np'`: Return Numpy `np.ndarray` objects.\n             return_attention_mask (`bool`, *optional*):\n                 Whether to return the attention mask. If left to the default, will return the attention mask according\n                 to the specific feature_extractor's default.\n@@ -232,18 +236,24 @@ def __call__(\n                 bugs.\n \n                 </Tip>\n-\n-            return_tensors (`str` or [`~utils.TensorType`], *optional*):\n-                If set, will return tensors instead of list of python integers. Acceptable values are:\n-\n-                - `'pt'`: Return PyTorch `torch.Tensor` objects.\n-                - `'np'`: Return Numpy `np.ndarray` objects.\n+            padding (`str` or [`~utils.PaddingStrategy`], *optional*, defaults to `'max_length'`):\n+                Activates and controls padding. Accepts the following values:\n+\n+                - `'longest'`: Pad to the longest sequence in the batch (or no padding if only a single sequence is\n+                  provided).\n+                - `'max_length'` (default): Pad to a maximum length specified with the argument `max_length` or to the\n+                  maximum acceptable input length for the model if that argument is not provided.\n+                - `'do_not_pad'`: No padding (i.e., can output a batch with sequences of different lengths).\n+            max_length (`int`, *optional*):\n+                Controls the maximum length to use by one of the truncation/padding parameters.\n+\n+                If left unset or set to `None`, this will use the predefined model maximum length if a maximum length\n+                is required by one of the truncation/padding parameters. If the model has no specific maximum input\n+                length (like XLNet) truncation/padding to a maximum length will be deactivated.\n             sampling_rate (`int`, *optional*):\n                 The sampling rate at which the `raw_speech` input was sampled. It is strongly recommended to pass\n                 `sampling_rate` at the forward call to prevent silent errors and allow automatic speech recognition\n                 pipeline.\n-            padding_value (`float`, *optional*, defaults to 0.0):\n-                The value that is used to fill the padding values / vectors.\n             do_normalize (`bool`, *optional*, defaults to `False`):\n                 Whether or not to zero-mean unit-variance normalize the input. Normalizing can help to significantly\n                 improve the performance of the model.\n@@ -255,6 +265,7 @@ def __call__(\n \n                 Whether or not to return the number of frames of the input raw_speech.\n                 These num_frames can be used by the model to compute word level timestamps.\n+            **kwargs: Not supported by WhisperFeatureExtractor.__call__() and ignored.\n         \"\"\"\n         if sampling_rate is not None:\n             if sampling_rate != self.sampling_rate:"
        }
    ],
    "stats": {
        "total": 33,
        "additions": 22,
        "deletions": 11
    }
}