{
    "author": "KyleMylonakisProtopia",
    "message": "build: :pushpin: Remove upper bound on PyTorch (#38789)\n\nbuild: :pushpin: remove upper bound on torch dependency as issue which originally resulted in the pin has been released in torch 2.7.1",
    "sha": "3542e0b8440383f017fd16670511a579ef6e5aa9",
    "files": [
        {
            "sha": "d47ccb197c4ae2e576a8e4ba97cd8e041f3949ec",
            "filename": "setup.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/3542e0b8440383f017fd16670511a579ef6e5aa9/setup.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3542e0b8440383f017fd16670511a579ef6e5aa9/setup.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/setup.py?ref=3542e0b8440383f017fd16670511a579ef6e5aa9",
            "patch": "@@ -189,7 +189,7 @@\n     \"tiktoken\",\n     \"timm<=1.0.11\",\n     \"tokenizers>=0.21,<0.22\",\n-    \"torch>=2.1,<2.7\",  # Installing torch 2.7 results in slower compiled LLMs. Pinned while we investigate.\n+    \"torch>=2.1\",\n     \"torchaudio\",\n     \"torchvision\",\n     \"pyctcdecode>=0.4.0\","
        },
        {
            "sha": "e75872d47900633513d84b9813d5c58b3816acda",
            "filename": "src/transformers/dependency_versions_table.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/3542e0b8440383f017fd16670511a579ef6e5aa9/src%2Ftransformers%2Fdependency_versions_table.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3542e0b8440383f017fd16670511a579ef6e5aa9/src%2Ftransformers%2Fdependency_versions_table.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdependency_versions_table.py?ref=3542e0b8440383f017fd16670511a579ef6e5aa9",
            "patch": "@@ -91,7 +91,7 @@\n     \"tiktoken\": \"tiktoken\",\n     \"timm\": \"timm<=1.0.11\",\n     \"tokenizers\": \"tokenizers>=0.21,<0.22\",\n-    \"torch\": \"torch>=2.1,<2.7\",\n+    \"torch\": \"torch>=2.1\",\n     \"torchaudio\": \"torchaudio\",\n     \"torchvision\": \"torchvision\",\n     \"pyctcdecode\": \"pyctcdecode>=0.4.0\","
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}