{
    "author": "yonigozlan",
    "message": "Use non nested images and batched text Idefics2/3  (#34222)\n\n* add support for non nested images and add tests\r\n\r\n* add tests error scenario\r\n\r\n* fix style\r\n\r\n* added single and no image to error tests",
    "sha": "940a6bd343cfd2ff4f4425b4cbc548d1e1d316da",
    "files": [
        {
            "sha": "ce0032f80c5ece081b5c96e3fd7c4b7e7a91e8cb",
            "filename": "src/transformers/models/idefics2/image_processing_idefics2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/940a6bd343cfd2ff4f4425b4cbc548d1e1d316da/src%2Ftransformers%2Fmodels%2Fidefics2%2Fimage_processing_idefics2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/940a6bd343cfd2ff4f4425b4cbc548d1e1d316da/src%2Ftransformers%2Fmodels%2Fidefics2%2Fimage_processing_idefics2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics2%2Fimage_processing_idefics2.py?ref=940a6bd343cfd2ff4f4425b4cbc548d1e1d316da",
            "patch": "@@ -99,6 +99,7 @@ def make_list_of_images(images: ImageInput) -> List[List[np.ndarray]]:\n         isinstance(images, (list, tuple))\n         and len(images) > 0\n         and isinstance(images[0], (list, tuple))\n+        and len(images[0]) > 0\n         and is_valid_image(images[0][0])\n     ):\n         pass"
        },
        {
            "sha": "9a041257c36b5b5cbea8511dcf35098e71171a69",
            "filename": "src/transformers/models/idefics2/processing_idefics2.py",
            "status": "modified",
            "additions": 16,
            "deletions": 1,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/940a6bd343cfd2ff4f4425b4cbc548d1e1d316da/src%2Ftransformers%2Fmodels%2Fidefics2%2Fprocessing_idefics2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/940a6bd343cfd2ff4f4425b4cbc548d1e1d316da/src%2Ftransformers%2Fmodels%2Fidefics2%2Fprocessing_idefics2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics2%2Fprocessing_idefics2.py?ref=940a6bd343cfd2ff4f4425b4cbc548d1e1d316da",
            "patch": "@@ -16,6 +16,7 @@\n Processor class for IDEFICS2.\n \"\"\"\n \n+from itertools import accumulate\n from typing import TYPE_CHECKING, List, Optional, Union\n \n from ...feature_extraction_utils import BatchFeature\n@@ -218,7 +219,21 @@ def __call__(\n             if is_image_or_image_url(images):\n                 images = [[images]]\n             elif isinstance(images, list) and is_image_or_image_url(images[0]):\n-                images = [images]\n+                if text is not None:\n+                    if sum(n_images_in_text) != len(images):\n+                        raise ValueError(\n+                            f\"The total number of {image_token} tokens in the prompts should be the same as the number of images passed.\"\n+                            f\" Found {sum(n_images_in_text)} {image_token} tokens and {len(images)} images.\"\n+                        )\n+                    # Reorganize the images to match the prompts\n+                    cumsum_images_in_text = [0] + list(accumulate(n_images_in_text))\n+                    images = [\n+                        images[cumsum_images_in_text[i] : cumsum_images_in_text[i + 1]]\n+                        for i in range(len(n_images_in_text))\n+                    ]\n+                else:\n+                    images = [images]\n+\n             elif (\n                 not isinstance(images, list)\n                 and not isinstance(images[0], list)"
        },
        {
            "sha": "05a1a396dc72d3566a2f16cb0ceb0a4c36854624",
            "filename": "src/transformers/models/idefics3/image_processing_idefics3.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/940a6bd343cfd2ff4f4425b4cbc548d1e1d316da/src%2Ftransformers%2Fmodels%2Fidefics3%2Fimage_processing_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/940a6bd343cfd2ff4f4425b4cbc548d1e1d316da/src%2Ftransformers%2Fmodels%2Fidefics3%2Fimage_processing_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics3%2Fimage_processing_idefics3.py?ref=940a6bd343cfd2ff4f4425b4cbc548d1e1d316da",
            "patch": "@@ -151,9 +151,11 @@ def get_resize_output_image_size(\n def make_list_of_images(images: ImageInput) -> List[List[np.ndarray]]:\n     \"\"\"\n     Convert a single image or a list of images to a list of numpy arrays.\n+\n     Args:\n         images (`ImageInput`):\n             A single image or a list of images.\n+\n     Returns:\n         A list of numpy arrays.\n     \"\"\"\n@@ -168,6 +170,7 @@ def make_list_of_images(images: ImageInput) -> List[List[np.ndarray]]:\n         isinstance(images, (list, tuple))\n         and len(images) > 0\n         and isinstance(images[0], (list, tuple))\n+        and len(images[0]) > 0\n         and is_valid_image(images[0][0])\n     ):\n         pass"
        },
        {
            "sha": "872f5206f20175ed1d516661f13b5bf291880e43",
            "filename": "src/transformers/models/idefics3/processing_idefics3.py",
            "status": "modified",
            "additions": 26,
            "deletions": 12,
            "changes": 38,
            "blob_url": "https://github.com/huggingface/transformers/blob/940a6bd343cfd2ff4f4425b4cbc548d1e1d316da/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/940a6bd343cfd2ff4f4425b4cbc548d1e1d316da/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py?ref=940a6bd343cfd2ff4f4425b4cbc548d1e1d316da",
            "patch": "@@ -17,6 +17,7 @@\n \"\"\"\n \n import re\n+from itertools import accumulate\n from typing import TYPE_CHECKING, Dict, List, Optional, Union\n \n from ...feature_extraction_utils import BatchFeature\n@@ -241,11 +242,31 @@ def __call__(\n         n_images_in_images = []\n         inputs = BatchFeature()\n \n+        if text is not None:\n+            if isinstance(text, str):\n+                text = [text]\n+            elif not isinstance(text, list) and not isinstance(text[0], str):\n+                raise ValueError(\"Invalid input text. Please provide a string, or a list of strings\")\n+            n_images_in_text = [sample.count(self.image_token.content) for sample in text]\n+\n         if images is not None:\n             if is_image_or_image_url(images):\n                 images = [[images]]\n             elif isinstance(images, list) and is_image_or_image_url(images[0]):\n-                images = [images]\n+                if text is not None:\n+                    if sum(n_images_in_text) != len(images):\n+                        raise ValueError(\n+                            f\"The total number of {self.image_token.content} tokens in the prompts should be the same as the number of images passed.\"\n+                            f\" Found {sum(n_images_in_text)} {self.image_token.content} tokens and {len(images)} images.\"\n+                        )\n+                    # Reorganize the images to match the prompts\n+                    cumsum_images_in_text = [0] + list(accumulate(n_images_in_text))\n+                    images = [\n+                        images[cumsum_images_in_text[i] : cumsum_images_in_text[i + 1]]\n+                        for i in range(len(n_images_in_text))\n+                    ]\n+                else:\n+                    images = [images]\n             elif (\n                 not isinstance(images, list)\n                 and not isinstance(images[0], list)\n@@ -263,10 +284,10 @@ def __call__(\n             inputs.update(image_inputs)\n \n         if text is not None:\n-            if isinstance(text, str):\n-                text = [text]\n-            elif not isinstance(text, list) and not isinstance(text[0], str):\n-                raise ValueError(\"Invalid input text. Please provide a string, or a list of strings\")\n+            if n_images_in_images != n_images_in_text:\n+                raise ValueError(\n+                    f\"The number of images in the text {n_images_in_text} and images  {n_images_in_images} should be the same.\"\n+                )\n \n             image_rows = inputs.pop(\"rows\", [[0] * len(text)])\n             image_cols = inputs.pop(\"cols\", [[0] * len(text)])\n@@ -277,8 +298,6 @@ def __call__(\n \n             prompt_strings = []\n             for sample, sample_rows, sample_cols in zip(text, image_rows, image_cols):\n-                n_images_in_text.append(sample.count(image_token))\n-\n                 # Replace the image token with fake tokens around the expanded image token sequence of length `image_seq_len`\n                 image_prompt_strings = []\n                 for n_rows, n_cols in zip(sample_rows, sample_cols):\n@@ -305,11 +324,6 @@ def __call__(\n             text_inputs = self.tokenizer(text=prompt_strings, **output_kwargs[\"text_kwargs\"])\n             inputs.update(text_inputs)\n \n-            if n_images_in_images != n_images_in_text:\n-                raise ValueError(\n-                    f\"The number of images in the text {n_images_in_text} and images  {n_images_in_images} should be the same.\"\n-                )\n-\n         return inputs\n \n     def batch_decode(self, *args, **kwargs):"
        },
        {
            "sha": "b4ec0e50c9ccc304003aa3b2cfdf3f0e54a30b64",
            "filename": "src/transformers/models/pixtral/image_processing_pixtral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/940a6bd343cfd2ff4f4425b4cbc548d1e1d316da/src%2Ftransformers%2Fmodels%2Fpixtral%2Fimage_processing_pixtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/940a6bd343cfd2ff4f4425b4cbc548d1e1d316da/src%2Ftransformers%2Fmodels%2Fpixtral%2Fimage_processing_pixtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpixtral%2Fimage_processing_pixtral.py?ref=940a6bd343cfd2ff4f4425b4cbc548d1e1d316da",
            "patch": "@@ -120,6 +120,7 @@ def make_list_of_images(images: ImageInput) -> List[List[np.ndarray]]:\n         isinstance(images, (list, tuple))\n         and len(images) > 0\n         and isinstance(images[0], (list, tuple))\n+        and len(images[0]) > 0\n         and is_valid_image(images[0][0])\n     ):\n         pass"
        },
        {
            "sha": "d89004679aef0f11be7c8913c1817765d220229b",
            "filename": "tests/models/idefics2/test_processor_idefics2.py",
            "status": "modified",
            "additions": 67,
            "deletions": 10,
            "changes": 77,
            "blob_url": "https://github.com/huggingface/transformers/blob/940a6bd343cfd2ff4f4425b4cbc548d1e1d316da/tests%2Fmodels%2Fidefics2%2Ftest_processor_idefics2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/940a6bd343cfd2ff4f4425b4cbc548d1e1d316da/tests%2Fmodels%2Fidefics2%2Ftest_processor_idefics2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fidefics2%2Ftest_processor_idefics2.py?ref=940a6bd343cfd2ff4f4425b4cbc548d1e1d316da",
            "patch": "@@ -226,6 +226,73 @@ def test_add_special_tokens_processor(self):\n         self.assertEqual(inputs[\"input_ids\"], expected_input_ids)\n         # fmt: on\n \n+    def test_non_nested_images_with_batched_text(self):\n+        processor = self.get_processor()\n+        processor.image_processor.do_image_splitting = False\n+\n+        image_str = \"<image>\"\n+        text_str_1 = \"In this image, we see\"\n+        text_str_2 = \"bla, bla\"\n+\n+        text = [\n+            image_str + text_str_1,\n+            text_str_2 + image_str + image_str,\n+        ]\n+        images = [self.image1, self.image2, self.image3]\n+\n+        inputs = processor(text=text, images=images, padding=True)\n+\n+        self.assertEqual(inputs[\"pixel_values\"].shape, (2, 2, 3, 767, 980))\n+        self.assertEqual(inputs[\"pixel_attention_mask\"].shape, (2, 2, 767, 980))\n+\n+    def test_process_interleaved_images_prompts_image_error(self):\n+        processor = self.get_processor()\n+\n+        text = [\n+            \"This is a test sentence.\",\n+            \"In this other sentence we try some good things\",\n+        ]\n+        images = [[self.image1], [self.image2]]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+        images = [[self.image1], []]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+\n+        text = [\n+            \"This is a test sentence.<image>\",\n+            \"In this other sentence we try some good things<image>\",\n+        ]\n+        images = [[self.image1], [self.image2, self.image3]]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+        images = [[], [self.image2]]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+        images = [self.image1, self.image2, self.image3]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+        images = [self.image1]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+\n+        text = [\n+            \"This is a test sentence.\",\n+            \"In this other sentence we try some good things<image>\",\n+        ]\n+        images = [[self.image1], []]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+        images = [[], [self.image2]]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+        images = [self.image1, self.image2]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+        images = [self.image1]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+\n     def test_apply_chat_template(self):\n         # Message contains content which a mix of lists with images and image urls and string\n         messages = [\n@@ -275,13 +342,3 @@ def prepare_text_inputs(self, batch_size: Optional[int] = None):\n         return [\"lower newer <image>\", \"<image> upper older longer string\"] + [\"<image> lower newer\"] * (\n             batch_size - 2\n         )\n-\n-    # Override as PixtralProcessor needs nested images to work properly with batched inputs\n-    @require_vision\n-    def prepare_image_inputs(self, batch_size: Optional[int] = None):\n-        \"\"\"This function prepares a list of PIL images for testing\"\"\"\n-        if batch_size is None:\n-            return super().prepare_image_inputs()\n-        if batch_size < 1:\n-            raise ValueError(\"batch_size must be greater than 0\")\n-        return [[super().prepare_image_inputs()]] * batch_size"
        },
        {
            "sha": "52d2f1539a486722b20252dd2a1bff1b5957ad25",
            "filename": "tests/models/idefics3/test_processor_idefics3.py",
            "status": "modified",
            "additions": 69,
            "deletions": 10,
            "changes": 79,
            "blob_url": "https://github.com/huggingface/transformers/blob/940a6bd343cfd2ff4f4425b4cbc548d1e1d316da/tests%2Fmodels%2Fidefics3%2Ftest_processor_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/940a6bd343cfd2ff4f4425b4cbc548d1e1d316da/tests%2Fmodels%2Fidefics3%2Ftest_processor_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fidefics3%2Ftest_processor_idefics3.py?ref=940a6bd343cfd2ff4f4425b4cbc548d1e1d316da",
            "patch": "@@ -250,6 +250,74 @@ def test_add_special_tokens_processor(self):\n         self.assertEqual(inputs[\"input_ids\"], expected_input_ids)\n         # fmt: on\n \n+    def test_non_nested_images_with_batched_text(self):\n+        processor = self.get_processor()\n+        processor.image_processor.do_image_splitting = False\n+\n+        image_str = \"<image>\"\n+        text_str_1 = \"In this image, we see\"\n+        text_str_2 = \"In this image, we see\"\n+\n+        text = [\n+            image_str + text_str_1,\n+            image_str + image_str + text_str_2,\n+        ]\n+        images = [self.image1, self.image2, self.image3]\n+\n+        inputs = processor(text=text, images=images, padding=True)\n+\n+        self.assertEqual(np.array(inputs[\"pixel_values\"]).shape, (2, 2, 3, 364, 364))\n+        self.assertEqual(np.array(inputs[\"pixel_attention_mask\"]).shape, (2, 2, 364, 364))\n+\n+    # Copied from tests.models.idefics2.test_processor_idefics2.Idefics2ProcessorTest.test_process_interleaved_images_prompts_image_error\n+    def test_process_interleaved_images_prompts_image_error(self):\n+        processor = self.get_processor()\n+\n+        text = [\n+            \"This is a test sentence.\",\n+            \"In this other sentence we try some good things\",\n+        ]\n+        images = [[self.image1], [self.image2]]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+        images = [[self.image1], []]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+\n+        text = [\n+            \"This is a test sentence.<image>\",\n+            \"In this other sentence we try some good things<image>\",\n+        ]\n+        images = [[self.image1], [self.image2, self.image3]]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+        images = [[], [self.image2]]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+        images = [self.image1, self.image2, self.image3]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+        images = [self.image1]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+\n+        text = [\n+            \"This is a test sentence.\",\n+            \"In this other sentence we try some good things<image>\",\n+        ]\n+        images = [[self.image1], []]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+        images = [[], [self.image2]]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+        images = [self.image1, self.image2]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+        images = [self.image1]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=images, padding=True)\n+\n     def test_apply_chat_template(self):\n         # Message contains content which a mix of lists with images and image urls and string\n         messages = [\n@@ -299,16 +367,7 @@ def prepare_text_inputs(self, batch_size: Optional[int] = None):\n             batch_size - 2\n         )\n \n-    # Override as Idefics3Processor needs nested images to work properly with batched inputs\n-    @require_vision\n-    def prepare_image_inputs(self, batch_size: Optional[int] = None):\n-        \"\"\"This function prepares a list of PIL images for testing\"\"\"\n-        if batch_size is None:\n-            return super().prepare_image_inputs()\n-        if batch_size < 1:\n-            raise ValueError(\"batch_size must be greater than 0\")\n-        return [[super().prepare_image_inputs()]] * batch_size\n-\n+    # Override tests as inputs_ids padded dimension is the second one but not the last one\n     @require_vision\n     @require_torch\n     def test_kwargs_overrides_default_tokenizer_kwargs(self):"
        }
    ],
    "stats": {
        "total": 216,
        "additions": 183,
        "deletions": 33
    }
}