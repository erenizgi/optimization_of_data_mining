{
    "author": "ChengLyu",
    "message": "Fix `past_key_values` type hint in model output types (#37953)\n\n* F: Fix type hint.\n\n* F: Use Cache type.\n\n* F: Sort import.\n\n* U: Format.\n\n* U: Address reviews.",
    "sha": "67b3d45eb6738292e1f63f159c6791bf759058de",
    "files": [
        {
            "sha": "40737bb69adfada2cb0838d4cdf6c9fa68e3ed58",
            "filename": "src/transformers/cache_utils.py",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/67b3d45eb6738292e1f63f159c6791bf759058de/src%2Ftransformers%2Fcache_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/67b3d45eb6738292e1f63f159c6791bf759058de/src%2Ftransformers%2Fcache_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcache_utils.py?ref=67b3d45eb6738292e1f63f159c6791bf759058de",
            "patch": "@@ -464,7 +464,7 @@ def get_max_cache_shape(self) -> Optional[int]:\n         \"\"\"Returns the maximum sequence length of the cache object. DynamicCache does not have a maximum length.\"\"\"\n         return None\n \n-    def to_legacy_cache(self) -> Tuple[Tuple[torch.Tensor], Tuple[torch.Tensor]]:\n+    def to_legacy_cache(self) -> Tuple[Tuple[torch.Tensor, torch.Tensor]]:\n         \"\"\"Converts the `DynamicCache` instance into the its equivalent in the legacy cache format. Used for\n         backward compatibility.\"\"\"\n         legacy_cache = ()\n@@ -473,7 +473,9 @@ def to_legacy_cache(self) -> Tuple[Tuple[torch.Tensor], Tuple[torch.Tensor]]:\n         return legacy_cache\n \n     @classmethod\n-    def from_legacy_cache(cls, past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None) -> \"DynamicCache\":\n+    def from_legacy_cache(\n+        cls, past_key_values: Optional[Tuple[Tuple[torch.FloatTensor, torch.FloatTensor]]] = None\n+    ) -> \"DynamicCache\":\n         \"\"\"Converts a cache in the legacy cache format into an equivalent `DynamicCache`. Used for\n         backward compatibility.\"\"\"\n         cache = cls()\n@@ -1505,8 +1507,8 @@ def __len__(self):\n         \"\"\"\n         return len(self.self_attention_cache)\n \n-    def to_legacy_cache(self) -> Tuple[Tuple[torch.Tensor], Tuple[torch.Tensor]]:\n-        \"\"\"Converts the `EncoderDecoderCache` instance into  its equivalent in the legacy cache format.\"\"\"\n+    def to_legacy_cache(self) -> Tuple[Tuple[torch.Tensor]]:\n+        \"\"\"Converts the `EncoderDecoderCache` instance into its equivalent in the legacy cache format.\"\"\"\n         legacy_cache = ()\n         if len(self.cross_attention_cache) > 0:\n             for self_attn, cross_attn in zip("
        },
        {
            "sha": "972db718f61d5108291874e349f2b9db066a385d",
            "filename": "src/transformers/modeling_outputs.py",
            "status": "modified",
            "additions": 58,
            "deletions": 96,
            "changes": 154,
            "blob_url": "https://github.com/huggingface/transformers/blob/67b3d45eb6738292e1f63f159c6791bf759058de/src%2Ftransformers%2Fmodeling_outputs.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/67b3d45eb6738292e1f63f159c6791bf759058de/src%2Ftransformers%2Fmodeling_outputs.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_outputs.py?ref=67b3d45eb6738292e1f63f159c6791bf759058de",
            "patch": "@@ -18,6 +18,7 @@\n \n import torch\n \n+from .cache_utils import Cache, EncoderDecoderCache\n from .utils import ModelOutput\n \n \n@@ -131,11 +132,8 @@ class BaseModelOutputWithPast(ModelOutput):\n \n             If `past_key_values` is used only the last hidden-state of the sequences of shape `(batch_size, 1,\n             hidden_size)` is output.\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and optionally if\n-            `config.is_encoder_decoder=True` 2 additional tensors of shape `(batch_size, num_heads,\n-            encoder_sequence_length, embed_size_per_head)`.\n+        past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks and optionally if\n             `config.is_encoder_decoder=True` in the cross-attention blocks) that can be used (see `past_key_values`\n@@ -154,7 +152,7 @@ class BaseModelOutputWithPast(ModelOutput):\n     \"\"\"\n \n     last_hidden_state: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[Cache] = None\n     hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n \n@@ -222,11 +220,8 @@ class BaseModelOutputWithPoolingAndCrossAttentions(ModelOutput):\n \n             Attentions weights of the decoder's cross-attention layer, after the attention softmax, used to compute the\n             weighted average in the cross-attention heads.\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and optionally if\n-            `config.is_encoder_decoder=True` 2 additional tensors of shape `(batch_size, num_heads,\n-            encoder_sequence_length, embed_size_per_head)`.\n+        past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks and optionally if\n             `config.is_encoder_decoder=True` in the cross-attention blocks) that can be used (see `past_key_values`\n@@ -236,7 +231,7 @@ class BaseModelOutputWithPoolingAndCrossAttentions(ModelOutput):\n     last_hidden_state: Optional[torch.FloatTensor] = None\n     pooler_output: Optional[torch.FloatTensor] = None\n     hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[Cache] = None\n     attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     cross_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n \n@@ -252,11 +247,8 @@ class BaseModelOutputWithPastAndCrossAttentions(ModelOutput):\n \n             If `past_key_values` is used only the last hidden-state of the sequences of shape `(batch_size, 1,\n             hidden_size)` is output.\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and optionally if\n-            `config.is_encoder_decoder=True` 2 additional tensors of shape `(batch_size, num_heads,\n-            encoder_sequence_length, embed_size_per_head)`.\n+        past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks and optionally if\n             `config.is_encoder_decoder=True` in the cross-attention blocks) that can be used (see `past_key_values`\n@@ -281,7 +273,7 @@ class BaseModelOutputWithPastAndCrossAttentions(ModelOutput):\n     \"\"\"\n \n     last_hidden_state: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[Cache] = None\n     hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     cross_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n@@ -298,9 +290,8 @@ class MoECausalLMOutputWithPast(ModelOutput):\n             Language modeling loss (for next-token prediction).\n         logits (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`):\n             Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`)\n+        past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks) that can be used (see\n             `past_key_values` input) to speed up sequential decoding.\n@@ -328,7 +319,7 @@ class MoECausalLMOutputWithPast(ModelOutput):\n \n     loss: Optional[torch.FloatTensor] = None\n     logits: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[Cache] = None\n     hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     z_loss: Optional[torch.FloatTensor] = None\n@@ -376,11 +367,8 @@ class MoeModelOutputWithPast(ModelOutput):\n     Args:\n         last_hidden_state (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`):\n             Sequence of hidden-states at the output of the last layer of the model.\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and optionally if\n-            `config.is_encoder_decoder=True` 2 additional tensors of shape `(batch_size, num_heads,\n-            encoder_sequence_length, embed_size_per_head)`.\n+        past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks and optionally if\n             `config.is_encoder_decoder=True` in the cross-attention blocks) that can be used (see `past_key_values`\n@@ -404,7 +392,7 @@ class MoeModelOutputWithPast(ModelOutput):\n     \"\"\"\n \n     last_hidden_state: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[Cache] = None\n     hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     router_logits: Optional[Tuple[torch.FloatTensor]] = None\n@@ -431,9 +419,8 @@ class MoeCausalLMOutputWithPast(ModelOutput):\n             Raw router logtis (post-softmax) that are computed by MoE routers, these terms are used to compute the auxiliary\n             loss for Mixture of Experts models.\n \n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`)\n+        past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks) that can be used (see\n             `past_key_values` input) to speed up sequential decoding.\n@@ -453,7 +440,7 @@ class MoeCausalLMOutputWithPast(ModelOutput):\n     loss: Optional[torch.FloatTensor] = None\n     aux_loss: Optional[torch.FloatTensor] = None\n     logits: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[Cache] = None\n     hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     router_logits: Optional[Tuple[torch.FloatTensor]] = None\n@@ -471,11 +458,8 @@ class MoEModelOutputWithPastAndCrossAttentions(ModelOutput):\n \n             If `past_key_values` is used only the last hidden-state of the sequences of shape `(batch_size, 1,\n             hidden_size)` is output.\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and optionally if\n-            `config.is_encoder_decoder=True` 2 additional tensors of shape `(batch_size, num_heads,\n-            encoder_sequence_length, embed_size_per_head)`.\n+        past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks and optionally if\n             `config.is_encoder_decoder=True` in the cross-attention blocks) that can be used (see `past_key_values`\n@@ -505,7 +489,7 @@ class MoEModelOutputWithPastAndCrossAttentions(ModelOutput):\n     \"\"\"\n \n     last_hidden_state: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[Cache] = None\n     hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     cross_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n@@ -524,10 +508,8 @@ class Seq2SeqModelOutput(ModelOutput):\n \n             If `past_key_values` is used only the last hidden-state of the sequences of shape `(batch_size, 1,\n             hidden_size)` is output.\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape\n-            `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n+        past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.EncoderDecoderCache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\n             blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n@@ -564,7 +546,7 @@ class Seq2SeqModelOutput(ModelOutput):\n     \"\"\"\n \n     last_hidden_state: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[EncoderDecoderCache] = None\n     decoder_hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     decoder_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     cross_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n@@ -585,10 +567,8 @@ class Seq2SeqMoEModelOutput(ModelOutput):\n \n             If `past_key_values` is used only the last hidden-state of the sequences of shape `(batch_size, 1,\n             hidden_size)` is output.\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape\n-            `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n+        past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.EncoderDecoderCache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\n             blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n@@ -634,7 +614,7 @@ class Seq2SeqMoEModelOutput(ModelOutput):\n     \"\"\"\n \n     last_hidden_state: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[EncoderDecoderCache] = None\n     decoder_hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     decoder_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     decoder_router_logits: Optional[Tuple[torch.FloatTensor]] = None\n@@ -684,9 +664,8 @@ class CausalLMOutputWithPast(ModelOutput):\n             Language modeling loss (for next-token prediction).\n         logits (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`):\n             Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`)\n+        past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks) that can be used (see\n             `past_key_values` input) to speed up sequential decoding.\n@@ -705,7 +684,7 @@ class CausalLMOutputWithPast(ModelOutput):\n \n     loss: Optional[torch.FloatTensor] = None\n     logits: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[Cache] = None\n     hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n \n@@ -737,18 +716,16 @@ class CausalLMOutputWithCrossAttentions(ModelOutput):\n \n             Cross attentions weights after the attention softmax, used to compute the weighted average in the\n             cross-attention heads.\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `torch.FloatTensor` tuples of length `config.n_layers`, with each tuple containing the cached key,\n-            value states of the self-attention and the cross-attention layers if model is used in encoder-decoder\n-            setting. Only relevant if `config.is_decoder = True`.\n+        past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the attention blocks) that can be used (see\n             `past_key_values` input) to speed up sequential decoding.\n     \"\"\"\n \n     loss: Optional[torch.FloatTensor] = None\n     logits: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[Cache] = None\n     hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     cross_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n@@ -764,9 +741,8 @@ class SequenceClassifierOutputWithPast(ModelOutput):\n             Classification (or regression if config.num_labels==1) loss.\n         logits (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`):\n             Classification (or regression if config.num_labels==1) scores (before SoftMax).\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`)\n+        past_key_values (`Cache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.Cache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks) that can be used (see\n             `past_key_values` input) to speed up sequential decoding.\n@@ -785,7 +761,7 @@ class SequenceClassifierOutputWithPast(ModelOutput):\n \n     loss: Optional[torch.FloatTensor] = None\n     logits: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[Cache] = None\n     hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n \n@@ -829,10 +805,8 @@ class Seq2SeqLMOutput(ModelOutput):\n             Language modeling loss.\n         logits (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`):\n             Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape\n-            `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n+        past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.EncoderDecoderCache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\n             blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n@@ -870,7 +844,7 @@ class Seq2SeqLMOutput(ModelOutput):\n \n     loss: Optional[torch.FloatTensor] = None\n     logits: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[EncoderDecoderCache] = None\n     decoder_hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     decoder_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     cross_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n@@ -889,10 +863,8 @@ class Seq2SeqMoEOutput(ModelOutput):\n             Language modeling loss.\n         logits (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`):\n             Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape\n-            `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n+        past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.EncoderDecoderCache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\n             blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n@@ -943,7 +915,7 @@ class Seq2SeqMoEOutput(ModelOutput):\n     decoder_z_loss: Optional[torch.FloatTensor] = None\n     encoder_aux_loss: Optional[torch.FloatTensor] = None\n     decoder_aux_loss: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[EncoderDecoderCache] = None\n     decoder_hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     decoder_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     decoder_router_logits: Optional[Tuple[torch.FloatTensor]] = None\n@@ -1023,10 +995,8 @@ class Seq2SeqSequenceClassifierOutput(ModelOutput):\n             Classification (or regression if config.num_labels==1) loss.\n         logits (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`):\n             Classification (or regression if config.num_labels==1) scores (before SoftMax).\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape\n-            `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n+        past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.EncoderDecoderCache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\n             blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n@@ -1064,7 +1034,7 @@ class Seq2SeqSequenceClassifierOutput(ModelOutput):\n \n     loss: Optional[torch.FloatTensor] = None\n     logits: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[EncoderDecoderCache] = None\n     decoder_hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     decoder_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     cross_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n@@ -1177,10 +1147,8 @@ class Seq2SeqQuestionAnsweringModelOutput(ModelOutput):\n             Span-start scores (before SoftMax).\n         end_logits (`torch.FloatTensor` of shape `(batch_size, sequence_length)`):\n             Span-end scores (before SoftMax).\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape\n-            `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n+        past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.EncoderDecoderCache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\n             blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n@@ -1219,7 +1187,7 @@ class Seq2SeqQuestionAnsweringModelOutput(ModelOutput):\n     loss: Optional[torch.FloatTensor] = None\n     start_logits: Optional[torch.FloatTensor] = None\n     end_logits: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[EncoderDecoderCache] = None\n     decoder_hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     decoder_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     cross_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n@@ -1508,10 +1476,8 @@ class Seq2SeqSpectrogramOutput(ModelOutput):\n             Spectrogram generation loss.\n         spectrogram (`torch.FloatTensor` of shape `(batch_size, sequence_length, num_bins)`):\n             The predicted spectrogram.\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape\n-            `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n+        past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.EncoderDecoderCache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\n             blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n@@ -1549,7 +1515,7 @@ class Seq2SeqSpectrogramOutput(ModelOutput):\n \n     loss: Optional[torch.FloatTensor] = None\n     spectrogram: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[EncoderDecoderCache] = None\n     decoder_hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     decoder_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     cross_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n@@ -1570,10 +1536,8 @@ class Seq2SeqTSModelOutput(ModelOutput):\n \n             If `past_key_values` is used only the last hidden-state of the sequences of shape `(batch_size, 1,\n             hidden_size)` is output.\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape\n-            `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n+        past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.EncoderDecoderCache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\n             blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n@@ -1618,7 +1582,7 @@ class Seq2SeqTSModelOutput(ModelOutput):\n     \"\"\"\n \n     last_hidden_state: Optional[torch.FloatTensor] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[EncoderDecoderCache] = None\n     decoder_hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     decoder_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     cross_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n@@ -1641,10 +1605,8 @@ class Seq2SeqTSPredictionOutput(ModelOutput):\n             Distributional loss.\n         params (`torch.FloatTensor` of shape `(batch_size, num_samples, num_params)`):\n             Parameters of the chosen distribution.\n-        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n-            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n-            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape\n-            `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n+        past_key_values (`EncoderDecoderCache`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n+            It is a [`~cache_utils.EncoderDecoderCache`] instance. For more details, see our [kv cache guide](https://huggingface.co/docs/transformers/en/kv_cache).\n \n             Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\n             blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n@@ -1690,7 +1652,7 @@ class Seq2SeqTSPredictionOutput(ModelOutput):\n \n     loss: Optional[torch.FloatTensor] = None\n     params: Optional[Tuple[torch.FloatTensor]] = None\n-    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n+    past_key_values: Optional[EncoderDecoderCache] = None\n     decoder_hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n     decoder_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n     cross_attentions: Optional[Tuple[torch.FloatTensor, ...]] = None"
        }
    ],
    "stats": {
        "total": 164,
        "additions": 64,
        "deletions": 100
    }
}