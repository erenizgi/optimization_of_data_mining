{
    "author": "IlyasMoutawwakil",
    "message": "Only count num items in batch when needed (#36867)\n\nonly count num itels when needed",
    "sha": "60b75d99b682ef8e3dca203c01f78df0481438ed",
    "files": [
        {
            "sha": "a00eec8b8260b8857cdb2322b83c7c9458df0ae7",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 18,
            "deletions": 2,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/60b75d99b682ef8e3dca203c01f78df0481438ed/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/60b75d99b682ef8e3dca203c01f78df0481438ed/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=60b75d99b682ef8e3dca203c01f78df0481438ed",
            "patch": "@@ -5232,13 +5232,29 @@ def _fsdp_qlora_plugin_updates(self):\n     def get_batch_samples(self, epoch_iterator, num_batches, device):\n         batch_samples = []\n         num_items_in_batch = None\n+\n         for _ in range(num_batches):\n             try:\n-                batch_samples += [next(epoch_iterator)]\n+                batch_samples.append(next(epoch_iterator))\n             except StopIteration:\n                 break\n \n-        if len(batch_samples) > 0 and \"labels\" in batch_samples[0]:\n+        count_num_items_in_batch = (\n+            len(batch_samples) > 0\n+            and \"labels\" in batch_samples[0]\n+            and (\n+                # num_items_in_batch is passed to model forward\n+                # https://github.com/huggingface/transformers/blob/v4.49.0/src/transformers/trainer.py#L3757\n+                self.model_accepts_loss_kwargs\n+                # num_items_in_batch is passed to compute_loss_func\n+                # https://github.com/huggingface/transformers/blob/v4.49.0/src/transformers/trainer.py#L3773\n+                or self.compute_loss_func is not None\n+                # num_items_in_batch is also verified if (self.model_accepts_loss_kwargs or self.compute_loss_func)\n+                # https://github.com/huggingface/transformers/blob/v4.49.0/src/transformers/trainer.py#L3790\n+            )\n+        )\n+\n+        if count_num_items_in_batch:\n             # For now we don't support object detection\n             try:\n                 num_items_in_batch = sum([(batch[\"labels\"].ne(-100)).sum() for batch in batch_samples])"
        }
    ],
    "stats": {
        "total": 20,
        "additions": 18,
        "deletions": 2
    }
}