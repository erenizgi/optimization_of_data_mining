{
    "author": "ydshieh",
    "message": "Fix `SeamlessM4Tv2ModelWithTextInputTest::test_retain_grad_hidden_states_attentions` (#40532)\n\n* fix\n\n* fix\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "008c0ba8e2a1226a6ef5a61c4915a0a8a340c157",
    "files": [
        {
            "sha": "cedbfe42330db72060009feb0f8344088867a812",
            "filename": "tests/models/seamless_m4t_v2/test_modeling_seamless_m4t_v2.py",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/008c0ba8e2a1226a6ef5a61c4915a0a8a340c157/tests%2Fmodels%2Fseamless_m4t_v2%2Ftest_modeling_seamless_m4t_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/008c0ba8e2a1226a6ef5a61c4915a0a8a340c157/tests%2Fmodels%2Fseamless_m4t_v2%2Ftest_modeling_seamless_m4t_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fseamless_m4t_v2%2Ftest_modeling_seamless_m4t_v2.py?ref=008c0ba8e2a1226a6ef5a61c4915a0a8a340c157",
            "patch": "@@ -76,6 +76,9 @@ def __init__(\n         decoder_layers=2,\n         encoder_ffn_dim=6,\n         decoder_ffn_dim=6,\n+        encoder_layerdrop=0.0,\n+        speech_encoder_layerdrop=0.0,\n+        decoder_layerdrop=0.0,\n         t2u_encoder_layers=2,\n         t2u_decoder_layers=2,\n         t2u_encoder_ffn_dim=6,\n@@ -154,6 +157,10 @@ def __init__(\n         self.speech_encoder_chunk_size = speech_encoder_chunk_size\n         self.speech_encoder_left_chunk_num = speech_encoder_left_chunk_num\n \n+        self.encoder_layerdrop = encoder_layerdrop\n+        self.speech_encoder_layerdrop = speech_encoder_layerdrop\n+        self.decoder_layerdrop = decoder_layerdrop\n+\n     def prepare_config_and_inputs(self):\n         if self.input_modality == \"text\":\n             inputs = ids_tensor([self.batch_size, self.seq_length], self.vocab_size - 1)\n@@ -218,6 +225,9 @@ def get_config(self):\n             right_max_position_embeddings=self.right_max_position_embeddings,\n             speech_encoder_chunk_size=self.speech_encoder_chunk_size,\n             speech_encoder_left_chunk_num=self.speech_encoder_left_chunk_num,\n+            encoder_layerdrop=self.encoder_layerdrop,\n+            speech_encoder_layerdrop=self.speech_encoder_layerdrop,\n+            decoder_layerdrop=self.decoder_layerdrop,\n         )\n \n     def prepare_config_and_inputs_for_decoder(self):"
        }
    ],
    "stats": {
        "total": 10,
        "additions": 10,
        "deletions": 0
    }
}