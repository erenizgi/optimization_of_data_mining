{
    "author": "douglas-reid",
    "message": "Fix rope_parameters for gemma3 weights conversion script (#41922)\n\nFix rope_parameters for gemma3 weights conversion script.\n\nCo-authored-by: Douglas Reid <21148125+douglas-reid@users.noreply.github.com>",
    "sha": "b47b35637f5c0c0a6f4b7563072a36c083fb4159",
    "files": [
        {
            "sha": "2129d04a362c27750d5c20fe691818c6c1c295c0",
            "filename": "src/transformers/models/gemma3/convert_gemma3_weights.py",
            "status": "modified",
            "additions": 12,
            "deletions": 3,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/b47b35637f5c0c0a6f4b7563072a36c083fb4159/src%2Ftransformers%2Fmodels%2Fgemma3%2Fconvert_gemma3_weights.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b47b35637f5c0c0a6f4b7563072a36c083fb4159/src%2Ftransformers%2Fmodels%2Fgemma3%2Fconvert_gemma3_weights.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma3%2Fconvert_gemma3_weights.py?ref=b47b35637f5c0c0a6f4b7563072a36c083fb4159",
            "patch": "@@ -191,7 +191,10 @@\n             num_hidden_layers=34,\n             num_key_value_heads=4,\n             sliding_window=1024,\n-            rope_parameters={\"rope_type\": \"linear\", \"factor\": 8.0},  # used for global RoPE only\n+            rope_parameters={\n+                \"full_attention\": {\"rope_type\": \"linear\", \"factor\": 8.0},\n+                \"sliding_attention\": {\"rope_type\": \"default\"},\n+            },\n             rope_theta=1_000_000,\n             rope_local_base_freq=10_000,\n             attn_logit_softcapping=None,\n@@ -209,7 +212,10 @@\n             num_hidden_layers=48,\n             num_key_value_heads=8,\n             sliding_window=1024,\n-            rope_parameters={\"rope_type\": \"linear\", \"factor\": 8.0},  # used for global RoPE only\n+            rope_parameters={\n+                \"full_attention\": {\"rope_type\": \"linear\", \"factor\": 8.0},\n+                \"sliding_attention\": {\"rope_type\": \"default\"},\n+            },\n             rope_theta=1_000_000,\n             rope_local_base_freq=10_000,\n             attn_logit_softcapping=None,\n@@ -227,7 +233,10 @@\n             num_key_value_heads=16,\n             head_dim=128,\n             sliding_window=1024,\n-            rope_parameters={\"rope_type\": \"linear\", \"factor\": 8.0},  # used for global RoPE only\n+            rope_parameters={\n+                \"full_attention\": {\"rope_type\": \"linear\", \"factor\": 8.0},\n+                \"sliding_attention\": {\"rope_type\": \"default\"},\n+            },\n             rope_theta=1_000_000,\n             rope_local_base_freq=10_000,\n             attn_logit_softcapping=None,"
        }
    ],
    "stats": {
        "total": 15,
        "additions": 12,
        "deletions": 3
    }
}