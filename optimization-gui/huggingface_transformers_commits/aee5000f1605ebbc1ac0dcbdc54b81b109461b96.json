{
    "author": "ebezzam",
    "message": "Fix Bark failing tests (#39478)\n\n* Fix vocab size for Bark generation.\n\n* Fix Bark processor tests.\n\n* Fix style.\n\n* Address comments.\n\n* Fix formatting.\n\n---------\n\nCo-authored-by: eustlb <94853470+eustlb@users.noreply.github.com>",
    "sha": "aee5000f1605ebbc1ac0dcbdc54b81b109461b96",
    "files": [
        {
            "sha": "227a84dd1d06d0126c6f995004588242cb0ecae7",
            "filename": "src/transformers/generation/utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/aee5000f1605ebbc1ac0dcbdc54b81b109461b96/src%2Ftransformers%2Fgeneration%2Futils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aee5000f1605ebbc1ac0dcbdc54b81b109461b96/src%2Ftransformers%2Fgeneration%2Futils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Futils.py?ref=aee5000f1605ebbc1ac0dcbdc54b81b109461b96",
            "patch": "@@ -3158,6 +3158,8 @@ def _beam_search(\n             vocab_size = self.config.audio_vocab_size\n         elif self.__class__.__name__ == \"ImageGPTForCausalImageModeling\":\n             vocab_size = self.get_output_embeddings().out_features\n+        elif self.__class__.__name__ == \"BarkSemanticModel\":\n+            vocab_size = self.config.output_vocab_size\n         else:\n             vocab_size = self.config.get_text_config().vocab_size\n         decoder_prompt_len = cur_len"
        },
        {
            "sha": "155f15cced201b57835fc3037c4f1dfb4a110ffa",
            "filename": "src/transformers/models/bark/processing_bark.py",
            "status": "modified",
            "additions": 60,
            "deletions": 18,
            "changes": 78,
            "blob_url": "https://github.com/huggingface/transformers/blob/aee5000f1605ebbc1ac0dcbdc54b81b109461b96/src%2Ftransformers%2Fmodels%2Fbark%2Fprocessing_bark.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aee5000f1605ebbc1ac0dcbdc54b81b109461b96/src%2Ftransformers%2Fmodels%2Fbark%2Fprocessing_bark.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbark%2Fprocessing_bark.py?ref=aee5000f1605ebbc1ac0dcbdc54b81b109461b96",
            "patch": "@@ -53,9 +53,9 @@ class BarkProcessor(ProcessorMixin):\n     attributes = [\"tokenizer\"]\n \n     preset_shape = {\n-        \"semantic_prompt\": 1,\n-        \"coarse_prompt\": 2,\n-        \"fine_prompt\": 2,\n+        \"semantic_prompt\": 1,  # 1D array of shape (X,)\n+        \"coarse_prompt\": 2,  # 2D array of shape (2,X)\n+        \"fine_prompt\": 2,  # 2D array of shape (8,X)\n     }\n \n     def __init__(self, tokenizer, speaker_embeddings=None):\n@@ -115,6 +115,9 @@ def from_pretrained(\n         else:\n             speaker_embeddings = None\n \n+        if speaker_embeddings is not None:\n+            if \"repo_or_path\" in speaker_embeddings:\n+                speaker_embeddings[\"repo_or_path\"] = pretrained_processor_name_or_path\n         tokenizer = AutoTokenizer.from_pretrained(pretrained_processor_name_or_path, **kwargs)\n \n         return cls(tokenizer=tokenizer, speaker_embeddings=speaker_embeddings)\n@@ -154,22 +157,21 @@ def save_pretrained(\n \n             embeddings_dict[\"repo_or_path\"] = save_directory\n \n-            for prompt_key in self.speaker_embeddings:\n-                if prompt_key != \"repo_or_path\":\n-                    voice_preset = self._load_voice_preset(prompt_key)\n+            for prompt_key in self.available_voice_presets:\n+                voice_preset = self._load_voice_preset(prompt_key)\n \n-                    tmp_dict = {}\n-                    for key in self.speaker_embeddings[prompt_key]:\n-                        np.save(\n-                            os.path.join(\n-                                embeddings_dict[\"repo_or_path\"], speaker_embeddings_directory, f\"{prompt_key}_{key}\"\n-                            ),\n-                            voice_preset[key],\n-                            allow_pickle=False,\n-                        )\n-                        tmp_dict[key] = os.path.join(speaker_embeddings_directory, f\"{prompt_key}_{key}.npy\")\n+                tmp_dict = {}\n+                for key in self.speaker_embeddings[prompt_key]:\n+                    np.save(\n+                        os.path.join(\n+                            embeddings_dict[\"repo_or_path\"], speaker_embeddings_directory, f\"{prompt_key}_{key}\"\n+                        ),\n+                        voice_preset[key],\n+                        allow_pickle=False,\n+                    )\n+                    tmp_dict[key] = os.path.join(speaker_embeddings_directory, f\"{prompt_key}_{key}.npy\")\n \n-                    embeddings_dict[prompt_key] = tmp_dict\n+                embeddings_dict[prompt_key] = tmp_dict\n \n             with open(os.path.join(save_directory, speaker_embeddings_dict_path), \"w\") as fp:\n                 json.dump(embeddings_dict, fp)\n@@ -223,6 +225,45 @@ def _validate_voice_preset_dict(self, voice_preset: Optional[dict] = None):\n             if len(voice_preset[key].shape) != self.preset_shape[key]:\n                 raise ValueError(f\"{key} voice preset must be a {str(self.preset_shape[key])}D ndarray.\")\n \n+    @property\n+    def available_voice_presets(self) -> list:\n+        \"\"\"\n+        Returns a list of available voice presets.\n+\n+        Returns:\n+            `list[str]`: A list of voice preset names.\n+        \"\"\"\n+        if self.speaker_embeddings is None:\n+            return []\n+\n+        voice_presets = list(self.speaker_embeddings.keys())\n+        if \"repo_or_path\" in voice_presets:\n+            voice_presets.remove(\"repo_or_path\")\n+        return voice_presets\n+\n+    def _verify_speaker_embeddings(self, remove_unavailable: bool = True):\n+        # check which actually downloaded properly / are available\n+        unavailable_keys = []\n+        if self.speaker_embeddings is not None:\n+            for voice_preset in self.available_voice_presets:\n+                try:\n+                    voice_preset_dict = self._load_voice_preset(voice_preset)\n+                except ValueError:\n+                    # error from `_load_voice_preset` of path not existing\n+                    unavailable_keys.append(voice_preset)\n+                    continue\n+                self._validate_voice_preset_dict(voice_preset_dict)\n+\n+            if unavailable_keys:\n+                logger.warning(\n+                    f\"The following {len(unavailable_keys)} speaker embeddings are not available: {unavailable_keys} \"\n+                    \"If you would like to use them, please check the paths or try downloading them again.\"\n+                )\n+\n+            if remove_unavailable:\n+                for voice_preset in unavailable_keys:\n+                    del self.speaker_embeddings[voice_preset]\n+\n     def __call__(\n         self,\n         text=None,\n@@ -248,7 +289,8 @@ def __call__(\n             voice_preset (`str`, `dict[np.ndarray]`):\n                 The voice preset, i.e the speaker embeddings. It can either be a valid voice_preset name, e.g\n                 `\"en_speaker_1\"`, or directly a dictionary of `np.ndarray` embeddings for each submodel of `Bark`. Or\n-                it can be a valid file name of a local `.npz` single voice preset.\n+                it can be a valid file name of a local `.npz` single voice preset containing the keys\n+                `\"semantic_prompt\"`, `\"coarse_prompt\"` and `\"fine_prompt\"`.\n             return_tensors (`str` or [`~utils.TensorType`], *optional*):\n                 If set, will return tensors of a particular framework. Acceptable values are:\n "
        },
        {
            "sha": "e20c3b302f33d9208998cd832989a0354d450f5a",
            "filename": "tests/models/bark/test_processing_bark.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/aee5000f1605ebbc1ac0dcbdc54b81b109461b96/tests%2Fmodels%2Fbark%2Ftest_processing_bark.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aee5000f1605ebbc1ac0dcbdc54b81b109461b96/tests%2Fmodels%2Fbark%2Ftest_processing_bark.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbark%2Ftest_processing_bark.py?ref=aee5000f1605ebbc1ac0dcbdc54b81b109461b96",
            "patch": "@@ -55,6 +55,13 @@ def test_save_load_pretrained_additional_features(self):\n             pretrained_processor_name_or_path=self.checkpoint,\n             speaker_embeddings_dict_path=self.speaker_embeddings_dict_path,\n         )\n+\n+        # TODO (ebezzam) not all speaker embedding are properly downloaded.\n+        # My hypothesis: there are many files (~700 speaker embeddings) and some fail to download (not the same at different first runs)\n+        # https://github.com/huggingface/transformers/blob/967045082faaaaf3d653bfe665080fd746b2bb60/src/transformers/models/bark/processing_bark.py#L89\n+        # https://github.com/huggingface/transformers/blob/967045082faaaaf3d653bfe665080fd746b2bb60/src/transformers/models/bark/processing_bark.py#L188\n+        # So for testing purposes, we will remove the unavailable speaker embeddings before saving.\n+        processor._verify_speaker_embeddings(remove_unavailable=True)\n         processor.save_pretrained(\n             self.tmpdirname,\n             speaker_embeddings_dict_path=self.speaker_embeddings_dict_path,"
        }
    ],
    "stats": {
        "total": 87,
        "additions": 69,
        "deletions": 18
    }
}