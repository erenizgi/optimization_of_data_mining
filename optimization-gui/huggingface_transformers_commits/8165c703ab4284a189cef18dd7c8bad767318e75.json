{
    "author": "Cyrilvallez",
    "message": "Fix Lfm2 and common tests (#39398)\n\n* fix\n\n* better fix\n\n* typo",
    "sha": "8165c703ab4284a189cef18dd7c8bad767318e75",
    "files": [
        {
            "sha": "7921fcbf1560cdb8ef83ad442087dea9e6106bad",
            "filename": "tests/models/lfm2/test_modeling_lfm2.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/8165c703ab4284a189cef18dd7c8bad767318e75/tests%2Fmodels%2Flfm2%2Ftest_modeling_lfm2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8165c703ab4284a189cef18dd7c8bad767318e75/tests%2Fmodels%2Flfm2%2Ftest_modeling_lfm2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flfm2%2Ftest_modeling_lfm2.py?ref=8165c703ab4284a189cef18dd7c8bad767318e75",
            "patch": "@@ -85,6 +85,12 @@ def test_contrastive_generate_dict_outputs_use_cache(self):\n     def test_contrastive_generate_low_memory(self):\n         pass\n \n+    @unittest.skip(\n+        \"Lfm2 has a special cache format which is not compatible with compile as it has static address for conv cache\"\n+    )\n+    def test_sdpa_can_compile_dynamic(self):\n+        pass\n+\n \n @require_torch_accelerator\n @require_read_token"
        },
        {
            "sha": "2550af422736c121f888b0559e70e9f6183ef5d0",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/8165c703ab4284a189cef18dd7c8bad767318e75/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8165c703ab4284a189cef18dd7c8bad767318e75/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=8165c703ab4284a189cef18dd7c8bad767318e75",
            "patch": "@@ -4484,6 +4484,7 @@ def test_torch_compile_for_training(self):\n             ),\n             \"position_ids\": torch.arange(0, 10, device=torch_device).unsqueeze(0),\n             \"labels\": torch.randint(low=1, high=model.config.vocab_size, size=(2, 10), device=torch_device),\n+            \"use_cache\": False,\n         }\n \n         # eager backward"
        }
    ],
    "stats": {
        "total": 7,
        "additions": 7,
        "deletions": 0
    }
}