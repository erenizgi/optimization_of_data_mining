{
    "author": "SunMarc",
    "message": "[serve] fix ` request_id` unexpected (#40501)\n\n* fix request-id in serving\n\n* style\n\n* fix",
    "sha": "8acbbdcadfc1becf14e674ab9d5cad795b510640",
    "files": [
        {
            "sha": "7d73fa80c1383ba6b6b29c7199c84f13aba97657",
            "filename": "src/transformers/commands/chat.py",
            "status": "modified",
            "additions": 2,
            "deletions": 6,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/8acbbdcadfc1becf14e674ab9d5cad795b510640/src%2Ftransformers%2Fcommands%2Fchat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8acbbdcadfc1becf14e674ab9d5cad795b510640/src%2Ftransformers%2Fcommands%2Fchat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fchat.py?ref=8acbbdcadfc1becf14e674ab9d5cad795b510640",
            "patch": "@@ -129,7 +129,6 @@ async def stream_output(self, stream: AsyncIterator[ChatCompletionStreamOutput])\n             text = \"\"\n             async for token in await stream:\n                 outputs = token.choices[0].delta.content\n-                request_id = token.id\n \n                 if not outputs:\n                     continue\n@@ -168,7 +167,7 @@ async def stream_output(self, stream: AsyncIterator[ChatCompletionStreamOutput])\n \n         self._console.print()\n \n-        return text, request_id\n+        return text\n \n     def input(self) -> str:\n         \"\"\"Gets user input from the console.\"\"\"\n@@ -700,8 +699,6 @@ async def _inner_run(self):\n         interface.clear()\n         chat = self.clear_chat_history(args.system_prompt)\n \n-        request_id = None\n-\n         # Starts the session with a minimal help message at the top, so that a user doesn't get stuck\n         interface.print_help(minimal=True)\n         while True:\n@@ -733,13 +730,12 @@ async def _inner_run(self):\n                     chat,\n                     stream=True,\n                     extra_body={\n-                        \"request_id\": request_id,\n                         \"generation_config\": generation_config.to_json_string(),\n                         \"model\": model,\n                     },\n                 )\n \n-                model_output, request_id = await interface.stream_output(stream)\n+                model_output = await interface.stream_output(stream)\n \n                 chat.append({\"role\": \"assistant\", \"content\": model_output})\n "
        }
    ],
    "stats": {
        "total": 8,
        "additions": 2,
        "deletions": 6
    }
}