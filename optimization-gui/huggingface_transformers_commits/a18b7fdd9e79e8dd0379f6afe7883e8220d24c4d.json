{
    "author": "Rocketknight1",
    "message": "Move audio top_k tests to the right file and add slow decorator (#36072)\n\n* Move audio top_k tests to the right file and add slow decorator because we load a real model\r\n\r\n* empty commit to trigger tests",
    "sha": "a18b7fdd9e79e8dd0379f6afe7883e8220d24c4d",
    "files": [
        {
            "sha": "a552b79634be439021193c63b39b89721ea32d29",
            "filename": "tests/pipelines/test_pipelines_audio_classification.py",
            "status": "modified",
            "additions": 57,
            "deletions": 0,
            "changes": 57,
            "blob_url": "https://github.com/huggingface/transformers/blob/a18b7fdd9e79e8dd0379f6afe7883e8220d24c4d/tests%2Fpipelines%2Ftest_pipelines_audio_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a18b7fdd9e79e8dd0379f6afe7883e8220d24c4d/tests%2Fpipelines%2Ftest_pipelines_audio_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_audio_classification.py?ref=a18b7fdd9e79e8dd0379f6afe7883e8220d24c4d",
            "patch": "@@ -188,3 +188,60 @@ def test_large_model_pt(self):\n     @unittest.skip(reason=\"Audio classification is not implemented for TF\")\n     def test_small_model_tf(self):\n         pass\n+\n+    @require_torch\n+    @slow\n+    def test_top_k_none_returns_all_labels(self):\n+        model_name = \"superb/wav2vec2-base-superb-ks\"  # model with more than 5 labels\n+        classification_pipeline = pipeline(\n+            \"audio-classification\",\n+            model=model_name,\n+            top_k=None,\n+        )\n+\n+        # Create dummy input\n+        sampling_rate = 16000\n+        signal = np.zeros((sampling_rate,), dtype=np.float32)\n+\n+        result = classification_pipeline(signal)\n+        num_labels = classification_pipeline.model.config.num_labels\n+\n+        self.assertEqual(len(result), num_labels, \"Should return all labels when top_k is None\")\n+\n+    @require_torch\n+    @slow\n+    def test_top_k_none_with_few_labels(self):\n+        model_name = \"superb/hubert-base-superb-er\"  # model with fewer labels\n+        classification_pipeline = pipeline(\n+            \"audio-classification\",\n+            model=model_name,\n+            top_k=None,\n+        )\n+\n+        # Create dummy input\n+        sampling_rate = 16000\n+        signal = np.zeros((sampling_rate,), dtype=np.float32)\n+\n+        result = classification_pipeline(signal)\n+        num_labels = classification_pipeline.model.config.num_labels\n+\n+        self.assertEqual(len(result), num_labels, \"Should handle models with fewer labels correctly\")\n+\n+    @require_torch\n+    @slow\n+    def test_top_k_greater_than_labels(self):\n+        model_name = \"superb/hubert-base-superb-er\"\n+        classification_pipeline = pipeline(\n+            \"audio-classification\",\n+            model=model_name,\n+            top_k=100,  # intentionally large number\n+        )\n+\n+        # Create dummy input\n+        sampling_rate = 16000\n+        signal = np.zeros((sampling_rate,), dtype=np.float32)\n+\n+        result = classification_pipeline(signal)\n+        num_labels = classification_pipeline.model.config.num_labels\n+\n+        self.assertEqual(len(result), num_labels, \"Should cap top_k to number of labels\")"
        },
        {
            "sha": "9911bd732343a72e4110f4a7828673b502201378",
            "filename": "tests/test_audio_classification_top_k.py",
            "status": "removed",
            "additions": 0,
            "deletions": 60,
            "changes": 60,
            "blob_url": "https://github.com/huggingface/transformers/blob/014047e1c8784c00e2a04cb04ffcecdd5cb23c16/tests%2Ftest_audio_classification_top_k.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/014047e1c8784c00e2a04cb04ffcecdd5cb23c16/tests%2Ftest_audio_classification_top_k.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_audio_classification_top_k.py?ref=014047e1c8784c00e2a04cb04ffcecdd5cb23c16",
            "patch": "@@ -1,60 +0,0 @@\n-import unittest\n-\n-import numpy as np\n-\n-from transformers import pipeline\n-from transformers.testing_utils import require_torch\n-\n-\n-@require_torch\n-class AudioClassificationTopKTest(unittest.TestCase):\n-    def test_top_k_none_returns_all_labels(self):\n-        model_name = \"superb/wav2vec2-base-superb-ks\"  # model with more than 5 labels\n-        classification_pipeline = pipeline(\n-            \"audio-classification\",\n-            model=model_name,\n-            top_k=None,\n-        )\n-\n-        # Create dummy input\n-        sampling_rate = 16000\n-        signal = np.zeros((sampling_rate,), dtype=np.float32)\n-\n-        result = classification_pipeline(signal)\n-        num_labels = classification_pipeline.model.config.num_labels\n-\n-        self.assertEqual(len(result), num_labels, \"Should return all labels when top_k is None\")\n-\n-    def test_top_k_none_with_few_labels(self):\n-        model_name = \"superb/hubert-base-superb-er\"  # model with fewer labels\n-        classification_pipeline = pipeline(\n-            \"audio-classification\",\n-            model=model_name,\n-            top_k=None,\n-        )\n-\n-        # Create dummy input\n-        sampling_rate = 16000\n-        signal = np.zeros((sampling_rate,), dtype=np.float32)\n-\n-        result = classification_pipeline(signal)\n-        num_labels = classification_pipeline.model.config.num_labels\n-\n-        self.assertEqual(len(result), num_labels, \"Should handle models with fewer labels correctly\")\n-\n-    def test_top_k_greater_than_labels(self):\n-        model_name = \"superb/hubert-base-superb-er\"\n-        classification_pipeline = pipeline(\n-            \"audio-classification\",\n-            model=model_name,\n-            top_k=100,  # intentionally large number\n-        )\n-\n-        # Create dummy input\n-        sampling_rate = 16000\n-        signal = np.zeros((sampling_rate,), dtype=np.float32)\n-\n-        result = classification_pipeline(signal)\n-        num_labels = classification_pipeline.model.config.num_labels\n-\n-        self.assertEqual(len(result), num_labels, \"Should cap top_k to number of labels\")"
        }
    ],
    "stats": {
        "total": 117,
        "additions": 57,
        "deletions": 60
    }
}