{
    "author": "ylacombe",
    "message": "Fix tests in ASR pipeline (#33545)",
    "sha": "f883827c0a0832b9dd53ede18aa7fffe74a1fec2",
    "files": [
        {
            "sha": "842933d2b76c945c63cc38d9cac55bb918a759ee",
            "filename": "tests/pipelines/test_pipelines_automatic_speech_recognition.py",
            "status": "modified",
            "additions": 35,
            "deletions": 39,
            "changes": 74,
            "blob_url": "https://github.com/huggingface/transformers/blob/f883827c0a0832b9dd53ede18aa7fffe74a1fec2/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f883827c0a0832b9dd53ede18aa7fffe74a1fec2/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py?ref=f883827c0a0832b9dd53ede18aa7fffe74a1fec2",
            "patch": "@@ -295,8 +295,8 @@ def test_torch_large(self):\n         self.assertEqual(output, {\"text\": \"\"})\n \n         ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\").sort(\"id\")\n-        filename = ds[40][\"file\"]\n-        output = speech_recognizer(filename)\n+        audio = ds[40][\"audio\"]\n+        output = speech_recognizer(audio)\n         self.assertEqual(output, {\"text\": \"A MAN SAID TO THE UNIVERSE SIR I EXIST\"})\n \n     @require_torch\n@@ -312,8 +312,8 @@ def test_torch_large_with_input_features(self):\n         self.assertEqual(output, {\"text\": \"\"})\n \n         ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\").sort(\"id\")\n-        filename = ds[40][\"file\"]\n-        output = speech_recognizer(filename)\n+        audio = ds[40][\"audio\"]\n+        output = speech_recognizer(audio)\n         self.assertEqual(output, {\"text\": \"a man said to the universe sir i exist\"})\n \n     @slow\n@@ -542,11 +542,11 @@ def test_torch_whisper(self):\n             framework=\"pt\",\n         )\n         ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\").sort(\"id\")\n-        filename = ds[40][\"file\"]\n-        output = speech_recognizer(filename)\n+        audio = ds[40][\"audio\"]\n+        output = speech_recognizer(audio)\n         self.assertEqual(output, {\"text\": \" A man said to the universe, Sir, I exist.\"})\n \n-        output = speech_recognizer([filename], chunk_length_s=5, batch_size=4)\n+        output = speech_recognizer([ds[40][\"audio\"]], chunk_length_s=5, batch_size=4)\n         self.assertEqual(output, [{\"text\": \" A man said to the universe, Sir, I exist.\"}])\n \n     @require_torch\n@@ -1014,8 +1014,8 @@ def test_torch_speech_encoder_decoder(self):\n         )\n \n         ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\").sort(\"id\")\n-        filename = ds[40][\"file\"]\n-        output = speech_recognizer(filename)\n+        audio = ds[40][\"audio\"]\n+        output = speech_recognizer(audio)\n         self.assertEqual(output, {\"text\": 'Ein Mann sagte zum Universum : \" Sir, ich existiert! \"'})\n \n     @slow\n@@ -1032,13 +1032,11 @@ def test_simple_wav2vec2(self):\n         self.assertEqual(output, {\"text\": \"\"})\n \n         ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\").sort(\"id\")\n-        filename = ds[40][\"file\"]\n-        output = asr(filename)\n+        audio = ds[40][\"audio\"]\n+        output = asr(audio)\n         self.assertEqual(output, {\"text\": \"A MAN SAID TO THE UNIVERSE SIR I EXIST\"})\n \n-        filename = ds[40][\"file\"]\n-        with open(filename, \"rb\") as f:\n-            data = f.read()\n+        data = Audio().encode_example(ds[40][\"audio\"])[\"bytes\"]\n         output = asr(data)\n         self.assertEqual(output, {\"text\": \"A MAN SAID TO THE UNIVERSE SIR I EXIST\"})\n \n@@ -1058,13 +1056,11 @@ def test_simple_s2t(self):\n         self.assertEqual(output, {\"text\": \"(Applausi)\"})\n \n         ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\").sort(\"id\")\n-        filename = ds[40][\"file\"]\n-        output = asr(filename)\n+        audio = ds[40][\"audio\"]\n+        output = asr(audio)\n         self.assertEqual(output, {\"text\": \"Un uomo disse all'universo: \\\"Signore, io esisto.\"})\n \n-        filename = ds[40][\"file\"]\n-        with open(filename, \"rb\") as f:\n-            data = f.read()\n+        data = Audio().encode_example(ds[40][\"audio\"])[\"bytes\"]\n         output = asr(data)\n         self.assertEqual(output, {\"text\": \"Un uomo disse all'universo: \\\"Signore, io esisto.\"})\n \n@@ -1078,13 +1074,13 @@ def test_simple_whisper_asr(self):\n             framework=\"pt\",\n         )\n         ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n-        filename = ds[0][\"file\"]\n-        output = speech_recognizer(filename)\n+        audio = ds[0][\"audio\"]\n+        output = speech_recognizer(audio)\n         self.assertEqual(\n             output,\n             {\"text\": \" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.\"},\n         )\n-        output = speech_recognizer(filename, return_timestamps=True)\n+        output = speech_recognizer(ds[0][\"audio\"], return_timestamps=True)\n         self.assertEqual(\n             output,\n             {\n@@ -1100,7 +1096,7 @@ def test_simple_whisper_asr(self):\n             },\n         )\n         speech_recognizer.model.generation_config.alignment_heads = [[2, 2], [3, 0], [3, 2], [3, 3], [3, 4], [3, 5]]\n-        output = speech_recognizer(filename, return_timestamps=\"word\")\n+        output = speech_recognizer(ds[0][\"audio\"], return_timestamps=\"word\")\n         # fmt: off\n         self.assertEqual(\n             output,\n@@ -1135,7 +1131,7 @@ def test_simple_whisper_asr(self):\n             \"^Whisper cannot return `char` timestamps, only word level or segment level timestamps. \"\n             \"Use `return_timestamps='word'` or `return_timestamps=True` respectively.$\",\n         ):\n-            _ = speech_recognizer(filename, return_timestamps=\"char\")\n+            _ = speech_recognizer(audio, return_timestamps=\"char\")\n \n     @slow\n     @require_torch\n@@ -1147,8 +1143,8 @@ def test_simple_whisper_translation(self):\n             framework=\"pt\",\n         )\n         ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\").sort(\"id\")\n-        filename = ds[40][\"file\"]\n-        output = speech_recognizer(filename)\n+        audio = ds[40][\"audio\"]\n+        output = speech_recognizer(audio)\n         self.assertEqual(output, {\"text\": \" A man said to the universe, Sir, I exist.\"})\n \n         model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")\n@@ -1158,7 +1154,7 @@ def test_simple_whisper_translation(self):\n         speech_recognizer_2 = AutomaticSpeechRecognitionPipeline(\n             model=model, tokenizer=tokenizer, feature_extractor=feature_extractor\n         )\n-        output_2 = speech_recognizer_2(filename)\n+        output_2 = speech_recognizer_2(ds[0][\"audio\"])\n         self.assertEqual(output, output_2)\n \n         # either use generate_kwargs or set the model's generation_config\n@@ -1170,7 +1166,7 @@ def test_simple_whisper_translation(self):\n             feature_extractor=feature_extractor,\n             generate_kwargs={\"task\": \"transcribe\", \"language\": \"<|it|>\"},\n         )\n-        output_3 = speech_translator(filename)\n+        output_3 = speech_translator(ds[0][\"audio\"])\n         self.assertEqual(output_3, {\"text\": \" Un uomo ha detto all'universo, Sir, esiste.\"})\n \n     @slow\n@@ -1182,10 +1178,10 @@ def test_whisper_language(self):\n             framework=\"pt\",\n         )\n         ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n-        filename = ds[0][\"file\"]\n+        audio = ds[0][\"audio\"]\n \n         # 1. English-only model compatible with no language argument\n-        output = speech_recognizer(filename)\n+        output = speech_recognizer(audio)\n         self.assertEqual(\n             output,\n             {\"text\": \" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.\"},\n@@ -1197,15 +1193,15 @@ def test_whisper_language(self):\n             \"Cannot specify `task` or `language` for an English-only model. If the model is intended to be multilingual, \"\n             \"pass `is_multilingual=True` to generate, or update the generation config.\",\n         ):\n-            _ = speech_recognizer(filename, generate_kwargs={\"language\": \"en\"})\n+            _ = speech_recognizer(ds[0][\"audio\"], generate_kwargs={\"language\": \"en\"})\n \n         # 3. Multilingual model accepts language argument\n         speech_recognizer = pipeline(\n             task=\"automatic-speech-recognition\",\n             model=\"openai/whisper-tiny\",\n             framework=\"pt\",\n         )\n-        output = speech_recognizer(filename, generate_kwargs={\"language\": \"en\"})\n+        output = speech_recognizer(ds[0][\"audio\"], generate_kwargs={\"language\": \"en\"})\n         self.assertEqual(\n             output,\n             {\"text\": \" Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.\"},\n@@ -1315,8 +1311,8 @@ def test_xls_r_to_en(self):\n         )\n \n         ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\").sort(\"id\")\n-        filename = ds[40][\"file\"]\n-        output = speech_recognizer(filename)\n+        audio = ds[40][\"audio\"]\n+        output = speech_recognizer(audio)\n         self.assertEqual(output, {\"text\": \"A man said to the universe: â€œSir, I exist.\"})\n \n     @slow\n@@ -1331,8 +1327,8 @@ def test_xls_r_from_en(self):\n         )\n \n         ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\").sort(\"id\")\n-        filename = ds[40][\"file\"]\n-        output = speech_recognizer(filename)\n+        audio = ds[40][\"audio\"]\n+        output = speech_recognizer(audio)\n         self.assertEqual(output, {\"text\": \"Ein Mann sagte zu dem Universum, Sir, ich bin da.\"})\n \n     @slow\n@@ -1348,9 +1344,8 @@ def test_speech_to_text_leveraged(self):\n         )\n \n         ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\").sort(\"id\")\n-        filename = ds[40][\"file\"]\n-\n-        output = speech_recognizer(filename)\n+        audio = ds[40][\"audio\"]\n+        output = speech_recognizer(audio)\n         self.assertEqual(output, {\"text\": \"a man said to the universe sir i exist\"})\n \n     @slow\n@@ -1561,6 +1556,7 @@ def test_whisper_longform(self):\n             feature_extractor=processor.feature_extractor,\n             max_new_tokens=128,\n             device=torch_device,\n+            return_timestamps=True,  # to allow longform generation\n         )\n \n         ds = load_dataset(\"distil-whisper/meanwhile\", \"default\")[\"test\"]"
        }
    ],
    "stats": {
        "total": 74,
        "additions": 35,
        "deletions": 39
    }
}