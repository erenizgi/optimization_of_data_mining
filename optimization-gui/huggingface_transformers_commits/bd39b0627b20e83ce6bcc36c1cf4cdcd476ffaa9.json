{
    "author": "jadechoghari",
    "message": "Update doc and default value of TextNetImageProcessor (#35563)\n\nupdate doc and default value",
    "sha": "bd39b0627b20e83ce6bcc36c1cf4cdcd476ffaa9",
    "files": [
        {
            "sha": "945ebe63fb830f409b5899c32fcba767926faf00",
            "filename": "src/transformers/models/textnet/image_processing_textnet.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/bd39b0627b20e83ce6bcc36c1cf4cdcd476ffaa9/src%2Ftransformers%2Fmodels%2Ftextnet%2Fimage_processing_textnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bd39b0627b20e83ce6bcc36c1cf4cdcd476ffaa9/src%2Ftransformers%2Fmodels%2Ftextnet%2Fimage_processing_textnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftextnet%2Fimage_processing_textnet.py?ref=bd39b0627b20e83ce6bcc36c1cf4cdcd476ffaa9",
            "patch": "@@ -56,7 +56,7 @@ class TextNetImageProcessor(BaseImageProcessor):\n         do_resize (`bool`, *optional*, defaults to `True`):\n             Whether to resize the image's (height, width) dimensions to the specified `size`. Can be overridden by\n             `do_resize` in the `preprocess` method.\n-        size (`Dict[str, int]` *optional*, defaults to `{\"shortest_edge\": 224}`):\n+        size (`Dict[str, int]` *optional*, defaults to `{\"shortest_edge\": 640}`):\n             Size of the image after resizing. The shortest edge of the image is resized to size[\"shortest_edge\"], with\n             the longest edge resized to keep the input aspect ratio. Can be overridden by `size` in the `preprocess`\n             method.\n@@ -108,7 +108,7 @@ def __init__(\n         **kwargs,\n     ) -> None:\n         super().__init__(**kwargs)\n-        size = size if size is not None else {\"shortest_edge\": 224}\n+        size = size if size is not None else {\"shortest_edge\": 640}\n         size = get_size_dict(size, default_to_square=False)\n         crop_size = crop_size if crop_size is not None else {\"height\": 224, \"width\": 224}\n         crop_size = get_size_dict(crop_size, param_name=\"crop_size\")"
        },
        {
            "sha": "d32a7351af893fe90d4f36264390186ac7658975",
            "filename": "src/transformers/models/textnet/modeling_textnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bd39b0627b20e83ce6bcc36c1cf4cdcd476ffaa9/src%2Ftransformers%2Fmodels%2Ftextnet%2Fmodeling_textnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bd39b0627b20e83ce6bcc36c1cf4cdcd476ffaa9/src%2Ftransformers%2Fmodels%2Ftextnet%2Fmodeling_textnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftextnet%2Fmodeling_textnet.py?ref=bd39b0627b20e83ce6bcc36c1cf4cdcd476ffaa9",
            "patch": "@@ -370,7 +370,7 @@ def forward(\n         >>> processor = TextNetImageProcessor.from_pretrained(\"czczup/textnet-base\")\n         >>> model = TextNetForImageClassification.from_pretrained(\"czczup/textnet-base\")\n \n-        >>> inputs = processor(images=image, return_tensors=\"pt\", size={\"height\": 640, \"width\": 640})\n+        >>> inputs = processor(images=image, return_tensors=\"pt\")\n         >>> with torch.no_grad():\n         ...     outputs = model(**inputs)\n         >>> outputs.logits.shape"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 3,
        "deletions": 3
    }
}