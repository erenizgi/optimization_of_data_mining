{
    "author": "emanrissha",
    "message": "Updated the Model docs - for the MARIAN model (#39138)\n\n* Update marian.md\n\nThis update improves the Marian model card to follow the Hugging Face standardized model card format. The changes include:\r\n\r\n- Added a clear description of MarianMT, its architecture, and how it differs from other models.\r\n- Provided usage examples for Pipeline and AutoModel.\r\n- Added a quantization example for optimizing model inference.\r\n- Included instructions and examples for multilingual translation with language codes.\r\n- Added an Attention Mask Visualizer example.\r\n- Added a Resources section with relevant links to papers, the Marian framework, language codes, tokenizer guides, and quantization documentation.\r\n- Fixed formatting issues in the code blocks for correct rendering.\r\n\r\nThis update improves the readability, usability, and consistency of the Marian model documentation for users.\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update marian.md\n\n* Update marian.md\n\n* Update marian.md\n\n* Update marian.md\n\n* Update docs/source/en/model_doc/marian.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update marian.md\n\n* Update marian.md\n\n* Update marian.md\n\n* Update marian.md\n\n---------\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
    "sha": "d61c0d087cedbfdbbee8c75b210d5837c35addb8",
    "files": [
        {
            "sha": "0bec4a49de14f8e9e862be0c14b618b8e3940fcb",
            "filename": "docs/source/en/model_doc/marian.md",
            "status": "modified",
            "additions": 99,
            "deletions": 120,
            "changes": 219,
            "blob_url": "https://github.com/huggingface/transformers/blob/d61c0d087cedbfdbbee8c75b210d5837c35addb8/docs%2Fsource%2Fen%2Fmodel_doc%2Fmarian.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/d61c0d087cedbfdbbee8c75b210d5837c35addb8/docs%2Fsource%2Fen%2Fmodel_doc%2Fmarian.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fmarian.md?ref=d61c0d087cedbfdbbee8c75b210d5837c35addb8",
            "patch": "@@ -14,159 +14,138 @@ rendered properly in your Markdown viewer.\n \n -->\n \n-# MarianMT\n-\n-<div class=\"flex flex-wrap space-x-1\">\n-<img alt=\"PyTorch\" src=\"https://img.shields.io/badge/PyTorch-DE3412?style=flat&logo=pytorch&logoColor=white\">\n-<img alt=\"TensorFlow\" src=\"https://img.shields.io/badge/TensorFlow-FF6F00?style=flat&logo=tensorflow&logoColor=white\">\n-<img alt=\"Flax\" src=\"https://img.shields.io/badge/Flax-29a79b.svg?style=flat&logo=data:image/png;base64,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\n+<div style=\"float: right;\">\n+    <div class=\"flex flex-wrap space-x-1\">\n+        <img alt=\"PyTorch\" src=\"https://img.shields.io/badge/PyTorch-DE3412?style=flat&logo=pytorch&logoColor=white\">\n+        <img alt=\"TensorFlow\" src=\"https://img.shields.io/badge/TensorFlow-FF6F00?style=flat&logo=tensorflow&logoColor=white\">\n+        <img alt=\"Flax\" src=\"https://img.shields.io/badge/Flax-29a79b.svg?style=flat&logo=data:image/png;base64,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\n \">\n-<img alt=\"FlashAttention\" src=\"https://img.shields.io/badge/%E2%9A%A1%EF%B8%8E%20FlashAttention-eae0c8?style=flat\">\n-<img alt=\"SDPA\" src=\"https://img.shields.io/badge/SDPA-DE3412?style=flat&logo=pytorch&logoColor=white\">\n+        <img alt=\"FlashAttention\" src=\"https://img.shields.io/badge/%E2%9A%A1%EF%B8%8E%20FlashAttention-eae0c8?style=flat\">\n+        <img alt=\"SDPA\" src=\"https://img.shields.io/badge/SDPA-DE3412?style=flat&logo=pytorch&logoColor=white\">\n+    </div>\n </div>\n \n-## Overview\n+# MarianMT\n+\n \n-A framework for translation models, using the same models as BART. Translations should be similar, but not identical to output in the test set linked to in each model card.\n-This model was contributed by [sshleifer](https://huggingface.co/sshleifer).\n \n+[MarianMT](https://huggingface.co/papers/1804.00344) is a machine translation model trained with the Marian framework which is written in pure C++. The framework includes its own custom auto-differentiation engine and efficient meta-algorithms to train encoder-decoder models like BART.\n \n-## Implementation Notes\n+All MarianMT models are transformer encoder-decoders with 6 layers in each component, use static sinusoidal positional embeddings, don't have a layernorm embedding, and the model starts generating with the prefix `pad_token_id` instead of `<s/>`.\n \n-- Each model is about 298 MB on disk, there are more than 1,000 models.\n-- The list of supported language pairs can be found [here](https://huggingface.co/Helsinki-NLP).\n-- Models were originally trained by [Jörg Tiedemann](https://researchportal.helsinki.fi/en/persons/j%C3%B6rg-tiedemann) using the [Marian](https://marian-nmt.github.io/) C++ library, which supports fast training and translation.\n-- All models are transformer encoder-decoders with 6 layers in each component. Each model's performance is documented\n-  in a model card.\n-- The 80 opus models that require BPE preprocessing are not supported.\n-- The modeling code is the same as [`BartForConditionalGeneration`] with a few minor modifications:\n \n-  - static (sinusoid) positional embeddings (`MarianConfig.static_position_embeddings=True`)\n-  - no layernorm_embedding (`MarianConfig.normalize_embedding=False`)\n-  - the model starts generating with `pad_token_id` (which has 0 as a token_embedding) as the prefix (Bart uses\n-    `<s/>`),\n-- Code to bulk convert models can be found in `convert_marian_to_pytorch.py`.\n \n+You can find all the original MarianMT checkpoints under the [Language Technology Research Group at the University of Helsinki](https://huggingface.co/Helsinki-NLP/models?search=opus-mt) organization.\n \n-## Naming\n \n-- All model names use the following format: `Helsinki-NLP/opus-mt-{src}-{tgt}`\n-- The language codes used to name models are inconsistent. Two digit codes can usually be found [here](https://developers.google.com/admin-sdk/directory/v1/languages), three digit codes require googling \"language\n-  code {code}\".\n-- Codes formatted like `es_AR` are usually `code_{region}`. That one is Spanish from Argentina.\n-- The models were converted in two stages. The first 1000 models use ISO-639-2 codes to identify languages, the second\n-  group use a combination of ISO-639-5 codes and ISO-639-2 codes.\n+> [!TIP]\n+> This model was contributed by [sshleifer](https://huggingface.co/sshleifer).\n+>\n+> Click on the MarianMT models in the right sidebar for more examples of how to apply MarianMT to translation tasks.\n \n \n-## Examples\n+The example below demonstrates how to translate text using [`Pipeline`] or the [`AutoModel`] class.\n \n-- Since Marian models are smaller than many other translation models available in the library, they can be useful for\n-  fine-tuning experiments and integration tests.\n-- [Fine-tune on GPU](https://github.com/huggingface/transformers/blob/master/examples/legacy/seq2seq/train_distil_marian_enro.sh)\n+<hfoptions id=\"usage\">\n+<hfoption id=\"Pipeline\">\n \n-## Multilingual Models\n+```python\n \n-- All model names use the following format: `Helsinki-NLP/opus-mt-{src}-{tgt}`:\n-- If a model can output multiple languages, and you should specify a language code by prepending the desired output\n-  language to the `src_text`.\n-- You can see a models's supported language codes in its model card, under target constituents, like in [opus-mt-en-roa](https://huggingface.co/Helsinki-NLP/opus-mt-en-roa).\n-- Note that if a model is only multilingual on the source side, like `Helsinki-NLP/opus-mt-roa-en`, no language\n-  codes are required.\n+import torch\n+from transformers import pipeline\n \n-New multi-lingual models from the [Tatoeba-Challenge repo](https://github.com/Helsinki-NLP/Tatoeba-Challenge)\n-require 3 character language codes:\n+pipeline = pipeline(\"translation_en_to_de\", model=\"Helsinki-NLP/opus-mt-en-de\", torch_dtype=torch.float16, device=0)\n+pipeline(\"Hello, how are you?\")\n \n-```python\n->>> from transformers import MarianMTModel, MarianTokenizer\n-\n->>> src_text = [\n-...     \">>fra<< this is a sentence in english that we want to translate to french\",\n-...     \">>por<< This should go to portuguese\",\n-...     \">>esp<< And this to Spanish\",\n-... ]\n-\n->>> model_name = \"Helsinki-NLP/opus-mt-en-roa\"\n->>> tokenizer = MarianTokenizer.from_pretrained(model_name)\n->>> print(tokenizer.supported_language_codes)\n-['>>zlm_Latn<<', '>>mfe<<', '>>hat<<', '>>pap<<', '>>ast<<', '>>cat<<', '>>ind<<', '>>glg<<', '>>wln<<', '>>spa<<', '>>fra<<', '>>ron<<', '>>por<<', '>>ita<<', '>>oci<<', '>>arg<<', '>>min<<']\n-\n->>> model = MarianMTModel.from_pretrained(model_name)\n->>> translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n->>> [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n-[\"c'est une phrase en anglais que nous voulons traduire en français\",\n- 'Isto deve ir para o português.',\n- 'Y esto al español']\n ```\n \n-Here is the code to see all available pretrained models on the hub:\n+</hfoption>\n+\n+<hfoption id=\"AutoModel\">\n \n ```python\n-from huggingface_hub import list_models\n \n-model_list = list_models()\n-org = \"Helsinki-NLP\"\n-model_ids = [x.id for x in model_list if x.id.startswith(org)]\n-suffix = [x.split(\"/\")[1] for x in model_ids]\n-old_style_multi_models = [f\"{org}/{s}\" for s in suffix if s != s.lower()]\n+import torch\n+from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n+\n+tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n+model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\", torch_dtype=torch.float16, attn_implementation=\"sdpa\", device_map=\"auto\")\n+\n+inputs = tokenizer(\"Hello, how are you?\", return_tensors=\"pt\").to(\"cuda\")\n+outputs = model.generate(**inputs, cache_implementation=\"static\")\n+print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n+\n ```\n \n-## Old Style Multi-Lingual Models\n-\n-These are the old style multi-lingual models ported from the OPUS-MT-Train repo: and the members of each language\n-group:\n-\n-```python no-style\n-['Helsinki-NLP/opus-mt-NORTH_EU-NORTH_EU',\n- 'Helsinki-NLP/opus-mt-ROMANCE-en',\n- 'Helsinki-NLP/opus-mt-SCANDINAVIA-SCANDINAVIA',\n- 'Helsinki-NLP/opus-mt-de-ZH',\n- 'Helsinki-NLP/opus-mt-en-CELTIC',\n- 'Helsinki-NLP/opus-mt-en-ROMANCE',\n- 'Helsinki-NLP/opus-mt-es-NORWAY',\n- 'Helsinki-NLP/opus-mt-fi-NORWAY',\n- 'Helsinki-NLP/opus-mt-fi-ZH',\n- 'Helsinki-NLP/opus-mt-fi_nb_no_nn_ru_sv_en-SAMI',\n- 'Helsinki-NLP/opus-mt-sv-NORWAY',\n- 'Helsinki-NLP/opus-mt-sv-ZH']\n-GROUP_MEMBERS = {\n- 'ZH': ['cmn', 'cn', 'yue', 'ze_zh', 'zh_cn', 'zh_CN', 'zh_HK', 'zh_tw', 'zh_TW', 'zh_yue', 'zhs', 'zht', 'zh'],\n- 'ROMANCE': ['fr', 'fr_BE', 'fr_CA', 'fr_FR', 'wa', 'frp', 'oc', 'ca', 'rm', 'lld', 'fur', 'lij', 'lmo', 'es', 'es_AR', 'es_CL', 'es_CO', 'es_CR', 'es_DO', 'es_EC', 'es_ES', 'es_GT', 'es_HN', 'es_MX', 'es_NI', 'es_PA', 'es_PE', 'es_PR', 'es_SV', 'es_UY', 'es_VE', 'pt', 'pt_br', 'pt_BR', 'pt_PT', 'gl', 'lad', 'an', 'mwl', 'it', 'it_IT', 'co', 'nap', 'scn', 'vec', 'sc', 'ro', 'la'],\n- 'NORTH_EU': ['de', 'nl', 'fy', 'af', 'da', 'fo', 'is', 'no', 'nb', 'nn', 'sv'],\n- 'SCANDINAVIA': ['da', 'fo', 'is', 'no', 'nb', 'nn', 'sv'],\n- 'SAMI': ['se', 'sma', 'smj', 'smn', 'sms'],\n- 'NORWAY': ['nb_NO', 'nb', 'nn_NO', 'nn', 'nog', 'no_nb', 'no'],\n- 'CELTIC': ['ga', 'cy', 'br', 'gd', 'kw', 'gv']\n-}\n+</hfoption>\n+</hfoptions>\n+\n+\n+Use the [AttentionMaskVisualizer](https://github.com/huggingface/transformers/blob/beb9b5b02246b9b7ee81ddf938f93f44cfeaad19/src/transformers/utils/attention_visualizer.py#L139) to better understand what tokens the model can and cannot attend to.\n+\n+```python\n+from transformers.utils.attention_visualizer import AttentionMaskVisualizer\n+\n+visualizer = AttentionMaskVisualizer(\"Helsinki-NLP/opus-mt-en-de\")\n+visualizer(\"Hello, how are you?\")\n ```\n+<div class=\"flex justify-center\">\n+   <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/model_doc/marianmt-attn-mask.png\"/>\n+</div>\n \n-Example of translating english to many romance languages, using old-style 2 character language codes\n+## Notes\n \n+- MarianMT models are ~298MB on disk and there are more than 1000 models. Check this [list](https://huggingface.co/Helsinki-NLP) for supported language pairs. The language codes may be inconsistent. Two digit codes can be found [here](https://developers.google.com/admin-sdk/directory/v1/languages) while three digit codes may require further searching.\n+- Models that require BPE preprocessing are not supported.\n+- All model names use the following format: `Helsinki-NLP/opus-mt-{src}-{tgt}`. Language codes formatted like `es_AR` usually refer to the `code_{region}`. For example, `es_AR` refers to Spanish from Argentina.\n+- If a model can output multiple languages, prepend the desired output language to `src_txt` as shown below. New multilingual models from the [Tatoeba-Challenge](https://github.com/Helsinki-NLP/Tatoeba-Challenge) require 3 character language codes.\n \n ```python\n->>> from transformers import MarianMTModel, MarianTokenizer\n-\n->>> src_text = [\n-...     \">>fr<< this is a sentence in english that we want to translate to french\",\n-...     \">>pt<< This should go to portuguese\",\n-...     \">>es<< And this to Spanish\",\n-... ]\n-\n->>> model_name = \"Helsinki-NLP/opus-mt-en-ROMANCE\"\n->>> tokenizer = MarianTokenizer.from_pretrained(model_name)\n-\n->>> model = MarianMTModel.from_pretrained(model_name)\n->>> translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n->>> tgt_text = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n-[\"c'est une phrase en anglais que nous voulons traduire en français\",\n- 'Isto deve ir para o português.',\n- 'Y esto al español']\n+\n+from transformers import MarianMTModel, MarianTokenizer\n+\n+# Model trained on multiple source languages → multiple target languages\n+# Example: multilingual to Arabic (arb)\n+model_name = \"Helsinki-NLP/opus-mt-mul-mul\"  # Tatoeba Challenge model\n+tokenizer = MarianTokenizer.from_pretrained(model_name)\n+model = MarianMTModel.from_pretrained(model_name)\n+\n+# Prepend the desired output language code (3-letter ISO 639-3)\n+src_texts = [\"arb>> Hello, how are you today?\"]\n+\n+# Tokenize and translate\n+inputs = tokenizer(src_texts, return_tensors=\"pt\", padding=True, truncation=True)\n+translated = model.generate(**inputs)\n+\n+# Decode and print result\n+translated_texts = tokenizer.batch_decode(translated, skip_special_tokens=True)\n+print(translated_texts[0])\n+\n ```\n+   \n+- Older multilingual models use 2 character language codes.\n \n-## Resources\n+```python\n+\n+from transformers import MarianMTModel, MarianTokenizer\n+\n+# Example: older multilingual model (like en → many)\n+model_name = \"Helsinki-NLP/opus-mt-en-ROMANCE\"  # English → French, Spanish, Italian, etc.\n+tokenizer = MarianTokenizer.from_pretrained(model_name)\n+model = MarianMTModel.from_pretrained(model_name)\n+\n+# Prepend the 2-letter ISO 639-1 target language code (older format)\n+src_texts = [\">>fr<< Hello, how are you today?\"]\n \n-- [Translation task guide](../tasks/translation)\n-- [Summarization task guide](../tasks/summarization)\n-- [Causal language modeling task guide](../tasks/language_modeling)\n+# Tokenize and translate\n+inputs = tokenizer(src_texts, return_tensors=\"pt\", padding=True, truncation=True)\n+translated = model.generate(**inputs)\n+\n+# Decode and print result\n+translated_texts = tokenizer.batch_decode(translated, skip_special_tokens=True)\n+print(translated_texts[0])\n+\n+```\n \n ## MarianConfig\n "
        }
    ],
    "stats": {
        "total": 219,
        "additions": 99,
        "deletions": 120
    }
}