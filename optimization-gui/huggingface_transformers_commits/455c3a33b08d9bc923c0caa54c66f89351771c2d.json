{
    "author": "zhanluxianshen",
    "message": "update Clean_up_tokenization_spaces typos. (#37865)\n\nSigned-off-by: zhanluxianshen <zhanluxianshen@163.com>",
    "sha": "455c3a33b08d9bc923c0caa54c66f89351771c2d",
    "files": [
        {
            "sha": "465d7c4954435bf64bfca80ad2aad14733afd617",
            "filename": "src/transformers/models/mllama/processing_mllama.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/455c3a33b08d9bc923c0caa54c66f89351771c2d/src%2Ftransformers%2Fmodels%2Fmllama%2Fprocessing_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/455c3a33b08d9bc923c0caa54c66f89351771c2d/src%2Ftransformers%2Fmodels%2Fmllama%2Fprocessing_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmllama%2Fprocessing_mllama.py?ref=455c3a33b08d9bc923c0caa54c66f89351771c2d",
            "patch": "@@ -370,7 +370,7 @@ def post_process_image_text_to_text(\n                 or `(sequence_length,)`.\n             skip_special_tokens (`bool`, *optional*, defaults to `True`):\n                 Whether or not to remove special tokens in the output. Argument passed to the tokenizer's `batch_decode` method.\n-            Clean_up_tokenization_spaces (`bool`, *optional*, defaults to `False`):\n+            clean_up_tokenization_spaces (`bool`, *optional*, defaults to `False`):\n                 Whether or not to clean up the tokenization spaces. Argument passed to the tokenizer's `batch_decode` method.\n             **kwargs:\n                 Additional arguments to be passed to the tokenizer's `batch_decode method`."
        },
        {
            "sha": "546c8acce7b2fcc4418a1ca8e47e4b6a82c9aaa9",
            "filename": "src/transformers/models/qwen2_5_vl/processing_qwen2_5_vl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/455c3a33b08d9bc923c0caa54c66f89351771c2d/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fprocessing_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/455c3a33b08d9bc923c0caa54c66f89351771c2d/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fprocessing_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fprocessing_qwen2_5_vl.py?ref=455c3a33b08d9bc923c0caa54c66f89351771c2d",
            "patch": "@@ -220,7 +220,7 @@ def post_process_image_text_to_text(\n                 or `(sequence_length,)`.\n             skip_special_tokens (`bool`, *optional*, defaults to `True`):\n                 Whether or not to remove special tokens in the output. Argument passed to the tokenizer's `batch_decode` method.\n-            Clean_up_tokenization_spaces (`bool`, *optional*, defaults to `False`):\n+            clean_up_tokenization_spaces (`bool`, *optional*, defaults to `False`):\n                 Whether or not to clean up the tokenization spaces. Argument passed to the tokenizer's `batch_decode` method.\n             **kwargs:\n                 Additional arguments to be passed to the tokenizer's `batch_decode method`."
        },
        {
            "sha": "d7e661342b1fc25b8be907ffe049033c30028386",
            "filename": "src/transformers/models/qwen2_vl/processing_qwen2_vl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/455c3a33b08d9bc923c0caa54c66f89351771c2d/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fprocessing_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/455c3a33b08d9bc923c0caa54c66f89351771c2d/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fprocessing_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fprocessing_qwen2_vl.py?ref=455c3a33b08d9bc923c0caa54c66f89351771c2d",
            "patch": "@@ -202,7 +202,7 @@ def post_process_image_text_to_text(\n                 or `(sequence_length,)`.\n             skip_special_tokens (`bool`, *optional*, defaults to `True`):\n                 Whether or not to remove special tokens in the output. Argument passed to the tokenizer's `batch_decode` method.\n-            Clean_up_tokenization_spaces (`bool`, *optional*, defaults to `False`):\n+            clean_up_tokenization_spaces (`bool`, *optional*, defaults to `False`):\n                 Whether or not to clean up the tokenization spaces. Argument passed to the tokenizer's `batch_decode` method.\n             **kwargs:\n                 Additional arguments to be passed to the tokenizer's `batch_decode method`."
        }
    ],
    "stats": {
        "total": 6,
        "additions": 3,
        "deletions": 3
    }
}