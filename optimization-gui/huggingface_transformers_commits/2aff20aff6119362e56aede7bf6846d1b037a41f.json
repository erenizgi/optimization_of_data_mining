{
    "author": "cyyever",
    "message": "Fix typos in documentation (#41641)\n\nFix typos\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>",
    "sha": "2aff20aff6119362e56aede7bf6846d1b037a41f",
    "files": [
        {
            "sha": "8ee9dea7de5e111415895903d6a20436b8dc3426",
            "filename": "docs/source/en/model_doc/evolla.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2aff20aff6119362e56aede7bf6846d1b037a41f/docs%2Fsource%2Fen%2Fmodel_doc%2Fevolla.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/2aff20aff6119362e56aede7bf6846d1b037a41f/docs%2Fsource%2Fen%2Fmodel_doc%2Fevolla.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fevolla.md?ref=2aff20aff6119362e56aede7bf6846d1b037a41f",
            "patch": "@@ -61,7 +61,7 @@ message_list = [\n     ]\n ]\n input_dict = processor(\n-    protein_informations, messages_list, return_tensors=\"pt\", text_max_length=512, protein_max_length=1024\n+    protein_inputs, messages_list, return_tensors=\"pt\", text_max_length=512, protein_max_length=1024\n )\n with torch.no_grad():\n     generated_ids = hf_model.generate(**input_dict)"
        },
        {
            "sha": "29f9cfe873aa0619558bc64f8aba8336c536f09d",
            "filename": "docs/source/en/model_doc/nllb.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2aff20aff6119362e56aede7bf6846d1b037a41f/docs%2Fsource%2Fen%2Fmodel_doc%2Fnllb.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/2aff20aff6119362e56aede7bf6846d1b037a41f/docs%2Fsource%2Fen%2Fmodel_doc%2Fnllb.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fnllb.md?ref=2aff20aff6119362e56aede7bf6846d1b037a41f",
            "patch": "@@ -55,7 +55,7 @@ pipeline(\"UN Chief says there is no military solution in Syria\")\n from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n \n tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n-model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\", dtype=\"auto\", attn_implementaiton=\"sdpa\")\n+model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\", dtype=\"auto\", attn_implementation=\"sdpa\")\n \n article = \"UN Chief says there is no military solution in Syria\"\n inputs = tokenizer(article, return_tensors=\"pt\")"
        },
        {
            "sha": "5c2d2c4fa229a9565d398ca987c6e26a05f0041f",
            "filename": "docs/source/en/model_doc/voxtral.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2aff20aff6119362e56aede7bf6846d1b037a41f/docs%2Fsource%2Fen%2Fmodel_doc%2Fvoxtral.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/2aff20aff6119362e56aede7bf6846d1b037a41f/docs%2Fsource%2Fen%2Fmodel_doc%2Fvoxtral.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fvoxtral.md?ref=2aff20aff6119362e56aede7bf6846d1b037a41f",
            "patch": "@@ -19,7 +19,7 @@ rendered properly in your Markdown viewer.\n \n Voxtral is an upgrade of [Ministral 3B and Mistral Small 3B](https://mistral.ai/news/ministraux), extending its language capabilities with audio input support. It is designed to handle tasks such as speech transcription, translation, and audio understanding.\n \n-You can read more in Mistral's [realease blog post](https://mistral.ai/news/voxtral).\n+You can read more in Mistral's [release blog post](https://mistral.ai/news/voxtral).\n \n The model is available in two checkpoints:\n "
        },
        {
            "sha": "045f0837c334de22ef45991c685d5862db16828f",
            "filename": "docs/source/en/trainer.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2aff20aff6119362e56aede7bf6846d1b037a41f/docs%2Fsource%2Fen%2Ftrainer.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/2aff20aff6119362e56aede7bf6846d1b037a41f/docs%2Fsource%2Fen%2Ftrainer.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftrainer.md?ref=2aff20aff6119362e56aede7bf6846d1b037a41f",
            "patch": "@@ -33,7 +33,7 @@ This guide will show you how [`Trainer`] works and how to customize it for your\n 3. update the weights based on the gradients\n 4. repeat until the predetermined number of epochs is reached\n \n-Manually coding this training loop everytime can be inconvenient or a barrier if you're just getting started with machine learning. [`Trainer`] abstracts this process, allowing you to focus on the model, dataset, and training design choices.\n+Manually coding this training loop every time can be inconvenient or a barrier if you're just getting started with machine learning. [`Trainer`] abstracts this process, allowing you to focus on the model, dataset, and training design choices.\n \n Configure your training with hyperparameters and options from [`TrainingArguments`] which supports many features such as distributed training, torch.compile, mixed precision training, and saving the model to the Hub.\n "
        },
        {
            "sha": "f641b03c59832dd0b14630c2fd19c0a0a28b7a26",
            "filename": "notebooks/README.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2aff20aff6119362e56aede7bf6846d1b037a41f/notebooks%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/2aff20aff6119362e56aede7bf6846d1b037a41f/notebooks%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/notebooks%2FREADME.md?ref=2aff20aff6119362e56aede7bf6846d1b037a41f",
            "patch": "@@ -100,7 +100,7 @@ You can open any page of the documentation as a notebook in Colab (there is a bu\n \n ### Optimum notebooks\n \n-ðŸ¤—  [Optimum](https://github.com/huggingface/optimum) is an extension of ðŸ¤— Transformers, providing a set of performance optimization tools enabling maximum efficiency to train and run models on targeted hardwares.\n+ðŸ¤—  [Optimum](https://github.com/huggingface/optimum) is an extension of ðŸ¤— Transformers, providing a set of performance optimization tools enabling maximum efficiency to train and run models on targeted hardware.\n \n | Notebook     |      Description      |   |   |\n |:----------|:-------------|:-------------|------:|"
        }
    ],
    "stats": {
        "total": 10,
        "additions": 5,
        "deletions": 5
    }
}