{
    "author": "winstxnhdw",
    "message": "refactor: remove redundant if-condition and improve type correctness for `convert_tokens_to_ids` (#34030)\n\n* chore: remove redundant if-condition\r\n\r\n* fix: import `Iterable`",
    "sha": "e2886166065db25029afb58c699d6272baf22965",
    "files": [
        {
            "sha": "fabc1a1d5ed81cda66c9b612bc03cfd90622b6be",
            "filename": "src/transformers/tokenization_utils_fast.py",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/e2886166065db25029afb58c699d6272baf22965/src%2Ftransformers%2Ftokenization_utils_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e2886166065db25029afb58c699d6272baf22965/src%2Ftransformers%2Ftokenization_utils_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_utils_fast.py?ref=e2886166065db25029afb58c699d6272baf22965",
            "patch": "@@ -21,7 +21,7 @@\n import json\n import os\n from collections import defaultdict\n-from typing import Any, Dict, List, Optional, Tuple, Union\n+from typing import Any, Dict, Iterable, List, Optional, Tuple, Union\n \n import tokenizers.pre_tokenizers as pre_tokenizers_fast\n from tokenizers import Encoding as EncodingFast\n@@ -326,20 +326,17 @@ def _convert_encoding(\n \n         return encoding_dict, encodings\n \n-    def convert_tokens_to_ids(self, tokens: Union[str, List[str]]) -> Union[int, List[int]]:\n+    def convert_tokens_to_ids(self, tokens: Union[str, Iterable[str]]) -> Union[int, List[int]]:\n         \"\"\"\n-        Converts a token string (or a sequence of tokens) in a single integer id (or a sequence of ids), using the\n+        Converts a token string (or a sequence of tokens) in a single integer id (or a Iterable of ids), using the\n         vocabulary.\n \n         Args:\n-            tokens (`str` or `List[str]`): One or several token(s) to convert to token id(s).\n+            tokens (`str` or `Iterable[str]`): One or several token(s) to convert to token id(s).\n \n         Returns:\n             `int` or `List[int]`: The token id or list of token ids.\n         \"\"\"\n-        if tokens is None:\n-            return None\n-\n         if isinstance(tokens, str):\n             return self._convert_token_to_id_with_added_voc(tokens)\n "
        }
    ],
    "stats": {
        "total": 11,
        "additions": 4,
        "deletions": 7
    }
}