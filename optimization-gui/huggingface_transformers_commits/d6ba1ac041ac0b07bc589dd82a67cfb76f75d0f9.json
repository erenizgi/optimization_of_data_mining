{
    "author": "yijun-lee",
    "message": "ğŸŒ [i18n-KO] Translated `gemma.md` to Korean (#33936)\n\n* docs: ko: gemma.md\r\n\r\n* feat: nmt draft\r\n\r\n* fix: manual edits",
    "sha": "d6ba1ac041ac0b07bc589dd82a67cfb76f75d0f9",
    "files": [
        {
            "sha": "f2eac1f444bdf9ebefcfc9fa87841fc75c681971",
            "filename": "docs/source/ko/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d6ba1ac041ac0b07bc589dd82a67cfb76f75d0f9/docs%2Fsource%2Fko%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/d6ba1ac041ac0b07bc589dd82a67cfb76f75d0f9/docs%2Fsource%2Fko%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2F_toctree.yml?ref=d6ba1ac041ac0b07bc589dd82a67cfb76f75d0f9",
            "patch": "@@ -392,6 +392,8 @@\n         title: (ë²ˆì—­ì¤‘) FSMT\n       - local: in_translation\n         title: (ë²ˆì—­ì¤‘) Funnel Transformer\n+      - local: model_doc/gemma\n+        title: Gemma\n       - local: in_translation\n         title: (ë²ˆì—­ì¤‘) GPT\n       - local: in_translation"
        },
        {
            "sha": "25fe6f1c772950ec5bab3d0f3a9850666d90b94f",
            "filename": "docs/source/ko/model_doc/gemma.md",
            "status": "added",
            "additions": 76,
            "deletions": 0,
            "changes": 76,
            "blob_url": "https://github.com/huggingface/transformers/blob/d6ba1ac041ac0b07bc589dd82a67cfb76f75d0f9/docs%2Fsource%2Fko%2Fmodel_doc%2Fgemma.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/d6ba1ac041ac0b07bc589dd82a67cfb76f75d0f9/docs%2Fsource%2Fko%2Fmodel_doc%2Fgemma.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fgemma.md?ref=d6ba1ac041ac0b07bc589dd82a67cfb76f75d0f9",
            "patch": "@@ -0,0 +1,76 @@\n+<!--Copyright 2024 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n+\n+âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+\n+# Gemma [[gemma]]\n+\n+## ê°œìš” [[overview]]\n+\n+Gemma ëª¨ë¸ì€ Googleì˜ Gemma íŒ€ì´ ì‘ì„±í•œ [Gemma: Open Models Based on Gemini Technology and Research](https://blog.google/technology/developers/gemma-open-models/)ì—ì„œ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤.\n+\n+Gemma ëª¨ë¸ì€ 6ì¡° í† í°ìœ¼ë¡œ í•™ìŠµë˜ì—ˆìœ¼ë©°, 2bì™€ 7bì˜ ë‘ ê°€ì§€ ë²„ì „ìœ¼ë¡œ ì¶œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.\n+\n+ë…¼ë¬¸ì˜ ì´ˆë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n+\n+*ì´ ì—°êµ¬ëŠ” ì–¸ì–´ ì´í•´, ì¶”ë¡  ë° ì•ˆì „ì„±ì— ëŒ€í•œ í•™ìˆ  ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ìƒˆë¡œìš´ ì˜¤í”ˆ ì–¸ì–´ ëª¨ë¸ ê³„ì—´ì¸ Gemmaë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë‘ ê°€ì§€ í¬ê¸°(20ì–µ ë° 70ì–µ ë§¤ê°œë³€ìˆ˜)ì˜ ëª¨ë¸ì„ ì¶œì‹œí•˜ë©°, ì‚¬ì „ í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸ì™€ ë¯¸ì„¸ ì¡°ì •ëœ ì²´í¬í¬ì¸íŠ¸ë¥¼ ëª¨ë‘ ì œê³µí•©ë‹ˆë‹¤. GemmaëŠ” 18ê°œì˜ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‘ì—… ì¤‘ 11ê°œì—ì„œ ìœ ì‚¬í•œ í¬ê¸°ì˜ ì˜¤í”ˆ ëª¨ë¸ì„ ëŠ¥ê°€í•˜ë©°, ìš°ë¦¬ëŠ” ëª¨ë¸ ê°œë°œì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ê³¼ í•¨ê»˜ ì•ˆì „ì„±ê³¼ ì±…ì„ ì¸¡ë©´ì— ëŒ€í•œ ì¢…í•©ì ì¸ í‰ê°€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” LLMì˜ ì±…ì„ê° ìˆëŠ” ê³µê°œê°€ ìµœì²¨ë‹¨ ëª¨ë¸ì˜ ì•ˆì „ì„±ì„ í–¥ìƒì‹œí‚¤ê³  ë‹¤ìŒ ì„¸ëŒ€ì˜ LLM í˜ì‹ ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ë° ì¤‘ìš”í•˜ë‹¤ê³  ë¯¿ìŠµë‹ˆë‹¤.*\n+\n+íŒ:\n+\n+- ì›ë³¸ ì²´í¬í¬ì¸íŠ¸ëŠ” ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ `src/transformers/models/gemma/convert_gemma_weights_to_hf.py`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+ì´ ëª¨ë¸ì€ [Arthur Zucker](https://huggingface.co/ArthurZ), [Younes Belkada](https://huggingface.co/ybelkada), [Sanchit Gandhi](https://huggingface.co/sanchit-gandhi), [Pedro Cuenca](https://huggingface.co/pcuenq)ê°€ ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤.\n+\n+## GemmaConfig [[transformers.GemmaConfig]]\n+\n+[[autodoc]] GemmaConfig\n+\n+## GemmaTokenizer [[transformers.GemmaTokenizer]]\n+\n+[[autodoc]] GemmaTokenizer\n+\n+\n+## GemmaTokenizerFast [[transformers.GemmaTokenizerFast]]\n+\n+[[autodoc]] GemmaTokenizerFast\n+\n+## GemmaModel [[transformers.GemmaModel]]\n+\n+[[autodoc]] GemmaModel\n+    - forward\n+\n+## GemmaForCausalLM [[transformers.GemmaForCausalLM]]\n+\n+[[autodoc]] GemmaForCausalLM\n+    - forward\n+\n+## GemmaForSequenceClassification [[transformers.GemmaForSequenceClassification]]\n+\n+[[autodoc]] GemmaForSequenceClassification\n+    - forward\n+\n+## GemmaForTokenClassification [[transformers.GemmaForTokenClassification]]\n+\n+[[autodoc]] GemmaForTokenClassification\n+    - forward\n+\n+## FlaxGemmaModel [[transformers.FlaxGemmaModel]]\n+\n+[[autodoc]] FlaxGemmaModel\n+    - __call__\n+\n+## FlaxGemmaForCausalLM [[transformers.FlaxGemmaForCausalLM]]\n+\n+[[autodoc]] FlaxGemmaForCausalLM\n+    - __call__"
        }
    ],
    "stats": {
        "total": 78,
        "additions": 78,
        "deletions": 0
    }
}