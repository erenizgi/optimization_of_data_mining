{
    "author": "qgallouedec",
    "message": "[bugfix] Fix tensor device in Idefics2, Idefics3, and SmolVLM (#39975)\n\n* [bugfix] ensure correct tensor device in Idefics2, Idefics3, and SmolVLM models\n\n* to cuda",
    "sha": "849c3778c620004e8d117cfb66ceb332350a65c4",
    "files": [
        {
            "sha": "1b15161ed76008bf3656f29977c25bcc99c12a6b",
            "filename": "src/transformers/models/idefics2/modeling_idefics2.py",
            "status": "modified",
            "additions": 7,
            "deletions": 4,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/849c3778c620004e8d117cfb66ceb332350a65c4/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/849c3778c620004e8d117cfb66ceb332350a65c4/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py?ref=849c3778c620004e8d117cfb66ceb332350a65c4",
            "patch": "@@ -141,8 +141,12 @@ def forward(self, pixel_values: torch.FloatTensor, patch_attention_mask: torch.B\n         embeddings = patch_embeds.flatten(2).transpose(1, 2)\n \n         max_nb_patches_h, max_nb_patches_w = max_im_h // self.patch_size, max_im_w // self.patch_size\n-        boundaries = torch.arange(1 / self.num_patches_per_side, 1.0, 1 / self.num_patches_per_side)\n-        position_ids = torch.full(size=(batch_size, max_nb_patches_h * max_nb_patches_w), fill_value=0)\n+        boundaries = torch.arange(\n+            1 / self.num_patches_per_side, 1.0, 1 / self.num_patches_per_side, device=pixel_values.device\n+        )\n+        position_ids = torch.full(\n+            size=(batch_size, max_nb_patches_h * max_nb_patches_w), fill_value=0, device=pixel_values.device\n+        )\n \n         for batch_idx, p_attn_mask in enumerate(patch_attention_mask):\n             nb_patches_h = p_attn_mask[:, 0].sum()\n@@ -158,9 +162,8 @@ def forward(self, pixel_values: torch.FloatTensor, patch_attention_mask: torch.B\n             bucket_coords_w = torch.bucketize(fractional_coords_w, boundaries, right=True)\n \n             pos_ids = (bucket_coords_h[:, None] * self.num_patches_per_side + bucket_coords_w).flatten()\n-            position_ids[batch_idx][p_attn_mask.view(-1).cpu()] = pos_ids\n+            position_ids[batch_idx][p_attn_mask.view(-1)] = pos_ids\n \n-        position_ids = position_ids.to(self.position_embedding.weight.device)\n         embeddings = embeddings + self.position_embedding(position_ids)\n         return embeddings\n "
        },
        {
            "sha": "541658f2ff596c5b2a2dcbae9a47fff1e7a7514c",
            "filename": "src/transformers/models/idefics3/modeling_idefics3.py",
            "status": "modified",
            "additions": 7,
            "deletions": 4,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/849c3778c620004e8d117cfb66ceb332350a65c4/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/849c3778c620004e8d117cfb66ceb332350a65c4/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py?ref=849c3778c620004e8d117cfb66ceb332350a65c4",
            "patch": "@@ -140,8 +140,12 @@ def forward(self, pixel_values: torch.FloatTensor, patch_attention_mask: torch.B\n         embeddings = patch_embeds.flatten(2).transpose(1, 2)\n \n         max_nb_patches_h, max_nb_patches_w = max_im_h // self.patch_size, max_im_w // self.patch_size\n-        boundaries = torch.arange(1 / self.num_patches_per_side, 1.0, 1 / self.num_patches_per_side)\n-        position_ids = torch.full(size=(batch_size, max_nb_patches_h * max_nb_patches_w), fill_value=0)\n+        boundaries = torch.arange(\n+            1 / self.num_patches_per_side, 1.0, 1 / self.num_patches_per_side, device=pixel_values.device\n+        )\n+        position_ids = torch.full(\n+            size=(batch_size, max_nb_patches_h * max_nb_patches_w), fill_value=0, device=pixel_values.device\n+        )\n \n         for batch_idx, p_attn_mask in enumerate(patch_attention_mask):\n             nb_patches_h = p_attn_mask[:, 0].sum()\n@@ -157,9 +161,8 @@ def forward(self, pixel_values: torch.FloatTensor, patch_attention_mask: torch.B\n             bucket_coords_w = torch.bucketize(fractional_coords_w, boundaries, right=True)\n \n             pos_ids = (bucket_coords_h[:, None] * self.num_patches_per_side + bucket_coords_w).flatten()\n-            position_ids[batch_idx][p_attn_mask.view(-1).cpu()] = pos_ids\n+            position_ids[batch_idx][p_attn_mask.view(-1)] = pos_ids\n \n-        position_ids = position_ids.to(self.position_embedding.weight.device)\n         embeddings = embeddings + self.position_embedding(position_ids)\n         return embeddings\n "
        },
        {
            "sha": "a2295f12ce9ff6349074fedd9a2ee7d3eff064f0",
            "filename": "src/transformers/models/smolvlm/modeling_smolvlm.py",
            "status": "modified",
            "additions": 7,
            "deletions": 4,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/849c3778c620004e8d117cfb66ceb332350a65c4/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fmodeling_smolvlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/849c3778c620004e8d117cfb66ceb332350a65c4/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fmodeling_smolvlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fmodeling_smolvlm.py?ref=849c3778c620004e8d117cfb66ceb332350a65c4",
            "patch": "@@ -135,8 +135,12 @@ def forward(self, pixel_values: torch.FloatTensor, patch_attention_mask: torch.B\n         embeddings = patch_embeds.flatten(2).transpose(1, 2)\n \n         max_nb_patches_h, max_nb_patches_w = max_im_h // self.patch_size, max_im_w // self.patch_size\n-        boundaries = torch.arange(1 / self.num_patches_per_side, 1.0, 1 / self.num_patches_per_side)\n-        position_ids = torch.full(size=(batch_size, max_nb_patches_h * max_nb_patches_w), fill_value=0)\n+        boundaries = torch.arange(\n+            1 / self.num_patches_per_side, 1.0, 1 / self.num_patches_per_side, device=pixel_values.device\n+        )\n+        position_ids = torch.full(\n+            size=(batch_size, max_nb_patches_h * max_nb_patches_w), fill_value=0, device=pixel_values.device\n+        )\n \n         for batch_idx, p_attn_mask in enumerate(patch_attention_mask):\n             nb_patches_h = p_attn_mask[:, 0].sum()\n@@ -152,9 +156,8 @@ def forward(self, pixel_values: torch.FloatTensor, patch_attention_mask: torch.B\n             bucket_coords_w = torch.bucketize(fractional_coords_w, boundaries, right=True)\n \n             pos_ids = (bucket_coords_h[:, None] * self.num_patches_per_side + bucket_coords_w).flatten()\n-            position_ids[batch_idx][p_attn_mask.view(-1).cpu()] = pos_ids\n+            position_ids[batch_idx][p_attn_mask.view(-1)] = pos_ids\n \n-        position_ids = position_ids.to(self.position_embedding.weight.device)\n         embeddings = embeddings + self.position_embedding(position_ids)\n         return embeddings\n "
        }
    ],
    "stats": {
        "total": 33,
        "additions": 21,
        "deletions": 12
    }
}