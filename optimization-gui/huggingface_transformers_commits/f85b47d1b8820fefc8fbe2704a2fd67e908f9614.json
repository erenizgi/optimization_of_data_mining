{
    "author": "vasqu",
    "message": "[`Generate`] Fix no grad on some models (#39008)\n\nfixes on torch no grad for generate",
    "sha": "f85b47d1b8820fefc8fbe2704a2fd67e908f9614",
    "files": [
        {
            "sha": "73898a8f0a6f50a0cbbf6024bbaeba1b5ce7e9df",
            "filename": "src/transformers/models/bark/modeling_bark.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/f85b47d1b8820fefc8fbe2704a2fd67e908f9614/src%2Ftransformers%2Fmodels%2Fbark%2Fmodeling_bark.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f85b47d1b8820fefc8fbe2704a2fd67e908f9614/src%2Ftransformers%2Fmodels%2Fbark%2Fmodeling_bark.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbark%2Fmodeling_bark.py?ref=f85b47d1b8820fefc8fbe2704a2fd67e908f9614",
            "patch": "@@ -1265,6 +1265,7 @@ def forward(\n             attentions=all_self_attentions,\n         )\n \n+    @torch.no_grad()\n     def generate(\n         self,\n         coarse_output: torch.Tensor,"
        },
        {
            "sha": "857e4eb320d573ab877f0fd47e7361e852de6437",
            "filename": "src/transformers/models/patchtsmixer/modeling_patchtsmixer.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f85b47d1b8820fefc8fbe2704a2fd67e908f9614/src%2Ftransformers%2Fmodels%2Fpatchtsmixer%2Fmodeling_patchtsmixer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f85b47d1b8820fefc8fbe2704a2fd67e908f9614/src%2Ftransformers%2Fmodels%2Fpatchtsmixer%2Fmodeling_patchtsmixer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpatchtsmixer%2Fmodeling_patchtsmixer.py?ref=f85b47d1b8820fefc8fbe2704a2fd67e908f9614",
            "patch": "@@ -1720,6 +1720,7 @@ def forward(\n             scale=scale,\n         )\n \n+    @torch.no_grad()\n     def generate(\n         self,\n         past_values: torch.Tensor,\n@@ -2104,6 +2105,7 @@ def forward(\n             hidden_states=model_output.hidden_states,\n         )\n \n+    @torch.no_grad()\n     def generate(\n         self,\n         past_values: torch.Tensor,"
        },
        {
            "sha": "ec8349dfd6fae0703c8bb13887d7aa27303d825e",
            "filename": "src/transformers/models/patchtst/modeling_patchtst.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f85b47d1b8820fefc8fbe2704a2fd67e908f9614/src%2Ftransformers%2Fmodels%2Fpatchtst%2Fmodeling_patchtst.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f85b47d1b8820fefc8fbe2704a2fd67e908f9614/src%2Ftransformers%2Fmodels%2Fpatchtst%2Fmodeling_patchtst.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpatchtst%2Fmodeling_patchtst.py?ref=f85b47d1b8820fefc8fbe2704a2fd67e908f9614",
            "patch": "@@ -1724,6 +1724,7 @@ def forward(\n             scale=scale,\n         )\n \n+    @torch.no_grad()\n     def generate(\n         self,\n         past_values: torch.Tensor,\n@@ -1933,6 +1934,7 @@ def forward(\n             attentions=model_output.attentions,\n         )\n \n+    @torch.no_grad()\n     def generate(\n         self,\n         past_values: torch.Tensor,"
        }
    ],
    "stats": {
        "total": 5,
        "additions": 5,
        "deletions": 0
    }
}