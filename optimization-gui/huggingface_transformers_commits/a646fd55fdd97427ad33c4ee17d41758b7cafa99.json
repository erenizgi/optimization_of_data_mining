{
    "author": "MShaheerMalik77",
    "message": "Updated CamemBERT model card to new standardized format (#39227)\n\n* Updated CamemBERT model card to new standardized format\n\n* Applied review suggestions for CamemBERT: restored API refs, added examples, badges, and attribution\n\n* Updated CamemBERT usage examples, quantization, badges, and format\n\n* Updated CamemBERT badges\n\n* Fixed CLI Section",
    "sha": "a646fd55fdd97427ad33c4ee17d41758b7cafa99",
    "files": [
        {
            "sha": "efa57e1704ba958cd1e20e2502beedf2ca81bd41",
            "filename": "docs/source/en/model_doc/camembert.md",
            "status": "modified",
            "additions": 88,
            "deletions": 33,
            "changes": 121,
            "blob_url": "https://github.com/huggingface/transformers/blob/a646fd55fdd97427ad33c4ee17d41758b7cafa99/docs%2Fsource%2Fen%2Fmodel_doc%2Fcamembert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/a646fd55fdd97427ad33c4ee17d41758b7cafa99/docs%2Fsource%2Fen%2Fmodel_doc%2Fcamembert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fcamembert.md?ref=a646fd55fdd97427ad33c4ee17d41758b7cafa99",
            "patch": "@@ -14,49 +14,105 @@ rendered properly in your Markdown viewer.\n \n -->\n \n+<div style=\"float: right;\">\n+\t<div class=\"flex flex-wrap space-x-1\">\n+\t\t<img alt=\"PyTorch\" src=\"https://img.shields.io/badge/PyTorch-DE3412?style=flat&logo=pytorch&logoColor=white\">\n+\t\t<img alt=\"TensorFlow\" src=\"https://img.shields.io/badge/TensorFlow-FF6F00?style=flat&logo=tensorflow&logoColor=white\">\n+    <img alt=\"SDPA\" src=\"https://img.shields.io/badge/SDPA-DE3412?style=flat&logo=pytorch&logoColor=white\">\n+\t</div>\n+</div>\n+\n # CamemBERT\n \n-<div class=\"flex flex-wrap space-x-1\">\n-<img alt=\"PyTorch\" src=\"https://img.shields.io/badge/PyTorch-DE3412?style=flat&logo=pytorch&logoColor=white\">\n-<img alt=\"TensorFlow\" src=\"https://img.shields.io/badge/TensorFlow-FF6F00?style=flat&logo=tensorflow&logoColor=white\">\n-<img alt=\"SDPA\" src=\"https://img.shields.io/badge/SDPA-DE3412?style=flat&logo=pytorch&logoColor=white\">\n-</div>\n+[CamemBERT](https://huggingface.co/papers/1911.03894) is a language model based on [RoBERTa](./roberta), but trained specifically on French text from the OSCAR dataset, making it more effective for French language tasks.\n+\n+What sets CamemBERT apart is that it learned from a huge, high quality collection of French data, as opposed to mixing lots of languages. This helps it really understand French better than many multilingual models.\n+\n+Common applications of CamemBERT include masked language modeling (Fill-mask prediction), text classification (sentiment analysis), token classification (entity recognition) and sentence pair classification (entailment tasks).\n+\n+You can find all the original CamemBERT checkpoints under the [ALMAnaCH](https://huggingface.co/almanach/models?search=camembert) organization.\n+\n+> [!TIP]\n+> This model was contributed by the [ALMAnaCH (Inria)](https://huggingface.co/almanach) team.\n+>\n+> Click on the CamemBERT models in the right sidebar for more examples of how to apply CamemBERT to different NLP tasks.\n+\n+The examples below demonstrate how to predict the `<mask>` token with [`Pipeline`], [`AutoModel`], and from the command line.\n+\n+<hfoptions id=\"usage\">\n+\n+<hfoption id=\"Pipeline\">\n+\n+```python\n+import torch\n+from transformers import pipeline\n \n-## Overview\n+pipeline = pipeline(\"fill-mask\", model=\"camembert-base\", torch_dtype=torch.float16, device=0)\n+pipeline(\"Le camembert est un délicieux fromage <mask>.\")\n+```\n+</hfoption> \n \n-The CamemBERT model was proposed in [CamemBERT: a Tasty French Language Model](https://huggingface.co/papers/1911.03894) by\n-[Louis Martin](https://huggingface.co/louismartin), [Benjamin Muller](https://huggingface.co/benjamin-mlr), [Pedro Javier Ortiz Suárez](https://huggingface.co/pjox), Yoann Dupont, Laurent Romary, Éric Villemonte de la\n-Clergerie, [Djamé Seddah](https://huggingface.co/Djame), and [Benoît Sagot](https://huggingface.co/sagot). It is based on Facebook's RoBERTa model released in 2019. It is a model\n-trained on 138GB of French text.\n+<hfoption id=\"AutoModel\">\n \n-The abstract from the paper is the following:\n+```python\n+import torch\n+from transformers import AutoTokenizer, AutoModelForMaskedLM\n \n-*Pretrained language models are now ubiquitous in Natural Language Processing. Despite their success, most available\n-models have either been trained on English data or on the concatenation of data in multiple languages. This makes\n-practical use of such models --in all languages except English-- very limited. Aiming to address this issue for French,\n-we release CamemBERT, a French version of the Bi-directional Encoders for Transformers (BERT). We measure the\n-performance of CamemBERT compared to multilingual models in multiple downstream tasks, namely part-of-speech tagging,\n-dependency parsing, named-entity recognition, and natural language inference. CamemBERT improves the state of the art\n-for most of the tasks considered. We release the pretrained model for CamemBERT hoping to foster research and\n-downstream applications for French NLP.*\n+tokenizer = AutoTokenizer.from_pretrained(\"camembert-base\")\n+model = AutoModelForMaskedLM.from_pretrained(\"camembert-base\", torch_dtype=\"auto\", device_map=\"auto\", attn_implementation=\"sdpa\")\n+inputs = tokenizer(\"Le camembert est un délicieux fromage <mask>.\", return_tensors=\"pt\").to(\"cuda\")\n \n-This model was contributed by [the ALMAnaCH team (Inria)](https://huggingface.co/almanach). The original code can be found [here](https://camembert-model.fr/).\n+with torch.no_grad():\n+    outputs = model(**inputs)\n+    predictions = outputs.logits\n \n-<Tip>\n+masked_index = torch.where(inputs['input_ids'] == tokenizer.mask_token_id)[1]\n+predicted_token_id = predictions[0, masked_index].argmax(dim=-1)\n+predicted_token = tokenizer.decode(predicted_token_id)\n \n-This implementation is the same as RoBERTa. Refer to the [documentation of RoBERTa](roberta) for usage examples as well \n-as the information relative to the inputs and outputs.\n+print(f\"The predicted token is: {predicted_token}\")\n+```\n+</hfoption> \n \n-</Tip>\n+<hfoption id=\"transformers CLI\">\n \n-## Resources\n+```bash\n+echo -e \"Le camembert est un délicieux fromage <mask>.\" | transformers run --task fill-mask --model camembert-base --device 0\n+```\n \n-- [Text classification task guide](../tasks/sequence_classification)\n-- [Token classification task guide](../tasks/token_classification)\n-- [Question answering task guide](../tasks/question_answering)\n-- [Causal language modeling task guide](../tasks/language_modeling)\n-- [Masked language modeling task guide](../tasks/masked_language_modeling)\n-- [Multiple choice task guide](../tasks/multiple_choice)\n+</hfoption> \n+\n+</hfoptions> \n+\n+\n+Quantization reduces the memory burden of large models by representing weights in lower precision. Refer to the [Quantization](../quantization/overview) overview for available options.\n+\n+The example below uses [bitsandbytes](../quantization/bitsandbytes) quantization to quantize the weights to 8-bits.\n+  \n+```python\n+from transformers import AutoTokenizer, AutoModelForMaskedLM, BitsAndBytesConfig\n+import torch\n+\n+quant_config = BitsAndBytesConfig(load_in_8bit=True)\n+model = AutoModelForMaskedLM.from_pretrained(\n+    \"almanach/camembert-large\",\n+    quantization_config=quant_config,\n+    device_map=\"auto\"\n+)\n+tokenizer = AutoTokenizer.from_pretrained(\"almanach/camembert-large\")\n+\n+inputs = tokenizer(\"Le camembert est un délicieux fromage <mask>.\", return_tensors=\"pt\").to(\"cuda\")\n+\n+with torch.no_grad():\n+    outputs = model(**inputs)\n+    predictions = outputs.logits\n+\n+masked_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n+predicted_token_id = predictions[0, masked_index].argmax(dim=-1)\n+predicted_token = tokenizer.decode(predicted_token_id)\n+\n+print(f\"The predicted token is: {predicted_token}\")\n+```\n \n ## CamembertConfig\n \n@@ -137,5 +193,4 @@ as the information relative to the inputs and outputs.\n [[autodoc]] TFCamembertForQuestionAnswering\n \n </tf>\n-</frameworkcontent>\n-\n+</frameworkcontent>\n\\ No newline at end of file"
        }
    ],
    "stats": {
        "total": 121,
        "additions": 88,
        "deletions": 33
    }
}