{
    "author": "Cyrilvallez",
    "message": "[modular] Use multi-processing + fix model import issue (#40481)\n\n* add mp and simplify a bit\n\n* improve\n\n* fix\n\n* fix imports\n\n* nit",
    "sha": "a3afebbbbeb18090b7708ed4da47b5ec1bbcceaf",
    "files": [
        {
            "sha": "5b9258cbd3f1789ba59301a2073972032f8c025d",
            "filename": "utils/check_modular_conversion.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/a3afebbbbeb18090b7708ed4da47b5ec1bbcceaf/utils%2Fcheck_modular_conversion.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a3afebbbbeb18090b7708ed4da47b5ec1bbcceaf/utils%2Fcheck_modular_conversion.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_modular_conversion.py?ref=a3afebbbbeb18090b7708ed4da47b5ec1bbcceaf",
            "patch": "@@ -36,7 +36,7 @@ def process_file(\n     # Read the actual modeling file\n     with open(file_path, \"r\", encoding=\"utf-8\") as modeling_file:\n         content = modeling_file.read()\n-    output_buffer = StringIO(generated_modeling_content[file_type][0])\n+    output_buffer = StringIO(generated_modeling_content[file_type])\n     output_buffer.seek(0)\n     output_content = output_buffer.read()\n     diff = difflib.unified_diff(\n@@ -54,7 +54,7 @@ def process_file(\n             shutil.copy(file_path, file_path + BACKUP_EXT)\n         # we always save the generated content, to be able to update dependant files\n         with open(file_path, \"w\", encoding=\"utf-8\", newline=\"\\n\") as modeling_file:\n-            modeling_file.write(generated_modeling_content[file_type][0])\n+            modeling_file.write(generated_modeling_content[file_type])\n         console.print(f\"[bold blue]Overwritten {file_path} with the generated content.[/bold blue]\")\n         if show_diff:\n             console.print(f\"\\n[bold red]Differences found between the generated code and {file_path}:[/bold red]\\n\")"
        },
        {
            "sha": "3c2206cccc284c8bd443d9e727a0c638a5238fc5",
            "filename": "utils/modular_model_converter.py",
            "status": "modified",
            "additions": 39,
            "deletions": 27,
            "changes": 66,
            "blob_url": "https://github.com/huggingface/transformers/blob/a3afebbbbeb18090b7708ed4da47b5ec1bbcceaf/utils%2Fmodular_model_converter.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a3afebbbbeb18090b7708ed4da47b5ec1bbcceaf/utils%2Fmodular_model_converter.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fmodular_model_converter.py?ref=a3afebbbbeb18090b7708ed4da47b5ec1bbcceaf",
            "patch": "@@ -15,6 +15,7 @@\n import argparse\n import glob\n import importlib\n+import multiprocessing as mp\n import os\n import re\n import subprocess\n@@ -1226,7 +1227,8 @@ def visit_ImportFrom(self, node: cst.ImportFrom) -> None:\n         if m.matches(node.module, m.Attribute()):\n             for imported_ in node.names:\n                 _import = re.search(\n-                    rf\"(?:transformers\\.models\\.)|(?:\\.\\.)\\w+\\.({self.match_patterns})_.*\", import_statement\n+                    rf\"(?:transformers\\.models\\.)|(?:\\.\\.\\.models\\.)|(?:\\.\\.)\\w+\\.({self.match_patterns})_.*\",\n+                    import_statement,\n                 )\n                 if _import:\n                     source = _import.group(1)\n@@ -1688,7 +1690,8 @@ def run_ruff(code, check=False):\n     return stdout.decode()\n \n \n-def convert_modular_file(modular_file):\n+def convert_modular_file(modular_file: str) -> dict[str, str]:\n+    \"\"\"Convert a `modular_file` into all the different model-specific files it depicts.\"\"\"\n     pattern = re.search(r\"modular_(.*)(?=\\.py$)\", modular_file)\n     output = {}\n     if pattern is not None:\n@@ -1712,34 +1715,30 @@ def convert_modular_file(modular_file):\n                 )\n                 ruffed_code = run_ruff(header + module.code, True)\n                 formatted_code = run_ruff(ruffed_code, False)\n-                output[file] = [formatted_code, ruffed_code]\n+                output[file] = formatted_code\n         return output\n     else:\n         print(f\"modular pattern not found in {modular_file}, exiting\")\n         return {}\n \n \n-def save_modeling_file(modular_file, converted_file):\n-    for file_type in converted_file:\n+def save_modeling_files(modular_file: str, converted_files: dict[str, str]):\n+    \"\"\"Save all the `converted_files` from the `modular_file`.\"\"\"\n+    for file_type in converted_files:\n         file_name_prefix = file_type.split(\"*\")[0]\n         file_name_suffix = file_type.split(\"*\")[-1] if \"*\" in file_type else \"\"\n         new_file_name = modular_file.replace(\"modular_\", f\"{file_name_prefix}_\").replace(\n             \".py\", f\"{file_name_suffix}.py\"\n         )\n-        non_comment_lines = len(\n-            [line for line in converted_file[file_type][0].strip().split(\"\\n\") if not line.strip().startswith(\"#\")]\n-        )\n-        if len(converted_file[file_type][0].strip()) > 0 and non_comment_lines > 0:\n-            with open(new_file_name, \"w\", encoding=\"utf-8\") as f:\n-                f.write(converted_file[file_type][0])\n-        else:\n-            non_comment_lines = len(\n-                [line for line in converted_file[file_type][0].strip().split(\"\\n\") if not line.strip().startswith(\"#\")]\n-            )\n-            if len(converted_file[file_type][1].strip()) > 0 and non_comment_lines > 0:\n-                logger.warning(\"The modeling code contains errors, it's written without formatting\")\n-                with open(new_file_name, \"w\", encoding=\"utf-8\") as f:\n-                    f.write(converted_file[file_type][1])\n+        with open(new_file_name, \"w\", encoding=\"utf-8\") as f:\n+            f.write(converted_files[file_type])\n+\n+\n+def run_converter(modular_file: str):\n+    \"\"\"Convert a modular file, and save resulting files.\"\"\"\n+    print(f\"Converting {modular_file} to a single model single file format\")\n+    converted_files = convert_modular_file(modular_file)\n+    save_modeling_files(modular_file, converted_files)\n \n \n if __name__ == \"__main__\":\n@@ -1759,9 +1758,17 @@ def save_modeling_file(modular_file, converted_file):\n         nargs=\"+\",\n         help=\"A list of `modular_xxxx` files that should be converted to single model file\",\n     )\n+    parser.add_argument(\n+        \"--num_workers\",\n+        \"-w\",\n+        default=-1,\n+        type=int,\n+        help=\"The number of workers to use. Default is -1, which means the number of CPU cores.\",\n+    )\n     args = parser.parse_args()\n     # Both arg represent the same data, but as positional and optional\n     files_to_parse = args.files if len(args.files) > 0 else args.files_to_parse\n+    num_workers = mp.cpu_count() if args.num_workers == -1 else args.num_workers\n \n     if files_to_parse == [\"all\"]:\n         files_to_parse = glob.glob(\"src/transformers/models/**/modular_*.py\", recursive=True)\n@@ -1779,12 +1786,17 @@ def save_modeling_file(modular_file, converted_file):\n                     raise ValueError(f\"Cannot find a modular file for {model_name}. Please provide the full path.\")\n                 files_to_parse[i] = full_path\n \n-    priority_list, _ = find_priority_list(files_to_parse)\n-    priority_list = [item for sublist in priority_list for item in sublist]  # flatten the list of lists\n-    assert len(priority_list) == len(files_to_parse), \"Some files will not be converted\"\n+    # This finds the correct order in which we should convert the modular files, so that a model relying on another one\n+    # is necessarily converted after its dependencies\n+    ordered_files, _ = find_priority_list(files_to_parse)\n+    if sum(len(level_files) for level_files in ordered_files) != len(files_to_parse):\n+        raise ValueError(\n+            \"Some files will not be converted because they do not appear in the dependency graph.\"\n+            \"This usually means that at least one modular file does not import any model-specific class\"\n+        )\n \n-    for file_name in priority_list:\n-        print(f\"Converting {file_name} to a single model single file format\")\n-        module_path = file_name.replace(\"/\", \".\").replace(\".py\", \"\").replace(\"src.\", \"\")\n-        converted_files = convert_modular_file(file_name)\n-        converter = save_modeling_file(file_name, converted_files)\n+    for dependency_level_files in ordered_files:\n+        # Process files with diff\n+        workers = min(num_workers, len(dependency_level_files))\n+        with mp.Pool(workers) as pool:\n+            pool.map(run_converter, dependency_level_files)"
        }
    ],
    "stats": {
        "total": 70,
        "additions": 41,
        "deletions": 29
    }
}