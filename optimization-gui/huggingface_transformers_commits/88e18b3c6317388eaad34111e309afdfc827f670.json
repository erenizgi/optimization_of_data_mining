{
    "author": "seanswyi",
    "message": "Update doc for `metric_for_best_model` when `save_strategy=\"best\"`. (#35389)\n\n* Updated docstring for _determine_best_metric.\n\n* Updated docstring for metric_for_best_model.\n\n* Added test case for save strategy.\n\n* Updated incorrect test case.\n\n* Changed eval_strategy to match save_strategy.\n\n* Separated test cases for metric.\n\n* Allow load_best_model when save_strategy == \"best\".\n\n* Updated docstring for metric_for_best_model.",
    "sha": "88e18b3c6317388eaad34111e309afdfc827f670",
    "files": [
        {
            "sha": "4cd9a6b4dfe7a474412fe617e8f7f20fb9f7e41b",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/88e18b3c6317388eaad34111e309afdfc827f670/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/88e18b3c6317388eaad34111e309afdfc827f670/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=88e18b3c6317388eaad34111e309afdfc827f670",
            "patch": "@@ -3156,7 +3156,6 @@ def _load_rng_state(self, checkpoint):\n     def _determine_best_metric(self, metrics, trial):\n         \"\"\"\n         Determine if the model should be saved based on the evaluation metrics.\n-        If args.metric_for_best_model is not set, the loss is used.\n \n         Returns:\n             bool: True if a new best metric was found, else False"
        },
        {
            "sha": "a7b2ba0db3a79e8cec3142a4cf9a04cd5a4d4169",
            "filename": "src/transformers/training_args.py",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/88e18b3c6317388eaad34111e309afdfc827f670/src%2Ftransformers%2Ftraining_args.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/88e18b3c6317388eaad34111e309afdfc827f670/src%2Ftransformers%2Ftraining_args.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftraining_args.py?ref=88e18b3c6317388eaad34111e309afdfc827f670",
            "patch": "@@ -476,11 +476,13 @@ class TrainingArguments:\n \n         metric_for_best_model (`str`, *optional*):\n             Use in conjunction with `load_best_model_at_end` to specify the metric to use to compare two different\n-            models. Must be the name of a metric returned by the evaluation with or without the prefix `\"eval_\"`. Will\n-            default to `\"loss\"` if unspecified and `load_best_model_at_end=True` (to use the evaluation loss).\n+            models. Must be the name of a metric returned by the evaluation with or without the prefix `\"eval_\"`.\n \n-            If you set this value, `greater_is_better` will default to `True`. Don't forget to set it to `False` if\n-            your metric is better when lower.\n+            If not specified, this will default to `\"loss\"` when either `load_best_model_at_end == True`\n+            or `lr_scheduler_type == SchedulerType.REDUCE_ON_PLATEAU` (to use the evaluation loss).\n+\n+            If you set this value, `greater_is_better` will default to `True` unless the name ends with \"loss\".\n+            Don't forget to set it to `False` if your metric is better when lower.\n         greater_is_better (`bool`, *optional*):\n             Use in conjunction with `load_best_model_at_end` and `metric_for_best_model` to specify if better models\n             should have a greater metric or not. Will default to:\n@@ -1636,7 +1638,7 @@ def __post_init__(self):\n             self.save_steps = int(self.save_steps)\n \n         # Sanity checks for load_best_model_at_end: we require save and eval strategies to be compatible.\n-        if self.load_best_model_at_end:\n+        if self.load_best_model_at_end and self.save_strategy != SaveStrategy.BEST:\n             if self.eval_strategy != self.save_strategy:\n                 raise ValueError(\n                     \"--load_best_model_at_end requires the save and eval strategy to match, but found\\n- Evaluation \""
        },
        {
            "sha": "f39adf13e0c0c92cfe54dbfe4cf7e8d4a23269bb",
            "filename": "tests/trainer/test_trainer.py",
            "status": "modified",
            "additions": 17,
            "deletions": 2,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/88e18b3c6317388eaad34111e309afdfc827f670/tests%2Ftrainer%2Ftest_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/88e18b3c6317388eaad34111e309afdfc827f670/tests%2Ftrainer%2Ftest_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_trainer.py?ref=88e18b3c6317388eaad34111e309afdfc827f670",
            "patch": "@@ -4220,7 +4220,9 @@ def test_save_best_checkpoint(self):\n                     total=total,\n                 )\n \n-        # Case 3: Metric name not provided; throw error.\n+    def test_metric_for_best_model_behavior(self):\n+        # Case 1: Metric name not provided when `save_strategy == \"best\"`.\n+        # Should raise ValueError.\n         with tempfile.TemporaryDirectory() as tmpdir:\n             with self.assertRaises(ValueError) as context:\n                 trainer = get_regression_trainer(\n@@ -4232,9 +4234,22 @@ def test_save_best_checkpoint(self):\n                     save_strategy=\"best\",\n                     compute_metrics=AlmostAccuracy(),\n                 )\n-\n             self.assertIn(\"`args.metric_for_best_model` must be provided\", str(context.exception))\n \n+        # Case 2: Metric name not provided when `load_best_model_at_end == True`.\n+        # `metric_for_best_model` should be set to `\"loss\"` by default.\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            trainer = get_regression_trainer(\n+                a=1.5,\n+                b=2.5,\n+                output_dir=tmpdir,\n+                learning_rate=0.1,\n+                eval_strategy=\"steps\",\n+                save_strategy=\"steps\",\n+                load_best_model_at_end=True,\n+            )\n+            self.assertTrue(trainer.args.metric_for_best_model == \"loss\")\n+\n \n @require_torch\n @is_staging_test"
        }
    ],
    "stats": {
        "total": 32,
        "additions": 24,
        "deletions": 8
    }
}