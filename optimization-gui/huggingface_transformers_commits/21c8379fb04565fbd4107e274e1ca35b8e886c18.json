{
    "author": "ydshieh",
    "message": "Make debugging failing tests (check and update expect output values) easier ðŸ”¥  (#40727)\n\n* fix\n\n* fix\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "21c8379fb04565fbd4107e274e1ca35b8e886c18",
    "files": [
        {
            "sha": "dd63a629d2c5ad0b929a3bd32004b8f180b28844",
            "filename": "conftest.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/21c8379fb04565fbd4107e274e1ca35b8e886c18/conftest.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21c8379fb04565fbd4107e274e1ca35b8e886c18/conftest.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/conftest.py?ref=21c8379fb04565fbd4107e274e1ca35b8e886c18",
            "patch": "@@ -16,6 +16,7 @@\n # by pytest before any tests are run\n \n import doctest\n+import os\n import sys\n import warnings\n from os.path import abspath, dirname, join\n@@ -27,6 +28,7 @@\n     HfDoctestModule,\n     HfDocTestParser,\n     is_torch_available,\n+    patch_testing_methods_to_collect_info,\n     patch_torch_compile_force_graph,\n )\n \n@@ -145,3 +147,8 @@ def check_output(self, want, got, optionflags):\n     # patch `torch.compile`: if `TORCH_COMPILE_FORCE_FULLGRAPH=1` (or values considered as true, e.g. yes, y, etc.),\n     # the patched version will always run with `fullgraph=True`.\n     patch_torch_compile_force_graph()\n+\n+\n+\n+if os.environ.get(\"PATCH_TESTING_METHODS_TO_COLLECT_OUTPUTS\", \"\").lower() in (\"yes\", \"true\", \"on\", \"y\", \"1\"):\n+    patch_testing_methods_to_collect_info()"
        },
        {
            "sha": "15b32c5fe45cfd0b40bb4d32bcd0141539781334",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 690,
            "deletions": 0,
            "changes": 690,
            "blob_url": "https://github.com/huggingface/transformers/blob/21c8379fb04565fbd4107e274e1ca35b8e886c18/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21c8379fb04565fbd4107e274e1ca35b8e886c18/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=21c8379fb04565fbd4107e274e1ca35b8e886c18",
            "patch": "@@ -12,6 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n+import ast\n import collections\n import contextlib\n import copy\n@@ -31,6 +32,7 @@\n import tempfile\n import threading\n import time\n+import traceback\n import types\n import unittest\n from collections import UserDict, defaultdict\n@@ -3433,6 +3435,384 @@ def patched(*args, **kwargs):\n         torch.compile = patched\n \n \n+def _get_test_info():\n+    \"\"\"\n+    Collect some information about the current test.\n+\n+    For example, test full name, line number, stack, traceback, etc.\n+    \"\"\"\n+\n+    full_test_name = os.environ.get(\"PYTEST_CURRENT_TEST\", \"\").split(\" \")[0]\n+    test_file, test_class, test_name = full_test_name.split(\"::\")\n+\n+    # from the most recent frame to the top frame\n+    stack_from_inspect = inspect.stack()\n+    # but visit from the top frame to the most recent frame\n+\n+    test_frame, test_obj, test_method = None, None, None\n+    for frame in reversed(stack_from_inspect):\n+        if test_file in str(frame).replace(r\"\\\\\", \"/\"):\n+            if test_name == frame.frame.f_locals[\"self\"]._testMethodName:\n+                test_frame = frame\n+                # The test instance\n+                test_obj = frame.frame.f_locals[\"self\"]\n+                test_method = getattr(test_obj, test_name)\n+                break\n+\n+    if test_frame is not None:\n+        line_number = test_frame.lineno\n+\n+    # most inner (recent) to most outer () frames\n+    captured_frames = []\n+    to_capture = False\n+    # up to the test method being called\n+    for frame in reversed(stack_from_inspect):\n+        if test_file in str(frame).replace(r\"\\\\\", \"/\"):\n+            if \"self\" in frame.frame.f_locals and test_name == frame.frame.f_locals[\"self\"]._testMethodName:\n+                to_capture = True\n+        elif \"patched\" in frame.frame.f_code.co_name:\n+            to_capture = False\n+            break\n+        if to_capture:\n+            captured_frames.append(frame)\n+\n+    tb_next = None\n+    for frame_info in reversed(captured_frames):\n+        tb = types.TracebackType(tb_next, frame_info.frame, frame_info.frame.f_lasti, frame_info.frame.f_lineno)\n+        tb_next = tb\n+    test_traceback = tb\n+\n+    stack = traceback.extract_stack()\n+\n+    # The frame that calls this patched method (it may not be the test method)\n+    # -1: `_get_test_info`; -2: `patched_xxx`; -3: the caller to `patched_xxx`\n+    caller_frame = stack[-3]\n+    caller_path = os.path.relpath(caller_frame.filename)\n+    caller_lineno = caller_frame.lineno\n+\n+    test_lineno = line_number\n+\n+    # Get the code context in the test function/method.\n+    from _pytest._code.source import Source\n+\n+    with open(test_file) as fp:\n+        s = fp.read()\n+        source = Source(s)\n+        test_code_context = \"\\n\".join(source.getstatement(test_lineno - 1).lines)\n+\n+    # Get the code context in the caller (to the patched function/method).\n+    with open(caller_path) as fp:\n+        s = fp.read()\n+        source = Source(s)\n+        caller_code_context = \"\\n\".join(source.getstatement(caller_lineno - 1).lines)\n+\n+    test_info = (\n+        f\"test:\\n\\n{full_test_name}\\n\\n{'-' * 80}\\n\\ntest context: {test_file}:{test_lineno}\\n\\n{test_code_context}\"\n+    )\n+    test_info = f\"{test_info}\\n\\n{'-' * 80}\\n\\ncaller context: {caller_path}:{caller_lineno}\\n\\n{caller_code_context}\"\n+\n+    return (\n+        full_test_name,\n+        test_file,\n+        test_lineno,\n+        test_obj,\n+        test_method,\n+        test_frame,\n+        test_traceback,\n+        test_code_context,\n+        caller_path,\n+        caller_lineno,\n+        caller_code_context,\n+        test_info,\n+    )\n+\n+\n+def _get_call_arguments(code_context):\n+    \"\"\"\n+    Analyze the positional and keyword arguments in a call expression.\n+\n+    This will extract the expressions of the positional and kwyword arguments, and associate them to the positions and\n+    the keyword arugment names.\n+    \"\"\"\n+\n+    def get_argument_name(node):\n+        \"\"\"Extract the name/expression from an AST node\"\"\"\n+        if isinstance(node, ast.Name):\n+            return node.id\n+        elif isinstance(node, ast.Attribute):\n+            return ast.unparse(node)\n+        elif isinstance(node, ast.Constant):\n+            return repr(node.value)\n+        else:\n+            return ast.unparse(node)\n+\n+    indent = len(code_context) - len(code_context.lstrip())\n+    code_context = code_context.replace(\" \" * indent, \"\")\n+\n+    try:\n+        # Parse the line\n+        tree = ast.parse(code_context, mode=\"eval\")\n+\n+        assert isinstance(tree.body, ast.Call)\n+        call_node = tree.body\n+\n+        if call_node:\n+            result = {\n+                \"positional_args\": [],\n+                \"keyword_args\": {},\n+                \"starargs\": None,  # *args\n+                \"kwargs\": None,  # **kwargs\n+            }\n+\n+            # Extract positional arguments\n+            for arg in call_node.args:\n+                arg_name = get_argument_name(arg)\n+                result[\"positional_args\"].append(arg_name)\n+\n+            # Extract keyword arguments\n+            for keyword in call_node.keywords:\n+                if keyword.arg is None:\n+                    # This is **kwargs\n+                    result[\"kwargs\"] = get_argument_name(keyword.value)\n+                else:\n+                    # Regular keyword argument\n+                    arg_name = get_argument_name(keyword.value)\n+                    result[\"keyword_args\"][keyword.arg] = arg_name\n+\n+            return result\n+\n+    except (SyntaxError, AttributeError) as e:\n+        print(f\"Error parsing: {e}\")\n+\n+    return None\n+\n+\n+def _prepare_debugging_info(test_info, info):\n+    \"\"\"Combine the information about the test and the call information to a patched function/method within it.\"\"\"\n+\n+    info = f\"{test_info}\\n\\n{info}\"\n+    p = os.path.join(os.environ.get(\"_PATCHED_TESTING_METHODS_OUTPUT_DIR\", \"\"), \"captured_info.txt\")\n+    # TODO (ydshieh): This is not safe when we use pytest-xdist with more than 1 worker.\n+    with open(p, \"a\") as fp:\n+        fp.write(f\"{info}\\n\\n{'=' * 120}\\n\\n\")\n+\n+    return info\n+\n+\n+def _patched_tearDown(self, *args, **kwargs):\n+    \"\"\"Used to report a test that has failures captured and handled by patched functions/methods (without re-raise).\n+\n+    The patched functions/methods refer to the `patched` defined in `_patch_with_call_info`, which is applied to\n+    `torch.testing.assert_close` and `unittest.case.TestCase.assertEqual`.\n+\n+    The objective is to avoid a failure being silence after being processed.\n+\n+    If there is any failure that is not handled by the patched functions/methods, we add custom error message for them\n+    along with the usual pytest failure report.\n+    \"\"\"\n+\n+    # Check for regular failures before clearing:\n+    # when `_patched_tearDown` is called, the current test fails due to an assertion error given by a method being\n+    # patched by `_patch_with_call_info`. The patched method catches such an error and continue running the remaining\n+    # statements within the test. If the test fails with another error not handled by the patched methods, we don't let\n+    # pytest to fail and report it but the original failure (the first one that was processed) instead.\n+    # We still record those failures not handled by the patched methods, and add custom messages along with the usual\n+    # pytest failure report.\n+    regular_failures_info = []\n+    if hasattr(self, \"_outcome\") and self._outcome.errors:\n+        for error_entry in self._outcome.errors:\n+            test_instance, (exc_type, exc_obj, exc_tb) = error_entry\n+            # breakpoint()\n+            regular_failures_info.append(\n+                {\n+                    \"message\": f\"{str(exc_obj)}\\n\\n\",\n+                    \"type\": exc_type.__name__,\n+                    \"file\": \"test_modeling_vit.py\",\n+                    \"line\": 237,  # get_deepest_frame_line(exc_tb)  # Your helper function\n+                }\n+            )\n+\n+        # Clear the regular failure (i.e. that is not from any of our patched assertion methods) from pytest's records.\n+        self._outcome.errors.clear()\n+\n+    # reset back to the original tearDown method, so `_patched_tearDown` won't be run by the subsequent tests if they\n+    # have only test failures that are not handle by the patched methods (or no test failure at all).\n+    orig_tearDown = _patched_tearDown.orig_tearDown\n+    type(self).tearDown = orig_tearDown\n+\n+    # Call the original tearDown\n+    orig_tearDown(self, *args, **kwargs)\n+\n+    # Get the failure\n+    test_method = getattr(self, self._testMethodName)\n+    captured_failures = test_method.__func__.captured_failures[id(test_method)]\n+\n+    # TODO: How could we show several exceptions in a sinigle test on the terminal? (Maybe not a good idea)\n+    captured_exceptions = captured_failures[0][\"exception\"]\n+    captured_traceback = captured_failures[0][\"traceback\"]\n+    # Show the cpatured information on the terminal.\n+    capturued_info = [x[\"info\"] for x in captured_failures]\n+    capturued_info_str = f\"\\n\\n{'=' * 80}\\n\\n\".join(capturued_info)\n+\n+    # Enhance the exception message if there were suppressed failures\n+    if regular_failures_info:\n+        enhanced_message = f\"\"\"{str(captured_exceptions)}\n+\n+{\"=\" * 80}\n+Handled Failures: ({len(capturued_info)} handled):\n+{\"-\" * 80}\\n\n+{capturued_info_str}\n+\n+{\"=\" * 80}\n+Unhandled Failures: ({len(regular_failures_info)} unhandled):\n+{\"-\" * 80}\\n\n+{\", \".join(f\"{info['type']}: {info['message']}{info['file']}:{info['line']}\" for info in regular_failures_info)}\n+\n+{\"-\" * 80}\n+Note: This failure occurred after other failures analyzed by the patched assertion methods.\n+To see the full details, temporarily disable assertion patching.\n+{\"=\" * 80}\"\"\"\n+\n+        # Create new exception with enhanced message\n+        enhanced_exception = type(captured_exceptions)(enhanced_message)\n+        enhanced_exception.__cause__ = captured_exceptions.__cause__\n+        enhanced_exception.__context__ = captured_exceptions.__context__\n+\n+        # Raise with your existing traceback reconstruction\n+        captured_exceptions = enhanced_exception\n+\n+    # clean up the recorded status\n+    del test_method.__func__.captured_failures\n+\n+    raise captured_exceptions.with_traceback(captured_traceback)\n+\n+\n+def _patch_with_call_info(module_or_class, attr_name, _parse_call_info_func, target_args):\n+    \"\"\"\n+    Patch a callerable `attr_name` of a module or class `module_or_class`.\n+\n+    This will allow us to collect the call information, e.g. the argument names and values, also the literal expressions\n+    passed as the arguments.\n+    \"\"\"\n+    orig_method = getattr(module_or_class, attr_name)\n+    if not callable(orig_method):\n+        return\n+\n+    def patched(*args, **kwargs):\n+        # If the target callable is not called within a test, simply call it without modification.\n+        if not os.environ.get(\"PYTEST_CURRENT_TEST\", \"\"):\n+            return orig_method(*args, **kwargs)\n+\n+        try:\n+            orig_method(*args, **kwargs)\n+        except AssertionError as e:\n+            captured_exception = e\n+            # captured_traceback = e.__traceback__\n+            (\n+                full_test_name,\n+                test_file,\n+                test_lineno,\n+                test_obj,\n+                test_method,\n+                test_frame,\n+                test_traceback,\n+                test_code_context,\n+                caller_path,\n+                caller_lineno,\n+                caller_code_context,\n+                test_info,\n+            ) = _get_test_info()\n+            test_info = f\"{test_info}\\n\\n{'-' * 80}\\n\\npatched method: {orig_method.__module__}.{orig_method.__name__}\"\n+            call_argument_expressions = _get_call_arguments(caller_code_context)\n+\n+            # This is specific\n+            info = _parse_call_info_func(orig_method, args, kwargs, call_argument_expressions, target_args)\n+            info = _prepare_debugging_info(test_info, info)\n+\n+            # Save this, so we can raise at the end of the current test\n+            captured_failure = {\n+                \"result\": \"failed\",\n+                \"exception\": captured_exception,\n+                \"traceback\": test_traceback,\n+                \"info\": info,\n+            }\n+\n+            # Record the failure status and its information, so we can raise it later.\n+            # We are modifying the (unbound) function at class level: not its logic but only adding a new extra\n+            # attribute.\n+            if getattr(test_method.__func__, \"captured_failures\", None) is None:\n+                test_method.__func__.captured_failures = {}\n+            if id(test_method) not in test_method.__func__.captured_failures:\n+                test_method.__func__.captured_failures[id(test_method)] = []\n+            test_method.__func__.captured_failures[id(test_method)].append(captured_failure)\n+\n+            # This modifies the `tearDown` which will be called after every tests, but we reset it back inside\n+            # `_patched_tearDown`.\n+            if not hasattr(type(test_obj).tearDown, \"orig_tearDown\"):\n+                orig_tearDown = type(test_obj).tearDown\n+                _patched_tearDown.orig_tearDown = orig_tearDown\n+                type(test_obj).tearDown = _patched_tearDown\n+\n+    setattr(module_or_class, attr_name, patched)\n+\n+\n+def _parse_call_info(func, args, kwargs, call_argument_expressions, target_args):\n+    \"\"\"\n+    Prepare a string containing the call info to `func`, e.g. argument names/values/expressions.\n+    \"\"\"\n+    signature = inspect.signature(func)\n+    signature_names = [param.name for param_name, param in signature.parameters.items()]\n+\n+    # called as `self.method_name()` or `xxx.method_name()`.\n+    if len(args) == len(call_argument_expressions[\"positional_args\"]) + 1:\n+        # We simply add \"self\" as the expression despite it might not be the actual argument name.\n+        # (This part is very unlikely what a user would be interest to know)\n+        call_argument_expressions[\"positional_args\"] = [\"self\"] + call_argument_expressions[\"positional_args\"]\n+\n+    param_position_mapping = {param_name: idx for idx, param_name in enumerate(signature_names)}\n+\n+    arg_info = {}\n+    for arg_name in target_args:\n+        if arg_name in kwargs:\n+            arg_value = kwargs[arg_name]\n+            arg_expr = call_argument_expressions[\"keyword_args\"][arg_name]\n+        else:\n+            arg_pos = param_position_mapping[arg_name]\n+            arg_value = args[arg_pos]\n+            arg_expr = call_argument_expressions[\"positional_args\"][arg_pos]\n+\n+        arg_value_str = _format_py_obj(arg_value)\n+        arg_info[arg_name] = {\"arg_expr\": arg_expr, \"arg_value_str\": arg_value_str}\n+\n+    info = \"\"\n+    for arg_name in arg_info:\n+        arg_expr, arg_value_str = arg_info[arg_name][\"arg_expr\"], arg_info[arg_name][\"arg_value_str\"]\n+        info += f\"{'-' * 80}\\n\\nargument name: `{arg_name}`\\nargument expression: `{arg_expr}`\\n\\nargument value:\\n\\n{arg_value_str}\\n\\n\"\n+\n+    # remove the trailing \\n\\n\n+    info = info[:-2]\n+\n+    return info\n+\n+\n+def patch_testing_methods_to_collect_info():\n+    \"\"\"\n+    Patch some methods (`torch.testing.assert_close`, `unittest.case.TestCase.assertEqual`, etc).\n+\n+    This will allow us to collect the call information, e.g. the argument names and values, also the literal expressions\n+    passed as the arguments.\n+    \"\"\"\n+    p = os.path.join(os.environ.get(\"_PATCHED_TESTING_METHODS_OUTPUT_DIR\", \"\"), \"captured_info.txt\")\n+    Path(p).unlink(missing_ok=True)\n+\n+    if is_torch_available():\n+        import torch\n+\n+        _patch_with_call_info(torch.testing, \"assert_close\", _parse_call_info, target_args=(\"actual\", \"expected\"))\n+\n+    _patch_with_call_info(unittest.case.TestCase, \"assertEqual\", _parse_call_info, target_args=(\"first\", \"second\"))\n+\n+\n def torchrun(script: str, nproc_per_node: int, is_torchrun: bool = True, env: Optional[dict] = None):\n     \"\"\"Run the `script` using `torchrun` command for multi-processing in a subprocess. Captures errors as necessary.\"\"\"\n     with tempfile.NamedTemporaryFile(mode=\"w+\", suffix=\".py\") as tmp:\n@@ -3451,3 +3831,313 @@ def torchrun(script: str, nproc_per_node: int, is_torchrun: bool = True, env: Op\n             _ = subprocess.run(cmd, capture_output=True, env=env, text=True, check=True)\n         except subprocess.CalledProcessError as e:\n             raise Exception(f\"The following error was captured: {e.stderr}\")\n+\n+\n+def _format_tensor(t, indent_level=0, sci_mode=None):\n+    \"\"\"Format torch's tensor in a pretty way to be shown ðŸ‘€ in the test report.\"\"\"\n+\n+    # `torch.testing.assert_close` could accept python int/float numbers.\n+    if not isinstance(t, torch.Tensor):\n+        t = torch.tensor(t)\n+\n+    # Simply make the processing below simpler (not to hande both case)\n+    is_scalar = False\n+    if t.ndim == 0:\n+        t = torch.tensor([t])\n+        is_scalar = True\n+\n+    # For scalar or one-dimensional tensor, keep it as one-line. If there is only one element along any dimension except\n+    # the last one, we also keep it as one-line.\n+    if t.ndim <= 1 or set(t.shape[0:-1]) == {1}:\n+        # Use `detach` to remove `grad_fn=<...>`, and use `to(\"cpu\")` to remove `device='...'`\n+        t = t.detach().to(\"cpu\")\n+\n+        # We work directly with the string representation instead the tensor itself\n+        t_str = str(t)\n+\n+        # remove `tensor( ... )` so keep only the content\n+        t_str = t_str.replace(\"tensor(\", \"\").replace(\")\", \"\")\n+\n+        # Sometimes there are extra spaces between `[` and the first digit of the first value (for alignment).\n+        # For example `[[ 0.06, -0.51], [-0.76, -0.49]]`. It may have multiple consecutive spaces.\n+        # Let's remove such extra spaces.\n+        while \"[ \" in t_str:\n+            t_str = t_str.replace(\"[ \", \"[\")\n+\n+        # Put everything in a single line. We replace `\\n` by a space ` ` so we still keep `,\\n` as `, `.\n+        t_str = t_str.replace(\"\\n\", \" \")\n+\n+        # Remove repeated spaces (introduced by the previous step)\n+        while \"  \" in t_str:\n+            t_str = t_str.replace(\"  \", \" \")\n+\n+        # remove leading `[` and `]` for scalar tensor\n+        if is_scalar:\n+            t_str = t_str[1:-1]\n+\n+        t_str = \" \" * 4 * indent_level + t_str\n+\n+        return t_str\n+\n+    # Otherwise, we separte the representations of every elements along an outer dimension by new lines (after a `,`).\n+    # The representatioin each element is obtained by calling this function recursively with corrent `indent_level`.\n+    else:\n+        t_str = str(t)\n+\n+        # (For the recursive calls should receive this value)\n+        if sci_mode is None:\n+            sci_mode = \"e+\" in t_str or \"e-\" in t_str\n+\n+        # Use the original content to determine the scientific mode to use. This is required as the representation of\n+        # t[index] (computed below) maybe have different format regarding scientific notation.\n+        torch.set_printoptions(sci_mode=sci_mode)\n+\n+        t_str = \" \" * 4 * indent_level + \"[\\n\"\n+        # Keep the ending `,` for all outer dimensions whose representations are not put in one-line, even if there is\n+        # only one element along that dimension.\n+        t_str += \",\\n\".join(_format_tensor(x, indent_level=indent_level + 1, sci_mode=sci_mode) for x in t)\n+        t_str += \",\\n\" + \" \" * 4 * indent_level + \"]\"\n+\n+        torch.set_printoptions(sci_mode=None)\n+\n+    return t_str\n+\n+\n+def _quote_string(s):\n+    \"\"\"Given a string `s`, return a python literal expression that give `s` when it is used in a python source code.\n+\n+    For example, if `s` is the string `abc`, the return value is `\"abc\"`.\n+\n+    We choice double quotes over single quote despite `str(s)` would give `'abc'` instead of `\"abc\"`.\n+    \"\"\"\n+    has_single_quote = \"'\" in s\n+    has_double_quote = '\"' in s\n+\n+    if has_single_quote and has_double_quote:\n+        # replace any double quote by the raw string r'\\\"'.\n+        s = s.replace('\"', r\"\\\"\")\n+        return f'\"{s}\"'\n+    elif has_single_quote:\n+        return f'\"{s}\"'\n+    elif has_double_quote:\n+        return f\"'{s}'\"\n+    else:\n+        return f'\"{s}\"'\n+\n+\n+def _format_py_obj(obj, indent=0, mode=\"\", cache=None, prefix=\"\"):\n+    \"\"\"Format python objects of basic built-in type in a pretty way so we could copy-past them to code editor easily.\n+\n+    Currently, this support int, float, str, list, tuple, and dict.\n+\n+    It also works with `torch.Tensor` via calling `format_tesnor`.\n+    \"\"\"\n+\n+    if cache is None:\n+        cache = {}\n+    else:\n+        if (id(obj), indent, mode, prefix) in cache:\n+            return cache[(id(obj), indent, mode, prefix)]\n+\n+    # special format method for `torch.Tensor`\n+    if str(obj.__class__) == \"<class 'torch.Tensor'>\":\n+        return _format_tensor(obj)\n+\n+    elif obj.__class__.__name__ == \"str\":\n+        quoted_string = _quote_string(obj)\n+        # we don't want the newline being interpreted\n+        quoted_string = quoted_string.replace(\"\\n\", r\"\\n\")\n+        output = quoted_string\n+\n+    elif obj.__class__.__name__ in [\"int\", \"float\"]:\n+        # for float like `1/3`, we will get `0.3333333333333333`\n+        output = str(obj)\n+\n+    elif obj.__class__.__name__ in [\"list\", \"tuple\", \"dict\"]:\n+        parenthesis = {\n+            \"list\": \"[]\",\n+            \"tuple\": \"()\",\n+            \"dict\": \"{}\",\n+        }\n+        p1, p2 = parenthesis[obj.__class__.__name__]\n+\n+        elements_without_indent = []\n+        if isinstance(obj, dict):\n+            for idx, (k, v) in enumerate(obj.items()):\n+                last_element = idx == len(obj) - 1\n+                ok = _format_py_obj(k, indent=indent + 1, mode=\"one-line\", cache=cache)\n+                ov = _format_py_obj(\n+                    v,\n+                    indent=indent + 1,\n+                    mode=mode,\n+                    cache=cache,\n+                    prefix=ok.lstrip() + \": \" + \",\" if not last_element else \"\",\n+                )\n+                # Each element could be multiple-line, but the indent of its first line is removed\n+                elements_without_indent.append(f\"{ok.lstrip()}: {ov.lstrip()}\")\n+\n+        else:\n+            for idx, x in enumerate(obj):\n+                last_element = idx == len(obj) - 1\n+                o = _format_py_obj(\n+                    x, indent=indent + 1, mode=mode, cache=cache, prefix=\",\" if not last_element else \"\"\n+                )\n+                # Each element could be multiple-line, but the indent of its first line is removed\n+                elements_without_indent.append(o.lstrip())\n+\n+        groups = []\n+        buf = []\n+        for idx, x in enumerate(elements_without_indent):\n+            buf.append(x)\n+\n+            x_expanded = \"\\n\" in buf[-1]\n+            not_last_element = idx != len(elements_without_indent) - 1\n+            # if `x` should be separated from subsequent elements\n+            should_finalize_x = x_expanded or len(f\"{' ' * (4 * (indent + 1))}\") + len(\n+                \", \".join(buf[-1:])\n+            ) > 120 - int(not_last_element)\n+\n+            # if `buf[:-1]` (i.e. without `x`) should be combined together (into one line)\n+            should_finalize_buf = x_expanded\n+\n+            # the recursive call returns single line, so we can use it to determine if we can fit the width limit\n+            if not should_finalize_buf:\n+                buf_not_fit_into_one_line = len(f\"{' ' * (4 * (indent + 1))}\") + len(\", \".join(buf)) > 120 - int(\n+                    not_last_element\n+                )\n+                should_finalize_buf = buf_not_fit_into_one_line\n+\n+            # any element of iterable type need to be on its own line\n+            if (type(obj[idx]) if type(obj) is not dict else type(list(obj.values())[idx])) in [list, tuple, dict]:\n+                should_finalize_x = True\n+                should_finalize_buf = True\n+\n+            # any type change --> need to be added after a new line\n+            prev_type = None\n+            current_type = type(obj[idx]) if type(obj) is not dict else type(list(obj.values())[idx])\n+            if len(buf) > 1:\n+                prev_type = type(obj[idx - 1]) if type(obj) is not dict else type(list(obj.values())[idx - 1])\n+                type_changed = current_type != prev_type\n+                if type_changed:\n+                    should_finalize_buf = True\n+\n+            # all elements in the buf are string --> don't finalize the buf by width limit\n+            if prev_type is None or (prev_type is str and current_type is str):\n+                should_finalize_buf = False\n+\n+            # collect as many elements of string type as possible (without width limit).\n+            # These will be examined as a whole (if not fit into the width, each element would be in its own line)\n+            if current_type is str:\n+                should_finalize_x = False\n+                # `len(buf) == 1` or `obj[idx-1]` is a string\n+                if prev_type in [None, str]:\n+                    should_finalize_buf = False\n+\n+            if should_finalize_buf:\n+                orig_buf_len = len(buf)\n+\n+                if orig_buf_len > 1:\n+                    not_fit_into_one_line = None\n+\n+                    # all elements in `obj` that give `buf[:-1]` are string.\n+                    if prev_type is str:\n+                        # `-1` at the end: because buf[-2] is not the last element\n+                        not_fit_into_one_line = len(f\"{' ' * (4 * (indent + 1))}\") + len(\", \".join(buf[:-1])) > 120 - 1\n+\n+                    if not_fit_into_one_line:\n+                        for x in buf[:-1]:\n+                            groups.append([x])\n+                    else:\n+                        groups.append(buf[:-1])\n+\n+                    buf = buf[-1:]\n+\n+                if should_finalize_x:\n+                    groups.append(buf)\n+                    buf = []\n+\n+        # The last buf\n+        if len(buf) > 0:\n+            not_fit_into_one_line = None\n+            if current_type is str:\n+                # no `-1` at the end: because buf[-1] is the last element\n+                not_fit_into_one_line = len(f\"{' ' * (4 * (indent + 1))}\") + len(\", \".join(buf)) > 120\n+\n+            if not_fit_into_one_line:\n+                for x in buf:\n+                    groups.append([x])\n+            else:\n+                groups.append(buf)\n+\n+        output = f\"{' ' * 4 * indent}{p1}\\n\"\n+        element_strings = [f\"{' ' * (4 * (indent + 1))}\" + \", \".join(buf) for buf in groups]\n+        output += \",\\n\".join(element_strings)\n+        output += f\"\\n{' ' * 4 * indent}{p2}\"\n+\n+        # if all elements are in one-line\n+        no_new_line_in_elements = all(\"\\n\" not in x for x in element_strings)\n+        # if yes, we can form a one-line representation of `obj`\n+        could_use_one_line = no_new_line_in_elements\n+\n+        # if mode == \"one-line\", this function always returns one-line representation, so `no_new_line_in_elements`\n+        # will be `True`.\n+        if could_use_one_line:\n+            one_line_form = \", \".join([x.lstrip() for x in element_strings])\n+            one_line_form = f\"{p1}{one_line_form}{p2}\"\n+\n+            if mode == \"one-line\":\n+                return output\n+\n+            # check with the width limit\n+            could_use_one_line = len(f\"{' ' * 4 * indent}\") + len(prefix) + len(one_line_form) <= 120\n+\n+            # extra conditions for returning one-line representation\n+            def use_one_line_repr(obj):\n+                # interable types\n+                if type(obj) in (list, tuple, dict):\n+                    # get all types\n+                    element_types = []\n+                    if type(obj) is dict:\n+                        element_types.extend(type(x) for x in obj.values())\n+                    elif type(obj) in [list, tuple]:\n+                        element_types.extend(type(x) for x in obj)\n+\n+                    # At least one element is of iterable type\n+                    if any(x in (list, tuple, dict) for x in element_types):\n+                        # If `obj` has more than one element and at least one of them is iterable --> no one line repr.\n+                        if len(obj) > 1:\n+                            return False\n+\n+                        # only one element that is iterable, but not the same type as `obj` --> no one line repr.\n+                        if type(obj) is not type(obj[0]):\n+                            return False\n+\n+                        # one-line repr. if possible, without width limit\n+                        return no_new_line_in_elements\n+\n+                    # all elements are of simple types, but more than one type --> no one line repr.\n+                    if len(set(element_types)) > 1:\n+                        return False\n+\n+                    # all elements are of the same simple type\n+                    if element_types[0] in [int, float]:\n+                        # one-line repr. without width limit\n+                        return no_new_line_in_elements\n+                    elif element_types[0] in [str]:\n+                        if len(obj) == 1:\n+                            # one single string element --> one-line repr. without width limit\n+                            return no_new_line_in_elements\n+                        else:\n+                            # multiple string elements --> one-line repr. if fit into width limit\n+                            return could_use_one_line\n+\n+                # simple types (int, flat, string)\n+                return True\n+\n+            # width condition combined with specific mode conditions\n+            if use_one_line_repr(obj):\n+                output = f\"{' ' * 4 * indent}{one_line_form}\"\n+\n+    cache[(id(obj), indent, mode, prefix)] = output\n+\n+    return output"
        }
    ],
    "stats": {
        "total": 697,
        "additions": 697,
        "deletions": 0
    }
}