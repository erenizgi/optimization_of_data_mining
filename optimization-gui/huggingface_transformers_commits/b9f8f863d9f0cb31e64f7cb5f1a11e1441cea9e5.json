{
    "author": "eustlb",
    "message": "[CSM] update model id (#38211)\n\n* update model id\n\n* codec_model eval\n\n* add processor img\n\n* use ungated repo for processor tests",
    "sha": "b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5",
    "files": [
        {
            "sha": "833ddb697b55a44aca1885708f8d2019dc2507b0",
            "filename": "docs/source/en/model_doc/csm.md",
            "status": "modified",
            "additions": 9,
            "deletions": 5,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/docs%2Fsource%2Fen%2Fmodel_doc%2Fcsm.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/docs%2Fsource%2Fen%2Fmodel_doc%2Fcsm.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fcsm.md?ref=b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5",
            "patch": "@@ -39,7 +39,7 @@ CSM can be used to simply generate speech from a text prompt:\n import torch\n from transformers import CsmForConditionalGeneration, AutoProcessor\n \n-model_id = \"eustlb/csm-1b\"\n+model_id = \"sesame/csm-1b\"\n device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n \n # load the model and the processor\n@@ -74,7 +74,7 @@ import torch\n from transformers import CsmForConditionalGeneration, AutoProcessor\n from datasets import load_dataset, Audio\n \n-model_id = \"eustlb/csm-1b\"\n+model_id = \"sesame/csm-1b\"\n device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n \n # load the model and the processor\n@@ -119,7 +119,7 @@ import torch\n from transformers import CsmForConditionalGeneration, AutoProcessor\n from datasets import load_dataset, Audio\n \n-model_id = \"eustlb/csm-1b\"\n+model_id = \"sesame/csm-1b\"\n device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n \n # load the model and the processor\n@@ -176,7 +176,7 @@ import copy\n from transformers import CsmForConditionalGeneration, AutoProcessor\n from datasets import load_dataset\n \n-model_id = \"eustlb/csm-1b\"\n+model_id = \"sesame/csm-1b\"\n device = \"cuda\"\n \n # set logs to ensure no recompilation and graph breaks\n@@ -308,7 +308,7 @@ CSM Transformers integration supports training!\n from transformers import CsmForConditionalGeneration, AutoProcessor\n from datasets import load_dataset, Audio\n \n-model_id = \"eustlb/csm-1b\"\n+model_id = \"sesame/csm-1b\"\n device = \"cuda\"\n \n # load the model and the processor\n@@ -356,6 +356,10 @@ The original code can be found [here](https://github.com/SesameAILabs/csm).\n \n ## CsmProcessor\n \n+<div class=\"flex justify-center\">\n+    <img src=\"https://huggingface.co/datasets/eustlb/documentation-images/resolve/main/fig1.jpg\"/>\n+</div>\n+\n [[autodoc]] CsmProcessor\n     - __call__\n "
        },
        {
            "sha": "b13b9d2a873a8c63f5d23810f3670506edff02d4",
            "filename": "src/transformers/models/csm/configuration_csm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/src%2Ftransformers%2Fmodels%2Fcsm%2Fconfiguration_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/src%2Ftransformers%2Fmodels%2Fcsm%2Fconfiguration_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcsm%2Fconfiguration_csm.py?ref=b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5",
            "patch": "@@ -28,7 +28,7 @@ class CsmDepthDecoderConfig(PretrainedConfig):\n     model according to the specified arguments, defining the model architecture. Instantiating a configuration with the defaults will yield\n     a similar configuration to that of the csm-1b.\n \n-    e.g. [eustlb/csm-1b](https://huggingface.co/eustlb/csm-1b)\n+    e.g. [sesame/csm-1b](https://huggingface.co/sesame/csm-1b)\n \n     Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the\n     documentation from [`PretrainedConfig`] for more information.\n@@ -210,7 +210,7 @@ class CsmConfig(PretrainedConfig):\n     model according to the specified arguments, defining the model architecture. Instantiating a configuration\n     with the defaults will yield a similar configuration to that of the csm-1b.\n \n-    e.g. [eustlb/csm-1b](https://huggingface.co/eustlb/csm-1b)\n+    e.g. [sesame/csm-1b](https://huggingface.co/sesame/csm-1b)\n \n     Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the\n     documentation from [`PretrainedConfig`] for more information."
        },
        {
            "sha": "7afc7c2d60c6651ad9d7cb4bca7db5c61bf4b838",
            "filename": "src/transformers/models/csm/generation_csm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/src%2Ftransformers%2Fmodels%2Fcsm%2Fgeneration_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/src%2Ftransformers%2Fmodels%2Fcsm%2Fgeneration_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcsm%2Fgeneration_csm.py?ref=b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5",
            "patch": "@@ -415,7 +415,7 @@ def generate(\n         >>> from transformers import CsmProcessor, CsmForConditionalGeneration\n         >>> from datasets import load_dataset, Audio\n \n-        >>> model_id = \"eustlb/csm-1b\"\n+        >>> model_id = \"sesame/csm-1b\"\n         >>> torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n \n         >>> processor = AutoProcessor.from_pretrained(model_id)"
        },
        {
            "sha": "c0c4f5927a5719efc1f193dd4542cb67e8d9c43b",
            "filename": "src/transformers/models/csm/modeling_csm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodeling_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodeling_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodeling_csm.py?ref=b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5",
            "patch": "@@ -1113,7 +1113,7 @@ def forward(\n         >>> from transformers import CsmForConditionalGeneration, AutoProcessor\n         >>> from datasets import load_dataset, Audio\n \n-        >>> model_id = \"eustlb/csm-1b\"\n+        >>> model_id = \"sesame/csm-1b\"\n         >>> torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n \n         >>> processor = AutoProcessor.from_pretrained(model_id)"
        },
        {
            "sha": "4322a2a07f8c12301cf14913c1cbd8a81ade58d3",
            "filename": "src/transformers/models/csm/modular_csm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodular_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodular_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodular_csm.py?ref=b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5",
            "patch": "@@ -727,7 +727,7 @@ def forward(\n         >>> from transformers import CsmForConditionalGeneration, AutoProcessor\n         >>> from datasets import load_dataset, Audio\n \n-        >>> model_id = \"eustlb/csm-1b\"\n+        >>> model_id = \"sesame/csm-1b\"\n         >>> torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n \n         >>> processor = AutoProcessor.from_pretrained(model_id)"
        },
        {
            "sha": "ca516d82640038f7895f7509dfbb89f58fb1bdeb",
            "filename": "src/transformers/models/csm/processing_csm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/src%2Ftransformers%2Fmodels%2Fcsm%2Fprocessing_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/src%2Ftransformers%2Fmodels%2Fcsm%2Fprocessing_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcsm%2Fprocessing_csm.py?ref=b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5",
            "patch": "@@ -76,7 +76,7 @@ class CsmProcessor(ProcessorMixin):\n         ds = load_dataset(\"hf-internal-testing/dailytalk-dummy\", split=\"train\")\n         audio = ds[0][\"audio\"][\"array\"]\n \n-        processor = CsmProcessor.from_pretrained(\"eustlb/csm-1b\")\n+        processor = CsmProcessor.from_pretrained(\"sesame/csm-1b\")\n \n         processor(\n             text=[\"<|begin_of_text|>[0]What are you working on?<|end_of_text|><|AUDIO|><|audio_eos|><|begin_of_text|>[1]I'm figuring out my budget.<|end_of_text|>\"],"
        },
        {
            "sha": "2425ff35ecf5e38032df45da0417e26bf9b0b5cd",
            "filename": "tests/models/csm/test_modeling_csm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/tests%2Fmodels%2Fcsm%2Ftest_modeling_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/tests%2Fmodels%2Fcsm%2Ftest_modeling_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fcsm%2Ftest_modeling_csm.py?ref=b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5",
            "patch": "@@ -417,7 +417,7 @@ def _get_custom_4d_mask_test_data(self):\n class CsmForConditionalGenerationIntegrationTest(unittest.TestCase):\n     def setUp(self):\n         # TODO: @eustlb, update with correct sesame's repo\n-        self.model_checkpoint = \"eustlb/csm-1b\"\n+        self.model_checkpoint = \"sesame/csm-1b\"\n \n     def tearDown(self):\n         cleanup(torch_device, gc_collect=True)"
        },
        {
            "sha": "dcd344d120362258aafef16e4452d02de7c3e6e2",
            "filename": "tests/models/csm/test_processor_csm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/tests%2Fmodels%2Fcsm%2Ftest_processor_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5/tests%2Fmodels%2Fcsm%2Ftest_processor_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fcsm%2Ftest_processor_csm.py?ref=b9f8f863d9f0cb31e64f7cb5f1a11e1441cea9e5",
            "patch": "@@ -37,8 +37,7 @@ class CsmProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n \n     @classmethod\n     def setUpClass(cls):\n-        # TODO: @eustlb, change for hf-internal-testing/csm-1b\n-        cls.checkpoint = \"eustlb/csm-1b\"\n+        cls.checkpoint = \"hf-internal-testing/namespace-sesame-repo_name_csm-1b\"\n         processor = CsmProcessor.from_pretrained(cls.checkpoint)\n         cls.audio_token = processor.audio_token\n         cls.audio_token_id = processor.audio_token_id"
        }
    ],
    "stats": {
        "total": 31,
        "additions": 17,
        "deletions": 14
    }
}