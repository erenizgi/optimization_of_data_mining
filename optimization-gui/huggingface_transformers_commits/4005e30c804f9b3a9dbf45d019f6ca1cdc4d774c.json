{
    "author": "OliBomby",
    "message": "Fix incorrect attention mask truncate in WhisperFlashAttention2 (#36477)\n\n* Fix incorrect attention mask truncate in whisper flash attention\n\n* also fix incorrect attention mask truncate in qwen2 audio\n\n* Nit attention mask truncate modeling_qwen2_audio.py\n\n* Nit attention mask truncate modeling_whisper.py\n\nCo-authored-by: Anton Vlasjuk <73884904+vasqu@users.noreply.github.com>\n\n---------\n\nCo-authored-by: Anton Vlasjuk <73884904+vasqu@users.noreply.github.com>\nCo-authored-by: eustlb <94853470+eustlb@users.noreply.github.com>",
    "sha": "4005e30c804f9b3a9dbf45d019f6ca1cdc4d774c",
    "files": [
        {
            "sha": "201120e3847be651bbd161752fd5ddebc3f93003",
            "filename": "src/transformers/models/qwen2_audio/modeling_qwen2_audio.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/4005e30c804f9b3a9dbf45d019f6ca1cdc4d774c/src%2Ftransformers%2Fmodels%2Fqwen2_audio%2Fmodeling_qwen2_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4005e30c804f9b3a9dbf45d019f6ca1cdc4d774c/src%2Ftransformers%2Fmodels%2Fqwen2_audio%2Fmodeling_qwen2_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_audio%2Fmodeling_qwen2_audio.py?ref=4005e30c804f9b3a9dbf45d019f6ca1cdc4d774c",
            "patch": "@@ -235,7 +235,7 @@ def forward(\n \n         causal_mask = attention_mask\n         if attention_mask is not None:  # no matter the length, we just slice it\n-            causal_mask = attention_mask[:, : key_states.shape[-2]]\n+            causal_mask = attention_mask[:, : key_states.shape[1]]\n \n         # In PEFT, usually we cast the layer norms in float32 for training stability reasons\n         # therefore the input hidden states gets silently casted in float32. Hence, we need"
        },
        {
            "sha": "fc320dd6cfd83613425caa145898edc1258b44ff",
            "filename": "src/transformers/models/whisper/modeling_whisper.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/4005e30c804f9b3a9dbf45d019f6ca1cdc4d774c/src%2Ftransformers%2Fmodels%2Fwhisper%2Fmodeling_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4005e30c804f9b3a9dbf45d019f6ca1cdc4d774c/src%2Ftransformers%2Fmodels%2Fwhisper%2Fmodeling_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Fmodeling_whisper.py?ref=4005e30c804f9b3a9dbf45d019f6ca1cdc4d774c",
            "patch": "@@ -417,7 +417,7 @@ def forward(\n \n         causal_mask = attention_mask\n         if attention_mask is not None:  # no matter the length, we just slice it\n-            causal_mask = attention_mask[:, : key_states.shape[-2]]\n+            causal_mask = attention_mask[:, : key_states.shape[1]]\n \n         # In PEFT, usually we cast the layer norms in float32 for training stability reasons\n         # therefore the input hidden states gets silently casted in float32. Hence, we need"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}