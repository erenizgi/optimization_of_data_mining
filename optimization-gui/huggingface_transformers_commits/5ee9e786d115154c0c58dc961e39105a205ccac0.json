{
    "author": "subhalingamd",
    "message": "Fix default behaviour in TextClassificationPipeline for regression problem type (#34066)\n\n* update code\r\n\r\n* update docstrings\r\n\r\n* update tests",
    "sha": "5ee9e786d115154c0c58dc961e39105a205ccac0",
    "files": [
        {
            "sha": "dadb29c386b41e4ca3bd1a49ee103308c3f02174",
            "filename": "src/transformers/pipelines/text_classification.py",
            "status": "modified",
            "additions": 8,
            "deletions": 3,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/5ee9e786d115154c0c58dc961e39105a205ccac0/src%2Ftransformers%2Fpipelines%2Ftext_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5ee9e786d115154c0c58dc961e39105a205ccac0/src%2Ftransformers%2Fpipelines%2Ftext_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftext_classification.py?ref=5ee9e786d115154c0c58dc961e39105a205ccac0",
            "patch": "@@ -40,7 +40,8 @@ class ClassificationFunction(ExplicitEnum):\n             The function to apply to the model outputs in order to retrieve the scores. Accepts four different values:\n \n             - `\"default\"`: if the model has a single label, will apply the sigmoid function on the output. If the model\n-              has several labels, will apply the softmax function on the output.\n+              has several labels, will apply the softmax function on the output. In case of regression tasks, will not\n+              apply any function on the output.\n             - `\"sigmoid\"`: Applies the sigmoid function on the output.\n             - `\"softmax\"`: Applies the softmax function on the output.\n             - `\"none\"`: Does not apply any function on the output.\"\"\",\n@@ -69,7 +70,8 @@ class TextClassificationPipeline(Pipeline):\n     `\"sentiment-analysis\"` (for classifying sequences according to positive or negative sentiments).\n \n     If multiple classification labels are available (`model.config.num_labels >= 2`), the pipeline will run a softmax\n-    over the results. If there is a single label, the pipeline will run a sigmoid over the result.\n+    over the results. If there is a single label, the pipeline will run a sigmoid over the result. In case of regression\n+    tasks (`model.config.problem_type == \"regression\"`), will not apply any function on the output.\n \n     The models that this pipeline can use are models that have been fine-tuned on a sequence classification task. See\n     the up-to-date list of available models on\n@@ -135,6 +137,7 @@ def __call__(self, inputs, **kwargs):\n                 If this argument is not specified, then it will apply the following functions according to the number\n                 of labels:\n \n+                - If problem type is regression, will not apply any function on the output.\n                 - If the model has a single label, will apply the sigmoid function on the output.\n                 - If the model has several labels, will apply the softmax function on the output.\n \n@@ -192,7 +195,9 @@ def postprocess(self, model_outputs, function_to_apply=None, top_k=1, _legacy=Tr\n         # the more natural result containing the list.\n         # Default value before `set_parameters`\n         if function_to_apply is None:\n-            if self.model.config.problem_type == \"multi_label_classification\" or self.model.config.num_labels == 1:\n+            if self.model.config.problem_type == \"regression\":\n+                function_to_apply = ClassificationFunction.NONE\n+            elif self.model.config.problem_type == \"multi_label_classification\" or self.model.config.num_labels == 1:\n                 function_to_apply = ClassificationFunction.SIGMOID\n             elif self.model.config.problem_type == \"single_label_classification\" or self.model.config.num_labels > 1:\n                 function_to_apply = ClassificationFunction.SOFTMAX"
        },
        {
            "sha": "23625f0d77b39e6ae386898bd688ec7d1c0cd1a8",
            "filename": "tests/pipelines/test_pipelines_text_classification.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/5ee9e786d115154c0c58dc961e39105a205ccac0/tests%2Fpipelines%2Ftest_pipelines_text_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5ee9e786d115154c0c58dc961e39105a205ccac0/tests%2Fpipelines%2Ftest_pipelines_text_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_text_classification.py?ref=5ee9e786d115154c0c58dc961e39105a205ccac0",
            "patch": "@@ -108,6 +108,12 @@ def test_small_model_pt(self):\n             ],\n         )\n \n+        # Do not apply any function to output for regression tasks\n+        # hack: changing problem_type artifically (so keep this test at last)\n+        text_classifier.model.config.problem_type = \"regression\"\n+        outputs = text_classifier(\"This is great !\")\n+        self.assertEqual(nested_simplify(outputs), [{\"label\": \"LABEL_0\", \"score\": 0.01}])\n+\n     @require_torch\n     def test_accepts_torch_device(self):\n         text_classifier = pipeline("
        }
    ],
    "stats": {
        "total": 17,
        "additions": 14,
        "deletions": 3
    }
}