{
    "author": "jiqing-feng",
    "message": "Compress (#42643)\n\n* fix compressed tensor tests\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\n\n* update\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\n\n* update comment\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\n\n* format\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\n\n---------\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>",
    "sha": "28906c3c25cf7cc2fa6bc6ff261f6170ea79b508",
    "files": [
        {
            "sha": "15d29e47f4a09df7c9c7f0b911d6b9d11fb0186c",
            "filename": "tests/quantization/compressed_tensors_integration/test_compressed_models.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28906c3c25cf7cc2fa6bc6ff261f6170ea79b508/tests%2Fquantization%2Fcompressed_tensors_integration%2Ftest_compressed_models.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28906c3c25cf7cc2fa6bc6ff261f6170ea79b508/tests%2Fquantization%2Fcompressed_tensors_integration%2Ftest_compressed_models.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fquantization%2Fcompressed_tensors_integration%2Ftest_compressed_models.py?ref=28906c3c25cf7cc2fa6bc6ff261f6170ea79b508",
            "patch": "@@ -80,7 +80,9 @@ def _has_nested_attr(obj, attr_path):\n                     if comp_decomp_obj is not None and hasattr(submodule, \"weight\"):\n                         if \"sparse-only\" in uncompressed_model:\n                             self.assertTrue(\n-                                torch.equal(submodule.weight, comp_decomp_obj.weight),\n+                                torch.equal(\n+                                    submodule.weight.to(torch_device), comp_decomp_obj.weight.to(torch_device)\n+                                ),\n                                 f\"Weight mismatch for module '{name}' in sparse-only model.\",\n                             )\n                         else:"
        },
        {
            "sha": "461ebe5aff47a5a5a99122624c385afed2ada0d1",
            "filename": "tests/quantization/compressed_tensors_integration/test_compressed_tensors.py",
            "status": "modified",
            "additions": 24,
            "deletions": 7,
            "changes": 31,
            "blob_url": "https://github.com/huggingface/transformers/blob/28906c3c25cf7cc2fa6bc6ff261f6170ea79b508/tests%2Fquantization%2Fcompressed_tensors_integration%2Ftest_compressed_tensors.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28906c3c25cf7cc2fa6bc6ff261f6170ea79b508/tests%2Fquantization%2Fcompressed_tensors_integration%2Ftest_compressed_tensors.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fquantization%2Fcompressed_tensors_integration%2Ftest_compressed_tensors.py?ref=28906c3c25cf7cc2fa6bc6ff261f6170ea79b508",
            "patch": "@@ -2,7 +2,13 @@\n import unittest\n \n from transformers import AutoModelForCausalLM, AutoTokenizer, CompressedTensorsConfig\n-from transformers.testing_utils import backend_empty_cache, require_compressed_tensors, require_torch, torch_device\n+from transformers.testing_utils import (\n+    backend_empty_cache,\n+    require_compressed_tensors,\n+    require_deterministic_for_xpu,\n+    require_torch,\n+    torch_device,\n+)\n from transformers.utils import is_torch_available\n \n \n@@ -47,22 +53,33 @@ def test_config_to_from_dict(self):\n         self.assertIsInstance(config_from_dict.sparsity_config, SparsityCompressionConfig)\n \n     def test_tinyllama_w8a8(self):\n-        expected_out = \"<s> Paris is the capital of which country?\\n\\n**A) 10** Paris is the capital of which country?\\n\\n**B) 11** Paris is the capital of which country?\\n\\n**C) 1\"\n+        expected_out = [\n+            \"<s> Paris is the capital of which country?\\n\\n**A) 10** Paris is the capital of which country?\\n\\n**B) 11** Paris is the capital of which country?\\n\\n**C) 1\",\n+            \"<s> Paris is the capital of which country?\\n\\n** 10.** Which country is the capital of which country?\\n\\n** 11.** Which country is the capital of which country?\\n\\n** 12.\",  # XPU\n+        ]\n         self._test_quantized_model(self.tinyllama_w8a8, expected_out)\n \n     def test_tinyllama_w4a16(self):\n-        expected_out = \"<s> Paris is the capital of which country?\\nAnswer: Paris is the capital of France.\\nQuestion: Which country is the capital of which city?\\nAnswer: The capital of the city of New York is New York.\\nQuestion: Which\"\n+        expected_out = [\n+            \"<s> Paris is the capital of which country?\\nAnswer: Paris is the capital of France.\\nQuestion: Which country is the capital of which city?\\nAnswer: The capital of the city of New York is New York.\\nQuestion: Which\"\n+        ]\n         self._test_quantized_model(self.tinyllama_w4a16, expected_out)\n \n     def test_tinyllama_w8a16(self):\n-        expected_out = \"<s> Paris is the capital of which country?\\nA. France\\nB. Germany\\nC. Spain\\nD. Italy\\nE. Switzerland\\nQ10. Which of the following is not a country in the European Union?\\nA.\"\n+        expected_out = [\n+            \"<s> Paris is the capital of which country?\\nA. France\\nB. Germany\\nC. Spain\\nD. Italy\\nE. Switzerland\\nQ10. Which of the following is not a country in the European Union?\\nA.\"\n+        ]\n         self._test_quantized_model(self.tinyllama_w8a16, expected_out)\n \n     def test_llama_8b_fp8(self):\n-        expected_out = \"<|begin_of_text|>Paris is the capital of which country? France\\nWhat is the name of the famous art museum in Paris? The Louvre\\nWhat is the name of the famous bridge in Paris? Pont des Arts\\nWhat is the name of the famous opera? \"\n+        expected_out = [\n+            \"<|begin_of_text|>Paris is the capital of which country? France\\nWhat is the name of the famous art museum in Paris? The Louvre\\nWhat is the name of the famous bridge in Paris? Pont des Arts\\nWhat is the name of the famous opera? \",\n+            \"<|begin_of_text|>Paris is the capital of which country? France\\nWhat is the name of the famous art museum in Paris? The Louvre\\nWhat is the name of the famous bridge in Paris? Pont des Arts\\nWhat is the name of the famous opera\",  # XPU\n+        ]\n         self._test_quantized_model(self.llama3_8b_fp8, expected_out)\n \n-    def _test_quantized_model(self, model_name: str, expected_output: str):\n+    @require_deterministic_for_xpu\n+    def _test_quantized_model(self, model_name: str, expected_output: list):\n         \"\"\"Carry out generation\"\"\"\n         quantized_model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n         tokenizer = AutoTokenizer.from_pretrained(model_name)\n@@ -84,4 +101,4 @@ def _test_quantized_model(self, model_name: str, expected_output: str):\n         outputs = tokenizer.batch_decode(generated_ids)\n \n         self.assertIsNotNone(outputs)\n-        self.assertEqual(outputs[0], expected_output)\n+        self.assertIn(outputs[0], expected_output)"
        }
    ],
    "stats": {
        "total": 35,
        "additions": 27,
        "deletions": 8
    }
}