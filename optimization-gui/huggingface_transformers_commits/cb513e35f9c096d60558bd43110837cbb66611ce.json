{
    "author": "LysandreJik",
    "message": "Protect ParallelInterface",
    "sha": "cb513e35f9c096d60558bd43110837cbb66611ce",
    "files": [
        {
            "sha": "52024f77c12461568c32663d3d08ee8babf3ff9c",
            "filename": "setup.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cb513e35f9c096d60558bd43110837cbb66611ce/setup.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cb513e35f9c096d60558bd43110837cbb66611ce/setup.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/setup.py?ref=cb513e35f9c096d60558bd43110837cbb66611ce",
            "patch": "@@ -125,7 +125,7 @@\n     \"jaxlib>=0.4.1,<=0.4.13\",\n     \"jieba\",\n     \"jinja2>=3.1.0\",\n-    \"kenlm@git+https://github.com/ydshieh/kenlm@78f664fb3dafe1468d868d71faf19534530698d5\",\n+    \"kenlm\",\n     # Keras pin - this is to make sure Keras 3 doesn't destroy us. Remove or change when we have proper support.\n     \"keras>2.9,<2.16\",\n     \"keras-nlp>=0.3.1,<0.14.0\",  # keras-nlp 0.14 doesn't support keras 2, see pin on keras.\n@@ -315,7 +315,7 @@ def run(self):\n     \"librosa\",\n     \"pyctcdecode\",\n     \"phonemizer\",\n-    \"kenlm@git+https://github.com/ydshieh/kenlm@78f664fb3dafe1468d868d71faf19534530698d5\",\n+    \"kenlm\",\n )\n # `pip install \".[speech]\"` is deprecated and `pip install \".[torch-speech]\"` should be used instead\n extras[\"speech\"] = deps_list(\"torchaudio\") + extras[\"audio\"]"
        },
        {
            "sha": "c01f5bb388c88bec8450ee3ef6b0e270592f742c",
            "filename": "src/transformers/dependency_versions_table.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cb513e35f9c096d60558bd43110837cbb66611ce/src%2Ftransformers%2Fdependency_versions_table.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cb513e35f9c096d60558bd43110837cbb66611ce/src%2Ftransformers%2Fdependency_versions_table.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdependency_versions_table.py?ref=cb513e35f9c096d60558bd43110837cbb66611ce",
            "patch": "@@ -32,7 +32,7 @@\n     \"jaxlib\": \"jaxlib>=0.4.1,<=0.4.13\",\n     \"jieba\": \"jieba\",\n     \"jinja2\": \"jinja2>=3.1.0\",\n-    \"kenlm@git+https://github.com/ydshieh/kenlm@78f664fb3dafe1468d868d71faf19534530698d5\": \"kenlm@git+https://github.com/ydshieh/kenlm@78f664fb3dafe1468d868d71faf19534530698d5\",\n+    \"kenlm\": \"kenlm\",\n     \"keras\": \"keras>2.9,<2.16\",\n     \"keras-nlp\": \"keras-nlp>=0.3.1,<0.14.0\",\n     \"kernels\": \"kernels>=0.4.4,<0.5\","
        },
        {
            "sha": "d07a768b01acaa8faff9da00c13741e16d1d84d0",
            "filename": "src/transformers/integrations/tensor_parallel.py",
            "status": "modified",
            "additions": 19,
            "deletions": 14,
            "changes": 33,
            "blob_url": "https://github.com/huggingface/transformers/blob/cb513e35f9c096d60558bd43110837cbb66611ce/src%2Ftransformers%2Fintegrations%2Ftensor_parallel.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cb513e35f9c096d60558bd43110837cbb66611ce/src%2Ftransformers%2Fintegrations%2Ftensor_parallel.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Ftensor_parallel.py?ref=cb513e35f9c096d60558bd43110837cbb66611ce",
            "patch": "@@ -729,23 +729,24 @@ class ParallelInterface(MutableMapping):\n \n     # Class instance object, so that a call to `register` can be reflected into all other files correctly, even if\n     # a new instance is created (in order to locally override a given function)\n-    _global_mapping = {\n-        \"colwise\": ColwiseParallel(),\n-        \"rowwise\": RowwiseParallel(),\n-        \"colwise_rep\": ColwiseParallel(output_layouts=Replicate()),\n-        \"rowwise_rep\": RowwiseParallel(input_layouts=Replicate()),\n-        \"local_colwise\": ColwiseParallel(use_dtensor=False),\n-        \"local_rowwise\": RowwiseParallel(use_dtensor=False),\n-        \"local\": IsolatedParallel(),\n-        \"gather\": GatherParallel(),\n-        \"local_packed_rowwise\": PackedRowwiseParallel(use_dtensor=False),\n-        \"sequence_parallel\": SequenceParallel(),\n-        \"replicate\": ReplicateParallel(),\n-    }\n \n     def __init__(self):\n         self._local_mapping = {}\n \n+        ParallelInterface._global_mapping = {\n+            \"colwise\": ColwiseParallel(),\n+            \"rowwise\": RowwiseParallel(),\n+            \"colwise_rep\": ColwiseParallel(output_layouts=Replicate()),\n+            \"rowwise_rep\": RowwiseParallel(input_layouts=Replicate()),\n+            \"local_colwise\": ColwiseParallel(use_dtensor=False),\n+            \"local_rowwise\": RowwiseParallel(use_dtensor=False),\n+            \"local\": IsolatedParallel(),\n+            \"gather\": GatherParallel(),\n+            \"local_packed_rowwise\": PackedRowwiseParallel(use_dtensor=False),\n+            \"sequence_parallel\": SequenceParallel(),\n+            \"replicate\": ReplicateParallel(),\n+        }\n+\n     def __getitem__(self, key):\n         # First check if instance has a local override\n         if key in self._local_mapping:\n@@ -775,7 +776,11 @@ def valid_keys(self) -> List[str]:\n \n \n # Global AttentionInterface shared by all models which do not need to overwrite any of the existing ones\n-ALL_PARALLEL_STYLES: ParallelInterface = ParallelInterface()\n+\n+if is_torch_greater_or_equal(\"2.5\") and _torch_distributed_available:\n+    ALL_PARALLEL_STYLES: ParallelInterface = ParallelInterface()\n+else:\n+    ALL_PARALLEL_STYLES = None\n \n \n def convert_local_tensor_to_dtensor("
        }
    ],
    "stats": {
        "total": 39,
        "additions": 22,
        "deletions": 17
    }
}