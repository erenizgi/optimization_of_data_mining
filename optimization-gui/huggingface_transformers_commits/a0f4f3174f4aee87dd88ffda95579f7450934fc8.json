{
    "author": "VictorAtIfInsurance",
    "message": "allow unused input parameters passthrough when chunking in asr pipelines (#33889)\n\n* allow unused parameter passthrough when chunking in asr pipelines\r\n\r\n* format code\r\n\r\n* format\r\n\r\n* run fixup\r\n\r\n* update tests\r\n\r\n* update parameters to pipline in test\r\n\r\n* updates parametrs in tests\r\n\r\n* change spelling in gitignore\r\n\r\n* revert .gitignore to main\r\n\r\n* add git ignore of devcontainer folder\r\n\r\n* assert asr output follows expected inference output type\r\n\r\n* run fixup\r\n\r\n* Remove .devcontainer from .gitignore\r\n\r\n* remove compliance check",
    "sha": "a0f4f3174f4aee87dd88ffda95579f7450934fc8",
    "files": [
        {
            "sha": "09958b5fca195b05aac3e8ec7a0860531d54c285",
            "filename": "src/transformers/pipelines/automatic_speech_recognition.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/a0f4f3174f4aee87dd88ffda95579f7450934fc8/src%2Ftransformers%2Fpipelines%2Fautomatic_speech_recognition.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a0f4f3174f4aee87dd88ffda95579f7450934fc8/src%2Ftransformers%2Fpipelines%2Fautomatic_speech_recognition.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fautomatic_speech_recognition.py?ref=a0f4f3174f4aee87dd88ffda95579f7450934fc8",
            "patch": "@@ -434,7 +434,7 @@ def preprocess(self, inputs, chunk_length_s=0, stride_length_s=None):\n             for item in chunk_iter(\n                 inputs, self.feature_extractor, chunk_len, stride_left, stride_right, self.torch_dtype\n             ):\n-                yield item\n+                yield {**item, **extra}\n         else:\n             if self.type == \"seq2seq_whisper\" and inputs.shape[0] > self.feature_extractor.n_samples:\n                 processed = self.feature_extractor("
        },
        {
            "sha": "e8cd8febca006e48e46133a8a059bab3b9d957c3",
            "filename": "tests/pipelines/test_pipelines_automatic_speech_recognition.py",
            "status": "modified",
            "additions": 19,
            "deletions": 0,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/a0f4f3174f4aee87dd88ffda95579f7450934fc8/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a0f4f3174f4aee87dd88ffda95579f7450934fc8/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py?ref=a0f4f3174f4aee87dd88ffda95579f7450934fc8",
            "patch": "@@ -1443,6 +1443,25 @@ def test_chunking_fast(self):\n         self.assertEqual(output, [{\"text\": ANY(str)}])\n         self.assertEqual(output[0][\"text\"][:6], \"ZBT ZC\")\n \n+    @require_torch\n+    def test_input_parameter_passthrough(self):\n+        \"\"\"Test that chunked vs non chunked versions of ASR pipelines returns the same structure for the same inputs.\"\"\"\n+        speech_recognizer = pipeline(\n+            task=\"automatic-speech-recognition\",\n+            model=\"hf-internal-testing/tiny-random-wav2vec2\",\n+        )\n+\n+        ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\").sort(\"id\")\n+        audio = ds[40][\"audio\"][\"array\"]\n+\n+        inputs = {\"raw\": audio, \"sampling_rate\": 16_000, \"id\": 1}\n+\n+        chunked_output = speech_recognizer(inputs.copy(), chunk_length_s=30)\n+        non_chunked_output = speech_recognizer(inputs.copy())\n+        assert (\n+            chunked_output.keys() == non_chunked_output.keys()\n+        ), \"The output structure should be the same for chunked vs non-chunked versions of asr pipelines.\"\n+\n     @require_torch\n     def test_return_timestamps_ctc_fast(self):\n         speech_recognizer = pipeline("
        }
    ],
    "stats": {
        "total": 21,
        "additions": 20,
        "deletions": 1
    }
}