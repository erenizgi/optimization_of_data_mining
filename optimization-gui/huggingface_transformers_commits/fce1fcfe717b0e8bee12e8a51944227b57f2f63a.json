{
    "author": "ydshieh",
    "message": "Ping team members for new failed tests in daily CI (#34171)\n\n* ping\r\n\r\n* fix\r\n\r\n* fix\r\n\r\n* fix\r\n\r\n* remove runner\r\n\r\n* update members\r\n\r\n---------\r\n\r\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "fce1fcfe717b0e8bee12e8a51944227b57f2f63a",
    "files": [
        {
            "sha": "f229765994d5851f9dd1ba53c9edc507e0b056a0",
            "filename": ".github/workflows/check_failed_model_tests.yml",
            "status": "added",
            "additions": 129,
            "deletions": 0,
            "changes": 129,
            "blob_url": "https://github.com/huggingface/transformers/blob/fce1fcfe717b0e8bee12e8a51944227b57f2f63a/.github%2Fworkflows%2Fcheck_failed_model_tests.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/fce1fcfe717b0e8bee12e8a51944227b57f2f63a/.github%2Fworkflows%2Fcheck_failed_model_tests.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fcheck_failed_model_tests.yml?ref=fce1fcfe717b0e8bee12e8a51944227b57f2f63a",
            "patch": "@@ -0,0 +1,129 @@\n+name: Process failed tests\n+\n+on:\n+  workflow_call:\n+    inputs:\n+      docker:\n+        required: true\n+        type: string\n+      start_sha:\n+        required: true\n+        type: string\n+\n+\n+env:\n+  HF_HOME: /mnt/cache\n+  TRANSFORMERS_IS_CI: yes\n+  OMP_NUM_THREADS: 8\n+  MKL_NUM_THREADS: 8\n+  RUN_SLOW: yes\n+  # For gated repositories, we still need to agree to share information on the Hub repo. page in order to get access.\n+  # This token is created under the bot `hf-transformers-bot`.\n+  HF_HUB_READ_TOKEN: ${{ secrets.HF_HUB_READ_TOKEN }}\n+  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}\n+  TF_FORCE_GPU_ALLOW_GROWTH: true\n+  RUN_PT_TF_CROSS_TESTS: 1\n+  CUDA_VISIBLE_DEVICES: 0,1\n+\n+\n+jobs:\n+  run_models_gpu:\n+    name: \" \"\n+    runs-on:\n+      group: aws-g4dn-2xlarge-cache\n+    container:\n+      image: ${{ inputs.docker }}\n+      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n+    steps:\n+      - uses: actions/download-artifact@v4\n+        with:\n+          name: ci_results_run_models_gpu\n+          path: /transformers/ci_results_run_models_gpu\n+\n+      - name: Update clone\n+        working-directory: /transformers\n+        run: git fetch && git checkout ${{ github.sha }}\n+\n+      - name: Get target commit\n+        working-directory: /transformers/utils\n+        run: |\n+          echo \"END_SHA=$(TOKEN=${{ secrets.ACCESS_REPO_INFO_TOKEN }} python3 -c 'import os; from get_previous_daily_ci import get_last_daily_ci_run_commit; commit=get_last_daily_ci_run_commit(token=os.environ[\"TOKEN\"]); print(commit)')\" >> $GITHUB_ENV\n+\n+      - name: Checkout to `start_sha`\n+        working-directory: /transformers\n+        run: git fetch && git checkout ${{ inputs.start_sha }}\n+\n+      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n+        working-directory: /transformers\n+        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n+\n+      - name: NVIDIA-SMI\n+        run: |\n+          nvidia-smi\n+\n+      - name: Environment\n+        working-directory: /transformers\n+        run: |\n+          python3 utils/print_env.py\n+\n+      - name: Show installed libraries and their versions\n+        working-directory: /transformers\n+        run: pip freeze\n+\n+      - name: Check failed tests\n+        working-directory: /transformers\n+        run: python3 utils/check_bad_commit.py --start_commit ${{ inputs.start_sha }} --end_commit ${{ env.END_SHA }} --file ci_results_run_models_gpu/new_model_failures.json --output_file new_model_failures_with_bad_commit.json\n+\n+      - name: Show results\n+        working-directory: /transformers\n+        run: |\n+          ls -l new_model_failures_with_bad_commit.json\n+          cat new_model_failures_with_bad_commit.json\n+\n+      - name: Checkout back\n+        working-directory: /transformers\n+        run: |\n+          git checkout ${{ inputs.start_sha }}\n+\n+      - name: Process report\n+        shell: bash\n+        working-directory: /transformers\n+        env:\n+          TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN: ${{ secrets.TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN }}\n+        run: |\n+          python3 utils/process_bad_commit_report.py\n+\n+      - name: Process report\n+        shell: bash\n+        working-directory: /transformers\n+        env:\n+          TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN: ${{ secrets.TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN }}\n+        run: |\n+          {\n+            echo 'REPORT_TEXT<<EOF'\n+            python3 utils/process_bad_commit_report.py\n+            echo EOF\n+          } >> \"$GITHUB_ENV\"\n+\n+      - name: Send processed report\n+        if: ${{ env.REPORT_TEXT != '' }}\n+        uses: slackapi/slack-github-action@6c661ce58804a1a20f6dc5fbee7f0381b469e001\n+        with:\n+          # Slack channel id, channel name, or user id to post message.\n+          # See also: https://api.slack.com/methods/chat.postMessage#channels\n+          channel-id: '#transformers-ci-feedback-tests'\n+          # For posting a rich message using Block Kit\n+          payload: |\n+            {\n+              \"blocks\": [\n+                {\n+                  \"type\": \"section\",\n+                  \"text\": {\n+                    \"type\": \"mrkdwn\",\n+                    \"text\": \"${{ env.REPORT_TEXT }}\"\n+                  }\n+                }\n+              ]\n+            }\n+        env:\n+          SLACK_BOT_TOKEN: ${{ secrets.SLACK_CIFEEDBACK_BOT_TOKEN }}"
        },
        {
            "sha": "353fb59843e4a5de503f7661998fd1133573a54d",
            "filename": ".github/workflows/self-scheduled.yml",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/fce1fcfe717b0e8bee12e8a51944227b57f2f63a/.github%2Fworkflows%2Fself-scheduled.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/fce1fcfe717b0e8bee12e8a51944227b57f2f63a/.github%2Fworkflows%2Fself-scheduled.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-scheduled.yml?ref=fce1fcfe717b0e8bee12e8a51944227b57f2f63a",
            "patch": "@@ -562,3 +562,13 @@ jobs:\n       ci_event: ${{ inputs.ci_event }}\n \n     secrets: inherit\n+\n+  check_new_model_failures:\n+    if: ${{ always() && inputs.ci_event == 'Daily CI' && inputs.job == 'run_models_gpu' && needs.send_results.result == 'success' }}\n+    name: Check new model failures\n+    needs: send_results\n+    uses: ./.github/workflows/check_failed_model_tests.yml\n+    with:\n+      docker: ${{ inputs.docker }}\n+      start_sha: ${{ github.sha }}\n+    secrets: inherit\n\\ No newline at end of file"
        },
        {
            "sha": "091ed5c4a427f95ea46ef97d7914320da15c5139",
            "filename": "utils/check_bad_commit.py",
            "status": "added",
            "additions": 188,
            "deletions": 0,
            "changes": 188,
            "blob_url": "https://github.com/huggingface/transformers/blob/fce1fcfe717b0e8bee12e8a51944227b57f2f63a/utils%2Fcheck_bad_commit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fce1fcfe717b0e8bee12e8a51944227b57f2f63a/utils%2Fcheck_bad_commit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_bad_commit.py?ref=fce1fcfe717b0e8bee12e8a51944227b57f2f63a",
            "patch": "@@ -0,0 +1,188 @@\n+#!/usr/bin/env python\n+# coding=utf-8\n+\n+# Copyright 2024 The HuggingFace Inc. team. All rights reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+import argparse\n+import json\n+import os\n+import re\n+import subprocess\n+\n+import requests\n+\n+\n+def create_script(target_test):\n+    \"\"\"Create a python script to be run by `git bisect run` to determine if `target_test` passes or fails.\n+    If a test is not found in a commit, the script with exit code `0` (i.e. `Success`).\n+\n+    Args:\n+        target_test (`str`): The test to check.\n+\n+    Returns:\n+        `str`: The script to be run by `git bisect run`.\n+    \"\"\"\n+\n+    script = f\"\"\"\n+import os\n+import subprocess\n+\n+result = subprocess.run(\n+    [\"python3\", \"-m\", \"pytest\", \"-v\", f\"{target_test}\"],\n+    capture_output = True,\n+    text=True,\n+)\n+print(result.stdout)\n+\n+if len(result.stderr) > 0:\n+    if \"ERROR: not found: \" in result.stderr:\n+        print(\"test not found in this commit\")\n+        exit(0)\n+    else:\n+        print(f\"pytest failed to run: {{result.stderr}}\")\n+        exit(-1)\n+elif f\"{target_test} FAILED\" in result.stdout:\n+    print(\"test failed\")\n+    exit(2)\n+\n+exit(0)\n+\"\"\"\n+\n+    with open(\"target_script.py\", \"w\") as fp:\n+        fp.write(script.strip())\n+\n+\n+def find_bad_commit(target_test, start_commit, end_commit):\n+    \"\"\"Find (backward) the earliest commit between `start_commit` and `end_commit` at which `target_test` fails.\n+\n+    Args:\n+        target_test (`str`): The test to check.\n+        start_commit (`str`): The latest commit.\n+        end_commit (`str`): The earliest commit.\n+\n+    Returns:\n+        `str`: The earliest commit at which `target_test` fails.\n+    \"\"\"\n+\n+    create_script(target_test=target_test)\n+\n+    bash = f\"\"\"\n+git bisect reset\n+git bisect start {start_commit} {end_commit}\n+git bisect run python3 target_script.py\n+\"\"\"\n+\n+    with open(\"run_git_bisect.sh\", \"w\") as fp:\n+        fp.write(bash.strip())\n+\n+    result = subprocess.run(\n+        [\"bash\", \"run_git_bisect.sh\"],\n+        capture_output=True,\n+        text=True,\n+    )\n+    print(result.stdout)\n+\n+    if \"error: bisect run failed\" in result.stderr:\n+        index = result.stderr.find(\"error: bisect run failed\")\n+        bash_error = result.stderr[index:]\n+\n+        error_msg = f\"Error when running git bisect:\\nbash error: {bash_error}\"\n+\n+        pattern = \"pytest failed to run: .+\"\n+        pytest_errors = re.findall(pattern, result.stdout)\n+        if len(pytest_errors) > 0:\n+            pytest_error = pytest_errors[0]\n+            index = pytest_error.find(\"pytest failed to run: \")\n+            index += len(\"pytest failed to run: \")\n+            pytest_error = pytest_error[index:]\n+            error_msg += f\"pytest error: {pytest_error}\"\n+\n+        raise ValueError(error_msg)\n+\n+    pattern = r\"(.+) is the first bad commit\"\n+    commits = re.findall(pattern, result.stdout)\n+\n+    bad_commit = None\n+    if len(commits) > 0:\n+        bad_commit = commits[0]\n+\n+    print(f\"Between `start_commit` {start_commit} and `end_commit` {end_commit}\")\n+    print(f\"bad_commit: {bad_commit}\\n\")\n+\n+    return bad_commit\n+\n+\n+def get_commit_info(commit):\n+    \"\"\"Get information for a commit via `api.github.com`.\"\"\"\n+    pr_number = None\n+    author = None\n+    merged_author = None\n+\n+    url = f\"https://api.github.com/repos/huggingface/transformers/commits/{commit}/pulls\"\n+    pr_info_for_commit = requests.get(url).json()\n+\n+    if len(pr_info_for_commit) > 0:\n+        pr_number = pr_info_for_commit[0][\"number\"]\n+\n+        url = f\"https://api.github.com/repos/huggingface/transformers/pulls/{pr_number}\"\n+        pr_for_commit = requests.get(url).json()\n+        author = pr_for_commit[\"user\"][\"login\"]\n+        merged_author = pr_for_commit[\"merged_by\"][\"login\"]\n+\n+    if author is None:\n+        url = f\"https://api.github.com/repos/huggingface/transformers/commits/{commit}\"\n+        commit_info = requests.get(url).json()\n+        author = commit_info[\"author\"][\"login\"]\n+\n+    return {\"commit\": commit, \"pr_number\": pr_number, \"author\": author, \"merged_by\": merged_author}\n+\n+\n+if __name__ == \"__main__\":\n+    parser = argparse.ArgumentParser()\n+    parser.add_argument(\"--start_commit\", type=str, required=True, help=\"The latest commit hash to check.\")\n+    parser.add_argument(\"--end_commit\", type=str, required=True, help=\"The earliest commit hash to check.\")\n+    parser.add_argument(\"--test\", type=str, help=\"The test to check.\")\n+    parser.add_argument(\"--file\", type=str, help=\"The report file.\")\n+    parser.add_argument(\"--output_file\", type=str, required=True, help=\"The path of the output file.\")\n+    args = parser.parse_args()\n+\n+    print(f\"start_commit: {args.start_commit}\")\n+    print(f\"end_commit: {args.end_commit}\")\n+\n+    if len({args.test is None, args.file is None}) != 2:\n+        raise ValueError(\"Exactly one argument `test` or `file` must be specified.\")\n+\n+    if args.test is not None:\n+        commit = find_bad_commit(target_test=args.test, start_commit=args.start_commit, end_commit=args.end_commit)\n+        with open(args.output_file, \"w\", encoding=\"UTF-8\") as fp:\n+            fp.write(f\"{args.test}\\n{commit}\")\n+    elif os.path.isfile(args.file):\n+        with open(args.file, \"r\", encoding=\"UTF-8\") as fp:\n+            reports = json.load(fp)\n+\n+        for model in reports:\n+            # TODO: make this script able to deal with both `single-gpu` and `multi-gpu` via a new argument.\n+            reports[model].pop(\"multi-gpu\", None)\n+            failed_tests = reports[model][\"single-gpu\"]\n+\n+            failed_tests_with_bad_commits = []\n+            for test in failed_tests:\n+                commit = find_bad_commit(target_test=test, start_commit=args.start_commit, end_commit=args.end_commit)\n+                info = {\"test\": test, \"commit\": commit}\n+                info.update(get_commit_info(commit))\n+                failed_tests_with_bad_commits.append(info)\n+            reports[model][\"single-gpu\"] = failed_tests_with_bad_commits\n+\n+        with open(args.output_file, \"w\", encoding=\"UTF-8\") as fp:\n+            json.dump(reports, fp, ensure_ascii=False, indent=4)"
        },
        {
            "sha": "efd7d24a752991f16a41f85654fdb86a04c8ba94",
            "filename": "utils/get_previous_daily_ci.py",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/fce1fcfe717b0e8bee12e8a51944227b57f2f63a/utils%2Fget_previous_daily_ci.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fce1fcfe717b0e8bee12e8a51944227b57f2f63a/utils%2Fget_previous_daily_ci.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fget_previous_daily_ci.py?ref=fce1fcfe717b0e8bee12e8a51944227b57f2f63a",
            "patch": "@@ -41,6 +41,18 @@ def get_last_daily_ci_runs(token):\n     return workflow_run_id\n \n \n+def get_last_daily_ci_run_commit(token):\n+    \"\"\"Get the commit sha of the last completed scheduled daily CI workflow run.\"\"\"\n+    workflow_runs = get_daily_ci_runs(token)\n+    head_sha = None\n+    for workflow_run in workflow_runs:\n+        if workflow_run[\"status\"] == \"completed\":\n+            head_sha = workflow_run[\"head_sha\"]\n+            break\n+\n+    return head_sha\n+\n+\n def get_last_daily_ci_artifacts(artifact_names, output_dir, token):\n     \"\"\"Get the artifacts of last completed workflow run id of the scheduled (daily) CI.\"\"\"\n     workflow_run_id = get_last_daily_ci_runs(token)"
        },
        {
            "sha": "629b793337889a2c9e49250e53833899eddda2bc",
            "filename": "utils/notification_service.py",
            "status": "modified",
            "additions": 26,
            "deletions": 1,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/fce1fcfe717b0e8bee12e8a51944227b57f2f63a/utils%2Fnotification_service.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fce1fcfe717b0e8bee12e8a51944227b57f2f63a/utils%2Fnotification_service.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fnotification_service.py?ref=fce1fcfe717b0e8bee12e8a51944227b57f2f63a",
            "patch": "@@ -539,11 +539,36 @@ def payload(self) -> str:\n             )\n             url = f\"https://huggingface.co/datasets/hf-internal-testing/transformers_daily_ci/raw/{commit_info.oid}/{datetime.datetime.today().strftime('%Y-%m-%d')}/ci_results_{job_name}/new_model_failures.txt\"\n \n+            # extra processing to save to json format\n+            new_failed_tests = {}\n+            for line in failure_text.split():\n+                if \"https://github.com/huggingface/transformers/actions/runs\" in line:\n+                    pattern = r\"<(https://github.com/huggingface/transformers/actions/runs/.+?/job/.+?)\\|(.+?)>\"\n+                    items = re.findall(pattern, line)\n+                elif \"tests/models/\" in line:\n+                    model = line.split(\"/\")[2]\n+                    new_failed_tests[model] = {\"single-gpu\": [], \"multi-gpu\": []}\n+                    for url, device in items:\n+                        new_failed_tests[model][f\"{device}-gpu\"].append(line)\n+            file_path = os.path.join(os.getcwd(), f\"ci_results_{job_name}/new_model_failures.json\")\n+            with open(file_path, \"w\", encoding=\"UTF-8\") as fp:\n+                json.dump(new_failed_tests, fp, ensure_ascii=False, indent=4)\n+\n+            # upload results to Hub dataset\n+            file_path = os.path.join(os.getcwd(), f\"ci_results_{job_name}/new_model_failures.json\")\n+            _ = api.upload_file(\n+                path_or_fileobj=file_path,\n+                path_in_repo=f\"{datetime.datetime.today().strftime('%Y-%m-%d')}/ci_results_{job_name}/new_model_failures.json\",\n+                repo_id=\"hf-internal-testing/transformers_daily_ci\",\n+                repo_type=\"dataset\",\n+                token=os.environ.get(\"TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN\", None),\n+            )\n+\n             block = {\n                 \"type\": \"section\",\n                 \"text\": {\n                     \"type\": \"plain_text\",\n-                    \"text\": \"bonjour\",\n+                    \"text\": \" \",\n                 },\n                 \"accessory\": {\n                     \"type\": \"button\","
        },
        {
            "sha": "f61f1b106644aa8376bbe76fffd6525f0dfd9e81",
            "filename": "utils/process_bad_commit_report.py",
            "status": "added",
            "additions": 77,
            "deletions": 0,
            "changes": 77,
            "blob_url": "https://github.com/huggingface/transformers/blob/fce1fcfe717b0e8bee12e8a51944227b57f2f63a/utils%2Fprocess_bad_commit_report.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fce1fcfe717b0e8bee12e8a51944227b57f2f63a/utils%2Fprocess_bad_commit_report.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fprocess_bad_commit_report.py?ref=fce1fcfe717b0e8bee12e8a51944227b57f2f63a",
            "patch": "@@ -0,0 +1,77 @@\n+\"\"\"An internal script to process `new_model_failures_with_bad_commit.json` produced by `utils/check_bad_commit.py`.\n+\n+This is used by `.github/workflows/check_failed_model_tests.yml` to produce a slack report of the following form\n+\n+```\n+<{url}|New failed tests>\n+{\n+   \"GH_ydshieh\": {\n+       \"vit\": 1\n+   }\n+}\n+```\n+\"\"\"\n+\n+import datetime\n+import json\n+import os\n+from collections import Counter\n+from copy import deepcopy\n+\n+from huggingface_hub import HfApi\n+\n+\n+if __name__ == \"__main__\":\n+    api = HfApi()\n+\n+    with open(\"new_model_failures_with_bad_commit.json\") as fp:\n+        data = json.load(fp)\n+\n+    # TODO: extend\n+    team_members = [\"ydshieh\", \"zucchini-nlp\", \"ArthurZucker\", \"gante\", \"LysandreJik\", \"molbap\", \"qubvel\"]\n+\n+    # Counting the number of failures grouped by authors\n+    new_data = {}\n+    for model, model_result in data.items():\n+        for device, failed_tests in model_result.items():\n+            for failed_test in failed_tests:\n+                author = failed_test[\"author\"]\n+\n+                if author not in team_members:\n+                    author = failed_test[\"merged_by\"]\n+\n+                if author not in new_data:\n+                    new_data[author] = Counter()\n+                new_data[author].update([model])\n+    for author in new_data:\n+        new_data[author] = dict(new_data[author])\n+\n+    # Group by author\n+    new_data_full = {author: deepcopy(data) for author in new_data}\n+    for author, _data in new_data_full.items():\n+        for model, model_result in _data.items():\n+            for device, failed_tests in model_result.items():\n+                failed_tests = [x for x in failed_tests if x[\"author\"] == author or x[\"merged_by\"] == author]\n+                model_result[device] = failed_tests\n+\n+    # Upload to Hub and get the url\n+    with open(\"new_model_failures_with_bad_commit_grouped_by_authors.json\", \"w\") as fp:\n+        json.dump(new_data_full, fp, ensure_ascii=False, indent=4)\n+    commit_info = api.upload_file(\n+        path_or_fileobj=\"new_model_failures_with_bad_commit_grouped_by_authors.json\",\n+        path_in_repo=f\"{datetime.datetime.today().strftime('%Y-%m-%d')}/ci_results_run_models_gpu/new_model_failures_with_bad_commit_grouped_by_authors.json\",\n+        repo_id=\"hf-internal-testing/transformers_daily_ci\",\n+        repo_type=\"dataset\",\n+        token=os.environ.get(\"TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN\", None),\n+    )\n+    url = f\"https://huggingface.co/datasets/hf-internal-testing/transformers_daily_ci/raw/{commit_info.oid}/{datetime.datetime.today().strftime('%Y-%m-%d')}/ci_results_run_models_gpu/new_model_failures_with_bad_commit_grouped_by_authors.json\"\n+\n+    # Add `GH_` prefix as keyword mention\n+    output = {}\n+    for author, item in new_data.items():\n+        author = f\"GH_{author}\"\n+        output[author] = item\n+\n+    report = f\"<{url}|New failed tests>\\\\n\\\\n\"\n+    report += json.dumps(output, indent=4).replace('\"', '\\\\\"').replace(\"\\n\", \"\\\\n\")\n+    print(report)"
        }
    ],
    "stats": {
        "total": 443,
        "additions": 442,
        "deletions": 1
    }
}