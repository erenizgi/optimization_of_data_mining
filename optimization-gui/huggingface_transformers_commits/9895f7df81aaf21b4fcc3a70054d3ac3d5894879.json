{
    "author": "zucchini-nlp",
    "message": "Idefics: fix docstring (#35079)\n\nnit: fix docstring",
    "sha": "9895f7df81aaf21b4fcc3a70054d3ac3d5894879",
    "files": [
        {
            "sha": "2e502d02fdefab510d4bdbc9db6f4d6eb1476ab1",
            "filename": "src/transformers/models/idefics/modeling_idefics.py",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/9895f7df81aaf21b4fcc3a70054d3ac3d5894879/src%2Ftransformers%2Fmodels%2Fidefics%2Fmodeling_idefics.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9895f7df81aaf21b4fcc3a70054d3ac3d5894879/src%2Ftransformers%2Fmodels%2Fidefics%2Fmodeling_idefics.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics%2Fmodeling_idefics.py?ref=9895f7df81aaf21b4fcc3a70054d3ac3d5894879",
            "patch": "@@ -747,7 +747,7 @@ def forward(\n \n \n class IdeficsGatedCrossAttentionLayer(nn.Module):\n-    def __init__(self, config: IdeficsConfig):\n+    def __init__(self, config: IdeficsConfig, layer_idx: int = None):\n         super().__init__()\n         self.hidden_size = config.hidden_size\n         self.cross_attn = IdeficsAttention(\n@@ -757,6 +757,7 @@ def __init__(self, config: IdeficsConfig):\n             dropout=config.dropout,\n             config=config,\n             qk_layer_norms=config.qk_layer_norms,\n+            layer_idx=layer_idx,\n         )\n         self.mlp = IdeficsMLP(\n             hidden_size=self.hidden_size,\n@@ -1048,7 +1049,7 @@ def __init__(self, config: IdeficsConfig):\n         self.cross_layer_interval = config.cross_layer_interval\n         num_cross_layers = config.num_hidden_layers // self.cross_layer_interval\n         self.gated_cross_attn_layers = nn.ModuleList(\n-            [IdeficsGatedCrossAttentionLayer(config) for _ in range(num_cross_layers)]\n+            [IdeficsGatedCrossAttentionLayer(config, layer_idx=i) for i in range(num_cross_layers)]\n         )\n         self.gradient_checkpointing = False\n "
        },
        {
            "sha": "3b0e92aac91e45df42d68c8abb7ccc65f16d97f9",
            "filename": "src/transformers/models/idefics/processing_idefics.py",
            "status": "modified",
            "additions": 7,
            "deletions": 3,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/9895f7df81aaf21b4fcc3a70054d3ac3d5894879/src%2Ftransformers%2Fmodels%2Fidefics%2Fprocessing_idefics.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9895f7df81aaf21b4fcc3a70054d3ac3d5894879/src%2Ftransformers%2Fmodels%2Fidefics%2Fprocessing_idefics.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics%2Fprocessing_idefics.py?ref=9895f7df81aaf21b4fcc3a70054d3ac3d5894879",
            "patch": "@@ -20,6 +20,7 @@\n from urllib.parse import urlparse\n \n from ...feature_extraction_utils import BatchFeature\n+from ...image_utils import ImageInput\n from ...processing_utils import (\n     ImagesKwargs,\n     ProcessingKwargs,\n@@ -203,7 +204,10 @@ class IdeficsProcessor(ProcessorMixin):\n             An instance of [`IdeficsImageProcessor`]. The image processor is a required input.\n         tokenizer (`LlamaTokenizerFast`):\n             An instance of [`LlamaTokenizerFast`]. The tokenizer is a required input.\n-        image_size (`int`, *optional*, defaults to 224): Image size (assuming a square image)\n+        image_size (`int`, *optional*, defaults to 224):\n+            Image size (assuming a square image)\n+        add_end_of_utterance_token (`str`, *optional*):\n+            The string representation of token representing end of utterance\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n@@ -240,7 +244,7 @@ def __init__(self, image_processor, tokenizer=None, image_size=224, add_end_of_u\n     @deprecate_kwarg(old_name=\"prompts\", version=\"5.0.0\", new_name=\"text\", raise_if_both_names=True)\n     def __call__(\n         self,\n-        images=None,\n+        images: Union[ImageInput, List[ImageInput], str, List[str], List[List[str]]] = None,\n         text: Union[\n             TextInput,\n             PreTokenizedInput,\n@@ -257,7 +261,7 @@ def __call__(\n         the model was trained on and prepares the image pixel values for the model to process.\n \n         Args:\n-            images (`Union[PIL.Image, str, List[PIL.Image], List[str]]`):\n+            images (`Union[ImageInput, List[ImageInput], str, List[str], List[List[str]]]`):\n                 either a single image or a batched list of images - can be passed in when text contains only text prompts,\n                 in order to use the image-text-to-text behavior.\n             text (`Union[List[TextInput], [List[List[TextInput]]]]`):"
        }
    ],
    "stats": {
        "total": 15,
        "additions": 10,
        "deletions": 5
    }
}