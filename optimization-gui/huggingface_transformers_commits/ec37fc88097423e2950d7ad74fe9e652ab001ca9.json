{
    "author": "Sai-Suraj-27",
    "message": "Fix failing `owlv2` image processor integration test (#42714)\n\nFixed failing owlv2 image processor integration test.",
    "sha": "ec37fc88097423e2950d7ad74fe9e652ab001ca9",
    "files": [
        {
            "sha": "0299404a75b73f28248d8d3719745816b090a9cb",
            "filename": "tests/models/owlv2/test_image_processing_owlv2.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/ec37fc88097423e2950d7ad74fe9e652ab001ca9/tests%2Fmodels%2Fowlv2%2Ftest_image_processing_owlv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ec37fc88097423e2950d7ad74fe9e652ab001ca9/tests%2Fmodels%2Fowlv2%2Ftest_image_processing_owlv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fowlv2%2Ftest_image_processing_owlv2.py?ref=ec37fc88097423e2950d7ad74fe9e652ab001ca9",
            "patch": "@@ -151,7 +151,9 @@ def test_image_processor_integration_test_resize(self):\n             with torch.no_grad():\n                 outputs = model(**inputs)\n \n-            results = processor.post_process_object_detection(outputs, threshold=0.2, target_sizes=[target_size])[0]\n+            results = processor.image_processor.post_process_object_detection(\n+                outputs, threshold=0.2, target_sizes=[target_size]\n+            )[0]\n \n             boxes = results[\"boxes\"]\n             torch.testing.assert_close(boxes, expected_boxes, atol=1e-1, rtol=1e-1)\n@@ -160,7 +162,7 @@ def test_image_processor_integration_test_resize(self):\n             inputs = processor(text=[text, text], images=[image, image], return_tensors=\"pt\")\n             with torch.no_grad():\n                 outputs = model(**inputs)\n-            results = processor.post_process_object_detection(\n+            results = processor.image_processor.post_process_object_detection(\n                 outputs, threshold=0.2, target_sizes=[target_size, target_size]\n             )\n "
        }
    ],
    "stats": {
        "total": 6,
        "additions": 4,
        "deletions": 2
    }
}