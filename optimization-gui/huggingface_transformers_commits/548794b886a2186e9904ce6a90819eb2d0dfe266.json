{
    "author": "LysandreJik",
    "message": "[serve] Model name or path should be required (#39178)\n\n* Model name or path should be required\n\n* Fix + add tests\n\n* Change print to log so it doesn't display in transformers chat",
    "sha": "548794b886a2186e9904ce6a90819eb2d0dfe266",
    "files": [
        {
            "sha": "8f6f49f26bca7775d12b53872a19be75f49fe7b4",
            "filename": "src/transformers/commands/chat.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/548794b886a2186e9904ce6a90819eb2d0dfe266/src%2Ftransformers%2Fcommands%2Fchat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/548794b886a2186e9904ce6a90819eb2d0dfe266/src%2Ftransformers%2Fcommands%2Fchat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fchat.py?ref=548794b886a2186e9904ce6a90819eb2d0dfe266",
            "patch": "@@ -333,6 +333,11 @@ def __init__(self, args):\n                     )\n \n                 args.host, args.port = args.model_name_or_path_or_address.rsplit(\":\", 1)\n+\n+                if args.model_name_or_path is None:\n+                    raise ValueError(\n+                        \"When connecting to a server, please specify a model name with the --model_name_or_path flag.\"\n+                    )\n             else:\n                 self.spawn_backend = True\n                 args.model_name_or_path = args.model_name_or_path_or_address"
        },
        {
            "sha": "f8b4131a4630f06e8bf93eba917f7c2f407730cd",
            "filename": "src/transformers/commands/serving.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/548794b886a2186e9904ce6a90819eb2d0dfe266/src%2Ftransformers%2Fcommands%2Fserving.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/548794b886a2186e9904ce6a90819eb2d0dfe266/src%2Ftransformers%2Fcommands%2Fserving.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fserving.py?ref=548794b886a2186e9904ce6a90819eb2d0dfe266",
            "patch": "@@ -623,7 +623,7 @@ def load_model_and_tokenizer(\n \n         self.loaded_model = model_id_and_revision\n \n-        print(\"Loaded model\", model_id_and_revision)\n+        logger.warning(f\"Loaded model {model_id_and_revision}\")\n         return model, tokenizer\n \n "
        },
        {
            "sha": "e07df4a393893c9436b2818307e4a4580aa75e23",
            "filename": "tests/commands/test_chat.py",
            "status": "modified",
            "additions": 23,
            "deletions": 1,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/548794b886a2186e9904ce6a90819eb2d0dfe266/tests%2Fcommands%2Ftest_chat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/548794b886a2186e9904ce6a90819eb2d0dfe266/tests%2Fcommands%2Ftest_chat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fcommands%2Ftest_chat.py?ref=548794b886a2186e9904ce6a90819eb2d0dfe266",
            "patch": "@@ -29,12 +29,34 @@ def test_help(self):\n         self.assertIn(\"chat interface\", cs.out.lower())\n \n     @patch.object(ChatCommand, \"run\")\n-    def test_cli_dispatch(self, run_mock):\n+    def test_cli_dispatch_model(self, run_mock):\n+        \"\"\"\n+        Running transformers chat with just a model should work & spawn a serve underneath\n+        \"\"\"\n         args = [\"transformers\", \"chat\", \"hf-internal-testing/tiny-random-gpt2\"]\n         with patch(\"sys.argv\", args):\n             cli.main()\n         run_mock.assert_called_once()\n \n+    def test_cli_dispatch_url(self):\n+        \"\"\"\n+        Running transformers chat with just a URL should not work as a model should additionally be specified\n+        \"\"\"\n+        args = [\"transformers\", \"chat\", \"localhost:8000\"]\n+        with self.assertRaises(ValueError):\n+            with patch(\"sys.argv\", args):\n+                cli.main()\n+\n+    @patch.object(ChatCommand, \"run\")\n+    def test_cli_dispatch_url_and_model(self, run_mock):\n+        \"\"\"\n+        Running transformers chat with a URL and a model should work\n+        \"\"\"\n+        args = [\"transformers\", \"chat\", \"localhost:8000\", \"--model_name_or_path=hf-internal-testing/tiny-random-gpt2\"]\n+        with patch(\"sys.argv\", args):\n+            cli.main()\n+        run_mock.assert_called_once()\n+\n     def test_parsed_args(self):\n         with (\n             patch.object(ChatCommand, \"__init__\", return_value=None) as init_mock,"
        }
    ],
    "stats": {
        "total": 31,
        "additions": 29,
        "deletions": 2
    }
}