{
    "author": "jiqing-feng",
    "message": "remove _run_third_party_device_tests (#37445)\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>",
    "sha": "14b3dbcf3b74e825ce7678cdc5a51479badaecbb",
    "files": [
        {
            "sha": "46616ccee12134a012234d7d12fe97f7a4b68a11",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 5,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/14b3dbcf3b74e825ce7678cdc5a51479badaecbb/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/14b3dbcf3b74e825ce7678cdc5a51479badaecbb/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=14b3dbcf3b74e825ce7678cdc5a51479badaecbb",
            "patch": "@@ -243,7 +243,6 @@ def parse_int_from_env(key, default=None):\n _run_staging = parse_flag_from_env(\"HUGGINGFACE_CO_STAGING\", default=False)\n _run_pipeline_tests = parse_flag_from_env(\"RUN_PIPELINE_TESTS\", default=True)\n _run_agent_tests = parse_flag_from_env(\"RUN_AGENT_TESTS\", default=False)\n-_run_third_party_device_tests = parse_flag_from_env(\"RUN_THIRD_PARTY_DEVICE_TESTS\", default=False)\n \n \n def is_staging_test(test_case):\n@@ -959,13 +958,13 @@ def require_torch_multi_hpu(test_case):\n             ) from e\n     elif torch.cuda.is_available():\n         torch_device = \"cuda\"\n-    elif _run_third_party_device_tests and is_torch_npu_available():\n+    elif is_torch_npu_available():\n         torch_device = \"npu\"\n-    elif _run_third_party_device_tests and is_torch_mlu_available():\n+    elif is_torch_mlu_available():\n         torch_device = \"mlu\"\n-    elif _run_third_party_device_tests and is_torch_hpu_available():\n+    elif is_torch_hpu_available():\n         torch_device = \"hpu\"\n-    elif _run_third_party_device_tests and is_torch_xpu_available():\n+    elif is_torch_xpu_available():\n         torch_device = \"xpu\"\n     else:\n         torch_device = \"cpu\""
        }
    ],
    "stats": {
        "total": 9,
        "additions": 4,
        "deletions": 5
    }
}