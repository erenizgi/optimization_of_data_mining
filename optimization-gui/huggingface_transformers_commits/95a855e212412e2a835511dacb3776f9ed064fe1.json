{
    "author": "MekkCyber",
    "message": "Deprecate quanto and switch to optimum-quanto (#35001)\n\n* deprecate quanto\n\n* fix style",
    "sha": "95a855e212412e2a835511dacb3776f9ed064fe1",
    "files": [
        {
            "sha": "23f2177b25d529d13fb08dedc3243d452bc358f8",
            "filename": "src/transformers/cache_utils.py",
            "status": "modified",
            "additions": 0,
            "deletions": 22,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/95a855e212412e2a835511dacb3776f9ed064fe1/src%2Ftransformers%2Fcache_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/95a855e212412e2a835511dacb3776f9ed064fe1/src%2Ftransformers%2Fcache_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcache_utils.py?ref=95a855e212412e2a835511dacb3776f9ed064fe1",
            "patch": "@@ -12,7 +12,6 @@\n from .utils import (\n     is_hqq_available,\n     is_optimum_quanto_available,\n-    is_quanto_available,\n     is_torchdynamo_compiling,\n     logging,\n )\n@@ -790,17 +789,6 @@ def __init__(self, cache_config: CacheConfig) -> None:\n                     f\"You need optimum-quanto package version to be greater or equal than 0.2.5 to use `QuantoQuantizedCache`. Detected version {optimum_quanto_version}.\"\n                 )\n             from optimum.quanto import MaxOptimizer, qint2, qint4\n-        elif is_quanto_available():\n-            logger.warning_once(\n-                \"Importing from quanto will be deprecated in v4.47. Please install optimum-quanto instead `pip install optimum-quanto`\"\n-            )\n-            quanto_version = version.parse(importlib.metadata.version(\"quanto\"))\n-            if quanto_version < version.parse(\"0.2.0\"):\n-                raise ImportError(\n-                    f\"You need quanto package version to be greater or equal than 0.2.0 to use `QuantoQuantizedCache`. Detected version {quanto_version}. \"\n-                    f\"Since quanto will be deprecated, please install optimum-quanto instead with `pip install -U optimum-quanto`\"\n-                )\n-            from quanto import MaxOptimizer, qint2, qint4\n \n         if self.nbits not in [2, 4]:\n             raise ValueError(f\"`nbits` for `quanto` backend has to be one of [`2`, `4`] but got {self.nbits}\")\n@@ -824,16 +812,6 @@ def _quantize(self, tensor, axis):\n             scale, zeropoint = self.optimizer(tensor, self.qtype, axis, self.q_group_size)\n             qtensor = quantize_weight(tensor, self.qtype, axis, scale, zeropoint, self.q_group_size)\n             return qtensor\n-        elif is_quanto_available():\n-            logger.warning_once(\n-                \"Importing from quanto will be deprecated in v4.47. Please install optimum-quanto instead `pip install optimum-quanto`\"\n-            )\n-            from quanto import AffineQuantizer\n-\n-            scale, zeropoint = self.optimizer(tensor, self.qtype.bits, axis, self.q_group_size)\n-            qtensor = AffineQuantizer.apply(tensor, self.qtype, axis, self.q_group_size, scale, zeropoint)\n-\n-        return qtensor\n \n     def _dequantize(self, qtensor):\n         return qtensor.dequantize()"
        },
        {
            "sha": "015cbebaa8e5dca0c8cd4bae21537d6a3bc2164c",
            "filename": "src/transformers/generation/utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/95a855e212412e2a835511dacb3776f9ed064fe1/src%2Ftransformers%2Fgeneration%2Futils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/95a855e212412e2a835511dacb3776f9ed064fe1/src%2Ftransformers%2Fgeneration%2Futils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Futils.py?ref=95a855e212412e2a835511dacb3776f9ed064fe1",
            "patch": "@@ -45,7 +45,6 @@\n     is_accelerate_available,\n     is_hqq_available,\n     is_optimum_quanto_available,\n-    is_quanto_available,\n     is_torchdynamo_compiling,\n     logging,\n )\n@@ -1787,7 +1786,7 @@ def _prepare_cache_for_generation(\n                 )\n                 cache_class = QUANT_BACKEND_CLASSES_MAPPING[cache_config.backend]\n \n-                if cache_config.backend == \"quanto\" and not (is_optimum_quanto_available() or is_quanto_available()):\n+                if cache_config.backend == \"quanto\" and not is_optimum_quanto_available():\n                     raise ImportError(\n                         \"You need to install optimum-quanto in order to use KV cache quantization with optimum-quanto backend. \"\n                         \"Please install it via  with `pip install optimum-quanto`\""
        },
        {
            "sha": "1c5702321937da5f1238427156452cbccdbcea4a",
            "filename": "src/transformers/integrations/quanto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 6,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/95a855e212412e2a835511dacb3776f9ed064fe1/src%2Ftransformers%2Fintegrations%2Fquanto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/95a855e212412e2a835511dacb3776f9ed064fe1/src%2Ftransformers%2Fintegrations%2Fquanto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Fquanto.py?ref=95a855e212412e2a835511dacb3776f9ed064fe1",
            "patch": "@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-from ..utils import is_optimum_quanto_available, is_quanto_available, is_torch_available, logging\n+from ..utils import is_optimum_quanto_available, is_torch_available, logging\n \n \n if is_torch_available():\n@@ -50,11 +50,6 @@ def replace_with_quanto_layers(\n \n     if is_optimum_quanto_available():\n         from optimum.quanto import QLayerNorm, QLinear, qfloat8, qint2, qint4, qint8\n-    elif is_quanto_available():\n-        logger.warning_once(\n-            \"Importing from quanto will be deprecated in v4.47. Please install optimum-quanto instead `pip install optimum-quanto`\"\n-        )\n-        from quanto import QLayerNorm, QLinear, qfloat8, qint2, qint4, qint8\n \n     w_mapping = {\"float8\": qfloat8, \"int8\": qint8, \"int4\": qint4, \"int2\": qint2}\n     a_mapping = {None: None, \"float8\": qfloat8, \"int8\": qint8}"
        },
        {
            "sha": "d91019dea1522630f04e5cc0c32becc746078067",
            "filename": "src/transformers/quantizers/quantizer_quanto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 12,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/95a855e212412e2a835511dacb3776f9ed064fe1/src%2Ftransformers%2Fquantizers%2Fquantizer_quanto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/95a855e212412e2a835511dacb3776f9ed064fe1/src%2Ftransformers%2Fquantizers%2Fquantizer_quanto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizer_quanto.py?ref=95a855e212412e2a835511dacb3776f9ed064fe1",
            "patch": "@@ -26,7 +26,6 @@\n from ..utils import (\n     is_accelerate_available,\n     is_optimum_quanto_available,\n-    is_quanto_available,\n     is_torch_available,\n     logging,\n )\n@@ -63,7 +62,7 @@ def post_init(self):\n             )\n \n     def validate_environment(self, *args, **kwargs):\n-        if not (is_optimum_quanto_available() or is_quanto_available()):\n+        if not is_optimum_quanto_available():\n             raise ImportError(\n                 \"Loading an optimum-quanto quantized model requires optimum-quanto library (`pip install optimum-quanto`)\"\n             )\n@@ -91,11 +90,6 @@ def update_torch_dtype(self, torch_dtype: \"torch.dtype\") -> \"torch.dtype\":\n     def update_missing_keys(self, model, missing_keys: List[str], prefix: str) -> List[str]:\n         if is_optimum_quanto_available():\n             from optimum.quanto import QModuleMixin\n-        elif is_quanto_available():\n-            logger.warning_once(\n-                \"Importing from quanto will be deprecated in v4.47. Please install optimum-quanto instead `pip install optimum-quanto`\"\n-            )\n-            from quanto import QModuleMixin\n \n         not_missing_keys = []\n         for name, module in model.named_modules():\n@@ -122,11 +116,6 @@ def check_quantized_param(\n         \"\"\"\n         if is_optimum_quanto_available():\n             from optimum.quanto import QModuleMixin\n-        elif is_quanto_available():\n-            logger.warning_once(\n-                \"Importing from quanto will be deprecated in v4.47. Please install optimum-quanto instead `pip install optimum-quanto`\"\n-            )\n-            from quanto import QModuleMixin\n \n         device_map = kwargs.get(\"device_map\", None)\n         param_device = kwargs.get(\"param_device\", None)"
        },
        {
            "sha": "08d23e0e6a5d41c5ecbf16120a74a65d2084808e",
            "filename": "src/transformers/utils/__init__.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/95a855e212412e2a835511dacb3776f9ed064fe1/src%2Ftransformers%2Futils%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/95a855e212412e2a835511dacb3776f9ed064fe1/src%2Ftransformers%2Futils%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2F__init__.py?ref=95a855e212412e2a835511dacb3776f9ed064fe1",
            "patch": "@@ -175,7 +175,6 @@\n     is_pytesseract_available,\n     is_pytest_available,\n     is_pytorch_quantization_available,\n-    is_quanto_available,\n     is_rjieba_available,\n     is_sacremoses_available,\n     is_safetensors_available,"
        },
        {
            "sha": "32a647594741dda40837beac356eee3b1b4abfc8",
            "filename": "src/transformers/utils/import_utils.py",
            "status": "modified",
            "additions": 0,
            "deletions": 7,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/95a855e212412e2a835511dacb3776f9ed064fe1/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/95a855e212412e2a835511dacb3776f9ed064fe1/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fimport_utils.py?ref=95a855e212412e2a835511dacb3776f9ed064fe1",
            "patch": "@@ -997,13 +997,6 @@ def is_auto_awq_available():\n     return _auto_awq_available\n \n \n-def is_quanto_available():\n-    logger.warning_once(\n-        \"Importing from quanto will be deprecated in v4.47. Please install optimum-quanto instead `pip install optimum-quanto`\"\n-    )\n-    return _quanto_available\n-\n-\n def is_optimum_quanto_available():\n     # `importlib.metadata.version` doesn't work with `optimum.quanto`, need to put `optimum_quanto`\n     return _is_optimum_quanto_available"
        }
    ],
    "stats": {
        "total": 53,
        "additions": 3,
        "deletions": 50
    }
}