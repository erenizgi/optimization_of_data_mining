{
    "author": "gante",
    "message": "RoPE: fix BC warning (#33331)",
    "sha": "6ff6069fa7e23dac9af999fb28503fec9d48c5bf",
    "files": [
        {
            "sha": "e7aa1ceb92132975d5209ab1a9dc7048504b91f6",
            "filename": "src/transformers/modeling_rope_utils.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/6ff6069fa7e23dac9af999fb28503fec9d48c5bf/src%2Ftransformers%2Fmodeling_rope_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6ff6069fa7e23dac9af999fb28503fec9d48c5bf/src%2Ftransformers%2Fmodeling_rope_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_rope_utils.py?ref=6ff6069fa7e23dac9af999fb28503fec9d48c5bf",
            "patch": "@@ -362,10 +362,10 @@ def _compute_llama3_parameters(\n \n def _check_received_keys(rope_type: str, received_keys: set, required_keys: set, optional_keys: Optional[set] = None):\n     \"\"\"Compare the received keys in `config.rope_scaling` against the expected and optional keys\"\"\"\n-    # BC: \"rope_type\" was originally \"type\" -- let's gracefully handle it\n-    if \"rope_type\" not in received_keys and \"type\" in received_keys:\n+    # BC: \"rope_type\" was originally \"type\" -- let's check for \"rope_type\" when \"type\" is present\n+    if \"type\" in received_keys:\n         received_keys -= {\"type\"}\n-        received_keys.add(\"rope_type\")\n+        required_keys.add(\"rope_type\")\n \n     missing_keys = required_keys - received_keys\n     if missing_keys:"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 3,
        "deletions": 3
    }
}