{
    "author": "zucchini-nlp",
    "message": "BLIP: this is correct now (#35081)\n\nthis is correct now",
    "sha": "e682c17e4a7877b13b7b661880bc3514b7fa2804",
    "files": [
        {
            "sha": "ed8ddd3c47dea32c6859d557f4495a7d1e622b72",
            "filename": "src/transformers/models/blip_2/modeling_blip_2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e682c17e4a7877b13b7b661880bc3514b7fa2804/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e682c17e4a7877b13b7b661880bc3514b7fa2804/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py?ref=e682c17e4a7877b13b7b661880bc3514b7fa2804",
            "patch": "@@ -2311,7 +2311,7 @@ def generate(\n         if input_ids is None:\n             start_tokens = [self.config.text_config.bos_token_id]\n             if getattr(self.config, \"image_token_index\", None) is not None:\n-                start_tokens += [self.config.image_token_index] * self.config.num_query_tokens\n+                start_tokens = [self.config.image_token_index] * self.config.num_query_tokens + start_tokens\n             input_ids = torch.tensor([start_tokens], dtype=torch.long, device=image_embeds.device)\n             input_ids = input_ids.repeat(batch_size, 1)\n "
        },
        {
            "sha": "acce24cc42f5d819b570ce0a431b1e4f7cbc6fa6",
            "filename": "src/transformers/models/instructblip/modeling_instructblip.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e682c17e4a7877b13b7b661880bc3514b7fa2804/src%2Ftransformers%2Fmodels%2Finstructblip%2Fmodeling_instructblip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e682c17e4a7877b13b7b661880bc3514b7fa2804/src%2Ftransformers%2Fmodels%2Finstructblip%2Fmodeling_instructblip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finstructblip%2Fmodeling_instructblip.py?ref=e682c17e4a7877b13b7b661880bc3514b7fa2804",
            "patch": "@@ -1593,7 +1593,7 @@ def generate(\n         if input_ids is None:\n             start_tokens = [self.config.text_config.bos_token_id]\n             if getattr(self.config, \"image_token_index\", None) is not None:\n-                start_tokens += [self.config.image_token_index] * self.config.num_query_tokens\n+                start_tokens = [self.config.image_token_index] * self.config.num_query_tokens + start_tokens\n             input_ids = torch.tensor([start_tokens], dtype=torch.long, device=image_embeds.device)\n             input_ids = input_ids.repeat(batch_size, 1)\n "
        },
        {
            "sha": "e91b05bc015263b65bf97ba7e6818960ebb0d836",
            "filename": "src/transformers/models/instructblipvideo/modeling_instructblipvideo.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e682c17e4a7877b13b7b661880bc3514b7fa2804/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodeling_instructblipvideo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e682c17e4a7877b13b7b661880bc3514b7fa2804/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodeling_instructblipvideo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodeling_instructblipvideo.py?ref=e682c17e4a7877b13b7b661880bc3514b7fa2804",
            "patch": "@@ -1628,7 +1628,7 @@ def generate(\n         if input_ids is None:\n             start_tokens = [self.config.text_config.bos_token_id]\n             if getattr(self.config, \"video_token_index\", None) is not None:\n-                start_tokens += [self.config.video_token_index] * self.config.num_query_tokens * 4\n+                start_tokens = [self.config.video_token_index] * self.config.num_query_tokens * 4 + start_tokens\n             input_ids = torch.tensor([start_tokens], dtype=torch.long, device=image_embeds.device)\n             input_ids = input_ids.repeat(batch_size, 1)\n "
        },
        {
            "sha": "7184955af3aa56956c1ec8b9c310fbaaf2b71945",
            "filename": "src/transformers/models/instructblipvideo/modular_instructblipvideo.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e682c17e4a7877b13b7b661880bc3514b7fa2804/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodular_instructblipvideo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e682c17e4a7877b13b7b661880bc3514b7fa2804/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodular_instructblipvideo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodular_instructblipvideo.py?ref=e682c17e4a7877b13b7b661880bc3514b7fa2804",
            "patch": "@@ -441,7 +441,7 @@ def generate(\n         if input_ids is None:\n             start_tokens = [self.config.text_config.bos_token_id]\n             if getattr(self.config, \"video_token_index\", None) is not None:\n-                start_tokens += [self.config.video_token_index] * self.config.num_query_tokens * 4\n+                start_tokens = [self.config.video_token_index] * self.config.num_query_tokens * 4 + start_tokens\n             input_ids = torch.tensor([start_tokens], dtype=torch.long, device=image_embeds.device)\n             input_ids = input_ids.repeat(batch_size, 1)\n "
        }
    ],
    "stats": {
        "total": 8,
        "additions": 4,
        "deletions": 4
    }
}