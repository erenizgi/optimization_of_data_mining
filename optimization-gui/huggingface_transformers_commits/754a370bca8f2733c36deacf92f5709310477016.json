{
    "author": "tugsbayasgalan",
    "message": "Remove unnecessary attr assignment (#36837)\n\nCo-authored-by: Pavel Iakubovskii <qubvel@gmail.com>",
    "sha": "754a370bca8f2733c36deacf92f5709310477016",
    "files": [
        {
            "sha": "6827a4a1882fd1f5406dc51e1ea64fceeeb74358",
            "filename": "src/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/754a370bca8f2733c36deacf92f5709310477016/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fmodeling_bigbird_pegasus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/754a370bca8f2733c36deacf92f5709310477016/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fmodeling_bigbird_pegasus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fmodeling_bigbird_pegasus.py?ref=754a370bca8f2733c36deacf92f5709310477016",
            "patch": "@@ -1958,8 +1958,6 @@ def forward(\n         if not return_dict:\n             return tuple(v for v in [hidden_states, encoder_states, all_attentions] if v is not None)\n \n-        self.encoder_o = hidden_states\n-\n         return BaseModelOutput(\n             last_hidden_state=hidden_states, hidden_states=encoder_states, attentions=all_attentions\n         )"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 0,
        "deletions": 2
    }
}