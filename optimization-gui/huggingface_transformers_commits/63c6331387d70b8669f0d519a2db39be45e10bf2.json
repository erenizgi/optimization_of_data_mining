{
    "author": "pcuenca",
    "message": "Qwen 2.5 Omni: apply video defaults (#37660)\n\n* Apply video defaults for min_pixels and max_pixels\n\n* fps kwarg should not be a list\n\n* Update test to account for new resizing",
    "sha": "63c6331387d70b8669f0d519a2db39be45e10bf2",
    "files": [
        {
            "sha": "57b2d43a3f5f6c26a4c49c343032a77fa2413f29",
            "filename": "src/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/63c6331387d70b8669f0d519a2db39be45e10bf2/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/63c6331387d70b8669f0d519a2db39be45e10bf2/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py?ref=63c6331387d70b8669f0d519a2db39be45e10bf2",
            "patch": "@@ -61,6 +61,8 @@ class Qwen2_5OmniProcessorKwargs(ProcessingKwargs, total=False):\n             \"seconds_per_chunk\": 2.0,\n             \"position_id_per_seconds\": 25,\n             \"use_audio_in_video\": False,\n+            \"min_pixels\": 128 * 28 * 28,\n+            \"max_pixels\": 768 * 28 * 28,\n         },\n         \"audio_kwargs\": {\n             \"sampling_rate\": 16000,\n@@ -147,7 +149,7 @@ def __call__(\n         seconds_per_chunk = output_kwargs[\"videos_kwargs\"].pop(\"seconds_per_chunk\")\n         position_id_per_seconds = output_kwargs[\"videos_kwargs\"].pop(\"position_id_per_seconds\")\n         use_audio_in_video = output_kwargs[\"videos_kwargs\"].pop(\"use_audio_in_video\")\n-        fps = output_kwargs[\"videos_kwargs\"].pop(\"fps\", None)\n+        fps = output_kwargs[\"videos_kwargs\"].pop(\"fps\", 2.0)\n \n         if audio is not None:\n             output_kwargs[\"audio_kwargs\"][\"padding\"] = \"max_length\"  # Support \"max_length\" padding only here\n@@ -174,8 +176,7 @@ def __call__(\n         if videos is not None:\n             videos = make_batched_videos(videos)\n             videos_inputs = self.image_processor(images=None, videos=videos, **output_kwargs[\"videos_kwargs\"])\n-            if fps is None:\n-                fps = [2.0] * len(videos)\n+            fps = [fps] * len(videos)\n             videos_inputs[\"video_second_per_grid\"] = [\n                 self.image_processor.temporal_patch_size / fps[i] for i in range(len(fps))\n             ]"
        },
        {
            "sha": "60b4622968956ee567cc4ff56cfdee00cd5dd064",
            "filename": "tests/models/qwen2_5_omni/test_processor_qwen2_5_omni.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/63c6331387d70b8669f0d519a2db39be45e10bf2/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_processor_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/63c6331387d70b8669f0d519a2db39be45e10bf2/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_processor_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_processor_qwen2_5_omni.py?ref=63c6331387d70b8669f0d519a2db39be45e10bf2",
            "patch": "@@ -433,7 +433,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n             num_frames=num_frames,\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 9568)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 5760)\n \n         # Load with `video_fps` arg\n         video_fps = 1\n@@ -445,7 +445,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n             video_fps=video_fps,\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 23920)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 14400)\n \n         # Load with `video_fps` and `num_frames` args, should raise an error\n         with self.assertRaises(ValueError):\n@@ -466,7 +466,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n             return_dict=True,\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 717600)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 432000)\n \n         # Load video as a list of frames (i.e. images). NOTE: each frame should have same size\n         # because we assume they come from one video\n@@ -484,7 +484,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n             return_dict=True,\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 5704)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 2904)\n \n     @require_av\n     def test_apply_chat_template_video_special_processing(self):"
        }
    ],
    "stats": {
        "total": 15,
        "additions": 8,
        "deletions": 7
    }
}