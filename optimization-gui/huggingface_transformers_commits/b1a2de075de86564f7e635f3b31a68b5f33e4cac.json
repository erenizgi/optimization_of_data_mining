{
    "author": "MekkCyber",
    "message": "Follow up to SpQR integration (#36176)\n\nfix",
    "sha": "b1a2de075de86564f7e635f3b31a68b5f33e4cac",
    "files": [
        {
            "sha": "7252e9808ee92e8607840d86c32b2b7a1850f133",
            "filename": "src/transformers/quantizers/quantizer_spqr.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/b1a2de075de86564f7e635f3b31a68b5f33e4cac/src%2Ftransformers%2Fquantizers%2Fquantizer_spqr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b1a2de075de86564f7e635f3b31a68b5f33e4cac/src%2Ftransformers%2Fquantizers%2Fquantizer_spqr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizer_spqr.py?ref=b1a2de075de86564f7e635f3b31a68b5f33e4cac",
            "patch": "@@ -35,6 +35,8 @@ class SpQRHfQuantizer(HfQuantizer):\n     Quantizer of the SpQR method. Enables the loading of prequantized models.\n     \"\"\"\n \n+    requires_calibration = True\n+\n     def __init__(self, quantization_config: QuantizationConfigMixin, **kwargs):\n         super().__init__(quantization_config, **kwargs)\n         self.quantization_config = quantization_config"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 2,
        "deletions": 0
    }
}