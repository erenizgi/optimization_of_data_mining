{
    "author": "vasqu",
    "message": "[`Pop2Piano`] Fix tied weights (#42193)\n\n* fix\n\n* try oh try\n\n* change fix",
    "sha": "f78cadfc974469bc4d834fca73f6cafd75ee9473",
    "files": [
        {
            "sha": "4394f955731d4afa912d8fdb542f65de44bca800",
            "filename": "src/transformers/models/pop2piano/configuration_pop2piano.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/f78cadfc974469bc4d834fca73f6cafd75ee9473/src%2Ftransformers%2Fmodels%2Fpop2piano%2Fconfiguration_pop2piano.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f78cadfc974469bc4d834fca73f6cafd75ee9473/src%2Ftransformers%2Fmodels%2Fpop2piano%2Fconfiguration_pop2piano.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpop2piano%2Fconfiguration_pop2piano.py?ref=f78cadfc974469bc4d834fca73f6cafd75ee9473",
            "patch": "@@ -122,6 +122,7 @@ def __init__(\n             is_encoder_decoder=is_encoder_decoder,\n             **kwargs,\n         )\n+        self.tie_encoder_decoder = True  # forcing it\n \n \n __all__ = [\"Pop2PianoConfig\"]"
        },
        {
            "sha": "086fc951dd04afd95a887ad6ccb1c81e8c911cdf",
            "filename": "src/transformers/models/pop2piano/modeling_pop2piano.py",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/f78cadfc974469bc4d834fca73f6cafd75ee9473/src%2Ftransformers%2Fmodels%2Fpop2piano%2Fmodeling_pop2piano.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f78cadfc974469bc4d834fca73f6cafd75ee9473/src%2Ftransformers%2Fmodels%2Fpop2piano%2Fmodeling_pop2piano.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpop2piano%2Fmodeling_pop2piano.py?ref=f78cadfc974469bc4d834fca73f6cafd75ee9473",
            "patch": "@@ -554,7 +554,7 @@ def _init_weights(self, module):\n             module.embedding.weight.normal_(mean=0.0, std=factor * 1.0)\n         elif isinstance(module, Pop2PianoForConditionalGeneration):\n             module.shared.weight.normal_(mean=0.0, std=factor * 1.0)\n-            if hasattr(module, \"lm_head\") and not self.config.tie_word_embeddings:\n+            if hasattr(module, \"lm_head\"):\n                 module.lm_head.weight.normal_(mean=0.0, std=factor * 1.0)\n         elif isinstance(module, Pop2PianoDenseActDense):\n             module.wi.weight.normal_(mean=0.0, std=factor * ((self.config.d_model) ** -0.5))\n@@ -948,7 +948,6 @@ class Pop2PianoForConditionalGeneration(Pop2PianoPreTrainedModel, GenerationMixi\n     _tied_weights_keys = {\n         \"encoder.embed_tokens.weight\": \"shared.weight\",\n         \"decoder.embed_tokens.weight\": \"shared.weight\",\n-        \"lm_head.weight\": \"shared.weight\",\n     }\n \n     def __init__(self, config: Pop2PianoConfig):\n@@ -963,13 +962,11 @@ def __init__(self, config: Pop2PianoConfig):\n         encoder_config = copy.deepcopy(config)\n         encoder_config.is_decoder = False\n         encoder_config.use_cache = False\n-        encoder_config.tie_encoder_decoder = False\n \n         self.encoder = Pop2PianoStack(encoder_config)\n \n         decoder_config = copy.deepcopy(config)\n         decoder_config.is_decoder = True\n-        decoder_config.tie_encoder_decoder = False\n         decoder_config.num_layers = config.num_decoder_layers\n         self.decoder = Pop2PianoStack(decoder_config)\n "
        },
        {
            "sha": "e68ea243df234ea1c1ebda1680b07869f6ec70e3",
            "filename": "tests/models/pop2piano/test_modeling_pop2piano.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f78cadfc974469bc4d834fca73f6cafd75ee9473/tests%2Fmodels%2Fpop2piano%2Ftest_modeling_pop2piano.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f78cadfc974469bc4d834fca73f6cafd75ee9473/tests%2Fmodels%2Fpop2piano%2Ftest_modeling_pop2piano.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpop2piano%2Ftest_modeling_pop2piano.py?ref=f78cadfc974469bc4d834fca73f6cafd75ee9473",
            "patch": "@@ -574,7 +574,7 @@ def test_v1_1_resize_embeddings(self):\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"sweetcocoa/pop2piano\"\n-        model = Pop2PianoForConditionalGeneration.from_pretrained(model_name, trust_remote_code=True)\n+        model = Pop2PianoForConditionalGeneration.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n     def test_pass_with_input_features(self):\n@@ -585,7 +585,7 @@ def test_pass_with_input_features(self):\n                 \"extrapolated_beatstep\": torch.randint(size=(1, 900), low=0, high=100).type(torch.float32),\n             }\n         )\n-        model = Pop2PianoForConditionalGeneration.from_pretrained(\"sweetcocoa/pop2piano\", trust_remote_code=True)\n+        model = Pop2PianoForConditionalGeneration.from_pretrained(\"sweetcocoa/pop2piano\")\n         model_opts = model.generate(input_features=input_features[\"input_features\"], return_dict_in_generate=True)\n \n         self.assertEqual(model_opts.sequences.ndim, 2)\n@@ -611,7 +611,7 @@ def test_pass_with_batched_input_features(self):\n                 \"attention_mask_extrapolated_beatstep\": torch.ones((5, 900)).type(torch.int32),\n             }\n         )\n-        model = Pop2PianoForConditionalGeneration.from_pretrained(\"sweetcocoa/pop2piano\", trust_remote_code=True)\n+        model = Pop2PianoForConditionalGeneration.from_pretrained(\"sweetcocoa/pop2piano\")\n         model_opts = model.generate(\n             input_features=input_features[\"input_features\"],\n             attention_mask=input_features[\"attention_mask\"],"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 5,
        "deletions": 7
    }
}