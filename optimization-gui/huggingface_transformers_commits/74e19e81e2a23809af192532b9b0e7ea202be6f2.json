{
    "author": "matsuo1234567",
    "message": "Fix spell mistakes (#33149)",
    "sha": "74e19e81e2a23809af192532b9b0e7ea202be6f2",
    "files": [
        {
            "sha": "10a2a02f7f3af4d4fda905d30c7d6f1a01f8f043",
            "filename": "examples/flax/language-modeling/README.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/74e19e81e2a23809af192532b9b0e7ea202be6f2/examples%2Fflax%2Flanguage-modeling%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/74e19e81e2a23809af192532b9b0e7ea202be6f2/examples%2Fflax%2Flanguage-modeling%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fflax%2Flanguage-modeling%2FREADME.md?ref=74e19e81e2a23809af192532b9b0e7ea202be6f2",
            "patch": "@@ -221,7 +221,7 @@ python run_clm_flax.py \\\n Training should converge at a loss and perplexity\n of 3.24 and 25.72 respectively after 20 epochs on a single TPUv3-8.\n This should take less than ~21 hours.\n-Training statistics can be accessed on [tfhub.de](https://tensorboard.dev/experiment/2zEhLwJ0Qp2FAkI3WVH9qA).\n+Training statistics can be accessed on [tfhub.dev](https://tensorboard.dev/experiment/2zEhLwJ0Qp2FAkI3WVH9qA).\n \n For a step-by-step walkthrough of how to do causal language modeling in Flax, please have a\n look at [this](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/causal_language_modeling_flax.ipynb) google colab."
        },
        {
            "sha": "2eb21f49b65fe282f0e7768554555a94d2962ed2",
            "filename": "examples/flax/summarization/README.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/74e19e81e2a23809af192532b9b0e7ea202be6f2/examples%2Fflax%2Fsummarization%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/74e19e81e2a23809af192532b9b0e7ea202be6f2/examples%2Fflax%2Fsummarization%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fflax%2Fsummarization%2FREADME.md?ref=74e19e81e2a23809af192532b9b0e7ea202be6f2",
            "patch": "@@ -30,6 +30,6 @@ python run_summarization_flax.py \\\n \t--push_to_hub\n ```\n \n-This should finish in 37min, with validation loss and ROUGE2 score of 1.7785 and 17.01 respectively after 6 epochs. training statistics can be accessed on [tfhub.de](https://tensorboard.dev/experiment/OcPfOIgXRMSJqYB4RdK2tA/#scalars).\n+This should finish in 37min, with validation loss and ROUGE2 score of 1.7785 and 17.01 respectively after 6 epochs. training statistics can be accessed on [tfhub.dev](https://tensorboard.dev/experiment/OcPfOIgXRMSJqYB4RdK2tA/#scalars).\n \n > Note that here we used default `generate` arguments, using arguments specific for `xsum` dataset should give better ROUGE scores.  "
        },
        {
            "sha": "63cf4e367c3d31f355b2c5282f93a3d7de34e09b",
            "filename": "examples/legacy/benchmarking/README.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/74e19e81e2a23809af192532b9b0e7ea202be6f2/examples%2Flegacy%2Fbenchmarking%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/74e19e81e2a23809af192532b9b0e7ea202be6f2/examples%2Flegacy%2Fbenchmarking%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Flegacy%2Fbenchmarking%2FREADME.md?ref=74e19e81e2a23809af192532b9b0e7ea202be6f2",
            "patch": "@@ -22,5 +22,5 @@ If you would like to list benchmark results on your favorite models of the [mode\n \n | Benchmark description | Results | Environment info |      Author      |\n |:----------|:-------------|:-------------|------:|\n-| PyTorch Benchmark on inference for `google-bert/bert-base-cased` |[memory](https://github.com/patrickvonplaten/files_to_link_to/blob/master/bert_benchmark/inference_memory.csv) | [env](https://github.com/patrickvonplaten/files_to_link_to/blob/master/bert_benchmark/env.csv) | [Partick von Platen](https://github.com/patrickvonplaten) | \n-| PyTorch Benchmark on inference for `google-bert/bert-base-cased` |[time](https://github.com/patrickvonplaten/files_to_link_to/blob/master/bert_benchmark/inference_time.csv) | [env](https://github.com/patrickvonplaten/files_to_link_to/blob/master/bert_benchmark/env.csv) | [Partick von Platen](https://github.com/patrickvonplaten) | \n+| PyTorch Benchmark on inference for `google-bert/bert-base-cased` |[memory](https://github.com/patrickvonplaten/files_to_link_to/blob/master/bert_benchmark/inference_memory.csv) | [env](https://github.com/patrickvonplaten/files_to_link_to/blob/master/bert_benchmark/env.csv) | [Patrick von Platen](https://github.com/patrickvonplaten) | \n+| PyTorch Benchmark on inference for `google-bert/bert-base-cased` |[time](https://github.com/patrickvonplaten/files_to_link_to/blob/master/bert_benchmark/inference_time.csv) | [env](https://github.com/patrickvonplaten/files_to_link_to/blob/master/bert_benchmark/env.csv) | [Patrick von Platen](https://github.com/patrickvonplaten) | "
        }
    ],
    "stats": {
        "total": 8,
        "additions": 4,
        "deletions": 4
    }
}