{
    "author": "Isotr0py",
    "message": "Fix GOT-OCR2 and Cohere2Vision image processor patches caculation (#40312)\n\nfix got-ocr patches caculation\n\nSigned-off-by: Isotr0py <mozf@mail2.sysu.edu.cn>",
    "sha": "a01f38b36483b1aa45fe7ac8e7686ad191c90e99",
    "files": [
        {
            "sha": "6b7c8327dc89f7123f36481a54134cc3fdfd8b55",
            "filename": "src/transformers/models/cohere2_vision/image_processing_cohere2_vision_fast.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/a01f38b36483b1aa45fe7ac8e7686ad191c90e99/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fimage_processing_cohere2_vision_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a01f38b36483b1aa45fe7ac8e7686ad191c90e99/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fimage_processing_cohere2_vision_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere2_vision%2Fimage_processing_cohere2_vision_fast.py?ref=a01f38b36483b1aa45fe7ac8e7686ad191c90e99",
            "patch": "@@ -301,7 +301,8 @@ def get_number_of_image_patches(self, height: int, width: int, images_kwargs=Non\n             num_columns, num_rows = get_optimal_tiled_canvas(\n                 (height, width), (patch_size[\"height\"], patch_size[\"width\"]), min_patches, max_patches\n             )\n-            num_patches += num_columns * num_rows\n+            if num_columns * num_rows > 1:\n+                num_patches += num_columns * num_rows\n \n         return num_patches\n "
        },
        {
            "sha": "6a0dca87355895b27db02528ea004379a6ad63a9",
            "filename": "src/transformers/models/got_ocr2/image_processing_got_ocr2.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/a01f38b36483b1aa45fe7ac8e7686ad191c90e99/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fimage_processing_got_ocr2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a01f38b36483b1aa45fe7ac8e7686ad191c90e99/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fimage_processing_got_ocr2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fimage_processing_got_ocr2.py?ref=a01f38b36483b1aa45fe7ac8e7686ad191c90e99",
            "patch": "@@ -515,7 +515,8 @@ def get_number_of_image_patches(self, height: int, width: int, images_kwargs=Non\n             num_columns, num_rows = get_optimal_tiled_canvas(\n                 (height, width), (patch_size[\"height\"], patch_size[\"width\"]), min_patches, max_patches\n             )\n-            num_patches += num_columns * num_rows\n+            if num_columns * num_rows > 1:\n+                num_patches += num_columns * num_rows\n \n         return num_patches\n "
        },
        {
            "sha": "6652e018263cdc6dae9f81b190dd56771bbdbcd3",
            "filename": "src/transformers/models/got_ocr2/image_processing_got_ocr2_fast.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/a01f38b36483b1aa45fe7ac8e7686ad191c90e99/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fimage_processing_got_ocr2_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a01f38b36483b1aa45fe7ac8e7686ad191c90e99/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fimage_processing_got_ocr2_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fimage_processing_got_ocr2_fast.py?ref=a01f38b36483b1aa45fe7ac8e7686ad191c90e99",
            "patch": "@@ -247,7 +247,8 @@ def get_number_of_image_patches(self, height: int, width: int, images_kwargs=Non\n             num_columns, num_rows = get_optimal_tiled_canvas(\n                 (height, width), (patch_size[\"height\"], patch_size[\"width\"]), min_patches, max_patches\n             )\n-            num_patches += num_columns * num_rows\n+            if num_columns * num_rows > 1:\n+                num_patches += num_columns * num_rows\n \n         return num_patches\n "
        },
        {
            "sha": "4228ffe4dcba858544a1837a3d42c08223ebd614",
            "filename": "tests/models/got_ocr2/test_image_processing_got_ocr2.py",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/a01f38b36483b1aa45fe7ac8e7686ad191c90e99/tests%2Fmodels%2Fgot_ocr2%2Ftest_image_processing_got_ocr2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a01f38b36483b1aa45fe7ac8e7686ad191c90e99/tests%2Fmodels%2Fgot_ocr2%2Ftest_image_processing_got_ocr2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgot_ocr2%2Ftest_image_processing_got_ocr2.py?ref=a01f38b36483b1aa45fe7ac8e7686ad191c90e99",
            "patch": "@@ -181,6 +181,16 @@ def test_get_num_patches_without_images(self):\n             )\n             self.assertEqual(num_patches, 1)\n \n+            num_patches = image_processing.get_number_of_image_patches(\n+                height=20, width=20, images_kwargs={\"crop_to_patches\": True}\n+            )\n+            self.assertEqual(num_patches, 1)\n+\n+            num_patches = image_processing.get_number_of_image_patches(\n+                height=60, width=60, images_kwargs={\"crop_to_patches\": True}\n+            )\n+            self.assertEqual(num_patches, 10)\n+\n             num_patches = image_processing.get_number_of_image_patches(\n                 height=100, width=100, images_kwargs={\"crop_to_patches\": True}\n             )"
        }
    ],
    "stats": {
        "total": 19,
        "additions": 16,
        "deletions": 3
    }
}