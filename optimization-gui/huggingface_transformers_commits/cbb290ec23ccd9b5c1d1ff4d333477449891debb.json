{
    "author": "mapmeld",
    "message": "Improve documentation and errors in Mamba2-based models (#41063)\n\n* fix bug in Mamba2 docs\n\n* correct 'because on of' issue\n\n* link to other Mamba2 model types\n\n* github URL is not changed\n\n* update error message in generated files",
    "sha": "cbb290ec23ccd9b5c1d1ff4d333477449891debb",
    "files": [
        {
            "sha": "11666e1fa5766b44c0cc517e1bc7e1c6cb948af1",
            "filename": "docs/source/en/model_doc/mamba2.md",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cbb290ec23ccd9b5c1d1ff4d333477449891debb/docs%2Fsource%2Fen%2Fmodel_doc%2Fmamba2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/cbb290ec23ccd9b5c1d1ff4d333477449891debb/docs%2Fsource%2Fen%2Fmodel_doc%2Fmamba2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fmamba2.md?ref=cbb290ec23ccd9b5c1d1ff4d333477449891debb",
            "patch": "@@ -1,4 +1,4 @@\n-<!--Copyright 2024 The HuggingFace Team. All rights reserved.\n+<!--Copyright 2025 The HuggingFace Team. All rights reserved.\n \n Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n the License. You may obtain a copy of the License at\n@@ -26,13 +26,15 @@ rendered properly in your Markdown viewer.\n \n You can find all the original Mamba 2 checkpoints under the [State Space Models](https://huggingface.co/state-spaces) organization, but the examples shown below use [mistralai/Mamba-Codestral-7B-v0.1](https://huggingface.co/mistralai/Mamba-Codestral-7B-v0.1) because a Hugging Face implementation isn't supported yet for the original checkpoints.\n \n+Other Mamba 2-based architectures include [Bamba](./bamba), [FalconH1](./falcon_h1), and [Zamba2](./zamba2).\n+\n > [!TIP]\n > This model was contributed by [ArthurZ](https://huggingface.co/ArthurZ).\n > Click on the Mamba models in the right sidebar for more examples of how to apply Mamba to different language tasks.\n \n The example below demonstrates how to generate text with [`Pipeline`], [`AutoModel`], and from the command line.\n \n-hfoptions id=\"usage\">\n+<hfoptions id=\"Usage\">\n <hfoption id=\"Pipeline\">\n \n ```python"
        },
        {
            "sha": "ba4324366a99f3468736eb9a98b91a54db6f1e9b",
            "filename": "docs/source/en/model_doc/zamba2.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cbb290ec23ccd9b5c1d1ff4d333477449891debb/docs%2Fsource%2Fen%2Fmodel_doc%2Fzamba2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/cbb290ec23ccd9b5c1d1ff4d333477449891debb/docs%2Fsource%2Fen%2Fmodel_doc%2Fzamba2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fzamba2.md?ref=cbb290ec23ccd9b5c1d1ff4d333477449891debb",
            "patch": "@@ -29,7 +29,7 @@ This model was contributed by [pglo](https://huggingface.co/pglo).\n \n ## Model details\n \n-[Zamba2-1.2B](https://www.zyphra.com/post/zamba2-mini), [Zamba2-2.7B](https://www.zyphra.com/post/zamba2-small) and [Zamba2-7B](https://www.zyphra.com/post/zamba2-7b) are hybrid models combining state-space models (Specifically [Mamba](https://github.com/state-spaces/mamba)) and transformer, and were trained using next-token prediction. Zamba2 uses shared transformer layers after every 6 mamba blocks. It uses the [Mistral v0.1 tokenizer](https://huggingface.co/mistralai/Mistral-7B-v0.1). We came to this architecture after a series of ablations at small scales. Zamba2-1.2B, Zamba2-2.7B and Zamba2-7B were pre-trained on 2T and 3T tokens, respectively.\n+[Zamba2-1.2B](https://www.zyphra.com/post/zamba2-mini), [Zamba2-2.7B](https://www.zyphra.com/post/zamba2-small) and [Zamba2-7B](https://www.zyphra.com/post/zamba2-7b) are hybrid models combining state-space models (Specifically [Mamba2](https://github.com/state-spaces/mamba)) and transformer, and were trained using next-token prediction. Zamba2 uses shared transformer layers after every 6 mamba blocks. It uses the [Mistral v0.1 tokenizer](https://huggingface.co/mistralai/Mistral-7B-v0.1). We came to this architecture after a series of ablations at small scales. Zamba2-1.2B, Zamba2-2.7B and Zamba2-7B were pre-trained on 2T and 3T tokens, respectively.\n \n <img src=https://github.com/user-attachments/assets/c2cff209-b901-483c-87aa-774b82a0769f width=30% height=40% />\n "
        },
        {
            "sha": "60bf385bf49423e3e34ba1c6bd3d737f509eed10",
            "filename": "src/transformers/models/bamba/modeling_bamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodeling_bamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodeling_bamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodeling_bamba.py?ref=cbb290ec23ccd9b5c1d1ff4d333477449891debb",
            "patch": "@@ -531,7 +531,7 @@ def __init__(self, config: BambaConfig, layer_idx: int):\n \n         if not is_fast_path_available:\n             logger.warning_once(\n-                \"The fast path is not available because on of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n+                \"The fast path is not available because one of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n                 \" is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and\"\n                 \" https://github.com/Dao-AILab/causal-conv1d\"\n             )"
        },
        {
            "sha": "5ae5313d21b83de27a95e2179906219d57779094",
            "filename": "src/transformers/models/bamba/modular_bamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodular_bamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodular_bamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodular_bamba.py?ref=cbb290ec23ccd9b5c1d1ff4d333477449891debb",
            "patch": "@@ -288,7 +288,7 @@ def __init__(self, config: BambaConfig, layer_idx: int):\n \n         if not is_fast_path_available:\n             logger.warning_once(\n-                \"The fast path is not available because on of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n+                \"The fast path is not available because one of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n                 \" is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and\"\n                 \" https://github.com/Dao-AILab/causal-conv1d\"\n             )"
        },
        {
            "sha": "3a8b13ef21d00e400fa19d4e7cea7ea0ab89e4a3",
            "filename": "src/transformers/models/falcon_h1/modeling_falcon_h1.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Ffalcon_h1%2Fmodeling_falcon_h1.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Ffalcon_h1%2Fmodeling_falcon_h1.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffalcon_h1%2Fmodeling_falcon_h1.py?ref=cbb290ec23ccd9b5c1d1ff4d333477449891debb",
            "patch": "@@ -570,7 +570,7 @@ def __init__(self, config: FalconH1Config, layer_idx: int):\n \n         if not is_fast_path_available:\n             logger.warning_once(\n-                \"The fast path is not available because on of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n+                \"The fast path is not available because one of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n                 \" is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and\"\n                 \" https://github.com/Dao-AILab/causal-conv1d\"\n             )"
        },
        {
            "sha": "fe716dded4b35dad154084d3ca7afc632bf8e996",
            "filename": "src/transformers/models/falcon_h1/modular_falcon_h1.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Ffalcon_h1%2Fmodular_falcon_h1.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Ffalcon_h1%2Fmodular_falcon_h1.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffalcon_h1%2Fmodular_falcon_h1.py?ref=cbb290ec23ccd9b5c1d1ff4d333477449891debb",
            "patch": "@@ -374,7 +374,7 @@ def __init__(self, config: FalconH1Config, layer_idx: int):\n \n         if not is_fast_path_available:\n             logger.warning_once(\n-                \"The fast path is not available because on of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n+                \"The fast path is not available because one of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n                 \" is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and\"\n                 \" https://github.com/Dao-AILab/causal-conv1d\"\n             )"
        },
        {
            "sha": "8f6059720b04b1befd7d6373a6d3409ccf97a0fa",
            "filename": "src/transformers/models/granitemoehybrid/modeling_granitemoehybrid.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py?ref=cbb290ec23ccd9b5c1d1ff4d333477449891debb",
            "patch": "@@ -458,7 +458,7 @@ def __init__(self, config: GraniteMoeHybridConfig, layer_idx: int):\n \n         if not is_fast_path_available:\n             logger.warning_once(\n-                \"The fast path is not available because on of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n+                \"The fast path is not available because one of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n                 \" is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and\"\n                 \" https://github.com/Dao-AILab/causal-conv1d\"\n             )"
        },
        {
            "sha": "7196045390b1f9f10ac801dbc3a533c8b87c594f",
            "filename": "src/transformers/models/jamba/modeling_jamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py?ref=cbb290ec23ccd9b5c1d1ff4d333477449891debb",
            "patch": "@@ -610,7 +610,7 @@ def __init__(self, config: JambaConfig, layer_idx):\n \n         if not is_fast_path_available:\n             logger.warning_once(\n-                \"The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)`\"\n+                \"The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)`\"\n                 \" is None. To install follow https://github.com/state-spaces/mamba/#installation and\"\n                 \" https://github.com/Dao-AILab/causal-conv1d. If you want to use the naive implementation, set `use_mamba_kernels=False` in the model config\"\n             )"
        },
        {
            "sha": "bb24e2422d3279cff642d77d18351a8a7df25f8b",
            "filename": "src/transformers/models/mamba2/modeling_mamba2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fmamba2%2Fmodeling_mamba2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fmamba2%2Fmodeling_mamba2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmamba2%2Fmodeling_mamba2.py?ref=cbb290ec23ccd9b5c1d1ff4d333477449891debb",
            "patch": "@@ -286,7 +286,7 @@ def __init__(self, config: Mamba2Config, layer_idx: int):\n \n         if not is_fast_path_available:\n             logger.warning_once(\n-                \"The fast path is not available because on of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n+                \"The fast path is not available because one of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n                 \" is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and\"\n                 \" https://github.com/Dao-AILab/causal-conv1d\"\n             )"
        },
        {
            "sha": "dc95e1e550faa51a0c9a973dfc660d405f85fd28",
            "filename": "src/transformers/models/zamba/modeling_zamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fzamba%2Fmodeling_zamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fzamba%2Fmodeling_zamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fzamba%2Fmodeling_zamba.py?ref=cbb290ec23ccd9b5c1d1ff4d333477449891debb",
            "patch": "@@ -355,7 +355,7 @@ def __init__(self, config: ZambaConfig, layer_idx):\n \n         if not is_fast_path_available:\n             logger.warning_once(\n-                \"The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)`\"\n+                \"The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)`\"\n                 \" is None. To install follow https://github.com/state-spaces/mamba/#installation and\"\n                 \" https://github.com/Dao-AILab/causal-conv1d. If you want to use the naive implementation, set `use_mamba_kernels=False` in the model config\"\n             )"
        },
        {
            "sha": "60e546f321209f38b1a02e984b98ddb8e6590dc1",
            "filename": "src/transformers/models/zamba2/modeling_zamba2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fzamba2%2Fmodeling_zamba2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fzamba2%2Fmodeling_zamba2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fzamba2%2Fmodeling_zamba2.py?ref=cbb290ec23ccd9b5c1d1ff4d333477449891debb",
            "patch": "@@ -563,7 +563,7 @@ def __init__(self, config: Zamba2Config, layer_idx: Optional[int] = None):\n \n         if not is_fast_path_available:\n             logger.warning_once(\n-                \"The fast path is not available because on of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n+                \"The fast path is not available because one of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n                 \" is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and\"\n                 \" https://github.com/Dao-AILab/causal-conv1d\"\n             )"
        },
        {
            "sha": "d05b23721142fd3df14aa4808b6c18212e3aa6df",
            "filename": "src/transformers/models/zamba2/modular_zamba2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fzamba2%2Fmodular_zamba2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cbb290ec23ccd9b5c1d1ff4d333477449891debb/src%2Ftransformers%2Fmodels%2Fzamba2%2Fmodular_zamba2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fzamba2%2Fmodular_zamba2.py?ref=cbb290ec23ccd9b5c1d1ff4d333477449891debb",
            "patch": "@@ -346,7 +346,7 @@ def __init__(self, config: Zamba2Config, layer_idx: Optional[int] = None):\n \n         if not is_fast_path_available:\n             logger.warning_once(\n-                \"The fast path is not available because on of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n+                \"The fast path is not available because one of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)`\"\n                 \" is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and\"\n                 \" https://github.com/Dao-AILab/causal-conv1d\"\n             )"
        }
    ],
    "stats": {
        "total": 28,
        "additions": 15,
        "deletions": 13
    }
}