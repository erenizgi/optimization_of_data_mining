{
    "author": "molbap",
    "message": "Security/fuyu (#41320)\n\nremove reference to compromised repo",
    "sha": "5abfa43f0252f7e069c2de99fe940138eb33600f",
    "files": [
        {
            "sha": "96cc85ee3c3ef55a3e9dae2c890019190012c77e",
            "filename": "src/transformers/models/fuyu/convert_fuyu_model_weights_to_hf.py",
            "status": "modified",
            "additions": 3,
            "deletions": 11,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/5abfa43f0252f7e069c2de99fe940138eb33600f/src%2Ftransformers%2Fmodels%2Ffuyu%2Fconvert_fuyu_model_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5abfa43f0252f7e069c2de99fe940138eb33600f/src%2Ftransformers%2Fmodels%2Ffuyu%2Fconvert_fuyu_model_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffuyu%2Fconvert_fuyu_model_weights_to_hf.py?ref=5abfa43f0252f7e069c2de99fe940138eb33600f",
            "patch": "@@ -34,21 +34,13 @@\n     tokenizer_class = LlamaTokenizer\n \n \"\"\"\n-Sample usage: # TODO fix clone links from persimmon to fuyu\n-```\n-git clone https://github.com/adept-ai-labs/adept-inference\n-wget https://axtkn4xl5cip.objectstorage.us-phoenix-1.oci.customer-oci.com/n/axtkn4xl5cip/b/adept-public-data/o/8b_base_model_release.tar\n-wget https://axtkn4xl5cip.objectstorage.us-phoenix-1.oci.customer-oci.com/n/axtkn4xl5cip/b/adept-public-data/o/8b_chat_model_release.tar\n-python src/transformers/models/fuyu/convert_fuyu_weights_to_hf.py  --input_dir /path/to/downloaded/fuyu/weights/ --output_dir /output/path\n-```\n-\n-Thereafter, models can be loaded via:\n \n+If you have the original models, they can be loaded with:\n ```py\n from transformers import FuyuForCausalLM, FuyuTokenizer\n \n-model = FuyuForCausalLM.from_pretrained(\"/output/path\")\n-tokenizer = FuyuTokenizer.from_pretrained(\"/output/path\")\n+model = FuyuForCausalLM.from_pretrained(\"/path/to/models/\")\n+tokenizer = FuyuTokenizer.from_pretrained(\"/path/to/models\")\n ```\n \n Important note: you need to be able to host the whole model in RAM to execute this script (even if the biggest versions"
        }
    ],
    "stats": {
        "total": 14,
        "additions": 3,
        "deletions": 11
    }
}