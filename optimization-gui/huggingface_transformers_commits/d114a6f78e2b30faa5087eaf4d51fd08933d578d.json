{
    "author": "gante",
    "message": "[Modular] skip modular checks based on diff (#36130)\n\nskip modular checks based on diff",
    "sha": "d114a6f78e2b30faa5087eaf4d51fd08933d578d",
    "files": [
        {
            "sha": "dbbebe9fc0656f13d65bb2380fc88f0e6f50eaee",
            "filename": ".circleci/config.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/d114a6f78e2b30faa5087eaf4d51fd08933d578d/.circleci%2Fconfig.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/d114a6f78e2b30faa5087eaf4d51fd08933d578d/.circleci%2Fconfig.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.circleci%2Fconfig.yml?ref=d114a6f78e2b30faa5087eaf4d51fd08933d578d",
            "patch": "@@ -58,7 +58,7 @@ jobs:\n             - run:\n                 name: \"Prepare pipeline parameters\"\n                 command: |\n-                    python utils/process_test_artifacts.py \n+                    python utils/process_test_artifacts.py\n \n             # To avoid too long generated_config.yaml on the continuation orb, we pass the links to the artifacts as parameters.\n             # Otherwise the list of tests was just too big. Explicit is good but for that it was a limitation.\n@@ -110,7 +110,7 @@ jobs:\n             - run:\n                 name: \"Prepare pipeline parameters\"\n                 command: |\n-                    python utils/process_test_artifacts.py \n+                    python utils/process_test_artifacts.py\n \n             # To avoid too long generated_config.yaml on the continuation orb, we pass the links to the artifacts as parameters.\n             # Otherwise the list of tests was just too big. Explicit is good but for that it was a limitation."
        },
        {
            "sha": "643b3714a7630d7388eea96b2d808f2f469a5be3",
            "filename": "tests/repo_utils/modular/test_conversion_order.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d114a6f78e2b30faa5087eaf4d51fd08933d578d/tests%2Frepo_utils%2Fmodular%2Ftest_conversion_order.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d114a6f78e2b30faa5087eaf4d51fd08933d578d/tests%2Frepo_utils%2Fmodular%2Ftest_conversion_order.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Frepo_utils%2Fmodular%2Ftest_conversion_order.py?ref=d114a6f78e2b30faa5087eaf4d51fd08933d578d",
            "patch": "@@ -48,7 +48,7 @@ def appear_after(model1: str, model2: str, priority_list: list[str]) -> bool:\n class ConversionOrderTest(unittest.TestCase):\n     def test_conversion_order(self):\n         # Find the order\n-        priority_list = create_dependency_mapping.find_priority_list(FILES_TO_PARSE)\n+        priority_list, _ = create_dependency_mapping.find_priority_list(FILES_TO_PARSE)\n         # Extract just the model names\n         model_priority_list = [file.rsplit(\"modular_\")[-1].replace(\".py\", \"\") for file in priority_list]\n "
        },
        {
            "sha": "c62a192c1075f47f30a50d72793c803a34dd28d1",
            "filename": "utils/check_copies.py",
            "status": "modified",
            "additions": 0,
            "deletions": 34,
            "changes": 34,
            "blob_url": "https://github.com/huggingface/transformers/blob/d114a6f78e2b30faa5087eaf4d51fd08933d578d/utils%2Fcheck_copies.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d114a6f78e2b30faa5087eaf4d51fd08933d578d/utils%2Fcheck_copies.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_copies.py?ref=d114a6f78e2b30faa5087eaf4d51fd08933d578d",
            "patch": "@@ -1024,40 +1024,6 @@ def _rep(match):\n     return readmes_match, \"\\n\".join((x[1] for x in sorted_index)) + \"\\n\"\n \n \n-def _find_text_in_file(filename: str, start_prompt: str, end_prompt: str) -> Tuple[str, int, int, List[str]]:\n-    \"\"\"\n-    Find the text in a file between two prompts.\n-\n-    Args:\n-        filename (`str`): The name of the file to look into.\n-        start_prompt (`str`): The string to look for that introduces the content looked for.\n-        end_prompt (`str`): The string to look for that ends the content looked for.\n-\n-    Returns:\n-        Tuple[str, int, int, List[str]]: The content between the two prompts, the index of the start line in the\n-        original file, the index of the end line in the original file and the list of lines of that file.\n-    \"\"\"\n-    with open(filename, \"r\", encoding=\"utf-8\", newline=\"\\n\") as f:\n-        lines = f.readlines()\n-    # Find the start prompt.\n-    start_index = 0\n-    while not lines[start_index].startswith(start_prompt):\n-        start_index += 1\n-    start_index += 1\n-\n-    end_index = start_index\n-    while not lines[end_index].startswith(end_prompt):\n-        end_index += 1\n-    end_index -= 1\n-\n-    while len(lines[start_index]) <= 1:\n-        start_index += 1\n-    while len(lines[end_index]) <= 1:\n-        end_index -= 1\n-    end_index += 1\n-    return \"\".join(lines[start_index:end_index]), start_index, end_index, lines\n-\n-\n # Map a model name with the name it has in the README for the check_readme check\n SPECIAL_MODEL_NAMES = {\n     \"Bert Generation\": \"BERT For Sequence Generation\","
        },
        {
            "sha": "e08621b5c32c85b9f7b7515638e2bc88b26a227a",
            "filename": "utils/check_modular_conversion.py",
            "status": "modified",
            "additions": 75,
            "deletions": 1,
            "changes": 76,
            "blob_url": "https://github.com/huggingface/transformers/blob/d114a6f78e2b30faa5087eaf4d51fd08933d578d/utils%2Fcheck_modular_conversion.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d114a6f78e2b30faa5087eaf4d51fd08933d578d/utils%2Fcheck_modular_conversion.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_modular_conversion.py?ref=d114a6f78e2b30faa5087eaf4d51fd08933d578d",
            "patch": "@@ -2,6 +2,7 @@\n import difflib\n import glob\n import logging\n+import subprocess\n from io import StringIO\n \n from create_dependency_mapping import find_priority_list\n@@ -61,6 +62,56 @@ def compare_files(modular_file_path, fix_and_overwrite=False):\n     return diff\n \n \n+def get_models_in_diff():\n+    \"\"\"\n+    Finds all models that have been modified in the diff.\n+\n+    Returns:\n+        A set containing the names of the models that have been modified (e.g. {'llama', 'whisper'}).\n+    \"\"\"\n+    fork_point_sha = subprocess.check_output(\"git merge-base main HEAD\".split()).decode(\"utf-8\")\n+    modified_files = (\n+        subprocess.check_output(f\"git diff --diff-filter=d --name-only {fork_point_sha}\".split())\n+        .decode(\"utf-8\")\n+        .split()\n+    )\n+\n+    # Matches both modelling files and tests\n+    relevant_modified_files = [x for x in modified_files if \"/models/\" in x and x.endswith(\".py\")]\n+    model_names = set()\n+    for file_path in relevant_modified_files:\n+        model_name = file_path.split(\"/\")[-2]\n+        model_names.add(model_name)\n+    return model_names\n+\n+\n+def guaranteed_no_diff(modular_file_path, dependencies, models_in_diff):\n+    \"\"\"\n+    Returns whether it is guaranteed to have no differences between the modular file and the modeling file.\n+\n+    Model is in the diff -> not guaranteed to have no differences\n+    Dependency is in the diff -> not guaranteed to have no differences\n+    Otherwise -> guaranteed to have no differences\n+\n+    Args:\n+        modular_file_path: The path to the modular file.\n+        dependencies: A dictionary containing the dependencies of each modular file.\n+        models_in_diff: A set containing the names of the models that have been modified.\n+\n+    Returns:\n+        A boolean indicating whether the model (code and tests) is guaranteed to have no differences.\n+    \"\"\"\n+    model_name = modular_file_path.rsplit(\"modular_\", 1)[1].replace(\".py\", \"\")\n+    if model_name in models_in_diff:\n+        return False\n+    for dep in dependencies[modular_file_path]:\n+        # two possible patterns: `transformers.models.model_name.(...)` or `model_name.(...)`\n+        dependency_model_name = dep.split(\".\")[-2]\n+        if dependency_model_name in models_in_diff:\n+            return False\n+    return True\n+\n+\n if __name__ == \"__main__\":\n     parser = argparse.ArgumentParser(description=\"Compare modular_xxx.py files with modeling_xxx.py files.\")\n     parser.add_argument(\n@@ -72,9 +123,32 @@ def compare_files(modular_file_path, fix_and_overwrite=False):\n     args = parser.parse_args()\n     if args.files == [\"all\"]:\n         args.files = glob.glob(\"src/transformers/models/**/modular_*.py\", recursive=True)\n+\n+    # Assuming there is a topological sort on the dependency mapping: if the file being checked and its dependencies\n+    # are not in the diff, then there it is guaranteed to have no differences. If no models are in the diff, then this\n+    # script will do nothing.\n+    models_in_diff = get_models_in_diff()\n+    if not models_in_diff:\n+        console.print(\"[bold green]No models files or model tests in the diff, skipping modular checks[/bold green]\")\n+        exit(0)\n+\n+    skipped_models = set()\n     non_matching_files = 0\n-    for modular_file_path in find_priority_list(args.files):\n+    ordered_files, dependencies = find_priority_list(args.files)\n+    for modular_file_path in ordered_files:\n+        is_guaranteed_no_diff = guaranteed_no_diff(modular_file_path, dependencies, models_in_diff)\n+        if is_guaranteed_no_diff:\n+            model_name = modular_file_path.rsplit(\"modular_\", 1)[1].replace(\".py\", \"\")\n+            skipped_models.add(model_name)\n+            continue\n         non_matching_files += compare_files(modular_file_path, args.fix_and_overwrite)\n+        models_in_diff = get_models_in_diff()  # When overwriting, the diff changes\n \n     if non_matching_files and not args.fix_and_overwrite:\n         raise ValueError(\"Some diff and their modeling code did not match.\")\n+\n+    if skipped_models:\n+        console.print(\n+            f\"[bold green]Skipped {len(skipped_models)} models and their dependencies that are not in the diff: \"\n+            f\"{', '.join(skipped_models)}[/bold green]\"\n+        )"
        },
        {
            "sha": "f0f62cf1b00052ca7918b8a984cc8a6a850a4a27",
            "filename": "utils/create_dependency_mapping.py",
            "status": "modified",
            "additions": 12,
            "deletions": 2,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/d114a6f78e2b30faa5087eaf4d51fd08933d578d/utils%2Fcreate_dependency_mapping.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d114a6f78e2b30faa5087eaf4d51fd08933d578d/utils%2Fcreate_dependency_mapping.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcreate_dependency_mapping.py?ref=d114a6f78e2b30faa5087eaf4d51fd08933d578d",
            "patch": "@@ -55,6 +55,16 @@ def map_dependencies(py_files):\n \n \n def find_priority_list(py_files):\n+    \"\"\"\n+    Given a list of modular files, sorts them by topological order. Modular models that DON'T depend on other modular\n+    models will be higher in the topological order.\n+\n+    Args:\n+        py_files: List of paths to the modular files\n+\n+    Returns:\n+        A tuple with the ordered files (list) and their dependencies (dict)\n+    \"\"\"\n     dependencies = map_dependencies(py_files)\n-    ordered_classes = topological_sort(dependencies)\n-    return ordered_classes\n+    ordered_files = topological_sort(dependencies)\n+    return ordered_files, dependencies"
        },
        {
            "sha": "3c5d062fbe3a1ac5d7020eb4f89db0bc5b9d3804",
            "filename": "utils/modular_model_converter.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d114a6f78e2b30faa5087eaf4d51fd08933d578d/utils%2Fmodular_model_converter.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d114a6f78e2b30faa5087eaf4d51fd08933d578d/utils%2Fmodular_model_converter.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fmodular_model_converter.py?ref=d114a6f78e2b30faa5087eaf4d51fd08933d578d",
            "patch": "@@ -1716,7 +1716,7 @@ def save_modeling_file(modular_file, converted_file):\n     if args.files_to_parse == [\"examples\"]:\n         args.files_to_parse = glob.glob(\"examples/**/modular_*.py\", recursive=True)\n \n-    priority_list = find_priority_list(args.files_to_parse)\n+    priority_list, _ = find_priority_list(args.files_to_parse)\n     assert len(priority_list) == len(args.files_to_parse), \"Some files will not be converted\"\n \n     for file_name in priority_list:"
        }
    ],
    "stats": {
        "total": 132,
        "additions": 91,
        "deletions": 41
    }
}