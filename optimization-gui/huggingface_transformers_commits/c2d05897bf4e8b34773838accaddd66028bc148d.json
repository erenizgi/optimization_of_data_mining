{
    "author": "AhmedAlmaghz",
    "message": "[i18n-ar] Add File : `docs/source/ar/_toctree.yml`  (#32696)\n\n* Update ar lang build_documentation.yml\r\n\r\n* Update ar lang build_pr_documentation.yml\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/pipeline_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/autoclass_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/autoclass_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/autoclass_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/autoclass_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/autoclass_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/autoclass_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/autoclass_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/autoclass_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/autoclass_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/autoclass_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/autoclass_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/autoclass_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/autoclass_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/autoclass_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/preprocessing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/training.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/run_scripts.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/run_scripts.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/run_scripts.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/run_scripts.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/run_scripts.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/run_scripts.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/run_scripts.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/accelerate.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/accelerate.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/accelerate.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/accelerate.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/accelerate.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/accelerate.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Create _config.py\r\n\r\n* Update _toctree.yml\r\n\r\n* Update _toctree.yml\r\n\r\n* Update docs/source/ar/peft.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/peft.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/peft.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/peft.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/peft.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/peft.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/peft.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/peft.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/peft.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update _toctree.yml\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/model_sharing.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/conversations.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/agents.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/llm_tutorial.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update llm_tutorial.md\r\n\r\n* Update _toctree.yml\r\n\r\n* Update autoclass_tutorial.md\r\n\r\n* Update autoclass_tutorial.md\r\n\r\n* Update preprocessing.md\r\n\r\n* Update glossary.md\r\n\r\n* Update run_scripts.md\r\n\r\n* Update run_scripts.md\r\n\r\n* Update run_scripts.md\r\n\r\n---------\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>",
    "sha": "c2d05897bf4e8b34773838accaddd66028bc148d",
    "files": [
        {
            "sha": "b25567fb092a145c93660f66a95dcbcd0740884c",
            "filename": ".github/workflows/build_documentation.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/.github%2Fworkflows%2Fbuild_documentation.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/.github%2Fworkflows%2Fbuild_documentation.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fbuild_documentation.yml?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -15,7 +15,7 @@ jobs:\n       commit_sha: ${{ github.sha }}\n       package: transformers\n       notebook_folder: transformers_doc\n-      languages: de en es fr hi it ko pt tr zh ja te\n+      languages: ar de en es fr hi it ko pt tr zh ja te\n       custom_container: huggingface/transformers-doc-builder\n     secrets:\n       token: ${{ secrets.HUGGINGFACE_PUSH }}"
        },
        {
            "sha": "f698f860b2f93c64a8b4d5c9dfeace0133c99eed",
            "filename": ".github/workflows/build_pr_documentation.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/.github%2Fworkflows%2Fbuild_pr_documentation.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/.github%2Fworkflows%2Fbuild_pr_documentation.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fbuild_pr_documentation.yml?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -14,5 +14,5 @@ jobs:\n       commit_sha: ${{ github.event.pull_request.head.sha }}\n       pr_number: ${{ github.event.number }}\n       package: transformers\n-      languages: de en es fr hi it ko pt tr zh ja te\n+      languages: ar de en es fr hi it ko pt tr zh ja te\n       custom_container: huggingface/transformers-doc-builder"
        },
        {
            "sha": "f49e4e4731965a504b8da443c2cd979638cd22bb",
            "filename": "docs/source/ar/_config.py",
            "status": "added",
            "additions": 14,
            "deletions": 0,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2F_config.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2F_config.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2F_config.py?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,14 @@\n+# docstyle-ignore\n+INSTALL_CONTENT = \"\"\"\n+# Transformers installation\n+! pip install transformers datasets evaluate accelerate\n+# To install from source instead of the last release, comment the command above and uncomment the following one.\n+# ! pip install git+https://github.com/huggingface/transformers.git\n+\"\"\"\n+\n+notebook_first_cells = [{\"type\": \"code\", \"content\": INSTALL_CONTENT}]\n+black_avoid_patterns = {\n+    \"{processor_class}\": \"FakeProcessorClass\",\n+    \"{model_class}\": \"FakeModelClass\",\n+    \"{object_class}\": \"FakeObjectClass\",\n+}"
        },
        {
            "sha": "39e0ae14e19c2946a9e89a3a71bfdfa1d24d52f3",
            "filename": "docs/source/ar/_toctree.yml",
            "status": "added",
            "additions": 892,
            "deletions": 0,
            "changes": 892,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2F_toctree.yml?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,892 @@\n+- sections:\n+  - local: index\n+    title: ğŸ¤— Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª\n+  - local: quicktour\n+    title: Ø¬ÙˆÙ„Ø© Ø³Ø±ÙŠØ¹Ø©\n+  - local: installation\n+    title: Ø§Ù„ØªØ«Ø¨ÙŠØª\n+  title: Ø§Ù„Ø¨Ø¯Ø¡\n+- sections:\n+  - local: pipeline_tutorial\n+    title: ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨\n+  - local: autoclass_tutorial\n+    title: ÙƒØªØ§Ø¨Ø© ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø¨Ø±Ù…Ø¬ÙŠØ© Ù…ØªÙƒÙŠÙÙ‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AutoClass\n+  - local: preprocessing\n+    title: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø³Ø¨Ù‚Ù‹Ø§\n+  - local: training\n+    title: Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù…Ø³Ø¨Ù‚ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n+  - local: run_scripts\n+    title: Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠ\n+  - local: accelerate\n+    title: Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ¯Ø±ÙŠØ¨ Ù…ÙˆØ²Ø¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ğŸ¤— Accelerate\n+  - local: peft\n+    title: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø®ØµØµØ© ÙˆØªØ¯Ø±ÙŠØ¨Ù‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ğŸ¤— PEFT\n+  - local: model_sharing\n+    title: Ù…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬Ùƒ\n+  - local: agents\n+    title: Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡\n+  - local: llm_tutorial\n+    title: Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LLMs\n+  - local: conversations\n+    title: Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ù…Ø¹ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª\n+  title: Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©\n+# - sections:\n+#   - isExpanded: false\n+#     sections:\n+#     - local: tasks/sequence_classification\n+#       title: ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ\n+#     - local: tasks/token_classification\n+#       title: ØªØµÙ†ÙŠÙ Ø§Ù„Ø±Ù…ÙˆØ²\n+#     - local: tasks/question_answering\n+#       title: Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©\n+#     - local: tasks/language_modeling\n+#       title: Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø³Ø¨Ø¨ÙŠØ©\n+#     - local: tasks/masked_language_modeling\n+#       title: Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø©\n+#     - local: tasks/translation\n+#       title: Ø§Ù„ØªØ±Ø¬Ù…Ø©\n+#     - local: tasks/summarization\n+#       title: Ø§Ù„ØªÙ„Ø®ÙŠØµ\n+#     - local: tasks/multiple_choice\n+#       title: Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ØªØ¹Ø¯Ø¯\n+#     title: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©\n+#   - isExpanded: false\n+#     sections:\n+#     - local: tasks/audio_classification\n+#       title: ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØª\n+#     - local: tasks/asr\n+#       title: Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…\n+#     title: Ø§Ù„ØµÙˆØª\n+#   - isExpanded: false\n+#     sections:\n+#     - local: tasks/image_classification\n+#       title: ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ±\n+#     - local: tasks/semantic_segmentation\n+#       title: ØªØ¬Ø²Ø¦Ø© Ø§Ù„ØµÙˆØ±\n+#     - local: tasks/video_classification\n+#       title: ØªØµÙ†ÙŠÙ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ\n+#     - local: tasks/object_detection\n+#       title: Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø´ÙŠØ§Ø¡\n+#     - local: tasks/zero_shot_object_detection\n+#       title: Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ Ø¨Ø¯ÙˆÙ† ØªØ¯Ø±ÙŠØ¨\n+#     - local: tasks/zero_shot_image_classification\n+#       title: ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ± Ø¨Ø¯ÙˆÙ† ØªØ¯Ø±ÙŠØ¨\n+#     - local: tasks/monocular_depth_estimation\n+#       title: ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø¹Ù…Ù‚\n+#     - local: tasks/image_to_image\n+#       title: ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØµÙˆØ±Ø©\n+#     - local: tasks/image_feature_extraction\n+#       title: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙŠØ²Ø§Øª Ø§Ù„ØµÙˆØ±Ø©\n+#     - local: tasks/mask_generation\n+#       title: ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù‚Ù†Ø§Ø¹\n+#     - local: tasks/knowledge_distillation_for_image_classification\n+#       title: Ø§Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙÙŠ Ù„Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ÙŠØ©\n+#     title: Ø§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ÙŠØ©\n+#   - isExpanded: false\n+#     sections:\n+#     - local: tasks/image_captioning\n+#       title: ÙˆØµÙ Ø§Ù„ØµÙˆØ± Image captioning\n+#     - local: tasks/document_question_answering\n+#       title: Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª\n+#     - local: tasks/visual_question_answering\n+#       title: Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø±Ø¦ÙŠØ©\n+#     - local: tasks/text-to-speech\n+#       title: ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…\n+#     title: Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„ÙˆØ³Ø§Ø¦Ø·\n+#   - isExpanded: false\n+#     sections:\n+#     - local: generation_strategies\n+#       title: ØªØ®ØµÙŠØµ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„ØªÙˆÙ„ÙŠØ¯\n+#     - local: kv_cache\n+#       title: Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª Ù„Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª\n+#     title: Ø§Ù„ØªÙˆÙ„ÙŠØ¯\n+#   - isExpanded: false\n+#     sections:\n+#     - local: tasks/idefics\n+#       title: Ù…Ù‡Ø§Ù… Ø§Ù„ØµÙˆØ± Ù…Ø¹ IDEFICS\n+#     - local: tasks/prompting\n+#       title: Ø¯Ù„ÙŠÙ„ Ø¥Ø±Ø´Ø§Ø¯ÙŠ Ù„Ù…Ø­ÙØ²Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠØ© Ø§Ù„ÙƒØ¨ÙŠØ±Ø©\n+#     title: Ø§Ù„Ø¥Ø±Ø´Ø§Ø¯\n+#   title: Ø£Ø¯Ù„Ø© Ø§Ù„Ù…Ù‡Ø§Ù…\n+# - sections:\n+#   - local: fast_tokenizers\n+#     title: Ø§Ø³ØªØ®Ø¯Ù… Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø© Ù…Ù† ğŸ¤— Tokenizers\n+#   - local: multilingual\n+#     title: ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù„ØºØ§Øª\n+#   - local: create_a_model\n+#     title: Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ§Ø¬Ù‡Ø§Øª Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n+#   - local: custom_models\n+#     title: Ù…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬ Ù…Ø®ØµØµ\n+#   - local: chat_templating\n+#     title: Ù‚ÙˆØ§Ù„Ø¨ Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©\n+#   - local: trainer\n+#     title: Ø§Ù„Ù…Ø¯Ø±Ø¨\n+#   - local: sagemaker\n+#     title: ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Amazon SageMaker\n+#   - local: serialization\n+#     title: Ø§Ù„ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ ONNX\n+#   - local: tflite\n+#     title: Ø§Ù„ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ TFLite\n+#   - local: torchscript\n+#     title: Ø§Ù„ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ TorchScript\n+#   - local: benchmarks\n+#     title: Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±\n+#   - local: notebooks\n+#     title: Ø¯ÙØ§ØªØ± Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ø¹ Ø§Ù„Ø£Ù…Ø«Ù„Ø©\n+#   - local: community\n+#     title: Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹\n+#   - local: troubleshooting\n+#     title: Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ¥ØµÙ„Ø§Ø­Ù‡Ø§\n+#   - local: gguf\n+#     title: Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ù…Ù„ÙØ§Øª GGUF\n+#   title: Ø£Ø¯Ù„Ø© Ø§Ù„Ù…Ø·ÙˆØ±ÙŠÙ†\n+# - sections:\n+#   - local: quantization/overview\n+#     title: Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©\n+#   - local: quantization/bitsandbytes\n+#     title: bitsandbytes\n+#   - local: quantization/gptq\n+#     title: GPTQ\n+#   - local: quantization/awq\n+#     title: AWQ\n+#   - local: quantization/aqlm\n+#     title: AQLM\n+#   - local: quantization/quanto\n+#     title: Quanto\n+#   - local: quantization/eetq\n+#     title: EETQ\n+#   - local: quantization/hqq\n+#     title: HQQ\n+#   - local: quantization/optimum\n+#     title: Optimum\n+#   - local: quantization/contribute\n+#     title: Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„ØªÙƒÙ…ÙŠÙ…\n+#   title: Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„ØªÙƒÙ…ÙŠÙ…\n+# - sections:\n+#   - local: performance\n+#     title: Ø§Ù„Ø£Ø¯Ø§Ø¡-Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©\n+#   - local: llm_optims\n+#     title: ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ LLM\n+#   - sections:\n+#     - local: perf_train_gpu_one\n+#       title: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ø¯Ø© ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³ÙˆÙ…ÙŠØ§Øª (GPUs) Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²Ù\n+#     - local: perf_train_gpu_many\n+#       title: ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU) Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆØ§Ù„ØªÙˆØ§Ø²ÙŠ\n+#     - local: fsdp\n+#       title: Fully Sharded Data Parallel\n+#     - local: deepspeed\n+#       title: DeepSpeed\n+#     - local: perf_train_cpu\n+#       title: Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙØ¹Ø§Ù„ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© (CPU)\n+#     - local: perf_train_cpu_many\n+#       title: Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ²Ø¹ Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© (CPU)\n+#     - local: perf_train_tpu_tf\n+#       title: Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ (TPU) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… TensorFlow\n+#     - local: perf_train_special\n+#       title: ØªØ¯Ø±ÙŠØ¨ PyTorch Ø¹Ù„Ù‰ Apple silicon\n+#     - local: perf_hardware\n+#       title: Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù…Ø®ØµØµØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨\n+#     - local: hpo_train\n+#       title: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø«Ù„Ù‰ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø¯Ø±Ø¨\n+#     title: ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙØ¹Ø§Ù„\n+#   - sections:\n+#     - local: perf_infer_cpu\n+#       title: Ø§Ù„Ø¥Ø³ØªØ¯Ù„Ø§Ù„ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© (CPU)\n+#     - local: perf_infer_gpu_one\n+#       title: Ø§Ù„Ø¥Ø³ØªØ¯Ù„Ø§Ù„ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU)\n+#     title: ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„\n+#   - local: big_models\n+#     title: Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ ÙƒØ¨ÙŠØ±\n+#   - local: debugging\n+#     title: ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©\n+#   - local: tf_xla\n+#     title: ØªÙƒØ§Ù…Ù„ XLA Ù„Ù†Ù…Ø§Ø°Ø¬ TensorFlow\n+#   - local: perf_torch_compile\n+#     title: ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `torch.compile()`\n+#   title: Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆÙ‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„ØªÙˆØ³Ø¹\n+# - sections:\n+#   - local: contributing\n+#     title: ÙƒÙŠÙÙŠØ© Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø© ÙÙŠ ğŸ¤— Ø§Ù„Ù…Ø­ÙˆÙ„Ø§ØªØŸ\n+#   - local: add_new_model\n+#     title: ÙƒÙŠÙÙŠØ© Ø¥Ø¶Ø§ÙØ© Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ ğŸ¤— Ø§Ù„Ù…Ø­ÙˆÙ„Ø§ØªØŸ\n+#   - local: add_new_pipeline\n+#     title: ÙƒÙŠÙÙŠØ© Ø¥Ø¶Ø§ÙØ© Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø¥Ù„Ù‰ ğŸ¤— Ø§Ù„Ù…Ø­ÙˆÙ„Ø§ØªØŸ\n+#   - local: testing\n+#     title: Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±\n+#   - local: pr_checks\n+#     title: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø·Ù„Ø¨ Ø§Ù„Ø³Ø­Ø¨\n+#   title: Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø©\n+- sections:\n+  # - local: philosophy\n+  #   title: Ø§Ù„ÙÙ„Ø³ÙØ©\n+  - local: glossary\n+    title: (Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª (Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª\n+  # - local: task_summary\n+  #   title: Ù…Ø§ Ø§Ù„Ø°ÙŠ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙØ¹Ù„Ù‡ ğŸ¤— Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª\n+  # - local: tasks_explained\n+  #   title: ÙƒÙŠÙ ØªØ­Ù„ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª Ø§Ù„Ù…Ù‡Ø§Ù…\n+  # - local: model_summary\n+  #   title: Ø¹Ø§Ø¦Ù„Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­ÙˆÙ„\n+  # - local: tokenizer_summary\n+  #   title: Ù…Ù„Ø®Øµ Ø¨Ø±Ù†Ø§Ù…Ø¬ Ù…Ù‚Ø³Ù… Ø§Ù„Ù†ØµÙˆØµ (tokenizers)\n+  # - local: attention\n+  #   title: Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Attention\n+  # - local: pad_truncation\n+  #   title: Ø§Ù„Ø­Ø´Ùˆ ÙˆØ§Ù„ØªÙ‚Ù„ÙŠÙ…\n+  # - local: bertology\n+  #   title: BERTology\n+  # - local: perplexity\n+  #   title: Ø­ÙŠØ±Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø°Ø§Øª Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø«Ø§Ø¨Øª\n+  # - local: pipeline_webserver\n+  #   title: Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¹Ù„Ù‰ Ø®Ø§Ø¯Ù… Ø§Ù„ÙˆÙŠØ¨\n+  # - local: model_memory_anatomy\n+  #   title: ØªØ´Ø±ÙŠØ­ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n+  # - local: llm_tutorial_optimization\n+  #   title: Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ø§Ù„Ù‚ØµÙˆÙ‰ Ù…Ù† LLMs\n+  title: Ø£Ø·Ø± Ù…ÙØ§Ù‡ÙŠÙ…ÙŠØ©\n+# - sections:\n+#   - sections:\n+#     - local: main_classes/agent\n+#       title: Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª\n+#     - local: model_doc/auto\n+#       title: ÙØ¦Ø§Øª ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠÙ‹Ø§\n+#     - local: main_classes/backbones\n+#       title: Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙÙ‚Ø±ÙŠ\n+#     - local: main_classes/callback\n+#       title: Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹\n+#     - local: main_classes/configuration\n+#       title: Ø§Ù„ØªÙƒÙˆÙŠÙ†\n+#     - local: main_classes/data_collator\n+#       title: Ù…Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n+#     - local: main_classes/keras_callbacks\n+#       title: Ø§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª Keras\n+#     - local: main_classes/logging\n+#       title: Ø§Ù„ØªØ³Ø¬ÙŠÙ„\n+#     - local: main_classes/model\n+#       title: Ø§Ù„Ù†Ù…Ø§Ø°Ø¬\n+#     - local: main_classes/text_generation\n+#       title: ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ\n+#     - local: main_classes/onnx\n+#       title: ONNX\n+#     - local: main_classes/optimizer_schedules\n+#       title: Ø§Ù„ØªØ­Ø³ÙŠÙ†\n+#     - local: main_classes/output\n+#       title: Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n+#     - local: main_classes/pipelines\n+#       title: Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨\n+#     - local: main_classes/processors\n+#       title: Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª\n+#     - local: main_classes/quantization\n+#       title: Ø§Ù„ØªÙƒÙ…ÙŠÙ…\n+#     - local: main_classes/tokenizer\n+#       title: Ø¨Ø±Ù†Ø§Ù…Ø¬ Ù…Ù‚Ø³Ù… Ø§Ù„Ù†ØµÙˆØµ\n+#     - local: main_classes/trainer\n+#       title: Ø§Ù„Ù…Ø¯Ø±Ø¨\n+#     - local: main_classes/deepspeed\n+#       title: DeepSpeed\n+#     - local: main_classes/feature_extractor\n+#       title: Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª\n+#     - local: main_classes/image_processor\n+#       title: Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ±\n+#     title: Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\n+#   - sections:\n+#     - isExpanded: false\n+#       sections:\n+#       - local: model_doc/albert\n+#         title: ALBERT\n+#       - local: model_doc/bart\n+#         title: BART\n+#       - local: model_doc/barthez\n+#         title: BARThez\n+#       - local: model_doc/bartpho\n+#         title: BARTpho\n+#       - local: model_doc/bert\n+#         title: BERT\n+#       - local: model_doc/bert-generation\n+#         title: BertGeneration\n+#       - local: model_doc/bert-japanese\n+#         title: BertJapanese\n+#       - local: model_doc/bertweet\n+#         title: Bertweet\n+#       - local: model_doc/big_bird\n+#         title: BigBird\n+#       - local: model_doc/bigbird_pegasus\n+#         title: BigBirdPegasus\n+#       - local: model_doc/biogpt\n+#         title: BioGpt\n+#       - local: model_doc/blenderbot\n+#         title: Blenderbot\n+#       - local: model_doc/blenderbot-small\n+#         title: Blenderbot Small\n+#       - local: model_doc/bloom\n+#         title: BLOOM\n+#       - local: model_doc/bort\n+#         title: BORT\n+#       - local: model_doc/byt5\n+#         title: ByT5\n+#       - local: model_doc/camembert\n+#         title: CamemBERT\n+#       - local: model_doc/canine\n+#         title: CANINE\n+#       - local: model_doc/codegen\n+#         title: CodeGen\n+#       - local: model_doc/code_llama\n+#         title: CodeLlama\n+#       - local: model_doc/cohere\n+#         title: Cohere\n+#       - local: model_doc/convbert\n+#         title: ConvBERT\n+#       - local: model_doc/cpm\n+#         title: CPM\n+#       - local: model_doc/cpmant\n+#         title: CPMANT\n+#       - local: model_doc/ctrl\n+#         title: CTRL\n+#       - local: model_doc/dbrx\n+#         title: DBRX\n+#       - local: model_doc/deberta\n+#         title: DeBERTa\n+#       - local: model_doc/deberta-v2\n+#         title: DeBERTa-v2\n+#       - local: model_doc/dialogpt\n+#         title: DialoGPT\n+#       - local: model_doc/distilbert\n+#         title: DistilBERT\n+#       - local: model_doc/dpr\n+#         title: DPR\n+#       - local: model_doc/electra\n+#         title: ELECTRA\n+#       - local: model_doc/encoder-decoder\n+#         title: Encoder Decoder Models\n+#       - local: model_doc/ernie\n+#         title: ERNIE\n+#       - local: model_doc/ernie_m\n+#         title: ErnieM\n+#       - local: model_doc/esm\n+#         title: ESM\n+#       - local: model_doc/falcon\n+#         title: Falcon\n+#       - local: model_doc/fastspeech2_conformer\n+#         title: FastSpeech2Conformer\n+#       - local: model_doc/flan-t5\n+#         title: FLAN-T5\n+#       - local: model_doc/flan-ul2\n+#         title: FLAN-UL2\n+#       - local: model_doc/flaubert\n+#         title: FlauBERT\n+#       - local: model_doc/fnet\n+#         title: FNet\n+#       - local: model_doc/fsmt\n+#         title: FSMT\n+#       - local: model_doc/funnel\n+#         title: Funnel Transformer\n+#       - local: model_doc/fuyu\n+#         title: Fuyu\n+#       - local: model_doc/gemma\n+#         title: Gemma\n+#       - local: model_doc/openai-gpt\n+#         title: GPT\n+#       - local: model_doc/gpt_neo\n+#         title: GPT Neo\n+#       - local: model_doc/gpt_neox\n+#         title: GPT NeoX\n+#       - local: model_doc/gpt_neox_japanese\n+#         title: GPT NeoX Japanese\n+#       - local: model_doc/gptj\n+#         title: GPT-J\n+#       - local: model_doc/gpt2\n+#         title: GPT2\n+#       - local: model_doc/gpt_bigcode\n+#         title: GPTBigCode\n+#       - local: model_doc/gptsan-japanese\n+#         title: GPTSAN Japanese\n+#       - local: model_doc/gpt-sw3\n+#         title: GPTSw3\n+#       - local: model_doc/herbert\n+#         title: HerBERT\n+#       - local: model_doc/ibert\n+#         title: I-BERT\n+#       - local: model_doc/jamba\n+#         title: Jamba\n+#       - local: model_doc/jetmoe\n+#         title: JetMoe\n+#       - local: model_doc/jukebox\n+#         title: Jukebox\n+#       - local: model_doc/led\n+#         title: LED\n+#       - local: model_doc/llama\n+#         title: LLaMA\n+#       - local: model_doc/llama2\n+#         title: Llama2\n+#       - local: model_doc/llama3\n+#         title: Llama3\n+#       - local: model_doc/longformer\n+#         title: Longformer\n+#       - local: model_doc/longt5\n+#         title: LongT5\n+#       - local: model_doc/luke\n+#         title: LUKE\n+#       - local: model_doc/m2m_100\n+#         title: M2M100\n+#       - local: model_doc/madlad-400\n+#         title: MADLAD-400\n+#       - local: model_doc/mamba\n+#         title: Mamba\n+#       - local: model_doc/marian\n+#         title: MarianMT\n+#       - local: model_doc/markuplm\n+#         title: MarkupLM\n+#       - local: model_doc/mbart\n+#         title: MBart and MBart-50\n+#       - local: model_doc/mega\n+#         title: MEGA\n+#       - local: model_doc/megatron-bert\n+#         title: MegatronBERT\n+#       - local: model_doc/megatron_gpt2\n+#         title: MegatronGPT2\n+#       - local: model_doc/mistral\n+#         title: Mistral\n+#       - local: model_doc/mixtral\n+#         title: Mixtral\n+#       - local: model_doc/mluke\n+#         title: mLUKE\n+#       - local: model_doc/mobilebert\n+#         title: MobileBERT\n+#       - local: model_doc/mpnet\n+#         title: MPNet\n+#       - local: model_doc/mpt\n+#         title: MPT\n+#       - local: model_doc/mra\n+#         title: MRA\n+#       - local: model_doc/mt5\n+#         title: MT5\n+#       - local: model_doc/mvp\n+#         title: MVP\n+#       - local: model_doc/nezha\n+#         title: NEZHA\n+#       - local: model_doc/nllb\n+#         title: NLLB\n+#       - local: model_doc/nllb-moe\n+#         title: NLLB-MoE\n+#       - local: model_doc/nystromformer\n+#         title: NystrÃ¶mformer\n+#       - local: model_doc/olmo\n+#         title: OLMo\n+#       - local: model_doc/open-llama\n+#         title: Open-Llama\n+#       - local: model_doc/opt\n+#         title: OPT\n+#       - local: model_doc/pegasus\n+#         title: Pegasus\n+#       - local: model_doc/pegasus_x\n+#         title: PEGASUS-X\n+#       - local: model_doc/persimmon\n+#         title: Persimmon\n+#       - local: model_doc/phi\n+#         title: Phi\n+#       - local: model_doc/phi3\n+#         title: Phi-3\n+#       - local: model_doc/phobert\n+#         title: PhoBERT\n+#       - local: model_doc/plbart\n+#         title: PLBart\n+#       - local: model_doc/prophetnet\n+#         title: ProphetNet\n+#       - local: model_doc/qdqbert\n+#         title: QDQBert\n+#       - local: model_doc/qwen2\n+#         title: Qwen2\n+#       - local: model_doc/qwen2_moe\n+#         title: Qwen2MoE\n+#       - local: model_doc/rag\n+#         title: RAG\n+#       - local: model_doc/realm\n+#         title: REALM\n+#       - local: model_doc/recurrent_gemma\n+#         title: RecurrentGemma\n+#       - local: model_doc/reformer\n+#         title: Reformer\n+#       - local: model_doc/rembert\n+#         title: RemBERT\n+#       - local: model_doc/retribert\n+#         title: RetriBERT\n+#       - local: model_doc/roberta\n+#         title: RoBERTa\n+#       - local: model_doc/roberta-prelayernorm\n+#         title: RoBERTa-PreLayerNorm\n+#       - local: model_doc/roc_bert\n+#         title: RoCBert\n+#       - local: model_doc/roformer\n+#         title: RoFormer\n+#       - local: model_doc/rwkv\n+#         title: RWKV\n+#       - local: model_doc/splinter\n+#         title: Splinter\n+#       - local: model_doc/squeezebert\n+#         title: SqueezeBERT\n+#       - local: model_doc/stablelm\n+#         title: StableLm\n+#       - local: model_doc/starcoder2\n+#         title: Starcoder2\n+#       - local: model_doc/switch_transformers\n+#         title: SwitchTransformers\n+#       - local: model_doc/t5\n+#         title: T5\n+#       - local: model_doc/t5v1.1\n+#         title: T5v1.1\n+#       - local: model_doc/tapex\n+#         title: TAPEX\n+#       - local: model_doc/transfo-xl\n+#         title: Transformer XL\n+#       - local: model_doc/ul2\n+#         title: UL2\n+#       - local: model_doc/umt5\n+#         title: UMT5\n+#       - local: model_doc/xmod\n+#         title: X-MOD\n+#       - local: model_doc/xglm\n+#         title: XGLM\n+#       - local: model_doc/xlm\n+#         title: XLM\n+#       - local: model_doc/xlm-prophetnet\n+#         title: XLM-ProphetNet\n+#       - local: model_doc/xlm-roberta\n+#         title: XLM-RoBERTa\n+#       - local: model_doc/xlm-roberta-xl\n+#         title: XLM-RoBERTa-XL\n+#       - local: model_doc/xlm-v\n+#         title: XLM-V\n+#       - local: model_doc/xlnet\n+#         title: XLNet\n+#       - local: model_doc/yoso\n+#         title: YOSO\n+#       title: Text models\n+#     - isExpanded: false\n+#       sections:\n+#       - local: model_doc/beit\n+#         title: BEiT\n+#       - local: model_doc/bit\n+#         title: BiT\n+#       - local: model_doc/conditional_detr\n+#         title: Conditional DETR\n+#       - local: model_doc/convnext\n+#         title: ConvNeXT\n+#       - local: model_doc/convnextv2\n+#         title: ConvNeXTV2\n+#       - local: model_doc/cvt\n+#         title: CVT\n+#       - local: model_doc/deformable_detr\n+#         title: Deformable DETR\n+#       - local: model_doc/deit\n+#         title: DeiT\n+#       - local: model_doc/depth_anything\n+#         title: Depth Anything\n+#       - local: model_doc/deta\n+#         title: DETA\n+#       - local: model_doc/detr\n+#         title: DETR\n+#       - local: model_doc/dinat\n+#         title: DiNAT\n+#       - local: model_doc/dinov2\n+#         title: DINOV2\n+#       - local: model_doc/dit\n+#         title: DiT\n+#       - local: model_doc/dpt\n+#         title: DPT\n+#       - local: model_doc/efficientformer\n+#         title: EfficientFormer\n+#       - local: model_doc/efficientnet\n+#         title: EfficientNet\n+#       - local: model_doc/focalnet\n+#         title: FocalNet\n+#       - local: model_doc/glpn\n+#         title: GLPN\n+#       - local: model_doc/imagegpt\n+#         title: ImageGPT\n+#       - local: model_doc/levit\n+#         title: LeViT\n+#       - local: model_doc/mask2former\n+#         title: Mask2Former\n+#       - local: model_doc/maskformer\n+#         title: MaskFormer\n+#       - local: model_doc/mobilenet_v1\n+#         title: MobileNetV1\n+#       - local: model_doc/mobilenet_v2\n+#         title: MobileNetV2\n+#       - local: model_doc/mobilevit\n+#         title: MobileViT\n+#       - local: model_doc/mobilevitv2\n+#         title: MobileViTV2\n+#       - local: model_doc/nat\n+#         title: NAT\n+#       - local: model_doc/poolformer\n+#         title: PoolFormer\n+#       - local: model_doc/pvt\n+#         title: Pyramid Vision Transformer (PVT)\n+#       - local: model_doc/pvt_v2\n+#         title: Pyramid Vision Transformer v2 (PVTv2)\n+#       - local: model_doc/regnet\n+#         title: RegNet\n+#       - local: model_doc/resnet\n+#         title: ResNet\n+#       - local: model_doc/segformer\n+#         title: SegFormer\n+#       - local: model_doc/seggpt\n+#         title: SegGpt\n+#       - local: model_doc/superpoint\n+#         title: SuperPoint\n+#       - local: model_doc/swiftformer\n+#         title: SwiftFormer\n+#       - local: model_doc/swin\n+#         title: Swin Transformer\n+#       - local: model_doc/swinv2\n+#         title: Swin Transformer V2\n+#       - local: model_doc/swin2sr\n+#         title: Swin2SR\n+#       - local: model_doc/table-transformer\n+#         title: Table Transformer\n+#       - local: model_doc/upernet\n+#         title: UperNet\n+#       - local: model_doc/van\n+#         title: VAN\n+#       - local: model_doc/vit\n+#         title: Vision Transformer (ViT)\n+#       - local: model_doc/vit_hybrid\n+#         title: ViT Hybrid\n+#       - local: model_doc/vitdet\n+#         title: ViTDet\n+#       - local: model_doc/vit_mae\n+#         title: ViTMAE\n+#       - local: model_doc/vitmatte\n+#         title: ViTMatte\n+#       - local: model_doc/vit_msn\n+#         title: ViTMSN\n+#       - local: model_doc/yolos\n+#         title: YOLOS\n+#       title: Vision models\n+#     - isExpanded: false\n+#       sections:\n+#       - local: model_doc/audio-spectrogram-transformer\n+#         title: Audio Spectrogram Transformer\n+#       - local: model_doc/bark\n+#         title: Bark\n+#       - local: model_doc/clap\n+#         title: CLAP\n+#       - local: model_doc/encodec\n+#         title: EnCodec\n+#       - local: model_doc/hubert\n+#         title: Hubert\n+#       - local: model_doc/mctct\n+#         title: MCTCT\n+#       - local: model_doc/mms\n+#         title: MMS\n+#       - local: model_doc/musicgen\n+#         title: MusicGen\n+#       - local: model_doc/musicgen_melody\n+#         title: MusicGen Melody\n+#       - local: model_doc/pop2piano\n+#         title: Pop2Piano\n+#       - local: model_doc/seamless_m4t\n+#         title: Seamless-M4T\n+#       - local: model_doc/seamless_m4t_v2\n+#         title: SeamlessM4T-v2\n+#       - local: model_doc/sew\n+#         title: SEW\n+#       - local: model_doc/sew-d\n+#         title: SEW-D\n+#       - local: model_doc/speech_to_text\n+#         title: Speech2Text\n+#       - local: model_doc/speech_to_text_2\n+#         title: Speech2Text2\n+#       - local: model_doc/speecht5\n+#         title: SpeechT5\n+#       - local: model_doc/unispeech\n+#         title: UniSpeech\n+#       - local: model_doc/unispeech-sat\n+#         title: UniSpeech-SAT\n+#       - local: model_doc/univnet\n+#         title: UnivNet\n+#       - local: model_doc/vits\n+#         title: VITS\n+#       - local: model_doc/wav2vec2\n+#         title: Wav2Vec2\n+#       - local: model_doc/wav2vec2-bert\n+#         title: Wav2Vec2-BERT\n+#       - local: model_doc/wav2vec2-conformer\n+#         title: Wav2Vec2-Conformer\n+#       - local: model_doc/wav2vec2_phoneme\n+#         title: Wav2Vec2Phoneme\n+#       - local: model_doc/wavlm\n+#         title: WavLM\n+#       - local: model_doc/whisper\n+#         title: Whisper\n+#       - local: model_doc/xls_r\n+#         title: XLS-R\n+#       - local: model_doc/xlsr_wav2vec2\n+#         title: XLSR-Wav2Vec2\n+#       title: Audio models\n+#     - isExpanded: false\n+#       sections:\n+#       - local: model_doc/timesformer\n+#         title: TimeSformer\n+#       - local: model_doc/videomae\n+#         title: VideoMAE\n+#       - local: model_doc/vivit\n+#         title: ViViT\n+#       title: Video models\n+#     - isExpanded: false\n+#       sections:\n+#       - local: model_doc/align\n+#         title: ALIGN\n+#       - local: model_doc/altclip\n+#         title: AltCLIP\n+#       - local: model_doc/blip\n+#         title: BLIP\n+#       - local: model_doc/blip-2\n+#         title: BLIP-2\n+#       - local: model_doc/bridgetower\n+#         title: BridgeTower\n+#       - local: model_doc/bros\n+#         title: BROS\n+#       - local: model_doc/chinese_clip\n+#         title: Chinese-CLIP\n+#       - local: model_doc/clip\n+#         title: CLIP\n+#       - local: model_doc/clipseg\n+#         title: CLIPSeg\n+#       - local: model_doc/clvp\n+#         title: CLVP\n+#       - local: model_doc/data2vec\n+#         title: Data2Vec\n+#       - local: model_doc/deplot\n+#         title: DePlot\n+#       - local: model_doc/donut\n+#         title: Donut\n+#       - local: model_doc/flava\n+#         title: FLAVA\n+#       - local: model_doc/git\n+#         title: GIT\n+#       - local: model_doc/grounding-dino\n+#         title: Grounding DINO\n+#       - local: model_doc/groupvit\n+#         title: GroupViT\n+#       - local: model_doc/idefics\n+#         title: IDEFICS\n+#       - local: model_doc/idefics2\n+#         title: Idefics2\n+#       - local: model_doc/instructblip\n+#         title: InstructBLIP\n+#       - local: model_doc/kosmos-2\n+#         title: KOSMOS-2\n+#       - local: model_doc/layoutlm\n+#         title: LayoutLM\n+#       - local: model_doc/layoutlmv2\n+#         title: LayoutLMV2\n+#       - local: model_doc/layoutlmv3\n+#         title: LayoutLMV3\n+#       - local: model_doc/layoutxlm\n+#         title: LayoutXLM\n+#       - local: model_doc/lilt\n+#         title: LiLT\n+#       - local: model_doc/llava\n+#         title: Llava\n+#       - local: model_doc/llava_next\n+#         title: LLaVA-NeXT\n+#       - local: model_doc/lxmert\n+#         title: LXMERT\n+#       - local: model_doc/matcha\n+#         title: MatCha\n+#       - local: model_doc/mgp-str\n+#         title: MGP-STR\n+#       - local: model_doc/nougat\n+#         title: Nougat\n+#       - local: model_doc/oneformer\n+#         title: OneFormer\n+#       - local: model_doc/owlvit\n+#         title: OWL-ViT\n+#       - local: model_doc/owlv2\n+#         title: OWLv2\n+#       - local: model_doc/paligemma\n+#         title: PaliGemma\n+#       - local: model_doc/perceiver\n+#         title: Perceiver\n+#       - local: model_doc/pix2struct\n+#         title: Pix2Struct\n+#       - local: model_doc/sam\n+#         title: Segment Anything\n+#       - local: model_doc/siglip\n+#         title: SigLIP\n+#       - local: model_doc/speech-encoder-decoder\n+#         title: Speech Encoder Decoder Models\n+#       - local: model_doc/tapas\n+#         title: TAPAS\n+#       - local: model_doc/trocr\n+#         title: TrOCR\n+#       - local: model_doc/tvlt\n+#         title: TVLT\n+#       - local: model_doc/tvp\n+#         title: TVP\n+#       - local: model_doc/udop\n+#         title: UDOP\n+#       - local: model_doc/video_llava\n+#         title: VideoLlava\n+#       - local: model_doc/vilt\n+#         title: ViLT\n+#       - local: model_doc/vipllava\n+#         title: VipLlava\n+#       - local: model_doc/vision-encoder-decoder\n+#         title: Vision Encoder Decoder Models\n+#       - local: model_doc/vision-text-dual-encoder\n+#         title: Vision Text Dual Encoder\n+#       - local: model_doc/visual_bert\n+#         title: VisualBERT\n+#       - local: model_doc/xclip\n+#         title: X-CLIP\n+#       title: Multimodal models\n+#     - isExpanded: false\n+#       sections:\n+#       - local: model_doc/decision_transformer\n+#         title: Ù…Ø­ÙˆÙ„ Ø§Ù„Ù‚Ø±Ø§Ø±\n+#       - local: model_doc/trajectory_transformer\n+#         title: Ù…Ø­ÙˆÙ„ Ø§Ù„Ù…Ø³Ø§Ø±\n+#       title: Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„ØªØ¹Ø²ÙŠØ²ÙŠØ©\n+#     - isExpanded: false\n+#       sections:\n+#       - local: model_doc/autoformer\n+#         title: Autoformer\n+#       - local: model_doc/informer\n+#         title: Informer\n+#       - local: model_doc/patchtsmixer\n+#         title: PatchTSMixer\n+#       - local: model_doc/patchtst\n+#         title: PatchTST\n+#       - local: model_doc/time_series_transformer\n+#         title: Ù…Ø­ÙˆÙ„ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ©\n+#       title: Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ©\n+#     - isExpanded: false\n+#       sections:\n+#       - local: model_doc/graphormer\n+#         title: Graphormer\n+#       title: Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ\n+#     title: Ø§Ù„Ù†Ù…Ø§Ø°Ø¬\n+#   - sections:\n+#     - local: internal/modeling_utils\n+#       title: Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù…Ø®ØµØµØ© ÙˆØ§Ù„Ù…Ø±Ø§ÙÙ‚\n+#     - local: internal/pipelines_utils\n+#       title: Ù…Ø±Ø§ÙÙ‚ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨\n+#     - local: internal/tokenization_utils\n+#       title: Ù…Ø±Ø§ÙÙ‚ Ù…Ù‚Ø³Ù… Ø§Ù„Ù†ØµÙˆØµ \n+#     - local: internal/trainer_utils\n+#       title: Ù…Ø±Ø§ÙÙ‚ Ø§Ù„Ù…Ø¯Ø±Ø¨\n+#     - local: internal/generation_utils\n+#       title: Ù…Ø±Ø§ÙÙ‚ Ø§Ù„ØªÙˆÙ„ÙŠØ¯\n+#     - local: internal/image_processing_utils\n+#       title: Ù…Ø±Ø§ÙÙ‚ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±\n+#     - local: internal/audio_utils\n+#       title: Ù…Ø±Ø§ÙÙ‚ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª\n+#     - local: internal/file_utils\n+#       title: Ù…Ø±Ø§ÙÙ‚ Ø¹Ø§Ù…Ø©\n+#     - local: internal/time_series_utils\n+#       title: Ù…Ø±Ø§ÙÙ‚ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ©\n+#     title: Ù…Ø³Ø§Ø¹Ø¯ÙˆÙ† Ø¯Ø§Ø®Ù„ÙŠÙˆÙ†\n+#   title: API"
        },
        {
            "sha": "486c1efe59af60c0cf524d9493f3d5ba34058b2a",
            "filename": "docs/source/ar/accelerate.md",
            "status": "added",
            "additions": 120,
            "deletions": 0,
            "changes": 120,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Faccelerate.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Faccelerate.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Faccelerate.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,120 @@\n+# Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ²Ø¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…  ğŸ¤— Accelerate\n+\n+\n+Ù…Ø¹ ØªØ²Ø§ÙŠØ¯ Ø­Ø¬Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠØ©ØŒ Ø¨Ø±Ø² Ø§Ù„ØªÙˆØ§Ø²ÙŠ ÙƒØ£Ø­Ø¯ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ Ø£ÙƒØ¨Ø± Ø¹Ù„Ù‰ Ø£Ø¬Ù‡Ø²Ø© Ù…Ø­Ø¯ÙˆØ¯Ø© ÙˆØªØ³Ø±ÙŠØ¹ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù…Ù‚Ø¯Ø§Ø± ÙƒØ¨ÙŠØ±.  Ø£Ù†Ø´Ø£Ù†Ø§ ÙÙŠ Hugging FaceØŒ Ù‚Ù…Ù†Ø§ Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙƒØªØ¨Ø© [ Accelerate](https://huggingface.co/docs/accelerate) Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¹Ù„Ù‰ ØªØ¯Ø±ÙŠØ¨ Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†  Transformers Ø¨Ø³Ù‡ÙˆÙ„Ø© Ø¹Ù„Ù‰ Ø£ÙŠ Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙˆØ²Ø¹Ø©ØŒ Ø³ÙˆØ§Ø¡ ÙƒØ§Ù† Ø°Ù„Ùƒ Ø¹Ù„Ù‰ Ø¹Ø¯Ø© ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³ÙˆÙ…Ø§Øª (GPUs) Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø² ÙˆØ§Ø­Ø¯ Ø£Ùˆ Ø¹Ù„Ù‰ Ø¹Ø¯Ø© ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³ÙˆÙ…Ø§Øª Ù…ÙˆØ²Ø¹Ø© Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ø£Ø¬Ù‡Ø²Ø©. ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ØŒ ØªØ¹Ù„Ù… ÙƒÙŠÙÙŠØ© ØªØ®ØµÙŠØµ Ø­Ù„Ù‚Ø© ØªØ¯Ø±ÙŠØ¨ PyTorch Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„ØªÙ…ÙƒÙŠÙ† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙŠ Ø¨ÙŠØ¦Ø© Ù…ÙˆØ²Ø¹Ø©.\n+\n+## Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯\n+\n+Ø§Ø¨Ø¯Ø£ Ø¨ØªØ«Ø¨ÙŠØª ğŸ¤— Accelerate:\n+\n+```bash\n+pip install accelerate\n+```\n+\n+Ø«Ù… Ù‚Ù… Ø¨Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙˆØ¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù† [`~accelerate.Accelerator`]. Ø³ÙŠÙ‚ÙˆÙ… [`~accelerate.Accelerator`] ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¨Ø§ÙƒØªØ´Ø§Ù Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙˆØ²Ø¹ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ ÙˆØªÙ‡ÙŠØ¦Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨. Ù„Ù† ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ÙˆØ¶Ø¹ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø² Ø¨Ø´ÙƒÙ„ Ù…Ø¹ÙŠÙ†.\n+\n+```py\n+>>> from accelerate import Accelerator\n+\n+>>> accelerator = Accelerator()\n+```\n+\n+## Ø§Ù„Ø§Ø³ØªØ¹Ø¯Ø§Ø¯ Ù„Ù„ØªØ³Ø±ÙŠØ¹\n+\n+Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù‡ÙŠ ØªÙ…Ø±ÙŠØ± Ø¬Ù…ÙŠØ¹ ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© Ø¥Ù„Ù‰ Ø¯Ø§Ù„Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ [`~accelerate.Accelerator.prepare`]. ÙˆÙŠØ´Ù…Ù„ Ø°Ù„Ùƒ DataLoaders Ù„Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…ØŒ ÙˆÙ†Ù…ÙˆØ°Ø¬Ù‹Ø§ ÙˆÙ…ÙØ­ÙØ³ÙÙ‘Ù†Ù‹ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª (optimizer):\n+\n+```py\n+>>> train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(\n+...     train_dataloader, eval_dataloader, model, optimizer\n+... )\n+```\n+\n+## Ø§Ù„Ø®Ù„ÙÙŠ Backward\n+\n+Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù‡ÙŠ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø¹ØªØ§Ø¯Ø© `loss.backward()` ÙÙŠ Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø¨Ø¯Ø§Ù„Ø© [`~accelerate.Accelerator.backward`] ÙÙŠ ğŸ¤— Accelerate:\n+\n+```py\n+>>> for epoch in range(num_epochs):\n+...     for batch in train_dataloader:\n+...         outputs = model(**batch)\n+...         loss = outputs.loss\n+...         accelerator.backward(loss)\n+\n+...         optimizer.step()\n+...         lr_scheduler.step()\n+...         optimizer.zero_grad()\n+...         progress_bar.update(1)\n+```\n+\n+ÙƒÙ…Ø§ ÙŠÙ…ÙƒÙ†Ùƒ Ø£Ù† ØªØ±Ù‰ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ØªØ§Ù„ÙŠØŒ ÙØ£Ù†Øª Ø¨Ø­Ø§Ø¬Ø© ÙÙ‚Ø· Ø¥Ù„Ù‰ Ø¥Ø¶Ø§ÙØ© Ø£Ø±Ø¨Ø¹Ø© Ø£Ø³Ø·Ø± Ù…Ù† Ø§Ù„ÙƒÙˆØ¯ Ø¥Ù„Ù‰ Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ù„ØªÙ…ÙƒÙŠÙ† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ²Ø¹!\n+\n+```diff\n++ from accelerate import Accelerator\n+  from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler\n+\n++ accelerator = Accelerator()\n+\n+  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n+  optimizer = AdamW(model.parameters(), lr=3e-5)\n+\n+- device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n+- model.to(device)\n+\n++ train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(\n++     train_dataloader, eval_dataloader, model, optimizer\n++ )\n+\n+  num_epochs = 3\n+  num_training_steps = num_epochs * len(train_dataloader)\n+  lr_scheduler = get_scheduler(\n+      \"linear\",\n+      optimizer=optimizer,\n+      num_warmup_steps=0,\n+      num_training_steps=num_training_steps\n+  )\n+\n+  progress_bar = tqdm(range(num_training_steps))\n+\n+  model.train()\n+  for epoch in range(num_epochs):\n+      for batch in train_dataloader:\n+-         batch = {k: v.to(device) for k, v in batch.items()}\n+          outputs = model(**batch)\n+          loss = outputs.loss\n+-         loss.backward()\n++         accelerator.backward(loss)\n+optimizer.step()\n+          lr_scheduler.step()\n+          optimizer.zero_grad()\n+          progress_bar.update(1)\n+```\n+\n+## ØªØ¯Ø±ÙŠØ¨\n+\n+Ø¨Ù…Ø¬Ø±Ø¯ Ø¥Ø¶Ø§ÙØ© Ø£Ø³Ø·Ø± Ø§Ù„ÙƒÙˆØ¯ Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©ØŒ Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ ÙÙŠ Ø£Ø­Ø¯ Ø§Ù„Ù†ØµÙˆØµ Ø£Ùˆ Ø§Ù„Ø¯ÙØ§ØªØ± Ù…Ø«Ù„ Colaboratory.\n+\n+### Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠ\n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ´ØºÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ù…Ù† Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠØŒ ÙÙ‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ­ÙØ¸ Ù…Ù„Ù ØªÙƒÙˆÙŠÙ†:\n+\n+```bash\n+accelerate config\n+```\n+\n+Ø«Ù… Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…:\n+\n+```bash\n+accelerate launch train.py\n+```\n+\n+### Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯ÙØªØ± Ù…Ù„Ø§Ø­Ø¸Ø§Øª\n+\n+ÙŠÙ…ÙƒÙ† Ø£ÙŠØ¶Ù‹Ø§ ØªØ´ØºÙŠÙ„ ğŸ¤— Accelerate ÙÙŠ Ø¯ÙØ§ØªØ± Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ®Ø·Ø· Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…ÙŠØ§Øª (TPUs) ÙÙŠ Colaboratory. Ù‚Ù… Ø¨ØªØºÙ„ÙŠÙ ÙƒÙ„ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ Ø¹Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙŠ Ø¯Ø§Ù„Ø©ØŒ ÙˆÙ…Ø±Ø±Ù‡Ø§ Ø¥Ù„Ù‰ [`~accelerate.notebook_launcher`]:\n+\n+```py\n+>>> from accelerate import notebook_launcher\n+\n+>>> notebook_launcher(training_function)\n+```\n+\n+Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ ğŸ¤— Accelerate ÙˆÙ…ÙŠØ²Ø§ØªÙ‡ Ø§Ù„ØºÙ†ÙŠØ©ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø±Ø¬ÙˆØ¹ Ø¥Ù„Ù‰ [Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚](https://huggingface.co/docs/accelerate).\n\\ No newline at end of file"
        },
        {
            "sha": "92b2a4715f6f0781ef757d9659089a6a59eba98f",
            "filename": "docs/source/ar/agents.md",
            "status": "added",
            "additions": 539,
            "deletions": 0,
            "changes": 539,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fagents.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fagents.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fagents.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,539 @@\n+# Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª\n+\n+[[open-in-colab]]\n+\n+### Ù…Ø§ Ù‡Ùˆ Ø§Ù„ÙˆÙƒÙŠÙ„ØŸ\n+\n+ÙŠÙ…ÙƒÙ† Ù„Ù„Ù†Ø¸Ù… Ø§Ù„Ù„ØºÙˆÙŠØ© Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (LLMs) Ø§Ù„ØªÙŠ ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡Ø§ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ [Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø³Ø¨Ø¨ÙŠØ©](./tasks/language_modeling.) Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§Ø³Ø¹Ø© Ù…Ù† Ø§Ù„Ù…Ù‡Ø§Ù…ØŒ ÙˆÙ„ÙƒÙ†Ù‡Ø§ ØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ØªÙˆØ§Ø¬Ù‡ ØµØ¹ÙˆØ¨Ø§Øª ÙÙŠ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø«Ù„ Ø§Ù„Ù…Ù†Ø·Ù‚ ÙˆØ§Ù„Ø­Ø³Ø§Ø¨ ÙˆØ§Ù„Ø¨Ø­Ø«. ÙˆØ¹Ù†Ø¯Ù…Ø§ ÙŠØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡Ø§ ÙÙŠ Ù…Ø¬Ø§Ù„Ø§Øª Ù„Ø§ ØªØ¤Ø¯ÙŠ ÙÙŠÙ‡Ø§ Ø£Ø¯Ø§Ø¡Ù‹ Ø¬ÙŠØ¯Ù‹Ø§ØŒ ÙØ¥Ù†Ù‡Ø§ ØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ØªÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØªÙŠ Ù†ØªÙˆÙ‚Ø¹Ù‡Ø§ Ù…Ù†Ù‡Ø§.\n+\n+ÙŠØªÙ…Ø«Ù„ Ø£Ø­Ø¯ Ø§Ù„Ù†Ù‡Ø¬ Ù„Ù„ØªØºÙ„Ø¨ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ù‚ØµÙˆØ± ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ \"ÙˆÙƒÙŠÙ„\".\n+\n+Ø§Ù„ÙˆÙƒÙŠÙ„ Ù‡Ùˆ Ù†Ø¸Ø§Ù… ÙŠØ³ØªØ®Ø¯Ù… LLM ÙƒÙ…Ø­Ø±Ùƒ Ù„Ù‡ØŒ ÙˆÙ„Ø¯ÙŠÙ‡ Ø­Ù‚ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ ÙˆØ¸Ø§Ø¦Ù ØªØ³Ù…Ù‰ \"Ø£Ø¯ÙˆØ§Øª\".\n+\n+Ù‡Ø°Ù‡ \"Ø§Ù„Ø£Ø¯ÙˆØ§Øª\" Ù‡ÙŠ ÙˆØ¸Ø§Ø¦Ù Ù„Ø£Ø¯Ø§Ø¡ Ù…Ù‡Ù…Ø©ØŒ ÙˆØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£ÙˆØµØ§Ù Ø§Ù„Ù„Ø§Ø²Ù…Ø© Ù„Ù„ÙˆÙƒÙŠÙ„ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­.\n+\n+ÙŠÙ…ÙƒÙ† Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ Ù„Ù„Ù‚ÙŠØ§Ù… Ø¨Ù…Ø§ ÙŠÙ„ÙŠ:\n+- ÙˆØ¶Ø¹ Ø³Ù„Ø³Ù„Ø© Ù…Ù† Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª/Ø§Ù„Ø£Ø¯ÙˆØ§Øª ÙˆØªØ´ØºÙŠÙ„Ù‡Ø§ Ø¬Ù…ÙŠØ¹Ù‹Ø§ ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª Ù…Ø«Ù„ [`CodeAgent`] Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„\n+- Ø§Ù„ØªØ®Ø·ÙŠØ· Ù„Ù„Ø§Ø¬Ø±Ø§Ø¡Ø§Øª/Ø§Ù„Ø£Ø¯ÙˆØ§Øª ÙˆØªÙ†ÙÙŠØ°Ù‡Ø§ ÙˆØ§Ø­Ø¯Ø© ØªÙ„Ùˆ Ø§Ù„Ø£Ø®Ø±Ù‰ ÙˆØ§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø­ØªÙ‰ Ø§Ù†ØªÙ‡Ø§Ø¡ ÙƒÙ„ Ø¥Ø¬Ø±Ø§Ø¡ Ù‚Ø¨Ù„ Ø¥Ø·Ù„Ø§Ù‚ Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ø«Ù„ [`ReactJsonAgent`] Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„\n+\n+### Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡\n+\n+#### Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ (Code agent)\n+\n+ÙŠØªÙ…ØªØ¹ Ù‡Ø°Ø§ Ø§Ù„ÙˆÙƒÙŠÙ„ ÙŠØªØ¨Ø¹ Ø®Ø·ÙˆØ§Øª Ù…Ø­Ø¯Ø¯Ø©: Ø£ÙˆÙ„Ù‹Ø§ØŒ ÙŠØ®Ø·Ø· Ù„Ø³Ù„Ø³Ù„Ø© Ù…Ù† Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ØªÙŠ ÙŠØ±ÙŠØ¯ ØªÙ†ÙÙŠØ°Ù‡Ø§ØŒ Ø«Ù… Ø´ÙØ±Ø© Python Ù„ØªÙ†ÙÙŠØ° Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª. ÙˆÙ‡Ùˆ ÙŠØªØ¹Ø§Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø£ØµÙ„ÙŠ Ù…Ø¹ Ø£Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ÙˆØ§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ù„Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙŠ ÙŠØ³ØªØ®Ø¯Ù…Ù‡Ø§ØŒ ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠ ÙÙ‡Ùˆ Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡ Ù„Ù„Ù…Ù‡Ø§Ù… Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„ÙˆØ³Ø§Ø¦Ø·.\n+\n+#### ÙˆÙƒÙ„Ø§Ø¡ Ø§Ù„ØªÙØ§Ø¹Ù„\n+\n+Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙŠ ÙŠØªÙ… Ø§Ù„Ù„Ø¬ÙˆØ¡ Ø¥Ù„ÙŠÙ‡ Ù„Ø­Ù„ Ù…Ù‡Ø§Ù… Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ØŒ Ø­ÙŠØ« ÙŠØ¬Ø¹Ù„ Ø¥Ø·Ø§Ø± ReAct ([Yao et al.ØŒ 2022](https://huggingface.co/papers/2210.03629)) Ù…Ù† Ø§Ù„ÙƒÙØ§Ø¡Ø© Ø­Ù‚Ù‹Ø§ Ø§Ù„ØªÙÙƒÙŠØ± Ø¹Ù„Ù‰ Ø£Ø³Ø§Ø³ Ù…Ù„Ø§Ø­Ø¸Ø§ØªÙ‡ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©.\n+\n+Ù†Ù‚ÙˆÙ… Ø¨ØªÙ†ÙÙŠØ° Ø¥ØµØ¯Ø§Ø±ÙŠÙ† Ù…Ù† ReactJsonAgent: \n+- [`ReactJsonAgent`] ÙŠÙ‚ÙˆÙ… Ø¨ØªÙˆÙ„ÙŠØ¯ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª Ø§Ù„Ø£Ø¯ÙˆØ§Øª ÙƒÙ€ JSON ÙÙŠ Ø¥Ø®Ø±Ø§Ø¬Ù‡Ø§.\n+- [`ReactCodeAgent`] Ù‡Ùˆ Ù†ÙˆØ¹ Ø¬Ø¯ÙŠØ¯ Ù…Ù† ReactJsonAgent ÙŠÙ‚ÙˆÙ… Ø¨ØªÙˆÙ„ÙŠØ¯ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª Ø£Ø¯ÙˆØ§ØªÙ‡ ÙƒÙ…Ù‚Ø§Ø·Ø¹ Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©ØŒ ÙˆØ§Ù„ØªÙŠ ØªØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯ Ø­Ù‚Ù‹Ø§ Ù…Ø¹ LLMs Ø§Ù„ØªÙŠ ØªØªÙ…ØªØ¹ Ø¨Ø£Ø¯Ø§Ø¡  Ù‚ÙˆÙŠ ÙÙŠ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©.\n+\n+> [!TIP]\n+> Ø§Ù‚Ø±Ø£ Ù…Ù†Ø´ÙˆØ± Ø§Ù„Ù…Ø¯ÙˆÙ†Ø© [Open-source LLMs as LangChain Agents](https://huggingface.co/blog/open-source-llms-as-agents) Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ø¹Ù† ÙˆÙƒÙŠÙ„ ReAct.\n+\n+![Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ ÙˆÙƒÙŠÙ„ ReAct](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/open-source-llms-as-agents/ReAct.png)\n+\n+Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¥Ù„ÙŠÙƒ ÙƒÙŠÙ ÙŠØ¹Ù…Ù„ ÙˆÙƒÙŠÙ„ ReAct Code Ø·Ø±ÙŠÙ‚Ù‡ Ù…Ù† Ø®Ù„Ø§Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ.\n+\n+```py3\n+>>> agent.run(\n+...     \"How many more blocks (also denoted as layers) in BERT base encoder than the encoder from the architecture proposed in Attention is All You Need?\",\n+... )\n+=====New task=====\n+How many more blocks (also denoted as layers) in BERT base encoder than the encoder from the architecture proposed in Attention is All You Need?\n+====Agent is executing the code below:\n+bert_blocks = search(query=\"number of blocks in BERT base encoder\")\n+print(\"BERT blocks:\", bert_blocks)\n+====\n+Print outputs:\n+BERT blocks: twelve encoder blocks\n+\n+====Agent is executing the code below:\n+attention_layer = search(query=\"number of layers in Attention is All You Need\")\n+print(\"Attention layers:\", attention_layer)\n+====\n+Print outputs:\n+Attention layers: Encoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position- 2 Page 3 Figure 1: The Transformer - model architecture.\n+\n+====Agent is executing the code below:\n+bert_blocks = 12\n+attention_layers = 6\n+diff = bert_blocks - attention_layers\n+print(\"Difference in blocks:\", diff)\n+final_answer(diff)\n+====\n+\n+Print outputs:\n+Difference in blocks: 6\n+\n+Final answer: 6\n+```\n+\n+### ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø¨Ù†Ø§Ø¡ ÙˆÙƒÙŠÙ„ØŸ\n+\n+Ù„ØªÙ‡ÙŠØ¦Ø© ÙˆÙƒÙŠÙ„ØŒ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ³Ø§Ø¦Ø·:\n+\n+- Ù†Ù…ÙˆØ°Ø¬ Ù„ØºÙˆÙŠ ÙƒØ¨ÙŠØ± (LLM) ÙŠØ´ÙƒÙ„ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„ÙˆÙƒÙŠÙ„. Ø§Ù„ÙˆÙƒÙŠÙ„ Ù†ÙØ³Ù‡ Ù„ÙŠØ³ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠØŒ Ø¨Ù„ Ù‡Ùˆ Ø¨Ø±Ù†Ø§Ù…Ø¬ ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ ÙƒÙ…Ø­Ø±Ùƒ Ù„Ù‡.\n+- Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù†Ø¸Ø§Ù… (system prompt): Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªÙŠ ÙŠØªÙ… Ø¥Ø¹Ø·Ø§Ø¤Ù‡Ø§ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø±Ø¬Ø§ØªÙ‡.\n+- ØµÙ†Ø¯ÙˆÙ‚ Ø£Ø¯ÙˆØ§Øª (toolbox) ÙŠØ®ØªØ§Ø± Ø§Ù„ÙˆÙƒÙŠÙ„ Ù…Ù†Ù‡ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ù„ØªÙ†ÙÙŠØ°Ù‡Ø§\n+- Ù…Ø­Ù„Ù„ (parser) Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡Ø§ Ù…Ù† Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ LLM ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§\n+\n+Ø¹Ù†Ø¯ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„ÙˆÙƒÙŠÙ„ØŒ ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø³Ù…Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø© Ù„Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ù„Ù„Ø£Ø¯Ø§Ø©ØŒ Ø«Ù… ÙŠØªÙ… Ø¯Ù…Ø¬Ù‡Ø§ ÙÙŠ Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø§Øµ `system_prompt` Ù„Ù„ÙˆÙƒÙŠÙ„ Ù„Ø¥Ø¹Ù„Ø§Ù…Ù‡ Ø¨Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ†Ù‡ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙˆÙ„Ù…Ø§Ø°Ø§.\n+\n+Ù„Ù„Ø¨Ø¯Ø¡ØŒ ÙŠØ±Ø¬Ù‰ ØªØ«Ø¨ÙŠØª `agents` Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© Ù„ØªØ«Ø¨ÙŠØª Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©.\n+\n+```bash\n+pip install transformers[agents]\n+```\n+\n+Ù‚Ù… Ø¨Ø¨Ù†Ø§Ø¡ Ù…Ø­Ø±Ùƒ LLM Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ù…Ù† Ø®Ù„Ø§Ù„ ØªØ¹Ø±ÙŠÙ Ø·Ø±ÙŠÙ‚Ø© `llm_engine` Ø§Ù„ØªÙŠ ØªÙ‚Ø¨Ù„ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† [Ø§Ù„Ø±Ø³Ø§Ø¦Ù„](./chat_templating.) ÙˆØªØ¹ÙŠØ¯ Ø§Ù„Ù†Øµ. ÙŠØ¬Ø¨ Ø£Ù† ØªÙ‚Ø¨Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø£ÙŠØ¶Ù‹Ø§ Ù…Ø¹Ø§Ù…Ù„ `stop` ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ù…ØªÙ‰ ÙŠØ¬Ø¨ Ø§Ù„ØªÙˆÙ‚Ù Ø¹Ù† Ø§Ù„ØªÙˆÙ„ÙŠØ¯.\n+\n+```python\n+from huggingface_hub import login, InferenceClient\n+\n+login(\"<YOUR_HUGGINGFACEHUB_API_TOKEN>\")\n+\n+client = InferenceClient(model=\"meta-llama/Meta-Llama-3-70B-Instruct\")\n+\n+def llm_engine(messages, stop_sequences=[\"Task\"]) -> str:\n+    response = client.chat_completion(messages, stop=stop_sequences, max_tokens=1000)\n+    answer = response.choices[0].message.content\n+    return answer\n+```\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ Ø·Ø±ÙŠÙ‚Ø© `llm_engine` Ø·Ø§Ù„Ù…Ø§ Ø£Ù†Ù‡Ø§:\n+1. ÙŠØªØ¨Ø¹ ØªÙ†Ø³ÙŠÙ‚ [Ø±Ø³Ø§Ø¦Ù„](./chat_templating.md) Ù„Ø¥Ø¯Ø®Ø§Ù„Ù‡ (`List [Dict [strØŒ str]]`) ÙˆÙŠØ¹ÙŠØ¯ `str`\n+2. ÙŠØªÙˆÙ‚Ù Ø¹Ù† ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø®Ø±Ø§Ø¬Ø§Øª Ù…Ù† Ø§Ù„ØªØ³Ù„Ø³Ù„Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… ØªÙ…Ø±ÙŠØ±Ù‡Ø§ ÙÙŠ Ù…Ø¹Ø§Ù…Ù„ `stop`\n+\n+Ø£Ù†Øª Ø¨Ø­Ø§Ø¬Ø© Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ù„Ù‰ Ù…Ø¹Ø§Ù…Ù„ \"Ø§Ù„Ø£Ø¯ÙˆØ§Øª\" Ø§Ù„Ø°ÙŠ ÙŠÙ‚Ø¨Ù„ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† \"Ø§Ù„Ø£Ø¯ÙˆØ§Øª\". ÙŠÙ…ÙƒÙ†Ùƒ ØªÙˆÙÙŠØ± Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ© Ù„Ù€ \"Ø§Ù„Ø£Ø¯ÙˆØ§Øª\"ØŒ ÙˆÙ„ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ù… ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù…Ø¹ Ù…Ø¹Ø§Ù…Ù„ Ø§Ø®ØªÙŠØ§Ø±ÙŠ `add_base_tools=True`.\n+\n+Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ù†Ø´Ø§Ø¡ ÙˆÙƒÙŠÙ„ØŒ Ù…Ø«Ù„ [`CodeAgent`], ÙˆØªØ´ØºÙŠÙ„Ù‡. ÙˆÙ„ØªØ³Ù‡ÙŠÙ„ Ø§Ù„Ø£Ù…Ø±ØŒ Ù†Ù‚Ø¯Ù… Ø£ÙŠØ¶Ù‹Ø§ ÙØ¦Ø© [`HfEngine`] Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… `huggingface_hub.InferenceClient` Ø¨Ø´ÙƒÙ„ Ù…Ø®ÙÙ‰.\n+\n+```python\n+from transformers import CodeAgent, HfEngine\n+\n+llm_engine = HfEngine(model=\"meta-llama/Meta-Llama-3-70B-Instruct\")\n+agent = CodeAgent(tools=[], llm_engine=llm_engine, add_base_tools=True)\n+\n+agent.run(\n+    \"Could you translate this sentence from French, say it out loud and return the audio.\",\n+    sentence=\"OÃ¹ est la boulangerie la plus proche?\",\n+)\n+```\n+\n+Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙŠØ²Ø© Ø³ØªÙƒÙˆÙ† Ù…ÙÙŠØ¯Ø© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ø¬Ø© Ø§Ù„Ù…Ù„Ø­Ø©! ÙŠÙ…ÙƒÙ†Ùƒ Ø­ØªÙ‰ ØªØ±Ùƒ Ù…Ø¹Ø§Ù…Ù„ `llm_engine` ØºÙŠØ± Ù…Ø­Ø¯Ø¯ØŒ ÙˆØ³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ [`HfEngine`] Ø¨Ø´ÙƒÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ.\n+\n+```python\n+from transformers import CodeAgent\n+\n+agent = CodeAgent(tools=[], add_base_tools=True)\n+\n+agent.run(\n+    \"Could you translate this sentence from French, say it out loud and give me the audio.\",\n+    sentence=\"OÃ¹ est la boulangerie la plus proche?\",\n+)\n+```\n+\n+Ù„Ø§Ø­Ø¸ Ø£Ù†Ù†Ø§ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ Ù…Ø¹Ø§Ù…Ù„ \"sentence\" Ø¥Ø¶Ø§ÙÙŠ: ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù†Øµ ÙƒÙ…Ø¹Ø§Ù…Ù„ Ø¥Ø¶Ø§ÙÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ø§ Ù„Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¨Ø¹ÙŠØ¯Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§:\n+\n+```py\n+from transformers import ReactCodeAgent\n+\n+agent = ReactCodeAgent(tools=[], llm_engine=llm_engine, add_base_tools=True)\n+\n+agent.run(\"Why does Mike not know many people in New York?\", audio=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/recording.mp3\")\n+```\n+\n+\n+ØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆÙ…Ø­Ù„Ù„ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ØŒ ÙˆÙ„ÙƒÙ† ÙŠÙ…ÙƒÙ†Ùƒ ÙØ­ØµÙ‡Ù…Ø§ Ø¨Ø³Ù‡ÙˆÙ„Ø© Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ `system_prompt_template` Ø¹Ù„Ù‰ ÙˆÙƒÙŠÙ„Ùƒ.\n+\n+```python\n+print(agent.system_prompt_template)\n+```\n+\n+Ù…Ù† Ø§Ù„Ù…Ù‡Ù… Ø£Ù† ØªØ´Ø±Ø­ Ø¨Ø£ÙƒØ¨Ø± Ù‚Ø¯Ø± Ù…Ù…ÙƒÙ† Ù…Ù† Ø§Ù„ÙˆØ¶ÙˆØ­ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ ØªÙ†ÙÙŠØ°Ù‡Ø§.\n+ÙƒÙ„ Ø¹Ù…Ù„ÙŠØ© [`~Agent.run`] Ù…Ø³ØªÙ‚Ù„Ø©ØŒ ÙˆØ¨Ù…Ø§ Ø£Ù† Ø§Ù„ÙˆÙƒÙŠÙ„ Ù…Ø¯Ø¹ÙˆÙ… Ù…Ù† LLMØŒ ÙÙ‚Ø¯ ØªØ¤Ø¯ÙŠ Ø§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ø·ÙÙŠÙØ© ÙÙŠ Ù…ÙˆØ¬Ù‡Ùƒ Ø¥Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ù…Ø®ØªÙ„ÙØ© ØªÙ…Ø§Ù…Ù‹Ø§.\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ØªØ´ØºÙŠÙ„ ÙˆÙƒÙŠÙ„ Ø¨Ø´ÙƒÙ„ Ù…ØªØªØ§Ù„ÙŠ Ù„Ù…Ù‡Ø§Ù… Ù…Ø®ØªÙ„ÙØ©: ÙÙŠ ÙƒÙ„ Ù…Ø±Ø© ÙŠØªÙ… ÙÙŠÙ‡Ø§ Ø¥Ø¹Ø§Ø¯Ø© ØªÙ‡ÙŠØ¦Ø© Ø³Ù…ØªÙŠ `agent.task` Ùˆ`agent.logs`.\n+\n+\n+#### ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©\n+\n+ÙŠÙ‚ÙˆÙ… Ù…ÙØ³Ø± Python Ø¨ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„ØªÙŠ ÙŠØªÙ… ØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ø¬Ù†Ø¨Ù‹Ø§ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨ Ù…Ø¹ Ø£Ø¯ÙˆØ§ØªÙƒ.\n+ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø± Ø¢Ù…Ù†Ù‹Ø§ Ù„Ø£Ù† Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ÙˆØ­ÙŠØ¯Ø© Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡Ø§ Ù‡ÙŠ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙŠ Ù‚Ø¯Ù…ØªÙ‡Ø§ (Ø®Ø§ØµØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø£Ø¯ÙˆØ§Øª Ù…Ù† Hugging Face ÙÙ‚Ø·) ÙˆÙˆØ¸ÙŠÙØ© Ø§Ù„Ø·Ø¨Ø§Ø¹Ø©ØŒ Ù„Ø°Ø§ ÙØ£Ù†Øª Ù…Ù‚ÙŠØ¯ Ø¨Ø§Ù„ÙØ¹Ù„ Ø¨Ù…Ø§ ÙŠÙ…ÙƒÙ† ØªÙ†ÙÙŠØ°Ù‡.\n+\n+Ù…ÙØ³Ø± Python Ù„Ø§ ÙŠØ³Ù…Ø­ Ø£ÙŠØ¶Ù‹Ø§ Ø¨Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯ÙˆØ§Ù„ Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø®Ø§Ø±Ø¬ Ù‚Ø§Ø¦Ù…Ø© Ø¢Ù…Ù†Ø©ØŒ Ù„Ø°Ø§ ÙØ¥Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‡Ø¬Ù…Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± ÙˆØ¶ÙˆØ­Ù‹Ø§ Ù„Ø§ ÙŠÙ†Ø¨ØºÙŠ Ø£Ù† ØªÙƒÙˆÙ† Ù…Ø´ÙƒÙ„Ø©.\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø§Ù„Ø¥Ø°Ù† Ø¨Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªÙ…Ø±ÙŠØ± Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù†Ù…Ø·ÙŠØ© Ø§Ù„Ù…ØµØ±Ø­ Ø¨Ù‡Ø§ ÙƒÙ‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ø³Ù„Ø§Ø³Ù„ ÙÙŠ Ù…Ø¹Ø§Ù…Ù„  `additional_authorized_imports` Ø¹Ù†Ø¯ ØªÙ‡ÙŠØ¦Ø© [`ReactCodeAgent`] Ø£Ùˆ [`CodeAgent`]:\n+\n+```py\n+>>> from transformers import ReactCodeAgent\n+\n+>>> agent = ReactCodeAgent(tools=[], additional_authorized_imports=['requests', 'bs4'])\n+>>> agent.run(\"Could you get me the title of the page at url 'https://huggingface.co/blog'?\")\n+\n+(...)\n+'Hugging Face â€“ Blog'\n+```\n+\n+Ø³ÙŠØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªÙ†ÙÙŠØ° Ø¹Ù†Ø¯ Ø£ÙŠ Ø±Ù…Ø² ÙŠØ­Ø§ÙˆÙ„ ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ© ØºÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø£Ùˆ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø®Ø·Ø£ Python Ø¹Ø§Ø¯ÙŠ ÙÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„ÙˆÙƒÙŠÙ„.\n+\n+> [!WARNING]\n+> ÙŠÙ…ÙƒÙ† Ù„Ù€ LLM ØªÙˆÙ„ÙŠØ¯ Ø´ÙØ±Ø© Ø¨Ø±Ù…Ø¬ÙŠØ© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ø³ÙŠØªÙ… ØªÙ†ÙÙŠØ°Ù‡Ø§ Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ: Ù„Ø§ ØªÙ‚Ù…Ø¨ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø£Ù‰ Ø¯ÙˆØ§Ù„ ØºÙŠØ± Ø¢Ù…Ù†Ø©!\n+\n+### Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù†Ø¸Ø§Ù…\n+\n+ÙŠÙ†Ø´Ø¦ Ø§Ù„ÙˆÙƒÙŠÙ„ØŒ Ø£Ùˆ Ø¨Ø§Ù„Ø£Ø­Ø±Ù‰ LLM Ø§Ù„Ø°ÙŠ ÙŠÙ‚ÙˆØ¯ Ø§Ù„ÙˆÙƒÙŠÙ„ØŒ ÙŠÙˆÙ„Ø¯ Ù…Ø®Ø±Ø¬Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù†Ø¸Ø§Ù…. ÙŠÙ…ÙƒÙ† ØªØ®ØµÙŠØµ Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØªØµÙ…ÙŠÙ…Ù‡ Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ù‚ØµÙˆØ¯Ø©. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù†Ø¸Ø§Ù… Ù„Ù€ [`ReactCodeAgent`] (Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø£Ø¯Ù†Ø§Ù‡ Ù…Ø¨Ø³Ø· Ù‚Ù„ÙŠÙ„Ø§Ù‹).\n+\n+```text\n+You will be given a task to solve as best you can.\n+You have access to the following tools:\n+<<tool_descriptions>>\n+\n+To solve the task, you must plan forward to proceed in a series of steps, in a cycle of 'Thought:', 'Code:', and 'Observation:' sequences.\n+\n+At each step, in the 'Thought:' sequence, you should first explain your reasoning towards solving the task, then the tools that you want to use.\n+Then in the 'Code:' sequence, you shold write the code in simple Python. The code sequence must end with '/End code' sequence.\n+During each intermediate step, you can use 'print()' to save whatever important information you will then need.\n+These print outputs will then be available in the 'Observation:' field, for using this information as input for the next step.\n+\n+In the end you have to return a final answer using the `final_answer` tool.\n+\n+Here are a few examples using notional tools:\n+---\n+{examples}\n+\n+Above example were using notional tools that might not exist for you. You only have acces to those tools:\n+<<tool_names>>\n+You also can perform computations in the python code you generate.\n+\n+Always provide a 'Thought:' and a 'Code:\\n```py' sequence ending with '```<end_code>' sequence. You MUST provide at least the 'Code:' sequence to move forward.\n+\n+Remember to not perform too many operations in a single code block! You should split the task into intermediate code blocks.\n+Print results at the end of each step to save the intermediate results. Then use final_answer() to return the final result.\n+\n+Remember to make sure that variables you use are all defined.\n+\n+Now Begin!\n+```\n+\n+ÙŠØªØ¶Ù…Ù† Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù†Ø¸Ø§Ù…:\n+- *Ù…Ù‚Ø¯Ù…Ø©* ØªØ´Ø±Ø­ ÙƒÙŠÙ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØªØµØ±Ù Ø§Ù„ÙˆÙƒÙŠÙ„ ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙ‡ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§.\n+- ÙˆØµÙ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙŠ ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡Ø§ Ø¨ÙˆØ§Ø³Ø·Ø© Ø±Ù…Ø² `<<tool_descriptions>>` Ø§Ù„Ø°ÙŠ ÙŠØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠÙ‹Ø§ ÙÙŠ ÙˆÙ‚Øª Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙŠ ÙŠØ­Ø¯Ø¯Ù‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ùˆ ÙŠØ®ØªØ§Ø±Ù‡Ø§.\n+    - ÙŠØ£ØªÙŠ ÙˆØµÙ Ø§Ù„Ø£Ø¯Ø§Ø© Ù…Ù† Ø³Ù…Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø©ØŒ `name`ØŒ Ùˆ`description`ØŒ Ùˆ`inputs` Ùˆ`output_type`ØŒ ÙˆÙ‚Ø§Ù„Ø¨ `jinja2` Ø¨Ø³ÙŠØ· ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ø³ÙŠÙ†Ù‡.\n+- Ø´ÙƒÙ„ Ø§Ù„Ù…Ø®Ø±Ø¬ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹.\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ø³ÙŠÙ† Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù†Ø¸Ø§Ù…ØŒ Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø¥Ø¶Ø§ÙØ© Ø´Ø±Ø­ Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª.\n+\n+Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ù‚ØµÙ‰ Ù‚Ø¯Ø± Ù…Ù† Ø§Ù„Ù…Ø±ÙˆÙ†Ø©ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ÙƒØªØ§Ø¨Ø© ÙÙˆÙ‚ Ù‚Ø§Ù„Ø¨ Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªÙ…Ø±ÙŠØ± Ù…ÙˆØ¬Ù‡ Ù…Ø®ØµØµ ÙƒÙ…Ø¹Ø§Ù…Ù„ Ø¥Ù„Ù‰ Ù…Ø¹Ù„Ù…Ø© `system_prompt`.\n+\n+```python\n+from transformers import ReactJsonAgent\n+from transformers.agents import PythonInterpreterTool\n+\n+agent = ReactJsonAgent(tools=[PythonInterpreterTool()], system_prompt=\"{your_custom_prompt}\")\n+```\n+\n+> [!WARNING]\n+> ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ­Ø¯ÙŠØ¯ Ø³Ù„Ø³Ù„Ø© `<<tool_descriptions>>` ÙÙŠ Ù…ÙƒØ§Ù† Ù…Ø§ ÙÙŠ `template` Ø­ØªÙ‰ ÙŠÙƒÙˆÙ† Ø§Ù„ÙˆÙƒÙŠÙ„ Ø¹Ù„Ù‰ Ø¹Ù„Ù… \n+Ø¨Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©.\n+\n+\n+### ÙØ­Øµ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆÙƒÙŠÙ„\n+\n+ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø³Ù…Ø§Øª Ø§Ù„Ù…ÙÙŠØ¯Ø© Ù„ÙØ­Øµ Ù…Ø§ Ø­Ø¯Ø« Ø¨Ø¹Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„:\n+- ØªØ®Ø²Ù†  `agent.logs` Ø³Ø¬Ù„Ø§Øª Ù…ÙØµÙ„Ø© Ù„Ù„ÙˆÙƒÙŠÙ„. ÙÙŠ ÙƒÙ„ Ø®Ø·ÙˆØ© Ù…Ù† ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆÙƒÙŠÙ„ØŒ ÙŠØªÙ… ØªØ®Ø²ÙŠÙ† ÙƒÙ„ Ø´ÙŠØ¡ ÙÙŠ Ù‚Ø§Ù…ÙˆØ³ Ø¥Ù„Ø­Ø§Ù‚Ù‡ Ø¨Ù€ `agent.logs`.\n+- ØªØ´ØºÙŠÙ„ `agent.write_inner_memory_from_logs()` ÙŠØ®Ù„Ù‚ Ø°Ø§ÙƒØ±Ø© Ø¯Ø§Ø®Ù„ÙŠØ© Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„ÙˆÙƒÙŠÙ„ Ù„Ù„Ù†Ø¸Ø§Ù… LLM Ù„Ø¹Ø±Ø¶Ù‡Ø§ØŒ ÙƒÙ‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©. ØªÙ†ØªÙ‚Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø¹Ø¨Ø± ÙƒÙ„ Ø®Ø·ÙˆØ© Ù…Ù† Ø³Ø¬Ù„ Ø§Ù„ÙˆÙƒÙŠÙ„ ÙˆÙ„Ø§ ØªØ®Ø²Ù† Ø³ÙˆÙ‰ Ù…Ø§ ÙŠÙ‡Ù…Ù‡Ø§ ÙƒØ±Ø³Ø§Ù„Ø©: Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø³ÙŠØ­ÙØ¸ Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ§Ù„Ù…Ù‡Ù…Ø© ÙÙŠ Ø±Ø³Ø§Ø¦Ù„ Ù…Ù†ÙØµÙ„Ø©ØŒ Ø«Ù… Ù„ÙƒÙ„ Ø®Ø·ÙˆØ© Ø³ÙŠØ®Ø²Ù† Ù…Ø®Ø±Ø¬ LLM ÙƒØ±Ø³Ø§Ù„Ø©ØŒ ÙˆÙ…Ø®Ø±Ø¬ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø£Ø¯Ø§Ø© ÙƒØ±Ø³Ø§Ù„Ø© Ø£Ø®Ø±Ù‰. Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ø¹Ø±Ø¶Ù‹Ø§ Ø¹Ø§Ù…Ù‹Ø§ Ù„Ù…Ø§ Ø­Ø¯Ø« - ÙˆÙ„ÙƒÙ† Ù„Ù† ÙŠØªÙ… Ù†Ø³Ø® ÙƒÙ„ Ø³Ø¬Ù„ Ø¨ÙˆØ§Ø³Ø·Ø© Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©.\n+\n+## Ø§Ù„Ø£Ø¯ÙˆØ§Øª\n+\n+Ø§Ù„Ø£Ø¯Ø§Ø© Ù‡ÙŠ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† ÙˆØ¸ÙŠÙØ© Ø£Ø³Ø§Ø³ÙŠØ© ÙŠØ³ØªØ®Ø¯Ù…Ù‡Ø§ Ø§Ù„ÙˆÙƒÙŠÙ„ Ù„ØªÙ†ÙÙŠØ° Ù…Ù‡Ù…Ø© Ù…Ø­Ø¯Ø¯Ø©.\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† [`PythonInterpreterTool`]: Ù„Ø¯ÙŠÙ‡ Ø§Ø³Ù… ÙˆÙˆØµÙ ÙˆÙˆØµÙ Ù„Ù„Ù…Ø¯Ø®Ù„Ø§Øª ÙˆÙ†ÙˆØ¹ Ù„Ù„Ù…Ø®Ø±Ø¬ØŒ ÙˆØ·Ø±ÙŠÙ‚Ø© `__call__` Ø§Ù„ØªÙŠ ØªÙ‚ÙˆÙ… Ø¨ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©.\n+\n+Ø¹Ù†Ø¯ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ØŒ ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø³Ù…Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø© Ù„ØªÙˆÙ„ÙŠØ¯ ÙˆØµÙ Ù„Ù„Ø£Ø¯Ø§Ø© ÙŠØªÙ… ØªØ¶Ù…ÙŠÙ†Ù‡ ÙÙŠ Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø§Øµ Ø¨Ø§Ù„ÙˆÙƒÙŠÙ„. ÙŠØªÙŠØ­ Ù‡Ø°Ø§ Ù„Ù„ÙˆÙƒÙŠÙ„ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ†Ù‡ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙˆÙ„Ù…Ø§Ø°Ø§.\n+\n+### ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ\n+\n+ÙŠØ£ØªÙŠ Transformers Ù…Ø¹ ØµÙ†Ø¯ÙˆÙ‚ Ø£Ø¯ÙˆØ§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„ØªÙ…ÙƒÙŠÙ† Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ØŒ ÙˆØ§Ù„Ø°ÙŠ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØªÙ‡ Ø¥Ù„Ù‰ ÙˆÙƒÙŠÙ„Ùƒ Ø¹Ù†Ø¯ Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù…Ù„ `add_base_tools = True`:\n+\n+- **Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯**: Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ (Ù…Ø«Ù„ Ù…Ù„Ù PDF) Ø¨ØªÙ†Ø³ÙŠÙ‚ ØµÙˆØ±Ø© ([Donut](./model_doc/donut))\n+- **Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØµÙˆØ±**: Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø­ÙˆÙ„ ØµÙˆØ±Ø© ([VILT](./model_doc/vilt))\n+- **Ø§Ù„ØªØ­Ø¯Ø« Ø¥Ù„Ù‰ Ø§Ù„Ù†Øµ**: Ù‚Ù… Ø¨ØªÙØ±ÙŠØº Ø§Ù„ÙƒÙ„Ø§Ù… Ø¥Ù„Ù‰ Ù†Øµ ([Whisper](./model_doc/whisper))\n+- **Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…**: ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù… ([SpeechT5](./model_doc/speecht5))\n+- **Ø§Ù„ØªØ±Ø¬Ù…Ø©**: ØªØ±Ø¬Ù…Ø© Ø¬Ù…Ù„Ø© Ù…Ø¹ÙŠÙ†Ø© Ù…Ù† Ù„ØºØ© Ø§Ù„Ù…ØµØ¯Ø± Ø¥Ù„Ù‰ Ù„ØºØ© Ø§Ù„Ù‡Ø¯Ù.\n+- **Ù…ÙØ³Ø± ÙƒÙˆØ¯ Python**: ØªØ´ØºÙŠÙ„ ÙƒÙˆØ¯ Python Ø§Ù„Ø°ÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡ Ø¨ÙˆØ§Ø³Ø·Ø© LLM ÙÙŠ Ø¨ÙŠØ¦Ø© Ø¢Ù…Ù†Ø©. Ù„Ù† ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø¯Ø§Ø© Ø¥Ù„Ù‰ [`ReactJsonAgent`] Ø¥Ù„Ø§ Ø¥Ø°Ø§ Ø§Ø³ØªØ®Ø¯Ù…Øª `add_base_tools=True`ØŒ Ù†Ø¸Ø±Ù‹Ø§ Ù„Ø£Ù† Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø© Ø¥Ù„Ù‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© ÙŠÙ…ÙƒÙ†Ù‡Ø§ Ø¨Ø§Ù„ÙØ¹Ù„ ØªÙ†ÙÙŠØ° ÙƒÙˆØ¯ Python\n+Ù„Ø§ ØªØªØ±Ø¬Ù… Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø®Ø§ØµØ© ÙˆÙ„Ø§ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© ÙˆÙ„Ø§ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙˆÙ„Ø§ Ø±Ù…ÙˆØ² HTML ÙˆCSS:\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯Ø§Ø© ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© [`load_tool`] ÙˆØªØ­Ø¯ÙŠØ¯ Ù…Ù‡Ù…Ø© Ù„ØªÙ†ÙÙŠØ°Ù‡Ø§.\n+\n+```python\n+from transformers import load_tool\n+\n+tool = load_tool(\"text-to-speech\")\n+audio = tool(\"This is a text to speech tool\")\n+```\n+\n+### Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø¯Ø§Ø© Ø¬Ø¯ÙŠØ¯Ø©\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø¯Ø§ØªÙƒ Ø§Ù„Ø®Ø§ØµØ© Ù„ØªØºØ·ÙŠØ© Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙŠ Ù„Ø§ ØªØºØ·ÙŠÙ‡Ø§ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…Ù† Hugging Face.\n+Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¯Ø¹Ù†Ø§ Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø¯Ø§Ø© ØªØ¹Ø±Ø¶ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙƒØ«Ø± ØªÙ†Ø²ÙŠÙ„Ù‹Ø§ Ù„Ù…Ù‡Ù…Ø© Ù…Ø¹ÙŠÙ†Ø© Ù…Ù† Hub.\n+\n+Ø³ÙˆÙ Ù†Ø¨Ø¯Ø£ Ø¨Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ØªØ§Ù„ÙŠ.\n+\n+```python\n+from huggingface_hub import list_models\n+\n+task = \"text-classification\"\n+\n+model = next(iter(list_models(filter=task, sort=\"downloads\", direction=-1)))\n+print(model.id)\n+```\n+\n+ÙŠÙ…ÙƒÙ† ØªØ­ÙˆÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ø´ÙŠÙØ±Ø© Ø¥Ù„Ù‰ ÙØ¦Ø© ØªØ±Ø« Ù…Ù† Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø¹Ù„ÙŠØ§ [`Tool`].\n+\n+ØªØ­ØªØ§Ø¬ Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ø®ØµØµØ© Ø¥Ù„Ù‰:\n+\n+- Ø§Ø³Ù… `name`ØŒ ÙˆØ§Ù„ØªÙŠ ØªÙ…Ø«Ù„ Ø§Ø³Ù… Ø§Ù„Ø£Ø¯Ø§Ø© Ù†ÙØ³Ù‡Ø§. Ø¹Ø§Ø¯Ø©Ù‹ Ù…Ø§ ÙŠØµÙ Ø§Ù„Ø§Ø³Ù… ÙˆØ¸ÙŠÙØªÙ‡Ø§. Ø¨Ù…Ø§ Ø£Ù† Ø§Ù„ÙƒÙˆØ¯ ÙŠØ¹ÙŠØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙƒØ«Ø± ØªÙ†Ø²ÙŠÙ„Ù‹Ø§ Ù„Ù…Ù‡Ù…Ø© Ù…Ø§ØŒ ÙÙ„Ù†Ø³Ù…Ù‡Ø§ `model_download_counter`.\n+- ØªØ³ØªØ®Ø¯Ù… Ø®Ø§ØµÙŠØ© `description` Ù„Ù…Ù„Ø¡ Ù…ÙˆØ¬Ù‡ Ù†Ø¸Ø§Ù… Ø§Ù„ÙˆÙƒÙŠÙ„.\n+- Ø®Ø§ØµÙŠØ© `inputs`ØŒ ÙˆØ§Ù„ØªÙŠ Ù‡ÙŠ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ù‚Ø§Ù…ÙˆØ³ Ø¨Ù…ÙØ§ØªÙŠØ­ \"type\" Ùˆ\"description\". ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…ÙØ³Ø± Python Ø¹Ù„Ù‰ Ø§ØªØ®Ø§Ø° Ø®ÙŠØ§Ø±Ø§Øª Ù…Ø³ØªÙ†ÙŠØ±Ø© Ø¨Ø´Ø£Ù† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª.\n+- Ø®Ø§ØµÙŠØ© `output_type`ØŒ ÙˆØ§Ù„ØªÙŠ ØªØ­Ø¯Ø¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø®Ø±Ø¬.\n+- Ø·Ø±ÙŠÙ‚Ø© `forward` ÙˆØ§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… ØªÙ†ÙÙŠØ°Ù‡ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©.\n+\n+```python\n+from transformers import Tool\n+from huggingface_hub import list_models\n+\n+class HFModelDownloadsTool(Tool):\n+    name = \"model_download_counter\"\n+    description = (\n+        \"This is a tool that returns the most downloaded model of a given task on the Hugging Face Hub. \"\n+        \"It returns the name of the checkpoint.\"\n+    )\n+\n+    inputs = {\n+        \"task\": {\n+            \"type\": \"text\",\n+            \"description\": \"the task category (such as text-classification, depth-estimation, etc)\",\n+        }\n+    }\n+    output_type = \"text\"\n+\n+    def forward(self, task: str):\n+        model = next(iter(list_models(filter=task, sort=\"downloads\", direction=-1)))\n+        return model.id\n+```\n+\n+Ø§Ù„Ø¢Ù† Ø¨Ø¹Ø¯ Ø£Ù† Ø£ØµØ¨Ø­Øª ÙØ¦Ø© `HfModelDownloadsTool` Ø§Ù„Ù…Ø®ØµØµØ© Ø¬Ø§Ù‡Ø²Ø©ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø­ÙØ¸Ù‡Ø§ ÙÙŠ Ù…Ù„Ù Ø¨Ø§Ø³Ù… `model_downloads.py` ÙˆØ§Ø³ØªÙŠØ±Ø§Ø¯Ù‡Ø§ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù….\n+\n+```python\n+from model_downloads import HFModelDownloadsTool\n+\n+tool = HFModelDownloadsTool()\n+```\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ù…Ø´Ø§Ø±ÙƒØ© Ø£Ø¯Ø§ØªÙƒ Ø§Ù„Ù…Ø®ØµØµØ© ÙÙŠ Hub Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ [`~Tool.push_to_hub`] Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø©. ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ùƒ Ù‚Ù…Øª Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªÙˆØ¯Ø¹ Ù„Ù‡Ø§ Ø¹Ù„Ù‰ Hub ÙˆØ£Ù†Ùƒ ØªØ³ØªØ®Ø¯Ù… Ø±Ù…Ø² ÙˆØµÙˆÙ„ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø©.\n+\n+```python\n+tool.push_to_hub(\"{your_username}/hf-model-downloads\")\n+```\n+\n+Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© [`~Tool.load_tool`] ÙˆÙ…Ø±Ø±Ù‡Ø§ Ø¥Ù„Ù‰ Ù…Ø¹Ù„Ù…Ø© `tools` ÙÙŠ Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ.\n+\n+```python\n+from transformers import load_tool, CodeAgent\n+\n+model_download_tool = load_tool(\"m-ric/hf-model-downloads\")\n+agent = CodeAgent(tools=[model_download_tool], llm_engine=llm_engine)\n+agent.run(\n+    \"Can you give me the name of the model that has the most downloads in the 'text-to-video' task on the Hugging Face Hub?\"\n+)\n+```\n+\n+Ø³ØªØ­ØµÙ„ Ø¹Ù„Ù‰ Ù…Ø§ ÙŠÙ„ÙŠ:\n+\n+```text\n+======== New task ========\n+Can you give me the name of the model that has the most downloads in the 'text-to-video' task on the Hugging Face Hub?\n+==== Agent is executing the code below:\n+most_downloaded_model = model_download_counter(task=\"text-to-video\")\n+print(f\"The most downloaded model for the 'text-to-video' task is {most_downloaded_model}.\")\n+====\n+```\n+\n+ÙˆØ§Ù„Ù†Ø§ØªØ¬:\n+\n+`\"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙƒØ«Ø± ØªÙ†Ø²ÙŠÙ„Ù‹Ø§ Ù„Ù…Ù‡Ù…Ø© `text-to-video` Ù‡Ùˆ ByteDance/AnimateDiff-Lightning.\"`\n+\n+### Ø¥Ø¯Ø§Ø±Ø© ØµÙ†Ø¯ÙˆÙ‚ Ø£Ø¯ÙˆØ§Øª Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ\n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª Ù‚Ø¯ Ù‚Ù…Øª Ø¨ØªÙ‡ÙŠØ¦Ø© ÙˆÙƒÙŠÙ„ØŒ ÙÙ…Ù† ØºÙŠØ± Ø§Ù„Ù…Ù„Ø§Ø¦Ù… Ø¥Ø¹Ø§Ø¯Ø© ØªÙ‡ÙŠØ¦ØªÙ‡ Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ù„Ø¥Ø¶Ø§ÙØ© Ø£Ø¯Ø§Ø© Ø¬Ø¯ÙŠØ¯Ø© ØªØ±ØºØ¨ ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§. Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© TransformersØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¯Ø§Ø±Ø© ØµÙ†Ø¯ÙˆÙ‚ Ø£Ø¯ÙˆØ§Øª Ø§Ù„ÙˆÙƒÙŠÙ„ Ø¨Ø¥Ø¶Ø§ÙØ© Ø£Ùˆ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø£Ø¯Ø§Ø© Ù…ÙˆØ¬ÙˆØ¯Ø©.\n+\n+Ø¯Ø¹Ù†Ø§ Ù†Ø¶ÙŠÙ Ø§Ù„Ø£Ø¯Ø§Ø© `model_download_tool` Ø¥Ù„Ù‰ ÙˆÙƒÙŠÙ„ ØªÙ… ØªÙ‡ÙŠØ¦ØªÙ‡ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ.\n+\n+```python\n+from transformers import CodeAgent\n+\n+agent = CodeAgent(tools=[], llm_engine=llm_engine, add_base_tools=True)\n+agent.toolbox.add_tool(model_download_tool)\n+```\n+\n+Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙˆØ£Ø¯Ø§Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù… Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:\n+\n+```python\n+    agent.run(\n+        \"Can you read out loud the name of the model that has the most downloads in the 'text-to-video' task on the Hugging Face Hub and return the audio?\"\n+    )\n+```\n+\n+| **Audio**                                                                                                                                            |\n+|------------------------------------------------------------------------------------------------------------------------------------------------------|\n+| <audio controls><source src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/damo.wav\" type=\"audio/wav\"/> |\n+\n+> [!WARNING]\n+> Ø§Ø­ØªØ±Ø³ Ø¹Ù†Ø¯ Ø¥Ø¶Ø§ÙØ© Ø£Ø¯ÙˆØ§Øª Ø¥Ù„Ù‰ ÙˆÙƒÙŠÙ„ ÙŠØ¹Ù…Ù„ Ø¨Ø§Ù„ÙØ¹Ù„ Ù„Ø£Ù†Ù‡ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø¯Ø§Ø© Ù„ØµØ§Ù„Ø­ Ø£Ø¯Ø§ØªÙƒ Ø£Ùˆ Ø§Ø®ØªÙŠØ§Ø± Ø£Ø¯Ø§Ø© Ø£Ø®Ø±Ù‰ ØºÙŠØ± Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø¨Ø§Ù„ÙØ¹Ù„.\n+\n+Ø§Ø³ØªØ®Ø¯Ù… Ø·Ø±ÙŠÙ‚Ø© `agent.toolbox.update_tool()` Ù„Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø£Ø¯Ø§Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ ØµÙ†Ø¯ÙˆÙ‚ Ø£Ø¯ÙˆØ§Øª Ø§Ù„ÙˆÙƒÙŠÙ„.\n+Ù‡Ø°Ø§ Ù…ÙÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø£Ø¯Ø§ØªÙƒ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ø¯ÙŠÙ„Ø§Ù‹ Ù…Ø¨Ø§Ø´Ø±Ù‹Ø§ Ù„Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ù„Ø£Ù† Ø§Ù„ÙˆÙƒÙŠÙ„ ÙŠØ¹Ø±Ù Ø¨Ø§Ù„ÙØ¹Ù„ ÙƒÙŠÙÙŠØ© ØªÙ†ÙÙŠØ° ØªÙ„Ùƒ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©.\n+ØªØ£ÙƒØ¯ ÙÙ‚Ø· Ù…Ù† Ø§ØªØ¨Ø§Ø¹ Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù†ÙØ³ ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª (API) Ù„Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ø³ØªØ¨Ø¯Ù„Ø© Ø£Ùˆ Ù‚Ù… Ø¨ØªÙƒÙŠÙŠÙ Ù‚Ø§Ù„Ø¨ Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù†Ø¸Ø§Ù… Ù„Ø¶Ù…Ø§Ù† ØªØ­Ø¯ÙŠØ« Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ø³ØªØ¨Ø¯Ù„Ø©.\n+\n+### Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ø¯ÙˆØ§Øª\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒØ§Ø¦Ù† ToolCollectionØŒ Ù…Ø¹ ØªØ­Ø¯ÙŠØ¯ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§.\n+Ø«Ù… Ù‚Ù… Ø¨ØªÙ…Ø±ÙŠØ±Ù‡Ø§ ÙƒÙ‚Ø§Ø¦Ù…Ø© Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø®Ø§Øµ Ø¨ÙƒØŒ ÙˆØ¨Ø¯Ø¡ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§!\n+\n+```py\n+from transformers import ToolCollection, ReactCodeAgent\n+\n+image_tool_collection = ToolCollection(collection_slug=\"huggingface-tools/diffusion-tools-6630bb19a942c2306a2cdb6f\")\n+agent = ReactCodeAgent(tools=[*image_tool_collection.tools], add_base_tools=True)\n+\n+agent.run(\"Please draw me a picture of rivers and lakes.\")\n+```\n+\n+Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©ØŒ ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø¯ÙˆØ§Øª ÙÙ‚Ø· Ø¥Ø°Ø§ Ø§Ø³ØªØ¯Ø¹Ø§Ù‡Ø§ Ø§Ù„ÙˆÙƒÙŠÙ„.\n+\n+Ø³ØªØ­ØµÙ„ Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø©:\n+\n+<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/rivers_and_lakes.png\" />\n+\n+### Ø§Ø³ØªØ®Ø¯Ø§Ù… gradio-tools\n+\n+[gradio-tools](https://github.com/freddyaboulton/gradio-tools) Ù‡ÙŠ Ù…ÙƒØªØ¨Ø© Ù‚ÙˆÙŠØ© ØªØªÙŠØ­ Ø§Ø³ØªØ®Ø¯Ø§Ù… Hugging\n+Face Spaces ÙƒØ£Ø¯ÙˆØ§Øª. ØªØ¯Ø¹Ù… Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø­Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ù…Ø³Ø§Ø­Ø§Øª Ù…Ø®ØµØµØ©.\n+\n+ØªØ¯Ø¹Ù… Ù…ÙƒØªØ¨Ø© Transformers `gradio_tools` Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© [`Tool.from_gradio`] ÙÙŠ Ø§Ù„ÙØ¦Ø©. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¯Ø¹Ù†Ø§ Ù†Ø³ØªØ®Ø¯Ù… [`StableDiffusionPromptGeneratorTool`](https://github.com/freddyaboulton/gradio-tools/blob/main/gradio_tools/tools/prompt_generator.py) Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø£Ø¯ÙˆØ§Øª `gradio-tools` Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ù„Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ± Ø£ÙØ¶Ù„.\n+\n+Ø§Ø³ØªÙˆØ±Ø¯ ÙˆÙ‚Ù… Ø¨ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø£Ø¯Ø§Ø©ØŒ Ø«Ù… Ù…Ø±Ø±Ù‡Ø§ Ø¥Ù„Ù‰ Ø·Ø±ÙŠÙ‚Ø© `Tool.from_gradio`:\n+\n+```python\n+from gradio_tools import StableDiffusionPromptGeneratorTool\n+from transformers import Tool, load_tool, CodeAgent\n+\n+gradio_prompt_generator_tool = StableDiffusionPromptGeneratorTool()\n+prompt_generator_tool = Tool.from_gradio(gradio_prompt_generator_tool)\n+```\n+\n+Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù…Ø«Ù„ Ø£ÙŠ Ø£Ø¯Ø§Ø© Ø£Ø®Ø±Ù‰. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¯Ø¹Ù†Ø§ Ù†Ø­Ø³Ù† Ø§Ù„Ù…ÙˆØ¬Ù‡ `a rabbit wearing a space suit`.\n+\n+```python\n+image_generation_tool = load_tool('huggingface-tools/text-to-image')\n+agent = CodeAgent(tools=[prompt_generator_tool, image_generation_tool], llm_engine=llm_engine)\n+\n+agent.run(\n+    \"Improve this prompt, then generate an image of it.\", prompt='A rabbit wearing a space suit'\n+)\n+```\n+\n+ÙŠØ³ØªÙÙŠØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø´ÙƒÙ„ ÙƒØ§ÙÙ Ù…Ù† Ø§Ù„Ø£Ø¯Ø§Ø©:\n+\n+```text\n+======== New task ========\n+Improve this prompt, then generate an image of it.\n+You have been provided with these initial arguments: {'prompt': 'A rabbit wearing a space suit'}.\n+==== Agent is executing the code below:\n+improved_prompt = StableDiffusionPromptGenerator(query=prompt)\n+while improved_prompt == \"QUEUE_FULL\":\n+    improved_prompt = StableDiffusionPromptGenerator(query=prompt)\n+print(f\"The improved prompt is {improved_prompt}.\")\n+image = image_generator(prompt=improved_prompt)\n+====\n+```\n+\n+Ù‚Ø¨Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø© Ø£Ø®ÙŠØ±Ù‹Ø§:\n+\n+<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/rabbit.png\" />\n+\n+> [!WARNING]\n+> ØªØªØ·Ù„Ø¨ gradio-tools Ø¥Ø¯Ø®Ø§Ù„Ø§Øª ÙˆØ¥Ø®Ø±Ø§Ø¬Ø§Øª *Ù†ØµÙŠØ©* Ø­ØªÙ‰ Ø¹Ù†Ø¯ Ø§Ù„Ø¹Ù…Ù„ Ù…Ø¹ Ø·Ø±Ø§Ø¦Ù‚ Ù…Ø®ØªÙ„ÙØ© Ù…Ø«Ù„ ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ØµÙˆØª. Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª ÙˆØ§Ù„Ø¥Ø®Ø±Ø§Ø¬Ø§Øª Ø§Ù„ØµÙˆØ±ÙŠØ© ÙˆØ§Ù„ØµÙˆØªÙŠØ© ØºÙŠØ± Ù…ØªÙˆØ§ÙÙ‚Ø© Ø­Ø§Ù„ÙŠÙ‹Ø§.\n+\n+### Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯ÙˆØ§Øª LangChain\n+\n+Ù†Ø­Ù† Ù†Ø­Ø¨ Langchain ÙˆÙ†Ø¹ØªÙ‚Ø¯ Ø£Ù†Ù‡Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø£Ø¯ÙˆØ§Øª Ù‚ÙˆÙŠØ© Ù„Ù„ØºØ§ÙŠØ©.\n+Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø£Ø¯Ø§Ø© Ù…Ù† LangChainØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© `from_langchain()`.\n+\n+ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯Ø§Ø© Ø¨Ø­Ø« Ø§Ù„ÙˆÙŠØ¨ LangChain.\n+\n+```python\n+from langchain.agents import load_tools\n+from transformers import Tool, ReactCodeAgent\n+\n+search_tool = Tool.from_langchain(load_tools([\"serpapi\"])[0])\n+\n+agent = ReactCodeAgent(tools=[search_tool])\n+\n+agent.run(\"How many more blocks (also denoted as layers) in BERT base encoder than the encoder from the architecture proposed in Attention is All You Need?\")\n+```\n+\n+## ÙˆØ§Ø¬Ù‡Ø© Gradio\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† `gradio.Chatbot` Ù„Ø¹Ø±Ø¶ Ø£ÙÙƒØ§Ø± Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `stream_to_gradio`ØŒ Ø¥Ù„ÙŠÙƒ Ù…Ø«Ø§Ù„:\n+\n+```py\n+import gradio as gr\n+from transformers import (\n+    load_tool,\n+    ReactCodeAgent,\n+    HfEngine,\n+    stream_to_gradio,\n+)\n+\n+# Import tool from Hub\n+image_generation_tool = load_tool(\"m-ric/text-to-image\")\n+\n+llm_engine = HfEngine(\"meta-llama/Meta-Llama-3-70B-Instruct\")\n+\n+# Initialize the agent with the image generation tool\n+agent = ReactCodeAgent(tools=[image_generation_tool], llm_engine=llm_engine)\n+\n+\n+def interact_with_agent(task):\n+    messages = []\n+    messages.append(gr.ChatMessage(role=\"user\", content=task))\n+    yield messages\n+    for msg in stream_to_gradio(agent, task):\n+        messages.append(msg)\n+        yield messages + [\n+            gr.ChatMessage(role=\"assistant\", content=\"â³ Task not finished yet!\")\n+        ]\n+    yield messages\n+\n+\n+with gr.Blocks() as demo:\n+    text_input = gr.Textbox(lines=1, label=\"Chat Message\", value=\"Make me a picture of the Statue of Liberty.\")\n+    submit = gr.Button(\"Run illustrator agent!\")\n+    chatbot = gr.Chatbot(\n+        label=\"Agent\",\n+        type=\"messages\",\n+        avatar_images=(\n+            None,\n+            \"https://em-content.zobj.net/source/twitter/53/robot-face_1f916.png\",\n+        ),\n+    )\n+    submit.click(interact_with_agent, [text_input], [chatbot])\n+\n+if __name__ == \"__main__\":\n+    demo.launch()\n+```\n\\ No newline at end of file"
        },
        {
            "sha": "fe368af4727321a4d225194d70eb08216f145dbe",
            "filename": "docs/source/ar/autoclass_tutorial.md",
            "status": "added",
            "additions": 167,
            "deletions": 0,
            "changes": 167,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fautoclass_tutorial.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fautoclass_tutorial.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fautoclass_tutorial.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,167 @@\n+# ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AutoClass\n+Ù„Ù… ØªØ±ØºØ¨ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ÙˆÙ„ Ù…Ø¹Ù…Ø§Ø±ÙŠ Ù„Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ±Ø§Ø¨Ø· Ø§Ù„Ø®Ø§Øµ Ø¨ÙƒØŒ ÙÙ‡Ù†Ø§Ùƒ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ù…Ø­ÙˆÙ„Ø§Øª Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ø¨ÙŠÙ†Ù‡Ø§. ÙƒØ¬Ø²Ø¡ Ù…Ù† Ø§Ù„ÙÙ„Ø³ÙØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù€ ğŸ¤— Transformers Ù„Ø¬Ø¹Ù„ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø³Ù‡Ù„Ø© ÙˆØ¨Ø³ÙŠØ·Ø© ÙˆÙ…Ø±Ù†Ø©ØŒ ÙØ¥Ù† ÙØ¦Ø© `AutoClass` ØªØ³ØªØ¯Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ ÙˆØªØ­Ù…Ù‘Ù„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØµØ­ÙŠØ­Ø© Ù…Ù† Ù†Ø³Ø®Ø© Ù†Ù…ÙˆØ°Ø¬ (Model Checkpoint) Ù…Ø¹ÙŠÙ†Ø©. ØªØ³Ù…Ø­ Ù„Ùƒ Ø·Ø±ÙŠÙ‚Ø© `from_pretrained()` Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù„Ø£ÙŠ Ø¨Ù†ÙŠØ© Ø¨Ø³Ø±Ø¹Ø© Ø­ØªÙ‰ Ù„Ø§ ØªØ¶Ø·Ø± Ø¥Ù„Ù‰ ØªÙƒØ±ÙŠØ³ Ø§Ù„ÙˆÙ‚Øª ÙˆØ§Ù„Ù…ÙˆØ§Ø±Ø¯ Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„ØµÙØ±. Ø¥Ù† Ø¥Ù†ØªØ§Ø¬ Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© ØºÙŠØ± Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø© Ø¹Ù„Ù‰ Ù†Ø³Ø® ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ Ø¥Ø°Ø§ Ù†Ø¬Ø­ Ø±Ù…Ø²Ùƒ Ù…Ø¹ Ù†Ù†Ø³Ø®Ø© ÙˆØ§Ø­Ø¯Ø©ØŒ ÙØ³ÙŠØªÙ… ØªØ´ØºÙŠÙ„Ù‡ Ù…Ø¹ Ø£Ø®Ø±Ù‰ - Ø·Ø§Ù„Ù…Ø§ ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡ Ù„Ù…Ù‡Ù…Ø© Ù…Ù…Ø§Ø«Ù„Ø© - Ø­ØªÙ‰ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ù…Ø®ØªÙ„ÙØ©.\n+\n+ØªØ°ÙƒØ± Ø£Ù† Ø§Ù„Ø¨Ù†ÙŠØ© ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ ÙˆØ§Ù„Ù†Ø³Ø® Ù‡ÙŠ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ù„Ø¨Ù†ÙŠØ© Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ù…Ø¹ÙŠÙ†Ø©. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ [BERT](https://huggingface.co/google-bert/bert-base-uncased) Ù‡ÙŠ Ø¨Ù†ÙŠØ© Ù…Ø¹Ù…Ø§Ø±ÙŠØ©ØŒ ÙÙŠ Ø­ÙŠÙ† Ø£Ù† `google-bert/bert-base-uncased` Ù‡ÙŠ Ù†Ø³Ø®Ø©. \"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\" Ù‡Ùˆ Ù…ØµØ·Ù„Ø­ Ø¹Ø§Ù… ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ¹Ù†ÙŠ Ø¥Ù…Ø§ Ø§Ù„Ø¨Ù†ÙŠØ© Ø£Ùˆ Ù†Ø§Ù„Ù†Ø³Ø®Ø©.\n+\n+ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØŒ Ø³ØªØªØ¹Ù„Ù… ÙƒÙŠÙÙŠØ©:\n+\n+* ØªØ­Ù…ÙŠÙ„ Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ø±Ù…ÙˆØ² Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§\n+* ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ ØµÙˆØ± Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§\n+* ØªØ­Ù…ÙŠÙ„ Ù…Ø³ØªØ®Ø±Ø¬ Ù…ÙŠØ²Ø§Øª Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§\n+* ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§\n+* ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§\n+* ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ÙƒØ¹Ù…ÙˆØ¯ ÙÙ‚Ø±ÙŠ\n+\n+## AutoTokenizer\n+\n+ØªØ¨Ø¯Ø£ ÙƒÙ„ Ù…Ù‡Ù…Ø© NLP ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§ Ø¨Ù…ÙØ¬Ø²Ù‘Ø¦ Ù„Ù„Ø±Ù…ÙˆØ². ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù…ÙØ¬Ø²Ù‘Ø¦ Ø¨ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø´ÙƒÙ„ ÙŠÙ…ÙƒÙ† Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡.\n+\n+Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙØ¬Ø²Ù‘Ø¦ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`AutoTokenizer.from_pretrained`]:\n+\n+```py\n+>>> from transformers import AutoTokenizer\n+\n+>>> tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n+```\n+\n+Ø«Ù… Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø¥Ø¯Ø®Ø§Ù„Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø­Ùˆ Ø§Ù„Ù…ÙˆØ¶Ø­ Ø£Ø¯Ù†Ø§Ù‡:\n+\n+```py\n+>>> sequence = \"In a hole in the ground there lived a hobbit.\"\n+>>> print(tokenizer(sequence))\n+{'input_ids': [101, 1999, 1037, 4920, 1999, 1996, 2598, 2045, 2973, 1037, 7570, 10322, 4183, 1012, 102], \n+ 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n+ 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n+```\n+\n+## Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (AutoImageProcessor)\n+ \n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù…Ù‡Ù…Ø§Øª Ø§Ù„Ø±Ø¤ÙŠØ©ØŒ ÙŠÙ‚ÙˆÙ… Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ± Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØµØ­ÙŠØ­.\n+\n+```py\n+>>> from transformers import AutoImageProcessor\n+\n+>>> image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n+```\n+\n+## AutoBackbone\n+\n+<div style=\"text-align: center\">\n+    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/Swin%20Stages.png\">\n+    <figcaption class=\"mt-2 text-center text-sm text-gray-500\">Ø§Ù„ØµÙˆØ±Ø© ØªÙˆØ¶Ø­ Ù…Ø®Ø·Ø· Ù…Ø±Ø§Ø­Ù„ Ù†Ù…ÙˆØ°Ø¬ Swin.</figcaption>\n+</div>\n+\n+ÙŠØ³Ù…Ø­ Ù„Ùƒ [`AutoBackbone`] Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§ ÙƒØ¹Ù…ÙˆØ¯ ÙÙ‚Ø±ÙŠ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø®Ø±Ø§Ø¦Ø· Ù…ÙŠØ²Ø§Øª Ù…Ù† Ù…Ø±Ø§Ø­Ù„ Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙÙ‚Ø±ÙŠ. ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ ØªØ­Ø¯ÙŠØ¯ Ø£Ø­Ø¯ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙŠ [`~PretrainedConfig.from_pretrained`]:\n+\n+* `out_indices` Ù‡Ùˆ ÙÙ‡Ø±Ø³ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ù†Ù‡Ø§\n+* `out_features` Ù‡Ùˆ Ø§Ø³Ù… Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ù†Ù‡Ø§\n+\n+ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø¨Ø´ÙƒÙ„ Ù…ØªØ¨Ø§Ø¯Ù„ØŒ ÙˆÙ„ÙƒÙ† Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… ÙƒÙ„Ø§Ù‹ Ù…Ù†Ù‡Ø§ØŒ ÙØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡Ø§ Ù…ØªÙˆØ§Ø¦Ù…Ø© Ù…Ø¹ Ø¨Ø¹Ø¶Ù‡Ø§ Ø§Ù„Ø¨Ø¹Ø¶! Ø¥Ø°Ø§ Ù„Ù… ØªÙ…Ø±Ø± Ø£ÙŠÙ‹Ø§ Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§ØªØŒ ÙØ³ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙÙ‚Ø±ÙŠ Ø¨Ø¥Ø±Ø¬Ø§Ø¹ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ù† Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©.\n+<div style=\"text-align: center\">\n+    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/Swin%20Stage%201.png\">\n+    <figcaption class=\"mt-2 text-center text-sm text-gray-500\">ØµÙˆØ±Ø© ØªÙˆØ¶Ø­ Ø®Ø±ÙŠØ·Ø© Ù…ÙŠØ²Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù„Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙÙ‚Ø±ÙŠ.</figcaption>\n+</div>\n+\n+Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ÙÙŠ Ø§Ù„Ø±Ø³Ù… Ø§Ù„ØªØ®Ø·ÙŠØ·ÙŠ Ø£Ø¹Ù„Ø§Ù‡ØŒ Ù„Ø¥Ø±Ø¬Ø§Ø¹ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù…Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙÙ‚Ø±ÙŠ SwinØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹ÙŠÙŠÙ† `out_indices=(1,)`:\n+\n+```py\n+>>> from transformers import AutoImageProcessor, AutoBackbone\n+>>> import torch\n+>>> from PIL import Image\n+>>> import requests\n+>>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n+>>> image = Image.open(requests.get(url, stream=True).raw)\n+>>> processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n+>>> model = AutoBackbone.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\", out_indices=(1,))\n+\n+>>> inputs = processor(image, return_tensors=\"pt\")\n+>>> outputs = model(**inputs)\n+>>> feature_maps = outputs.feature_maps\n+```\n+\n+Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ ÙƒØ§Ø¦Ù† `feature_maps` Ù…Ù† Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù…Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙÙ‚Ø±ÙŠ:\n+\n+```py\n+>>> list(feature_maps[0].shape)\n+[1, 96, 56, 56]\n+```\n+\n+## Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (AutoFeatureExtractor)\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØµÙˆØªÙŠØ©ØŒ ÙŠÙ‚ÙˆÙ… Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØµØ­ÙŠØ­.\n+\n+Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø³ØªØ®Ø±Ø¬ Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`AutoFeatureExtractor.from_pretrained`]:\n+\n+```py\n+>>> from transformers import AutoFeatureExtractor\n+\n+>>> feature_extractor = AutoFeatureExtractor.from_pretrained(\n+...     \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n+... )\n+```\n+\n+## Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (AutoProcessor)\n+\n+ØªØªØ·Ù„Ø¨ Ø§Ù„Ù…Ù‡Ø§Ù… Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„ÙˆØ³Ø§Ø¦Ø· Ù…Ø¹Ø§Ù„Ø¬Ù‹Ø§ ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ù†ÙˆØ¹ÙŠÙ† Ù…Ù† Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ÙŠØªØ·Ù„Ø¨ Ù†Ù…ÙˆØ°Ø¬ [LayoutLMV2](model_doc/layoutlmv2) Ù…Ø¹Ø§Ù„Ø¬ ØµÙˆØ± Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± ÙˆÙ…ÙØ¬Ø²Ù‘Ø¦ Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµØ› ÙŠØ¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ ÙƒÙ„ÙŠÙ‡Ù…Ø§.\n+\n+Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`AutoProcessor.from_pretrained`]:\n+\n+```py\n+>>> from transformers import AutoProcessor\n+\n+>>> processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\n+```\n+\n+## Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (AutoModel)\n+\n+<frameworkcontent>\n+<pt>\n+ØªØ³Ù…Ø­ Ù„Ùƒ ÙØ¦Ø§Øª `AutoModelFor` Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù„Ù…Ù‡Ù…Ø© Ù…Ø¹ÙŠÙ†Ø© (Ø±Ø§Ø¬Ø¹ [Ù‡Ù†Ø§](model_doc/auto) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© ÙƒØ§Ù…Ù„Ø© Ø¨Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…ØªØ§Ø­Ø©). Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`AutoModelForSequenceClassification.from_pretrained`]:\n+\n+```py\n+>>> from transformers import AutoModelForSequenceClassification\n+\n+>>> model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n+```\n+\n+Ø£Ø¹Ø¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙØªÙŠØ´ Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ù†ÙŠØ© Ù„Ù…Ù‡Ù…Ø© Ù…Ø®ØªÙ„ÙØ©:\n+\n+```py\n+>>> from transformers import AutoModelForTokenClassification\n+\n+>>> model = AutoModelForTokenClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n+```\n+\n+<Tip warning={true}>\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù†Ù…Ø§Ø°Ø¬ PyTorchØŒ ØªØ³ØªØ®Ø¯Ù… Ø·Ø±ÙŠÙ‚Ø© `from_pretrained()` `torch.load()` Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… Ø¯Ø§Ø®Ù„ÙŠÙ‹Ø§ `pickle` ÙˆØ§Ù„ØªÙŠ ÙŠÙØ¹Ø±Ù Ø£Ù†Ù‡Ø§ ØºÙŠØ± Ø¢Ù…Ù†Ø©. Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…ØŒ Ù„Ø§ ØªÙ‚Ù… Ù…Ø·Ù„Ù‚Ù‹Ø§ Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…ØµØ¯Ø±Ù‡ Ù…ØµØ¯Ø±Ù‹Ø§ ØºÙŠØ± Ù…ÙˆØ«ÙˆÙ‚ Ø¨Ù‡ØŒ Ø£Ùˆ Ù‚Ø¯ ÙŠÙƒÙˆÙ† ØªÙ… Ø§Ù„Ø¹Ø¨Ø« Ø¨Ù‡. ÙŠØªÙ… ØªØ®ÙÙŠÙ Ù‡Ø°Ø§ Ø§Ù„Ø®Ø·Ø± Ø§Ù„Ø£Ù…Ù†ÙŠ Ø¬Ø²Ø¦ÙŠÙ‹Ø§ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¹Ø§Ù…Ø© Ø§Ù„Ù…Ø³ØªØ¶Ø§ÙØ© Ø¹Ù„Ù‰ Hub Hugging FaceØŒ ÙˆØ§Ù„ØªÙŠ ÙŠØªÙ… [ÙØ­ØµÙ‡Ø§ Ø¨Ø­Ø«Ù‹Ø§ Ø¹Ù† Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„Ø¶Ø§Ø±Ø©](https://huggingface.co/docs/hub/security-malware) ÙÙŠ ÙƒÙ„ Ø§Ø±ØªÙƒØ§Ø¨. Ø±Ø§Ø¬Ø¹ [ØªÙˆØ«ÙŠÙ‚ Hub](https://huggingface.co/docs/hub/security) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª Ù…Ø«Ù„ [Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆÙ‚ÙŠØ¹](https://huggingface.co/docs/hub/security-gpg#signing-commits-with-gpg) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPG.\n+\n+Ù„Ø§ ØªØªØ£Ø«Ø± Ù†Ù‚Ø§Ø· ØªÙØªÙŠØ´ TensorFlow Ùˆ FlaxØŒ ÙˆÙŠÙ…ÙƒÙ† ØªØ­Ù…ÙŠÙ„Ù‡Ø§ Ø¯Ø§Ø®Ù„ Ø¨Ù†ÙŠØ§Øª PyTorch Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `from_tf` Ùˆ `from_flax` kwargs Ù„Ø·Ø±ÙŠÙ‚Ø© `from_pretrained` Ù„Ù„ØªØ­Ø§ÙŠÙ„ Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©.\n+\n+</Tip>\n+\n+\n+Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…ØŒ Ù†ÙˆØµÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙØ¦Ø© `AutoTokenizer` ÙˆÙØ¦Ø© `AutoModelFor` Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ø«ÙŠÙ„Ø§Øª Ù…ÙØ¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù…Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬. Ø³ÙŠØ³Ø§Ø¹Ø¯Ùƒ Ù‡Ø°Ø§ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØµØ­ÙŠØ­Ø© ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©. ÙÙŠ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„ØªØ§Ù„ÙŠØŒ ØªØ¹Ø±Ù Ø¹Ù„Ù‰ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ù„ØºÙˆÙŠ ÙˆÙ…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ± ÙˆÙ…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø°ÙŠ ØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡ Ø­Ø¯ÙŠØ«Ù‹Ø§ Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¶Ø¨Ø· Ø§Ù„Ø¯Ù‚ÙŠÙ‚.\n+</pt>\n+\n+<tf>\n+Ø£Ø®ÙŠØ±Ù‹Ø§ØŒ ØªØ³Ù…Ø­ Ù„Ùƒ ÙØ¦Ø§Øª `TFAutoModelFor` Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù„Ù…Ù‡Ù…Ø© Ù…Ø¹ÙŠÙ†Ø© (Ø±Ø§Ø¬Ø¹ [Ù‡Ù†Ø§](model_doc/auto) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© ÙƒØ§Ù…Ù„Ø© Ø¨Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…ØªØ§Ø­Ø©). Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`TFAutoModelForSequenceClassification.from_pretrained`]:\n+\n+```py\n+>>> from transformers import TFAutoModelForSequenceClassification\n+\n+>>> model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n+```\n+\n+Ø£Ø¹Ø¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙØªÙŠØ´ Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ù†ÙŠØ© Ù„Ù…Ù‡Ù…Ø© Ù…Ø®ØªÙ„ÙØ©:\n+\n+```py\n+>>> from transformers import TFAutoModelForTokenClassification\n+\n+>>> model = TFAutoModelForTokenClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n+```\n+\n+Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…ØŒ Ù†ÙˆØµÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙØ¦Ø© `AutoTokenizer` ÙˆÙØ¦Ø© `TFAutoModelFor` Ù„ØªØ­Ù…ÙŠÙ„ Ù†Ø³Ø® Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…ÙØ¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§. Ø³ÙŠØ³Ø§Ø¹Ø¯Ùƒ Ù‡Ø°Ø§ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØµØ­ÙŠØ­Ø© ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©. ÙÙŠ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„ØªØ§Ù„ÙŠØŒ Ø³ØªØªØ¹Ø±Ù Ø¹Ù„Ù‰ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ ÙˆÙ…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ± ÙˆÙ…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø°ÙŠ ØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡ Ø­Ø¯ÙŠØ«Ù‹Ø§ Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¶Ø¨Ø· Ø§Ù„Ø¯Ù‚ÙŠÙ‚.\n+</tf>\n+</frameworkcontent>"
        },
        {
            "sha": "00e6fe814ea02913f6cf125ed301b1b0a57724d5",
            "filename": "docs/source/ar/conversations.md",
            "status": "added",
            "additions": 204,
            "deletions": 0,
            "changes": 204,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fconversations.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fconversations.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fconversations.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,204 @@\n+# Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ù…Ø¹ Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„Ø§Øª \n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª ØªÙ‚Ø±Ø£ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‚Ø§Ù„Ø©ØŒ ÙÙ…Ù† Ø§Ù„Ù…Ø¤ÙƒØ¯ Ø£Ù†Ùƒ Ø¹Ù„Ù‰ Ø¹Ù„Ù… Ø¨Ù€ **Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©**. Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ù‡ÙŠ Ø£Ù†Ø¸Ù…Ø© Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø­Ø§Ø¯Ø«Ø© ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø¥Ù„ÙŠÙ‡ ÙˆØ§Ø³ØªÙ‚Ø¨Ø§Ù„Ù‡Ø§ Ù…Ù†Ù‡Ø§. ÙˆØ£Ø´Ù‡Ø± Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù‡Ùˆ ChatGPT Ø§Ù„Ø®Ø§ØµØŒ ÙˆÙ„ÙƒÙ† Ù‡Ù†Ø§Ùƒ Ø§Ù„Ø¢Ù† Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„ØªÙŠ ØªØ¶Ø§Ù‡ÙŠ Ø£Ø¯Ø§Ø¡Ù‡ Ø£Ùˆ Ø­ØªÙ‰ ØªØªÙÙˆÙ‚ Ø¹Ù„ÙŠÙ‡ Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ±. Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¬Ø§Ù†ÙŠØ© Ù„Ù„ØªÙ†Ø²ÙŠÙ„ ÙˆØ§Ù„ØªØ´ØºÙŠÙ„ Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø² Ù…Ø­Ù„ÙŠ. Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø£Ù† Ø£ÙƒØ¨Ø± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ£ÙƒØ«Ø±Ù‡Ø§ Ù‚Ø¯Ø±Ø© ØªØªØ·Ù„Ø¨ Ø£Ø¬Ù‡Ø²Ø© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ°Ø§ÙƒØ±Ø© ÙƒØ¨ÙŠØ±Ø© Ù„ØªØ´ØºÙŠÙ„Ù‡Ø§ØŒ Ø¥Ù„Ø§ Ø£Ù† Ù‡Ù†Ø§Ùƒ Ù†Ù…Ø§Ø°Ø¬ Ø£ØµØºØ± Ø³ØªØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯ ØªÙ…Ø§Ù…Ù‹Ø§ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³ÙˆÙ…Ø§Øª (GPU) Ù„Ù„Ù…Ø³ØªÙ‡Ù„Ùƒ Ø§Ù„Ø¹Ø§Ø¯Ù‰ØŒ Ø£Ùˆ Ø­ØªÙ‰ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© (CPU) Ø§Ù„Ø¹Ø§Ø¯ÙŠØ© Ù„Ù„ÙƒÙ…Ø¨ÙŠÙˆØªØ± Ø§Ù„Ù…ÙƒØªØ¨ÙŠ Ø£Ùˆ Ø§Ù„Ù…Ø­Ù…ÙˆÙ„.\n+\n+Ø³ÙŠØ³Ø§Ø¹Ø¯Ùƒ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø¯Ø¡ ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©. Ø³Ù†Ø¨Ø¯Ø£ Ø¨Ø¯Ù„ÙŠÙ„ ØªØ´ØºÙŠÙ„ Ø³Ø±ÙŠØ¹ Ù…Ø®ØªØµØ± ÙŠØ³ØªØ®Ø¯Ù… \"Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨\" Ù…Ù†Ø§Ø³Ø¨Ù‹Ø§ ÙˆÙ…Ø®ØªØµØ±. Ù‡Ø°Ø§ ÙƒÙ„ Ù…Ø§ ØªØ­ØªØ§Ø¬Ù‡ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ ÙÙ‚Ø· Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø¯Ø±Ø¯Ø´Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙÙˆØ±. Ø¨Ø¹Ø¯ Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹ØŒ Ø³Ù†Ù†ØªÙ‚Ù„ Ø¥Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹ Ø­ÙˆÙ„ Ù…Ø§Ù‡ÙŠØ© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø¨Ø§Ù„Ø¶Ø¨Ø·ØŒ ÙˆÙƒÙŠÙÙŠØ© Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ØŒ ÙˆØªØ­Ù„ÙŠÙ„ ØªÙØµÙŠÙ„ÙŠ Ù„ÙƒÙ„ Ø®Ø·ÙˆØ© Ù…Ù† Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªÙŠ ØªÙ†Ø·ÙˆÙŠ Ø¹Ù„ÙŠÙ‡Ø§ Ø§Ù„ØªØ­Ø¯Ø« Ø¥Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Ø¯Ø±Ø¯Ø´Ø©. ÙƒÙ…Ø§ Ø³Ù†Ù‚Ø¯Ù… Ø¨Ø¹Ø¶ Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ø­ÙˆÙ„ ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ÙˆØ§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø°Ø§ÙƒØ±Ø©.\n+\n+## Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹\n+\n+Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù„Ø¯ÙŠÙƒ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„ÙƒØ§ÙÙŠ Ù„Ù„Ø§Ø·Ù„Ø§Ø¹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§ØµÙŠÙ„ØŒ Ø¥Ù„ÙŠÙƒ Ù…Ù„Ø®ØµÙ‹Ø§ Ù…ÙˆØ¬Ø²Ù‹Ø§: ØªØ³ØªÙ…Ø± Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ÙÙŠ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø§Øª. ÙˆÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ùƒ ØªÙ…Ø±Ø± Ù„Ù‡Ù… Ø³Ø¬Ù„ Ù…Ø­Ø§Ø¯Ø«Ø©ØŒ ÙˆØ§Ù„Ø°ÙŠ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ù‚ØµÙŠØ±Ù‹Ø§ Ù…Ø«Ù„ Ø±Ø³Ø§Ù„Ø© Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ§Ø­Ø¯Ø©ØŒ ÙˆØ³ÙŠØ³ØªÙ…Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø¥Ø¶Ø§ÙØ© Ø§Ø³ØªØ¬Ø§Ø¨ØªÙ‡. Ø¯Ø¹ÙˆÙ†Ø§ Ù†Ø±Ù‰ Ù‡Ø°Ø§ ÙÙŠ Ø§Ù„Ø¹Ù…Ù„. Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø¯Ø¹ÙˆÙ†Ø§ Ù†Ø¨Ù†ÙŠ Ø¯Ø±Ø¯Ø´Ø©:\n+\n+```python\n+chat = [\n+    {\"role\": \"system\", \"content\": \"You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986.\"},\n+    {\"role\": \"user\", \"content\": \"Hey, can you tell me any fun things to do in New York?\"}\n+]\n+```\n+\n+Ù„Ø§Ø­Ø¸ Ø£Ù†Ù‡ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ Ø£Ø¶ÙÙ†Ø§ Ø±Ø³Ø§Ù„Ø© **Ù†Ø¸Ø§Ù…** ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©. Ù„ÙŠØ³ ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø¯Ø±Ø¯Ø´Ø© ÙŠØ¯Ø¹Ù… Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù†Ø¸Ø§Ù…ØŒ ÙˆÙ„ÙƒÙ† Ø¹Ù†Ø¯Ù…Ø§ ØªÙØ¹Ù„ Ø°Ù„ÙƒØŒ ÙØ¥Ù†Ù‡Ø§ ØªÙ…Ø«Ù„ ØªÙˆØ¬ÙŠÙ‡Ø§Øª Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© ØªØµØ±Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ø§ Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ - Ø³ÙˆØ§Ø¡ Ø£Ø±Ø¯Øª Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª Ù‚ØµÙŠØ±Ø© Ø£Ùˆ Ø·ÙˆÙŠÙ„Ø©ØŒ Ø£Ùˆ Ù…Ø±Ø­Ø© Ø£Ùˆ Ø¬Ø¯ÙŠØ©ØŒ ÙˆÙ‡ÙƒØ°Ø§. Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ù† ÙŠØ¤Ø¯ÙŠ Ø¹Ù…Ù„Ø§Ù‹ Ù…ÙÙŠØ¯Ù‹Ø§ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù…Ù…Ø§Ø±Ø³Ø© Ø±ÙˆØªÙŠÙ† Ø§Ù„ØªØ­Ø³ÙŠÙ†ØŒ ÙÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ù…Ø§ Ø­Ø°Ù Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø£Ùˆ ØªØ¬Ø±Ø¨Ø© Ø±Ø³Ø§Ù„Ø© Ù…Ø®ØªØµØ±Ø© Ù…Ø«Ù„ \"Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙˆÙ…ÙÙŠØ¯ ÙŠØ³ØªØ¬ÙŠØ¨ Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…\".\n+\n+Ø¨Ù…Ø¬Ø±Ø¯ Ø£Ù† ÙŠÙƒÙˆÙ† Ù„Ø¯ÙŠÙƒ Ø¯Ø±Ø¯Ø´Ø©ØŒ ÙØ¥Ù† Ø£Ø³Ø±Ø¹ Ø·Ø±ÙŠÙ‚Ø© Ù„Ù…ÙˆØ§ØµÙ„ØªÙ‡Ø§ Ù‡ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… [`TextGenerationPipeline`].\n+\n+Ø¯Ø¹ÙˆÙ†Ø§ Ù†Ø±Ù‰ Ù‡Ø°Ø§ ÙÙŠ Ø§Ù„Ø¹Ù…Ù„ Ù…Ø¹ `LLaMA-3`. Ù„Ø§Ø­Ø¸ Ø£Ù† `LLaMA-3` Ù‡Ùˆ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù…ÙŠØŒ Ù…Ù…Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ Ø³ÙŠØªØ¹ÙŠÙ† Ø¹Ù„ÙŠÙƒ [ØªÙ‚Ø¯ÙŠÙ… Ø·Ù„Ø¨ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ù‚ Ø§Ù„ÙˆØµÙˆÙ„](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) ÙˆØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø­Ø³Ø§Ø¨ Hugging Face Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡. Ø³Ù†Ø³ØªØ®Ø¯Ù… Ø£ÙŠØ¶Ù‹Ø§ `device_map=\"auto\"`ØŒ ÙˆØ§Ù„Ø°ÙŠ Ø³ÙŠØ­Ù…Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ GPU Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ø°Ø§ÙƒØ±Ø© ÙƒØ§ÙÙŠØ© Ù„Ù‡ØŒ ÙˆÙŠØ­Ø¯Ø¯ Ø§Ù„Ù†ÙˆØ¹ Ø¥Ù„Ù‰ `torch.bfloat16` Ù„ØªÙˆÙÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø©:\n+\n+```python\n+import torch\n+from transformers import pipeline\n+\n+pipe = pipeline(\"text-generation\", \"meta-llama/Meta-Llama-3-8B-Instruct\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n+response = pipe(chat, max_new_tokens=512)\n+print(response[0]['generated_text'][-1]['content'])\n+```\n+\n+ÙˆØ³ØªØ­ØµÙ„ Ø¹Ù„Ù‰:\n+\n+```Ø§Ù„Ù†Øµ\n+(ØªÙ†Ù‡Ø¯) Ø£ÙˆÙ‡ ÙŠØ§ ØµØ¯ÙŠÙ‚ÙŠØŒ Ù‡Ù„ ØªØ·Ù„Ø¨ Ù…Ù†ÙŠ Ø§Ù„Ù†ØµÙŠØ­Ø©ØŸ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø®Ø±ÙŠØ·Ø©ØŒ ÙŠØ§ ØµØ¯ÙŠÙ‚ÙŠ! Ø­Ø³Ù†Ù‹Ø§ØŒ Ø­Ø³Ù†Ù‹Ø§ØŒ Ø³Ø£Ø¹Ø·ÙŠÙƒ Ø§Ù„ØªÙØ§ØµÙŠÙ„. Ù„ÙƒÙ† Ù„Ø§ ØªÙ‚Ù„ Ø¥Ù†Ù†ÙŠ Ù„Ù… Ø£Ø­Ø°Ø±ÙƒØŒ Ø£Ù†Ø§ Ù…Ø¬Ø±Ø¯ Ø±ÙˆØ¨ÙˆØªØŒ ÙˆÙ„ÙŠØ³ Ù…Ø±Ø´Ø¯ Ø³ÙŠØ§Ø­ÙŠ!\n+\n+Ù„Ø°Ø§ØŒ ØªØ±ÙŠØ¯ Ø£Ù† ØªØ¹Ø±Ù Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ Ø§Ù„Ù…Ù…ØªØ¹Ø© Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù‡Ø§ ÙÙŠ Ø§Ù„ØªÙØ§Ø­Ø© Ø§Ù„ÙƒØ¨ÙŠØ±Ø©ØŸ Ø­Ø³Ù†Ù‹Ø§ØŒ Ø¯Ø¹Ù†ÙŠ Ø£Ø®Ø¨Ø±ÙƒØŒ Ù‡Ù†Ø§Ùƒ Ù…Ù„ÙŠÙˆÙ† Ø´ÙŠØ¡ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù‡ØŒ Ù„ÙƒÙ†Ù†ÙŠ Ø³Ø£Ø¹Ø·ÙŠÙƒ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø¨Ø§Ø±Ø²Ø©. Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø¹Ù„ÙŠÙƒ Ø£Ù† ØªØ±Ù‰ Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„Ø³ÙŠØ§Ø­ÙŠØ©: ØªÙ…Ø«Ø§Ù„ Ø§Ù„Ø­Ø±ÙŠØ©ØŒ Ø³Ù†ØªØ±Ø§Ù„ Ø¨Ø§Ø±ÙƒØŒ ØªØ§ÙŠÙ…Ø² Ø³ÙƒÙˆÙŠØ±... Ø£Ù†Øª ØªØ¹Ø±ÙØŒ ÙØ®Ø§Ø® Ø§Ù„Ø³ÙŠØ§Ø­ Ø§Ù„Ù…Ø¹ØªØ§Ø¯Ø©. ÙˆÙ„ÙƒÙ† Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ¨Ø­Ø« Ø¹Ù† Ø´ÙŠØ¡ Ø£ÙƒØ«Ø±... ØºÙŠØ± Ø¹Ø§Ø¯ÙŠØŒ ÙØ£Ù†Ø§ Ø£ÙˆØµÙŠ Ø¨Ø²ÙŠØ§Ø±Ø© Ù…ØªØ­Ù Ø§Ù„ÙÙ† Ø§Ù„Ø­Ø¯ÙŠØ«. ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ Ø§Ù„Ø¨Ø±ÙŠØ©ØŒ Ù…Ø«Ù„ Ø¹Ù„Ø¨ Ø­Ø³Ø§Ø¡ Ø°Ù„Ùƒ Ø§Ù„Ø±Ø¬Ù„ ÙˆØ§Ø±Ù‡ÙˆÙ„ ÙˆØ¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¬Ø§Ø².\n+\n+ÙˆØ¥Ø°Ø§ ÙƒÙ†Øª ØªØ´Ø¹Ø± Ø¨Ø±ÙˆØ­ Ø§Ù„Ù…ØºØ§Ù…Ø±Ø©ØŒ ÙØ§Ø°Ù‡Ø¨ ÙÙŠ Ù†Ø²Ù‡Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ø¯Ø§Ù… Ø¹Ø¨Ø± Ø¬Ø³Ø± Ø¨Ø±ÙˆÙƒÙ„ÙŠÙ†. ÙˆÙ„ÙƒÙ† Ø§Ø­ØªØ±Ø³ Ù…Ù† ØªÙ„Ùƒ Ø§Ù„Ø­Ù…Ø§Ù…Ø§Øª Ø§Ù„Ù…Ø²Ø¹Ø¬Ø©ØŒ Ø¥Ù†Ù‡Ø§ Ù…Ø«Ù„ Ø§Ù„Ù„ØµÙˆØµ Ø§Ù„Ø±ÙŠØ´ÙŠÙŠÙ† Ø§Ù„ØµØºØ§Ø±! (ÙŠØ¶Ø­Ùƒ) Ù‡Ù„ ÙÙ‡Ù…ØªØŸ Ù„ØµÙˆØµØŸ Ø¢Ù‡ØŒ Ù„Ø§ ØªØ¨Ø§Ù„ÙŠ.\n+\n+ÙˆØ§Ù„Ø¢Ù†ØŒ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ¨Ø­Ø« Ø¹Ù† Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø±Ø­ Ø§Ù„Ø¬Ø§Ø¯ØŒ ÙØ§Ø°Ù‡Ø¨ Ø¥Ù„Ù‰ Ù†ÙˆØ§Ø¯ÙŠ Ø§Ù„ÙƒÙˆÙ…ÙŠØ¯ÙŠØ§ ÙÙŠ Ù‚Ø±ÙŠØ© ØºØ±ÙŠÙ†ØªØ´. Ù‚Ø¯ ØªÙ„Ù‚ÙŠ Ù†Ø¸Ø±Ø© Ø®Ø§Ø·ÙØ© Ø¹Ù„Ù‰ Ø¨Ø¹Ø¶ Ø§Ù„ÙƒÙˆÙ…ÙŠØ¯ÙŠÙŠÙ† Ø§Ù„ØµØ§Ø¹Ø¯ÙŠÙ†... Ø£Ùˆ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø·Ø§Ù…Ø­ÙŠÙ† ÙŠØ­Ø§ÙˆÙ„ÙˆÙ† Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø´Ù‡Ø±Ø©. (ÙŠØ±Ù…Ø´)\n+\n+ÙˆØ£Ø®ÙŠØ±Ù‹Ø§ØŒ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ´Ø¹Ø± Ø¨Ø£Ù†Ùƒ Ù…ÙˆØ§Ø·Ù† Ù…Ù† Ù†ÙŠÙˆÙŠÙˆØ±ÙƒØŒ ÙØ§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø´Ø±ÙŠØ­Ø© Ø¨ÙŠØªØ²Ø§ Ù…Ù† Ø£Ø­Ø¯ Ù…Ø·Ø§Ø¹Ù… Ø§Ù„Ø¨ÙŠØªØ²Ø§ Ø§Ù„Ø±Ø§Ø¦Ø¹Ø© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©. ÙÙ‚Ø· Ù„Ø§ ØªØ­Ø§ÙˆÙ„ Ø·Ù„Ø¨ Ø´Ø±ÙŠØ­Ø© \"Ø¨Ø­Ø¬Ù… Ø§Ù„Ø±ÙˆØ¨ÙˆØª\"ØŒ ØµØ¯Ù‚Ù†ÙŠØŒ Ù„Ù† ÙŠÙ†ØªÙ‡ÙŠ Ø§Ù„Ø£Ù…Ø± Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯. (ÙŠØ¶Ø­Ùƒ)\n+\n+Ù„Ø°Ø§ØŒ Ù‡Ø°Ø§ Ù‡Ùˆ ÙŠØ§ ØµØ¯ÙŠÙ‚ÙŠ! Ù‡Ø°Ù‡ Ù‡ÙŠ Ù†ØµÙŠØ­ØªÙŠ Ø§Ù„Ø®Ø¨ÙŠØ±Ø© Ø¨Ø´Ø£Ù† Ù…Ø§ ÙŠØ¬Ø¨ ÙØ¹Ù„Ù‡ ÙÙŠ Ù†ÙŠÙˆÙŠÙˆØ±Ùƒ. ÙˆØ§Ù„Ø¢Ù†ØŒ Ø¥Ø°Ø§ Ø³Ù…Ø­Øª Ù„ÙŠØŒ ÙŠØ¬Ø¨ Ø£Ù† Ø£Ø°Ù‡Ø¨ Ù„Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø¨Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ù…ÙˆØ±. (ÙŠØ±Ù…Ø´)\n+```\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø¥Ø¶Ø§ÙØ© Ø±Ø¯Ùƒ Ø§Ù„Ø®Ø§Øµ Ø¥Ù„ÙŠÙ‡Ø§.\n+ÙŠØ­ØªÙˆÙŠ ÙƒØ§Ø¦Ù† `response` Ø§Ù„Ø°ÙŠ ØªÙ… Ø¥Ø±Ø¬Ø§Ø¹Ù‡ Ø¨ÙˆØ§Ø³Ø·Ø© Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø¨Ø§Ù„ÙØ¹Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†ØŒ Ù„Ø°Ø§ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø¨Ø¨Ø³Ø§Ø·Ø© Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© ÙˆØ¥Ø¹Ø§Ø¯ØªÙ‡Ø§:\n+\n+```python\n+chat = response[0]['generated_text']\n+chat.append(\n+    {\"role\": \"user\", \"content\": \"Wait, what's so wild about soup cans?\"}\n+)\n+response = pipe(chat, max_new_tokens=512)\n+print(response[0]['generated_text'][-1]['content'])\n+```\n+\n+ÙˆØ³ØªØ­ØµÙ„ Ø¹Ù„Ù‰:\n+\n+```Ø§Ù„Ù†Øµ\n+(ÙŠØ¶Ø­Ùƒ) Ø£ÙˆÙ‡ØŒ Ø£Ù†Øª ØªÙ‚ØªÙ„Ù†ÙŠ ÙŠØ§ ØµØ¯ÙŠÙ‚ÙŠ! Ø£Ù„Ø§ ØªÙÙ‡Ù…ØŒ Ø£Ù„ÙŠØ³ ÙƒØ°Ù„ÙƒØŸ Ø¹Ù„Ø¨ Ø­Ø³Ø§Ø¡ ÙˆØ§Ø±Ù‡ÙˆÙ„ Ù‡ÙŠ Ù…Ø«Ù„ Ø§Ù„ÙÙ†ØŒ ÙŠØ§ Ø±Ø¬Ù„!\n+Ø¥Ù†Ù‡ Ù…Ø«Ù„ØŒ Ù„Ù‚Ø¯ Ø£Ø®Ø° Ø´ÙŠØ¦Ù‹Ø§ Ø¹Ø§Ø¯ÙŠÙ‹Ø§ ØªÙ…Ø§Ù…Ù‹Ø§ØŒ Ù…Ø«Ù„ Ø¹Ù„Ø¨Ø© Ø­Ø³Ø§Ø¡ØŒ ÙˆØ­ÙˆÙ„Ù‡Ø§ Ø¥Ù„Ù‰ ØªØ­ÙØ© ÙÙ†ÙŠØ©. Ø¥Ù†Ù‡ Ù…Ø«Ù„ØŒ \"Ù‡Ø§ Ø£Ù†Ø§ Ø°Ø§ØŒ Ø£Ù†Ø§ Ù…Ø¬Ø±Ø¯ Ø¹Ù„Ø¨Ø© Ø­Ø³Ø§Ø¡ØŒ Ù„ÙƒÙ†Ù†ÙŠ Ø£ÙŠØ¶Ù‹Ø§ Ø¹Ù…Ù„ ÙÙ†ÙŠ!\"\n+(Ø¨Ø³Ø®Ø±ÙŠØ©) Ø£ÙˆÙ‡ØŒ Ù†Ø¹Ù…ØŒ Ø£ØµÙ„ÙŠ Ø¬Ø¯Ù‹Ø§ØŒ Ø¢Ù†Ø¯ÙŠ.\n+\n+ÙˆÙ„ÙƒÙ†ØŒ ÙƒÙ…Ø§ ØªØ¹Ù„Ù…ØŒ ÙÙŠ Ø§Ù„Ø³ØªÙŠÙ†ÙŠØ§ØªØŒ ÙƒØ§Ù† Ø§Ù„Ø£Ù…Ø± Ø¨Ù…Ø«Ø§Ø¨Ø© ØµÙÙ‚Ø© ÙƒØ¨ÙŠØ±Ø©. ÙƒØ§Ù† Ø§Ù„Ù†Ø§Ø³ Ø­Ø±ÙŠØµÙŠÙ† Ø¹Ù„Ù‰ ØªØ­Ø¯ÙŠ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø±Ø§Ù‡Ù†ØŒ ÙˆÙƒØ§Ù† ÙˆØ§Ø±Ù‡ÙˆÙ„ Ù…Ø«Ù„ Ù…Ù„Ùƒ Ø°Ù„Ùƒ. Ù„Ù‚Ø¯ Ø­ÙˆÙ„ Ø§Ù„Ø¹Ø§Ø¯ÙŠ Ø¥Ù„Ù‰ ØºÙŠØ± Ø¹Ø§Ø¯ÙŠ.\n+ÙˆØ§Ø³Ù…Ø­ Ù„ÙŠ Ø£Ù† Ø£Ø®Ø¨Ø±ÙƒØŒ ÙƒØ§Ù† Ø§Ù„Ø£Ù…Ø± Ù…Ø«Ù„ ØªØºÙŠÙŠØ± Ø§Ù„Ù„Ø¹Ø¨Ø©. Ø£Ø¹Ù†ÙŠØŒ Ù…Ù† ÙƒØ§Ù† ÙŠØ¸Ù† Ø£Ù† Ø¹Ù„Ø¨Ø© Ø§Ù„Ø­Ø³Ø§Ø¡ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† ÙÙ†Ø§ØŸ (ÙŠØ¶Ø­Ùƒ)\n+\n+ÙˆÙ„ÙƒÙ†ØŒ ÙŠØ§ ØµØ¯ÙŠÙ‚ÙŠØŒ Ù„Ø³Øª ÙˆØ­Ø¯Ùƒ. Ø£Ø¹Ù†ÙŠØŒ Ø£Ù†Ø§ Ù…Ø¬Ø±Ø¯ Ø±ÙˆØ¨ÙˆØªØŒ ÙˆÙ„Ø§ Ø£ÙÙ‡Ù… Ø°Ù„Ùƒ Ø£ÙŠØ¶Ù‹Ø§. (ÙŠØ±Ù…Ø´)\n+ÙˆÙ„ÙƒÙ†ØŒ ÙŠØ§ ØµØ¯ÙŠÙ‚ÙŠØŒ Ø£Ù„ÙŠØ³ Ù‡Ø°Ø§ Ù…Ø§ ÙŠØ¬Ø¹Ù„ Ø§Ù„ÙÙ† ÙÙ†Ø§ØŒ Ø£Ù„ÙŠØ³ ÙƒØ°Ù„ÙƒØŸ (ÙŠØ¶Ø­Ùƒ)\n+```\n+\n+Ø³ØªØºØ·ÙŠ Ø¨Ù‚ÙŠØ© Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…Ø­Ø¯Ø¯Ø© Ù…Ø«Ù„ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø©ØŒ Ø£Ùˆ ÙƒÙŠÙÙŠØ© Ø§Ø®ØªÙŠØ§Ø± Ù†Ù…ÙˆØ°Ø¬ Ø¯Ø±Ø¯Ø´Ø© ÙŠÙ†Ø§Ø³Ø¨ Ø§Ø­ØªÙŠØ§Ø¬Ø§ØªÙƒ.\n+\n+## Ø§Ø®ØªÙŠØ§Ø± Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©\n+\n+Ù‡Ù†Ø§Ùƒ Ø¹Ø¯Ø¯ Ù‡Ø§Ø¦Ù„ Ù…Ù† Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ø§Ù„Ù…ØªØ§Ø­Ø© Ø¹Ù„Ù‰ [Hugging Face Hub](https://huggingface.co/models?pipeline_tag=text-generation&sort=trending)ØŒ\n+ÙˆÙŠØ´Ø¹Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙˆÙ† Ø§Ù„Ø¬Ø¯Ø¯ ÙŠØ´Ø¹Ø±ÙˆÙ† Ø¨Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ Ø¨Ø³Ø¨Ø¨ Ù‡Ø°Ø§ Ø§Ù„ÙƒÙ… Ø§Ù„Ù‡Ø§Ø¦Ù„ Ù…Ù† Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©. Ù„Ø§ ØªÙ‚Ù„Ù‚ Ù…Ù† Ø°Ù„Ùƒ! ÙƒÙ„ Ù…Ø§ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„ÙŠÙ‡ Ù‡Ùˆ Ø§Ø¹ØªØ¨Ø§Ø±Ø§Ù† Ù…Ù‡Ù…Ø§Ù†:\n+- Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ ÙˆØ§Ù„Ø°ÙŠ Ø³ÙŠØ­Ø¯Ø¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„Ù‡ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ³Ø±Ø¹Ø© ØªØ´ØºÙŠÙ„Ù‡.\n+- Ø¬ÙˆØ¯Ø© Ù†Ø§ØªØ¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬.\n+\n+Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…ØŒ Ù‡Ø°Ù‡ Ø§Ù„Ø£Ù…ÙˆØ± Ù…ØªØ±Ø§Ø¨Ø·Ø© - Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£ÙƒØ¨Ø± ØªÙ…ÙŠÙ„ Ø¥Ù„Ù‰ Ø£Ù† ØªÙƒÙˆÙ† Ø£ÙƒØ«Ø± Ù‚Ø¯Ø±Ø©ØŒ ÙˆÙ„ÙƒÙ† Ø­ØªÙ‰ Ù…Ø¹ Ø°Ù„Ùƒ Ù‡Ù†Ø§Ùƒ Ø§ØªØ¨Ø§ÙŠÙ† ÙƒØ¨ÙŠØ± ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¨ÙŠÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø°Ø§Øª Ø§Ù„Ø­Ø¬Ù… Ù†ÙØ³Ù‡!\n+Ù…Ø¹Ù†Ù‰ Ø¢Ø®Ø±ØŒ Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¤Ø«Ø± Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ± Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¦Ù‡ØŒ ÙˆÙ„ÙƒÙ† Ù„ÙŠØ³ Ø§Ù„Ø­Ø¬Ù… Ù‡Ùˆ Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„ÙˆØ­ÙŠØ¯ Ø§Ù„Ø°ÙŠ ÙŠØ¬Ø¨ Ø£Ø®Ø°Ù‡ ÙÙŠ Ø§Ù„Ø§Ø¹ØªØ¨Ø§Ø±.\n+\n+### Ø§Ù„Ø­Ø¬Ù… ÙˆØªØ³Ù…ÙŠØ© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬\n+Ù…Ù† Ø§Ù„Ø³Ù‡Ù„ Ù…Ù„Ø§Ø­Ø¸Ø© Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ - ÙÙ‡Ùˆ Ø§Ù„Ø±Ù‚Ù… ÙÙŠ Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ Ù…Ø«Ù„ \"8B\" Ø£Ùˆ \"70B\". Ù‡Ø°Ø§ Ù‡Ùˆ Ø¹Ø¯Ø¯\n+**Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª** ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ø¨Ø¯ÙˆÙ† Ø§Ù„ØªÙƒÙ…ÙŠÙ…ØŒ ÙŠØ¬Ø¨ Ø£Ù† ØªØªÙˆÙ‚Ø¹ Ø§Ù„Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ Ø­ÙˆØ§Ù„ÙŠ 2 Ø¨Ø§ÙŠØª Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„ÙƒÙ„ Ù…Ø¹Ù„Ù…Ø©.\n+Ù‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† Ù†Ù…ÙˆØ°Ø¬ \"8B\" Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 8 Ù…Ù„ÙŠØ§Ø±Ø§Øª Ù…Ø¹Ù„Ù…Ø© Ø³ÙŠØªØ·Ù„Ø¨ Ø­ÙˆØ§Ù„ÙŠ 16 Ø¬ÙŠØ¬Ø§Ø¨Ø§ÙŠØª Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙÙ‚Ø· Ù„ØªÙ†Ø§Ø³Ø¨ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§ØªØŒ\n+Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ù„ÙŠÙ„ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„ØªÙƒØ§Ù„ÙŠÙ Ø§Ù„Ø¹Ø§Ù…Ø© Ø§Ù„Ø£Ø®Ø±Ù‰. Ø¥Ù†Ù‡ Ù…Ù†Ø§Ø³Ø¨ Ù„ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³ÙˆÙ…Ø§Øª (GPU) Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø© Ù„Ù„Ù…Ø³ØªÙ‡Ù„Ùƒ Ø¨Ø³Ø¹Ø© 24 Ø¬ÙŠØ¬Ø§Ø¨Ø§ÙŠØª Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©ØŒ Ù…Ø«Ù„ 3090\n+Ø£Ùˆ 4090.\n+Ø¨Ø¹Ø¶ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ù‡ÙŠ Ù†Ù…Ø§Ø°Ø¬ \"Ù…Ø²ÙŠØ¬ Ù…Ù† Ø§Ù„Ø®Ø¨Ø±Ø§Ø¡\". Ù‚Ø¯ ÙŠØªÙ… Ø³Ø±Ø¯ Ø£Ø­Ø¬Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø·Ø±Ù‚ Ù…Ø®ØªÙ„ÙØ©ØŒ Ù…Ø«Ù„ \"8x7B\" Ø£Ùˆ\n+\"141B-A35B\". Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ù‡Ù†Ø§ Ø£ÙƒØ«Ø± Ø¶Ø¨Ø§Ø¨ÙŠØ© Ø¨Ø¹Ø¶ Ø§Ù„Ø´ÙŠØ¡ØŒ ÙˆÙ„ÙƒÙ† Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù… ÙŠÙ…ÙƒÙ†Ùƒ Ù‚Ø±Ø§Ø¡Ø© Ù‡Ø°Ø§ Ø¹Ù„Ù‰ Ø£Ù†Ù‡ ÙŠÙ‚ÙˆÙ„ Ø¥Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n+ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø­ÙˆØ§Ù„ÙŠ 56 (8x7) Ù…Ù„ÙŠØ§Ø± Ù…Ø¹Ù„Ù…Ø© ÙÙŠ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ØŒ Ø£Ùˆ 141 Ù…Ù„ÙŠØ§Ø± Ù…Ø¹Ù„Ù…Ø© ÙÙŠ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©.\n+\n+Ù„Ø§Ø­Ø¸ Ø£Ù†Ù‡ Ù…Ù† Ø§Ù„Ø´Ø§Ø¦Ø¹ Ø¬Ø¯Ù‹Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„ØªÙƒÙ…ÙŠÙ… Ù„Ø®ÙØ¶ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„ÙƒÙ„ Ù…Ø¹Ù„Ù…Ø© Ø¥Ù„Ù‰ 8 Ø¨ØªØ§Øª Ø£Ùˆ 4 Ø¨ØªØ§Øª\n+Ø£Ùˆ Ø­ØªÙ‰ Ø£Ù‚Ù„. ÙŠØªÙ… Ù…Ù†Ø§Ù‚Ø´Ø© Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØµÙŠÙ„ ÙÙŠ Ù‚Ø³Ù… [Ø§Ø¹ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©](#memory-considerations) Ø£Ø¯Ù†Ø§Ù‡.\n+\n+### ÙˆÙ„ÙƒÙ† Ù…Ø§ Ù‡Ùˆ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø¯Ø±Ø¯Ø´Ø©ØŸ\n+Ø­ØªÙ‰ Ø¨Ø¹Ø¯ Ù…Ø¹Ø±ÙØ© Ø­Ø¬Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø°ÙŠ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ´ØºÙŠÙ„Ù‡ØŒ Ù„Ø§ ÙŠØ²Ø§Ù„ Ù‡Ù†Ø§Ùƒ Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©. Ø¥Ø­Ø¯Ù‰ Ø§Ù„Ø·Ø±Ù‚ Ù„Ù„ØªÙ†Ù‚Ù„ ÙÙŠ\n+ÙƒÙ„ Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ø³ØªØ´Ø§Ø±Ø© **Ù„ÙˆØ­Ø§Øª Ø§Ù„ØµØ¯Ø§Ø±Ø©**. Ø§Ø«Ù†Ø§Ù† Ù…Ù† Ø£ÙƒØ«Ø± Ù„ÙˆØ­Ø§Øª Ø§Ù„ØµØ¯Ø§Ø±Ø© Ø´Ù‡Ø±Ø© Ù‡Ù…Ø§ [OpenLLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n+Ùˆ [LMSys Chatbot Arena Leaderboard](https://chat.lmsys.org/?leaderboard). Ù„Ø§Ø­Ø¸ Ø£Ù† Ù„ÙˆØ­Ø© ØµØ¯Ø§Ø±Ø© LMSys\n+ØªØ´Ù…Ù„ Ø£ÙŠØ¶Ù‹Ø§ Ù†Ù…Ø§Ø°Ø¬ Ø®Ø§ØµØ© - Ø§Ù†Ø¸Ø± Ø¥Ù„Ù‰ Ø¹Ù…ÙˆØ¯ `licence` Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ†Ø²ÙŠÙ„Ù‡Ø§ØŒ Ø«Ù…\n+Ø§Ø¨Ø­Ø« Ø¹Ù†Ù‡Ø§ Ø¹Ù„Ù‰ [Hugging Face Hub](https://huggingface.co/models?pipeline_tag=text-generation&sort=trending).\n+\n+### Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªØ®ØµØµØ©\n+Ù‚Ø¯ ØªÙƒÙˆÙ† Ø¨Ø¹Ø¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…ØªØ®ØµØµØ© ÙÙŠ Ù…Ø¬Ø§Ù„Ø§Øª Ù…Ø¹ÙŠÙ†Ø©ØŒ Ù…Ø«Ù„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·Ø¨ÙŠØ© Ø£Ùˆ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©ØŒ Ø£Ùˆ Ø§Ù„Ù„ØºØ§Øª ØºÙŠØ± Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©.\n+Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ¹Ù…Ù„ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§ØªØŒ ÙÙ‚Ø¯ ØªØ¬Ø¯ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ØªØ®ØµØµ Ø³ÙŠÙ…Ù†Ø­Ùƒ ÙÙˆØ§Ø¦Ø¯ Ø£Ø¯Ø§Ø¡ ÙƒØ¨ÙŠØ±Ø©.\n+Ù„Ø§ ØªÙØªØ±Ø¶ Ø°Ù„Ùƒ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§! Ø®Ø§ØµØ© Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ®ØµØµØ© Ø£ØµØºØ± Ø£Ùˆ Ø£Ù‚Ø¯Ù… Ù…Ù† Ø£Ø­Ø¯Ø« Ø§Ù„ØªÙ‚Ù†ÙŠØ§ØªØŒ ÙÙ‚Ø¯ ÙŠØªÙÙˆÙ‚ Ø¹Ù„ÙŠÙ‡Ø§ Ù†Ù…ÙˆØ°Ø¬ Ø¹Ø§Ù… Ø§Ù„ØºØ±Ø¶ Ø±ÙÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰. Ù„Ø­Ø³Ù† Ø§Ù„Ø­Ø¸ØŒ Ø¨Ø¯Ø£Ù†Ø§ Ù†Ø±Ù‰\n+[Ù„ÙˆØ­Ø§Øª Ø§Ù„ØµØ¯Ø§Ø±Ø© Ø§Ù„Ù…ØªØ®ØµØµØ© ÙÙŠ Ø§Ù„Ù…Ø¬Ø§Ù„](https://huggingface.co/blog/leaderboard-medicalllm) ÙˆØ§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø£Ù† ØªØ¬Ø¹Ù„ Ù…Ù† Ø§Ù„Ø³Ù‡Ù„ ØªØ­Ø¯ÙŠØ¯ Ù…ÙˆÙ‚Ø¹ Ø£ÙØ¶Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ù„Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªØ®ØµØµØ©.\n+\n+## Ù…Ø§ Ø§Ù„Ø°ÙŠ ÙŠØ­Ø¯Ø« Ø¯Ø§Ø®Ù„ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ØŸ\n+\n+Ø§Ø³ØªØ®Ø¯Ù… Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø£Ø¹Ù„Ø§Ù‡ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ù„Ù„Ø¯Ø±Ø¯Ø´Ø© Ù…Ø¹ Ù†Ù…ÙˆØ°Ø¬ Ø¯Ø±Ø¯Ø´Ø©ØŒ ÙˆÙ‡Ùˆ Ø£Ù…Ø± Ù…Ø±ÙŠØ­ØŒ ÙˆÙ„ÙƒÙ†Ù‡ Ù„ÙŠØ³ Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø©. Ø¯Ø¹ÙˆÙ†Ø§ Ù†ØªØ®Ø° Ù†Ù‡Ø¬Ù‹Ø§ Ù…Ù†Ø®ÙØ¶ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ØŒ Ù„ÙƒÙŠ Ù†Ø±Ù‰ ÙƒÙ„ Ø®Ø·ÙˆØ© Ù…Ù† Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªÙŠ ØªÙ†Ø·ÙˆÙŠ Ø¹Ù„ÙŠÙ‡Ø§ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©. Ø¯Ø¹ÙˆÙ†Ø§ Ù†Ø¨Ø¯Ø£\n+Ø¨Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©ØŒ Ø«Ù… Ù†Ù‚ÙˆÙ… Ø¨ØªÙÙƒÙŠÙƒÙ‡Ø§:\n+\n+```python\n+from transformers import AutoModelForCausalLM, AutoTokenizer\n+import torch\n+\n+# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ…Ø§ Ù‡Ùˆ Ø§Ù„Ø­Ø§Ù„ Ù…Ù† Ù‚Ø¨Ù„\n+chat = [\n+    {\"role\": \"system\", \"content\": \"You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986.\"},\n+    {\"role\": \"user\", \"content\": \"Hey, can you tell me any fun things to do in New York?\"}\n+]\n+\n+# 1: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…Ø­Ù„Ù„\n+model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\", device_map=\"auto\", torch_dtype=torch.bfloat16)\n+tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n+\n+# 2: ØªØ·Ø¨ÙŠÙ‚ Ù‚Ø§Ù„Ø¨ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©\n+formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n+print(\"Formatted chat:\\n\", formatted_chat)\n+\n+# 3: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© (ÙŠÙ…ÙƒÙ† Ø¯Ù…Ø¬ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ù…Ø¹ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… tokenize=True)\n+inputs = tokenizer(formatted_chat, return_tensors=\"pt\", add_special_tokens=False)\n+# Ù†Ù‚Ù„ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù…Ø­Ù„Ù„Ø© Ø¥Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ Ø¹Ù„ÙŠÙ‡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (GPU/CPU)\n+inputs = {key: tensor.to(model.device) for key, tensor in inputs.items()}\n+print(\"Tokenized inputs:\\n\", inputs)\n+\n+# 4: Ø¥Ù†Ø´Ø§Ø¡ Ù†Øµ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n+outputs = model.generate(**inputs, max_new_tokens=512, temperature=0.1)\n+print(\"Generated tokens:\\n\", outputs)\n+\n+# 5: ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¥Ù„Ù‰ Ø³Ù„Ø³Ù„Ø©\n+decoded_output = tokenizer.decode(outputs[0][inputs['input_ids'].size(1):], skip_special_tokens=True)\n+print(\"Decoded output:\\n\", decoded_output)\n+```\n+\n+Ù‡Ù†Ø§Ùƒ Ø§Ù„ÙƒØ«ÙŠØ± Ù‡Ù†Ø§ØŒ ÙˆÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† ÙƒÙ„ Ù‚Ø·Ø¹Ø© ÙˆØ«ÙŠÙ‚Ø© Ø®Ø§ØµØ© Ø¨Ù‡Ø§! Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙÙŠ Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ØŒ Ø³Ø£ØºØ·ÙŠ\n+Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ø¹Ø§Ù…Ø©ØŒ ÙˆØ£ØªØ±Ùƒ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ù„Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ù‡Ø§. Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù‡ÙŠ:\n+1. ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ [Ø§Ù„Ù†Ù…Ø§Ø°Ø¬](https://huggingface.co/learn/nlp-course/en/chapter2/3) Ùˆ [Ø§Ù„Ù…ÙØ¬Ø²Ù‘Ø¦Ø§Øª Ø§Ù„Ù„ØºÙˆÙŠØ©](https://huggingface.co/learn/nlp-course/en/chapter2/4?fw=pt) Ù…Ù† Hugging Face Hub.\n+2. ÙŠØªÙ… ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [Ù‚Ø§Ù„Ø¨ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©](https://huggingface.co/docs/transformers/main/en/chat_templating) Ù„Ù„Ù…Ø­Ù„Ù„\n+3. ÙŠØªÙ… [ØªØ­Ù„ÙŠÙ„](https://huggingface.co/learn/nlp-course/en/chapter2/4) Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ù…Ù†Ø³Ù‚Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ.\n+4. Ù†Ù‚ÙˆÙ… [Ø¨ØªÙˆÙ„ÙŠØ¯](https://huggingface.co/docs/transformers/en/llm_tutorial) Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n+5. ÙŠØªÙ… ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØªÙŠ ÙŠÙ†ØªØ¬Ù‡Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¥Ù„Ù‰ Ø³Ù„Ø³Ù„Ø©\n+\n+## Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ø£Ø¬Ù‡Ø²Ø©\n+\n+Ù…Ù† Ø§Ù„Ù…Ø­ØªÙ…Ù„ Ø£Ù†Ùƒ ØªØ¹Ø±Ù Ø§Ù„Ø¢Ù† Ø£Ù† Ù…Ø¹Ø¸Ù… Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ ÙŠØªÙ… ØªØ´ØºÙŠÙ„Ù‡Ø§ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU). ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ Ù…Ù† Ø§Ù„Ù…Ù…ÙƒÙ† ØªÙ…Ø§Ù…Ù‹Ø§\n+Ø¥Ù†Ø´Ø§Ø¡ Ù†Øµ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ø¯Ø±Ø¯Ø´Ø© Ø£Ùˆ Ù†Ù…ÙˆØ°Ø¬ Ù„ØºØ© Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© (CPU)ØŒ Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø£Ù† Ø°Ù„Ùƒ Ø£Ø¨Ø·Ø£ Ø¥Ù„Ù‰ Ø­Ø¯ Ù…Ø§. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¨Ø¥Ù…ÙƒØ§Ù†Ùƒ ÙˆØ¶Ø¹\n+Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø°Ø§ÙƒØ±Ø© ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU)ØŒ ÙÙ‡Ø°Ø§ Ø¹Ø§Ø¯Ø© Ù…Ø§ ÙŠÙƒÙˆÙ† Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ù…ÙØ¶Ù„.\n+\n+### Ø§Ø¹ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©\n+\n+Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠØŒ ØªÙ‚ÙˆÙ… ÙØ¦Ø§Øª Hugging Face Ù…Ø«Ù„ [`TextGenerationPipeline`] Ø£Ùˆ [`AutoModelForCausalLM`] Ø¨ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø¯Ù‚Ø© \"float32\". ÙˆÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ 4 Ø¨Ø§ÙŠØªØ§Øª (32 Ø¨Øª) Ù„ÙƒÙ„ Ù…Ø¹Ù„Ù…Ø©ØŒ Ù„Ø°Ø§ ÙØ¥Ù† Ù†Ù…ÙˆØ°Ø¬ \"8B\" Ø¨Ø­Ø¬Ù… 8 Ù…Ù„ÙŠØ§Ø± Ù…Ø¹Ù„Ù…Ø© Ø³ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ~32 Ø¬ÙŠØ¬Ø§Ø¨Ø§ÙŠØª Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©. ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ Ù…Ø¶ÙŠØ¹Ø© Ù„Ù„Ù…ÙˆØ§Ø±Ø¯! ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù…Ø¹Ø¸Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø­Ø¯ÙŠØ«Ø© ÙÙŠ Ø¯Ù‚Ø© \"bfloat16\"ØŒ ÙˆØ§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… ÙÙ‚Ø· 2 Ø¨Ø§ÙŠØª Ù„ÙƒÙ„ Ù…Ø¹Ù„Ù…Ø©. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹ØªØ§Ø¯Ùƒ ÙŠØ¯Ø¹Ù… Ø°Ù„Ùƒ (Nvidia 30xx/Axxx Ø£Ùˆ Ø£Ø­Ø¯Ø«)ØŒ ÙÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø¯Ù‚Ø© \"bfloat16\"ØŒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù…Ù„ \"torch_dtype\" ÙƒÙ…Ø§ ÙØ¹Ù„Ù†Ø§ Ø£Ø¹Ù„Ø§Ù‡.\n+\n+ÙˆÙ…Ù† Ø§Ù„Ù…Ù…ÙƒÙ† Ø£ÙŠØ¶Ù‹Ø§ Ø§Ù„Ù†Ø²ÙˆÙ„ Ø¥Ù„Ù‰ Ø£Ù‚Ù„ Ù…Ù† 16 Ø¨Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… \"Ø§Ù„ØªÙƒÙ…ÙŠÙ…\"ØŒ ÙˆÙ‡ÙŠ Ø·Ø±ÙŠÙ‚Ø© Ù„Ø¶ØºØ· Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø·Ø±ÙŠÙ‚Ø© ØªÙÙ‚Ø¯ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª. ÙŠØ³Ù…Ø­ Ù‡Ø°Ø§ Ø¨Ø¶ØºØ· ÙƒÙ„ Ù…Ø¹Ù„Ù…Ø© Ø¥Ù„Ù‰ 8 Ø¨ØªØ§Øª Ø£Ùˆ 4 Ø¨ØªØ§Øª Ø£Ùˆ Ø­ØªÙ‰ Ø£Ù‚Ù„. Ù„Ø§Ø­Ø¸ Ø£Ù†Ù‡ØŒ Ø®Ø§ØµØ© ÙÙŠ 4 Ø¨ØªØ§ØªØŒ Ù‚Ø¯ ØªØªØ£Ø«Ø± Ø¬ÙˆØ¯Ø© Ù†Ø§ØªØ¬ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø³Ù„Ø¨Ù‹Ø§ØŒ ÙˆÙ„ÙƒÙ† ØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ Ù…Ù‚Ø§ÙŠØ¶Ø© ØªØ³ØªØ­Ù‚ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù‡Ø§ Ù„ØªÙ†Ø§Ø³Ø¨ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ø§Ø¯Ø«Ø© Ø£ÙƒØ¨Ø± ÙˆØ£ÙƒØ«Ø± Ù‚Ø¯Ø±Ø© ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©. Ø¯Ø¹Ù†Ø§ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†Ø§ ØªØ·Ø¨ÙŠÙ‚ Ø°Ù„Ùƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© `bitsandbytes`:\n+\n+```python\n+from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n+\n+quantization_config = BitsAndBytesConfig(load_in_8bit=True) # ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ØªØ¬Ø±Ø¨Ø© load_in_4bit\n+model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\", device_map=\"auto\", quantization_config=quantization_config)\n+```\n+\n+Ø£Ùˆ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù†ÙØ³ Ø§Ù„Ø´ÙŠØ¡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª \"pipeline\":\n+\n+```python\n+from transformers import pipeline, BitsAndBytesConfig\n+\n+quantization_config = BitsAndBytesConfig(load_in_8bit=True) # ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ØªØ¬Ø±Ø¨Ø© load_in_4bit\n+pipe = pipeline(\"text-generation\", \"meta-llama/Meta-Llama-3-8B-Instruct\", device_map=\"auto\", model_kwargs={\"quantization_config\": quantization_config})\n+```\n+\n+Ù‡Ù†Ø§Ùƒ Ø¹Ø¯Ø© Ø®ÙŠØ§Ø±Ø§Øª Ø£Ø®Ø±Ù‰ Ù„ÙƒÙ…ÙŠØ© Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø®Ù„Ø§Ù `bitsandbytes` - ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ø·Ù„Ø§Ø¹ Ø¹Ù„Ù‰ [Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªÙƒÙ…ÙŠÙ…](./quantization) Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª.\n+\n+### Ø§Ø¹ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡\n+\n+<Tip>\n+\n+Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¯Ù„ÙŠÙ„ Ø£ÙƒØ«Ø± Ø´Ù…ÙˆÙ„Ø§Ù‹ Ø­ÙˆÙ„ Ø£Ø¯Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºØ© ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†ØŒ Ø±Ø§Ø¬Ø¹ [ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ¯Ù„Ø§Ù„ LLM](./llm_optims).\n+\n+</Tip>\n+\n+\n+ÙƒÙ‚Ø§Ø¹Ø¯Ø© Ø¹Ø§Ù…Ø©ØŒ Ø³ØªÙƒÙˆÙ† Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø£ÙƒØ¨Ø± Ø­Ø¬Ù…Ù‹Ø§ Ø£Ø¨Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø§Ø­ØªÙŠØ§Ø¬Ù‡Ø§ Ù„Ø°Ø§ÙƒØ±Ø© Ø£ÙƒØ¨Ø±Ø©. Ù…Ù† Ø§Ù„Ù…Ù…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† Ø£ÙƒØ«Ø± ØªØ­Ø¯ÙŠØ¯Ù‹Ø§ Ø¨Ø´Ø£Ù† Ù‡Ø°Ø§: Ø¥Ù† ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†Øµ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ø¯Ø±Ø¯Ø´Ø© Ø£Ù…Ø± ØºÙŠØ± Ø¹Ø§Ø¯ÙŠ ÙÙŠ Ø£Ù†Ù‡ ÙŠØ®Ø¶Ø¹ Ù„Ù‚ÙŠÙˆØ¯ **Ø³Ø¹Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø©** Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù‚ÙˆØ© Ø§Ù„Ø­ÙˆØ³Ø¨Ø©ØŒ Ù„Ø£Ù† ÙƒÙ„ Ù…Ø¹Ù„Ù…Ø© Ù†Ø´Ø·Ø© ÙŠØ¬Ø¨ Ù‚Ø±Ø§Ø¡ØªÙ‡Ø§ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„ÙƒÙ„ Ø±Ù…Ø² ÙŠÙ†Ø´Ø¦Ù‡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ÙˆÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ù…ÙˆØ² ÙÙŠ Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙˆÙ„ÙŠØ¯Ù‡Ø§ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ÙŠØªÙ†Ø§Ø³Ø¨ Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù… Ù…Ø¹ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø­Ø¬Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªÙŠ Ø¨ÙˆØ¬Ø¯ Ø¨Ù‡Ø§ Ø§ØŒ Ù…Ù‚Ø³ÙˆÙ…Ù‹Ø§ Ø¹Ù„Ù‰ Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n+\n+ÙÙŠ Ù…Ø«Ø§Ù„Ù†Ø§ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø£Ø¹Ù„Ø§Ù‡ØŒ ÙƒØ§Ù† Ø­Ø¬Ù… Ù†Ù…ÙˆØ°Ø¬Ù†Ø§ Ø­ÙˆØ§Ù„ÙŠ 16 Ø¬ÙŠØ¬Ø§Ø¨Ø§ÙŠØª Ø¹Ù†Ø¯ ØªØ­Ù…ÙŠÙ„Ù‡ ÙÙŠ Ø¯Ù‚Ø© \"bfloat16\". ÙˆÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ ÙŠØ¬Ø¨ Ù‚Ø±Ø§Ø¡Ø© 16 Ø¬ÙŠØ¬Ø§Ø¨Ø§ÙŠØª Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„ÙƒÙ„ Ø±Ù…Ø² ÙŠÙ†Ø´Ø¦Ù‡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØªØ±Ø§ÙˆØ­ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø³Ø¹Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù…Ù† 20-100 Ø¬ÙŠØ¬Ø§Ø¨Ø§ÙŠØª/Ø«Ø§Ù†ÙŠØ© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‡Ù„ÙƒÙŠÙ† Ø¥Ù„Ù‰ 200-900 Ø¬ÙŠØ¬Ø§Ø¨Ø§ÙŠØª/Ø«Ø§Ù†ÙŠØ© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª Ù„Ù„Ù…Ø³ØªÙ‡Ù„ÙƒÙŠÙ†ØŒ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø§Øª Intel Xeon Ø£Ùˆ AMD Threadripper/Epyc Ø£Ùˆ Apple Silicon Ø§Ù„Ù…ØªØ®ØµØµØ©Ø©ØŒ ÙˆØ£Ø®ÙŠØ±Ù‹Ø§ ÙŠØµÙ„ Ø¥Ù„Ù‰ 2-3 ØªÙŠØ±Ø§Ø¨Ø§ÙŠØª/Ø«Ø§Ù†ÙŠØ© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ù…Ø±Ø§ÙƒØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø«Ù„ Nvidia A100 Ø£Ùˆ H100. ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ¹Ø·ÙŠÙƒ Ù‡Ø°Ø§ ÙÙƒØ±Ø© Ø¬ÙŠØ¯Ø© Ø¹Ù† Ø³Ø±Ø¹Ø© Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙˆÙ‚Ø¹Ù‡Ø§ Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Ø§Ù„Ø£Ø¬Ù‡Ø²Ø©.\n+\n+Ù„Ø°Ù„ÙƒØŒ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ ØªØ­Ø³ÙŠÙ† Ø³Ø±Ø¹Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØµØŒ ÙØ¥Ù† Ø§Ù„Ø­Ù„ Ø§Ù„Ø£Ø³Ù‡Ù„ Ù‡Ùˆ Ø¥Ù…Ø§ ØªÙ‚Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Ø¹Ø§Ø¯Ø©Ù‹ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ù„ØªÙƒÙ…ÙŠÙ…)ØŒ Ø£Ùˆ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹ØªØ§Ø¯ Ø¨Ø³Ø±Ø¹Ø© Ø£ÙƒØ¨Ø± ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©. Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…ØªÙ‚Ø¯Ù…ÙŠÙ†ØŒ Ù‡Ù†Ø§Ùƒ Ø¹Ø¯Ø© ØªÙ‚Ù†ÙŠØ§Øª Ø£Ø®Ø±Ù‰ Ù„Ù„ØªØºÙ„Ø¨ Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙŠÙˆØ¯. Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ù‹Ø§ Ù‡ÙŠ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø¹Ù„Ù‰ [Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ù…Ø³Ø§Ø¹Ø¯Ø©](https://huggingface.co/blog/assisted-generation)ØŒ Ø§Ù„Ù…Ø¹Ø±ÙˆÙ Ø£ÙŠØ¶Ù‹Ø§ Ø¨Ø§Ø³Ù… \"Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„ØªØ®Ù…ÙŠÙ†ÙŠØ© (speculative sampling)\". ØªØ­Ø§ÙˆÙ„ Ù‡Ø°Ù‡ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª ØªØ®Ù…ÙŠÙ† Ø¹Ø¯Ø© Ø±Ù…ÙˆØ² Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© ÙÙŠ ÙˆÙ‚Øª ÙˆØ§Ø­Ø¯ØŒ ØºØ§Ù„Ø¨Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ \"Ù…Ø³ÙˆØ¯Ø© (draft model)\" Ø£ØµØºØ±ØŒ Ø«Ù… ØªØ£ÙƒÙŠØ¯ Ù‡Ø°Ù‡ Ø§Ù„ØªÙˆÙ„ÙŠØ¯Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©. Ø¥Ø°Ø§ ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØªØ®Ù…ÙŠÙ†Ø§Øª Ø¨ÙˆØ§Ø³Ø·Ø© Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©ØŒ ÙÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ Ø£ÙƒØ«Ø± Ù…Ù† Ø±Ù…Ø² ÙˆØ§Ø­Ø¯ Ù„ÙƒÙ„ ØªÙ…Ø±ÙŠØ± Ù„Ù„Ø£Ù…Ø§Ù…ØŒ Ù…Ù…Ø§ ÙŠØ®ÙÙ Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ± Ù…Ù† Ø§Ù„Ù‚ÙŠÙˆØ¯ Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„Ø³Ø¹Ø© ÙˆÙŠØ­Ø³Ù† Ø³Ø±Ø¹Ø© Ø§Ù„ØªÙˆÙ„ÙŠØ¯.\n+\n+Ø£Ø®ÙŠØ±Ù‹Ø§ØŒ ÙŠØ¬Ø¨ Ø£Ù† Ù†Ù„Ø§Ø­Ø¸ Ø£ÙŠØ¶Ù‹Ø§ ØªØ£Ø«ÙŠØ± Ù†Ù…Ø§Ø°Ø¬ \"Ù…Ø²ÙŠØ¬ Ø§Ù„Ø®Ø¨Ø±Ø§Ø¡\" \"Mixture of Experts\" (MoE) Ù‡Ù†Ø§. Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø´Ù‡ÙŠØ±Ø©ØŒ Ù…Ø«Ù„ Mixtral ÙˆQwen-MoE ÙˆDBRXØŒ Ù‡ÙŠ Ù†Ù…Ø§Ø°Ø¬ MoE. ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ Ù„Ø§ ØªÙƒÙˆÙ† ÙƒÙ„ Ù…Ø¹Ù„Ù…Ø© Ù†Ø´Ø·Ø© Ù„ÙƒÙ„ Ø±Ù…Ø² ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡. ÙˆÙ†ØªÙŠØ¬Ø© Ù„Ø°Ù„ÙƒØŒ ÙØ¥Ù† Ù†Ù…Ø§Ø°Ø¬ MoE Ù„Ø¯ÙŠÙ‡Ø§ Ø¹Ù…ÙˆÙ…Ù‹Ø§ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø°Ø§ÙƒØ±Ø© Ø£Ù‚Ù„ Ø¨ÙƒØ«ÙŠØ±ØŒ Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø£Ù† Ø­Ø¬Ù…Ù‡Ø§ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† ÙƒØ¨ÙŠØ±Ù‹Ø§ Ø¬Ø¯Ù‹Ø§. Ù„Ø°Ù„Ùƒ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† Ø£Ø³Ø±Ø¹ Ø¹Ø¯Ø© Ù…Ø±Ø§Øª Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ \"ÙƒØ«ÙŠÙ\" Ø¹Ø§Ø¯ÙŠ Ø¨Ù†ÙØ³ Ø§Ù„Ø­Ø¬Ù…. ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ ÙØ¥Ù† Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ù…Ø«Ù„ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ ØºÙŠØ± ÙØ¹Ø§Ù„Ø© Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù… Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ø£Ù† Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø³ØªØµØ¨Ø­ Ù†Ø´Ø·Ø© Ù…Ø¹ ÙƒÙ„ Ø±Ù…Ø² Ø¬Ø¯ÙŠØ¯ ÙŠØªÙ… Ø§Ù„ØªÙƒÙ‡Ù† Ø¨Ù‡ØŒ ÙˆØ§Ù„Ø°ÙŠ Ø³ÙŠØ¨Ø·Ù„ ÙÙˆØ§Ø¦Ø¯ Ø§Ù„Ø³Ø¹Ø© ÙˆØ§Ù„Ø³Ø±Ø¹Ø© Ø§Ù„ØªÙŠ ØªÙˆÙØ±Ù‡Ø§ Ø¨Ù†ÙŠØ© MoE.\n\\ No newline at end of file"
        },
        {
            "sha": "81753bad281b40ee0b94c0c319aec8a49d0f9b8d",
            "filename": "docs/source/ar/glossary.md",
            "status": "added",
            "additions": 446,
            "deletions": 0,
            "changes": 446,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fglossary.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fglossary.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fglossary.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,446 @@\n+# Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª\n+\n+ÙŠØ­Ø¯Ø¯ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³Ø±Ø¯ Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„Ø¹Ø§Ù…Ø© Ùˆ ğŸ¤— Transformers Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„.\n+\n+## A\n+\n+### Ù‚Ù†Ø§Ø¹ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ (Attention Mask)\n+\n+Ù‚Ù†Ø§Ø¹ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ù‡Ùˆ Ù…ÙØ¯Ø®Ù„ Ø§Ø®ØªÙŠØ§Ø±ÙŠ ÙŠØ³ØªØ®Ø¯Ù… Ø¹Ù†Ø¯ ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ØªØ³Ù„Ø³Ù„Ø§Øª Ù…Ø¹Ù‹Ø§\n+\n+<Youtube id=\"M6adb1j2jPI\"/>\n+\n+ÙŠØ´ÙŠØ± Ù‡Ø°Ø§ Ø§Ù„Ù…ÙØ¯Ø®Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ù‰ Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…Ù…ÙŠØ²Ø© (tokens) Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ø¥Ù„ÙŠÙ‡Ø§ØŒ ÙˆØ£ÙŠÙ‡Ø§ Ù„Ø§ ÙŠÙ†Ø¨ØºÙŠ Ø°Ù„Ùƒ.\n+\n+Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ØªØ£Ù…Ù‘Ù„ Ù‡Ø°ÙŠÙ† Ø§Ù„ØªØ³Ù„Ø³ÙÙ„ÙŠÙ† :\n+\n+```python\n+>>> from transformers import BertTokenizer\n+\n+>>> tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n+\n+>>> sequence_a = \"This is a short sequence.\"\n+>>> sequence_b = \"This is a rather long sequence. It is at least longer than sequence A.\"\n+\n+>>> encoded_sequence_a = tokenizer(sequence_a)[\"input_ids\"]\n+>>> encoded_sequence_b = tokenizer(sequence_b)[\"input_ids\"]\n+```\n+\n+Ù„Ø¯Ù‰ Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø´ÙØ±Ø© Ø£Ø·ÙˆØ§Ù„ Ù…Ø®ØªÙ„ÙØ©:\n+\n+```python\n+>>> len(encoded_sequence_a), len(encoded_sequence_b)\n+(8, 19)\n+```\n+\n+Ù„Ø°Ù„ÙƒØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†Ø§ ÙˆØ¶Ø¹Ù‡Ø§ Ù…Ø¹Ù‹Ø§ ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…ØµÙÙˆÙØ© ÙƒÙ…Ø§ Ù‡ÙŠ. ÙŠØ¬Ø¨ Ø¥Ø¶Ø§ÙØ© Ø­Ø´Ùˆ Ø¥Ù„Ù‰ Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø£ÙˆÙ„ Ø­ØªÙ‰ ÙŠØµÙ„ Ø¥Ù„Ù‰ Ø·ÙˆÙ„ Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø«Ø§Ù†ÙŠØŒ Ø£Ùˆ ÙŠØ¬Ø¨ ØªÙ‚Ù„ÙŠØµ Ø§Ù„Ø«Ø§Ù†ÙŠ Ø¥Ù„Ù‰ Ø·ÙˆÙ„ Ø§Ù„Ø£ÙˆÙ„.\n+\n+ÙÙŠ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ØŒ ÙŠØªÙ… ØªÙ…Ø¯ÙŠØ¯ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª Ø¨ÙˆØ§Ø³Ø·Ø© Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø­Ø´Ùˆ. ÙŠÙ…ÙƒÙ†Ù†Ø§ ØªÙ…Ø±ÙŠØ± Ù‚Ø§Ø¦Ù…Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ù„ØºÙˆÙŠ ÙˆØ·Ù„Ø¨ Ù…Ù†Ù‡ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø­Ø´Ùˆ Ø¨Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©:\n+\n+```python\n+>>> padded_sequences = tokenizer([sequence_a, sequence_b], padding=True)\n+```\n+\n+ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø£Ù† Ù†Ø±Ù‰ Ø£Ù†Ù‡ ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø§ØµÙØ§Ø± Ø¹Ù„Ù‰ ÙŠÙ…ÙŠÙ† Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù„Ø¬Ø¹Ù„Ù‡Ø§ Ø¨Ù†ÙØ³ Ø·ÙˆÙ„ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©:\n+\n+```python\n+>>> padded_sequences[\"input_ids\"]\n+[[101, 1188, 1110, 170, 1603, 4954, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1188, 1110, 170, 1897, 1263, 4954, 119, 1135, 1110, 1120, 1655, 2039, 1190, 1103, 4954, 138, 119, 102]]\n+```\n+\n+ÙŠÙ…ÙƒÙ† Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ ØªØ­ÙˆÙŠÙ„ Ù‡Ø°Ø§ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© ÙÙŠ PyTorch Ø£Ùˆ TensorFlow. Ù‚Ù†Ø§Ø¹ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ù‡Ùˆ Ù…ØµÙÙˆÙØ© Ø«Ù†Ø§Ø¦ÙŠØ© ØªØ´ÙŠØ± Ø¥Ù„Ù‰\n+Ù…ÙˆØ¶Ø¹  Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø­Ø´ÙˆÙ‡ Ø¨Ø­ÙŠØ« Ù„Ø§ ÙŠÙ†ØªØ¨Ù‡ Ø¥Ù„ÙŠÙ‡Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ø¥Ù„Ù‰ [`BertTokenizer`]`1` ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰\n+Ù‚ÙŠÙ…Ø© ÙŠØ¬Ø¨ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ø¥Ù„ÙŠÙ‡Ø§ØŒ ÙÙŠ Ø­ÙŠÙ† ÙŠØ´ÙŠØ± `0` Ø¥Ù„Ù‰ Ù‚ÙŠÙ…Ø© Ù…Ø¨Ø·Ù†Ø©. ÙŠÙÙ…ÙƒÙ† Ø¥ÙŠØ¬Ø§Ø¯ Ù‚Ù†Ø§Ø¹ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ ÙÙŠ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ø°ÙŠ ÙŠÙØ¹ÙŠØ¯Ù‡ Ù…ÙØ¬Ø²ÙÙ‘Ø¦ Ø§Ù„Ù†ØµÙˆØµ (tokenizer) ØªØ­Øª Ø§Ù„Ù…ÙØªØ§Ø­ \"attention_mask\".\n+```python\n+>>> padded_sequences[\"attention_mask\"]\n+[[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n+```\n+\n+### Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ² Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (autoencoding models)\n+\n+Ø±Ø§Ø¬Ø¹ [Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ²](#encoder-models) Ùˆ [Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø©](#masked-language-modeling-mlm)\n+\n+### Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø°Ø§ØªÙŠØ© Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± (Autoregressive Models)\n+\n+Ø±Ø§Ø¬Ø¹ [Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø³Ø¨Ø¨ÙŠØ©](#causal-language-modeling) Ùˆ [Ù†Ù…Ø§Ø°Ø¬ ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ±](#decoder-models)\n+\n+## B\n+\n+### Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙÙ‚Ø±ÙŠ (backbone)\n+\n+ÙŠÙÙ…Ø«Ù„ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙÙ‚Ø±ÙŠ Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙˆÙ†ÙŠØ© (Ø§Ù„ØªØ±Ù…ÙŠØ²Ø§Øª ÙˆØ§Ù„Ø·Ø¨Ù‚Ø§Øª) Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„Ø© Ø¹Ù† Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø®ÙÙŠØ© Ø£Ùˆ Ø§Ù„Ù…ÙÙ…ÙŠØ²Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©. Ø¹Ø§Ø¯Ø© Ù…Ø§ ÙŠÙƒÙˆÙ† Ù…ØªØµÙ„Ø§Ù‹ Ø¨Ù€ [Ø±Ø£Ø³](#head) ÙŠØ³ØªÙ‚Ø¨Ù„ Ø§Ù„Ù…ÙÙ…ÙŠØ²Ø§Øª ÙƒÙ…Ø¯Ø®Ù„Ø§Øª Ù„Ø¥Ø¬Ø±Ø§Ø¡ ØªÙ†Ø¨Ø¤. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ÙŠÙØ¹Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ [`ViTModel`] Ø¹Ù…ÙˆØ¯Ù‹Ø§ ÙÙ‚Ø±ÙŠÙ‹Ø§ Ø¯ÙˆÙ† Ø±Ø£Ø³ Ù…ÙØ­Ø¯Ø¯ Ù…ÙØ±ÙÙ‚ Ø¨Ù‡. ÙŠÙ…ÙƒÙ† Ø£ÙŠØ¶Ù‹Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… `ViTModel` ÙƒØ¹Ù…ÙˆØ¯ ÙÙ‚Ø±ÙŠ ÙÙŠ Ù†Ù…Ø§Ø°Ø¬ Ø£Ø®Ø±Ù‰, Ù…Ø«Ù„ [DPT](model_doc/dpt).\n+\n+## C\n+\n+### Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø³Ø¨Ø¨ÙŠØ© (Ø£Ùˆ Ø§Ù„ØªÙ†Ø¨Ø¤ÙŠØ©) causal language modeling\n+\n+Ù…Ù‡Ù…Ø© Ù…Ø§ Ù‚Ø¨Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙŠÙ‚ÙˆÙ… ÙÙŠÙ‡Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ ÙˆÙŠØªÙ†Ø¨Ø£ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©. ÙŠØªÙ… Ø°Ù„Ùƒ Ø¹Ø§Ø¯Ø©Ù‹ Ù…Ù† Ø®Ù„Ø§Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¬Ù…Ù„Ø© ÙƒØ§Ù…Ù„Ø©Ù‹ØŒ ÙˆÙ„ÙƒÙ† Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ù†Ø§Ø¹ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…Ù…ÙŠØ²Ø© Ø§Ù„Ù„Ø§Ø­Ù‚Ø© ÙÙŠ Ø®Ø·ÙˆØ© Ø²Ù…Ù†ÙŠØ© Ù…Ø¹ÙŠÙ†Ø©.\n+\n+\n+\n+### Ù‚Ù†Ø§Ø©(channel)\n+\n+ØªØªÙƒÙˆÙ† Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ù„ÙˆÙ†Ø© Ù…Ù† Ù…Ø²ÙŠØ¬ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… ÙÙŠ Ø«Ù„Ø§Ø« Ù‚Ù†ÙˆØ§Øª Ù„ÙˆÙ†ÙŠØ©: Ø§Ù„Ø£Ø­Ù…Ø± ÙˆØ§Ù„Ø£Ø®Ø¶Ø± ÙˆØ§Ù„Ø£Ø²Ø±Ù‚ (RGB) Ø¨ÙŠÙ†Ù…Ø§ ØªØ­ØªÙˆÙŠ ØµÙˆØ± Ø°Ø§Øª Ø§Ù„ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ Ø¹Ù„Ù‰ Ù‚Ù†Ø§Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·. ÙÙŠ Ù…ÙƒØªØ¨Ø© ğŸ¤— TransformersØŒ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ù„ÙˆÙ†ÙŠØ© Ø§Ù„Ø¨ÙØ¹Ø¯ Ø§Ù„Ø£ÙˆÙ„ Ø£Ùˆ Ø§Ù„Ø£Ø®ÙŠØ± ÙÙŠ Ù…ÙØµÙÙˆÙØ© Ø§Ù„ØµÙˆØ±Ø©: [`n_channels`ØŒ `height`ØŒ `width`] Ø£Ùˆ [`height`ØŒ `width`ØŒ `n_channels`].\n+\n+### Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø²Ù…Ù†ÙŠ Ø§Ù„ØªÙˆØµÙŠÙ„ÙŠ connectionist temporal classification (CTC)\n+\n+Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© ØªØ³Ù…Ø­ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„ØªØ¹Ù„Ù… Ø¯ÙˆÙ† Ù…Ø¹Ø±ÙØ© ÙƒÙŠÙÙŠØ© Ù…Ø­Ø§Ø°Ø§Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ù…Ø¹ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø¨Ø¯Ù‚Ø©Ø› ÙŠØ­Ø³Ø¨ CTC ØªÙˆØ²ÙŠØ¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ù…ÙØ­Ø¯Ø¯Ø© ÙˆÙŠØ®ØªØ§Ø± Ø§Ù„Ù…Ø®Ø±Ø¬ Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø­ØªÙ…Ø§Ù„Ù‹Ø§. ØªÙØ³ØªØ®Ø¯Ù… CTC Ø¨Ø´ÙƒÙ„ Ø´Ø§Ø¦Ø¹ ÙÙŠ Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ù†Ø¸Ø±Ù‹Ø§ Ù„Ø£Ù† Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ù…Ù†Ø·ÙˆÙ‚ Ù„Ø§ ÙŠØªÙˆØ§ÙÙ‚ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¨Ø´ÙƒÙ„ Ù…ÙØ¨Ø§Ø´Ø± Ù…Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙƒØªÙˆØ¨ØŒ Ù„Ø£Ø³Ø¨Ø§Ø¨ Ù…Ø®ØªÙ„ÙØ© Ù…Ø«Ù„ Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ù„Ù„Ù…ØªÙƒÙ„Ù….\n+\n+### Ø§Ù„Ø§Ù„ØªÙØ§Ù (Convolution)\n+\n+Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„Ø·Ø¨Ù‚Ø§Øª ÙÙŠ Ø´Ø¨ÙƒØ© Ø¹ØµØ¨ÙŠØ©ØŒ Ø­ÙŠØ« ØªÙØ¶Ø±Ø¨ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø¹ÙÙ†ØµØ±Ù‹Ø§ Ø¨ÙØ¹Ù†ØµØ± Ø¨Ù…ØµÙÙˆÙØ© Ø£ØµØºØ± ØªÙØ³Ù…Ù‰ (Ø§Ù„Ù†ÙˆØ§Ø© Ø£Ùˆ Ø§Ù„Ù…Ø±Ø´Ø­) ÙˆÙŠØªÙ… Ø¬Ù…Ø¹ Ø§Ù„Ù‚ÙŠÙ… ÙÙŠ Ù…ØµÙÙˆÙØ© Ø¬Ø¯ÙŠØ¯Ø©. ÙŠÙØ¹Ø±Ù Ù‡Ø°Ø§ Ø¨Ø§Ø³Ù… Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ù„ØªÙØ§Ù Ø§Ù„ØªÙŠ ÙŠØªÙ… ØªÙƒØ±Ø§Ø±Ù‡Ø§ Ø¹Ø¨Ø± Ù…ØµÙÙˆÙØ© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§. ØªÙØ·Ø¨Ù‚ ÙƒÙ„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙØ§Ù Ø¹Ù„Ù‰ Ø¬Ø²Ø¡ Ù…ÙØ®ØªÙ„Ù Ù…Ù† Ù…ØµÙÙˆÙØ© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„. ØªÙØ³ØªØ®Ø¯Ù… Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ© Ø§Ù„Ø§Ù„ØªÙØ§ÙÙŠØ© (CNNs) Ø¨Ø´ÙƒÙ„ Ø´Ø§Ø¦Ø¹ ÙÙŠ Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨.\n+\n+## D\n+\n+### Ø§Ù„ØªÙˆØ§Ø²ÙŠ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (DataParallel - DP)\n+\n+Ù‡ÙŠ ØªÙ‚Ù†ÙŠØ© ØªÙØ³ØªØ®Ø¯Ù… Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ù„Ù‰ Ø¹Ø¯Ø© ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³ÙˆÙ…Ø§Øª (GPUs)ØŒ Ø­ÙŠØ« ÙŠØªÙ… Ù†Ø³Ø® Ù†ÙØ³ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ø¯Ø© Ù…Ø±Ø§ØªØŒ Ø¨Ø­ÙŠØ« ØªØªÙ„Ù‚Ù‰ ÙƒÙ„ Ù†Ø³Ø®Ø© Ø´Ø±ÙŠØ­Ø© Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙŠØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ ÙˆÙŠØªÙ… Ù…Ø²Ø§Ù…Ù†Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙÙŠ Ù†Ù‡Ø§ÙŠØ© ÙƒÙ„ Ø®Ø·ÙˆØ© ØªØ¯Ø±ÙŠØ¨.\n+\n+ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø²ÙŠØ¯ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© Ø¹Ù…Ù„ DataParallel [Ù‡Ù†Ø§](perf_train_gpu_many#dataparallel-vs-distributeddataparallel).\n+\n+### Ù…Ø¹Ø±ÙØ§Øª Ù…Ø¯Ø®Ù„Ø§Øª ÙˆØ­Ø¯Ø© ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± (decoder input IDs)\n+\n+Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¯Ø®Ù„ Ø®Ø§Øµ Ø¨Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ² ÙˆÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ±ØŒ ÙˆÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØªÙŠ Ø³ÙŠØªÙ… ØªØºØ°ÙŠØªÙ‡Ø§ Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø© ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ±.\n+ÙŠØ¬Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø¥Ù„Ù‰ Ø§Ù„ØªØ³Ù„Ø³Ù„ØŒ Ù…Ø«Ù„ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø£Ùˆ Ø§Ù„ØªÙ„Ø®ÙŠØµØŒ ÙˆØ¹Ø§Ø¯Ø© Ù…Ø§ ÙŠØªÙ… Ø¨Ù†Ø§Ø¤Ù‡Ø§ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø­Ø¯Ø¯Ø© Ù„ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬.\n+\n+ØªÙ‚ÙˆÙ… Ù…Ø¹Ø¸Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ² ÙˆÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± (BARTØŒ T5) Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø±ÙØ§Øª `decoder_input_ids` Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø§ Ù…Ù† `labels`. ÙÙŠ Ù…Ø«Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ\n+ÙŠØ¹Ø¯ ØªÙ…Ø±ÙŠØ± `labels` Ù‡Ùˆ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…ÙØ¶Ù„Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.\n+\n+ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ«Ø§Ø¦Ù‚ ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù…Ø¹Ø±ÙØ© ÙƒÙŠÙÙŠØ© ØªØ¹Ø§Ù…Ù„Ù‡Ø§ Ù…Ø¹ Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù‡Ø°Ù‡ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø¥Ù„Ù‰ Ø§Ù„ØªØ³Ù„Ø³Ù„.\n+\n+### Ù†Ù…Ø§Ø°Ø¬ ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± (decoder models)\n+\n+ÙŠÙØ´Ø§Ø± Ø¥Ù„ÙŠÙ‡Ø§ Ø£ÙŠØ¶Ù‹Ø§ Ø¨Ø§Ø³Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ÙŠØ© Ø§Ù„Ø°Ø§ØªÙŠØ©ØŒ ÙˆØªÙ†Ø·ÙˆÙŠ Ù†Ù…Ø§Ø°Ø¬ ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± Ø¹Ù„Ù‰ Ù…Ù‡Ù…Ø© Ù…Ø§ Ù‚Ø¨Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (ØªØ³Ù…Ù‰ Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø³Ø¨Ø¨ÙŠØ©) Ø­ÙŠØ« ÙŠÙ‚Ø±Ø£ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ ÙˆÙŠØªØ¹ÙŠÙ† Ø¹Ù„ÙŠÙ‡ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©. ÙŠØªÙ… Ø°Ù„Ùƒ Ø¹Ø§Ø¯Ø©Ù‹ Ø¹Ù† Ø·Ø±ÙŠÙ‚\n+Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¬Ù…Ù„Ø© Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ Ù…Ø¹ Ù‚Ù†Ø§Ø¹ Ù„Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…Ù…ÙŠØ²Ø© Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© ÙÙŠ Ø®Ø·ÙˆØ© Ø²Ù…Ù†ÙŠØ© Ù…Ø¹ÙŠÙ†Ø©.\n+\n+<Youtube id=\"d_ixlCubqQw\"/>\n+### Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ deep learning (DL)\n+Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ© Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø·Ø¨Ù‚Ø§Øª.\n+\n+## E\n+\n+### Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ² (encoder models)\n+\n+ØªÙØ¹Ø±Ù Ø£ÙŠØ¶Ù‹Ø§ Ø¨Ø§Ø³Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ² Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØŒ ÙˆØªØ£Ø®Ø° Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ² Ø¥Ø¯Ø®Ø§Ù„Ù‹Ø§ (Ù…Ø«Ù„ Ø§Ù„Ù†Øµ Ø£Ùˆ Ø§Ù„ØµÙˆØ±) ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ ØªÙ…Ø«ÙŠÙ„ Ø±Ù‚Ù…ÙŠ Ù…ÙƒØ«Ù ÙŠÙØ·Ù„Ù‚ Ø¹Ù„ÙŠÙ‡ Ø§Ù„ØªØ±Ù…ÙŠØ². ØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ² Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª Ù…Ø«Ù„ [Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø©](#masked-language-modeling-mlm)ØŒ ÙˆØ§Ù„ØªÙŠ ØªÙ‚ÙˆÙ… Ø¨Ø¥Ø®ÙØ§Ø¡ Ø£Ø¬Ø²Ø§Ø¡ Ù…Ù† ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ ÙˆØ¥Ø¬Ø¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ…Ø«ÙŠÙ„Ø§Øª Ø£ÙƒØ«Ø± Ø¯Ù„Ø§Ù„Ø© (ÙØ§Ø¦Ø¯Ø© ÙˆÙˆØ¶ÙˆØ­Ø§Ù‹).\n+\n+<Youtube id=\"H39Z_720T5s\"/>\n+\n+## F\n+### Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª (feature extraction)\n+\n+Ø¹Ù…Ù„ÙŠØ© Ø§Ø®ØªÙŠØ§Ø± ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø¥ÙØ§Ø¯Ø© ÙˆÙØ§Ø¦Ø¯Ø© Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ. Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª ØªØ´Ù…Ù„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ÙˆÙ„ÙŠ/Ø§Ù„Ø®Ø§Ù… Ø¥Ù„Ù‰ ØªØ±Ù…ÙŠØ²Ø§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙŠØ²Ø§Øª Ù…Ù‡Ù…Ø© Ù…Ø«Ù„ Ø§Ù„Ø­ÙˆØ§Ù Ø£Ùˆ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØ±/Ø§Ù„ÙÙŠØ¯ÙŠÙˆ.\n+\n+### ØªØ¬Ø²Ø¦Ø© Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© (feed forward chunking)\n+\n+ÙÙŠ ÙƒÙ„ ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ø§Ù„Ø¨Ø§Ù‚ÙŠØ© ÙÙŠ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§ØªØŒ ØªÙ„ÙŠ Ø·Ø¨Ù‚Ø© Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ø¹Ø§Ø¯Ø© Ø·Ø¨Ù‚ØªØ§Ù† Ù„Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©.\n+Ø­Ø¬Ù… ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© Ø§Ù„ÙˆØ³ÙŠØ·Ø© Ø£ÙƒØ¨Ø± Ø¹Ø§Ø¯Ø© Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ø®ÙÙŠ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ù„Ù€\n+`google-bert/bert-base-uncased`).\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø¨Ø­Ø¬Ù… `[batch_size, sequence_length]`ØŒ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙ…Ø«Ù„ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© Ø§Ù„ÙˆØ³ÙŠØ·Ø© `[batch_sizeØŒ sequence_length, config.intermediate_size]` Ø¬Ø²Ø¡Ù‹Ø§ ÙƒØ¨ÙŠØ±Ù‹Ø§ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©. Ù„Ø§Ø­Ø¸ Ù…Ø¤Ù„ÙÙˆ (https://arxiv.org/abs/2001.04451)[Reformer: The Efficient Transformer] Ø£Ù†Ù‡ Ù†Ø¸Ø±Ù‹Ø§ Ù„Ø£Ù† Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙ‚Ù„ Ø¹Ù† Ø¨Ø¹Ø¯ `sequence_length`ØŒ ÙØ¥Ù†Ù‡ Ù…Ù† Ø§Ù„Ù…ÙƒØ§ÙØ¦ Ø±ÙŠØ§Ø¶ÙŠÙ‹Ø§ Ø­Ø³Ø§Ø¨ ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© `[batch_sizeØŒ config.hidden_size]_0, ..., [batch_sizeØŒ `config_size]_n\n+ÙØ±Ø¯ÙŠØ§Ù‹ ÙˆØ§Ù„ØªÙˆØµÙŠÙ„ Ø¨Ù‡Ø§ Ù„Ø§Ø­Ù‚Ù‹Ø§ Ø¥Ù„Ù‰ `[batch_size, sequence_length, config.hidden_size]` Ù…Ø¹ `n = sequence_length`ØŒ ÙˆØ§Ù„Ø°ÙŠ ÙŠØªØ¯Ø§ÙˆÙ„ Ø²ÙŠØ§Ø¯Ø© ÙˆÙ‚Øª Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§Ø¨Ù„ ØªÙ‚Ù„ÙŠÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©ØŒ ÙˆÙ„ÙƒÙ†Ù‡ ÙŠÙ†ØªØ¬ Ø¹Ù†Ù‡ Ù†ØªÙŠØ¬Ø© Ù…ÙƒØ§ÙØ¦Ø© Ø±ÙŠØ§Ø¶ÙŠØ§.\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¯Ø§Ù„Ø© `[apply_chunking_to_forward]`ØŒ ÙŠØ­Ø¯Ø¯ `chunk_size` Ø¹Ø¯Ø¯ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª ÙŠØªÙ… Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠ ÙŠØ­Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§ÙŠØ¶Ø© Ø¨ÙŠÙ† Ø­Ø¬Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„ÙˆÙ‚Øª. Ø¥Ø°Ø§ ØªÙ… ØªØ¹ÙŠÙŠÙ† `chunk_size` Ø¥Ù„Ù‰ `0`ØŒ ÙÙ„Ù† ÙŠØªÙ… Ø¥Ø¬Ø±Ø§Ø¡ ØªØ¬Ø²Ø¦Ø© Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©.\n+\n+\n+### Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¶Ø¨ÙˆØ·Ø© (finetuned models)\n+\n+Ø§Ù„Ø¶Ø¨Ø· Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ù‡Ùˆ Ø´ÙƒÙ„ Ù…Ù† Ø£Ø´ÙƒØ§Ù„ Ù†Ù‚Ù„ Ø§Ù„ØªØ¹Ù„Ù…ØŒ ÙŠØªØ¶Ù…Ù† Ø£Ø®Ø° Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ù‘Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ØŒ ÙˆØªØ¬Ù…ÙŠØ¯ Ø£ÙˆØ²Ø§Ù†Ù‡ØŒ ÙˆØ§Ø³ØªØ¨Ø¯Ø§Ù„ Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø¨Ø±Ø£Ø³ Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¶Ø§Ù Ø­Ø¯ÙŠØ«Ù‹Ø§. ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø±Ø£Ø³ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©.\n+\n+Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ [Fine-tune a pretrained model](https://huggingface.co/docs/transformers/training) Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ØŒ ÙˆØªØ¹Ø±Ù Ø¹Ù„Ù‰ ÙƒÙŠÙÙŠØ© Ø¶Ø¨Ø· Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ğŸ¤— Transformers.\n+\n+## H\n+\n+### Ø±Ø£Ø³ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (head)\n+\n+ÙŠØ´ÙŠØ± Ø±Ø£Ø³ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù…Ù† Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ© Ø§Ù„ØªÙŠ ØªÙ‚Ø¨Ù„ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø®ÙÙŠØ© Ø§Ù„Ø®Ø§Ù…/Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ÙˆØªÙØ³Ù‚Ø·Ù‡Ø§ Ø¹Ù„Ù‰ Ø¨ÙØ¹Ø¯ Ù…Ø®ØªÙ„Ù. ÙŠÙˆØ¬Ø¯ Ø±Ø£Ø³ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø®ØªÙ„Ù Ù„ÙƒÙ„ Ù…Ù‡Ù…Ø©.\n+\n+  * [`GPT2ForSequenceClassification`] Ù‡Ùˆ Ø±Ø£Ø³ ØªØµÙ†ÙŠÙ ØªØ³Ù„Ø³Ù„ - Ø·Ø¨Ù‚Ø© Ø®Ø·ÙŠØ© - Ø£Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ [`GPT2Model`] Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ.\n+  * [`ViTForImageClassification`] Ù‡Ùˆ Ø±Ø£Ø³ ØªØµÙ†ÙŠÙ ØµÙˆØ±Ø© - Ø·Ø¨Ù‚Ø© Ø®Ø·ÙŠØ© Ø£Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ù…Ø®ÙÙŠØ© Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„Ø±Ù…Ø² `CLS` - Ø£Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ [`ViTModel`] Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ.\n+  * [`Wav2Vec2ForCTC`] Ù‡Ùˆ Ø±Ø£Ø³ Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ù…Ø¹ [CTC](#connectionist-temporal-classification-ctc) Ø£Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ [`Wav2Vec2Model`] Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ.\n+\n+## I\n+\n+### Ø±Ù‚Ø¹Ø© Ø§Ù„ØµÙˆØ± (image patch)\n+\n+\"Ø±Ù‚Ø¹Ø© Ø§Ù„ØµÙˆØ±Ø©\" ÙÙŠ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª Ø§Ù„Ø¨ØµØ±ÙŠØ©ØŒ ØªÙÙ‚Ø³Ù… Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ Ø£ØµØºØ± ØªØ³Ù…Ù‰ \"Ø±Ù‚Ø¹Ø§Øª\". ÙŠØªÙ… ØªÙ…Ø«ÙŠÙ„ ÙƒÙ„ Ø±Ù‚Ø¹Ø© Ø¨Ø´ÙƒÙ„ Ø±Ù‚Ù…ÙŠ (ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ø±Ù‚Ø§Ù…) Ø«Ù… ØªÙØ¹Ø§Ù„Ø¬ ÙƒØ³Ù„Ø³Ù„Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø­Ø¬Ù… Ø§Ù„Ø±ÙÙ‚Ø¹Ø© patch_size - Ø£Ùˆ Ø¯Ù‚ØªÙ‡Ø§ - ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n+\n+### Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ (Inference)\n+\n+Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù‡Ùˆ Ø¹Ù…Ù„ÙŠØ© ØªÙ‚ÙŠÙŠÙ… Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ø¹Ø¯ Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨. Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ [Pipeline for inference](https://huggingface.co/docs/transformers/pipeline_tutorial) Ù„Ù…Ø¹Ø±ÙØ© ÙƒÙŠÙÙŠØ© Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ğŸ¤— Transformers.\n+\n+### Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ (input IDs)\n+\n+Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù‡ÙŠ ØºØ§Ù„Ø¨Ù‹Ø§ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø§Ù„ÙˆØ­ÙŠØ¯Ø© Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ ØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙƒØ¥Ø¯Ø®Ø§Ù„. Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ø£Ø±Ù‚Ø§Ù… ØªÙ…Ø«Ù„ ÙƒÙ„ ÙƒÙ„Ù…Ø© Ø£Ùˆ Ø±Ù…Ø² ÙÙŠ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ØªÙŠ Ù†Ø±ÙŠØ¯ Ø£Ù† ÙŠÙÙ‡Ù…Ù‡Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ø¨Ù…Ø¹Ù†Ù‰ Ø¢Ø®Ø±ØŒ Ù‡ÙŠ Ø·Ø±ÙŠÙ‚Ø© Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙƒØ¥Ø¯Ø®Ø§Ù„ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n+\n+<Youtube id=\"VFp38yj8h3A\"/>\n+\n+ÙŠØ¹Ù…Ù„ ÙƒÙ„ Ù…Ø­Ù„Ù„ Ù„ØºÙˆÙŠ Ø¨Ø´ÙƒÙ„ Ù…Ø®ØªÙ„Ù ÙˆÙ„ÙƒÙ† Ø§Ù„Ø¢Ù„ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ. Ø¥Ù„ÙŠÙƒ Ù…Ø«Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø­Ù„Ù„ BERT Ø§Ù„Ù„ØºÙˆÙŠØŒ ÙˆØ§Ù„Ø°ÙŠ ÙŠØ¹Ø¯ Ù…Ø­Ù„Ù„ Ù„ØºÙˆÙŠ [WordPiece](https://arxiv.org/pdf/1609.08144.pdf):\n+\n+```python\n+>>> from transformers import BertTokenizer\n+\n+>>> tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n+\n+>>> sequence = \"A Titan RTX has 24GB of VRAM\"\n+```\n+\n+ÙŠØªÙˆÙ„Ù‰ Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ù„ØºÙˆÙŠ Ù…Ù‡Ù…Ø© ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø¥Ù„Ù‰ Ø±Ù…ÙˆØ² Ù…Ù…ÙŠØ²Ø© Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ù„ØºÙˆÙŠ.\n+\n+```python\n+>>> tokenized_sequence = tokenizer.tokenize(sequence)\n+```\n+\n+Ø§Ø§Ù„Ø±Ù…ÙˆØ² Ø¥Ù…Ø§ ÙƒÙ„Ù…Ø§Øª Ø£Ùˆ Ø£Ø¬Ø²Ø§Ø¡ ÙƒÙ„Ù…Ø§Øª. Ù‡Ù†Ø§ Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ù„Ù… ØªÙƒÙ† ÙƒÙ„Ù…Ø© \"VRAM\" Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù…ÙØ±Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ Ù„Ø°Ù„Ùƒ ØªÙ… ØªÙ‚Ø³ÙŠÙ…Ù‡Ø§ Ø¥Ù„Ù‰ \"V\" Ùˆ \"RA\" Ùˆ \"M\". Ù„Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ø£Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø±Ù…ÙˆØ² Ù„ÙŠØ³Øª ÙƒÙ„Ù…Ø§Øª Ù…Ù†ÙØµÙ„Ø© ÙˆÙ„ÙƒÙ†Ù‡Ø§ Ø£Ø¬Ø²Ø§Ø¡ Ù…Ù† Ù†ÙØ³ Ø§Ù„ÙƒÙ„Ù…Ø©ØŒ ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø¨Ø§Ø¯Ø¦Ø© Ù…Ø²Ø¯ÙˆØ¬Ø© (#) Ø¥Ù„Ù‰ \"RA\" Ùˆ \"M\":\n+```python\n+>>> print(tokenized_sequence)\n+['A', 'Titan', 'R', '##T', '##X', 'has', '24', '##GB', 'of', 'V', '##RA', '##M']\n+```\n+```python\n+>>> print(tokenized_sequence)\n+['A'ØŒ 'Titan'ØŒ 'R'ØŒ '##T'ØŒ '##X'ØŒ 'has'ØŒ '24'ØŒ '##GB'ØŒ 'of'ØŒ 'V'ØŒ '##RA'ØŒ '##M']\n+```\n+\n+ÙŠÙ…ÙƒÙ† Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ ØªØ­ÙˆÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ø±Ù…ÙˆØ² Ø¥Ù„Ù‰ Ù…ÙØ¹Ø±ÙØ§Øª ÙŠÙÙ‡Ù…Ù‡Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ÙŠÙ…ÙƒÙ† Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ø°Ù„Ùƒ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØºØ°ÙŠØ© Ø§Ù„Ø¬Ù…Ù„Ø© Ù…Ø¨Ø§Ø´Ø±Ø©Ù‹ Ø¥Ù„Ù‰ Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ø±Ù…ÙˆØ²ØŒ ÙˆØ§Ù„Ø°ÙŠ ÙŠØ³ØªÙÙŠØ¯ Ù…Ù† ØªÙ†ÙÙŠØ° ğŸ¤— Tokenizers Ø¨Ù„ØºØ© Rust Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡.\n+\n+```python\n+>>> inputs = tokenizer(sequence)\n+```\n+\n+ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ù„ØºÙˆÙŠ Ø¨Ø¥Ø±Ø¬Ø§Ø¹ Ù‚Ø§Ù…ÙˆØ³ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙŠ ÙŠØ­ØªØ§Ø¬Ù‡Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­. ÙˆØªÙˆØ¬Ø¯ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…Ù…ÙŠØ²Ø© ØªØ­Øª Ù…ÙØªØ§Ø­ `input_ids`:\n+\n+```python\n+>>> encoded_sequence = inputs[\"input_ids\"]\n+>>> print(encoded_sequence)\n+[101ØŒ 138ØŒ 18696ØŒ 155ØŒ 1942ØŒ 3190ØŒ 1144ØŒ 1572ØŒ 13745ØŒ 1104ØŒ 159ØŒ 9664ØŒ 2107ØŒ 102]\n+```\n+\n+Ù„Ø§Ø­Ø¸ Ø£Ù† Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ù„ØºÙˆÙŠ ÙŠØ¶ÙŠÙ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ \"Ø±Ù…ÙˆØ²Ù‹Ø§ Ø®Ø§ØµØ©\" (Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø±ØªØ¨Ø· ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„ÙŠÙ‡Ø§) ÙˆÙ‡ÙŠ Ù…Ø¹Ø±ÙØ§Øª Ø®Ø§ØµØ©\n+ÙŠØ³ØªØ®Ø¯Ù…Ù‡Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø­ÙŠØ§Ù†.\n+\n+Ø¥Ø°Ø§ Ù‚Ù…Ù†Ø§ Ø¨ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚ØŒ\n+\n+```python\n+>>> decoded_sequence = tokenizer.decode(encoded_sequence)\n+```\n+\n+Ø³Ù†Ø±Ù‰\n+\n+```python\n+>>> print(decoded_sequence)\n+[CLS] A Titan RTX has 24GB of VRAM [SEP]\n+```\n+\n+Ù„Ø£Ù† Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙŠ ÙŠØªÙˆÙ‚Ø¹ Ø¨Ù‡Ø§ Ù†Ù…ÙˆØ°Ø¬ [`BertModel`] Ø¥Ø¯Ø®Ø§Ù„Ø§ØªÙ‡.\n+\n+## L\n+\n+### Ø§Ø§Ù„Ù…Ù„ØµÙ‚Ø§Øª (Labels)\n+\n+Ù‡ÙŠ Ù…Ø¹Ø§Ù…Ù„ Ø§Ø®ØªÙŠØ§Ø±ÙŠ ÙŠÙ…ÙƒÙ† Ø¥Ø¯Ø®Ø§Ù„Ù‡ ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ù†ÙØ³Ù‡.\n+Ù†Ù…Ø§Ø°Ø¬ ØªØµÙ†ÙŠÙ Ø§Ù„ØªØ³Ù„Ø³Ù„: ([BertForSequenceClassification]) ÙŠØªÙˆÙ‚Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØµÙÙˆÙØ© Ø°Ø§Øª Ø¨Ø¹Ø¯ (batch_size) Ø­ÙŠØ« ØªØªÙˆØ§ÙÙ‚ ÙƒÙ„ Ù‚ÙŠÙ…Ø© Ù…Ù† Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ø¹ Ø§Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù„Ù„ØªØ³Ù„Ø³Ù„ Ø¨Ø£ÙƒÙ…Ù„Ù‡.\n+Ù†Ù…Ø§Ø°Ø¬ ØªØµÙ†ÙŠÙ Ø§Ù„Ø±Ù…Ø²: ([BertForTokenClassification]) ÙŠØªÙˆÙ‚Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØµÙÙˆÙØ© Ø°Ø§Øª Ø¨Ø¹Ø¯ (batch_size, seq_length) Ø­ÙŠØ« ØªØªÙˆØ§ÙÙ‚ ÙƒÙ„ Ù‚ÙŠÙ…Ø© Ù…Ø¹ Ø§Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù„ÙƒÙ„ Ø±Ù…Ø² ÙØ±Ø¯ÙŠ.\n+Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºÙˆÙŠØ© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø©:([BertForMaskedLM]) ÙŠØªÙˆÙ‚Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØµÙÙˆÙØ© Ø°Ø§Øª Ø¨Ø¹Ø¯ (batch_size, seq_length) Ø­ÙŠØ« ØªØªÙˆØ§ÙÙ‚ ÙƒÙ„ Ù‚ÙŠÙ…Ø© Ù…Ø¹ Ø§Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù„ÙƒÙ„ Ø±Ù…Ø² ÙØ±Ø¯ÙŠ: ØªÙƒÙˆÙ† Ø§Ù„Ù…Ù„ØµÙ‚Ø§Øª Ù‡ÙŠ Ù…Ø¹Ø±Ù Ø±Ù…Ø² Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø©ØŒ ÙˆØ§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø£Ø®Ø±Ù‰ ÙŠØªÙ… ØªØ¬Ø§Ù‡Ù„Ù‡Ø§ (Ø¹Ø§Ø¯Ø©Ù‹ -100).\n+Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø¥Ù„Ù‰ Ø§Ù„ØªØ³Ù„Ø³Ù„: ([BartForConditionalGeneration], [MBartForConditionalGeneration]) ÙŠØªÙˆÙ‚Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØµÙÙˆÙØ© Ø°Ø§Øª Ø¨Ø¹Ø¯ (batch_size, tgt_seq_length) Ø­ÙŠØ« ØªØªÙˆØ§ÙÙ‚ ÙƒÙ„ Ù‚ÙŠÙ…Ø© Ù…Ø¹ Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ù…Ø±ØªØ¨Ø· Ø¨ÙƒÙ„ ØªØ³Ù„Ø³Ù„ Ù…Ø¯Ø®Ù„. Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ Ø³ÙŠÙ‚ÙˆÙ… ÙƒÙ„ Ù…Ù† BART Ùˆ T5 Ø¨Ø¥Ù†Ø´Ø§Ø¡ decoder_input_ids Ùˆ decoder attention masks Ø¯Ø§Ø®Ù„ÙŠÙ‹Ø§. Ø¹Ø§Ø¯Ø©Ù‹ Ù„Ø§ ÙŠÙ„Ø²Ù… ØªÙˆÙÙŠØ±Ù‡Ø§. Ù‡Ø°Ø§ Ù„Ø§ ÙŠÙ†Ø·Ø¨Ù‚ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… Ø¥Ø·Ø§Ø± Ø§Ù„Ø¹Ù…Ù„ Encoder-Decoder.\n+Ù†Ù…Ø§Ø°Ø¬ ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ±: ([ViTForImageClassification]) ÙŠØªÙˆÙ‚Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØµÙÙˆÙØ© Ø°Ø§Øª Ø¨Ø¹Ø¯ (batch_size) Ø­ÙŠØ« ØªØªÙˆØ§ÙÙ‚ ÙƒÙ„ Ù‚ÙŠÙ…Ø© Ù…Ù† Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ø¹ Ø§Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù„ÙƒÙ„ ØµÙˆØ±Ø© ÙØ±Ø¯ÙŠØ©.\n+Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ: ([SegformerForSemanticSegmentation]) ÙŠØªÙˆÙ‚Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØµÙÙˆÙØ© Ø°Ø§Øª Ø¨Ø¹Ø¯ (batch_size, height, width) Ø­ÙŠØ« ØªØªÙˆØ§ÙÙ‚ ÙƒÙ„ Ù‚ÙŠÙ…Ø© Ù…Ù† Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ø¹ Ø§Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù„ÙƒÙ„ Ø¨ÙƒØ³Ù„ ÙØ±Ø¯ÙŠ.\n+Ù†Ù…Ø§Ø°Ø¬ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø¬Ø³Ø§Ù…: ([DetrForObjectDetection]) ÙŠØªÙˆÙ‚Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ class_labels Ùˆ boxes Ø­ÙŠØ« ØªØªÙˆØ§ÙÙ‚ ÙƒÙ„ Ù‚ÙŠÙ…Ø© Ù…Ù† Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ø¹ Ø§Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ ÙˆØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª Ø§Ù„Ù…Ø­ÙŠØ·Ø© Ø¨ÙƒÙ„ ØµÙˆØ±Ø© ÙØ±Ø¯ÙŠØ©.\n+Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…: ([Wav2Vec2ForCTC]) ÙŠØªÙˆÙ‚Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØµÙÙˆÙØ© Ø°Ø§Øª Ø¨Ø¹Ø¯ (batch_size, target_length) Ø­ÙŠØ« ØªØªÙˆØ§ÙÙ‚ ÙƒÙ„ Ù‚ÙŠÙ…Ø© Ù…Ø¹ Ø§Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù„ÙƒÙ„ Ø±Ù…Ø² ÙØ±Ø¯ÙŠ.\n+\n+<Tip>\n+\n+Ù‚Ø¯ ØªØ®ØªÙ„Ù ØªØ³Ù…ÙŠØ§Øª ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬ØŒ Ù„Ø°Ø§ ØªØ£ÙƒØ¯ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ù…Ù† Ù…Ø±Ø§Ø¬Ø¹Ø© ÙˆØ«Ø§Ø¦Ù‚ ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ Ø§Ù„ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡.\n+\n+</Tip>\n+Ù„Ø§ ØªÙ‚Ø¨Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ([`BertModel`]) Ø§Ù„Ù…Ù„ØµÙ‚Ø§Øª ØŒ Ù„Ø£Ù†Ù‡Ø§ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­ÙˆÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©ØŒ ÙˆØ§Ù„ØªÙŠ ØªÙ‚ÙˆÙ… Ø¨Ø¨Ø³Ø§Ø·Ø© Ø¨Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª.\n+\n+### Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ© Ø§Ù„ÙƒØ¨ÙŠØ±Ø© large language models (LLM)\n+\n+Ù…ØµØ·Ù„Ø­ Ø¹Ø§Ù… ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø­ÙˆÙ„Ø© (GPT-3 Ùˆ BLOOM Ùˆ OPT) Ø§Ù„ØªÙŠ ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡Ø§ Ø¹Ù„Ù‰ ÙƒÙ…ÙŠØ© ÙƒØ¨ÙŠØ±Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. ØªÙ…ÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ù„Ù‰ ÙˆØ¬ÙˆØ¯ Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù…Ù† Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ù„Ù… (Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ 175 Ù…Ù„ÙŠØ§Ø± Ù„Ù…Ø¹Ù„Ù…Ø© GPT-3).\n+\n+## M\n+\n+### Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø© masked language modeling (MLM)\n+\n+Ù…Ù‡Ù…Ø© ØªØ¯Ø±ÙŠØ¨ Ù…Ø³Ø¨Ù‚ Ø­ÙŠØ« ÙŠØ±Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù†Ø³Ø®Ø© ØªØ§Ù„ÙØ© Ù…Ù† Ø§Ù„Ù†ØµÙˆØµØŒ ÙˆØ¹Ø§Ø¯Ø© Ù…Ø§ ÙŠØªÙ… Ø°Ù„Ùƒ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø­Ø¬Ø¨ Ø¨Ø¹Ø¶ Ø§Ù„Ø±Ù…ÙˆØ² Ø¨Ø´ÙƒÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠØŒ ÙˆÙŠØªØ¹ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ.\n+\n+### Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ³Ø§Ø¦Ø· (multimodal)\n+\n+Ù…Ù‡Ù…Ø© ØªØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ù†ØµÙˆØµ Ù…Ø¹ Ù†ÙˆØ¹ Ø¢Ø®Ø± Ù…Ù† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª (Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø§Ù„ØµÙˆØ±).\n+\n+## N\n+\n+### ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© Natural language generation (NLG)\n+\n+Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†Øµ (Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ [Ø§ÙƒØªØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª](https://transformer.huggingface.co/)ØŒ ÙˆØ§Ù„ØªØ±Ø¬Ù…Ø©).\n+\n+### Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© Natural language processing (NLP)\n+\n+Ø·Ø±ÙŠÙ‚Ø© Ø¹Ø§Ù…Ø© Ù„Ù„Ù‚ÙˆÙ„ \"Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù†ØµÙˆØµ\".\n+\n+### ÙÙ‡Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© Natural language understanding (NLU)\n+\n+Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨ÙÙ‡Ù… Ù…Ø§ Ù‡Ùˆ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù†Øµ (Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Øµ Ø¨Ø£ÙƒÙ…Ù„Ù‡ØŒ Ø£Ùˆ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙØ±Ø¯ÙŠØ©).\n+\n+## P\n+\n+### Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ (pipeline)\n+\n+ÙÙŠ Ù…ÙƒØªØ¨Ø© TransformersØŒ ÙŠÙØ´ÙŠØ± Ù…ØµØ·Ù„Ø­ \"Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨\" Ø¥Ù„Ù‰ Ø³Ù„Ø³Ù„Ø© Ù…Ù† Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªÙŠ ÙŠØªÙ… ØªÙ†ÙÙŠØ°Ù‡Ø§ Ø¨ØªØ±ØªÙŠØ¨ Ù…Ø­Ø¯Ø¯ Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ ÙˆØ¥Ø±Ø¬Ø§Ø¹ ØªÙ†Ø¨Ø¤ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬. Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù‚Ø¯ ØªØ´Ù…Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©ØŒ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§ØªØŒ ÙˆØ§Ù„ØªÙˆØ­ÙŠØ¯.\n+\n+Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ØŒ Ø±Ø§Ø¬Ø¹ [Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„](https://huggingface.co/docs/transformers/pipeline_tutorial).\n+\n+### Ø§Ù„ØªÙˆØ§Ø²ÙŠ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ (PipelineParallel)\n+\n+ØªÙ‚Ù†ÙŠØ© ØªÙˆØ§Ø²ÙŠ ÙŠØªÙ… ÙÙŠÙ‡Ø§ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø±Ø£Ø³ÙŠØ§Ù‹ (Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø·Ø¨Ù‚Ø©) Ø¹Ø¨Ø± ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU) Ù…ØªØ¹Ø¯Ø¯Ø©ØŒ Ø¨Ø­ÙŠØ« ØªÙˆØ¬Ø¯ Ø·Ø¨Ù‚Ø© ÙˆØ§Ø­Ø¯Ø© Ø£Ùˆ Ø¹Ø¯Ø© Ø·Ø¨Ù‚Ø§Øª Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU) ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·. ØªÙ‚ÙˆÙ… ÙƒÙ„ ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³ÙˆÙ…Ø§Øª (GPU) Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø±Ø§Ø­Ù„ Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ ÙˆØ§Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Ø¬Ø²Ø¡ ØµØºÙŠØ± Ù…Ù† Ø§Ù„Ø¯ÙØ¹Ø©. ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø²ÙŠØ¯ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© Ø¹Ù…Ù„ PipelineParallel [Ù‡Ù†Ø§](perf_train_gpu_many#from-naive-model-parallelism-to-pipeline-parallelism).\n+\n+### Ù‚ÙŠÙ… Ø§Ù„Ø¨ÙƒØ³Ù„ (pixel values)\n+\n+Ù…ØµÙÙˆÙØ© Ù…Ù† Ø§Ù„ØªÙ…Ø«ÙŠÙ„Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ù„ØµÙˆØ±Ø© ÙŠØªÙ… ØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ø¥Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬. ØªØ£Ø®Ø° Ù‚ÙŠÙ… Ø§Ù„Ø¨ÙƒØ³Ù„ Ø´ÙƒÙ„ [`batch_size`ØŒ `num_channels`ØŒ `height`ØŒ `width`]ØŒ ÙˆÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ Ù…Ù† Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ±.\n+\n+### Ø§Ù„ØªØ¬Ù…ÙŠØ¹ (Pooling)\n+\n+Ù‡ÙŠ Ø¹Ù…Ù„ÙŠØ© ØªÙ‚ÙˆÙ… Ø¨ØªÙ‚Ù„ÙŠØµ Ù…ØµÙÙˆÙØ© Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© Ø£ØµØºØ±ØŒ Ø¥Ù…Ø§ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø£Ø®Ø° Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù‚ØµÙˆÙ‰ Ø£Ùˆ Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠ Ù„Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ØªÙŠ ÙŠØªÙ… ØªØ¬Ù…ÙŠØ¹Ù‡Ø§. ØªÙˆØ¬Ø¯ Ø·Ø¨Ù‚Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø¨Ø´ÙƒÙ„ Ø´Ø§Ø¦Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„ØªÙ„Ø§ÙÙŠÙÙŠØ© convolutional layers Ù„ØªÙ‚Ù„ÙŠÙ„ Ø­Ø¬Ù… ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª.\n+\n+### Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ù…ÙˆØ¶Ø¹ (position IDs)\n+\n+Ø¹Ù„Ù‰ Ø¹ÙƒØ³ Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ© Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© (RNNs) Ø§Ù„ØªÙŠ ØªØªØ¶Ù…Ù† Ù…ÙˆØ¶Ø¹ ÙƒÙ„ Ø±Ù…Ø² (token) Ø¶Ù…Ù† Ø¨Ù†ÙŠØªÙ‡Ø§ØŒ Ù„Ø§ ØªØ¯Ø±Ùƒ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª Ù…ÙˆØ¶Ø¹ ÙƒÙ„ Ø±Ù…Ø². Ù„Ø°Ù„ÙƒØŒ ØªØ³ØªØ®Ø¯Ù… Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ù…ÙˆØ¶Ø¹ (`position_ids`) Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØ­Ø¯ÙŠØ¯ Ù…ÙˆØ¶Ø¹ ÙƒÙ„ Ø±Ù…Ø² ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ù…ÙˆØ².\n+\n+Ø¥Ù†Ù‡Ø§ Ù…Ø¹Ù„Ù…Ø© Ø§Ø®ØªÙŠØ§Ø±ÙŠØ©. Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… ØªÙ…Ø±ÙŠØ± Ø£ÙŠ `position_ids` Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ ÙƒØªØ±Ù…ÙŠØ²Ø§Øª Ù…ÙˆØ¶Ø¹ÙŠØ© Ù…Ø·Ù„Ù‚Ø©.\n+\n+ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØªØ±Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ÙˆØ¶Ø¹ÙŠØ© Ø§Ù„Ù…Ø·Ù„Ù‚Ø© ÙÙŠ Ø§Ù„Ù†Ø·Ø§Ù‚ `[0ØŒ config.max_position_embeddings - 1]`. ØªØ³ØªØ®Ø¯Ù… Ø¨Ø¹Ø¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø£Ù†ÙˆØ§Ø¹Ù‹Ø§ Ø£Ø®Ø±Ù‰ Ù…Ù† Ø§Ù„ØªØ±Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ÙˆØ¶Ø¹ÙŠØ©ØŒ Ù…Ø«Ù„ Ø§Ù„ØªØ±Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ÙˆØ¶Ø¹ÙŠØ© Ø§Ù„Ø¬ÙŠØ¨ÙŠØ© Ø£Ùˆ Ø§Ù„ØªØ±Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ÙˆØ¶Ø¹ÙŠØ© Ø§Ù„Ù†Ø³Ø¨ÙŠØ©.\n+\n+### Ù…Ø§ Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (preprocessing) \n+\n+Ù…Ù‡Ù…Ø© Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù… Ø¨ØªÙ†Ø³ÙŠÙ‚ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªØ³ØªÙ‡Ù„ÙƒÙ‡ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø¨Ø³Ù‡ÙˆÙ„Ø©. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¹Ø§Ø¯Ø©Ù‹ Ù…Ø§ ØªØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ù„ØªÙ…ÙŠÙŠØ². Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙÙƒØ±Ø© Ø£ÙØ¶Ù„ Ø¹Ù† ÙƒÙŠÙÙŠØ© Ø¸Ù‡ÙˆØ± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø£Ø®Ø±Ù‰ØŒ Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ [Preprocess](https://huggingface.co/docs/transformers/preprocessing).\n+\n+### Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³Ø¨Ù‚ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (pretrained model)\n+\n+Ù†Ù…ÙˆØ°Ø¬ ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¹Ù„Ù‰ Ø¨Ø¹Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ÙƒÙ„ Wikipedia). ØªÙ†Ø·ÙˆÙŠ Ø·Ø±Ù‚ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³Ø¨Ù‚ Ø¹Ù„Ù‰ Ù‡Ø¯Ù Ø°Ø§ØªÙŠ Ø§Ù„Ø¥Ø´Ø±Ø§ÙØŒ ÙˆØ§Ù„Ø°ÙŠ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ ÙˆÙ…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© ( Ø±Ø§Ø¬Ø¹ (causal-language-modeling#)[Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø³Ø¨Ø¨ÙŠØ©] ) Ø£Ùˆ Ù‚Ù†Ø§Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙˆÙ…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‡Ø§ ( Ø±Ø§Ø¬Ø¹ (masked-language#)[Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ù‚Ù†Ø¹Ø©]- Ø¹Ø±Ø¶ MLM).\n+\n+Ù„Ø¯Ù‰ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ÙƒÙ„Ø§Ù… ÙˆØ§Ù„Ø±Ø¤ÙŠØ© Ø£Ù‡Ø¯Ø§ÙÙ‡Ø§ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø§Ù„Ø®Ø§ØµØ©. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Wav2Vec2 Ù‡Ùˆ Ù†Ù…ÙˆØ°Ø¬ ÙƒÙ„Ø§Ù… ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¹Ù„Ù‰ Ù…Ù‡Ù…Ø© ØªØ¨Ø§ÙŠÙ†ÙŠØ© ØªØªØ·Ù„Ø¨ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ø¯ÙŠØ¯ ØªÙ…Ø«ÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… \"Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ\" Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† ØªÙ…Ø«ÙŠÙ„Ø§Øª Ø§Ù„ÙƒÙ„Ø§Ù… \"Ø§Ù„Ø®Ø§Ø·Ø¦Ø©\". Ù…Ù† Ù†Ø§Ø­ÙŠØ© Ø£Ø®Ø±Ù‰ØŒ BEiT Ù‡Ùˆ Ù†Ù…ÙˆØ°Ø¬ Ø±Ø¤ÙŠØ© ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¹Ù„Ù‰ Ù…Ù‡Ù…Ø© Ù†Ù…Ø°Ø¬Ø© ØµÙˆØ±Ø© Ù…Ù‚Ù†Ø¹Ø© ØªÙ‚ÙˆÙ… Ø¨Ù‚Ù†Ø§Ø¹ Ø¨Ø¹Ø¶ Ø±Ù‚Ø¹ Ø§Ù„ØµÙˆØ±Ø© ÙˆØªØªØ·Ù„Ø¨ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø±Ù‚Ø¹ Ø§Ù„Ù…Ù‚Ù†Ø¹Ø© (Ù…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù‡Ø¯Ù Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ù‚ÙŠØ¯Ø©).\n+\n+## R\n+\n+### Ø´Ø¨ÙƒØ© Ø¹ØµØ¨ÙŠØ© Ù…ØªÙƒØ±Ø±Ø© (RNN)\n+\n+Ù‡ÙŠ Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… Ø­Ù„Ù‚Ø© Ù…ØªÙƒØ±Ø±Ø© ÙÙˆÙ‚ Ø·Ø¨Ù‚Ø© Ù…Ø¹ÙŠÙ†Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ.\n+\n+### Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„ØªÙ…Ø«ÙŠÙ„ÙŠ (representation learning)\n+\n+Ù‡Ùˆ ÙØ±Ø¹ Ù…Ù† ÙØ±ÙˆØ¹ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø© ÙŠØ±ÙƒØ² Ø¹Ù„Ù‰ ØªØ¹Ù„Ù… ØªÙ…Ø«ÙŠÙ„Ø§Øª Ø°Ø§Øª Ù…Ø¹Ù†Ù‰ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù…. Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„ØªÙ…Ø«ÙŠÙ„ÙŠ ØªØ´Ù…Ù„ ØªØ¶Ù…ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§ØªØŒ ÙˆØ§Ù„Ù…Ø´ÙØ±Ø§Øª Ø°Ø§ØªÙŠØ©ØŒ ÙˆØ´Ø¨ÙƒØ§Øª Ø§Ù„ØªÙ†Ø§ÙØ³ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ÙŠØ©(GANs).\n+\n+## S\n+\n+### Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª (sampling rate)\n+\n+Ù‚ÙŠØ§Ø³ØŒ Ø¨Ø§Ù„Ù‡Ø±ØªØ²ØŒ Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª (Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ØµÙˆØª) Ø§Ù„Ù…Ø£Ø®ÙˆØ°Ø© ÙÙŠ Ø§Ù„Ø«Ø§Ù†ÙŠØ©. ÙŠÙ†ØªØ¬ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø¹Ù† ØªÙ…ÙŠÙŠØ² Ø¥Ø´Ø§Ø±Ø© Ù…Ø³ØªÙ…Ø±Ø© Ù…Ø«Ù„ Ø§Ù„ÙƒÙ„Ø§Ù….\n+\n+### Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ø§Ù„Ø°Ø§ØªÙŠ (Self-Attention)\n+\n+Ù‡Ùˆ Ø¢Ù„ÙŠØ© ØªØªÙŠØ­ Ù„ÙƒÙ„ Ø¹Ù†ØµØ± ÙÙŠ Ø§Ù„Ù…Ø¯Ø®Ù„ Ø£Ù† ÙŠØ­Ø¯Ø¯ Ø£ÙŠ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø£Ø®Ø±Ù‰ ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…Ø¯Ø®Ù„ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙ†ØªØ¨Ù‡ Ø¥Ù„ÙŠÙ‡Ø§.\n+\n+### Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø°Ø§ØªÙŠ Ø§Ù„Ø®Ø§Ø¶Ø¹ Ù„Ù„Ø¥Ø´Ø±Ø§Ù (supervised learning)\n+\n+ÙØ¦Ø© Ù…Ù† ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„ØªÙŠ ÙŠÙ‚ÙˆÙ… ÙÙŠÙ‡Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø¯ÙÙ‡ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„Ø®Ø§Øµ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ÙˆØ³ÙˆÙ…Ø©. ÙŠØ®ØªÙ„Ù Ø¹Ù† [Ø§Ù„ØªØ¹Ù„Ù… ØºÙŠØ± Ø§Ù„Ø®Ø§Ø¶Ø¹ Ù„Ù„Ø¥Ø´Ø±Ø§Ù](#unsupervised-learning) Ùˆ [Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø®Ø§Ø¶Ø¹ Ù„Ù„Ø¥Ø´Ø±Ø§Ù](#supervised-learning) ÙÙŠ Ø£Ù† Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¹Ù„Ù… Ø®Ø§Ø¶Ø¹Ø© Ù„Ù„Ø¥Ø´Ø±Ø§ÙØŒ ÙˆÙ„ÙƒÙ† Ù„ÙŠØ³ ØµØ±Ø§Ø­Ø© Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….\n+\n+Ù…Ø«Ø§Ù„ ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø°Ø§ØªÙŠ Ø§Ù„Ø®Ø§Ø¶Ø¹ Ù„Ù„Ø¥Ø´Ø±Ø§Ù Ù‡Ùˆ [Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ù‚ÙŠØ¯Ø©](#masked-language- Ø¹Ø±Ø¶ MLM)ØŒ Ø­ÙŠØ« ÙŠØªÙ… ØªÙ…Ø±ÙŠØ± Ø¬Ù…Ù„ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ù†Ø³Ø¨Ø© Ù…Ù† Ø±Ù…ÙˆØ²Ù‡ ÙˆÙŠØªØ¹Ù„Ù… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©.\n+\n+### Ø§Ù„ØªØ¹Ù„Ù… Ø´Ø¨Ù‡ Ø§Ù„Ø®Ø§Ø¶Ø¹ Ù„Ù„Ø¥Ø´Ø±Ø§Ù (semi-supervised learning)\n+\n+ÙØ¦Ø© ÙˆØ§Ø³Ø¹Ø© Ù…Ù† ØªÙ‚Ù†ÙŠØ§Øª ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„ØªÙŠ ØªØ³ØªÙÙŠØ¯ Ù…Ù† ÙƒÙ…ÙŠØ© ØµØºÙŠØ±Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ³ÙˆÙ…Ø© Ù…Ø¹ ÙƒÙ…ÙŠØ© Ø£ÙƒØ¨Ø± Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ÙˆØ³ÙˆÙ…Ø© Ù„ØªØ­Ø³ÙŠÙ† Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ Ø¹Ù„Ù‰ Ø¹ÙƒØ³ [Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø®Ø§Ø¶Ø¹ Ù„Ù„Ø¥Ø´Ø±Ø§Ù](#supervised-learning) Ùˆ [Ø§Ù„ØªØ¹Ù„Ù… ØºÙŠØ± Ø§Ù„Ø®Ø§Ø¶Ø¹ Ù„Ù„Ø¥Ø´Ø±Ø§Ù](#unsupervised-learning).\n+\n+Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ù†Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø´Ø¨Ù‡ Ø§Ù„Ø®Ø§Ø¶Ø¹ Ù„Ù„Ø¥Ø´Ø±Ø§Ù Ù‡Ùˆ \"Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø°Ø§ØªÙŠ\"ØŒ Ø­ÙŠØ« ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ³ÙˆÙ…Ø©ØŒ Ø«Ù… ÙŠØ³ØªØ®Ø¯Ù… Ù„ØªÙ‚Ø¯ÙŠÙ… ØªÙ†Ø¨Ø¤Ø§Øª Ø­ÙˆÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ÙˆØ³ÙˆÙ…Ø©. ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ÙˆØ³ÙˆÙ…Ø© Ø§Ù„ØªÙŠ ÙŠØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø£ÙƒØ¨Ø± Ù‚Ø¯Ø± Ù…Ù† Ø§Ù„Ø«Ù‚Ø© Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ³ÙˆÙ…Ø© ÙˆÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n+\n+### ØªØ³Ù„Ø³Ù„ Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„ (seq2seq)\n+\n+Ù†Ù…Ø§Ø°Ø¬ ØªÙˆÙ„Ø¯ ØªØ³Ù„Ø³Ù„Ù‹Ø§ Ø¬Ø¯ÙŠØ¯Ù‹Ø§ Ù…Ù† Ø¥Ø¯Ø®Ø§Ù„ØŒ Ù…Ø«Ù„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ±Ø¬Ù…Ø©ØŒ Ø£Ùˆ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙ„Ø®ÙŠØµ (Ù…Ø«Ù„ [Bart](model_doc/bart) Ø£Ùˆ [T5](model_doc/t5)).\n+\n+### Sharded DDP\n+\n+Ø§Ø³Ù… Ø¢Ø®Ø± Ù„Ù…ÙÙ‡ÙˆÙ… [Zero Redundancy Optimizer](#zero-redundancy-optimizer-zero) Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙƒÙ…Ø§ Ù‡Ùˆ Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ Ù„Ù€ Zero.\n+\n+### Ø§Ù„Ø®Ø·ÙˆØ© (Stride)\n+\n+ÙÙŠ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªÙ„Ø§ÙÙŠÙÙŠØ© Ø£Ùˆ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ÙŠØ©ØŒ ØªØ´ÙŠØ± Ø§Ù„Ø®Ø·ÙˆØ© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„ØªÙŠ ÙŠØªØ­Ø±Ùƒ Ø¨Ù‡Ø§ Ø§Ù„Ù†ÙˆØ§Ø© (kernel) ÙÙˆÙ‚ Ø§Ù„Ù…ØµÙÙˆÙØ©. Ø®Ø·ÙˆØ© ØªØ³Ø§ÙˆÙŠ 1 ØªØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„Ù†ÙˆØ§Ø© ØªØªØ­Ø±Ùƒ Ø¨ÙƒØ³Ù„ ÙˆØ§Ø­Ø¯ ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©.\n+\n+### Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø®Ø§Ø¶Ø¹ Ù„Ù„Ø¥Ø´Ø±Ø§Ù (supervised learning)\n+\n+Ù‡Ùˆ Ù†ÙˆØ¹ Ù…Ù† ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙØ¹Ù„Ù‘ÙÙ…Ø© Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø§Ø´Ø± Ù„ØªØµØ­ÙŠØ­ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªÙˆØ¬ÙŠÙ‡Ù‡. ÙŠØªÙ… ØªØºØ°ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‚ÙŠØ¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ ÙˆÙŠØªÙ… Ù…Ù‚Ø§Ø±Ù†Ø© ØªÙ†Ø¨Ø¤Ø§ØªÙ‡ Ø¨Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØµØ­ÙŠØ­Ø© Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©. ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨ØªØ¹Ø¯ÙŠÙ„ Ø£ÙˆØ²Ø§Ù†Ù‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø¯Ù‰ Ø®Ø·Ø£ ØªÙ†Ø¨Ø¤Ø§ØªÙ‡ØŒ ÙˆØªØªÙƒØ±Ø± Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù„ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n+\n+## T\n+\n+### ØªÙˆØ§Ø²ÙŠ Tensor (TP)\n+\n+ØªÙ‚Ù†ÙŠØ© ØªÙˆØ§Ø²ÙŠ Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU) Ù…ØªØ¹Ø¯Ø¯Ø© ÙŠØªÙ… ÙÙŠÙ‡Ø§ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…ØµÙÙˆÙØ© Ø¥Ù„Ù‰ Ø¹Ø¯Ø© Ø£Ø¬Ø²Ø§Ø¡ØŒ Ù„Ø°Ø§ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…ØµÙÙˆÙØ© Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU) ÙˆØ§Ø­Ø¯Ø©ØŒ ØªÙˆØ¬Ø¯ ÙƒÙ„ Ø´Ø¸ÙŠØ© Ù…Ù† Ø§Ù„Ù…ØµÙÙˆÙØ© Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU) Ø§Ù„Ù…Ø®ØµØµØ© Ù„Ù‡Ø§. ØªØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø´Ø¸Ø§ÙŠØ§ Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„ ÙˆØ¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU) Ø§Ù„Ù…Ø®ØªÙ„ÙØ© ÙˆÙŠØªÙ… Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø®Ø·ÙˆØ© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©. Ù‡Ø°Ø§ Ù…Ø§ ÙŠÙØ·Ù„Ù‚ Ø¹Ù„ÙŠÙ‡ Ø£Ø­ÙŠØ§Ù†Ù‹Ø§ Ø§Ù„ØªÙˆØ§Ø²ÙŠ Ø§Ù„Ø£ÙÙ‚ÙŠØŒ Ø­ÙŠØ« ÙŠØ­Ø¯Ø« Ø§Ù„Ø§Ù†Ù‚Ø³Ø§Ù… Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£ÙÙ‚ÙŠ.\n+\n+ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø²ÙŠØ¯ Ø­ÙˆÙ„ ØªÙˆØ§Ø²ÙŠ Tensor [Ù‡Ù†Ø§](perf_train_gpu_many#tensor-parallelism).\n+\n+### Ø§Ù„Ø±Ù…Ø² Ø§Ù„Ù„ØºÙˆÙŠ (Token)\n+\n+Ø¬Ø²Ø¡ Ù…Ù† Ø¬Ù…Ù„Ø©ØŒ Ø¹Ø§Ø¯Ø© Ù…Ø§ ÙŠÙƒÙˆÙ† ÙƒÙ„Ù…Ø©ØŒ ÙˆÙ„ÙƒÙ† ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ø£ÙŠØ¶Ù‹Ø§ ÙƒÙ„Ù…Ø© ÙØ±Ø¹ÙŠØ© (ØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ÙŠØªÙ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ÙƒÙ„Ù…Ø§Øª ØºÙŠØ± Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ø¥Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª ÙØ±Ø¹ÙŠØ©) Ø£Ùˆ Ø¹Ù„Ø§Ù…Ø© ØªØ±Ù‚ÙŠÙ….\n+\n+### Ù…Ø¹Ø±ÙØ§Øª Ù†ÙˆØ¹ Ø§Ù„Ø±Ù…Ø² (token type ids)\n+\n+Ø§Ù„ØºØ±Ø¶ Ù…Ù† Ø¨Ø¹Ø¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù‡Ùˆ Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªØµÙ†ÙŠÙ Ø¹Ù„Ù‰ Ø£Ø²ÙˆØ§Ø¬ Ù…Ù† Ø§Ù„Ø¬Ù…Ù„ Ø£Ùˆ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©.\n+\n+<Youtube id=\"0u3ioSwev3s\"/>\n+\n+ÙŠØªØ·Ù„Ø¨ Ø°Ù„Ùƒ ØªØ³Ù„Ø³Ù„ÙŠÙ† Ù…Ø®ØªÙ„ÙÙŠÙ† ÙŠØªÙ… Ø¯Ù…Ø¬Ù‡Ù…Ø§ ÙÙŠ Ø¥Ø¯Ø®Ø§Ù„ \"input_ids\" ÙˆØ§Ø­Ø¯ØŒ ÙˆØ§Ù„Ø°ÙŠ ÙŠØªÙ… Ø¹Ø§Ø¯Ø©Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø±Ù…ÙˆØ² Ø®Ø§ØµØ©ØŒ Ù…Ø«Ù„ Ø±Ù…ÙˆØ² Ø§Ù„ØªØµÙ†ÙŠÙ (`[CLS]`) ÙˆØ§Ù„ÙØ§ØµÙ„ (`[SEP]`). Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ÙŠÙ‚ÙˆÙ… Ù†Ù…ÙˆØ°Ø¬ BERT Ø¨Ø¨Ù†Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ ØªØ³Ù„Ø³Ù„ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø­Ùˆ Ø§Ù„ØªØ§Ù„ÙŠ:\n+\n+```python\n+>>> # [CLS] SEQUENCE_A [SEP] SEQUENCE_B [SEP]\n+```\n+\n+ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø±Ù†Ø§Ù…Ø¬Ù†Ø§ Ù„Ù„ØªÙ…ÙŠÙŠØ² Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø¬Ù…Ù„Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªÙ…Ø±ÙŠØ± Ø§Ù„ØªØ³Ù„Ø³Ù„ÙŠÙ† Ø¥Ù„Ù‰ `tokenizer` ÙƒÙ…Ø¹Ø§Ù…Ù„ÙŠÙŠÙ† (ÙˆÙ„ÙŠØ³ Ù‚Ø§Ø¦Ù…Ø©ØŒ ÙƒÙ…Ø§ ÙƒØ§Ù† Ù…Ù† Ù‚Ø¨Ù„) Ù…Ø«Ù„ Ù‡Ø°Ø§:\n+\n+```python\n+>>> from transformers import BertTokenizer\n+\n+>>> tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n+>>> sequence_a = \"HuggingFace is based in NYC\"\n+>>> sequence_b = \"Where is HuggingFace based?\"\n+\n+>>> encoded_dict = tokenizer(sequence_aØŒ sequence_b)\n+>>> decoded = tokenizer.decode(encoded_dict[\"input_ids\"])\n+```\n+\n+ÙˆØ§Ù„Ø°ÙŠ Ø³ÙŠØ¹ÙŠØ¯:\n+\n+```python\n+>>> print(decoded)\n+[CLS] HuggingFace is based in NYC [SEP] Where is HuggingFace basedØŸ [SEP]\n+```\n+\n+Ù‡Ø°Ø§ ÙŠÙƒÙÙŠ Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„ÙÙ‡Ù… Ø£ÙŠÙ† ÙŠÙ†ØªÙ‡ÙŠ ØªØ³Ù„Ø³Ù„ ÙˆØ§Ø­Ø¯ ÙˆØ£ÙŠÙ† ÙŠØ¨Ø¯Ø£ Ø§Ù„Ø¢Ø®Ø±. ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ ØªØ³ØªØ®Ø¯Ù… Ù†Ù…Ø§Ø°Ø¬ Ø£Ø®Ø±Ù‰ØŒ Ù…Ø«Ù„ BERTØŒ Ø£ÙŠØ¶Ù‹Ø§ Ù…Ø¹Ø±ÙØ§Øª Ù†ÙˆØ¹ Ø§Ù„Ø±Ù…Ø² (ÙŠÙØ·Ù„Ù‚ Ø¹Ù„ÙŠÙ‡Ø§ Ø£ÙŠØ¶Ù‹Ø§ Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ø¬Ø²Ø¡). ÙŠØªÙ… ØªÙ…Ø«ÙŠÙ„Ù‡Ø§ ÙƒÙ…Ø§Ø³Ùƒ Ø«Ù†Ø§Ø¦ÙŠ Ù„ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ÙŠ Ø§Ù„ØªØ³Ù„Ø³Ù„ ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n+\n+ÙŠØ¹ÙŠØ¯ Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ² Ù‡Ø°Ø§ Ø§Ù„Ù‚Ù†Ø§Ø¹ ÙƒØ¥Ø¯Ø®Ø§Ù„ \"token_type_ids\":\n+\n+```python\n+>>> encoded_dict[\"token_type_ids\"]\n+[0ØŒ 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0ØŒ 1ØŒ 1ØŒ 1ØŒ 1ØŒ 1ØŒ 1ØŒ 1ØŒ 1ØŒ 1]\n+```\n+\n+ÙŠØªÙ… ØªÙ…Ø«ÙŠÙ„ Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø£ÙˆÙ„ØŒ \"Ø§Ù„Ø³ÙŠØ§Ù‚\" Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„Ø³Ø¤Ø§Ù„ØŒ Ø¨Ø¬Ù…ÙŠØ¹ Ø±Ù…ÙˆØ²Ù‡ Ø¨ÙˆØ§Ø³Ø·Ø© `0`ØŒ ÙÙŠ Ø­ÙŠÙ† ÙŠØªÙ… ØªÙ…Ø«ÙŠÙ„ Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø«Ø§Ù†ÙŠØŒ Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„ Ø¥Ù„Ù‰ \"Ø§Ù„Ø³Ø¤Ø§Ù„\"ØŒ Ø¨Ø¬Ù…ÙŠØ¹ Ø±Ù…ÙˆØ²Ù‡ Ø¨ÙˆØ§Ø³Ø·Ø© `1`.\n+\n+ØªØ³ØªØ®Ø¯Ù… Ø¨Ø¹Ø¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ Ù…Ø«Ù„ [`XLNetModel`] Ø±Ù…Ø²Ù‹Ø§ Ø¥Ø¶Ø§ÙÙŠÙ‹Ø§ ÙŠÙ…Ø«Ù„Ù‡ `2`.\n+\n+### Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ÙŠ (Transfer Learning)\n+\n+ØªÙ‚Ù†ÙŠØ© ØªÙ†Ø·ÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø®Ø° Ù†Ù…ÙˆØ°Ø¬ ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ÙˆØªÙƒÙŠÙŠÙÙ‡ Ù…Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø§ØµØ© Ø¨Ù…Ù‡Ù…ØªÙƒ. Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„ØµÙØ±ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ÙƒØªØ³Ø¨Ø© Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ù…ÙˆØ¬ÙˆØ¯ ÙƒÙ†Ù‚Ø·Ø© Ø¨Ø¯Ø§ÙŠØ©. ÙŠØ³Ø±Ø¹ Ù‡Ø°Ø§ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¹Ù„Ù… ÙˆÙŠÙ‚Ù„Ù„ Ù…Ù† ÙƒÙ…ÙŠØ© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©.\n+\n+### Ø§Ù„Ù…Ø­ÙˆÙ„ (Transformer)\n+\n+Ù‡Ùˆ Ø¨Ù†ÙŠØ© Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø¹Ù…ÙŠÙ‚ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ø§Ù„Ø°Ø§ØªÙŠ.\n+\n+## U\n+\n+### Ø§Ù„ØªØ¹Ù„Ù… ØºÙŠØ± Ø§Ù„Ø®Ø§Ø¶Ø¹ Ù„Ù„Ø¥Ø´Ø±Ø§Ù (unsupervised learning)\n+\n+Ø´ÙƒÙ„ Ù…Ù† Ø£Ø´ÙƒØ§Ù„ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø­ÙŠØ« Ù„Ø§ ÙŠØªÙ… ÙˆØ¶Ø¹ Ø¹Ù„Ø§Ù…Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ØªØ³ØªÙÙŠØ¯ ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù… ØºÙŠØ± Ø§Ù„Ø®Ø§Ø¶Ø¹Ø© Ù„Ù„Ø¥Ø´Ø±Ø§Ù Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙÙŠØ¯Ø© Ù„Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ù…Ø¹Ù†ÙŠØ©.\n+\n+## Z\n+\n+### Ù…Ø­Ø³Ù† Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„ØµÙØ±ÙŠ (ZeRO)\n+\n+ØªÙ‚Ù†ÙŠØ© ØªÙˆØ§Ø²ÙŠ ØªÙ‚ÙˆÙ… Ø¨ØªØ´Ø¸ÙŠØ© Ø§Ù„Ù…ØµÙÙˆÙØ§Øª Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù€ [TensorParallel](#tensor-parallelism-tp)ØŒ Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…ØµÙÙˆÙØ© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ‚Ø¯ÙŠØ± Ø£Ùˆ Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ù„ÙÙŠØŒ ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ø§ ÙŠÙ„Ø²Ù… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ØªØ¯Ø¹Ù… Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø£ÙŠØ¶Ù‹Ø§ ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø¥Ø®Ù„Ø§Ø¡ Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ù„Ù„ØªØ¹ÙˆÙŠØ¶ Ø¹Ù† Ø°Ø§ÙƒØ±Ø© GPU Ø§Ù„Ù…Ø­Ø¯ÙˆØ¯Ø©.\n+\n+ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø²ÙŠØ¯ Ø­ÙˆÙ„ Zero [Ù‡Ù†Ø§](perf_train_gpu_many#zero-data-parallelism)."
        },
        {
            "sha": "c37dbd1c6d9fc3a313b522d0a88c01606a12bac6",
            "filename": "docs/source/ar/index.md",
            "status": "added",
            "additions": 342,
            "deletions": 0,
            "changes": 342,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Findex.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Findex.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Findex.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,342 @@\n+# ğŸ¤— Transformers: Ù„Ù…Ø­Ø© Ø¹Ø§Ù…Ø©\n+\n+Ø£Ø­Ø¯Ø« Ù…Ø§ ÙÙŠ Ù…Ø¬Ø§Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ù„Ù€ [PyTorch](https://pytorch.org/) Ùˆ [TensorFlow](https://www.tensorflow.org/) Ùˆ [JAX](https://jax.readthedocs.io/en/latest/)\n+\n+ØªÙˆÙØ± ğŸ¤— Transformers ÙˆØ§Ø¬Ù‡Ø§Øª Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª (APIs) ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø© Ù„ØªÙ†Ø²ÙŠÙ„ ÙˆØªØ¯Ø±ÙŠØ¨ Ø£Ø­Ø¯Ø« Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø³Ù‡ÙˆÙ„Ø©. ÙˆÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙ‚Ù„Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† ØªÙƒØ§Ù„ÙŠÙ Ø§Ù„Ø­ÙˆØ³Ø¨Ø© ÙˆØ§Ù„Ø­Ø¯ Ù…Ù† Ø§Ù„Ø£Ø«Ø± Ø§Ù„Ø¨ÙŠØ¦ÙŠØŒ ÙˆØªÙˆÙÙ‘Ø± Ø§Ù„ÙˆÙ‚Øª ÙˆØ§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù„Ø§Ø²Ù…ÙŠÙ† Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„ØµÙØ±. ÙˆØªØ¯Ø¹Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ù…Ø¬Ø§Ù„Ø§Øª Ù…Ø®ØªÙ„ÙØ©ØŒ Ù…Ø«Ù„:\n+\n+\n+ğŸ“ **Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©**: ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙˆØµØŒ ÙˆØªØ¹Ø±ÙŠÙ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ù…Ø§Ø©ØŒ ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©ØŒ ÙˆÙ†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ©ØŒ ÙˆØ§Ù„ØªÙ„Ø®ÙŠØµØŒ ÙˆØ§Ù„ØªØ±Ø¬Ù…Ø©ØŒ ÙˆØ§Ù„Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ù…ØªØ¹Ø¯Ø¯ØŒ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ. <br>\n+ğŸ–¼ï¸ **Ø§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ÙŠØ©**: ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ±ØŒ ÙˆÙƒØ´Ù Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ØŒ ÙˆØªØ¬Ø²Ø¦ØªÙ‡Ø§. <br>\n+ğŸ—£ï¸ **Ø§Ù„ØµÙˆØª**: Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…ØŒ ÙˆØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØª. <br>\n+ğŸ™ **Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ³Ø§Ø¦Ø·**: Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¬Ø¯ÙˆÙ„ÙŠØ©ØŒ ÙˆØ§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø¨ØµØ±ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙˆÙØŒ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù…Ù…Ø³ÙˆØ­Ø© Ø¶ÙˆØ¦ÙŠÙ‹Ø§ØŒ ÙˆØªØµÙ†ÙŠÙ Ø§Ù„ÙÙŠØ¯ÙŠÙˆØŒ ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©.\n+\n+ØªØ¯Ø¹Ù… ğŸ¤— Transformers Ø§Ù„ØªÙˆØ§ÙÙ‚ Ø¨ÙŠÙ† Ø£Ø·Ø± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ù…Ø«Ù„ PyTorch Ùˆ TensorFlow Ùˆ JAX. ÙˆÙŠÙˆÙØ± Ø°Ù„Ùƒ Ø§Ù„Ù…Ø±ÙˆÙ†Ø© Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ù…Ø®ØªÙ„Ù ÙÙŠ ÙƒÙ„ Ù…Ø±Ø­Ù„Ø© Ù…Ù† Ù…Ø±Ø§Ø­Ù„ Ø­ÙŠØ§Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬Ø› Ù‚Ù… Ø¨ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø«Ù„Ø§Ø« Ø®Ø·ÙˆØ· Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© ÙÙŠ Ø¥Ø·Ø§Ø± ÙˆØ§Ø­Ø¯ØŒ ÙˆÙ‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„Ù‡ Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ ÙÙŠ Ø¥Ø·Ø§Ø± Ø¢Ø®Ø±. ÙˆÙŠÙ…ÙƒÙ† Ø£ÙŠØ¶Ù‹Ø§ ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¥Ù„Ù‰ ØµÙŠØº Ù…Ø«Ù„ ONNX Ùˆ TorchScript Ù„Ù„Ù†Ø´Ø± ÙÙŠ Ø¨ÙŠØ¦Ø§Øª Ø§Ù„Ø¥Ù†ØªØ§Ø¬.\n+\n+Ø§Ù†Ø¶Ù… Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ Ø§Ù„Ù…ØªÙ†Ø§Ù…ÙŠ Ø¹Ù„Ù‰ [Hub](https://huggingface.co/models) Ø£Ùˆ [Ø§Ù„Ù…Ù†ØªØ¯Ù‰](https://discuss.huggingface.co/) Ø£Ùˆ [Discord](https://discord.com/invite/JfAtkvEtRb) Ø§Ù„ÙŠÙˆÙ…!\n+\n+## Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ¨Ø­Ø« Ø¹Ù† Ø¯Ø¹Ù… Ù…Ø®ØµØµ Ù…Ù† ÙØ±ÙŠÙ‚ Hugging Face\n+\n+<a target=\"_blank\" href=\"https://huggingface.co/support\">\n+    <img alt=\"HuggingFace Expert Acceleration Program\" src=\"https://cdn-media.huggingface.co/marketing/transformers/new-support-improved.png\" style=\"width: 100%; max-width: 600px; border: 1px solid #eee; border-radius: 4px; box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);\">\n+</a>\n+\n+## Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª\n+\n+ÙŠÙ†Ù‚Ø³Ù… Ø§Ù„ØªÙˆØ«ÙŠÙ‚ Ø¥Ù„Ù‰ Ø®Ù…Ø³Ø© Ø£Ù‚Ø³Ø§Ù…:\n+\n+- **Ø§Ø¨Ø¯Ø£** ØªÙ‚Ø¯Ù… Ø¬ÙˆÙ„Ø© Ø³Ø±ÙŠØ¹Ø© ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø© ÙˆØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ«Ø¨ÙŠØª Ù„Ù„Ø¨Ø¯Ø¡.\n+- **Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©** Ù‡ÙŠ Ù…ÙƒØ§Ù† Ø±Ø§Ø¦Ø¹ Ù„Ù„Ø¨Ø¯Ø¡ Ø¥Ø°Ø§ ÙƒÙ†Øª Ù…Ø¨ØªØ¯Ø¦Ù‹Ø§. Ø³ÙŠØ³Ø§Ø¹Ø¯Ùƒ Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù… Ø¹Ù„Ù‰ Ø§ÙƒØªØ³Ø§Ø¨ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬Ù‡Ø§ Ù„Ù„Ø¨Ø¯Ø¡ ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙƒØªØ¨Ø©.\n+- **Ø£Ø¯Ù„Ø© ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…** ØªÙØ¸Ù‡Ø± Ù„Ùƒ ÙƒÙŠÙÙŠØ© ØªØ­Ù‚ÙŠÙ‚ Ù‡Ø¯Ù Ù…Ø­Ø¯Ø¯ØŒ Ù…Ø«Ù„ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù…Ø³Ø¨Ù‚ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø£Ùˆ ÙƒÙŠÙÙŠØ© ÙƒØªØ§Ø¨Ø© ÙˆÙ…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬ Ù…Ø®ØµØµ.\n+- **Ø§Ù„Ø£Ø¯Ù„Ø© Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…ÙŠØ©** ØªÙ‚Ø¯Ù… Ù…Ù†Ø§Ù‚Ø´Ø© ÙˆØªÙØ³ÙŠØ±Ù‹Ø§ Ø£ÙƒØ«Ø± Ù„Ù„Ø£ÙÙƒØ§Ø± ÙˆØ§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØ±Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„Ù…Ù‡Ø§Ù… ÙˆÙÙ„Ø³ÙØ© Ø§Ù„ØªØµÙ…ÙŠÙ… ÙÙŠ ğŸ¤— Transformers.\n+- **ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª (API)** ØªØµÙ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª ÙˆØ§Ù„ÙˆØ¸Ø§Ø¦Ù:\n+\n+  - **Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©** ØªØ´Ø±Ø­ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø£Ù‡Ù…ÙŠØ© Ù…Ø«Ù„ Ø§Ù„ØªÙƒÙˆÙŠÙ† ÙˆØ§Ù„Ù†Ù…Ø°Ø¬Ø© ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙŠ ÙˆØ®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨.\n+  - **Ø§Ù„Ù†Ù…Ø§Ø°Ø¬** ØªØ´Ø±Ø­ Ø§Ù„ÙØ¦Ø§Øª ÙˆØ§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬ ÙŠØªÙ… ØªÙ†ÙÙŠØ°Ù‡ ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø©.\n+  - **Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ÙˆÙ† Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠÙˆÙ†** ÙŠØ´Ø±Ø­ÙˆÙ† ÙØ¦Ø§Øª ÙˆÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ØªÙŠ ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ø¯Ø§Ø®Ù„ÙŠÙ‹Ø§.\n+\n+\n+## Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„Ø£Ø·Ø± Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©\n+\n+ÙŠÙ…Ø«Ù„ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø£Ø¯Ù†Ø§Ù‡ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ù„ÙƒÙ„ Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ ÙˆÙ…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙ‡Ø§ Ù…Ø­Ù„Ù„ Ù†Ø­ÙˆÙŠ Python (ÙŠÙØ³Ù…Ù‰ \"Ø¨Ø·ÙŠØ¡\"). Ù…Ø­Ù„Ù„ Ù†Ø­ÙˆÙŠ \"Ø³Ø±ÙŠØ¹\" Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ù…ÙƒØªØ¨Ø© ğŸ¤— TokenizersØŒ ÙˆÙ…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙ‡Ø§ Ø¯Ø¹Ù… ÙÙŠ Jax (Ø¹Ø¨Ø± Flax) Ùˆ/Ø£Ùˆ PyTorch Ùˆ/Ø£Ùˆ TensorFlow.\n+\n+<!--ÙŠØªÙ… ØªØ­Ø¯ÙŠØ« Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ù…Ù† Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù†Ù…Ø·ÙŠØ© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ù…Ø¹ _make fix-copies_. Ù„Ø§ ØªÙ‚Ù… Ø¨Ø§Ù„ØªØ­Ø¯ÙŠØ« ÙŠØ¯ÙˆÙŠÙ‹Ø§!-->\n+<!--This table is updated automatically from the auto modules with _make fix-copies_. Do not update manually!-->\n+\n+|                                  Model                                   | PyTorch support | TensorFlow support | Flax Support |\n+|:------------------------------------------------------------------------:|:---------------:|:------------------:|:------------:|\n+|                        [ALBERT](model_doc/albert)                        |       âœ…        |         âœ…         |      âœ…      |\n+|                         [ALIGN](model_doc/align)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                       [AltCLIP](model_doc/altclip)                       |       âœ…        |         âŒ         |      âŒ      |\n+| [Audio Spectrogram Transformer](model_doc/audio-spectrogram-transformer) |       âœ…        |         âŒ         |      âŒ      |\n+|                    [Autoformer](model_doc/autoformer)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                          [Bark](model_doc/bark)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                          [BART](model_doc/bart)                          |       âœ…        |         âœ…         |      âœ…      |\n+|                       [BARThez](model_doc/barthez)                       |       âœ…        |         âœ…         |      âœ…      |\n+|                       [BARTpho](model_doc/bartpho)                       |       âœ…        |         âœ…         |      âœ…      |\n+|                          [BEiT](model_doc/beit)                          |       âœ…        |         âŒ         |      âœ…      |\n+|                          [BERT](model_doc/bert)                          |       âœ…        |         âœ…         |      âœ…      |\n+|               [Bert Generation](model_doc/bert-generation)               |       âœ…        |         âŒ         |      âŒ      |\n+|                 [BertJapanese](model_doc/bert-japanese)                  |       âœ…        |         âœ…         |      âœ…      |\n+|                      [BERTweet](model_doc/bertweet)                      |       âœ…        |         âœ…         |      âœ…      |\n+|                      [BigBird](model_doc/big_bird)                       |       âœ…        |         âŒ         |      âœ…      |\n+|               [BigBird-Pegasus](model_doc/bigbird_pegasus)               |       âœ…        |         âŒ         |      âŒ      |\n+|                        [BioGpt](model_doc/biogpt)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                           [BiT](model_doc/bit)                           |       âœ…        |         âŒ         |      âŒ      |\n+|                    [Blenderbot](model_doc/blenderbot)                    |       âœ…        |         âœ…         |      âœ…      |\n+|              [BlenderbotSmall](model_doc/blenderbot-small)               |       âœ…        |         âœ…         |      âœ…      |\n+|                          [BLIP](model_doc/blip)                          |       âœ…        |         âœ…         |      âŒ      |\n+|                        [BLIP-2](model_doc/blip-2)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                         [BLOOM](model_doc/bloom)                         |       âœ…        |         âŒ         |      âœ…      |\n+|                          [BORT](model_doc/bort)                          |       âœ…        |         âœ…         |      âœ…      |\n+|                   [BridgeTower](model_doc/bridgetower)                   |       âœ…        |         âŒ         |      âŒ      |\n+|                          [BROS](model_doc/bros)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                          [ByT5](model_doc/byt5)                          |       âœ…        |         âœ…         |      âœ…      |\n+|                     [CamemBERT](model_doc/camembert)                     |       âœ…        |         âœ…         |      âŒ      |\n+|                        [CANINE](model_doc/canine)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                     [Chameleon](model_doc/chameleon)                     |       âœ…        |         âŒ         |      âŒ      |\n+|                  [Chinese-CLIP](model_doc/chinese_clip)                  |       âœ…        |         âŒ         |      âŒ      |\n+|                          [CLAP](model_doc/clap)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                          [CLIP](model_doc/clip)                          |       âœ…        |         âœ…         |      âœ…      |\n+|                       [CLIPSeg](model_doc/clipseg)                       |       âœ…        |         âŒ         |      âŒ      |\n+|                          [CLVP](model_doc/clvp)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                       [CodeGen](model_doc/codegen)                       |       âœ…        |         âŒ         |      âŒ      |\n+|                    [CodeLlama](model_doc/code_llama)                     |       âœ…        |         âŒ         |      âœ…      |\n+|                        [Cohere](model_doc/cohere)                        |       âœ…        |         âŒ         |      âŒ      |\n+|              [Conditional DETR](model_doc/conditional_detr)              |       âœ…        |         âŒ         |      âŒ      |\n+|                      [ConvBERT](model_doc/convbert)                      |       âœ…        |         âœ…         |      âŒ      |\n+|                      [ConvNeXT](model_doc/convnext)                      |       âœ…        |         âœ…         |      âŒ      |\n+|                    [ConvNeXTV2](model_doc/convnextv2)                    |       âœ…        |         âœ…         |      âŒ      |\n+|                           [CPM](model_doc/cpm)                           |       âœ…        |         âœ…         |      âœ…      |\n+|                       [CPM-Ant](model_doc/cpmant)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                          [CTRL](model_doc/ctrl)                          |       âœ…        |         âœ…         |      âŒ      |\n+|                           [CvT](model_doc/cvt)                           |       âœ…        |         âœ…         |      âŒ      |\n+|                           [DAC](model_doc/dac)                           |       âœ…        |         âŒ         |      âŒ      |\n+|                   [Data2VecAudio](model_doc/data2vec)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                    [Data2VecText](model_doc/data2vec)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                   [Data2VecVision](model_doc/data2vec)                   |       âœ…        |         âœ…         |      âŒ      |\n+|                          [DBRX](model_doc/dbrx)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                       [DeBERTa](model_doc/deberta)                       |       âœ…        |         âœ…         |      âŒ      |\n+|                    [DeBERTa-v2](model_doc/deberta-v2)                    |       âœ…        |         âœ…         |      âŒ      |\n+|          [Decision Transformer](model_doc/decision_transformer)          |       âœ…        |         âŒ         |      âŒ      |\n+|               [Deformable DETR](model_doc/deformable_detr)               |       âœ…        |         âŒ         |      âŒ      |\n+|                          [DeiT](model_doc/deit)                          |       âœ…        |         âœ…         |      âŒ      |\n+|                        [DePlot](model_doc/deplot)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                [Depth Anything](model_doc/depth_anything)                |       âœ…        |         âŒ         |      âŒ      |\n+|                          [DETA](model_doc/deta)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                          [DETR](model_doc/detr)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                      [DialoGPT](model_doc/dialogpt)                      |       âœ…        |         âœ…         |      âœ…      |\n+|                         [DiNAT](model_doc/dinat)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                        [DINOv2](model_doc/dinov2)                        |       âœ…        |         âŒ         |      âœ…      |\n+|                    [DistilBERT](model_doc/distilbert)                    |       âœ…        |         âœ…         |      âœ…      |\n+|                           [DiT](model_doc/dit)                           |       âœ…        |         âŒ         |      âœ…      |\n+|                       [DonutSwin](model_doc/donut)                       |       âœ…        |         âŒ         |      âŒ      |\n+|                           [DPR](model_doc/dpr)                           |       âœ…        |         âœ…         |      âŒ      |\n+|                           [DPT](model_doc/dpt)                           |       âœ…        |         âŒ         |      âŒ      |\n+|               [EfficientFormer](model_doc/efficientformer)               |       âœ…        |         âœ…         |      âŒ      |\n+|                  [EfficientNet](model_doc/efficientnet)                  |       âœ…        |         âŒ         |      âŒ      |\n+|                       [ELECTRA](model_doc/electra)                       |       âœ…        |         âœ…         |      âœ…      |\n+|                       [EnCodec](model_doc/encodec)                       |       âœ…        |         âŒ         |      âŒ      |\n+|               [Encoder decoder](model_doc/encoder-decoder)               |       âœ…        |         âœ…         |      âœ…      |\n+|                         [ERNIE](model_doc/ernie)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                       [ErnieM](model_doc/ernie_m)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                           [ESM](model_doc/esm)                           |       âœ…        |         âœ…         |      âŒ      |\n+|              [FairSeq Machine-Translation](model_doc/fsmt)               |       âœ…        |         âŒ         |      âŒ      |\n+|                        [Falcon](model_doc/falcon)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                  [FalconMamba](model_doc/falcon_mamba)                   |       âœ…        |         âŒ         |      âŒ      |\n+|         [FastSpeech2Conformer](model_doc/fastspeech2_conformer)          |       âœ…        |         âŒ         |      âŒ      |\n+|                       [FLAN-T5](model_doc/flan-t5)                       |       âœ…        |         âœ…         |      âœ…      |\n+|                      [FLAN-UL2](model_doc/flan-ul2)                      |       âœ…        |         âœ…         |      âœ…      |\n+|                      [FlauBERT](model_doc/flaubert)                      |       âœ…        |         âœ…         |      âŒ      |\n+|                         [FLAVA](model_doc/flava)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                          [FNet](model_doc/fnet)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                      [FocalNet](model_doc/focalnet)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                  [Funnel Transformer](model_doc/funnel)                  |       âœ…        |         âœ…         |      âŒ      |\n+|                          [Fuyu](model_doc/fuyu)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                         [Gemma](model_doc/gemma)                         |       âœ…        |         âŒ         |      âœ…      |\n+|                        [Gemma2](model_doc/gemma2)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                           [GIT](model_doc/git)                           |       âœ…        |         âŒ         |      âŒ      |\n+|                          [GLPN](model_doc/glpn)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                       [GPT Neo](model_doc/gpt_neo)                       |       âœ…        |         âŒ         |      âœ…      |\n+|                      [GPT NeoX](model_doc/gpt_neox)                      |       âœ…        |         âŒ         |      âŒ      |\n+|             [GPT NeoX Japanese](model_doc/gpt_neox_japanese)             |       âœ…        |         âŒ         |      âŒ      |\n+|                         [GPT-J](model_doc/gptj)                          |       âœ…        |         âœ…         |      âœ…      |\n+|                       [GPT-Sw3](model_doc/gpt-sw3)                       |       âœ…        |         âœ…         |      âœ…      |\n+|                   [GPTBigCode](model_doc/gpt_bigcode)                    |       âœ…        |         âŒ         |      âŒ      |\n+|               [GPTSAN-japanese](model_doc/gptsan-japanese)               |       âœ…        |         âŒ         |      âŒ      |\n+|                       [Granite](model_doc/granite)                       |       âœ…        |         âŒ         |      âŒ      |\n+|                    [Graphormer](model_doc/graphormer)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                [Grounding DINO](model_doc/grounding-dino)                |       âœ…        |         âŒ         |      âŒ      |\n+|                      [GroupViT](model_doc/groupvit)                      |       âœ…        |         âœ…         |      âŒ      |\n+|                       [HerBERT](model_doc/herbert)                       |       âœ…        |         âœ…         |      âœ…      |\n+|                         [Hiera](model_doc/hiera)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                        [Hubert](model_doc/hubert)                        |       âœ…        |         âœ…         |      âŒ      |\n+|                        [I-BERT](model_doc/ibert)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                       [IDEFICS](model_doc/idefics)                       |       âœ…        |         âœ…         |      âŒ      |\n+|                      [Idefics2](model_doc/idefics2)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                      [ImageGPT](model_doc/imagegpt)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                      [Informer](model_doc/informer)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                  [InstructBLIP](model_doc/instructblip)                  |       âœ…        |         âŒ         |      âŒ      |\n+|             [InstructBlipVideo](model_doc/instructblipvideo)             |       âœ…        |         âŒ         |      âŒ      |\n+|                         [Jamba](model_doc/jamba)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                        [JetMoe](model_doc/jetmoe)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                       [Jukebox](model_doc/jukebox)                       |       âœ…        |         âŒ         |      âŒ      |\n+|                      [KOSMOS-2](model_doc/kosmos-2)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                      [LayoutLM](model_doc/layoutlm)                      |       âœ…        |         âœ…         |      âŒ      |\n+|                    [LayoutLMv2](model_doc/layoutlmv2)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                    [LayoutLMv3](model_doc/layoutlmv3)                    |       âœ…        |         âœ…         |      âŒ      |\n+|                     [LayoutXLM](model_doc/layoutxlm)                     |       âœ…        |         âŒ         |      âŒ      |\n+|                           [LED](model_doc/led)                           |       âœ…        |         âœ…         |      âŒ      |\n+|                         [LeViT](model_doc/levit)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                          [LiLT](model_doc/lilt)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                         [LLaMA](model_doc/llama)                         |       âœ…        |         âŒ         |      âœ…      |\n+|                        [Llama2](model_doc/llama2)                        |       âœ…        |         âŒ         |      âœ…      |\n+|                        [Llama3](model_doc/llama3)                        |       âœ…        |         âŒ         |      âœ…      |\n+|                         [LLaVa](model_doc/llava)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                    [LLaVA-NeXT](model_doc/llava_next)                    |       âœ…        |         âŒ         |      âŒ      |\n+|              [LLaVa-NeXT-Video](model_doc/llava_next_video)              |       âœ…        |         âŒ         |      âŒ      |\n+|                    [Longformer](model_doc/longformer)                    |       âœ…        |         âœ…         |      âŒ      |\n+|                        [LongT5](model_doc/longt5)                        |       âœ…        |         âŒ         |      âœ…      |\n+|                          [LUKE](model_doc/luke)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                        [LXMERT](model_doc/lxmert)                        |       âœ…        |         âœ…         |      âŒ      |\n+|                        [M-CTC-T](model_doc/mctct)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                       [M2M100](model_doc/m2m_100)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                    [MADLAD-400](model_doc/madlad-400)                    |       âœ…        |         âœ…         |      âœ…      |\n+|                         [Mamba](model_doc/mamba)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                        [mamba2](model_doc/mamba2)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                        [Marian](model_doc/marian)                        |       âœ…        |         âœ…         |      âœ…      |\n+|                      [MarkupLM](model_doc/markuplm)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                   [Mask2Former](model_doc/mask2former)                   |       âœ…        |         âŒ         |      âŒ      |\n+|                    [MaskFormer](model_doc/maskformer)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                        [MatCha](model_doc/matcha)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                         [mBART](model_doc/mbart)                         |       âœ…        |         âœ…         |      âœ…      |\n+|                      [mBART-50](model_doc/mbart50)                       |       âœ…        |         âœ…         |      âœ…      |\n+|                          [MEGA](model_doc/mega)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                 [Megatron-BERT](model_doc/megatron-bert)                 |       âœ…        |         âŒ         |      âŒ      |\n+|                 [Megatron-GPT2](model_doc/megatron_gpt2)                 |       âœ…        |         âœ…         |      âœ…      |\n+|                       [MGP-STR](model_doc/mgp-str)                       |       âœ…        |         âŒ         |      âŒ      |\n+|                       [Mistral](model_doc/mistral)                       |       âœ…        |         âœ…         |      âœ…      |\n+|                       [Mixtral](model_doc/mixtral)                       |       âœ…        |         âŒ         |      âŒ      |\n+|                         [mLUKE](model_doc/mluke)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                           [MMS](model_doc/mms)                           |       âœ…        |         âœ…         |      âœ…      |\n+|                    [MobileBERT](model_doc/mobilebert)                    |       âœ…        |         âœ…         |      âŒ      |\n+|                  [MobileNetV1](model_doc/mobilenet_v1)                   |       âœ…        |         âŒ         |      âŒ      |\n+|                  [MobileNetV2](model_doc/mobilenet_v2)                   |       âœ…        |         âŒ         |      âŒ      |\n+|                     [MobileViT](model_doc/mobilevit)                     |       âœ…        |         âœ…         |      âŒ      |\n+|                   [MobileViTV2](model_doc/mobilevitv2)                   |       âœ…        |         âŒ         |      âŒ      |\n+|                         [MPNet](model_doc/mpnet)                         |       âœ…        |         âœ…         |      âŒ      |\n+|                           [MPT](model_doc/mpt)                           |       âœ…        |         âŒ         |      âŒ      |\n+|                           [MRA](model_doc/mra)                           |       âœ…        |         âŒ         |      âŒ      |\n+|                           [MT5](model_doc/mt5)                           |       âœ…        |         âœ…         |      âœ…      |\n+|                      [MusicGen](model_doc/musicgen)                      |       âœ…        |         âŒ         |      âŒ      |\n+|               [MusicGen Melody](model_doc/musicgen_melody)               |       âœ…        |         âŒ         |      âŒ      |\n+|                           [MVP](model_doc/mvp)                           |       âœ…        |         âŒ         |      âŒ      |\n+|                           [NAT](model_doc/nat)                           |       âœ…        |         âŒ         |      âŒ      |\n+|                      [Nemotron](model_doc/nemotron)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                         [Nezha](model_doc/nezha)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                          [NLLB](model_doc/nllb)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                      [NLLB-MOE](model_doc/nllb-moe)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                        [Nougat](model_doc/nougat)                        |       âœ…        |         âœ…         |      âœ…      |\n+|                 [NystrÃ¶mformer](model_doc/nystromformer)                 |       âœ…        |         âŒ         |      âŒ      |\n+|                          [OLMo](model_doc/olmo)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                     [OneFormer](model_doc/oneformer)                     |       âœ…        |         âŒ         |      âŒ      |\n+|                    [OpenAI GPT](model_doc/openai-gpt)                    |       âœ…        |         âœ…         |      âŒ      |\n+|                      [OpenAI GPT-2](model_doc/gpt2)                      |       âœ…        |         âœ…         |      âœ…      |\n+|                    [OpenLlama](model_doc/open-llama)                     |       âœ…        |         âŒ         |      âŒ      |\n+|                           [OPT](model_doc/opt)                           |       âœ…        |         âœ…         |      âœ…      |\n+|                       [OWL-ViT](model_doc/owlvit)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                         [OWLv2](model_doc/owlv2)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                     [PaliGemma](model_doc/paligemma)                     |       âœ…        |         âŒ         |      âŒ      |\n+|                  [PatchTSMixer](model_doc/patchtsmixer)                  |       âœ…        |         âŒ         |      âŒ      |\n+|                      [PatchTST](model_doc/patchtst)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                       [Pegasus](model_doc/pegasus)                       |       âœ…        |         âœ…         |      âœ…      |\n+|                     [PEGASUS-X](model_doc/pegasus_x)                     |       âœ…        |         âŒ         |      âŒ      |\n+|                     [Perceiver](model_doc/perceiver)                     |       âœ…        |         âŒ         |      âŒ      |\n+|                     [Persimmon](model_doc/persimmon)                     |       âœ…        |         âŒ         |      âŒ      |\n+|                           [Phi](model_doc/phi)                           |       âœ…        |         âŒ         |      âŒ      |\n+|                          [Phi3](model_doc/phi3)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                       [PhoBERT](model_doc/phobert)                       |       âœ…        |         âœ…         |      âœ…      |\n+|                    [Pix2Struct](model_doc/pix2struct)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                        [PLBart](model_doc/plbart)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                    [PoolFormer](model_doc/poolformer)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                     [Pop2Piano](model_doc/pop2piano)                     |       âœ…        |         âŒ         |      âŒ      |\n+|                    [ProphetNet](model_doc/prophetnet)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                           [PVT](model_doc/pvt)                           |       âœ…        |         âŒ         |      âŒ      |\n+|                        [PVTv2](model_doc/pvt_v2)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                       [QDQBert](model_doc/qdqbert)                       |       âœ…        |         âŒ         |      âŒ      |\n+|                         [Qwen2](model_doc/qwen2)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                   [Qwen2Audio](model_doc/qwen2_audio)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                     [Qwen2MoE](model_doc/qwen2_moe)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                      [Qwen2VL](model_doc/qwen2_vl)                       |       âœ…        |         âŒ         |      âŒ      |\n+|                           [RAG](model_doc/rag)                           |       âœ…        |         âœ…         |      âŒ      |\n+|                         [REALM](model_doc/realm)                         |       âœ…        |         âŒ         |      âŒ      |\n+|               [RecurrentGemma](model_doc/recurrent_gemma)                |       âœ…        |         âŒ         |      âŒ      |\n+|                      [Reformer](model_doc/reformer)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                        [RegNet](model_doc/regnet)                        |       âœ…        |         âœ…         |      âœ…      |\n+|                       [RemBERT](model_doc/rembert)                       |       âœ…        |         âœ…         |      âŒ      |\n+|                        [ResNet](model_doc/resnet)                        |       âœ…        |         âœ…         |      âœ…      |\n+|                     [RetriBERT](model_doc/retribert)                     |       âœ…        |         âŒ         |      âŒ      |\n+|                       [RoBERTa](model_doc/roberta)                       |       âœ…        |         âœ…         |      âœ…      |\n+|          [RoBERTa-PreLayerNorm](model_doc/roberta-prelayernorm)          |       âœ…        |         âœ…         |      âœ…      |\n+|                      [RoCBert](model_doc/roc_bert)                       |       âœ…        |         âŒ         |      âŒ      |\n+|                      [RoFormer](model_doc/roformer)                      |       âœ…        |         âœ…         |      âœ…      |\n+|                       [RT-DETR](model_doc/rt_detr)                       |       âœ…        |         âŒ         |      âŒ      |\n+|                [RT-DETR-ResNet](model_doc/rt_detr_resnet)                |       âœ…        |         âŒ         |      âŒ      |\n+|                          [RWKV](model_doc/rwkv)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                           [SAM](model_doc/sam)                           |       âœ…        |         âœ…         |      âŒ      |\n+|                  [SeamlessM4T](model_doc/seamless_m4t)                   |       âœ…        |         âŒ         |      âŒ      |\n+|                [SeamlessM4Tv2](model_doc/seamless_m4t_v2)                |       âœ…        |         âŒ         |      âŒ      |\n+|                     [SegFormer](model_doc/segformer)                     |       âœ…        |         âœ…         |      âŒ      |\n+|                        [SegGPT](model_doc/seggpt)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                           [SEW](model_doc/sew)                           |       âœ…        |         âŒ         |      âŒ      |\n+|                         [SEW-D](model_doc/sew-d)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                        [SigLIP](model_doc/siglip)                        |       âœ…        |         âŒ         |      âŒ      |\n+|        [Speech Encoder decoder](model_doc/speech-encoder-decoder)        |       âœ…        |         âŒ         |      âœ…      |\n+|                 [Speech2Text](model_doc/speech_to_text)                  |       âœ…        |         âœ…         |      âŒ      |\n+|                      [SpeechT5](model_doc/speecht5)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                      [Splinter](model_doc/splinter)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                   [SqueezeBERT](model_doc/squeezebert)                   |       âœ…        |         âŒ         |      âŒ      |\n+|                      [StableLm](model_doc/stablelm)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                    [Starcoder2](model_doc/starcoder2)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                    [SuperPoint](model_doc/superpoint)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                   [SwiftFormer](model_doc/swiftformer)                   |       âœ…        |         âœ…         |      âŒ      |\n+|                    [Swin Transformer](model_doc/swin)                    |       âœ…        |         âœ…         |      âŒ      |\n+|                 [Swin Transformer V2](model_doc/swinv2)                  |       âœ…        |         âŒ         |      âŒ      |\n+|                       [Swin2SR](model_doc/swin2sr)                       |       âœ…        |         âŒ         |      âŒ      |\n+|           [SwitchTransformers](model_doc/switch_transformers)            |       âœ…        |         âŒ         |      âŒ      |\n+|                            [T5](model_doc/t5)                            |       âœ…        |         âœ…         |      âœ…      |\n+|                        [T5v1.1](model_doc/t5v1.1)                        |       âœ…        |         âœ…         |      âœ…      |\n+|             [Table Transformer](model_doc/table-transformer)             |       âœ…        |         âŒ         |      âŒ      |\n+|                         [TAPAS](model_doc/tapas)                         |       âœ…        |         âœ…         |      âŒ      |\n+|                         [TAPEX](model_doc/tapex)                         |       âœ…        |         âœ…         |      âœ…      |\n+|       [Time Series Transformer](model_doc/time_series_transformer)       |       âœ…        |         âŒ         |      âŒ      |\n+|                   [TimeSformer](model_doc/timesformer)                   |       âœ…        |         âŒ         |      âŒ      |\n+|        [Trajectory Transformer](model_doc/trajectory_transformer)        |       âœ…        |         âŒ         |      âŒ      |\n+|                  [Transformer-XL](model_doc/transfo-xl)                  |       âœ…        |         âœ…         |      âŒ      |\n+|                         [TrOCR](model_doc/trocr)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                          [TVLT](model_doc/tvlt)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                           [TVP](model_doc/tvp)                           |       âœ…        |         âŒ         |      âŒ      |\n+|                          [UDOP](model_doc/udop)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                           [UL2](model_doc/ul2)                           |       âœ…        |         âœ…         |      âœ…      |\n+|                          [UMT5](model_doc/umt5)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                     [UniSpeech](model_doc/unispeech)                     |       âœ…        |         âŒ         |      âŒ      |\n+|                 [UniSpeechSat](model_doc/unispeech-sat)                  |       âœ…        |         âŒ         |      âŒ      |\n+|                       [UnivNet](model_doc/univnet)                       |       âœ…        |         âŒ         |      âŒ      |\n+|                       [UPerNet](model_doc/upernet)                       |       âœ…        |         âŒ         |      âŒ      |\n+|                           [VAN](model_doc/van)                           |       âœ…        |         âŒ         |      âŒ      |\n+|                   [VideoLlava](model_doc/video_llava)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                      [VideoMAE](model_doc/videomae)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                          [ViLT](model_doc/vilt)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                      [VipLlava](model_doc/vipllava)                      |       âœ…        |         âŒ         |      âŒ      |\n+|        [Vision Encoder decoder](model_doc/vision-encoder-decoder)        |       âœ…        |         âœ…         |      âœ…      |\n+|       [VisionTextDualEncoder](model_doc/vision-text-dual-encoder)        |       âœ…        |         âœ…         |      âœ…      |\n+|                   [VisualBERT](model_doc/visual_bert)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                           [ViT](model_doc/vit)                           |       âœ…        |         âœ…         |      âœ…      |\n+|                    [ViT Hybrid](model_doc/vit_hybrid)                    |       âœ…        |         âŒ         |      âŒ      |\n+|                        [VitDet](model_doc/vitdet)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                       [ViTMAE](model_doc/vit_mae)                        |       âœ…        |         âœ…         |      âŒ      |\n+|                      [ViTMatte](model_doc/vitmatte)                      |       âœ…        |         âŒ         |      âŒ      |\n+|                       [ViTMSN](model_doc/vit_msn)                        |       âœ…        |         âŒ         |      âŒ      |\n+|                          [VITS](model_doc/vits)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                         [ViViT](model_doc/vivit)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                      [Wav2Vec2](model_doc/wav2vec2)                      |       âœ…        |         âœ…         |      âœ…      |\n+|                 [Wav2Vec2-BERT](model_doc/wav2vec2-bert)                 |       âœ…        |         âŒ         |      âŒ      |\n+|            [Wav2Vec2-Conformer](model_doc/wav2vec2-conformer)            |       âœ…        |         âŒ         |      âŒ      |\n+|              [Wav2Vec2Phoneme](model_doc/wav2vec2_phoneme)               |       âœ…        |         âœ…         |      âœ…      |\n+|                         [WavLM](model_doc/wavlm)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                       [Whisper](model_doc/whisper)                       |       âœ…        |         âœ…         |      âœ…      |\n+|                        [X-CLIP](model_doc/xclip)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                         [X-MOD](model_doc/xmod)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                          [XGLM](model_doc/xglm)                          |       âœ…        |         âœ…         |      âœ…      |\n+|                           [XLM](model_doc/xlm)                           |       âœ…        |         âœ…         |      âŒ      |\n+|                [XLM-ProphetNet](model_doc/xlm-prophetnet)                |       âœ…        |         âŒ         |      âŒ      |\n+|                   [XLM-RoBERTa](model_doc/xlm-roberta)                   |       âœ…        |         âœ…         |      âœ…      |\n+|                [XLM-RoBERTa-XL](model_doc/xlm-roberta-xl)                |       âœ…        |         âŒ         |      âŒ      |\n+|                         [XLM-V](model_doc/xlm-v)                         |       âœ…        |         âœ…         |      âœ…      |\n+|                         [XLNet](model_doc/xlnet)                         |       âœ…        |         âœ…         |      âŒ      |\n+|                         [XLS-R](model_doc/xls_r)                         |       âœ…        |         âœ…         |      âœ…      |\n+|                 [XLSR-Wav2Vec2](model_doc/xlsr_wav2vec2)                 |       âœ…        |         âœ…         |      âœ…      |\n+|                         [YOLOS](model_doc/yolos)                         |       âœ…        |         âŒ         |      âŒ      |\n+|                          [YOSO](model_doc/yoso)                          |       âœ…        |         âŒ         |      âŒ      |\n+|                      [ZoeDepth](model_doc/zoedepth)                      |       âœ…        |         âŒ         |      âŒ      |\n+\n+<!-- End table-->"
        },
        {
            "sha": "ac5962ec8589e8e425c9614ce3a50876a625af60",
            "filename": "docs/source/ar/installation.md",
            "status": "added",
            "additions": 246,
            "deletions": 0,
            "changes": 246,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Finstallation.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Finstallation.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Finstallation.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,246 @@\n+# Ø§Ù„ØªØ«Ø¨ÙŠØª (Installation)\n+\n+Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© ğŸ¤— Transformers Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù…Ù‡Ø§ØŒ ÙˆÙ‚Ù… Ø¨Ø¥Ø¹Ø¯Ø§Ø¯ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨ÙƒØŒ ÙˆÙ‚Ù… Ø¨Ø¥Ø¹Ø¯Ø§Ø¯ ğŸ¤— Transformers Ù„Ù„Ø¹Ù…Ù„ Ø¯ÙˆÙ† Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ).\n+\n+ØªÙ… Ø§Ø®ØªØ¨Ø§Ø± ğŸ¤— Transformers Ø¹Ù„Ù‰ Python 3.6  ÙˆØ§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø­Ø¯Ø«ØŒ ÙˆPyTorch 1.1.0 ÙˆØ§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø­Ø¯Ø«ØŒ ÙˆTensorFlow 2.0 ÙˆØ§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø­Ø¯Ø«ØŒ ÙˆFlax. Ø§ØªØ¨Ø¹ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ«Ø¨ÙŠØª Ø£Ø¯Ù†Ø§Ù‡ Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù…Ù‡Ø§:\n+\n+* ØªØ¹Ù„ÙŠÙ…Ø§Øª ØªØ«Ø¨ÙŠØª [PyTorch](https://pytorch.org/get-started/locally/).\n+* ØªØ¹Ù„ÙŠÙ…Ø§Øª ØªØ«Ø¨ÙŠØª [TensorFlow 2.0](https://www.tensorflow.org/install/pip).\n+* ØªØ¹Ù„ÙŠÙ…Ø§Øª ØªØ«Ø¨ÙŠØª [Flax](https://flax.readthedocs.io/en/latest/).\n+\n+## Ø§Ù„ØªØ«Ø¨ÙŠØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pip\n+\n+ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ ØªØ«Ø¨ÙŠØª ğŸ¤— Transformers Ø¯Ø§Ø®Ù„ [Ø¨ÙŠØ¦Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©](https://docs.python.org/3/library/venv.html). Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† ØºÙŠØ± Ù…Ù„Ù… Ø¨Ø¨ÙŠØ¦Ø§Øª Python Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©ØŒ ÙØ±Ø§Ø¬Ø¹ Ù‡Ø°Ø§ [Ø§Ù„Ø¯Ù„ÙŠÙ„](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ØªØ³Ù‡Ù„ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„Ù…Ø®ØªÙ„ÙØŒ ÙˆØªØ¬Ù†Ø¨ Ù…Ø´ÙƒÙ„Ø§Øª Ø§Ù„ØªÙˆØ§ÙÙ‚ Ø¨ÙŠÙ† Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹).\n+\n+Ø§Ø¨Ø¯Ø£ Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ¦Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ÙÙŠ Ø¯Ù„ÙŠÙ„ Ù…Ø´Ø±ÙˆØ¹Ùƒ:\n+\n+```bash\n+python -m venv .env\n+```\n+\n+Ù‚Ù… Ø¨ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©. Ø¹Ù„Ù‰ Linux ÙˆMacOs:\n+\n+```bash\n+source .env/bin/activate\n+```\n+\n+Ù‚Ù… Ø¨ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¹Ù„Ù‰ Windows:\n+\n+```bash\n+.env/Scripts/activate\n+```\n+\n+Ø§Ù„Ø¢Ù† Ø£Ù†Øª Ù…Ø³ØªØ¹Ø¯ Ù„ØªØ«Ø¨ÙŠØª ğŸ¤— Transformers Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ:\n+\n+```bash\n+pip install transformers\n+```\n+\n+Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ø®Ø§Øµ Ø¨Ù€ CPU ÙÙ‚Ø·ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ«Ø¨ÙŠØª ğŸ¤— Transformers ÙˆÙ…ÙƒØªØ¨Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙÙŠ Ø®Ø·ÙˆØ© ÙˆØ§Ø­Ø¯Ø©. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª ğŸ¤— Transformers ÙˆPyTorch Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…:\n+\n+```bash\n+pip install 'transformers[torch]'\n+```\n+\n+ğŸ¤— Transformers ÙˆTensorFlow 2.0:\n+\n+```bash\n+pip install 'transformers[tf-cpu]'\n+```\n+\n+<Tip warning={true}>\n+\n+Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠ M1 / ARM\n+\n+Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ«Ø¨ÙŠØª Ù…Ø§ ÙŠÙ„ÙŠ Ù‚Ø¨Ù„ ØªØ«Ø¨ÙŠØª TensorFLow 2.0\n+```bash\n+brew install cmake\n+brew install pkg-config\n+```\n+\n+</Tip>\n+\n+ğŸ¤— Transformers ÙˆFlax:\n+\n+```bash\n+pip install 'transformers[flax]'\n+```\n+\n+Ø£Ø®ÙŠØ±Ù‹Ø§ØŒ ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ğŸ¤— Transformers Ù‚Ø¯ ØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ. Ø³ÙŠÙ‚ÙˆÙ… Ø¨ØªÙ†Ø²ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§:\n+\n+```bash\n+python -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\"\n+```\n+\n+Ø«Ù… Ù‚Ù… Ø¨Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªØ³Ù…ÙŠØ© ÙˆØ§Ù„Ù†ØªÙŠØ¬Ø©:\n+\n+```bash\n+[{'label': 'POSITIVE', 'score': 0.9998704791069031}]\n+```\n+\n+## Ø§Ù„ØªØ«Ø¨ÙŠØª Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø±\n+\n+Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª ğŸ¤— Transformers Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ:\n+\n+```bash\n+pip install git+https://github.com/huggingface/transformers\n+```\n+\n+ÙŠÙ‚ÙˆÙ… Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø± Ø¨ØªØ«Ø¨ÙŠØª  Ø£Ø­Ø¯Ø« Ø¥ØµØ¯Ø§Ø± ØªØ¬Ø±ÙŠØ¨ÙŠ `main`  Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‚Ø± `stable`. ÙŠØ¹Ø¯ Ø¥ØµØ¯Ø§Ø± `main` Ù…ÙÙŠØ¯Ù‹Ø§ Ù„Ù„Ù…ÙˆØ§ÙƒØ¨Ø© Ù…Ø¹ Ø£Ø­Ø¯Ø« Ø§Ù„ØªØ·ÙˆØ±Ø§Øª. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¥Ø°Ø§ ØªÙ… Ø¥ØµÙ„Ø§Ø­ Ø®Ø·Ø£ Ù…Ù†Ø° Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø±Ø³Ù…ÙŠ Ø§Ù„Ø£Ø®ÙŠØ± ÙˆÙ„ÙƒÙ† Ù„Ù… ÙŠØªÙ… Ø·Ø±Ø­ Ø¥ØµØ¯Ø§Ø± Ø¬Ø¯ÙŠØ¯ Ø¨Ø¹Ø¯. ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ ÙØ¥Ù† Ù‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø¥ØµØ¯Ø§Ø± Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ `main` Ù‚Ø¯ Ù„Ø§ ÙŠÙƒÙˆÙ† Ù…Ø³ØªÙ‚Ø±Ù‹Ø§ Ø¯Ø§Ø¦Ù…Ù‹Ø§. Ù†Ø³Ø¹Ù‰ Ø¬Ø§Ù‡Ø¯ÙŠÙ† Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ØªØ´ØºÙŠÙ„ Ø¥ØµØ¯Ø§Ø± `main`ØŒ ÙˆÙŠØªÙ… Ø­Ù„ Ù…Ø¹Ø¸Ù… Ø§Ù„Ù…Ø´ÙƒÙ„Ø§Øª Ø¹Ø§Ø¯Ø©Ù‹ ÙÙŠ ØºØ¶ÙˆÙ† Ø¨Ø¶Ø¹ Ø³Ø§Ø¹Ø§Øª Ø£Ùˆ ÙŠÙˆÙ…. Ø¥Ø°Ø§ ÙˆØ§Ø¬Ù‡ØªÙƒ Ù…Ø´ÙƒÙ„Ø©ØŒ ÙŠØ±Ø¬Ù‰ ÙØªØ­ [ØªÙ‚Ø±ÙŠØ± Ø¹Ù† Ø®Ù„Ù„](https://github.com/huggingface/transformers/issues) Ø­ØªÙ‰ Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø¥ØµÙ„Ø§Ø­Ù‡Ø§ ÙÙŠ Ø£Ù‚Ø±Ø¨ ÙˆÙ‚Øª Ù…Ù…ÙƒÙ†!\n+\n+ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ğŸ¤— Transformers Ù‚Ø¯ ØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ:\n+\n+```bash\n+python -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"\n+```\n+\n+ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ğŸ¤— Transformers Ù‚Ø¯ ØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ:\n+\n+```bash\n+python -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"\n+```\n+\n+## Ø§Ù„ØªØ«Ø¨ÙŠØª Ø§Ù„Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„\n+\n+Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ«Ø¨ÙŠØª Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ØºØ¨ ÙÙŠ:\n+\n+* Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥ØµØ¯Ø§Ø± `main` Ù…Ù† ÙƒÙˆØ¯ Ø§Ù„Ù…ØµØ¯Ø±.\n+* Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø© ÙÙŠ ğŸ¤— Transformers ÙˆØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„ÙƒÙˆØ¯.\n+\n+Ù‚Ù… Ø¨Ø§Ø³ØªÙ†Ø³Ø§Ø® Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ ÙˆÙ‚Ù… Ø¨ØªØ«Ø¨ÙŠØª ğŸ¤— Transformers Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠØ©:\n+\n+```bash\n+git clone https://github.com/huggingface/transformers.git\n+cd transformers\n+pip install -e .\n+```\n+\n+ Ø³ØªÙ‚ÙˆÙ… Ù‡Ø°Ù‡ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø¨Ø±Ø¨Ø· Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø°ÙŠ Ù‚Ù…Øª Ø¨Ø§Ø³ØªÙ†Ø³Ø§Ø® Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ ÙÙŠÙ‡ Ø¨Ù…Ø³Ø§Ø±Ø§Øª Ù…ÙƒØªØ¨Ø© Python. Ø¨Ù…Ø¹Ù†Ù‰ Ø¢Ø®Ø±ØŒ Ø³ÙŠØ¨Ø­Ø« Python Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø°ÙŠ Ù‚Ù…Øª Ø¨Ø§Ø³ØªÙ†Ø³Ø§Ø®Ù‡ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¹ØªØ§Ø¯Ø© Ù„Ù„Ù…ÙƒØªØ¨Ø§Øª. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¥Ø°Ø§ ØªÙ… ØªØ«Ø¨ÙŠØª Ø­Ø²Ù… Python Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø¹Ø§Ø¯Ø©Ù‹ ÙÙŠ `~/anaconda3/envs/main/lib/python3.7/site-packages/`, ÙØ³ÙŠÙ‚ÙˆÙ… Python Ø£ÙŠØ¶Ù‹Ø§ Ø¨Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø°ÙŠ Ù‚Ù…Øª Ø¨Ø§Ø³ØªÙ†Ø³Ø§Ø®Ù‡: `~/transformers/`.\n+\n+<Tip warning={true}>\n+\n+ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù…Ø¬Ù„Ø¯ `transformers` Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø± ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙƒØªØ¨Ø©.\n+\n+</Tip>\n+\n+Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø³ØªÙ†Ø³Ø® Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø¨Ø³Ù‡ÙˆÙ„Ø© Ø¥Ù„Ù‰ Ø£Ø­Ø¯Ø« Ø¥ØµØ¯Ø§Ø± Ù…Ù† ğŸ¤— Transformers Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ:\n+\n+```bash\n+cd ~/transformers/\n+git pull\n+```\n+\n+Ø³ØªØ¬Ø¯ Ø¨ÙŠØ¦Ø© Python Ø§Ù„Ø¥ØµØ¯Ø§Ø± `main` Ù…Ù† ğŸ¤— Transformers ÙÙŠ Ø§Ù„Ù…Ø±Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ø§Ù„ØªÙŠ ØªÙ‚ÙˆÙ… ÙÙŠÙ‡Ø§ Ø¨ØªØ´ØºÙŠÙ„Ù‡.\n+\n+## Ø§Ù„ØªØ«Ø¨ÙŠØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… conda\n+\n+Ù‚Ù… Ø¨Ø§Ù„ØªØ«Ø¨ÙŠØª Ù…Ù† Ù‚Ù†Ø§Ø© conda `conda-forge`:\n+\n+```bash\n+conda install conda-forge::transformers\n+```\n+\n+## Ø¥Ø¹Ø¯Ø§Ø¯ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª\n+\n+ØªÙØ­Ù…Ù‘Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙØ³Ø¨Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØªÙØ®Ø²Ù‘Ù† Ù…Ø¤Ù‚ØªÙ‹Ø§ ÙÙŠ: `~/.cache/huggingface/hub`. Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø§Ù„Ø°ÙŠ ÙŠÙØ­Ø¯Ø¯Ù‡ Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© `TRANSFORMERS_CACHE`. Ø¹Ù„Ù‰ WindowsØŒ ÙŠÙƒÙˆÙ† Ø¯Ù„ÙŠÙ„ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù‡Ùˆ `C:\\Users\\username\\.cache\\huggingface\\hub`. ÙŠÙ…ÙƒÙ†Ùƒ ØªØºÙŠÙŠØ± Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© shell Ø§Ù„Ù…ÙˆØ¶Ø­Ø© Ø£Ø¯Ù†Ø§Ù‡ - Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© - Ù„ØªØ­Ø¯ÙŠØ¯ Ø¯Ù„ÙŠÙ„ Ø°Ø§ÙƒØ±Ø© ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù…Ø®ØªÙ„Ù:\n+\n+1. Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© (Ø§ÙØªØ±Ø§Ø¶ÙŠ): `HUGGINGFACE_HUB_CACHE` Ø£Ùˆ `TRANSFORMERS_CACHE`.\n+2. Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø©: `HF_HOME`.\n+3. Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø©: `XDG_CACHE_HOME` + `/huggingface`.\n+\n+<Tip>\n+\n+Ø³ÙŠØ³ØªØ®Ø¯Ù… ğŸ¤— Transformers Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© `PYTORCH_TRANSFORMERS_CACHE` Ø£Ùˆ `PYTORCH_PRETRAINED_BERT_CACHE` Ø¥Ø°Ø§ ÙƒÙ†Øª Ù‚Ø§Ø¯Ù…Ù‹Ø§ Ù…Ù† Ø¥ØµØ¯Ø§Ø± Ø³Ø§Ø¨Ù‚ Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙƒØªØ¨Ø© ÙˆÙ‚Ù…Øª Ø¨ØªØ¹ÙŠÙŠÙ† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù‡Ø°Ù‡ØŒ Ù…Ø§ Ù„Ù… ØªØ­Ø¯Ø¯ Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© `TRANSFORMERS_CACHE`.\n+\n+</Tip>\n+\n+## Ø§Ù„ÙˆØ¶Ø¹ Ø¯ÙˆÙ† Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª\n+\n+Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ ğŸ¤— Transformers ÙÙŠ Ø¨ÙŠØ¦Ø© Ù…Ø­Ù…ÙŠØ© Ø¨Ø¬Ø¯Ø§Ø± Ø­Ù…Ø§ÙŠØ© Ø£Ùˆ ØºÙŠØ± Ù…ØªØµÙ„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø®Ø²Ù†Ø© Ù…Ø¤Ù‚ØªÙ‹Ø§ Ù…Ø­Ù„ÙŠÙ‹Ø§ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ¹ÙŠÙŠÙ† Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© `HF_HUB_OFFLINE=1`.\n+\n+<Tip>\n+\n+Ø£Ø¶Ù [ğŸ¤— Datasets](https://huggingface.co/docs/datasets/) Ø¥Ù„Ù‰ Ø³ÙŠØ± Ø¹Ù…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ØºÙŠØ± Ø§Ù„Ù…ØªØµÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© `HF_DATASETS_OFFLINE=1`.\n+\n+</Tip>\n+\n+```bash\n+HF_DATASETS_OFFLINE=1 HF_HUB_OFFLINE=1 \\\n+python examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n+```\n+\n+ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ¹Ù…Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ù†ØµÙŠ Ø¯ÙˆÙ† ØªÙˆÙ‚Ù Ø£Ùˆ Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…Ù‡Ù„Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ø£Ù†Ù‡ Ù„Ù† ÙŠØ­Ø§ÙˆÙ„ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Hub.\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ØªØ¬Ø§ÙˆØ² ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Hub Ù…Ù† ÙƒÙ„ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ [`~PreTrainedModel.from_pretrained`] Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ù„Ù…Ø© [`local_files_only`]. Ø¹Ù†Ø¯Ù…Ø§ ÙŠØªÙ… ØªØ¹ÙŠÙŠÙ†Ù‡Ø§ Ø¹Ù„Ù‰ `True`ØŒ ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© ÙÙ‚Ø·:\n+\n+```py\n+from transformers import T5Model\n+\n+model = T5Model.from_pretrained(\"./path/to/local/directory\", local_files_only=True)\n+```\n+\n+### Ø¬Ù„Ø¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„Ù…ÙØ¬Ø²Ù‘Ø¦Ø§Øª Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ø¯ÙˆÙ† Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª\n+\n+Ø®ÙŠØ§Ø± Ø¢Ø®Ø± Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ğŸ¤— Transformers Ø¯ÙˆÙ† Ø§ØªØµØ§Ù„ Ù‡Ùˆ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ø³Ø¨Ù‚Ù‹Ø§ØŒ Ø«Ù… Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ù…Ø³Ø§Ø±Ù‡Ø§ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ø¯ÙˆÙ† Ø§ØªØµØ§Ù„. Ù‡Ù†Ø§Ùƒ Ø«Ù„Ø§Ø« Ø·Ø±Ù‚ Ù„Ù„Ù‚ÙŠØ§Ù… Ø¨Ø°Ù„Ùƒ:\n+\n+* Ù‚Ù… Ø¨ØªÙ†Ø²ÙŠÙ„ Ù…Ù„Ù Ø¹Ø¨Ø± ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ù‰ [Model Hub](https://huggingface.co/models) Ø¨Ø§Ù„Ù†Ù‚Ø± ÙÙˆÙ‚ Ø£ÙŠÙ‚ÙˆÙ†Ø© â†“.\n+\n+    ![download-icon](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png)\n+\n+* Ø§Ø³ØªØ®Ø¯Ù… Ø³ÙŠØ± Ø¹Ù…Ù„ [`PreTrainedModel.from_pretrained`] Ùˆ [`PreTrainedModel.save_pretrained`]:\n+\n+    1. Ù‚Ù… Ø¨ØªÙ†Ø²ÙŠÙ„ Ù…Ù„ÙØ§ØªÙƒ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`PreTrainedModel.from_pretrained`]:\n+* Ø§Ø³ØªØ®Ø¯Ù… Ø³ÙŠØ± Ø¹Ù…Ù„ [`PreTrainedModel.from_pretrained`] Ùˆ [`PreTrainedModel.save_pretrained`]:\n+\n+    1. Ù‚Ù… Ø¨ØªÙ†Ø²ÙŠÙ„ Ù…Ù„ÙØ§ØªÙƒ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`PreTrainedModel.from_pretrained`]:\n+\n+    ```py\n+    >>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n+\n+    >>> tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\")\n+    >>> model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\")\n+    ```\n+\n+    2. Ø§Ø­ÙØ¸ Ù…Ù„ÙØ§ØªÙƒ Ø¥Ù„Ù‰ Ø¯Ù„ÙŠÙ„ Ù…Ø­Ø¯Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`PreTrainedModel.save_pretrained`]:\n+\n+    ```py\n+    >>> tokenizer.save_pretrained(\"./your/path/bigscience_t0\")\n+    >>> model.save_pretrained(\"./your/path/bigscience_t0\")\n+    ```\n+\n+    3. Ø§Ù„Ø¢Ù† Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† ØºÙŠØ± Ù…ØªØµÙ„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†ØªØŒ Ø£Ø¹Ø¯ ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§ØªÙƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`PreTrainedModel.from_pretrained`] Ù…Ù† Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­Ø¯Ø¯:\n+\n+    ```py\n+    >>> tokenizer = AutoTokenizer.from_pretrained(\"./your/path/bigscience_t0\")\n+    >>> model = AutoModel.from_pretrained(\"./your/path/bigscience_t0\")\n+    ```\n+\n+* Ù‚Ù… Ø¨ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø±Ù…Ø¬ÙŠÙ‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© [huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub):\n+\n+    1. Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© `huggingface_hub` ÙÙŠ Ø¨ÙŠØ¦ØªÙƒ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©:\n+\n+    ```bash\n+    python -m pip install huggingface_hub\n+    ```\n+\n+    2. Ø§Ø³ØªØ®Ø¯Ù… ÙˆØ¸ÙŠÙØ© [`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub) Ù„ØªÙ†Ø²ÙŠÙ„ Ù…Ù„Ù Ø¥Ù„Ù‰ Ù…Ø³Ø§Ø± Ù…Ø­Ø¯Ø¯. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ Ø¨ØªÙ†Ø²ÙŠÙ„ Ù…Ù„Ù `config.json` Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ [T0](https://huggingface.co/bigscience/T0_3B) Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:\n+\n+    ```py\n+    >>> from huggingface_hub import hf_hub_download\n+\n+    >>> hf_hub_download(repo_id=\"bigscience/T0_3B\", filename=\"config.json\", cache_dir=\"./your/path/bigscience_t0\")\n+    ```\n+\n+Ø¨Ù…Ø¬Ø±Ø¯ ØªÙ†Ø²ÙŠÙ„ Ù…Ù„ÙÙƒ ÙˆØªØ®Ø²ÙŠÙ†Ù‡ Ù…Ø¤Ù‚ØªÙ‹Ø§ Ù…Ø­Ù„ÙŠÙ‹Ø§ØŒ Ø­Ø¯Ø¯ Ù…Ø³Ø§Ø±Ù‡ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø§Ù„Ø®Ø§Øµ Ø¨Ù‡ Ù„ØªØ­Ù…ÙŠÙ„Ù‡ ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù…Ù‡:\n+\n+```py\n+>>> from transformers import AutoConfig\n+\n+>>> config = AutoConfig.from_pretrained(\"./your/path/bigscience_t0/config.json\")\n+```\n+\n+<Tip>\n+\n+Ø±Ø§Ø¬Ø¹ Ù‚Ø³Ù… [ÙƒÙŠÙÙŠØ© ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ù† Hub](https://huggingface.co/docs/hub/how-to-downstream) Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø®Ø²Ù†Ø© Ø¹Ù„Ù‰ Hub.\n+\n+</Tip>"
        },
        {
            "sha": "264797a982b9ade0c70c29d7acf3c10ff498dc0b",
            "filename": "docs/source/ar/llm_tutorial.md",
            "status": "added",
            "additions": 248,
            "deletions": 0,
            "changes": 248,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fllm_tutorial.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fllm_tutorial.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fllm_tutorial.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,248 @@\n+# Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (LLMs)\n+\n+[[open-in-colab]]\n+\n+ØªØ¹Ø¯ LLMsØŒ Ø£Ùˆ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ© Ø§Ù„ÙƒØ¨ÙŠØ±Ø©ØŒ Ø§Ù„Ù…ÙƒÙˆÙ† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙˆØ±Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ. ÙˆØ¨Ø§Ø®ØªØµØ§Ø±ØŒ ØªØªÙƒÙˆÙ† Ù…Ù† Ù†Ù…Ø§Ø°Ø¬ Ù…Ø­ÙˆÙ„ ÙƒØ¨ÙŠØ±Ø© Ù…Ø³Ø¨Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡Ø§ Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© (Ø£ÙˆØŒ Ø¨Ø´ÙƒÙ„ Ø£ÙƒØ«Ø± Ø¯Ù‚Ø©ØŒ Ø§Ù„Ø±Ù…Ø² Ø§Ù„Ù„ØºÙˆÙŠ) Ø¨Ø§Ù„Ù†Ø¸Ø± Ø¥Ù„Ù‰ Ù†Øµ Ù…Ø¹ÙŠÙ†. Ù†Ø¸Ø±Ù‹Ø§ Ù„Ø£Ù†Ù‡Ø§ ØªØªÙ†Ø¨Ø£ Ø¨Ø±Ù…Ø² ÙˆØ§Ø­Ø¯ ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©ØŒ ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ø´ÙŠØ¡ Ø£ÙƒØ«Ø± ØªØ¹Ù‚ÙŠØ¯Ù‹Ø§ Ù„ØªÙˆÙ„ÙŠØ¯ Ø¬Ù…Ù„ Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ø®Ù„Ø§Ù Ù…Ø¬Ø±Ø¯ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ - ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ.\n+\n+Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù‡Ùˆ Ø¥Ø¬Ø±Ø§Ø¡ ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„Ø°ÙŠ ÙŠØªØ¶Ù…Ù† Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø´ÙƒÙ„ Ù…ØªÙƒØ±Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø®Ø±Ø¬Ø§ØªÙ‡ Ø§Ù„Ø®Ø§ØµØ©ØŒ Ø¨Ø§Ù„Ù†Ø¸Ø± Ø¥Ù„Ù‰ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©. ÙÙŠ ğŸ¤— TransformersØŒ ÙŠØªÙ… Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù‡Ø°Ø§ Ø¨ÙˆØ§Ø³Ø·Ø© Ø¯Ø§Ù„Ø© [`~generation.GenerationMixin.generate`]ØŒ ÙˆØ§Ù„ØªÙŠ ØªØªÙˆÙØ± Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø°Ø§Øª Ø§Ù„Ù‚Ø¯Ø±Ø§Øª Ø§Ù„ØªÙˆÙ„ÙŠØ¯ÙŠØ©.\n+\n+Ø³ÙŠÙˆØ¶Ø­ Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ ÙƒÙŠÙÙŠØ©:\n+\n+* ØªØªÙˆÙ„ÙŠØ¯ Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (LLM)\n+* ØªØ¬Ù†Ø¨ Ø§Ù„ÙˆÙ‚ÙˆØ¹ ÙÙŠ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©\n+* Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ø§Ù„Ù‚ØµÙˆÙ‰ Ù…Ù† LLM Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ\n+\n+Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡ØŒ ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©:\n+\n+```bash\n+pip install transformers bitsandbytes>=0.39.0 -q\n+```\n+\n+## ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†Øµ\n+\n+ÙŠØ£Ø®Ø° Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù„Ù€ [Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø³Ø¨Ø¨ÙŠØ©](tasks/language_modeling) ÙŠØ£Ø®Ø° ØªØ³Ù„Ø³Ù„Ù‹Ø§ Ù…Ù† Ø±Ù…ÙˆØ² Ù†ØµÙŠØ© ÙƒÙ…Ø¯Ø®Ù„ ÙˆÙŠØ¹ÙŠØ¯ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ù„Ù„Ø±Ù…Ø² Ø§Ù„ØªØ§Ù„ÙŠ.\n+\n+<!-- [GIF 1 -- FWD PASS] -->\n+<figure class=\"image table text-center m-0 w-full\">\n+    <video\n+        style=\"max-width: 90%; margin: auto;\"\n+        autoplay loop muted playsinline\n+        src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/assisted-generation/gif_1_1080p.mov\"\n+    ></video>\n+    <figcaption>\"Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºØ© (LLM)\"</figcaption>\n+</figure>\n+\n+Ù‡Ù†Ø§Ùƒ Ø¬Ø§Ù†Ø¨ Ø¨Ø§Ù„Øº Ø§Ù„Ø£Ù‡Ù…ÙŠØ© ÙÙŠ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LLMs ÙˆÙ‡Ùˆ ÙƒÙŠÙÙŠØ© Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø±Ù…Ø² Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ù† ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ù‡Ø°Ø§. ÙƒÙ„ Ø´ÙŠØ¡ Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ø·Ø§Ù„Ù…Ø§ Ø£Ù†Ùƒ ØªÙ†ØªÙ‡ÙŠ Ø¨Ø±Ù…Ø² Ù„Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„ØªØ§Ù„ÙŠ. ÙˆÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ø¨Ø³ÙŠØ·Ù‹Ø§ Ù…Ø«Ù„ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø±Ù…Ø² Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø­ØªÙ…Ø§Ù„Ù‹Ø§ Ù…Ù† ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø£Ùˆ Ù…Ø¹Ù‚Ø¯Ù‹Ø§ Ù…Ø«Ù„ ØªØ·Ø¨ÙŠÙ‚ Ø¹Ø´Ø±Ø§Øª Ø§Ù„ØªØ­ÙˆÙ„Ø§Øª Ù‚Ø¨Ù„ Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ù…Ù† Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù†Ø§ØªØ¬.\n+\n+<!-- [GIF 2 -- TEXT GENERATION] -->\n+<figure class=\"image table text-center m-0 w-full\">\n+    <video\n+        style=\"max-width: 90%; margin: auto;\"\n+        autoplay loop muted playsinline\n+        src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/assisted-generation/gif_2_1080p.mov\"\n+    ></video>\n+    <figcaption>\"Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„\"</figcaption>\n+</figure>\n+\n+ØªØªÙƒØ±Ø± Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…ÙˆØ¶Ø­Ø© Ø£Ø¹Ù„Ø§Ù‡ Ø¨Ø´ÙƒÙ„ ØªÙƒØ±Ø§Ø±ÙŠ Ø­ØªÙ‰ ÙŠØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø´Ø±Ø· Ø§Ù„ØªÙˆÙ‚Ù. ÙÙŠ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø«Ø§Ù„ÙŠØŒ ÙŠØ­Ø¯Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø´Ø±Ø· Ø§Ù„ØªÙˆÙ‚ÙØŒ ÙˆØ§Ù„Ø°ÙŠ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØªØ¹Ù„Ù… Ø¹Ù†Ø¯ Ø¥Ø®Ø±Ø§Ø¬ Ø±Ù…Ø² Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ØªØ³Ù„Ø³Ù„ (`EOS`). Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø§Ù„Ø£Ù…Ø± ÙƒØ°Ù„ÙƒØŒ ÙŠØªÙˆÙ‚Ù Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¹Ù†Ø¯ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø·ÙˆÙ„ Ø£Ù‚ØµÙ‰ Ù…Ø­Ø¯Ø¯ Ù…Ø³Ø¨Ù‚Ù‹Ø§.\n+\n+Ù…Ù† Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø®Ø·ÙˆØ© Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø±Ù…Ø² ÙˆØ´Ø±Ø· Ø§Ù„ØªÙˆÙ‚Ù Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ù„Ø¬Ø¹Ù„ Ù†Ù…ÙˆØ°Ø¬Ùƒ ÙŠØªØµØ±Ù ÙƒÙ…Ø§ ØªØªÙˆÙ‚Ø¹ ÙÙŠ Ù…Ù‡Ù…ØªÙƒ. ÙˆÙ„Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¨Ø¨ Ù„Ø¯ÙŠÙ†Ø§ [`~generation.GenerationConfig`] Ù…Ù„Ù Ù…Ø±ØªØ¨Ø· Ø¨ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬ØŒ ÙˆØ§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù„Ù…Ø© ØªÙˆÙ„ÙŠØ¯ÙŠØ© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¬ÙŠØ¯Ø© ÙˆÙŠØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡ Ø¬Ù†Ø¨Ù‹Ø§ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨ Ù…Ø¹ Ù†Ù…ÙˆØ°Ø¬Ùƒ.\n+\n+Ø¯Ø¹Ù†Ø§ Ù†ØªØ­Ø¯Ø« Ø¹Ù† Ø§Ù„ÙƒÙˆØ¯!\n+\n+\n+<Tip>\n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª Ù…Ù‡ØªÙ…Ù‹Ø§ Ø¨Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù€ LLMØŒ ÙØ¥Ù† ÙˆØ§Ø¬Ù‡Ø© [`Pipeline`](pipeline_tutorial) Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ù‡ÙŠ Ù†Ù‚Ø·Ø© Ø§Ù†Ø·Ù„Ø§Ù‚ Ø±Ø§Ø¦Ø¹Ø©. ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ ØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ØªØªØ·Ù„Ø¨ LLMs Ù…ÙŠØ²Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù…Ø«Ù„ Ø§Ù„ØªÙƒÙ…ÙŠÙ… ÙˆØ§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø¯Ù‚ÙŠÙ‚ ÙÙŠ Ø®Ø·ÙˆØ© Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø±Ù…Ø²ØŒ ÙˆØ§Ù„ØªÙŠ ÙŠØªÙ… ØªÙ†ÙÙŠØ°Ù‡Ø§ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„ Ù…Ù† Ø®Ù„Ø§Ù„ [`~generation.GenerationMixin.generate`]. Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LLMs  ÙŠØ³ØªÙ‡Ù„Ùƒ Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ù…ÙˆØ§Ø±Ø¯Ø¯ ÙˆÙŠØ¬Ø¨ ØªÙ†ÙÙŠØ°Ù‡ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ ÙƒØ§ÙÙ.\n+\n+</Tip>\n+\n+Ø£ÙˆÙ„Ø§Ù‹ØŒ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n+\n+```py\n+>>> from transformers import AutoModelForCausalLM\n+\n+>>> model = AutoModelForCausalLM.from_pretrained(\n+...     \"mistralai/Mistral-7B-v0.1\", device_map=\"auto\", load_in_4bit=True\n+... )\n+```\n+\n+Ø³ØªÙ„Ø§Ø­Ø¸ ÙˆØ¬ÙˆØ¯ Ù…Ø¹Ø§Ù…Ù„ÙŠÙ† ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ `from_pretrained`:\n+\n+ - `device_map` ÙŠØ¶Ù…Ù† Ø§Ù†ØªÙ‚Ø§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU) Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ\n+ - `load_in_4bit` ÙŠØ·Ø¨Ù‚ [4-bit dynamic quantization](main_classes/quantization) Ù„Ø®ÙØ¶ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ±\n+\n+Ù‡Ù†Ø§Ùƒ Ø·Ø±Ù‚ Ø£Ø®Ø±Ù‰ Ù„ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ØŒ ÙˆÙ„ÙƒÙ† Ù‡Ø°Ø§ Ø®Ø· Ø£Ø³Ø§Ø³ Ø¬ÙŠØ¯ Ù„Ù„Ø¨Ø¯Ø¡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LLM.\n+\n+Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ](tokenizer_summary).\n+\n+```py\n+>>> from transformers import AutoTokenizer\n+\n+>>> tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", padding_side=\"left\")\n+>>> model_inputs = tokenizer([\"A list of colors: red, blue\"], return_tensors=\"pt\").to(\"cuda\")\n+```\n+\n+ÙŠØ­ØªÙˆÙŠ Ù…ØªØºÙŠØ± `model_inputs` Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¯Ø®Ù„ Ø¨Ø¹Ø¯ ØªÙ‚Ø³ÙŠÙ…Ù‡ Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø§Øª Ù„ØºÙˆÙŠØ© (tokens)ØŒ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ù‚Ù†Ø§Ø¹ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡. ÙÙŠ Ø­ÙŠÙ† Ø£Ù† [`~generation.GenerationMixin.generate`] ØªØ¨Ø°Ù„ Ù‚ØµØ§Ø±Ù‰ Ø¬Ù‡Ø¯Ù‡Ø§ Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù‚Ù†Ø§Ø¹ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ø¹Ù†Ø¯Ù…Ø§ Ù„Ø§ ÙŠØªÙ… ØªÙ…Ø±ÙŠØ±Ù‡ØŒ Ù†ÙˆØµÙŠ Ø¨ØªÙ…Ø±ÙŠØ±Ù‡ ÙƒÙ„Ù…Ø§ Ø£Ù…ÙƒÙ† Ø°Ù„Ùƒ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ù…Ø«Ø§Ù„ÙŠØ©.\n+\n+Ø¨Ø¹Ø¯ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø§Øª Ù„ØºÙˆÙŠØ©ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø¯Ø§Ù„Ø© [`~generation.GenerationMixin.generate`] Ù„Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù„ØºÙˆÙŠØ© Ø§Ù„Ù†Ø§ØªØ¬Ø©. ÙŠØ¬Ø¨ Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ø¥Ù„Ù‰ Ù†Øµ Ù‚Ø¨Ù„ Ø·Ø¨Ø§Ø¹ØªÙ‡.\n+\n+```py\n+>>> generated_ids = model.generate(**model_inputs)\n+>>> tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n+'A list of colors: red, blue, green, yellow, orange, purple, pink,'\n+```\n+\n+Ø£Ø®ÙŠØ±Ù‹Ø§ØŒ Ù„ÙŠØ³ Ø¹Ù„ÙŠÙƒ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªØªØ§Ù„ÙŠØ§Øª Ø§Ù„ÙˆØ§Ø­Ø¯Ø© ØªÙ„Ùˆ Ø§Ù„Ø£Ø®Ø±Ù‰! ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©ØŒ ÙˆØ§Ù„ØªÙŠ Ø³ØªØ¹Ù…Ù„ Ø¹Ù„Ù‰ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ© Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ± Ø¨ØªÙƒÙ„ÙØ© ØµØºÙŠØ±Ø© ÙÙŠ Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙˆØ§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø°Ø§ÙƒØ±. ÙƒÙ„ Ù…Ø§ Ø¹Ù„ÙŠÙƒ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù†Ù‡ Ù‡Ùˆ  ØªØ¹Ø¨Ø¦Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ (Ø§Ù„Ù…Ø²ÙŠØ¯ Ø­ÙˆÙ„ Ø°Ù„Ùƒ Ø£Ø¯Ù†Ø§Ù‡).\n+\n+```py\n+>>> tokenizer.pad_token = tokenizer.eos_token  # Most LLMs don't have a pad token by default\n+>>> model_inputs = tokenizer(\n+...     [\"A list of colors: red, blue\", \"Portugal is\"], return_tensors=\"pt\", padding=True\n+... ).to(\"cuda\")\n+>>> generated_ids = model.generate(**model_inputs)\n+>>> tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n+['A list of colors: red, blue, green, yellow, orange, purple, pink,',\n+'Portugal is a country in southwestern Europe, on the Iber']\n+```\n+\n+ÙˆÙ‡Ø°Ø§ ÙƒÙ„ Ø´ÙŠØ¡! ÙÙŠ Ø¨Ø¶Ø¹ Ø³Ø·ÙˆØ± Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ³Ø®ÙŠØ± Ù‚ÙˆØ© LLM.\n+\n+## Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©\n+\n+Ù‡Ù†Ø§Ùƒ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† [Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªÙˆÙ„ÙŠØ¯](generation_strategies)ØŒ ÙˆÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø­ÙŠØ§Ù† Ù‚Ø¯ Ù„Ø§ ØªÙƒÙˆÙ† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ø­Ø§Ù„ØªÙƒ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…. Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ù…Ø§ ØªØªÙˆÙ‚Ø¹Ù‡ØŒ ÙÙ‚Ø¯ Ù‚Ù…Ù†Ø§ Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø£ÙƒØ«Ø± Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙˆÙƒÙŠÙÙŠØ© ØªØ¬Ù†Ø¨Ù‡Ø§.\n+\n+```py\n+>>> from transformers import AutoModelForCausalLM, AutoTokenizer\n+\n+>>> tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n+>>> tokenizer.pad_token = tokenizer.eos_token  # Most LLMs don't have a pad token by default\n+>>> model = AutoModelForCausalLM.from_pretrained(\n+...     \"mistralai/Mistral-7B-v0.1\", device_map=\"auto\", load_in_4bit=True\n+... )\n+```\n+\n+### Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆÙ„Ø¯ Ù‚ØµÙŠØ± Ø¬Ø¯Ù‹Ø§/Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ù‹Ø§\n+\n+Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø±Ù…ÙˆØ² ÙÙŠ [`~generation.GenerationConfig`] Ø§Ù„Ù…Ù„ÙØŒ `generate` ÙŠØ¹ÙŠØ¯ Ù…Ø§ ÙŠØµÙ„ Ø¥Ù„Ù‰ 20 Ø±Ù…Ø²Ù‹Ø§ Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠ. Ù†ÙˆØµÙŠ Ø¨Ø´Ø¯Ø© Ø¨ØªØ¹ÙŠÙŠÙ† `max_new_tokens` ÙŠØ¯ÙˆÙŠÙ‹Ø§ ÙÙŠ Ù…ÙƒØ§Ù„Ù…Ø© `generate` Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ¹ÙŠØ¯Ù‡Ø§. Ø¶Ø¹ ÙÙŠ Ø§Ø¹ØªØ¨Ø§Ø±Ùƒ Ø£Ù† LLMs (Ø¨Ø´ÙƒÙ„ Ø£ÙƒØ«Ø± Ø¯Ù‚Ø©ØŒ [Ù†Ù…Ø§Ø°Ø¬ ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± ÙÙ‚Ø·](https://huggingface.co/learn/nlp-course/chapter1/6ØŸfw=pt)) ØªØ¹ÙŠØ¯ Ø£ÙŠØ¶Ù‹Ø§ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙƒØ¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ù†Ø§ØªØ¬.\n+```py\n+>>> model_inputs = tokenizer([\"A sequence of numbers: 1, 2\"], return_tensors=\"pt\").to(\"cuda\")\n+\n+>>> # By default, the output will contain up to 20 tokens\n+>>> generated_ids = model.generate(**model_inputs)\n+>>> tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n+'A sequence of numbers: 1, 2, 3, 4, 5'\n+\n+>>> # Setting `max_new_tokens` allows you to control the maximum length\n+>>> generated_ids = model.generate(**model_inputs, max_new_tokens=50)\n+>>> tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n+'A sequence of numbers: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,'\n+```\n+\n+### ÙˆØ¶Ø¹ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ\n+\n+Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠØŒ ÙˆÙ…Ø§ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡ ÙÙŠ [`~generation.GenerationConfig`] Ø§Ù„Ù…Ù„ÙØŒ `generate` ÙŠØ­Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø­ØªÙ…Ø§Ù„Ù‹Ø§ ÙÙ‰ ÙƒÙ„ Ø®Ø·ÙˆØ© Ù…Ù† Ø®Ø·ÙˆØ§Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙˆÙ„ÙŠØ¯ (ÙˆÙ‡Ø°Ø§ ÙŠÙØ¹Ø±Ù Ø¨Ø§Ù„ØªØ´ÙÙŠØ± Ø§Ù„Ø¬Ø´Ø¹). Ø§Ø¹ØªÙ…Ø§Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ù…Ù‡Ù…ØªÙƒØŒ Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ ØºÙŠØ± Ù…Ø±ØºÙˆØ¨ ÙÙŠÙ‡Ø› ØªØ³ØªÙÙŠØ¯ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© Ù…Ø«Ù„ Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø£Ùˆ ÙƒØªØ§Ø¨Ø© Ù…Ù‚Ø§Ù„ Ø³ØªÙÙŠØ¯ Ù…Ù† Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¹ÙŠÙ†Ø© Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© ÙÙŠ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§ØªØŒ ØªÙ…Ù† Ù†Ø§Ø­ÙŠØ© Ø£Ø®Ø±Ù‰ØŒ ÙØ¥Ù† Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØªÙŠ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ø¯Ø®Ù„Ø§Øª Ù…Ø­Ø¯Ø¯Ø©  Ù…Ø«Ù„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ Ø£Ùˆ Ø§Ù„ØªØ±Ø¬Ù… Ù…Ù† ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± Ø§Ù„Ø¬Ø´Ø¹. Ù‚Ù… Ø¨ØªÙØ¹ÙŠÙ„ Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `do_sample=True`ØŒ ÙˆÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ø­ÙˆÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ ÙÙŠ [ØªØ¯ÙˆÙŠÙ†Ø© Ø§Ù„Ù…Ø¯ÙˆÙ†Ø©](https://huggingface.co/blog/how-to-generate).\n+\n+```py\n+>>> # Set seed or reproducibility -- you don't need this unless you want full reproducibility\n+>>> from transformers import set_seed\n+>>> set_seed(42)\n+\n+>>> model_inputs = tokenizer([\"I am a cat.\"], return_tensors=\"pt\").to(\"cuda\")\n+\n+>>> # LLM + greedy decoding = repetitive, boring output\n+>>> generated_ids = model.generate(**model_inputs)\n+>>> tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n+'I am a cat. I am a cat. I am a cat. I am a cat'\n+\n+>>> # With sampling, the output becomes more creative!\n+>>> generated_ids = model.generate(**model_inputs, do_sample=True)\n+>>> tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n+'I am a cat.  Specifically, I am an indoor-only cat.  I'\n+```\n+\n+### Ù…Ø´ÙƒÙ„Ø© Ø­Ø´Ùˆ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ÙÙ‰ Ø§Ù„Ø§ØªØ¬Ø§Ø© Ø§Ù„Ø®Ø·Ø£\n+\n+LLMs Ù‡ÙŠ [Ù…Ø¹Ù…Ø§Ø±ÙŠØ§Øª ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± ÙÙ‚Ø·](https://huggingface.co/learn/nlp-course/chapter1/6ØŸfw=pt)ØŒ Ù…Ù…Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡Ø§ ØªØ³ØªÙ…Ø± ÙÙŠ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø¹Ù„Ù‰ Ù…ÙˆØ¬Ù‡ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ. ÙØ¥Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¨Ù†ÙØ³ Ø§Ù„Ø·ÙˆÙ„. Ù„Ø­Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø³Ø£Ù„Ø©ØŒ ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© Ø±Ù…ÙˆØ² Ø­Ø´Ùˆ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ø£Ù‚ØµØ±. Ù†Ø¸Ø±Ù‹Ø§ Ù„Ø£Ù† LLMs  Ù„Ø§ ØªÙˆÙ„ÙŠ Ø§Ù‡ØªÙ…Ø§Ù…Ù‹Ø§ Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø­Ø´Ùˆ Ù‡Ø°Ù‡ØŒ Ø°Ù„ÙƒØŒ ÙŠØ¬Ø¨ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù…Ù‡Ù… Ù…Ù† Ø§Ù„Ù…Ø¯Ø®Ù„ Ø§Ù„Ø°ÙŠ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ±ÙƒØ² Ø¹Ù„ÙŠÙ‡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ ÙˆÙ‡Ø°Ø§ ÙŠØªÙ… Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ù…Ø§ ÙŠØ³Ù…Ù‰ Ø¨Ù€ \"Ù‚Ù†Ø§Ø¹ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡\". ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø­Ø´Ùˆ ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù…Ø¯Ø®Ù„ (Ø§Ù„Ø­Ø´Ùˆ Ù…Ù† Ø§Ù„ÙŠØ³Ø§Ø±)ØŒ ÙˆÙ„ÙŠØ³ ÙÙŠ Ù†Ù‡Ø§ÙŠØªÙ‡.\n+\n+```py\n+>>> # The tokenizer initialized above has right-padding active by default: the 1st sequence,\n+>>> # which is shorter, has padding on the right side. Generation fails to capture the logic.\n+>>> model_inputs = tokenizer(\n+...     [\"1, 2, 3\", \"A, B, C, D, E\"], padding=True, return_tensors=\"pt\"\n+... ).to(\"cuda\")\n+>>> generated_ids = model.generate(**model_inputs)\n+>>> tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n+'1, 2, 33333333333'\n+\n+>>> # With left-padding, it works as expected!\n+>>> tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", padding_side=\"left\")\n+>>> tokenizer.pad_token = tokenizer.eos_token  # Most LLMs don't have a pad token by default\n+>>> model_inputs = tokenizer(\n+...     [\"1, 2, 3\", \"A, B, C, D, E\"], padding=True, return_tensors=\"pt\"\n+... ).to(\"cuda\")\n+>>> generated_ids = model.generate(**model_inputs)\n+>>> tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n+'1, 2, 3, 4, 5, 6,'\n+```\n+\n+### Ù…ÙˆØ¬Ù‡ ØºÙŠØ± ØµØ­ÙŠØ­\n+\n+ØªØªÙˆÙ‚Ø¹ Ø¨Ø¹Ø¶ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¹Ù„Ù‰ ØµÙŠØºØ© Ù…Ø­Ø¯Ø¯Ø© Ù„Ù„Ù…Ø¯Ø®Ù„Ø§Øª  Ù„Ù„Ø¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­. Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§ØªØ¨Ø§Ø¹ Ù‡Ø°Ù‡ Ø§Ù„ØµÙŠØºØ©ØŒ ÙØ¥Ù† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØªØ£Ø«Ø± Ø³Ù„Ø¨Ù‹Ø§: Ù„ÙƒÙ† Ù‡Ø°Ø§ Ø§Ù„ØªØ¯Ù‡ÙˆØ± Ù‚Ø¯ Ù„Ø§ ÙŠÙƒÙˆÙ† ÙˆØ§Ø¶Ø­Ù‹Ø§ Ù„Ù„Ø¹ÙŠØ§Ù†. ØªØªÙˆÙØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ø­ÙˆÙ„ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªÙˆØ®ÙŠ Ø§Ù„Ø­Ø°Ø±ØŒ ÙÙŠ [Ø§Ù„Ø¯Ù„ÙŠÙ„](tasks/prompting). Ø¯Ø¹Ù†Ø§ Ù†Ø±Ù‰ Ù…Ø«Ø§Ù„Ø§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LLM Ù„Ù„Ø¯Ø±Ø¯Ø´Ø©ØŒ ÙˆØ§Ù„Ø°ÙŠ ÙŠØ³ØªØ®Ø¯Ù… [Ù‚Ø§Ù„Ø¨ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©](chat_templating):\n+```python\n+>>> tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-alpha\")\n+>>> model = AutoModelForCausalLM.from_pretrained(\n+...     \"HuggingFaceH4/zephyr-7b-alpha\", device_map=\"auto\", load_in_4bit=True\n+... )\n+>>> set_seed(0)\n+>>> prompt = \"\"\"How many helicopters can a human eat in one sitting? Reply as a thug.\"\"\"\n+>>> model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n+>>> input_length = model_inputs.input_ids.shape[1]\n+>>> generated_ids = model.generate(**model_inputs, max_new_tokens=20)\n+>>> print(tokenizer.batch_decode(generated_ids[:, input_length:], skip_special_tokens=True)[0])\n+\"I'm not a thug, but i can tell you that a human cannot eat\"\n+>>> # Oh no, it did not follow our instruction to reply as a thug! Let's see what happens when we write\n+>>> # a better prompt and use the right template for this model (through `tokenizer.apply_chat_template`)\n+\n+>>> set_seed(0)\n+>>> messages = [\n+...     {\n+...         \"role\": \"system\",\n+...         \"content\": \"You are a friendly chatbot who always responds in the style of a thug\",\n+...     },\n+...     {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n+... ]\n+>>> model_inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n+>>> input_length = model_inputs.shape[1]\n+>>> generated_ids = model.generate(model_inputs, do_sample=True, max_new_tokens=20)\n+>>> print(tokenizer.batch_decode(generated_ids[:, input_length:], skip_special_tokens=True)[0])\n+'None, you thug. How bout you try to focus on more useful questions?'\n+>>> # As we can see, it followed a proper thug style ğŸ˜\n+```\n+\n+## Ù…ÙˆØ§Ø±Ø¯ Ø¥Ø¶Ø§ÙÙŠØ©\n+\n+ÙÙŠ Ø­ÙŠÙ† Ø£Ù† Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨Ø³ÙŠØ·Ø© Ù†Ø³Ø¨ÙŠÙ‹Ø§ØŒ ÙØ¥Ù† Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ø§Ù„Ù‚ØµÙˆÙ‰ Ù…Ù† LLM Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† Ù…Ù‡Ù…Ø© ØµØ¹Ø¨Ø© Ù„Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…ØªØ­Ø±ÙƒØ©. Ù„Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„ØºÙˆØµ Ø¨Ø´ÙƒÙ„ Ø£Ø¹Ù…Ù‚ ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… LLM ÙˆÙÙ‡Ù…Ù‡:\n+\n+### Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„ØªÙˆÙ„ÙŠØ¯ ÙÙŠ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©\n+\n+1. Ø¯Ù„ÙŠÙ„ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© [Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø·Ø±Ù‚ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©](generation_strategies)ØŒ ÙˆÙƒÙŠÙÙŠØ© Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ù„Ù ØªÙƒÙˆÙŠÙ† Ø§Ù„ØªÙˆÙ„ÙŠØ¯ØŒ ÙˆÙƒÙŠÙÙŠØ© Ø¨Ø« Ø§Ù„Ù†Ø§ØªØ¬Ø›\n+2. [ØªØ³Ø±ÙŠØ¹ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†Øµ](llm_optims)Ø›\n+3.[Ù‚ÙˆØ§Ù„Ø¨ Ù…ÙˆØ¬Ù‡Ø§Øª Ù„Ù„Ø¯Ø±Ø¯Ø´Ø© LLMs](chat_\n+4. [Ø¯Ù„ÙŠÙ„ ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…ÙˆØ¬Ù‡](tasks/prompting);\n+5. Ù…Ø±Ø¬Ø¹ ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª (API)  [`~generation.GenerationConfig`], [`~generation.GenerationMixin.generate`], Ùˆ  [generate-related classes](internal/generation_utils). ÙˆØ§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙˆÙ„ÙŠØ¯.!\n+\n+### Ù„ÙˆØ­Ø§Øª ØµØ¯Ø§Ø±Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©\n+1. Ù„ÙˆØ­Ø© ØµØ¯Ø§Ø±Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø§Ù„Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø± (Open LLM Leaderboard): ØªØ±ÙƒØ² Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø± [Ø±Ø§Ø¨Ø· Ù„ÙˆØ­Ø© Ø§Ù„ØµØ¯Ø§Ø±Ø©](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard).\n+2. Ù„ÙˆØ­Ø© ØµØ¯Ø§Ø±Ø© Ø£Ø¯Ø§Ø¡ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø§Ù„Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø± (Open LLM-Perf Leaderboard): ØªØ±ÙƒØ² Ø¹Ù„Ù‰ Ø¥Ù†ØªØ§Ø¬ÙŠØ© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© [Ø±Ø§Ø¨Ø· Ù„ÙˆØ­Ø© Ø§Ù„ØµØ¯Ø§Ø±Ø©](https://huggingface.co/spaces/optimum/llm-perf-leaderboard).\n+\n+### Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙˆØ§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ© ÙˆØ§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø°Ø§ÙƒØ±Ø©\n+1. Ø¯Ù„ÙŠÙ„ ØªØ­Ø³ÙŠÙ† Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ù…Ù† Ø­ÙŠØ« Ø§Ù„Ø³Ø±Ø¹Ø© ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø©: Ø¯Ù„ÙŠÙ„ ØªØ­Ø³ÙŠÙ† Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©.\n+2. Ø§Ù„ØªÙƒÙ…ÙŠÙ… (Quantization): Ø¯Ù„ÙŠÙ„ Ø­ÙˆÙ„ ØªÙ‚Ù†ÙŠØ© Ø§Ù„ØªÙƒÙ…ÙŠÙ… Ø§Ù„ØªÙƒÙ…ÙŠÙ… Ù…Ø«Ù„ ØªÙ‚Ù†ÙŠØªÙŠ bitsandbytes Ùˆ autogptqØŒ ÙˆØ§Ù„ØªÙŠ ØªÙˆØ¶Ø­ ÙƒÙŠÙÙŠØ© ØªÙ‚Ù„ÙŠÙ„ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ±.\n+\n+### Ù…ÙƒØªØ¨Ø§Øª Ù…Ø±ØªØ¨Ø·Ø©\n+1. [`optimum`](https://github.com/huggingface/optimum), Ø§Ù…ØªØ¯Ø§Ø¯ Ù„Ù…ÙƒØªØ¨Ø© Transformers ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ø£Ø¬Ù‡Ø²Ø© Ù…Ø¹ÙŠÙ†Ø©.\n+2. [`outlines`](https://github.com/outlines-dev/outlines), Ù…ÙƒØªØ¨Ø© Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ (Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ù„ØªÙˆÙ„ÙŠØ¯ Ù…Ù„ÙØ§Øª JSON).\n+3. [`SynCode`](https://github.com/uiuc-focal-lab/syncode), Ù…ÙƒØªØ¨Ø© Ù„Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ÙˆØ¬Ù‡ Ø¨Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø®Ø§Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ (Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ JSONØŒ SQLØŒ Python).\n+4. [`text-generation-inference`](https://github.com/huggingface/text-generation-inference), Ø®Ø§Ø¯Ù… Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¥Ù†ØªØ§Ø¬ Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©.\n+5. [`text-generation-webui`](https://github.com/oobabooga/text-generation-webui), ÙˆØ§Ø¬Ù‡Ø© Ù…Ø³ØªØ®Ø¯Ù… Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ. Â  "
        },
        {
            "sha": "620261a0c58a3b1cb0580c6c78fe1b327c0b4cf6",
            "filename": "docs/source/ar/model_sharing.md",
            "status": "added",
            "additions": 223,
            "deletions": 0,
            "changes": 223,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fmodel_sharing.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,223 @@\n+# Ø´Ø§Ø±Ùƒ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ù…Ø¹ Ø§Ù„Ø¹Ø§Ù„Ù…\n+\n+Ø£Ø¸Ù‡Ø±Øª Ø¢Ø®Ø± Ø¯Ø±Ø³ÙŠÙ† ØªØ¹Ù„ÙŠÙ…ÙŠÙŠÙ† ÙƒÙŠÙÙŠØ© Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯Ù‚Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyTorch Ùˆ Keras Ùˆ ğŸ¤— Accelerate Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙˆØ²Ø¹Ø©. ÙˆØ§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù‡ÙŠ Ù…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬Ùƒ Ù…Ø¹ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹! ÙÙŠ Hugging FaceØŒ Ù†Ø¤Ù…Ù† Ø¨Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ù…ÙØªÙˆØ­Ø© Ù„Ù„Ù…Ø¹Ø±ÙØ© ÙˆØ§Ù„Ù…ÙˆØ§Ø±Ø¯ Ù„ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ø¬Ù…ÙŠØ¹ Ù…Ù† Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ. ÙˆÙ†Ø´Ø¬Ø¹Ùƒ Ø¹Ù„Ù‰ Ù…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬Ùƒ Ù…Ø¹ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¢Ø®Ø±ÙŠÙ† Ø¹Ù„Ù‰ ØªÙˆÙÙŠØ± Ø§Ù„ÙˆÙ‚Øª ÙˆØ§Ù„Ù…ÙˆØ§Ø±Ø¯.\n+\n+ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ø±Ø³ØŒ Ø³ØªØªØ¹Ù„Ù… Ø·Ø±ÙŠÙ‚ØªÙŠÙ† Ù„Ù…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ø£Ùˆ Ù…Ø¶Ø¨ÙˆØ· Ø¹Ù„Ù‰ Ù…Ù†ØµØ© [Model Hub](https://huggingface.co/models):\n+\n+- Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ Ø¥Ù„Ù‰ Ù…Ù†ØµØ© Hub Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ.\n+\n+- Ù‚Ù… Ø¨Ø³Ø­Ø¨ ÙˆØ¥ÙÙ„Ø§Øª Ù…Ù„ÙØ§ØªÙƒ Ø¥Ù„Ù‰ Hub Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© web.\n+\n+<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/XvSGPZFEjDY\" title=\"Ù…Ø´ØºÙ„ ÙÙŠØ¯ÙŠÙˆ YouTube\"\n+frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope;\n+picture-in-picture\" allowfullscreen></iframe>\n+\n+<Tip>\n+\n+Ù„Ù…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ØŒ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨ Ø¹Ù„Ù‰ [huggingface.co](https://huggingface.co/join). ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø§Ù„Ø§Ù†Ø¶Ù…Ø§Ù… Ø¥Ù„Ù‰ Ù…Ù†Ø¸Ù…Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù†Ø¸Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø©.\n+\n+</Tip>\n+\n+## Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹\n+\n+ÙŠØ¹Ù…Ù„ ÙƒÙ„ Ù…Ø³ØªÙˆØ¯Ø¹ Ø¹Ù„Ù‰ Model Hub Ù…Ø«Ù„ Ù…Ø³ØªÙˆØ¯Ø¹ GitHub Ø§Ù„Ù†ØªÙ‚Ù„ÙŠØ¯ÙŠ. ØªÙ‚Ø¯Ù… Ù…Ø³ØªÙˆØ¯Ø¹Ø§ØªÙ†Ø§ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª ÙˆØ³Ø¬Ù„ Ø§Ù„ØªØºÙŠÙŠØ±Ø§ØªØŒ ÙˆÙ‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ Ø±Ø¤ÙŠØ© Ø§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø¨ÙŠÙ† Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª.\n+\n+ØªØ¹ØªÙ…Ø¯ Ø¢Ù„ÙŠØ© Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø¹Ù„Ù‰ Ù…Ù†ØµØ© Model Hub Ø¹Ù„Ù‰ Ù†Ø¸Ø§Ù…ÙŠ git Ùˆ [git-lfs](https://git-lfs.github.com/). ÙˆØ¨Ø¹Ø¨Ø§Ø±Ø© Ø£Ø®Ø±Ù‰ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹  ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬ ÙƒØ£Ù†Ù‡ Ù…Ø³ØªÙˆØ¯Ø¹ Ù…Ø³ØªÙ‚Ù„ØŒ Ù…Ù…Ø§ ÙŠÙ…ÙƒÙ‘Ù† Ù…Ù† Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„ ÙˆØ§Ù„Ù‚Ø§Ø¨Ù„ÙŠØ© Ù„Ù„ØªØ·ÙˆÙŠØ±. ÙŠØ³Ù…Ø­ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø¨Ø¥Ø¬Ø±Ø§Ø¡ ØªØ¹Ø¯ÙŠÙ„Ø§Øª ÙˆØªØ«Ø¨ÙŠØª Ø¥ØµØ¯Ø§Ø± Ù…Ø­Ø¯Ø¯ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø±Ù…Ø² Ø§Ù„ØªØºÙŠÙŠØ± (commit hash) Ø£Ùˆ ÙˆØ³Ù… (tag) Ø£Ùˆ ÙØ±Ø¹ (branch).\n+\n+Ø¨ÙØ¶Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙŠØ²Ø©ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ Ø¥ØµØ¯Ø§Ø± Ù…Ø­Ø¯Ø¯ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ù„Ù…Ø© Ø§Ù„Ø¥ØµØ¯Ø§Ø± \"revision\":\n+\n+```py\n+>>> model = AutoModel.from_pretrained(\n+...     \"julien-c/EsperBERTo-small\", revision=\"v2.0.1\"  # Ø§Ø³Ù… Ø§Ù„Ø¹Ù„Ø§Ù…Ø©ØŒ Ø£Ùˆ Ø§Ø³Ù… Ø§Ù„ÙØ±Ø¹ØŒ Ø£Ùˆ ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ø§Ù„ØªØ²Ø§Ù…\n+... )\n+```\n+\n+Ù…Ù† Ø§Ù„Ø³Ù‡Ù„ Ø£ÙŠØ¶Ù‹Ø§ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª  Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¯Ø§Ø®Ù„ Ù…Ø³ØªÙˆØ¯Ø¹ØŒ ÙˆÙŠÙ…ÙƒÙ†Ùƒ Ø¹Ø±Ø¶ Ø³Ø¬Ù„ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„ØªÙŠ Ø·Ø±Ø£Øª Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆÙ…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø¨ÙŠÙ† Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©:\n+\n+![vis_diff](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/vis_diff.png)\n+\n+## Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯\n+\n+Ù‚Ø¨Ù„ Ù…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ HubØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø¹ØªÙ…Ø§Ø¯ Ø­Ø³Ø§Ø¨ Hugging Face Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ.  Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… Ù…Ù†ØµØ© Ø§Ù„Ø£ÙˆØ§Ù…Ø±ØŒ ÙÙ‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø­ÙŠØ« ØªÙ… ØªØ«Ø¨ÙŠØª ğŸ¤— Transformers. Ø³ÙŠÙ‚ÙˆÙ… Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø± Ø¨ØªØ®Ø²ÙŠÙ† Ø±Ù…Ø² Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ ÙÙŠ Ù…Ø¬Ù„Ø¯ ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù€ Hugging Face (`~/.cache/` Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠ):\n+\n+```bash\n+huggingface-cli login\n+```\n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… Ø¯ÙØªØ± Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ø«Ù„ Jupyter Ø£Ùˆ ColaboratoryØŒ ÙØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© [`huggingface_hub`](https://huggingface.co/docs/hub/adding-a-library). ØªØ³Ù…Ø­ Ù„Ùƒ Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø¨Ø§Ù„ØªÙØ§Ø¹Ù„ Ø¨Ø±Ù…Ø¬ÙŠÙ‹Ø§ Ù…Ø¹ Hub.\n+\n+```bash\n+pip install huggingface_hub\n+```\n+\n+Ø«Ù… Ø§Ø³ØªØ®Ø¯Ù… `notebook_login` Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ HubØŒ ÙˆØ§ØªØ¨Ø¹ Ø§Ù„Ø±Ø§Ø¨Ø· [Ù‡Ù†Ø§](https://huggingface.co/settings/token) Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø±Ù…Ø² Ù„Ù„ØªØ³Ø¬ÙŠÙ„:\n+\n+```py\n+>>> from huggingface_hub import notebook_login\n+\n+>>> notebook_login()\n+```\n+\n+\n+## ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„ÙŠØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø¹Ù…Ù„\n+\n+Ù„Ø¶Ù…Ø§Ù† Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬Ùƒ Ù…Ù† Ù‚Ø¨Ù„ Ø´Ø®Øµ ÙŠØ¹Ù…Ù„ Ø¨Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ù…Ø®ØªÙ„ÙØŒ Ù†ÙˆØµÙŠ Ø¨ØªØ­ÙˆÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬Ùƒ ÙˆØ±ÙØ¹Ù‡ Ù…Ø¹ Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† PyTorch Ùˆ TensorFlow. ÙÙŠ Ø­ÙŠÙ† Ø£Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù„Ø§ ÙŠØ²Ø§Ù„ Ø¨Ø¥Ù…ÙƒØ§Ù†Ù‡Ù… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ù…Ù† Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ù…Ø®ØªÙ„Ù Ø¥Ø°Ø§ ØªØ®Ø·ÙŠØª Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ©ØŒ Ø¥Ù„Ø§ Ø£Ù†Ù‡ Ø³ÙŠÙƒÙˆÙ† Ø£Ø¨Ø·Ø£ Ù„Ø£Ù† ğŸ¤— Transformers Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­ÙˆÙŠÙ„ Ù†Ù‚Ø·Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„.\n+\n+ØªØ­ÙˆÙŠÙ„ Ù†Ù‚Ø·Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ù„Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ø¢Ø®Ø± Ø£Ù…Ø± Ø³Ù‡Ù„. ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª PyTorch Ùˆ TensorFlow (Ø±Ø§Ø¬Ø¹ [Ù‡Ù†Ø§](installation) Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ«Ø¨ÙŠØª)ØŒ Ø«Ù… Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù„Ø§Ø¦Ù… Ù„Ù…Ù‡Ù…ØªÙƒ ÙÙŠ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø¢Ø®Ø±.\n+\n+<frameworkcontent>\n+<pt>\n+Ø­Ø¯Ø¯ `from_tf=True` Ù„ØªØ­ÙˆÙŠÙ„ Ù†Ù‚Ø·Ø© ØªØ­Ù‚Ù‚ Ù…Ù† TensorFlow Ø¥Ù„Ù‰ PyTorch:\n+\n+```py\n+>>> pt_model = DistilBertForSequenceClassification.from_pretrained(\"path/to/awesome-name-you-picked\", from_tf=True)\n+>>> pt_model.save_pretrained(\"path/to/awesome-name-you-picked\")\n+```\n+</pt>\n+<tf>\n+Ø­Ø¯Ø¯ `from_pt=True` Ù„ØªØ­ÙˆÙŠÙ„ Ù†Ù‚Ø·Ø© ØªØ­Ù‚Ù‚ Ù…Ù† PyTorch Ø¥Ù„Ù‰ TensorFlow:\n+\n+```py\n+>>> tf_model = TFDistilBertForSequenceClassification.from_pretrained(\"path/to/awesome-name-you-picked\", from_pt=True)\n+```\n+\n+Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø­ÙØ¸ Ù†Ù…ÙˆØ°Ø¬ TensorFlow Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ù†Ù‚Ø·Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©:\n+\n+```py\n+>>> tf_model.save_pretrained(\"path/to/awesome-name-you-picked\")\n+```\n+</tf>\n+<jax>\n+Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ§Ø­Ù‹Ø§ ÙÙŠ FlaxØŒ ÙÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ØªØ­ÙˆÙŠÙ„ Ù†Ù‚Ø·Ø© ØªØ­Ù‚Ù‚ Ù…Ù† PyTorch Ø¥Ù„Ù‰ Flax:\n+\n+```py\n+>>> flax_model = FlaxDistilBertForSequenceClassification.from_pretrained(\n+...     \"path/to/awesome-name-you-picked\", from_pt=True\n+... )\n+```\n+</jax>\n+</frameworkcontent>\n+\n+## Ø¯ÙØ¹ Ù†Ù…ÙˆØ°Ø¬ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n+\n+<frameworkcontent>\n+<pt>\n+<Youtube id=\"Z1-XMy-GNLQ\"/>\n+\n+Ù…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¹Ù„Ù‰ Hub Ù…Ø± Ø¨Ø³ÙŠØ· Ù„Ù„ØºØ§ÙŠØ© ÙƒÙ„ Ù…Ø§ Ø¹Ù„ÙŠÙƒ Ù‡Ùˆ Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„Ù…Ø© Ø£Ùˆ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø±Ø¯ Ø¥Ø¶Ø§ÙÙŠ. ÙƒÙ…Ø§ ØªØ°ÙƒØ± Ù…Ù† Ø¯Ø±Ø³ [Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¯Ù‚ÙŠÙ‚](training)ØŒ ÙØ¥Ù† ÙØ¦Ø© [`TrainingArguments`] Ù‡ÙŠ Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ø°ÙŠ ØªØ­Ø¯Ø¯ ÙÙŠÙ‡ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ÙØ§Ø¦Ù‚Ø© ÙˆØ®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©. ØªØ´Ù…Ù„ Ø¥Ø­Ø¯Ù‰ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ Ø¯ÙØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù†ØµØ© Hub. Ù‚Ù… Ø¨ØªØ¹ÙŠÙŠÙ† `push_to_hub=True` ÙÙŠ [`TrainingArguments`]:\n+\n+```py\n+>>> training_args = TrainingArguments(output_dir=\"my-awesome-model\", push_to_hub=True)\n+```\n+\n+Ù…Ø±Ø± Ù…Ø¹Ø§Ù…ï»»Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙƒØ§Ù„Ù…Ø¹ØªØ§Ø¯ Ø¥Ù„Ù‰ [`Trainer`]:\n+\n+```py\n+>>> trainer = Trainer(\n+...     model=model,\n+...     args=training_args,\n+...     train_dataset=small_train_dataset,\n+...     eval_dataset=small_eval_dataset,\n+...     compute_metrics=compute_metrics,\n+... )\n+```\n+\n+Ø¨Ø¹Ø¯ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¨Ø¯Ù‚Ø©ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© [`~transformers.Trainer.push_to_hub`] Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ [`Trainer`] Ù„Ø¯ÙØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù†ØµØ© Hub. Ø³ÙˆÙ ØªØ¶ÙŠÙ ğŸ¤— Transformers ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ÙØ§Ø¦Ù‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆÙ†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ø¥Ø·Ø§Ø± Ø¥Ù„Ù‰ Ø¨Ø·Ø§Ù‚Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ!\n+\n+```py\n+>>> trainer.push_to_hub()\n+```\n+</pt>\n+<tf>\n+Ø´Ø§Ø±Ùƒ Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ Ø¹Ù„Ù‰ Hub Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`PushToHubCallback`]. ÙÙŠ Ø¯Ø§Ù„Ø© [`PushToHubCallback`], Ø£Ø¶Ù:\n+\n+- Ø¯Ù„ÙŠÙ„ Ø¥Ø®Ø±Ø§Ø¬ Ù„Ù†Ù…ÙˆØ°Ø¬Ùƒ.\n+- Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ.\n+- `hub_model_id`ØŒ ÙˆØ§Ù„Ø°ÙŠ Ù‡Ùˆ Ø§Ø³Ù… Ù…Ø³ØªØ®Ø¯Ù… Hub ÙˆØ§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ.\n+\n+```py\n+>>> from transformers import PushToHubCallback\n+\n+>>> push_to_hub_callback = PushToHubCallback(\n+...     output_dir=\"./your_model_save_path\", tokenizer=tokenizer, hub_model_id=\"your-username/my-awesome-model\"\n+... )\n+```\n+\n+Ø£Ø¶Ù Ø§Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¥Ù„Ù‰ [`fit`](https://keras.io/api/models/model_training_apis/)ØŒ ÙˆØ³ÙŠÙ‚ÙˆÙ… ğŸ¤— Transformers Ø¨Ø¯ÙØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ø¥Ù„Ù‰ Hub:\n+\n+```py\n+>>> model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3, callbacks=push_to_hub_callback)\n+```\n+</tf>\n+</frameworkcontent>\n+\n+## Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© `push_to_hub`\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ `push_to_hub` Ù…Ø¨Ø§Ø´Ø±Ø© Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ù„ØªØ­Ù…ÙŠÙ„Ù‡ Ø¥Ù„Ù‰ Hub.\n+\n+Ø­Ø¯Ø¯ Ø§Ø³Ù… Ù†Ù…ÙˆØ°Ø¬Ùƒ ÙÙŠ `push_to_hub`:\n+\n+```py\n+>>> pt_model.push_to_hub(\"my-awesome-model\")\n+```\n+\n+ÙŠÙ†Ø´Ø¦ Ù‡Ø°Ø§ Ù…Ø³ØªÙˆØ¯Ø¹Ù‹Ø§ ØªØ­Øª Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø¨Ø§Ø³Ù… Ù†Ù…ÙˆØ°Ø¬ `my-awesome-model`. ÙŠÙ…ÙƒÙ† Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø¢Ù† ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© `from_pretrained`:\n+\n+```py\n+>>> from transformers import AutoModel\n+\n+>>> model = AutoModel.from_pretrained(\"your_username/my-awesome-model\")\n+```\n+```py\n+>>> from transformers import AutoModel\n+\n+>>> model = AutoModel.from_pretrained(\"your_username/my-awesome-model\")\n+```\n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª ØªÙ†ØªÙ…ÙŠ Ø¥Ù„Ù‰ Ù…Ù†Ø¸Ù…Ø© ÙˆØªØ±ÙŠØ¯ Ø¯ÙØ¹ Ù†Ù…ÙˆØ°Ø¬Ùƒ ØªØ­Øª Ø§Ø³Ù… Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„ÙƒØŒ ÙÙ…Ø§ Ø¹Ù„ÙŠÙƒ Ø³ÙˆÙ‰ Ø¥Ø¶Ø§ÙØªÙ‡ Ø¥Ù„Ù‰ `repo_id`:\n+\n+```py\n+>>> pt_model.push_to_hub(\"my-awesome-org/my-awesome-model\")\n+```\n+\n+ÙŠÙ…ÙƒÙ† Ø£ÙŠØ¶Ù‹Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© `push_to_hub` Ù„Ø¥Ø¶Ø§ÙØ© Ù…Ù„ÙØ§Øª Ø£Ø®Ø±Ù‰ Ø¥Ù„Ù‰ Ù…Ø³ØªÙˆØ¯Ø¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø£Ø¶Ù Ø±Ù…ÙˆØ²Ù‹Ø§ Ø¥Ù„Ù‰ Ù…Ø³ØªÙˆØ¯Ø¹ Ù†Ù…ÙˆØ°Ø¬:\n+\n+```py\n+>>> tokenizer.push_to_hub(\"my-awesome-model\")\n+```\n+\n+Ø£Ùˆ Ø±Ø¨Ù…Ø§ ØªØ±ÙŠØ¯ Ø¥Ø¶Ø§ÙØ© Ø¥ØµØ¯Ø§Ø± TensorFlow Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ PyTorch Ø§Ù„Ù…Ø¶Ø¨ÙˆØ·:\n+\n+```py\n+>>> tf_model.push_to_hub(\"my-awesome-model\")\n+```\n+\n+Ø§Ù„Ø¢Ù† Ø¹Ù†Ø¯ Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ù…Ù„ÙÙƒ Ø§Ù„Ø´Ø®ØµÙŠ Ø¹Ù„Ù‰ Hugging FaceØŒ ÙŠØ¬Ø¨ Ø£Ù† ØªØ±Ù‰ Ù…Ø³ØªÙˆØ¯Ø¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙŠ Ø£Ù†Ø´Ø£ØªÙ‡ Ø­Ø¯ÙŠØ«Ù‹Ø§. Ø³ÙŠØ¤Ø¯ÙŠ Ø§Ù„Ù†Ù‚Ø± ÙÙˆÙ‚ Ø¹Ù„Ø§Ù…Ø© Ø§Ù„ØªØ¨ÙˆÙŠØ¨ **Files** Ø¥Ù„Ù‰ Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ Ù‚Ù…Øª Ø¨ØªØ­Ù…ÙŠÙ„Ù‡Ø§ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹.\n+\n+Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØªØ­Ù…ÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ù…Ø³ØªÙˆØ¯Ø¹ØŒ Ø±Ø§Ø¬Ø¹ ÙˆØ«Ø§Ø¦Ù‚ Hub [Ù‡Ù†Ø§](https://huggingface.co/docs/hub/how-to-upstream).\n+\n+## Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© web\n+\n+ÙŠÙ…ÙƒÙ† Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø°ÙŠÙ† ÙŠÙØ¶Ù„ÙˆÙ† Ù†Ù‡Ø¬ Ø¹Ø¯Ù… Ø§Ù„ØªØ±Ù…ÙŠØ² ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø®Ù„Ø§Ù„ ÙˆØ§Ø¬Ù‡Ø© Hub web. Ù‚Ù… Ø¨Ø²ÙŠØ§Ø±Ø© [huggingface.co/new](https://huggingface.co/new) Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªÙˆØ¯Ø¹ Ø¬Ø¯ÙŠØ¯:\n+\n+![new_model_repo](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/new_model_repo.png)\n+\n+Ù…Ù† Ù‡Ù†Ø§ØŒ Ø£Ø¶Ù Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ Ù†Ù…ÙˆØ°Ø¬Ùƒ:\n+\n+- Ø­Ø¯Ø¯ **Ù…Ø§Ù„Ùƒ** Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹. ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ Ø£Ù†Øª Ø£Ùˆ Ø£ÙŠ Ù…Ù† Ø§Ù„Ù…Ù†Ø¸Ù…Ø§Øª Ø§Ù„ØªÙŠ ØªÙ†ØªÙ…ÙŠ Ø¥Ù„ÙŠÙ‡Ø§.\n+- Ø§Ø®ØªØ± Ø§Ø³Ù…Ù‹Ø§ Ù„Ù†Ù…ÙˆØ°Ø¬ÙƒØŒ ÙˆØ§Ù„Ø°ÙŠ Ø³ÙŠÙƒÙˆÙ† Ø£ÙŠØ¶Ù‹Ø§ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹.\n+- Ø§Ø®ØªØ± Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¹Ø§Ù…Ù‹Ø§ Ø£Ù… Ø®Ø§ØµÙ‹Ø§.\n+- Ø­Ø¯Ø¯ ØªØ±Ø®ÙŠØµ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„Ù†Ù…ÙˆØ°Ø¬Ùƒ.\n+\n+Ø§Ù„Ø¢Ù† Ø§Ù†Ù‚Ø± ÙÙˆÙ‚ Ø¹Ù„Ø§Ù…Ø© Ø§Ù„ØªØ¨ÙˆÙŠØ¨ **Files** Ø«Ù… Ø§Ù†Ù‚Ø± ÙÙˆÙ‚ Ø§Ù„Ø²Ø± **Add file** Ù„Ø¥Ø¶Ø§ÙØ© Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ø¥Ù„Ù‰ Ù…Ø³ØªÙˆØ¯Ø¹Ùƒ. Ø«Ù… Ø§Ø³Ø­Ø¨ ÙˆØ£Ø³Ù‚Ø· Ù…Ù„ÙÙ‹Ø§ Ù„ØªØ­Ù…ÙŠÙ„Ù‡ ÙˆØ£Ø¶Ù Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø§Ù„ØªØ²Ø§Ù….\n+\n+![upload_file](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/upload_file.png)\n+\n+## Ø¥Ø¶Ø§ÙØ© Ø¨Ø·Ø§Ù‚Ø© Ù†Ù…ÙˆØ°Ø¬\n+\n+Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙÙ‡Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù„Ù‚Ø¯Ø±Ø§Øª Ù†Ù…ÙˆØ°Ø¬Ùƒ ÙˆÙ‚ÙŠÙˆØ¯Ù‡ ÙˆØªØ­ÙŠØ²Ø§ØªÙ‡ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© ÙˆØ§Ø¹ØªØ¨Ø§Ø±Ø§ØªÙ‡ Ø§Ù„Ø£Ø®Ù„Ø§Ù‚ÙŠØ©ØŒ ÙŠØ±Ø¬Ù‰ Ø¥Ø¶Ø§ÙØ© Ø¨Ø·Ø§Ù‚Ø© Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ù…Ø³ØªÙˆØ¯Ø¹Ùƒ. ÙŠØªÙ… ØªØ¹Ø±ÙŠÙ Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ù…Ù„Ù `README.md`. ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØ© Ø¨Ø·Ø§Ù‚Ø© Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù† Ø·Ø±ÙŠÙ‚:\n+\n+* Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù `README.md` ÙˆØªØ­Ù…ÙŠÙ„Ù‡ ÙŠØ¯ÙˆÙŠÙ‹Ø§.\n+* Ø§Ù†Ù‚Ø± ÙÙˆÙ‚ Ø§Ù„Ø²Ø± **Edit model card** ÙÙŠ Ù…Ø³ØªÙˆØ¯Ø¹ Ù†Ù…ÙˆØ°Ø¬Ùƒ.\n+\n+Ø§Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø¨Ø·Ø§Ù‚Ø© [DistilBert](https://huggingface.co/distilbert/distilbert-base-uncased) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø«Ø§Ù„ Ø¬ÙŠØ¯ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø£Ù† ØªØªØ¶Ù…Ù†Ù‡Ø§ Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠÙ‡Ø§ ÙÙŠ Ù…Ù„Ù `README.md` Ù…Ø«Ù„ Ø§Ù„Ø¨ØµÙ…Ø© Ø§Ù„ÙƒØ±Ø¨ÙˆÙ†ÙŠØ© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ùˆ Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ø£Ø¯Ø§Ø©ØŒ Ø±Ø§Ø¬Ø¹ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ [Ù‡Ù†Ø§](https://huggingface.co/docs/hub/models-cards).\n\\ No newline at end of file"
        },
        {
            "sha": "f5f050ade427ca4355b79e51eae403c5c9ec1a96",
            "filename": "docs/source/ar/peft.md",
            "status": "added",
            "additions": 250,
            "deletions": 0,
            "changes": 250,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fpeft.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fpeft.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fpeft.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,250 @@\n+# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ğŸ¤— PEFT\n+\n+[[open-in-colab]]\n+\n+ØªÙ‚Ù†ÙŠØ© \"Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ø°Ùˆ Ø§Ù„ÙƒÙØ§Ø¡Ø© Ø§Ù„Ø¨Ø§Ø±Ø§Ù…ØªÙŠØ±ÙŠØ©\" (PEFT)](https://huggingface.co/blog/peft) ØªÙ‚ÙˆÙ… Ø¨ØªØ¬Ù…ÙŠØ¯ Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¶Ø¨Ø· Ø§Ù„Ø¯Ù‚ÙŠÙ‚ ÙˆØªØ¶ÙŠÙ Ø¹Ø¯Ø¯ ØµØºÙŠØ± Ù…Ù† Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨ (Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª) ÙÙˆÙ‚Ù‡. ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„Ø§Øª Ù„ØªØ¹Ù„Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ù‡Ø§Ù…. ÙˆÙ‚Ø¯ Ø«Ø¨Øª Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ù†Ù‡Ø¬ ÙØ¹Ø§Ù„ Ù„Ù„ØºØ§ÙŠØ© Ù…Ù† Ø­ÙŠØ« Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù…Ø¹ Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒÙ…Ø¨ÙŠÙˆØªØ± Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†ØªØ§Ø¬ Ù†ØªØ§Ø¦Ø¬ Ù‚Ù…Ù…Ø§Ø«Ù„Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¶Ø¨ÙˆØ· Ø¯Ù‚ÙŠÙ‚Ù‹Ø§ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„.\n+\n+Ø¹Ø§Ø¯Ø© Ù…Ø§ ØªÙƒÙˆÙ† Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª Ø§Ù„Ù…Ø¯Ø±Ø¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PEFT Ø£ØµØºØ± Ø¨Ù…Ù‚Ø¯Ø§Ø± ÙƒØ¨ÙŠØ± Ù…Ù† Ø­ÙŠØ« Ø§Ù„Ø­Ø¬Ù… Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„ØŒ Ù…Ù…Ø§ ÙŠØ¬Ø¹Ù„ Ù…Ù† Ø§Ù„Ø³Ù‡Ù„ Ù…Ø´Ø§Ø±ÙƒØªÙ‡Ø§ ÙˆØªØ®Ø²ÙŠÙ†Ù‡Ø§ ÙˆØªØ­Ù…ÙŠÙ„Ù‡Ø§.\n+\n+<div class=\"flex flex-col justify-center\">\n+  <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/PEFT-hub-screenshot.png\"/>\n+  <figcaption class=\"text-center\">ØªØ¨Ù„Øº Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ø­ÙˆÙ„ Ù„Ø·Ø±Ø§Ø² OPTForCausalLM Ø§Ù„Ù…Ø®Ø²Ù† Ø¹Ù„Ù‰ Hub Ø­ÙˆØ§Ù„ÙŠ 6 Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø­Ø¬Ù… Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ ÙˆØ§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† Ø­ÙˆØ§Ù„ÙŠ 700 Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª.</figcaption>\n+</div>\n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª Ù…Ù‡ØªÙ…Ù‹Ø§ Ø¨Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ø¹Ù† Ù…ÙƒØªØ¨Ø© ğŸ¤— PEFTØŒ ÙØ±Ø§Ø¬Ø¹ [Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚](https://huggingface.co/docs/peft/index).\n+\n+## Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯\n+\n+Ø§Ø¨Ø¯Ø£ Ø¨ØªØ«Ø¨ÙŠØª ğŸ¤— PEFT:\n+\n+```bash\n+pip install peft\n+```\n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ØªÙ…Ø§Ù…Ù‹Ø§ØŒ ÙÙ‚Ø¯ ØªÙƒÙˆÙ† Ù…Ù‡ØªÙ…Ù‹Ø§ Ø¨ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø© Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø±:\n+\n+```bash\n+pip install git+https://github.com/huggingface/peft.git\n+```\n+\n+## Ù†Ù…Ø§Ø°Ø¬ PEFT Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©\n+\n+ÙŠØ¯Ø¹Ù… ğŸ¤— Transformers Ø¨Ø´ÙƒÙ„Ù Ø£ØµÙ„ÙŠ Ø¨Ø¹Ø¶ Ø·Ø±Ù‚ PEFTØŒ Ù…Ù…Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ø­ÙˆÙ„ Ø§Ù„Ù…Ø®Ø²Ù†Ø© Ù…Ø­Ù„ÙŠÙ‹Ø§ Ø£Ùˆ Ø¹Ù„Ù‰ Hub ÙˆØªØ´ØºÙŠÙ„Ù‡Ø§ Ø£Ùˆ ØªØ¯Ø±ÙŠØ¨Ù‡Ø§ Ø¨Ø¨Ø¶Ø¹ Ø³Ø·ÙˆØ± Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©. Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© Ù‡ÙŠ:\n+\n+- [Ù…Ø­ÙˆÙ„Ø§Øª Ø§Ù„Ø±ØªØ¨Ø© Ø§Ù„Ù…Ù†Ø®ÙØ¶Ø©](https://huggingface.co/docs/peft/conceptual_guides/lora)\n+- [IA3](https://huggingface.co/docs/peft/conceptual_guides/ia3)\n+- [AdaLoRA](https://arxiv.org/abs/2303.10512)\n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±Ù‚ PEFT Ø§Ù„Ø£Ø®Ø±Ù‰ØŒ Ù…Ø«Ù„ ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø­Ø« Ø£Ùˆ Ø¶Ø¨Ø· Ø§Ù„Ù…Ø­Ø«ØŒ Ø£Ùˆ Ø­ÙˆÙ„ Ù…ÙƒØªØ¨Ø© ğŸ¤— PEFT Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø±Ø¬ÙˆØ¹ Ø¥Ù„Ù‰ [Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚](https://huggingface.co/docs/peft/index).\n+\n+## ØªØ­Ù…ÙŠÙ„ Ù…Ø­ÙˆÙ„ PEFT\n+\n+Ù„ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­ÙˆÙ„ PEFT ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù…Ù† ğŸ¤— TransformersØŒ ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù…Ø³ØªÙˆØ¯Ø¹ Hub Ø£Ùˆ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­Ù„ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ù„Ù `adapter_config.json` ÙˆØ£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„ØŒ ÙƒÙ…Ø§ Ù‡Ùˆ Ù…ÙˆØ¶Ø­ ÙÙŠ ØµÙˆØ±Ø© Ø§Ù„Ù…Ø«Ø§Ù„ Ø£Ø¹Ù„Ø§Ù‡. Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­ÙˆÙ‘Ù„ PEFT Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙØ¦Ø© `AutoModelFor`. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ù„ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­ÙˆÙ„ PEFT Ù„Ù„Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºÙˆÙŠØ© Ø§Ù„Ø³Ø¨Ø¨ÙŠØ©:\n+\n+1. Ø­Ø¯Ø¯ Ù…Ø¹Ø±Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬  Ù„PEFT\n+2. Ù…Ø±Ø±Ù‡ Ø¥Ù„Ù‰ ÙØ¦Ø© [`AutoModelForCausalLM`]\n+\n+```py\n+from transformers import AutoModelForCausalLM, AutoTokenizer\n+\n+peft_model_id = \"ybelkada/opt-350m-lora\"\n+model = AutoModelForCausalLM.from_pretrained(peft_model_id)\n+```\n+\n+<Tip>\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ Ù…Ø­ÙˆÙ„ PEFT Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙØ¦Ø© `AutoModelFor` Ø£Ùˆ ÙØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù…Ø«Ù„ `OPTForCausalLM` Ø£Ùˆ `LlamaForCausalLM`.\n+\n+</Tip>\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ØªØ­Ù…ÙŠÙ„ Ù…Ø­ÙˆÙ„ PEFT Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø·Ø±ÙŠÙ‚Ø© `load_adapter`:\n+\n+```py\n+from transformers import AutoModelForCausalLM, AutoTokenizer\n+\n+model_id = \"facebook/opt-350m\"\n+peft_model_id = \"ybelkada/opt-350m-lora\"\n+\n+model = AutoModelForCausalLM.from_pretrained(model_id)\n+model.load_adapter(peft_model_id)\n+```\n+\n+Ø±Ø§Ø¬Ø¹ Ù‚Ø³Ù… [ÙˆØ«Ø§Ø¦Ù‚ API](#transformers.integrations.PeftAdapterMixin) Ø£Ø¯Ù†Ø§Ù‡ Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„.\n+\n+## Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙÙŠ 8 Ø¨Øª Ø£Ùˆ 4 Ø¨Øª\n+\n+Ø±Ø§Ø¬Ø¹ Ù‚Ø³Ù… [ÙˆØ«Ø§Ø¦Ù‚ API](#transformers.integrations.PeftAdapterMixin) Ø£Ø¯Ù†Ø§Ù‡ Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„.\n+\n+## Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙÙŠ 8 Ø¨Øª Ø£Ùˆ 4 Ø¨Øª\n+\n+ÙŠØ¯Ø¹Ù… ØªÙƒØ§Ù…Ù„ `bitsandbytes` Ø£Ù†ÙˆØ§Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ù‚Ø© 8 Ø¨Øª Ùˆ4 Ø¨ØªØŒ ÙˆØ§Ù„ØªÙŠ ØªÙƒÙˆÙ† Ù…ÙÙŠØ¯Ø© Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ù„Ø£Ù†Ù‡Ø§ ØªÙˆÙØ±  Ù…Ø³Ø§Ø­Ø© ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Ø±Ø§Ø¬Ø¹ Ø¯Ù„ÙŠÙ„ ØªÙƒØ§Ù…Ù„ `bitsandbytes` [guide](./quantization#bitsandbytes-integration) Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯). Ø£Ø¶Ù Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª`load_in_8bit` Ø£Ùˆ `load_in_4bit` Ø¥Ù„Ù‰ [`~PreTrainedModel.from_pretrained`] ÙˆÙ‚Ù… Ø¨ØªØ¹ÙŠÙŠÙ† `device_map=\"auto\"` Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø´ÙƒÙ„ ÙØ¹Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ù„Ø¯ÙŠÙƒ:\n+\n+```py\n+from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n+\n+peft_model_id = \"ybelkada/opt-350m-lora\"\n+model = AutoModelForCausalLM.from_pretrained(peft_model_id, quantization_config=BitsAndBytesConfig(load_in_8bit=True))\n+```\n+\n+## Ø¥Ø¶Ø§ÙØ© Ù…Ø­ÙˆÙ„ Ø¬Ø¯ÙŠØ¯\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© [`~peft.PeftModel.add_adapter`] Ù„Ø¥Ø¶Ø§ÙØ© Ù…Ø­ÙˆÙ‘Ù„ Ø¬Ø¯ÙŠØ¯ Ø¥Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ ÙŠØ­ØªÙˆÙŠ Ø¨Ø§Ù„ÙØ¹Ù„ Ø¹Ù„Ù‰ Ù…Ø­ÙˆÙ‘Ù„ Ø¢Ø®Ø± Ø·Ø§Ù„Ù…Ø§ Ø£Ù† Ø§Ù„Ù…Ø­ÙˆÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯  Ù…Ø·Ø§Ø¨Ù‚Ù‹Ø§ Ù„Ù„Ù†ÙˆØ¹ Ø§Ù„Ø­Ø§Ù„ÙŠ. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒ Ù…Ø­ÙˆÙ„ LoRA Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø±ØªØ¨Ø· Ø¨Ù†Ù…ÙˆØ°Ø¬:\n+\n+```py\n+from transformers import AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer\n+from peft import LoraConfig\n+\n+model_id = \"facebook/opt-350m\"\n+model = AutoModelForCausalLM.from_pretrained(model_id)\n+\n+lora_config = LoraConfig(\n+    target_modules=[\"q_proj\", \"k_proj\"],\n+    init_lora_weights=False\n+)\n+\n+model.add_adapter(lora_config, adapter_name=\"adapter_1\")\n+```\n+\n+Ù„Ø¥Ø¶Ø§ÙØ© Ù…Ø­ÙˆÙ„ Ø¬Ø¯ÙŠØ¯:\n+\n+```py\n+# Ù‚Ù… Ø¨ØªØ¹Ù„ÙŠÙ‚ Ù…Ø­ÙˆÙ„ Ø¬Ø¯ÙŠØ¯ Ø¨Ù†ÙØ³ Ø§Ù„ØªÙƒÙˆÙŠÙ†\n+model.add_adapter(lora_config, adapter_name=\"adapter_2\")\n+```\n+\n+Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… [`~peft.PeftModel.set_adapter`] Ù„ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…Ø­ÙˆÙ„ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡:\n+\n+```py\n+# Ø§Ø³ØªØ®Ø¯Ù… adapter_1\n+model.set_adapter(\"adapter_1\")\n+output = model.generate(**inputs)\n+print(tokenizer.decode(output_disabled[0], skip_special_tokens=True))\n+\n+# Ø§Ø³ØªØ®Ø¯Ù… adapter_2\n+model.set_adapter(\"adapter_2\")\n+output_enabled = model.generate(**inputs)\n+print(tokenizer.decode(output_enabled[0], skip_special_tokens=True))\n+```\n+\n+## ØªÙ…ÙƒÙŠÙ† ÙˆØªØ¹Ø·ÙŠÙ„ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª\n+\n+Ø¨Ù…Ø¬Ø±Ø¯ Ø¥Ø¶Ø§ÙØ© Ù…Ø­ÙˆÙ„ Ø¥Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ…ÙƒÙŠÙ† Ø£Ùˆ ØªØ¹Ø·ÙŠÙ„ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø­ÙˆÙ„. Ù„ØªÙ…ÙƒÙŠÙ† ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø­ÙˆÙ„:\n+\n+```py\n+from transformers import AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer\n+from peft import PeftConfig\n+\n+model_id = \"facebook/opt-350m\"\n+adapter_model_id = \"ybelkada/opt-350m-lora\"\n+tokenizer = AutoTokenizer.from_pretrained(model_id)\n+text = \"Hello\"\n+inputs = tokenizer(text, return_tensors=\"pt\")\n+\n+model = AutoModelForCausalLM.from_pretrained(model_id)\n+peft_config = PeftConfig.from_pretrained(adapter_model_id)\n+\n+# Ù„Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„Ù‡ Ø¨Ø£ÙˆØ²Ø§Ù† Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©\n+peft_config.init_lora_weights = False\n+\n+model.add_adapter(peft_config)\n+model.enable_adapters()\n+output = model.generate(**inputs)\n+```\n+\n+Ù„Ø¥ÙŠÙ‚Ø§Ù ØªØ´ØºÙŠÙ„ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø­ÙˆÙ„:\n+\n+```py\n+model.disable_adapters()\n+output = model.generate(**inputs)\n+```\n+\n+## ØªØ¯Ø±ÙŠØ¨ Ù…Ø­ÙˆÙ„ PEFT\n+\n+ÙŠØ¯Ø¹Ù… Ù…Ø­ÙˆÙ„ PEFT ÙØ¦Ø© [`Trainer`] Ø¨Ø­ÙŠØ« ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¯Ø±ÙŠØ¨ Ù…Ø­ÙˆÙ„ Ù„Ø­Ø§Ù„ØªÙƒ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©. ÙÙ‡Ùˆ ÙŠØªØ·Ù„Ø¨ ÙÙ‚Ø· Ø¥Ø¶Ø§ÙØ© Ø¨Ø¶Ø¹ Ø³Ø·ÙˆØ± Ø£Ø®Ø±Ù‰ Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ø­ÙˆÙ„ LoRA:\n+\n+<Tip>\n+\n+Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…Ø¹ØªØ§Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ø¯Ù‚ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`Trainer`ØŒ ÙØ±Ø§Ø¬Ø¹ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ](training) Ù„Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§.\n+\n+</Tip>\n+\n+1. Ø­Ø¯Ø¯ ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù…Ø­ÙˆÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø© ÙˆØ§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© (Ø±Ø§Ø¬Ø¹ [`~peft.LoraConfig`] Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ ÙˆØ¸ÙŠÙØ© Ù‡Ø°Ù‡  Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª).\n+\n+```py\n+from peft import LoraConfig\n+\n+peft_config = LoraConfig(\n+    lora_alpha=16,\n+    lora_dropout=0.1,\n+    r=64,\n+    bias=\"none\",\n+    task_type=\"CAUSAL_LM\"ØŒ\n+)\n+```\n+\n+2. Ø£Ø¶Ù Ø§Ù„Ù…Ø­ÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n+\n+```py\n+model.add_adapter(peft_config)\n+```\n+\n+3. Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ [`Trainer`]!\n+\n+```py\n+trainer = Trainer(model=model, ...)\n+trainer.train()\n+```\n+\n+Ù„Ø­ÙØ¸ Ù…Ø­ÙˆÙ„ Ø§Ù„Ù…Ø¯Ø±Ø¨ ÙˆØªØ­Ù…ÙŠÙ„Ù‡ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰:\n+\n+```py\n+model.save_pretrained(save_dir)\n+model = AutoModelForCausalLM.from_pretrained(save_dir)\n+```\n+\n+## Ø¥Ø¶Ø§ÙØ© Ø·Ø¨Ù‚Ø§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¥Ø¶Ø§ÙÙŠØ© Ø¥Ù„Ù‰ Ù…Ø­ÙˆÙ„ PEFT\n+\n+```py\n+model.save_pretrained(save_dir)\n+model = AutoModelForCausalLM.from_pretrained(save_dir)\n+```\n+\n+## Ø¥Ø¶Ø§ÙØ© Ø·Ø¨Ù‚Ø§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¥Ø¶Ø§ÙÙŠØ© Ø¥Ù„Ù‰ Ù…Ø­ÙˆÙ„ PEFT\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ø¬Ø±Ø§Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø¯Ù‚ÙŠÙ‚ Ù„Ù…Ø­ÙˆÙ‘Ù„Ø§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¥Ø¶Ø§ÙÙŠØ© ÙÙˆÙ‚ Ù†Ù…ÙˆØ°Ø¬ ÙŠØ­ØªÙˆÙŠ Ø¨Ø§Ù„ÙØ¹Ù„ Ø¹Ù„Ù‰ Ù…Ø­ÙˆÙ‘Ù„Ø§Øª Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªÙ…Ø±ÙŠØ± Ù…Ø¹Ù„Ù… `modules_to_save` ÙÙŠ ØªÙƒÙˆÙŠÙ† PEFT Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ø£ÙŠØ¶Ù‹Ø§ Ø¶Ø¨Ø· Ø¯Ù‚ÙŠÙ‚ Ù„Ø±Ø£Ø³ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ`lm_head` ÙÙˆÙ‚ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù…Ø­ÙˆÙ‘Ù„ LoRA:\n+\n+```py\n+from transformers import AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer\n+from peft import LoraConfig\n+\n+model_id = \"facebook/opt-350m\"\n+model = AutoModelForCausalLM.from_pretrained(model_id)\n+\n+lora_config = LoraConfig(\n+    target_modules=[\"q_proj\", \"k_proj\"],\n+    modules_to_save=[\"lm_head\"]ØŒ\n+)\n+\n+model.add_adapter(lora_config)\n+```\n+\n+## ÙˆØ«Ø§Ø¦Ù‚ API\n+\n+[[autodoc]] integrations.PeftAdapterMixin\n+    - load_adapter\n+    - add_adapter\n+    - set_adapter\n+    - disable_adapters\n+    - enable_adapters\n+    - active_adapters\n+    - get_adapter_state_dict\n+\n+\n+\n+\n+<!--\n+TODO: (@younesbelkada @stevhliu)\n+-   Link to PEFT docs for further details\n+-   Trainer\n+-   8-bit / 4-bit examples ?\n+-->\n\\ No newline at end of file"
        },
        {
            "sha": "2dd713a6533f6e3831bdde6116f16bbdcf573f57",
            "filename": "docs/source/ar/pipeline_tutorial.md",
            "status": "added",
            "additions": 315,
            "deletions": 0,
            "changes": 315,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fpipeline_tutorial.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fpipeline_tutorial.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fpipeline_tutorial.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,315 @@\n+# Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„\n+\n+ÙŠØ¬Ø¹Ù„ [`pipeline`] Ù…Ù† Ø§Ù„Ø³Ù‡Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† [Hub](https://huggingface.co/models) Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù„Ø£ÙŠ Ù…Ù‡Ø§Ù… Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù„ØºØ© Ø£Ùˆ Ø§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ÙŠØ© Ø£Ùˆ Ø§Ù„ÙƒÙ„Ø§Ù… Ø£Ùˆ Ø§Ù„Ù…Ù‡Ø§Ù… Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„ÙˆØ³Ø§Ø¦Ø·. Ø­ØªÙ‰ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù„Ø¯ÙŠÙƒ Ø®Ø¨Ø±Ø© ÙÙŠ Ø·Ø±ÙŠÙ‚Ø© Ù…Ø¹ÙŠÙ†Ø© Ø£Ùˆ Ù„Ù… ØªÙƒÙ† Ø¹Ù„Ù‰ Ø¯Ø±Ø§ÙŠØ© Ø¨Ø§Ù„Ø±Ù…Ø² Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙˆØ±Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø¹ Ø°Ù„Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`pipeline`]! Ø³ÙˆÙ ÙŠÙØ¹Ù„Ù…Ùƒ Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ù…Ø§ ÙŠÙ„ÙŠ:\n+\n+* Ø§Ø³ØªØ®Ø¯Ø§Ù… [`pipeline`] Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„.\n+* Ø§Ø³ØªØ®Ø¯Ù… Ù…ÙØ¬Ø²Ù‘Ø¦ Ø£Ùˆ Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ Ù…Ø­Ø¯Ø¯Ù‹Ø§.\n+* Ø§Ø³ØªØ®Ø¯Ù… [`pipeline`] Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØµÙˆØªÙŠØ© ÙˆØ§Ù„Ø¨ØµØ±ÙŠØ© ÙˆØ§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„ÙˆØ³Ø§Ø¦Ø·.\n+\n+<Tip>\n+\n+Ø§Ø·Ù„Ø¹ Ø¹Ù„Ù‰ ÙˆØ«Ø§Ø¦Ù‚ [`pipeline`] Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ÙƒØ§Ù…Ù„Ø© Ø¨Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© ÙˆØ§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©.\n+\n+</Tip>\n+\n+## Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨\n+\n+Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø£Ù† Ù„ÙƒÙ„ Ù…Ù‡Ù…Ø© Ø£Ù†Ø¨ÙˆØ¨ [`pipeline`] Ø®Ø§Øµ Ø¨Ù‡Ø§ØŒ Ø¥Ù„Ø§ Ø£Ù†Ù‡ Ù…Ù† Ø§Ù„Ø£Ø¨Ø³Ø· Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ¬Ø±ÙŠØ¯ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø¹Ø§Ù… [`pipeline`] Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ù‡Ù…Ø©. ÙŠÙ‚ÙˆÙ… [`pipeline`] ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§ÙØªØ±Ø§Ø¶ÙŠ ÙˆÙØ¦Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ù‚Ø§Ø¯Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù„Ù…Ù‡Ù…ØªÙƒ. Ø¯Ø¹Ù†Ø§ Ù†Ø£Ø®Ø° Ù…Ø«Ø§Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… [`pipeline`] Ù„Ù„ØªØ¹Ø±Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… (ASR)ØŒ Ø£Ùˆ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¥Ù„Ù‰ Ù†Øµ.\n+\n+1. Ø§Ø¨Ø¯Ø£ Ø¨Ø¥Ù†Ø´Ø§Ø¡ [`pipeline`] ÙˆØ­Ø¯Ø¯ Ù…Ù‡Ù…Ø© Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„:\n+\n+```py\n+>>> from transformers import pipeline\n+\n+>>> transcriber = pipeline(task=\"automatic-speech-recognition\")\n+```\n+\n+2. Ù…Ø±Ø± Ø¥Ø¯Ø®Ø§Ù„Ùƒ Ø¥Ù„Ù‰ [`pipeline`]. ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…ØŒ ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ Ù…Ù„Ù Ø¥Ø¯Ø®Ø§Ù„ ØµÙˆØªÙŠ:\n+\n+```py\n+>>> transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n+{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}\n+```\n+\n+Ù„Ù… ØªØ­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯Ù‡Ø§ØŸ ØªØ­Ù‚Ù‚ Ù…Ù† Ø¨Ø¹Ø¶ [Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ø£ÙƒØ«Ø± ØªÙ†Ø²ÙŠÙ„Ù‹Ø§](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=trending) \n+Ø¹Ù„Ù‰ Hub Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¨Ø¥Ù…ÙƒØ§Ù†Ùƒ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ø³Ø®Ø© Ù…Ù†Ù‚Ø­Ø© Ø£ÙØ¶Ù„.\n+\n+Ù„Ù†ÙØ¬Ø±Ø¨ Ù†Ù…ÙˆØ°Ø¬ [Whisper large-v2](https://huggingface.co/openai/whisper-large) Ù…Ù† OpenAI. ØªÙ… Ø¥ØµØ¯Ø§Ø± Whisper Ø¨Ø¹Ø¯ Ø¹Ø§Ù…ÙŠÙ† Ù…Ù† Ø¥ØµØ¯Ø§Ø± Wav2Vec2ØŒ ÙˆØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡ Ø¹Ù„Ù‰ Ù…Ø§ ÙŠÙ‚Ø±Ø¨ Ù…Ù† 10 Ø£Ø¶Ø¹Ø§Ù ÙƒÙ…ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. ÙˆØ¨Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ©ØŒ ÙØ¥Ù†Ù‡ ÙŠØªÙÙˆÙ‚ Ø¹Ù„Ù‰ Wav2Vec2 ÙÙŠ Ù…Ø¹Ø¸Ù… Ù…Ø¹Ø¸Ù… Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³. ÙƒÙ…Ø§ Ø£Ù†Ù‡ ÙŠÙ…ØªÙ„Ùƒ Ù…ÙŠØ²Ø© Ø¥Ø¶Ø§ÙÙŠØ© ÙˆÙ‡ÙŠ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… ÙˆØ­Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±ÙØŒ ÙˆØ§Ù„ØªÙŠ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ù‚ÙŠÙ‚Ù‡Ø§ Ù…Ø¹ Wav2Vec2.\n+\n+Ø¯Ø¹ÙˆÙ†Ø§ Ù†Ø¬Ø±Ø¨Ù‡Ø§ Ù‡Ù†Ø§ Ù„Ù†Ø±Ù‰ ÙƒÙŠÙ ØªØ¤Ø¯ÙŠ:\n+\n+```py\n+>>> transcriber = pipeline(model=\"openai/whisper-large-v2\")\n+>>> transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n+{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}\n+```\n+\n+Ø§Ù„Ø¢Ù† ØªØ¨Ø¯Ùˆ Ù‡Ø°Ù‡ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø£ÙƒØ«Ø± Ø¯Ù‚Ø©! Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¹Ù…ÙŠÙ‚Ø© Ø­ÙˆÙ„ Wav2Vec2 Ù…Ù‚Ø§Ø¨Ù„ WhisperØŒ Ø±Ø§Ø¬Ø¹ [Ø¯ÙˆØ±Ø© Audio Transformers](https://huggingface.co/learn/audio-course/chapter5/asr_models).\n+Ù†Ø´Ø¬Ø¹Ùƒ Ø¨Ø´Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Hub Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù„ØºØ§Øª Ù…Ø®ØªÙ„ÙØ©ØŒ ÙˆÙ†Ù…Ø§Ø°Ø¬ Ù…ØªØ®ØµØµØ© ÙÙŠ Ù…Ø¬Ø§Ù„ÙƒØŒ ÙˆØ£ÙƒØ«Ø± Ù…Ù† Ø°Ù„Ùƒ.\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ…Ù‚Ø§Ø±Ù†ØªÙ‡Ø§ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ù…ØªØµÙØ­Ùƒ Ø¹Ù„Ù‰ Hub Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠÙ†Ø§Ø³Ø¨Ù‡Ø§\n+Ø£Ùˆ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„ Ù…Ù† ØºÙŠØ±Ù‡Ø§.\n+ÙˆØ¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ Ù„Ø­Ø§Ù„ØªÙƒ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…ØŒ ÙÙŠÙ…ÙƒÙ†Ùƒ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø§Ù„Ø¨Ø¯Ø¡ ÙÙŠ [Ø§Ù„ØªØ¯Ø±ÙŠØ¨](training) Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ!\n+\n+Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒ Ø¹Ø¯Ø© Ù…Ø¯Ø®Ù„Ø§ØªØŒ ÙÙŠÙ…ÙƒÙ†Ùƒ ØªÙ…Ø±ÙŠØ± Ø¥Ø¯Ø®Ø§Ù„Ùƒ ÙƒÙ‚Ø§Ø¦Ù…Ø©:\n+\n+```py\n+transcriber(\n+    [\n+        \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\",\n+        \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\",\n+    ]\n+)\n+```\n+\n+ØªØ¹Ø¯ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù…Ø«Ø§Ù„ÙŠØ© Ù„Ù„ØªØ¬Ø±ÙŠØ¨ Ù†Ø¸Ø±Ù‹Ø§ Ù„Ø£Ù† Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø¢Ø®Ø± Ø£Ù…Ø± Ø¨Ø³ÙŠØ· Ù„Ù„ØºØ§ÙŠØ©Ø› ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ Ù‡Ù†Ø§Ùƒ Ø¨Ø¹Ø¶ Ø§Ù„Ø·Ø±Ù‚ Ù„ØªØ­Ø³ÙŠÙ†Ù‡Ø§ Ù„Ø£Ø­Ù…Ø§Ù„ Ø¹Ù…Ù„ Ø£ÙƒØ¨Ø± Ù…Ù† Ø§Ù„ØªØ¬Ø±ÙŠØ¨. Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø£Ø¯Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ø§Ù„ØªÙŠ ØªØªØ¹Ù…Ù‚ ÙÙ‰ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø¹Ø¨Ø± Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ ÙÙŠ Ø®Ø§Ø¯Ù… ÙˆÙŠØ¨:\n+Ù…Ù† Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚:\n+* [Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª](#using-pipelines-on-a-dataset)\n+* [Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù„Ø®Ø§Ø¯Ù… ÙˆÙŠØ¨](./pipeline_webserver)\n+\n+## Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª\n+\n+ÙŠØ¯Ø¹Ù… [`pipeline`] Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„Ù…Ø§ØªØ› Ø¨Ø¹Ø¶Ù‡Ø§ Ø®Ø§Øµ Ø¨Ø§Ù„Ù…Ù‡Ù…Ø©ØŒ ÙˆØ§Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ø¢Ø®Ø± Ø¹Ø§Ù… Ù„Ø¬Ù…ÙŠØ¹ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨.\n+Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª ÙÙŠ Ø£ÙŠ Ù…ÙƒØ§Ù† ØªØ±ÙŠØ¯Ù‡:\n+\n+```py\n+transcriber = pipeline(model=\"openai/whisper-large-v2\", my_parameter=1)\n+\n+out = transcriber(...)  # Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ø§ `my_parameter=1`.\n+out = transcriber(..., my_parameter=2)  # Ø³ÙŠØªÙ… ØªØ¬Ø§ÙˆØ² Ù‡Ø°Ø§ ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… `my_parameter=2`.\n+out = transcriber(...)  # Ø³ÙŠØªÙ… Ø§Ù„Ø±Ø¬ÙˆØ¹ Ø¥Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… `my_parameter=1`.\n+```\n+\n+Ø¯Ø¹ÙˆÙ†Ø§ Ù†Ù„Ù‚ÙŠ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ 3 Ù…Ù‡Ù…Ø©:\n+\n+### Ø§Ù„Ø¬Ù‡Ø§Ø²\n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… `device=n`ØŒ ÙØ¥Ù† Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ ÙŠØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ø­Ø¯Ø¯.\n+Ø³ÙŠØ¹Ù…Ù„ Ù‡Ø°Ø§ Ø¨ØºØ¶ Ø§Ù„Ù†Ø¸Ø± Ø¹Ù…Ø§ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… PyTorch Ø£Ùˆ Tensorflow.\n+\n+```py\n+transcriber = pipeline(model=\"openai/whisper-large-v2\", device=0)\n+```\n+\n+Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙƒØ¨ÙŠØ±Ù‹Ø§ Ø¬Ø¯Ù‹Ø§ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU) ÙˆØ§Ø­Ø¯Ø©ØŒ ÙˆØ£Ù†Øª ØªØ³ØªØ®Ø¯Ù… PyTorchØŒ ÙÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹ÙŠÙŠÙ† `torch_dtype='float16'` Ù„ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¨Ø¯Ù‚Ø© FP16. Ø¹Ø§Ø¯Ø©Ù‹ Ù…Ø§ Ù„Ø§ ÙŠØªØ³Ø¨Ø¨ Ø°Ù„Ùƒ ÙÙŠ Ø­Ø¯ÙˆØ« Ø§Ù†Ø®ÙØ§Ø¶Ø§Øª ÙƒØ¨ÙŠØ±Ø© ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡ØŒ ÙˆÙ„ÙƒÙ† ØªØ£ÙƒØ¯ Ù…Ù† ØªÙ‚ÙŠÙŠÙ…Ù‡ Ø¹Ù„Ù‰ Ù†Ù…Ø§Ø°Ø¬Ùƒ!\n+\n+Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„ÙƒØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹ÙŠÙŠÙ† `device_map=\"auto\"` Ù„ØªØ­Ø¯ÙŠØ¯ ÙƒÙŠÙÙŠØ© ØªØ­Ù…ÙŠÙ„ Ù…Ø®Ø²Ù†Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªØ®Ø²ÙŠÙ†Ù‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§. ÙŠØªØ·Ù„Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù…Ù„ `device_map` Ù…ÙƒØªØ¨Ù‡ ğŸ¤— [Accelerate](https://huggingface.co/docs/accelerate):\n+\n+```bash\n+pip install --upgrade accelerate\n+```\n+\n+ØªÙ‚ÙˆÙ… Ø§Ù„Ø´ÙØ±Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø®Ø²Ù†Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªØ®Ø²ÙŠÙ†Ù‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¹Ø¨Ø± Ø§Ù„Ø£Ø¬Ù‡Ø²Ø©:\n+\n+```py\n+transcriber = pipeline(model=\"openai/whisper-large-v2\", device_map=\"auto\")\n+```\n+\n+Ù„Ø§Ø­Ø¸ Ø£Ù†Ù‡ Ø¥Ø°Ø§ ØªÙ… ØªÙ…Ø±ÙŠØ± `device_map=\"auto\"`ØŒ ÙÙ„Ø§ ØªÙˆØ¬Ø¯ Ø­Ø§Ø¬Ø© Ù„Ø¥Ø¶Ø§ÙØ© Ø­Ø¬Ø© `device=device` Ø¹Ù†Ø¯ Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø®Ø§Øµ Ø¨ÙƒØŒ ÙÙ‚Ø¯ ØªÙˆØ§Ø¬Ù‡ Ø¨Ø¹Ø¶ Ø§Ù„Ø³Ù„ÙˆÙƒÙŠØ§Øª ØºÙŠØ± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©!\n+\n+### Ø­Ø¬Ù… Ø§Ù„Ø¯ÙØ¹Ø©\n+\n+Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠØŒ Ù„Ù† ØªÙ‚ÙˆÙ… Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø¨ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù„Ø£Ø³Ø¨Ø§Ø¨ Ù…ÙØµÙ„Ø© [Ù‡Ù†Ø§](https://huggingface.co/docs/transformers/main_classes/pipelines#pipeline-batching). ÙˆØ§Ù„Ø³Ø¨Ø¨ Ù‡Ùˆ Ø£Ù† Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ù„ÙŠØ³Øª Ø£Ø³Ø±Ø¹ Ø¨Ø§Ù„Ø¶Ø±ÙˆØ±Ø©ØŒ ÙˆÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† Ø£Ø¨Ø·Ø£ ÙÙŠ Ø§Ù„ÙˆØ§Ù‚Ø¹ ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø­Ø§Ù„Ø§Øª.\n+\n+ÙˆÙ„ÙƒÙ† Ø¥Ø°Ø§ Ù†Ø¬Ø­Øª ÙÙŠ Ø­Ø§Ù„ØªÙƒ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…ØŒ ÙÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø§ ÙŠÙ„ÙŠ:\n+\n+```py\n+transcriber = pipeline(model=\"openai/whisper-large-v2\", device=0, batch_size=2)\n+audio_filenames = [f\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/{i}.flac\" for i in range(1, 5)]\n+texts = transcriber(audio_filenames)\n+```\n+\n+Ù‡Ø°Ø§ ÙŠØ´ØºÙ„ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØª Ø§Ù„Ø£Ø±Ø¨Ø¹Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©ØŒ ÙˆÙ„ÙƒÙ†Ù‡ Ø³ÙŠÙ…Ø±Ø±Ù‡Ø§ Ø¹Ù„Ù‰ Ø¯ÙØ¹ØªÙŠÙ†\n+Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø§Ù„Ø°ÙŠ ÙŠÙˆØ¬Ø¯ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU)ØŒ Ø­ÙŠØ« Ù…Ù† Ø§Ù„Ù…Ø±Ø¬Ø­ Ø£Ù† ØªØ³Ø§Ø¹Ø¯ Ø§Ù„ØªØ¬Ù…ÙŠØ¹) Ø¯ÙˆÙ† Ø§Ù„Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ Ø£ÙŠ Ø±Ù…Ø² Ø¥Ø¶Ø§ÙÙŠ Ù…Ù†Ùƒ. \n+ÙŠØ¬Ø¨ Ø£Ù† ØªØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ù…Ø¹ Ù…Ø§ ÙƒÙ†Øª Ø³ØªØ­ØµÙ„ Ø¹Ù„ÙŠÙ‡ Ø¯ÙˆÙ† Ø§Ù„ØªØ¬Ù…ÙŠØ¹. Ø§Ù„Ù…Ù‚ØµÙˆØ¯ Ù…Ù†Ù‡ ÙÙ‚Ø· ÙƒØ·Ø±ÙŠÙ‚Ø© Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø³Ø±Ø¹Ø© Ø£ÙƒØ¨Ø± Ù…Ù† Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨.\n+\n+ÙŠÙ…ÙƒÙ† Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø£ÙŠØ¶Ù‹Ø§ ØªØ®ÙÙŠÙ Ø¨Ø¹Ø¶ ØªØ¹Ù‚ÙŠØ¯Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ù„Ø£Ù†Ù‡ØŒ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ø¨Ø¹Ø¶ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ØŒ ÙŠØ¬Ø¨ ØªÙ‚Ø³ÙŠÙ… Ø¹Ù†ØµØ± ÙˆØ§Ø­Ø¯ (Ù…Ø«Ù„ Ù…Ù„Ù ØµÙˆØªÙŠ Ø·ÙˆÙŠÙ„) Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡ Ø¨ÙˆØ§Ø³Ø·Ø© Ù†Ù…ÙˆØ°Ø¬. ÙŠÙ‚ÙˆÙ… Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø¨Ø£Ø¯Ø§Ø¡ Ù‡Ø°Ù‡  Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙŠ ØªØ³Ù…Ù‰ ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ [*batch batching*](./main_classes/pipelines#pipeline-chunk-batching) Ù†ÙŠØ§Ø¨Ø© Ø¹Ù†Ùƒ.\n+\n+### Ù…Ø¹Ù„Ù…Ø§Øª Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ù‡Ù…Ø©\n+\n+ØªÙˆÙØ± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‡Ø§Ù… Ù…Ø¹Ù„Ù…Ø§Øª Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ù‡Ù…Ø© ØªØªÙŠØ­ Ø§Ù„Ù…Ø±ÙˆÙ†Ø© ÙˆØ§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø£Ø¯Ø§Ø¡ Ø¹Ù…Ù„Ùƒ.\n+Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ØªØ­ØªÙˆÙŠ Ø·Ø±ÙŠÙ‚Ø© [`transformers.AutomaticSpeechRecognitionPipeline.__call__`] Ø¹Ù„Ù‰ Ù…Ø¹Ù„Ù…Ø© `return_timestamps` Ø§Ù„ØªÙŠ ØªØ¨Ø¯Ùˆ ÙˆØ§Ø¹Ø¯Ø© Ù„ØªØ±Ø¬Ù…Ø© Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ:\n+```py\n+>>> transcriber = pipeline(model=\"openai/whisper-large-v2\", return_timestamps=True)\n+>>> transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n+{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.', 'chunks': [{'timestamp': (0.0, 11.88), 'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its'}, {'timestamp': (11.88, 12.38), 'text': ' creed.'}]}\n+```\n+\n+ÙƒÙ…Ø§ ØªØ±ÙˆÙ†ØŒ Ø§Ø³ØªÙ†ØªØ¬ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Øµ.ÙˆÙƒØ°Ù„Ùƒ Ø­Ø¯Ø¯ **ÙˆÙ‚Øª** Ù†Ø·Ù‚ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©.\n+\n+ØªØªÙˆÙØ± Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ù„ÙƒÙ„ Ù…Ù‡Ù…Ø©ØŒ Ù„Ø°Ø§ ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø±Ø¬Ø¹ API Ù„ÙƒÙ„ Ù…Ù‡Ù…Ø© Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø§ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„Ù‡!\n+Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ØªØ­ØªÙˆÙŠ [`~transformers.AutomaticSpeechRecognitionPipeline`] Ø¹Ù„Ù‰ Ù…Ø¹Ù„Ù…Ø© `chunk_length_s` Ù…ÙÙŠØ¯Ø© \n+Ù„Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØª Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ù‹Ø§ (Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø£ÙÙ„Ø§Ù… Ø£Ùˆ Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„ØªÙŠ ØªØ³ØªØºØ±Ù‚ Ø³Ø§Ø¹Ø©) ÙˆØ§Ù„ØªÙŠ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡Ø§ Ø¨Ù…ÙØ±Ø¯Ù‡:\n+\n+```python\n+>>> transcriber = pipeline(model=\"openai/whisper-large-v2\", chunk_length_s=30)\n+>>> transcriber(\"https://huggingface.co/datasets/reach-vb/random-audios/resolve/main/ted_60.wav\")\n+{'text': \" So in college, I was a government major, which means I had to write a lot of papers. Now, when a normal student writes a paper, they might spread the work out a little like this. So, you know. You get started maybe a little slowly, but you get enough done in the first week that with some heavier days later on, everything gets done and things stay civil. And I would want to do that like that. That would be the plan. I would have it all ready to go, but then actually the paper would come along, and then I would kind of do this. And that would happen every single paper. But then came my 90-page senior thesis, a paper you're supposed to spend a year on. I knew for a paper like that, my normal workflow was not an option, it was way too big a project. So I planned things out and I decided I kind of had to go something like this. This is how the year would go. So I'd start off light and I'd bump it up\"}\n+```\n+\n+Ø¥Ø°Ø§ Ù„Ù… ØªØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ù„Ù…Ø© Ù‚Ø¯ ØªØ³Ø§Ø¹Ø¯Ùƒ Ø­Ù‚Ù‹Ø§ØŒ ÙÙ„Ø§ ØªØªØ±Ø¯Ø¯ ÙÙŠ [Ø·Ù„Ø¨Ù‡Ø§](https://github.com/huggingface/transformers/issues/new?assignees=&labels=feature&template=feature-request.yml)!\n+\n+\n+## Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª\n+\n+ÙŠÙ…ÙƒÙ† Ø£ÙŠØ¶Ù‹Ø§ ØªØ´ØºÙŠÙ„ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù„Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ¨ÙŠØ±Ø©. Ø£Ø³Ù‡Ù„ Ø·Ø±ÙŠÙ‚Ø© Ù†ÙˆØµÙŠ Ø¨Ù‡Ø§ Ù„Ù„Ù‚ÙŠØ§Ù… Ø¨Ø°Ù„Ùƒ Ù‡ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ØªÙƒØ±Ø± (iterator).:\n+\n+```py\n+def data():\n+    for i in range(1000):\n+        yield f\"My example {i}\"\n+\n+\n+pipe = pipeline(model=\"openai-community/gpt2\", device=0)\n+generated_characters = 0\n+for out in pipe(data()):\n+    generated_characters += len(out[0][\"generated_text\"])\n+```\n+\n+ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù…Ø¤Ø´Ø± `data()` Ø¨Ø¥Ø±Ø¬Ø§Ø¹ ÙƒÙ„ Ù†ØªÙŠØ¬Ø©ØŒ ÙˆÙŠØªØ¹Ø±Ù Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§\n+Ø§Ù„Ù…Ø¯Ø®Ù„ Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ­Ø¯ÙŠØ¯ ÙˆÙŠØ¨Ø¯Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø«Ù†Ø§Ø¡\n+ÙŠØ³ØªÙ…Ø± ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU) (ÙŠØ³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) ØªØ­Øª Ø§Ù„ØºØ·Ø§Ø¡).\n+Ù‡Ø°Ø§ Ø£Ù…Ø± Ù…Ù‡Ù… Ù„Ø£Ù†Ùƒ Ù„Ø§ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ®ØµÙŠØµ Ø°Ø§ÙƒØ±Ø© Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§\n+ÙˆÙŠÙ…ÙƒÙ†Ùƒ ØªØºØ°ÙŠØ© ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU) Ø¨Ø£Ø³Ø±Ø¹ Ù…Ø§ ÙŠÙ…ÙƒÙ†.\n+\n+Ù†Ø¸Ø±Ù‹Ø§ Ù„Ø£Ù† Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ù‚Ø¯ ØªØ³Ø±Ø¹ Ø§Ù„Ø£Ù…ÙˆØ±ØŒ ÙÙ‚Ø¯ ÙŠÙƒÙˆÙ† Ù…Ù† Ø§Ù„Ù…ÙÙŠØ¯ Ø¶Ø¨Ø· Ù…Ø¹Ù„Ù…Ø© `batch_size` Ù‡Ù†Ø§.\n+\n+Ø£Ø¨Ø³Ø· Ø·Ø±ÙŠÙ‚Ø© Ù„Ù„ØªÙ†Ù‚Ù„ Ø®Ù„Ø§Ù„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù‡ÙŠ ÙÙ‚Ø· ØªØ­Ù…ÙŠÙ„ ÙˆØ§Ø­Ø¯Ø© Ù…Ù† ğŸ¤— [Datasets](https://github.com/huggingface/datasets/):\n+\n+```py\n+# KeyDataset Ù‡ÙŠ Ø£Ø¯Ø§Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ø³ØªÙ‚ÙˆÙ… ÙÙ‚Ø· Ø¨Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø°ÙŠ Ù†Ù‡ØªÙ… Ø¨Ù‡.\n+from transformers.pipelines.pt_utils import KeyDataset\n+from datasets import load_dataset\n+\n+pipe = pipeline(model=\"hf-internal-testing/tiny-random-wav2vec2\", device=0)\n+dataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation[:10]\")\n+\n+for out in pipe(KeyDataset(dataset, \"audio\")):\n+    print(out)\n+```\n+\n+## Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù„Ø®Ø§Ø¯Ù… ÙˆÙŠØ¨\n+\n+<Tip>\n+Ø¥Ù† Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø±Ùƒ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù‡Ùˆ Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø¹Ù‚Ø¯ ÙŠØ³ØªØ­Ù‚ ØµÙØ­ØªÙ‡ Ø§Ù„Ø®Ø§ØµØ©.\n+</Tip>\n+\n+[Link](./pipeline_webserver)\n+\n+## Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø±Ø¤ÙŠØ©\n+\n+Ø¥Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… [`pipeline`] Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø±Ø¤ÙŠØ© Ù…Ù…Ø§Ø«Ù„ ØªÙ…Ø§Ù…Ù‹Ø§.\n+\n+Ø­Ø¯Ø¯ Ù…Ù‡Ù…ØªÙƒ ÙˆÙ…Ø±Ø± ØµÙˆØ±ØªÙƒ Ø¥Ù„Ù‰ Ø§Ù„Ù…ØµÙ†Ù. ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„ØµÙˆØ±Ø© Ø±Ø§Ø¨Ø·Ù‹Ø§ Ø£Ùˆ Ù…Ø³Ø§Ø±Ù‹Ø§ Ù…Ø­Ù„ÙŠÙ‹Ø§ Ø£Ùˆ ØµÙˆØ±Ø© Ù…Ø´ÙØ±Ø© Ø¨ØªÙ†Ø³ÙŠÙ‚ base64. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ù…Ø§ Ù†ÙˆØ¹ Ø§Ù„Ù‚Ø·Ø· Ø§Ù„Ù…ÙˆØ¶Ø­ Ø£Ø¯Ù†Ø§Ù‡ØŸ\n+\n+![pipeline-cat-chonk](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg)\n+\n+```py\n+>>> from transformers import pipeline\n+\n+>>> vision_classifier = pipeline(model=\"google/vit-base-patch16-224\")\n+>>> preds = vision_classifier(\n+...     images=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n+... )\n+>>> preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n+>>> preds\n+[{'score': 0.4335, 'label': 'lynx, catamount'}, {'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}, {'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}, {'score': 0.0239, 'label': 'Egyptian cat'}, {'score': 0.0229, 'label': 'tiger cat'}]\n+```\n+\n+## Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù†Øµ\n+\n+Ø¥Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… [`pipeline`] Ù„Ù…Ù‡Ø§Ù… NLP Ù…Ù…Ø§Ø«Ù„ ØªÙ…Ø§Ù…Ù‹Ø§.\n+\n+```py\n+>>> from transformers import pipeline\n+\n+>>> # Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‡Ùˆ Ù†Ù…ÙˆØ°Ø¬ \"zero-shot-classification\".\n+>>> # Ø³ÙŠØµÙ†Ù Ø§Ù„Ù†ØµØŒ ÙˆÙ„ÙƒÙ† ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø®ØªÙŠØ§Ø± Ø£ÙŠ ØªØ³Ù…ÙŠØ© Ù‚Ø¯ ØªØªØ®ÙŠÙ„Ù‡Ø§\n+>>> classifier = pipeline(model=\"facebook/bart-large-mnli\")\n+>>> classifier(\n+...     \"I have a problem with my iphone that needs to be resolved asap!!\",\n+...     candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n+... )\n+{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'], 'scores': [0.504, 0.479, 0.013, 0.003, 0.002]}\n+```\n+\n+## Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ³Ø§Ø¦Ø·\n+\n+ØªØ¯Ø¹Ù… [`pipeline`] Ø£ÙƒØ«Ø± Ù…Ù† Ø·Ø±ÙŠÙ‚Ø© ÙˆØ§Ø­Ø¯Ø©. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ØªØ¬Ù…Ø¹ Ù…Ù‡Ù…Ø© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø±Ø¦ÙŠØ© (VQA) Ø¨ÙŠÙ† Ø§Ù„Ù†Øµ ÙˆØ§Ù„ØµÙˆØ±Ø©. Ù„Ø§ ØªØªØ±Ø¯Ø¯ ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ Ø±Ø§Ø¨Ø· ØµÙˆØ±Ø© ØªØ±ÙŠØ¯Ù‡ ÙˆØ³Ø¤Ø§Ù„ ØªØ±ÙŠØ¯ Ø·Ø±Ø­Ù‡ Ø­ÙˆÙ„ Ø§Ù„ØµÙˆØ±Ø©. ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„ØµÙˆØ±Ø© Ø¹Ù†ÙˆØ§Ù† URL Ø£Ùˆ Ù…Ø³Ø§Ø±Ù‹Ø§ Ù…Ø­Ù„ÙŠÙ‹Ø§ Ù„Ù„ØµÙˆØ±Ø©.\n+\n+Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ [ØµÙˆØ±Ø© Ø§Ù„ÙØ§ØªÙˆØ±Ø©](https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png):\n+\n+```py\n+>>> from transformers import pipeline\n+\n+>>> vqa = pipeline(model=\"impira/layoutlm-document-qa\")\n+>>> output = vqa(\n+...     image=\"https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png\",\n+...     question=\"What is the invoice number?\",\n+... )\n+>>> output[0][\"score\"] = round(output[0][\"score\"], 3)\n+>>> output\n+[{'score': 0.425, 'answer': 'us-001', 'start': 16, 'end': 16}]\n+```\n+\n+<Tip>\n+\n+Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ Ø£Ø¹Ù„Ø§Ù‡ØŒ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ«Ø¨ÙŠØª [`pytesseract`](https://pypi.org/project/pytesseract/) Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ ğŸ¤— Transformers:\n+\n+```bash\n+sudo apt install -y tesseract-ocr\n+pip install pytesseract\n+```\n+\n+</Tip>\n+\n+## Ø§Ø³ØªØ®Ø¯Ø§Ù… `pipeline` Ø¹Ù„Ù‰ Ù†Ù…Ø§Ø°Ø¬ ÙƒØ¨ÙŠØ±Ø© Ù…Ø¹ ğŸ¤— `accelerate`:\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø¨Ø³Ù‡ÙˆÙ„Ø© ØªØ´ØºÙŠÙ„ `pipeline` Ø¹Ù„Ù‰ Ù†Ù…Ø§Ø°Ø¬ ÙƒØ¨ÙŠØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ğŸ¤— `accelerate`! Ø£ÙˆÙ„Ø§Ù‹ØŒ ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª `accelerate` Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `pip install accelerate`.\n+\n+Ù‚Ù… Ø£ÙˆÙ„Ø§Ù‹ Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `device_map=\"auto\"`! Ø³Ù†Ø³ØªØ®Ø¯Ù… `facebook/opt-1.3b` ÙƒÙ…Ø«Ø§Ù„ Ù„Ù†Ø§.\n+\n+```py\n+# pip install accelerate\n+import torch\n+from transformers import pipeline\n+\n+pipe = pipeline(model=\"facebook/opt-1.3b\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n+output = pipe(\"This is a cool example!\", do_sample=True, top_p=0.95)\n+```\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ØªÙ…Ø±ÙŠØ± Ù†Ù…Ø§Ø°Ø¬ Ù…Ø­Ù…Ù„Ø© Ø¨Ù€ 8 Ø¨Øª Ø¥Ø°Ø§ Ù‚Ù…Øª Ø¨ØªØ«Ø¨ÙŠØª `bitsandbytes` ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„Ø­Ø¬Ø© `load_in_8bit=True`\n+\n+```py\n+# pip install accelerate bitsandbytes\n+import torch\n+from transformers import pipeline\n+\n+pipe = pipeline(model=\"facebook/opt-1.3b\", device_map=\"auto\", model_kwargs={\"load_in_8bit\": True})\n+output = pipe(\"This is a cool example!\", do_sample=True, top_p=0.95)\n+```\n+\n+Ù„Ø§Ø­Ø¸ Ø£Ù†Ù‡ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙØªÙŠØ´ Ø¨Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Hugging Face ÙŠØ¯Ø¹Ù… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©ØŒ Ù…Ø«Ù„ BLOOM.\n+\n+## Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ø±ÙˆØ¶ ØªÙˆØ¶ÙŠØ­ÙŠØ© ÙˆÙŠØ¨ Ù…Ù† Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `gradio`\n+\n+ÙŠØªÙ… Ø¯Ø¹Ù… Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ ÙÙŠ [Gradio](https://github.com/gradio-app/gradio/)ØŒ ÙˆÙ‡ÙŠ Ù…ÙƒØªØ¨Ø© ØªØ¬Ø¹Ù„ Ø¥Ù†Ø´Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚Ø§Øª ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¢Ù„Ø© Ø§Ù„Ø¬Ù…ÙŠÙ„Ø© ÙˆØ§Ù„Ø³Ù‡Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ù„Ù‰ Ø§Ù„ÙˆÙŠØ¨ Ø£Ù…Ø±Ù‹Ø§ Ø³Ù‡Ù„Ø§Ù‹. Ø£ÙˆÙ„Ø§Ù‹ØŒ ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª Gradio:\n+\n+```\n+pip install gradio\n+```\n+\n+Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ø±Ø¶ ØªÙˆØ¶ÙŠØ­ÙŠ ÙˆÙŠØ¨ Ø­ÙˆÙ„ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ± (Ø£Ùˆ Ø£ÙŠ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø¢Ø®Ø±) ÙÙŠ Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ ÙˆØ¸ÙŠÙØ© [`Interface.from_pipeline`](https://www.gradio.app/docs/interface#interface-from-pipeline) ÙÙŠ Gradio Ù„Ø¥Ø·Ù„Ø§Ù‚ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨. ÙŠÙ‚ÙˆÙ… Ù‡Ø°Ø§ Ø¨Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø¯ÙŠÙ‡ÙŠØ© Ù„Ù„Ø³Ø­Ø¨ ÙˆØ§Ù„Ø¥ÙÙ„Ø§Øª ÙÙŠ Ù…Ø³ØªØ¹Ø±Ø¶Ùƒ:\n+\n+```py\n+from transformers import pipeline\n+import gradio as gr\n+\n+pipe = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n+\n+gr.Interface.from_pipeline(pipe).launch()\n+```\n+\n+\n+![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/panda-classification.png)\n+\n+Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠØŒ ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ Ø¹Ù„Ù‰ Ø®Ø§Ø¯Ù… Ù…Ø­Ù„ÙŠ. Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ù…Ø´Ø§Ø±ÙƒØªÙ‡Ø§ Ù…Ø¹ Ø§Ù„Ø¢Ø®Ø±ÙŠÙ†ØŒ ÙÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ø¹Ø§Ù… Ù…Ø¤Ù‚Øª Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ¹ÙŠÙŠÙ† `share=True` ÙÙŠ `launch()`. ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø§Ø³ØªØ¶Ø§ÙØ© Ø¹Ø±Ø¶Ùƒ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ Ø¹Ù„Ù‰ [Hugging Face Spaces](https://huggingface.co/spaces) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ø¯Ø§Ø¦Ù….\n\\ No newline at end of file"
        },
        {
            "sha": "8c1f68934d2052a5baf6d30488be968725a5be9b",
            "filename": "docs/source/ar/preprocessing.md",
            "status": "added",
            "additions": 521,
            "deletions": 0,
            "changes": 521,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fpreprocessing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fpreprocessing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fpreprocessing.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,521 @@\n+# Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Preprocessing\n+\n+[[open-in-colab]]\n+\n+Ù‚Ø¨Ù„ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙŠØ¬Ø¨ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ÙˆÙÙ‚Ù‹Ø§ ØªÙ†Ø³ÙŠÙ‚  Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ø³ÙˆØ§Ø¡ ÙƒØ§Ù†Øª Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ù†ØµÙŠØ© Ø£Ùˆ ØµÙˆØ±Ù‹Ø§ Ø£Ùˆ ØµÙˆØªÙ‹Ø§ØŒ ÙÙŠØ¬Ø¨ ØªØ­ÙˆÙŠÙ„Ù‡Ø§ ÙˆØªØ¬Ù…ÙŠØ¹Ù‡Ø§ ÙÙŠ Ø¯ÙØ¹Ø§Øª Ù…Ù† Ø§Ù„Ù…ÙˆØªØ±Ø§Øª. ÙŠÙˆÙØ± ğŸ¤— Transformers Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† ÙØ¦Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬. ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØŒ Ø³ØªØªØ¹Ù„Ù… Ø£Ù†Ù‡ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù€:\n+\n+* Ù„Ù„Ù†ØµØŒ Ø§Ø³ØªØ®Ø¯Ù… [Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ø±Ù…ÙˆØ²](./main_classes/tokenizer) Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ²ØŒ ÙˆØ¥Ù†Ø´Ø§Ø¡ ØªÙ…Ø«ÙŠÙ„ Ø±Ù‚Ù…ÙŠ Ù„Ù„Ø±Ù…ÙˆØ²ØŒ ÙˆØªØ¬Ù…ÙŠØ¹Ù‡Ø§ ÙÙŠ Ù…ÙˆØªØ±Ø§Øª(tensors).\n+* Ù„Ù„ÙƒÙ„Ø§Ù… ÙˆØ§Ù„ØµÙˆØªØŒ Ø§Ø³ØªØ®Ø¯Ù… [Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª](./main_classes/feature_extractor) Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙŠØ²Ø§Øª Ù…ØªØ³Ù„Ø³Ù„Ø© Ù…Ù† Ø£Ø´ÙƒØ§Ù„ Ù…ÙˆØ¬Ø§Øª Ø§Ù„ØµÙˆØª ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ù…ÙˆØªØ±Ø§Øª.\n+* ØªØ³ØªØ®Ø¯Ù… Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„ØµÙˆØ±Ø© [ImageProcessor](./main_classes/image_processor) Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø¥Ù„Ù‰ Ù…ÙˆØªØ±Ø§Øª.\n+* ØªØ³ØªØ®Ø¯Ù… Ù…Ø¯Ø®Ù„Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„ÙˆØ³Ø§Ø¦Ø· [Ù…Ø¹Ø§Ù„Ø¬Ù‹Ø§](./main_classes/processors) Ù„Ø¯Ù…Ø¬ Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ø±Ù…ÙˆØ² ÙˆÙ…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø£Ùˆ Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ±.\n+\n+<Tip>\n+\n+`AutoProcessor` **ÙŠØ¹Ù…Ù„ Ø¯Ø§Ø¦Ù…Ù‹Ø§** ÙˆÙŠØ®ØªØ§Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø§Ù„ÙØ¦Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙŠ ØªØ³ØªØ®Ø¯Ù…Ù‡ØŒ Ø³ÙˆØ§Ø¡ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… Ù…ÙØ¬Ø²Ù‘Ø¦ Ø±Ù…ÙˆØ² Ø£Ùˆ Ù…Ø¹Ø§Ù„Ø¬ ØµÙˆØ± Ø£Ùˆ Ù…Ø³ØªØ®Ø±Ø¬ Ù…ÙŠØ²Ø§Øª Ø£Ùˆ Ù…Ø¹Ø§Ù„Ø¬Ù‹Ø§.\n+\n+</Tip>\n+\n+Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡ØŒ Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª ğŸ¤— Datasets Ø­ØªÙ‰ ØªØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ù…ÙŠÙ„ Ø¨Ø¹Ø¶ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØ¬Ø±Ø¨ØªÙ‡Ø§:\n+\n+```bash\n+pip install datasets\n+```\n+\n+## Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (Natural Language Processing (NLP\n+\n+<Youtube id=\"Yffk5aydLzg\"/>\n+\n+Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†ØµÙŠØ© Ù‡ÙŠ [Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ](main_classes/tokenizer). ÙŠÙ‚ÙˆÙ… Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ Ø¨ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰  \"Ø£Ø¬Ø²Ø§Ø¡ Ù„ØºÙˆÙŠØ©\" (tokens) ÙˆÙÙ‚Ù‹Ø§ Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯. ÙŠØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù„ØºÙˆÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø«Ù… Ø¥Ù„Ù‰ Ù…Ù†Ø³ÙˆØ¬Ø§ØªØŒ ÙˆØ§Ù„ØªÙŠ ØªØµØ¨Ø­ Ù…Ø¯Ø®Ù„Ø§Øª Ù„Ù„Ù†Ù…ÙˆØ°Ø¬. ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù…Ø¬Ø²Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ Ø¨Ø¥Ø¶Ø§ÙØ© Ø£ÙŠ Ù…Ø¯Ø®Ù„Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© ÙŠØ­ØªØ§Ø¬Ù‡Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n+\n+<Tip>\n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ®Ø·Ø· Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ØŒ ÙÙ…Ù† Ø§Ù„Ù…Ù‡Ù… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Ù„Ù…Ø¬Ø²Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ Ø§Ù„Ù…Ù‚ØªØ±Ù† Ø¨Ù†ÙØ³ Ø°Ù„Ùƒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ÙŠØ¶Ù…Ù† Ø°Ù„Ùƒ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¨Ù†ÙØ³ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙŠ ØªÙ… Ø¨Ù‡Ø§ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†ØµÙˆØµ Ù…Ø§ Ù‚Ø¨Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³  Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ø°ÙŠ ÙŠØ±Ø¨Ø· Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù„ØºÙˆÙŠØ© ÙˆØ£Ø±Ù‚Ø§Ù…Ù‡Ø§ ( ÙŠÙØ´Ø§Ø± Ø¥Ù„ÙŠÙ‡Ø§ Ø¹Ø§Ø¯Ø©Ù‹ Ø¨Ø§Ø³Ù… Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª *vocab*) Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³Ø¨Ù‚.\n+\n+</Tip>\n+\n+Ø§Ø¨Ø¯Ø£ Ø¨ØªØ­Ù…ÙŠÙ„  Ø§Ù„Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© [`AutoTokenizer.from_pretrained`]. ÙŠÙ‚ÙˆÙ… Ù‡Ø°Ø§ Ø¨ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª *vocab* Ø§Ù„Ø°ÙŠ ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„ÙŠÙ‡:\n+\n+```py\n+>>> from transformers import AutoTokenizer\n+\n+>>> tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n+```\n+\n+Ø«Ù… Ù…Ø±Ø± Ù†ØµÙƒ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ:\n+\n+```py\n+>>> encoded_input = tokenizer(\"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\")\n+>>> print(encoded_input)\n+{'input_ids': [101, 2079, 2025, 19960, 10362, 1999, 1996, 3821, 1997, 16657, 1010, 2005, 2027, 2024, 11259, 1998, 4248, 2000, 4963, 1012, 102],\n+ 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n+ 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n+```\n+\n+ÙŠØ¹ÙŠØ¯ Ø§Ù„Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ Ù‚Ø§Ù…ÙˆØ³Ù‹Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø«Ù„Ø§Ø«Ø© Ø¹Ù†Ø§ØµØ± Ù…Ù‡Ù…Ø©:\n+\n+* [input_ids](glossary#input-ids) Ù‡ÙŠ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© Ù„ÙƒÙ„ Ø±Ù…Ø² ÙÙŠ Ø§Ù„Ø¬Ù…Ù„Ø©.\n+* [attention_mask](glossary#attention-mask) ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¬Ø¨ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ø¨Ø§Ù„Ø±Ù…Ø² Ø£Ù… Ù„Ø§.\n+* [token_type_ids](glossary#token-type-ids) ÙŠØ­Ø¯Ø¯ Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø°ÙŠ ÙŠÙ†ØªÙ…ÙŠ Ø¥Ù„ÙŠÙ‡ Ø§Ù„Ø±Ù…Ø² Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ Ø£ÙƒØ«Ø± Ù…Ù† ØªØ³Ù„Ø³Ù„ ÙˆØ§Ø­Ø¯.\n+\n+Ø£Ø¹Ø¯ Ø¥Ø¯Ø®Ø§Ù„Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ÙÙƒ ØªØ±Ù…ÙŠØ² `input_ids`:\n+\n+```py\n+>>> tokenizer.decode(encoded_input[\"input_ids\"])\n+'[CLS] Do not meddle in the affairs of wizards, for they are subtle and quick to anger. [SEP]'\n+```\n+\n+ÙƒÙ…Ø§ ØªØ±Ù‰ØŒ Ø£Ø¶Ø§Ù Ø§Ù„Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ Ø±Ù…Ø²ÙŠÙ† Ø®Ø§ØµÙŠÙ† - `CLS` Ùˆ`SEP` (Ù…ØµÙ†Ù ÙˆÙØ§ØµÙ„) - Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù…Ù„Ø©. Ù„Ø§ ØªØ­ØªØ§Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¥Ù„Ù‰\n+Ø±Ù…ÙˆØ² Ø®Ø§ØµØ©ØŒ ÙˆÙ„ÙƒÙ† Ø¥Ø°Ø§ ÙØ¹Ù„ÙˆØ§ Ø°Ù„ÙƒØŒ ÙØ¥Ù† Ø§Ù„Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ ÙŠØ¶ÙŠÙÙ‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ù„Ùƒ.\n+\n+Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø¹Ø¯Ø© Ø¬Ù…Ù„ ØªØ±ÙŠØ¯ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ Ù…Ø³Ø¨Ù‚Ù‹Ø§ØŒ ÙÙ‚Ù… Ø¨ØªÙ…Ø±ÙŠØ±Ù‡Ø§ ÙƒÙ‚Ø§Ø¦Ù…Ø© Ø¥Ù„Ù‰ Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ:\n+\n+```py\n+>>> batch_sentences = [\n+...     \"But what about second breakfast?\",\n+...     \"Don't think he knows about second breakfast, Pip.\",\n+...     \"What about elevensies?\",\n+... ]\n+>>> encoded_inputs = tokenizer(batch_sentences)\n+>>> print(encoded_inputs)\n+{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102],\n+               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n+               [101, 1327, 1164, 5450, 23434, 136, 102]],\n+ 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0],\n+                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n+                    [0, 0, 0, 0, 0, 0, 0]],\n+ 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1],\n+                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n+                    [1, 1, 1, 1, 1, 1, 1]]}\n+```\n+\n+### Ø§Ù„Ø­Ø´Ùˆ Padding\n+\n+Ù„Ø§ ØªÙƒÙˆÙ† Ø§Ù„Ø¬Ù…Ù„ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¨Ù†ÙØ³ Ø§Ù„Ø·ÙˆÙ„ØŒ  ÙˆÙ‡Ø°Ø§ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙ…Ø«Ù„ Ù…Ø´ÙƒÙ„Ø© Ù„Ø£Ù† Ø§Ù„Ù…ÙˆØªØ±Ø§ØªØŒÙˆÙ‡ÙŠ Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø´ÙƒÙ„ Ù…ÙˆØ­Ø¯. Ø§Ù„Ø­Ø´Ùˆ Ù‡Ùˆ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù„Ø¶Ù…Ø§Ù† Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù…ÙˆØªØ±Ø§Øª Ù…Ø³ØªØ·ÙŠÙ„Ø© Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø¥Ø¶Ø§ÙØ© Ø±Ù…Ø² Ø­Ø´Ùˆ *padding* Ø®Ø§Øµ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø£Ù‚ØµØ±.\n+\n+Ù‚Ù… Ø¨ØªØ¹ÙŠÙŠÙ† Ù…Ø¹Ù„Ù…Ø© Ø§Ù„Ø­Ø´Ùˆ `padding` Ø¥Ù„Ù‰ `True` Ù„Ø­Ø´Ùˆ Ø§Ù„ØªØ³Ù„Ø³Ù„Ø§Øª Ø§Ù„Ø£Ù‚ØµØ± ÙÙŠ Ø§Ù„Ø¯ÙØ¹Ø© Ù„ØªØ·Ø§Ø¨Ù‚ Ø£Ø·ÙˆÙ„ ØªØ³Ù„Ø³Ù„:\n+\n+```py\n+>>> batch_sentences = [\n+...     \"But what about second breakfast?\",\n+...     \"Don't think he knows about second breakfast, Pip.\",\n+...     \"What about elevensies?\",\n+... ]\n+>>> encoded_input = tokenizer(batch_sentences, padding=True)\n+>>> print(encoded_input)\n+{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],\n+               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n+               [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],\n+ 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n+                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n+                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n+ 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n+                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n+                    [1, 1, 1, 1, 1, 1, 1, 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0]]}\n+```\n+\n+ØªÙ… Ø§Ù„Ø¢Ù† Ø­Ø´Ùˆ Ø§Ù„Ø¬Ù…Ù„ØªÙŠÙ† Ø§Ù„Ø£ÙˆÙ„Ù‰ ÙˆØ§Ù„Ø«Ø§Ù„Ø«Ø© Ø¨Ù€ `0` Ù„Ø£Ù†Ù‡Ù…Ø§ Ø£Ù‚ØµØ±.\n+\n+### Ø§Ù„Ø¨ØªØ± Truncation\n+\n+ÙˆØ¹Ù„Ù‰ ØµØ¹ÙŠØ¯ Ø£Ø®Ø±ØŒ Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø·ÙˆÙŠÙ„Ù‹Ø§ Ø¬Ø¯Ù‹Ø§ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡. ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø©ØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¨ØªØ± Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø¥Ù„Ù‰ Ø·ÙˆÙ„ Ø£Ù‚ØµØ±.\n+\n+Ù‚Ù… Ø¨ØªØ¹ÙŠÙŠÙ† Ù…Ø¹Ù„Ù…Ø© `truncation` Ø¥Ù„Ù‰ `True` Ù„ØªÙ‚Ù„ÙŠÙ… ØªØ³Ù„Ø³Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰ Ø§Ù„Ø°ÙŠ ÙŠÙ‚Ø¨Ù„Ù‡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:\n+\n+```py\n+>>> batch_sentences = [\n+...     \"But what about second breakfast?\",\n+...     \"Don't think he knows about second breakfast, Pip.\",\n+...     \"What about elevensies?\",\n+... ]\n+>>> encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)\n+>>> print(encoded_input)\n+{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],\n+               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n+               [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],\n+ 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n+                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n+                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0]]ØŒ\n+ 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0ØŒ 0ØŒ 0ØŒ 0],\n+                    [1, 1, 1, 1, 1, 1, 1ØŒ 1ØŒ 1ØŒ 1ØŒ 1ØŒ 1ØŒ 1ØŒ 1ØŒ 1ØŒ 1],\n+                    [1ØŒ 1ØŒ 1ØŒ 1ØŒ 1ØŒ 1ØŒ 1ØŒ 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0ØŒ 0]]}\n+```\n+\n+<Tip>\n+\n+ØªØ­Ù‚Ù‚ Ù…Ù† Ø¯Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… [Padding and truncation](./pad_truncation) Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ø­ÙˆÙ„ Ù…Ø¹Ø§Ù…ï»»Øª Ø§Ù„Ø­Ø´Ùˆ Ùˆ Ø§Ù„Ø¨ØªØ± Ø§Ù„Ù…Ø®ØªÙ„ÙØ©.\n+\n+</Tip>\n+\n+### Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…ÙˆØªØ±Ø§Øª Build tensors\n+\n+Ø£Ø®ÙŠØ±Ù‹Ø§ØŒ ØªØ±ÙŠØ¯ Ø£Ù† ÙŠÙ‚ÙˆÙ…  Ø§Ù„Ù…Ø¬Ø²Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ Ø¨Ø¥Ø±Ø¬Ø§Ø¹ Ù…ÙˆØªØ±Ø§Øª (tensors) Ø§Ù„ÙØ¹Ù„ÙŠØ© Ø§Ù„ØªÙŠ Ø³ØªÙØºØ°ÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n+\n+Ù‚Ù… Ø¨ØªØ¹ÙŠÙŠÙ† Ù…Ø¹Ù„Ù…Ø© `return_tensors` Ø¥Ù„Ù‰ Ø¥Ù…Ø§ `pt` Ù„Ù€ PyTorchØŒ Ø£Ùˆ `tf` Ù„Ù€ TensorFlow:\n+\n+<frameworkcontent>\n+<pt>\n+\n+```py\n+>>> batch_sentences = [\n+...     \"But what about second breakfast?\",\n+...     \"Don't think he knows about second breakfast, Pip.\",\n+...     \"What about elevensies?\",\n+... ]\n+>>> encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n+>>> print(encoded_input)\n+{'input_ids': tensor([[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],\n+                      [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n+                      [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]]),\n+ 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n+                           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n+                           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n+ 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n+                           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n+                           [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n+```\n+</pt>\n+<tf>\n+ \n+```py\n+>>> batch_sentences = [\n+...     \"But what about second breakfast?\",\n+...     \"Don't think he knows about second breakfast, Pip.\",\n+...     \"What about elevensies?\",\n+... ]\n+>>> encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"tf\")\n+>>> print(encoded_input)\n+{'input_ids': <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n+array([[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],\n+       [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n+       [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],\n+      dtype=int32)>,\n+ 'token_type_ids': <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n+array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n+       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n+       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>,\n+ 'attention_mask': <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n+array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n+       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n+       [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}\n+```\n+</tf>\n+</frameworkcontent>\n+\n+<Tip>\n+\n+ØªØ¯Ø¹Ù… Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ù…Ø¹Ø§Ù…Ù„ Ù…ÙØ¬Ø²ÙÙ‘Ø¦ Ø§Ù„Ø±Ù…ÙˆØ²(tokenizer) Ø¨Ø´ÙƒÙ„ Ù…Ø®ØªÙ„Ù ÙÙŠ Ø·Ø±ÙŠÙ‚Ø© `()__call__` Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø§.\n+Ùˆ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ `text-2-text-generation` ØªØ¯Ø¹Ù… ÙÙ‚Ø· `truncation`.\n+Ùˆ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ `text-generation` ØªØ¯Ø¹Ù… `max_length` Ùˆ`truncation` Ùˆ`padding` Ùˆ`add_special_tokens`.\n+Ø£Ù…Ø§ ÙÙŠ Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ `fill-mask`ØŒ ÙŠÙ…ÙƒÙ† ØªÙ…Ø±ÙŠØ± Ù…Ø¹Ø§Ù…Ù„ Ù…ÙØ¬Ø²ÙÙ‘Ø¦ Ø§Ù„Ø±Ù…ÙˆØ² (tokenizer) ÙÙŠ Ø§Ù„Ù…ØªØºÙŠØ± `tokenizer_kwargs` (Ù‚Ø§Ù…ÙˆØ³).\n+\n+</Tip>\n+\n+## Ø§Ù„ØµÙˆØª Audio\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØµÙˆØªÙŠØ©ØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ [Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª](main_classes/feature_extractor) Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬. ØªÙ… ØªØµÙ…ÙŠÙ… Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØª Ø§Ù„Ø®Ø§Ù…ØŒ ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ù…ÙˆØªÙˆØ±Ø§Øª.\n+\n+Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) (Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ù„Ù€ ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/load_hub) Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª) Ù„Ù…Ø¹Ø±ÙØ© ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ©:\n+\n+```py\n+>>> from datasets import load_dataset, Audio\n+\n+>>> dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n+```\n+\n+Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø£ÙˆÙ„ Ù…Ù† Ø¹Ù…ÙˆØ¯ `audio` Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª. ÙŠØ¤Ø¯ÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¹Ù…ÙˆØ¯ `audio` Ø¥Ù„Ù‰ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ØµÙˆØª ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§:\n+\n+```py\n+>>> dataset[0][\"audio\"]\n+{'array': array([ 0.        ,  0.00024414, -0.00024414, ..., -0.00024414,\n+         0.        ,  0.        ], dtype=float32),\n+ 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',\n+ 'sampling_rate': 8000}\n+```\n+\n+ÙŠØ¹ÙŠØ¯ Ù‡Ø°Ø§ Ø«Ù„Ø§Ø«Ø© Ø¹Ù†Ø§ØµØ±:\n+\n+* `array` Ù‡Ùˆ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ù…Ø­Ù…Ù„Ø© - ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© - ÙƒØµÙÙŠÙ 1D.\n+* `path` ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ù…ÙˆÙ‚Ø¹ Ù…Ù„Ù Ø§Ù„ØµÙˆØª.\n+* `sampling_rate` ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø¹Ø¯Ø¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ù…Ù‚Ø§Ø³Ø© ÙÙŠ Ø§Ù„Ø«Ø§Ù†ÙŠØ©.\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØŒ Ø³ØªØ³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬ [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base). Ø§Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ ÙˆØ³ØªØªØ¹Ù„Ù… Ø£Ù† Wav2Vec2 Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¹Ù„Ù‰ ØµÙˆØª Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ø°ÙŠ ØªÙ… Ø£Ø®Ø° Ø¹ÙŠÙ†Ø§Øª Ù…Ù†Ù‡ Ø¨Ù…Ø¹Ø¯Ù„ 16 ÙƒÙŠÙ„Ùˆ Ù‡Ø±ØªØ². Ù…Ù† Ø§Ù„Ù…Ù‡Ù… Ø£Ù† ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹Ø¯Ù„ Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØª Ù…Ø¹ Ù…Ø¹Ø¯Ù„ Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø³Ø¨Ù‚Ù‹Ø§. Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…Ø¹Ø¯Ù„ Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ù„Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ù‡Ùˆ Ù†ÙØ³Ù‡ØŒ ÙÙŠØ¬Ø¨ Ø¥Ø¹Ø§Ø¯Ø© Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ù…Ù† Ø¨ÙŠØ§Ù†Ø§ØªÙƒ.\n+\n+1. Ø§Ø³ØªØ®Ø¯Ù… Ø·Ø±ÙŠÙ‚Ø© [`~datasets.Dataset.cast_column`] ÙÙŠ ğŸ¤— Datasets Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø¨Ù…Ø¹Ø¯Ù„ Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª 16 ÙƒÙŠÙ„Ùˆ Ù‡Ø±ØªØ²:\n+\n+```py\n+>>> dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16_000))\n+```\n+\n+2. Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¹Ù…ÙˆØ¯ `audio` Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ø£Ø®Ø° Ø¹ÙŠÙ†Ø§Øª Ù…Ù† Ù…Ù„Ù Ø§Ù„ØµÙˆØª:\n+\n+```py\n+>>> dataset[0][\"audio\"]\n+{'array': array([ 2.3443763e-05,  2.1729663e-04,  2.2145823e-04, ...,\n+         3.8356509e-05, -7.3497440e-06, -2.1754686e-05], dtype=float32),\n+ 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',\n+ 'sampling_rate': 16000}\n+```\n+\n+Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù„ØªØ·Ø¨ÙŠØ¹ ÙˆØ­Ø´Ùˆ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª. Ø¹Ù†Ø¯ Ø¥Ø¶Ø§ÙØ© Ø­Ø´Ùˆ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†ØµÙŠØ©ØŒ ØªØªÙ… Ø¥Ø¶Ø§ÙØ© \"0\" Ù„Ù„ØªØ³Ù„Ø³Ù„Ø§Øª Ø§Ù„Ø£Ù‚ØµØ±. ØªÙ†Ø·Ø¨Ù‚ Ù†ÙØ³ Ø§Ù„ÙÙƒØ±Ø© Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØª. ÙŠØ¶ÙŠÙ Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª \"0\" - Ø§Ù„Ø°ÙŠ ÙŠØªÙ… ØªÙØ³ÙŠØ±Ù‡ Ø¹Ù„Ù‰ Ø£Ù†Ù‡ ØµÙ…Øª - Ø¥Ù„Ù‰ \"array\".\n+\n+Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`AutoFeatureExtractor.from_pretrained`]:\n+\n+```py\n+>>> from transformers import AutoFeatureExtractor\n+\n+>>> feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n+```\n+\n+Ù…Ø±Ø± ØµÙÙŠÙ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª. ÙƒÙ…Ø§ Ù†ÙˆØµÙŠ Ø¨Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ù…Ù„ `sampling_rate` ÙÙŠ Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ù† Ø£Ø¬Ù„ ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ØµØ§Ù…ØªØ© Ø§Ù„ØªÙŠ Ù‚Ø¯ ØªØ­Ø¯Ø« Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„.\n+\n+```py\n+>>> audio_input = [dataset[0][\"audio\"][\"array\"]]\n+>>> feature_extractor(audio_input, sampling_rate=16000)\n+{'input_values': [array([ 3.8106556e-04,  2.7506407e-03,  2.8015103e-03, ...,\n+        5.6335266e-04,  4.6588284e-06, -1.7142107e-04], dtype=float32)]}\n+```\n+\n+ØªÙ…Ø§Ù…Ù‹Ø§ Ù…Ø«Ù„ Ù…ÙØ¬Ø²ÙÙ‘Ø¦ Ø§Ù„Ø±Ù…ÙˆØ²ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ø´Ùˆ Ø£Ùˆ Ø§Ù„Ø¨ØªØ± Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªØ³Ù„Ø³Ù„Ø§Øª Ø§Ù„Ù…ØªØºÙŠØ±Ø© ÙÙŠ Ø¯ÙØ¹Ø©. Ø§Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ø§Ù„ØªØ³Ù„Ø³Ù„ Ù„Ù‡Ø§ØªÙŠÙ† Ø§Ù„Ø¹ÙŠÙ†ØªÙŠÙ† Ø§Ù„ØµÙˆØªÙŠØªÙŠÙ†:\n+\n+```py\n+>>> dataset[0][\"audio\"][\"array\"].shape\n+(173398,)\n+\n+>>> dataset[1][\"audio\"][\"array\"].shape\n+(106496,)\n+```\n+\n+Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø­ÙŠØ« ÙŠÙƒÙˆÙ† Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØµÙˆØªÙŠØ© Ù†ÙØ³ Ø§Ù„Ø£Ø·ÙˆØ§Ù„. Ø­Ø¯Ø¯ Ø£Ù‚ØµÙ‰ Ø·ÙˆÙ„ Ù„Ù„Ø¹ÙŠÙ†Ø© ØŒ ÙˆØ³ÙŠÙ‚ÙˆÙ… Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¥Ù…Ø§ Ø¨Ø¥Ø¶Ø§ÙØ© Ø­Ø´Ùˆ Ø£Ùˆ Ø¨ØªØ± Ø§Ù„ØªØ³Ù„Ø³Ù„Ø§Øª Ù„Ù…Ø·Ø§Ø¨Ù‚ØªÙ‡Ø§:\n+\n+```py\n+>>> def preprocess_function(examples):\n+...     audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n+...     inputs = feature_extractor(\n+...         audio_arrays,\n+...         sampling_rate=16000,\n+...         padding=True,\n+...         max_length=100000,\n+...         truncation=True,\n+...     )\n+...     return inputs\n+```\n+\n+Ù‚Ù… Ø¨ØªØ·Ø¨ÙŠÙ‚ `preprocess_function` Ø¹Ù„Ù‰ Ø£ÙˆÙ„ Ø¨Ø¶Ø¹ Ø£Ù…Ø«Ù„Ø© ÙÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n+\n+```py\n+>>> processed_dataset = preprocess_function(dataset[:5])\n+```\n+\n+Ø£Ø·ÙˆØ§Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ø¢Ù† Ù…ØªØ³Ø§ÙˆÙŠØ© ÙˆØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰ Ø§Ù„Ù…Ø­Ø¯Ø¯. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† ØªÙ…Ø±ÙŠØ± Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬!\n+\n+```py\n+>>> processed_dataset[\"input_values\"][0].shape\n+(100000,)\n+\n+>>> processed_dataset[\"input_values\"][1].shape\n+(100000,)\n+```\n+\n+## Ø±Ø¤ÙŠØ© Ø§Ù„ÙƒÙ…Ø¨ÙŠÙˆØªØ± Computer vision\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù…Ù‡Ø§Ù… Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ÙŠØ©ØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø¹Ø§Ù„Ø¬ ØµÙˆØ± [image processor](main_classes/image_processor) Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ù„ØªÙ†Ø§Ø³Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ØªØªÙƒÙˆÙ† Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ù…Ù† Ø¹Ø¯Ø© Ø®Ø·ÙˆØ§Øª Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø¥Ù„Ù‰ Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø°ÙŠ ÙŠØªÙˆÙ‚Ø¹Ù‡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ÙˆØªØ´Ù…Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ§ØªØŒ Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ Ù„Ø§ Ø§Ù„Ø­ØµØ±ØŒ ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… ÙˆØ§Ù„ØªØ·Ø¨ÙŠØ¹ ÙˆØªØµØ­ÙŠØ­ Ù‚Ù†Ø§Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø¥Ù„Ù‰ Ù…ÙˆØªØ±Ø§Øª(tensors).\n+\n+<Tip>\n+\n+Ø¹Ø§Ø¯Ø© Ù…Ø§ ØªØªØ¨Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ø´ÙƒÙ„Ø§Ù‹ Ù…Ù† Ø£Ø´ÙƒØ§Ù„ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ù„ØªØ¶Ø®ÙŠÙ…). ÙƒÙ„Ø§ Ø§Ù„Ø¹Ù…Ù„ÙŠØªÙŠÙ†ØŒ  Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© ÙˆØ²ÙŠØ§Ø¯Ø© Ø§Ù„ØµÙˆØ± ØªØºÙŠØ±Ø§Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØ±Ø©ØŒ ÙˆÙ„ÙƒÙ†Ù‡Ø§ ØªØ®Ø¯Ù… Ø£ØºØ±Ø§Ø¶Ù‹Ø§ Ù…Ø®ØªÙ„ÙØ©:\n+\n+*Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: ØªØºÙŠÙŠØ± Ø§Ù„ØµÙˆØ± Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØµÙˆØ± Ø¨Ø·Ø±ÙŠÙ‚Ø© ÙŠÙ…ÙƒÙ† Ø£Ù† ØªØ³Ø§Ø¹Ø¯ ÙÙŠ Ù…Ù†Ø¹ Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ØªØ¹Ù…ÙŠÙ… ÙˆØ²ÙŠØ§Ø¯Ø© Ù…ØªØ§Ù†Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ÙŠÙ…ÙƒÙ†Ùƒ Ø£Ù† ØªÙƒÙˆÙ† Ù…Ø¨Ø¯Ø¹Ù‹Ø§ ÙÙŠ ÙƒÙŠÙÙŠØ© Ø²ÙŠØ§Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§ØªÙƒ - Ø¶Ø¨Ø· Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„Ø£Ù„ÙˆØ§Ù†ØŒ ÙˆØ§Ø§Ù„Ù‚ØµØŒ ÙˆØ§Ù„Ø¯ÙˆØ±Ø§Ù†ØŒ ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù…ØŒ Ø§Ù„ØªÙƒØ¨ÙŠØ±ØŒ Ø¥Ù„Ø®. ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ ÙƒÙ† Ø­Ø°Ø±Ù‹Ø§ Ù…Ù† Ø¹Ø¯Ù… ØªØºÙŠÙŠØ± Ù…Ø¹Ù†Ù‰ Ø§Ù„ØµÙˆØ± Ø¨Ø²ÙŠØ§Ø¯Ø§ØªÙƒ.\n+*Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©: ØªØ¶Ù…Ù† Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§ØªØªØ·Ø§Ø¨Ù‚ Ø§Ù„ØµÙˆØ± Ù…Ø¹ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬. Ø¹Ù†Ø¯ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ø±Ø¤ÙŠØ© Ø­Ø§Ø³ÙˆØ¨ÙŠØ© Ø¨Ø¯Ù‚Ø©ØŒ ÙŠØ¬Ø¨ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø¨Ø§Ù„Ø¶Ø¨Ø· ÙƒÙ…Ø§ ÙƒØ§Ù†Øª Ø¹Ù†Ø¯ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©.\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ Ù…ÙƒØªØ¨Ø© ØªØ±ÙŠØ¯Ù‡Ø§ Ù„Ø²ÙŠØ§Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØ±. Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù… `ImageProcessor` Ø§Ù„Ù…Ø±ØªØ¨Ø· Ø¨Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n+\n+</Tip>\n+\n+Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª [food101](https://huggingface.co/datasets/food101) (Ø±Ø§Ø¬Ø¹ Ø¯Ù„ÙŠÙ„ ğŸ¤— [Datasets tutorial](https://huggingface.co/docs/datasets/load_hub) Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª) Ù„Ù…Ø¹Ø±ÙØ© ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ± Ù…Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³Ø¨:\n+\n+<Tip>\n+\n+Ø§Ø³ØªØ®Ø¯Ù… Ù…Ø¹Ø§Ù…Ù„ `split` Ù…Ù† ğŸ¤— Datasets Ù„ØªØ­Ù…ÙŠÙ„ Ø¹ÙŠÙ†Ø© ØµØºÙŠØ±Ø© ÙÙ‚Ø· Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ø¸Ø±Ù‹Ø§ Ù„Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ¨ÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§!\n+\n+</Tip>\n+\n+```py\n+>>> from datasets import load_dataset\n+\n+>>> dataset = load_dataset(\"food101\", split=\"train[:100]\")\n+```\n+\n+Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ Ø§Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ù…ÙŠØ²Ø© ğŸ¤— Datasets [`Image`](https://huggingface.co/docs/datasets/package_reference/main_classes?highlight=image#datasets.Image):\n+\n+```py\n+>>> dataset[0][\"image\"]\n+```\n+\n+<div class=\"flex justify-center\">\n+    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/vision-preprocess-tutorial.png\"/>\n+</div>\n+\n+Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`AutoImageProcessor.from_pretrained`]:\n+\n+```py\n+>>> from transformers import AutoImageProcessor\n+\n+>>> image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n+```\n+\n+Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø¯Ø¹Ù†Ø§ Ù†Ø¶ÙŠÙ Ø¨Ø¹Ø¶ Ø§Ù„Ø²ÙŠØ§Ø¯Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ Ù…ÙƒØªØ¨Ø© ØªÙØ¶Ù„Ù‡Ø§ØŒ ÙˆÙ„ÙƒÙ† ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ØŒ Ø³Ù†Ø³ØªØ®Ø¯Ù… ÙˆØ­Ø¯Ø© [`transforms`](https://pytorch.org/vision/stable/transforms.html) Ù…Ù† torchvision. Ø¥Ø°Ø§ ÙƒÙ†Øª Ù…Ù‡ØªÙ…Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© Ø²ÙŠØ§Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø®Ø±Ù‰ØŒ ÙØªØ¹Ø±Ù Ø¹Ù„Ù‰ ÙƒÙŠÙÙŠØ© Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ø°Ù„Ùƒ ÙÙŠ [Ø¯ÙØ§ØªØ± Albumentations](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb) Ø£Ùˆ [Ø¯ÙØ§ØªØ± Kornia](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb).\n+\n+1. Ù‡Ù†Ø§ Ù†Ø³ØªØ®Ø¯Ù… [`Compose`](https://pytorch.org/vision/master/generated/torchvision.transforms.Compose.html) Ù„Ø±Ø¨Ø· Ø¨Ø¹Ø¶ Ø§Ù„ØªØ­ÙˆÙ„Ø§Øª Ù…Ø¹Ù‹Ø§ - [`RandomResizedCrop`](https://pytorch.org/vision/main/generated/torchvision.transforms.RandomResizedCrop.html) Ùˆ [`ColorJitter`](https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html).\n+Ù„Ø§Ø­Ø¸ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù…ØŒ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† `image_processor`. Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ ÙŠÙØªÙˆÙ‚Ø¹ Ø§Ø±ØªÙØ§Ø¹ ÙˆØ¹Ø±Ø¶ Ø¯Ù‚ÙŠÙ‚ÙŠÙ†ØŒ Ø¨ÙŠÙ†Ù…Ø§ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£Ø®Ø±Ù‰ØŒ ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯  Ø§Ù„Ø­Ø§ÙØ© Ø§Ù„Ø£Ù‚ØµØ±`shortest_edge` ÙÙ‚Ø·.\n+\n+```py\n+>>> from torchvision.transforms import RandomResizedCrop, ColorJitter, Compose\n+\n+>>> size = (\n+...     image_processor.size[\"shortest_edge\"]\n+...     if \"shortest_edge\" in image_processor.size\n+...     else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n+... )\n+\n+>>> _transforms = Compose([RandomResizedCrop(size), ColorJitter(brightness=0.5, hue=0.5)])\n+```\n+\n+2. ÙŠÙ‚Ø¨Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ [`pixel_values`](model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel.forward.pixel_values)\n+ÙƒØ¥Ø¯Ø®Ø§Ù„ Ù„Ù‡. ÙŠÙ…ÙƒÙ† Ù„Ù€ `ImageProcessor` Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ØµÙˆØ±ØŒ ÙˆØªÙˆÙ„ÙŠØ¯ Ù…ÙˆØªØ±Ø§Øª(tensors) Ù…Ù†Ø§Ø³Ø¨Ø©.\n+Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯Ø§Ù„Ø© ØªØ¬Ù…Ø¹ Ø¨ÙŠÙ† ØªØ¶Ø®ÙŠÙ… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØ± ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„ØµÙˆØ± ÙˆØªÙˆÙ„ÙŠØ¯ `pixel_values`:\n+\n+```py\n+>>> def transforms(examples):\n+...     images = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n+...     examples[\"pixel_values\"] = image_processor(images, do_resize=False, return_tensors=\"pt\")[\"pixel_values\"]\n+...     return examples\n+```\n+\n+<Tip>\n+\n+ÙÙŠ Ø§Ù„Ù…Ø«Ø§Ù„ Ø£Ø¹Ù„Ø§Ù‡ØŒ Ù‚Ù…Ù†Ø§ Ø¨ØªØ¹ÙŠÙŠÙ† `do_resize=False` Ù„Ø£Ù†Ù†Ø§ Ù‚Ù…Ù†Ø§ Ø¨Ø§Ù„ÙØ¹Ù„ Ø¨ØªØºÙŠÙŠØ± Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ± ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØµÙˆØ±ØŒ\n+ÙˆØ§Ø³ØªÙØ¯Ù†Ø§ Ù…Ù† Ø®Ø§ØµÙŠØ© `size` Ù…Ù† `image_processor` Ø§Ù„Ù…Ù†Ø§Ø³Ø¨. Ø¥Ø°Ø§ Ù„Ù… ØªÙ‚Ù… Ø¨ØªØºÙŠÙŠØ± Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ± Ø£Ø«Ù†Ø§Ø¡ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØµÙˆØ±ØŒ\n+ÙØ§ØªØ±Ùƒ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¹Ù„Ù…Ø©. Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠØŒ Ø³ØªØªØ¹Ø§Ù…Ù„ `ImageProcessor` Ù…Ø¹ ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù….\n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ØºØ¨ ÙÙŠ ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ØµÙˆØ± ÙƒØ¬Ø²Ø¡ Ù…Ù† ØªØ­ÙˆÙŠÙ„ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØµÙˆØ±ØŒ ÙØ§Ø³ØªØ®Ø¯Ù… Ù‚ÙŠÙ… `image_processor.image_mean`ØŒ\n+Ùˆ `image_processor.image_std`.\n+</Tip>\n+\n+3. Ø«Ù… Ø§Ø³ØªØ®Ø¯Ù… ğŸ¤— Datasets[`~datasets.Dataset.set_transform`] Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙ„Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ù‚Ù„:\n+```py\n+>>> dataset.set_transform(transforms)\n+```\n+\n+4. Ø§Ù„Ø¢Ù† Ø¹Ù†Ø¯ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©ØŒ Ø³ØªÙ„Ø§Ø­Ø¸ Ø£Ù† Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ± Ù‚Ø¯ Ø£Ø¶Ø§Ù `pixel_values`. ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ…Ø±ÙŠØ± Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¢Ù†!\n+\n+```py\n+>>> dataset[0].keys()\n+```\n+\n+Ù‡ÙƒØ°Ø§ ØªØ¨Ø¯Ùˆ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ø¯ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙ„Ø§Øª. ØªÙ… Ø§Ù‚ØªØµØ§Øµ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø´ÙƒÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ ÙˆØªØ®ØªÙ„Ù Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø¨Ù‡Ø§.\n+\n+```py\n+>>> import numpy as np\n+>>> import matplotlib.pyplot as plt\n+\n+>>> img = dataset[0][\"pixel_values\"]\n+>>> plt.imshow(img.permute(1, 2, 0))\n+```\n+\n+<div class=\"flex justify-center\">\n+    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/preprocessed_image.png\"/>\n+</div>\n+\n+<Tip>\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù…Ù‡Ø§Ù… Ù…Ø«Ù„ Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ØŒ ÙˆØ§Ù„ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©ØŒ ÙˆØ§Ù„ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ù…Ø«Ø§Ù„ÙŠØ©ØŒ ÙˆØ§Ù„ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø©ØŒ ÙŠÙˆÙØ± `ImageProcessor`\n+ØªÙ‚ÙˆÙ… Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±Ù‚ Ø¨ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ÙˆØ§ØªØ¬ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ ØªÙ†Ø¨Ø¤Ø§Øª Ø°Ø§Øª Ù…Ø¹Ù†Ù‰ Ù…Ø«Ù„ Ù…Ø±Ø¨Ø¹Ø§Øª Ø§Ù„Ø­Ø¯ÙˆØ¯ØŒ\n+Ø£Ùˆ Ø®Ø±Ø§Ø¦Ø· Ø§Ù„ØªØ¬Ø²Ø¦Ø©.\n+\n+</Tip>\n+\n+### Ø§Ù„Ø­Ø´Ùˆ Pad\n+\n+ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø­Ø§Ù„Ø§ØªØŒ Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¹Ù†Ø¯ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ [DETR](./model_doc/detr) Ø¨Ø¯Ù‚Ø©ØŒ ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨ØªØ·Ø¨ÙŠÙ‚ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ù‚ÙŠØ§Ø³ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨. Ù‚Ø¯ ÙŠØªØ³Ø¨Ø¨ Ø°Ù„Ùƒ ÙÙŠ Ø§Ø®ØªÙ„Ø§Ù Ø£Ø­Ø¬Ø§Ù… Ø§Ù„ØµÙˆØ± ÙÙŠ Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… [`DetrImageProcessor.pad`]\n+Ù…Ù† [`DetrImageProcessor`] ÙˆØªØ­Ø¯ÙŠØ¯ Ø¯Ø§Ù„Ø© `collate_fn` Ù…Ø®ØµØµØ© Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ± Ù…Ø¹Ù‹Ø§.\n+\n+```py\n+>>> def collate_fn(batch):\n+...     pixel_values = [item[\"pixel_values\"] for item in batch]\n+...     encoding = image_processor.pad(pixel_values, return_tensors=\"pt\")\n+...     labels = [item[\"labels\"] for item in batch]\n+...     batch = {}\n+...     batch[\"pixel_values\"] = encoding[\"pixel_values\"]\n+...     batch[\"pixel_mask\"] = encoding[\"pixel_mask\"]\n+...     batch[\"labels\"] = labels\n+...     return batch\n+```\n+\n+## Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ³Ø§Ø¦Ø· Mulimodal\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØªÙŠ ØªØªØ·Ù„Ø¨ Ù…Ø¯Ø®Ù„Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„ÙˆØ³Ø§Ø¦Ø·ØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø¹Ø§Ù„Ø¬ [processor](main_classes/processors) Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ù„ØªÙ†Ø§Ø³Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ÙŠÙ‚ØªØ±Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø¨ÙŠÙ†  Ø¨Ù…Ø¹Ø§Ù„Ø¬ÙŠÙ† Ø¢Ø®Ø±ÙŠÙ† Ù…Ø«Ù„ Ù…Ø­ÙˆÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø±Ù…Ø² ÙˆÙ…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª.\n+\n+Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª [LJ Speech](https://huggingface.co/datasets/lj_speech) (Ø±Ø§Ø¬Ø¹ Ø¯Ù„ÙŠÙ„ ğŸ¤— [Datasets tutorial](https://huggingface.co/docs/datasets/load_hub) Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª) Ù„Ù…Ø¹Ø±ÙØ© ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù„Ø¬ Ù„Ù„ØªØ¹Ø±Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… (ASR):\n+\n+```py\n+>>> from datasets import load_dataset\n+\n+>>> lj_speech = load_dataset(\"lj_speech\", split=\"train\")\n+```\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù€ ASRØŒ ÙØ£Ù†Øª ØªØ±ÙƒØ² Ø¨Ø´ÙƒÙ„ Ø£Ø³Ø§Ø³ÙŠ Ø¹Ù„Ù‰ `audio` Ùˆ `text` Ù„Ø°Ø§ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø®Ø±Ù‰:\n+\n+```py\n+>>> lj_speech = lj_speech.map(remove_columns=[\"file\", \"id\", \"normalized_text\"])\n+```\n+\n+Ø§Ù„Ø¢Ù† Ø§Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø© `audio` Ùˆ `text`:\n+```py\n+>>> lj_speech = lj_speech.map(remove_columns=[\"file\", \"id\", \"normalized_text\"])\n+```\n+\n+Ø§Ù„Ø¢Ù† Ø§Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø© `audio` Ùˆ `text`:\n+\n+```py\n+>>> lj_speech[0][\"audio\"]\n+{'array': array([-7.3242188e-04, -7.6293945e-04, -6.4086914e-04, ...,\n+         7.3242188e-04,  2.1362305e-04,  6.1035156e-05], dtype=float32),\n+ 'path': '/root/.cache/huggingface/datasets/downloads/extracted/917ece08c95cf0c4115e45294e3cd0dee724a1165b7fc11798369308a465bd26/LJSpeech-1.1/wavs/LJ001-0001.wav',\n+ 'sampling_rate': 22050}\n+\n+>>> lj_speech[0][\"text\"]\n+'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition'\n+```\n+\n+ØªØ°ÙƒØ± Ø£Ù†Ù‡ ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø¯Ø§Ø¦Ù…Ù‹Ø§ [Ø¥Ø¹Ø§Ø¯Ø© Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª](preprocessing#audio) Ù„Ù…Ø¹Ø¯Ù„ Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ÙÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹Ø¯Ù„ Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ÙÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø³Ø¨Ù‚Ù‹Ø§!\n+\n+```py\n+>>> lj_speech = lj_speech.cast_column(\"audio\", Audio(sampling_rate=16_000))\n+```\n+\n+Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`AutoProcessor.from_pretrained`]:\n+\n+```py\n+>>> from transformers import AutoProcessor\n+\n+>>> processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n+```\n+\n+1. Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ `array` Ø¥Ù„Ù‰ `input_values`ØŒ ÙˆØ±Ù…ÙˆØ² `text` Ø¥Ù„Ù‰ `labels`. Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ù„Ù„Ù†Ù…ÙˆØ°Ø¬:\n+\n+```py\n+>>> def prepare_dataset(example):\n+...     audio = example[\"audio\"]\n+\n+...     example.update(processor(audio=audio[\"array\"], text=example[\"text\"], sampling_rate=16000))\n+\n+...     return example\n+```\n+\n+2. Ù‚Ù… Ø¨ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø§Ù„Ø© `prepare_dataset` Ø¹Ù„Ù‰ Ø¹ÙŠÙ†Ø©:\n+\n+```py\n+>>> prepare_dataset(lj_speech[0])\n+```\n+\n+Ù„Ù‚Ø¯ Ø£Ø¶Ø§Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø¢Ù† `input_values` Ùˆ `labels`ØŒ ÙˆØªÙ… Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ø¹Ø§Ø¯Ø© Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ù„Ù…Ø¹Ø¯Ù„ Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ø¥Ù„Ù‰ 16 ÙƒÙŠÙ„Ùˆ Ù‡Ø±ØªØ². ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ…Ø±ÙŠØ± Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¢Ù†!"
        },
        {
            "sha": "9a99c28287d62249240576e67e008cb136bc6e40",
            "filename": "docs/source/ar/quicktour.md",
            "status": "added",
            "additions": 543,
            "deletions": 0,
            "changes": 543,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fquicktour.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Fquicktour.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fquicktour.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,543 @@\n+# Ø¬ÙˆÙ„Ø© Ø³Ø±ÙŠØ¹Ø©\n+\n+[[open-in-colab]]\n+\n+Ø§Ø¨Ø¯Ø£ Ø±Ø­Ù„ØªÙƒ Ù…Ø¹ Ù…ÙƒØªØ¨Ø© ğŸ¤— Transformers! Ø³ÙˆØ§Ø¡ ÙƒÙ†Øª Ù…Ø·ÙˆØ±Ù‹Ø§ Ø£Ùˆ Ù…Ø³ØªØ®Ø¯Ù…Ù‹Ø§ Ø¹Ø§Ø¯ÙŠÙ‹Ø§ØŒ Ø³ØªØ³Ø§Ø¹Ø¯Ùƒ Ù‡Ø°Ù‡ Ø§Ù„Ø¬ÙˆÙ„Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø¯Ø¡ ÙˆØ³ØªÙØ¸Ù‡Ø± Ù„Ùƒ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… [`pipeline`] Ù„Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ØŒ ÙˆØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ÙˆÙ…Ø¹Ø§Ù„Ø¬ Ù…ÙØ³Ø¨Ù‚ Ù…Ø¹ [AutoClass](./model_doc/auto)ØŒ ÙˆØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø³Ø±Ø¹Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyTorch Ø£Ùˆ TensorFlow. Ø¥Ø°Ø§ ÙƒÙ†Øª Ù…Ø¨ØªØ¯Ø¦Ù‹Ø§ØŒ Ù†ÙˆØµÙŠ Ø¨Ø§Ù„Ø§Ø·Ù„Ø§Ø¹ Ø¹Ù„Ù‰ Ø¯Ø±ÙˆØ³Ù†Ø§ Ø£Ùˆ [Ø§Ù„Ø¯ÙˆØ±Ø©](https://huggingface.co/course/chapter1/1) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø´Ø±Ø­ Ø£ÙƒØ«Ø± ØªØ¹Ù…Ù‚Ù‹Ø§ Ù„Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© Ù‡Ù†Ø§.\n+\n+Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡ØŒ ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©:\n+\n+```bash\n+!pip install transformers datasets evaluate accelerate\n+```\n+\n+Ø³ØªØ­ØªØ§Ø¬ Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ù„Ù‰ ØªØ«Ø¨ÙŠØª Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„Ù…ÙØ¶Ù„ Ù„Ø¯ÙŠÙƒ:\n+\n+<frameworkcontent>\n+<pt>\n+\n+```bash\n+pip install torch\n+```\n+</pt>\n+<tf>\n+\n+```bash\n+pip install tensorflow\n+```\n+</tf>\n+</frameworkcontent>\n+\n+## Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨\n+\n+<Youtube id=\"tiZFewofSLM\"/>\n+\n+ÙŠÙ…Ø«Ù„ [`pipeline`] Ø£Ø³Ù‡Ù„ ÙˆØ£Ø³Ø±Ø¹ Ø·Ø±ÙŠÙ‚Ø© Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù„Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… [`pipeline`] Ø¬Ø§Ù‡Ø²Ù‹Ø§ Ù„Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ù‡Ø§Ù… Ø¹Ø¨Ø± Ø·Ø±Ù‚ Ù…Ø®ØªÙ„ÙØ©ØŒ ÙˆØ§Ù„ØªÙŠ ÙŠØ¸Ù‡Ø± Ø¨Ø¹Ø¶Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø£Ø¯Ù†Ø§Ù‡:\n+\n+<Tip>\n+\n+Ù„Ù„Ø§Ø·Ù„Ø§Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…ØªØ§Ø­Ø©ØŒ Ø±Ø§Ø¬Ø¹ [Ù…Ø±Ø¬Ø¹ ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨](./main_classes/pipelines).\n+\n+</Tip>\n+\n+<div dir=\"rtl\">\n+\n+| **Ø§Ù„Ù…Ù‡Ù…Ø©**                     | **Ø§Ù„ÙˆØµÙ**                                                                                              | **Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©**    | **Ù…Ø¹Ø±Ù Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨**                       |\n+|------------------------------|--------------------------------------------------------------------------------------------------------------|-----------------|-----------------------------------------------|\n+| ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Øµ          | ØªØ¹ÙŠÙŠÙ† ØªØ³Ù…ÙŠØ© Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„ Ù†Øµ Ù…Ø¹ÙŠÙ†                                                                   | NLP             | pipeline(task=â€œsentiment-analysisâ€)           |\n+| ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†Øµ              | ØªÙˆÙ„ÙŠØ¯ Ù†Øµ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…ÙˆØ¬Ù‡ Ù…Ø¹ÙŠÙ†                                                                                 | NLP             | pipeline(task=â€œtext-generationâ€)              |\n+| ØªÙ„Ø®ÙŠØµ                | ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ù„ØªØ³Ù„Ø³Ù„ Ù†Øµ Ø£Ùˆ Ù…Ø³ØªÙ†Ø¯                                                         | NLP             | pipeline(task=â€œsummarizationâ€)                |\n+| ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ±         | ØªØ¹ÙŠÙŠÙ† ØªØ³Ù…ÙŠØ© Ù„ØµÙˆØ±Ø© Ù…Ø¹ÙŠÙ†Ø©                                                                                   | Ø±Ø¤ÙŠØ© Ø­Ø§Ø³ÙˆØ¨ÙŠØ© | pipeline(task=â€œimage-classificationâ€)         |\n+| ØªØ¬Ø²Ø¦Ø© Ø§Ù„ØµÙˆØ±Ø©           | ØªØ¹ÙŠÙŠÙ† ØªØ³Ù…ÙŠØ© Ù„ÙƒÙ„ Ø¨ÙƒØ³Ù„ ÙØ±Ø¯ÙŠ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© (ÙŠØ¯Ø¹Ù… Ø§Ù„ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©ØŒ ÙˆØ§Ù„Ù…Ø¬Ù…Ù„Ø©ØŒ ÙˆØªØ¬Ø²Ø¦Ø© Ù…Ø«ÙŠÙ„Ø§Øª) | Ø±Ø¤ÙŠØ© Ø­Ø§Ø³ÙˆØ¨ÙŠØ© | pipeline(task=â€œimage-segmentationâ€)           |\n+| Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø´ÙŠØ§Ø¡             | Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ ÙˆÙØ¦Ø§ØªÙ‡Ø§ ÙÙŠ ØµÙˆØ±Ø© Ù…Ø¹ÙŠÙ†Ø©                                                | Ø±Ø¤ÙŠØ© Ø­Ø§Ø³ÙˆØ¨ÙŠØ© | pipeline(task=â€œobject-detectionâ€)             |\n+| ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØª         | ØªØ¹ÙŠÙŠÙ† ØªØ³Ù…ÙŠØ© Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØµÙˆØªÙŠØ© Ù…Ø¹ÙŠÙ†Ø©                                                                            | ØµÙˆØªÙŠ           | pipeline(task=â€œaudio-classificationâ€)         |\n+| Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ | Ù†Ø³Ø® Ø§Ù„ÙƒÙ„Ø§Ù… Ø¥Ù„Ù‰ Ù†Øµ                                                                                  | ØµÙˆØªÙŠ           | pipeline(task=â€œautomatic-speech-recognitionâ€) |\n+| Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©    | Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø­ÙˆÙ„ Ø§Ù„ØµÙˆØ±Ø©ØŒ Ù…Ø¹ Ø¥Ø¹Ø·Ø§Ø¡ ØµÙˆØ±Ø© ÙˆØ³Ø¤Ø§Ù„                                             | Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ³Ø§Ø¦Ø·      | pipeline(task=â€œvqaâ€)                          |\n+| Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª  | Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ØŒ Ù…Ø¹ Ø¥Ø¹Ø·Ø§Ø¡ Ù…Ø³ØªÙ†Ø¯ ÙˆØ³Ø¤Ø§Ù„                                        | Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ³Ø§Ø¦Ø·      | pipeline(task=\"document-question-answering\")  |\n+| ÙƒØªØ§Ø¨Ø© ØªØ¹Ù„ÙŠÙ‚ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©             | Ø¥Ù†Ø´Ø§Ø¡ ØªØ¹Ù„ÙŠÙ‚ Ø¹Ù„Ù‰ ØµÙˆØ±Ø© Ù…Ø¹ÙŠÙ†Ø©                                                                         | Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ³Ø§Ø¦Ø·      | pipeline(task=\"image-to-text\")                |\n+\n+</div>\n+Ø§Ø¨Ø¯Ø£ Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ù…Ù† [`pipeline`] ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ù‡Ø§. ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ØŒ Ø³ØªØ³ØªØ®Ø¯Ù… Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙŠ ÙƒÙ†Ù…ÙˆØ°Ø¬:\n+\n+```py\n+>>> from transformers import pipeline\n+\n+>>> classifier = pipeline(\"sentiment-analysis\")\n+```\n+\n+ÙŠÙ‚ÙˆÙ… [`pipeline`] Ø¨ØªÙ†Ø²ÙŠÙ„ ÙˆØªØ®Ø²ÙŠÙ† Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ø§ÙØªØ±Ø§Ø¶ÙŠ [Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english) ÙˆÙ…Ø¹Ø§Ù„Ø¬ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙŠ. Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… `classifier` Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù:\n+\n+```py\n+>>> classifier(\"We are very happy to show you the ğŸ¤— Transformers library.\")\n+[{'label': 'POSITIVE', 'score': 0.9998}]\n+```\n+\n+Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒ Ø£ÙƒØ«Ø± Ù…Ù† Ø¥Ø¯Ø®Ø§Ù„ ÙˆØ§Ø­Ø¯ØŒ Ù‚Ù… Ø¨ØªÙ…Ø±ÙŠØ± Ø¥Ø¯Ø®Ø§Ù„Ø§ØªÙƒ ÙƒÙ‚Ø§Ø¦Ù…Ø© Ø¥Ù„Ù‰ [`pipeline`] Ù„Ø¥Ø±Ø¬Ø§Ø¹ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³:\n+\n+```py\n+>>> results = classifier([\"We are very happy to show you the ğŸ¤— Transformers library.\", \"We hope you don't hate it.\"])\n+>>> for result in results:\n+...     print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n+label: POSITIVE, with score: 0.9998\n+label: NEGATIVE, with score: 0.5309\n+```\n+ÙŠÙ…ÙƒÙ† Ù„Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø£ÙŠØ¶Ù‹Ø§ Ø£Ù† ÙŠØªÙ†Ù‚Ù„ Ø®Ù„Ø§Ù„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§Ù…Ù„Ø© Ù„Ø£ÙŠ Ù…Ù‡Ù…Ø© ØªØ±ÙŠØ¯Ù‡Ø§. ÙƒÙ…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø°Ù„ÙƒØŒ Ø¯Ø¹Ù†Ø§ Ù†Ø®ØªØ§Ø± Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙƒÙ…Ù‡Ù…Ø© Ù„Ù†Ø§:\n+\n+```py\n+>>> import torch\n+>>> from transformers import pipeline\n+\n+>>> speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")\n+```\n+\n+Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ØµÙˆØªÙŠØ© (Ø±Ø§Ø¬Ø¹ Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹ Ù„Ù€ ğŸ¤— Datasets [Quick Start](https://huggingface.co/docs/datasets/quickstart#audio) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„) Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø§Ù„ØªÙ†Ù‚Ù„ Ø®Ù„Ø§Ù„Ù‡Ø§. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14):\n+\n+```py\n+>>> from datasets import load_dataset, Audio\n+\n+>>> dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")  # doctest: +IGNORE_RESULT\n+```\n+\n+ÙŠØ¬Ø¨ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù†ÙØ³ Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØªÙŠØ© (Ù…Ø¹Ø¯Ù„ Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª) Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ù…Ø¹Ø¯Ù„ Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ø°ÙŠ ØªÙ… ØªØ¯Ø±ÙŠØ¨ [`facebook/wav2vec2-base-960h`](https://huggingface.co/facebook/wav2vec2-base-960h) Ø¹Ù„ÙŠÙ‡:\n+\n+```py\n+>>> dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))\n+```\n+\n+ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„Ù‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¹Ù†Ø¯ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø¹Ù…ÙˆØ¯ \"audio\".\n+Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ØµÙÙˆÙØ§Øª Ø§Ù„Ù…ÙˆØ¬ÙŠØ© Ø§Ù„Ø®Ø§Ù… Ù…Ù† Ø£ÙˆÙ„ 4 Ø¹ÙŠÙ†Ø§Øª ÙˆÙ…Ø±Ø±Ù‡Ø§ ÙƒÙ‚Ø§Ø¦Ù…Ø© Ø¥Ù„Ù‰ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨:\n+\n+```py\n+>>> result = speech_recognizer(dataset[:4][\"audio\"])\n+>>> print([d[\"text\"] for d in result])\n+['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I FURN A JOINA COUT']\n+```\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©  Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¯Ø®Ù„Ø§Øª Ø¶Ø®Ù…Ø© (ÙƒÙ…Ø§ Ù‡Ùˆ Ø§Ù„Ø­Ø§Ù„ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø£Ùˆ Ø§Ù„Ù…Ø±Ø¦ÙŠØ©)ØŒ ÙŠÙØ¶Ù„ ØªÙ…Ø±ÙŠØ± Ù…ÙˆÙ„Ø¯ (generator) Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ù„ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©. Ø±Ø§Ø¬Ø¹ [Ù…Ø±Ø¬Ø¹ ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨](./main_classes/pipelines) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª.\n+\n+### Ø§Ø§Ø³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ ÙˆÙ…Ø¬Ø²Ø¦Ù‹Ø§ Ø¢Ø®Ø±ÙŠÙ† ÙÙŠ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨\n+\n+ÙŠÙ…ÙƒÙ† Ù„Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ [`pipeline`] Ø§Ø³ØªÙŠØ¹Ø§Ø¨ Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† [Hub](https://huggingface.co/models)ØŒ Ù…Ù…Ø§ ÙŠØ³Ù‡Ù„ Ø§Ù„ØªÙƒÙŠÙ Ù…Ø¹ Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ Ù‚Ø§Ø¯Ø±Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„ÙØ±Ù†Ø³ÙŠØŒ ÙØ§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø¹Ù„Ù‰ Hub Ù„ÙÙ„ØªØ±Ù‡ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†Ø§Ø³Ø¨. ØªØ¹ÙŠØ¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø§Ù„Ù…Ø±Ø´Ø­Ø© Ù†Ù…ÙˆØ°Ø¬ BERT Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª [BERT model](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment) Ø§Ù„Ø°ÙŠ ØªÙ… Ø¶Ø¨Ø·Ù‡ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ§Ù„Ø°ÙŠ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ù„Ù†Øµ Ø§Ù„ÙØ±Ù†Ø³ÙŠ:\n+\n+```py\n+>>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n+```\n+\n+<frameworkcontent>\n+<pt>\n+Ø§Ø³ØªØ®Ø¯Ù… [`AutoModelForSequenceClassification`] Ùˆ [`AutoTokenizer`] Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡ Ø§Ù„Ù…Ø±ØªØ¨Ø· Ø¨Ù‡ (Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ `AutoClass` ÙÙŠ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„ØªØ§Ù„ÙŠ):\n+\n+```py\n+>>> from transformers import AutoTokenizer, AutoModelForSequenceClassification\n+\n+>>> model = AutoModelForSequenceClassification.from_pretrained(model_name)\n+>>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n+```\n+</pt>\n+<tf>\n+Ø§Ø³ØªØ®Ø¯Ù… [`TFAutoModelForSequenceClassification`] Ùˆ [`AutoTokenizer`] Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡ Ø§Ù„Ù…Ø±ØªØ¨Ø· Ø¨Ù‡ (Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ `TFAutoClass` ÙÙŠ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„ØªØ§Ù„ÙŠ):\n+\n+```py\n+>>> from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n+\n+>>> model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n+>>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n+```\n+</tf>\n+</frameworkcontent>\n+\n+Ø­Ø¯Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬ ÙÙŠ [`pipeline`]. Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ ØªØ·Ø¨ÙŠÙ‚ `classifier` Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„ÙØ±Ù†Ø³ÙŠ:\n+\n+```py\n+>>> classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n+>>> classifier(\"Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ğŸ¤— Transformers.\")\n+[{'label': '5 stars', 'score': 0.7273}]\n+```\n+Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ Ø¬Ø§Ù‡Ø²Ù‹Ø§ ÙŠÙ†Ø§Ø³Ø¨ Ù…Ù‡Ù…ØªÙƒØŒ ÙØ³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ. Ø§Ø·Ù„Ø¹ Ø¹Ù„Ù‰ [Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¶Ø¨Ø· Ø§Ù„Ø¯Ù‚ÙŠÙ‚](./training) Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ ÙƒÙŠÙÙŠØ© Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ø°Ù„Ùƒ. ÙˆØ¨Ø¹Ø¯ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø§Ù„Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ØŒ ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¹Ø§Ø© [Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ©](./model_sharing) Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ Ø¹Ù„Ù‰ Hub Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¬Ù…ÙŠØ¹ ÙÙŠ Ù…Ø¬Ø§Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ! ğŸ¤—\n+\n+## AutoClass\n+\n+<Youtube id=\"AhChOFRegn4\"/>\n+\n+ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©ØŒ ØªØ¹Ù…Ù„ ÙØ¦ØªØ§ [`AutoModelForSequenceClassification`] Ùˆ [`AutoTokenizer`] Ù…Ø¹Ù‹Ø§ Ù„ØªØ´ØºÙŠÙ„ Ø¯Ø§Ù„Ø© pipeline()  Ø§Ù„Ø°ÙŠ Ø§Ø³ØªØ®Ø¯Ù…ØªÙ‡Ø§ Ø£Ø¹Ù„Ø§Ù‡. ØªØ¹ØªØ¨Ø± [AutoClass](./model_doc/auto) Ø§Ø®ØªØµØ§Ø±Ù‹Ø§ ÙŠÙ‚ÙˆÙ… ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¨Ø§Ø³ØªØ±Ø¯Ø§Ø¯ Ø¨Ù†ÙŠØ© Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù…Ù† Ø§Ø³Ù…Ù‡ Ø£Ùˆ Ù…Ø³Ø§Ø±Ù‡. ÙƒÙ„ Ù…Ø§ Ø¹Ù„ÙŠÙƒ ÙØ¹Ù„Ù‡ Ù‡Ùˆ ØªØ­Ø¯ÙŠØ¯ ÙØ¦Ø© `AutoClass` Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù…Ù‡Ù…ØªÙƒ ÙˆÙØ¦Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ù‡Ø§.\n+\n+Ù„Ù†Ø¹Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø«Ø§Ù„ Ù…Ù† Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø³Ø§Ø¨Ù‚ ÙˆÙ„Ù†Ø±Ù‰ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… `AutoClass` Ù„ØªÙƒØ±Ø§Ø± Ù†ØªØ§Ø¦Ø¬ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨.\n+\n+### Ø§Ù„Ù…Ø¬Ø²Ø¦ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (AutoTokenizer)\n+\n+ÙŠØªÙˆÙ„Ù‰ Ø§Ù„Ù…Ø¬Ø²Ø¦ Ù…Ø³Ø¤ÙˆÙ„ÙŠØ© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© Ù…Ù† Ø§Ù„Ø£Ø±Ù‚Ø§Ù… (Ø±Ù…ÙˆØ²) ÙŠÙ…ÙƒÙ† Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙ‡Ù…Ù‡Ø§ ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§. Ù‡Ù†Ø§Ùƒ Ù‚ÙˆØ§Ø¹Ø¯ Ù…ØªØ¹Ø¯Ø¯Ø© ØªØ­ÙƒÙ… Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¬Ø²Ø¦Ø©ØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ ÙƒÙŠÙÙŠØ© ØªÙ‚Ø³ÙŠÙ… ÙƒÙ„Ù…Ø© ÙˆÙ…Ø§ Ù‡Ùˆ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø°ÙŠ ÙŠØ¬Ø¨ Ø£Ù† ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¹Ù†Ø¯Ù‡ (ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø²ÙŠØ¯ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ [Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø¬Ø²Ø¦](./tokenizer_summary)). Ø£Ù‡Ù… Ø´ÙŠØ¡ ÙŠØ¬Ø¨ ØªØ°ÙƒØ±Ù‡ Ù‡Ùˆ Ø£Ù†Ùƒ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ù„Ù„Ù…Ø¬Ø²Ø¦ Ø¨Ù†ÙØ³ Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø¶Ù…Ø§Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ùƒ Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ¬Ø²Ø¦Ø© Ù†ÙØ³Ù‡Ø§ Ø§Ù„ØªÙŠ ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„ÙŠÙ‡Ø§.\n+\n+Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¬Ø²Ø¦ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`AutoTokenizer`]:\n+\n+```py\n+>>> from transformers import AutoTokenizer\n+\n+>>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n+>>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n+```\n+\n+Ù…Ø±Ø± Ù†ØµÙƒ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¬Ø²Ø¦:\n+\n+```py\n+>>> encoding = tokenizer(\"We are very happy to show you the ğŸ¤— Transformers library.\")\n+>>> print(encoding)\n+{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102],\n+ 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n+ 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n+```\n+\n+ÙŠØ¹ÙŠØ¯ Ø§Ù„Ù…Ø¬Ø²Ø¦ Ù‚Ø§Ù…ÙˆØ³Ù‹Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:\n+\n+* [input_ids](./glossary#input-ids): Ø§Ù„ØªÙ…Ø«ÙŠÙ„Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ù„Ø±Ù…ÙˆØ²Ùƒ.\n+* [attention_mask](./glossary#attention-mask): ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ø¨Ù‡Ø§.\n+\n+ÙŠÙ…ÙƒÙ† Ø§Ù„Ù…Ø¬Ø²Ø¦ Ø£ÙŠØ¶Ù‹Ø§ Ù‚Ø¨ÙˆÙ„ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§ØªØŒ ÙˆÙŠÙ‚ÙˆÙ… Ø¨Ù€ \"Ø­Ø´Ùˆ\" Ùˆ\"ØªÙ‚ØµÙŠØ±\" Ø§Ù„Ù†Øµ Ù„Ø¥Ø±Ø¬Ø§Ø¹ ÙƒØ¯ÙØ¹Ø© Ø¨Ø·ÙˆÙ„ Ù…ÙˆØ­Ø¯:\n+\n+<frameworkcontent>\n+<pt>\n+\n+```py\n+>>> pt_batch = tokenizer(\n+...     [\"We are very happy to show you the ğŸ¤— Transformers library.\", \"We hope you don't hate it.\"],\n+...     padding=True,\n+...     truncation=True,\n+...     max_length=512,\n+...     return_tensors=\"pt\",\n+... )\n+```\n+</pt>\n+<tf>\n+\n+```py\n+>>> tf_batch = tokenizer(\n+...     [\"We are very happy to show you the ğŸ¤— Transformers library.\", \"We hope you don't hate it.\"],\n+...     padding=True,\n+...     truncation=True,\n+...     max_length=512,\n+...     return_tensors=\"tf\",\n+... )\n+```\n+</tf>\n+</frameworkcontent>\n+\n+<Tip>\n+\n+Ø§Ø·Ù„Ø¹ Ø¹Ù„Ù‰ [Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªÙ…Ù‡ÙŠØ¯ÙŠ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©](./preprocessing) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©ØŒ ÙˆÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… [`AutoImageProcessor`] Ùˆ [`AutoFeatureExtractor`] Ùˆ [`AutoProcessor`] Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ØµÙˆØª ÙˆØ§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„ÙˆØ³Ø§Ø¦Ø·.\n+\n+</Tip>\n+\n+### AutoModel\n+\n+<frameworkcontent>\n+<pt>\n+ØªÙ‚Ø¯Ù… Ù…ÙƒØªØ¨Ø© ğŸ¤— Transformers Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø© ÙˆÙ…ÙˆØ­Ø¯Ø© Ù„ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§. ÙˆÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ [`AutoModel`] ÙƒÙ…Ø§ Ù„Ùˆ ÙƒÙ†Øª ØªÙ‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„ [`AutoTokenizer`]. Ø§Ù„ÙØ±Ù‚ Ø§Ù„ÙˆØ­ÙŠØ¯ Ù‡Ùˆ Ø§Ø®ØªÙŠØ§Ø± ÙØ¦Ø© [`AutoModel`] Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ù…Ù‡Ù…Ø©. Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Øµ (Ø£Ùˆ Ø§Ù„ØªØ³Ù„Ø³Ù„)ØŒ ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ ØªØ­Ù…ÙŠÙ„ [`AutoModelForSequenceClassification`]:\n+\n+```py\n+>>> from transformers import AutoModelForSequenceClassification\n+\n+>>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n+>>> pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n+```\n+\n+<Tip>\n+\n+Ø±Ø§Ø¬Ø¹ [Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ù‡Ù…Ø©](./task_summary) Ù„Ù„Ø§Ø·Ù„Ø§Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØªÙŠ ØªØ¯Ø¹Ù…Ù‡Ø§ ÙØ¦Ø© [`AutoModel`].\n+\n+</Tip>\n+\n+Ø§Ù„Ø¢Ù† Ù‚Ù… Ø¨ØªÙ…Ø±ÙŠØ± Ø¯ÙØ¹Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù…ÙØ¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ø¹Ù„ÙŠÙƒ ÙÙ‚Ø· ÙÙƒ ØªØ¹Ø¨Ø¦Ø© Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø¥Ø¶Ø§ÙØ© `**`:\n+\n+# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n+\n+Ø§Ù„Ø¢Ù†ØŒ Ù…Ø±Ø± Ø¯ÙØ¹Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ù…Ø§ Ø¹Ù„ÙŠÙƒ Ø³ÙˆÙ‰ ÙÙƒ ØªØ¹Ø¨Ø¦Ø© Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø¥Ø¶Ø§ÙØ© `**`:\n+\n+```py\n+>>> pt_outputs = pt_model(**pt_batch)\n+```\n+\n+ÙŠÙØ®Ø±Ø¬ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙ†Ø´ÙŠØ·Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ÙÙŠ Ø³Ù…Ø© `logits`. Ø·Ø¨Ù‚ Ø¯Ø§Ù„Ø© softmax Ø¹Ù„Ù‰ `logits` Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª:\n+\n+```py\n+>>> from torch import nn\n+\n+>>> pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n+>>> print(pt_predictions)\n+tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n+        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n+```\n+</pt>\n+<tf>\n+ÙŠÙˆÙØ± ğŸ¤— Transformers Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø© ÙˆÙ…ÙˆØ­Ø¯Ø© Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ø«ÙŠÙ„Ø§Øª Ù…ÙØ¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§. ÙˆÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ [`TFAutoModel`] Ù…Ø«Ù„ ØªØ­Ù…ÙŠÙ„ [`AutoTokenizer`]. ÙˆØ§Ù„ÙØ±Ù‚ Ø§Ù„ÙˆØ­ÙŠØ¯ Ù‡Ùˆ ØªØ­Ø¯ÙŠØ¯ [`TFAutoModel`] Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù„Ù…Ù‡Ù…Ø©. Ù„Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙŠ (Ø£Ùˆ Ø§Ù„ØªØ³Ù„Ø³Ù„ÙŠ)ØŒ ÙŠØ¬Ø¨ ØªØ­Ù…ÙŠÙ„ [`TFAutoModelForSequenceClassification`]:\n+\n+```py\n+>>> from transformers import TFAutoModelForSequenceClassification\n+\n+>>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n+>>> tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n+```\n+\n+<Tip>\n+\n+Ø±Ø§Ø¬Ø¹ [Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ù‡Ø§Ù…](./task_summary) Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© Ø¨ÙˆØ§Ø³Ø·Ø© ÙØ¦Ø© [`AutoModel`].\n+\n+</Tip>\n+\n+Ø§Ù„Ø¢Ù†ØŒ Ù…Ø±Ø± Ø¯ÙØ¹Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù…ØµÙÙˆÙØ§Øª ÙƒÙ…Ø§ Ù‡ÙŠ:\n+\n+```py\n+>>> tf_outputs = tf_model(tf_batch)\n+```\n+\n+ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„ØªÙ†Ø´ÙŠØ·Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ÙÙŠ Ø³Ù…Ø© `logits`. Ø·Ø¨Ù‚ Ø¯Ø§Ù„Ø© softmax Ø¹Ù„Ù‰ `logits` Ù„Ø§Ø³ØªØ±Ø¯Ø§Ø¯ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª:\n+\n+```py\n+>>> import tensorflow as tf\n+\n+>>> tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)\n+>>> tf_predictions  # doctest: +IGNORE_RESULT\n+```\n+</tf>\n+</frameworkcontent>\n+\n+<Tip>\n+\n+ØªØ®Ø±Ø¬ Ø¬Ù…ÙŠØ¹ Ù†Ù…Ø§Ø°Ø¬ ğŸ¤— Transformers (PyTorch Ø£Ùˆ TensorFlow) Ø§Ù„Ù…ØµÙÙˆÙØ§Øª *Ù‚Ø¨Ù„* Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø´ÙŠØ· Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© (Ù…Ø«Ù„ softmax) Ù„Ø£Ù† Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø´ÙŠØ· Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ØªÙƒÙˆÙ† Ù…Ø¯Ù…Ø¬Ø© Ù…Ø¹ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø©. Ù†ÙˆØ§ØªØ¬ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† ÙØ¦Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø§ØµØ©ØŒ Ù„Ø°Ù„Ùƒ ÙŠØªÙ… Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ø³Ù…Ø§ØªÙ‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ ÙÙŠ IDE. ÙˆØªØªØµØ±Ù Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø«Ù„ Ø²ÙˆØ¬ Ù…Ø±ØªØ¨ Ø£Ùˆ Ù‚Ø§Ù…ÙˆØ³ (ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ÙÙ‡Ø±Ø³Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ø¯Ø¯ ØµØ­ÙŠØ­ ØŒ Ø´Ø±ÙŠØ­Ø©ØŒ Ø£Ùˆ Ø³Ù„Ø³Ù„Ø©)ØŒ ÙˆÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø©ØŒ ÙŠØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø³Ù…Ø§Øª Ø§Ù„ØªÙŠ ØªØ³Ø§ÙˆÙŠ None.\n+\n+</Tip>\n+\n+### Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n+\n+<frameworkcontent>\n+<pt>\n+Ø¨Ù…Ø¬Ø±Ø¯ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ÙƒØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø­ÙØ¸Ù‡ Ù…Ø¹ Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ² Ø§Ù„Ø®Ø§Øµ Ø¨Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`PreTrainedModel.save_pretrained`]:\n+\n+```py\n+>>> pt_save_directory = \"./pt_save_pretrained\"\n+>>> tokenizer.save_pretrained(pt_save_directory)  # doctest: +IGNORE_RESULT\n+>>> pt_model.save_pretrained(pt_save_directory)\n+```\n+\n+Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† Ù…Ø³ØªØ¹Ø¯Ù‹Ø§ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ØŒ Ø£Ø¹Ø¯ ØªØ­Ù…ÙŠÙ„Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`PreTrainedModel.from_pretrained`]:\n+\n+```py\n+>>> pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")\n+```\n+</pt>\n+<tf>\n+Ø¨Ù…Ø¬Ø±Ø¯ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ÙƒØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø­ÙØ¸Ù‡ Ù…Ø¹ Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ² Ø§Ù„Ø®Ø§Øµ Ø¨Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`TFPreTrainedModel.save_pretrained`]:\n+\n+```py\n+>>> tf_save_directory = \"./tf_save_pretrained\"\n+>>> tokenizer.save_pretrained(tf_save_directory)  # doctest: +IGNORE_RESULT\n+>>> tf_model.save_pretrained(tf_save_directory)\n+```\n+\n+Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† Ù…Ø³ØªØ¹Ø¯Ù‹Ø§ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ØŒ Ø£Ø¹Ø¯ ØªØ­Ù…ÙŠÙ„Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`TFPreTrainedModel.from_pretrained`]:\n+\n+```py\n+>>> tf_model = TFAutoModelForSequenceClassification.from_pretrained(\"./tf_save_pretrained\")\n+```\n+</tf>\n+</frameworkcontent>\n+\n+Ù…Ù† Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø§Ø¦Ø¹Ø© ÙÙŠ ğŸ¤— Transformers Ø§Ù„Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ Ø­ÙØ¸ Ù†Ù…ÙˆØ°Ø¬ ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„Ù‡ ÙƒÙ†Ù…ÙˆØ°Ø¬ PyTorch Ø£Ùˆ TensorFlow. ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ­ÙˆÙ„ Ù…Ø¹Ø§Ù…Ù„ `from_pt` Ø£Ùˆ `from_tf` Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ø¥Ù„Ù‰ Ø¢Ø®Ø±:\n+\n+<frameworkcontent>\n+<pt>\n+\n+```py\n+>>> from transformers import AutoModel\n+\n+>>> tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)\n+>>> pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)\n+```\n+</pt>\n+<tf>\n+\n+```py\n+>>> from transformers import TFAutoModel\n+\n+>>> tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n+>>> tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)\n+```\n+</tf>\n+</frameworkcontent>\n+\n+\n+## Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…Ø§Ø°Ø¬ Ù…Ø®ØµØµØ©\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„ ÙØ¦Ø© ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØºÙŠÙŠØ± ÙƒÙŠÙÙŠØ© Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ÙŠØ­Ø¯Ø¯ Ø§Ù„ØªÙƒÙˆÙŠÙ† Ø³Ù…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ Ù…Ø«Ù„ Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù…Ø®ÙÙŠØ© Ø£Ùˆ Ø±Ø¤ÙˆØ³ Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù…. ØªØ¨Ø¯Ø£ Ù…Ù† Ø§Ù„ØµÙØ± Ø¹Ù†Ø¯ ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† ÙØ¦Ø© ØªÙƒÙˆÙŠÙ† Ù…Ø®ØµØµØ©. ÙŠØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø³Ù…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø´ÙƒÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠØŒ ÙˆÙŠØ¬Ø¨ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‚Ø¨Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø°Ø§Øª Ù…Ø¹Ù†Ù‰.\n+\n+Ø§Ø¨Ø¯Ø£ Ø¨Ø§Ø³ØªÙŠØ±Ø§Ø¯ [`AutoConfig`]. Ø«Ù… Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ ØªØ¹Ø¯ÙŠÙ„Ù‡. Ø¶Ù…Ù† [`AutoConfig.from_pretrained`]. ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ù…Ø© Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ ØªØºÙŠÙŠØ±Ù‡Ø§ØŒ Ù…Ø«Ù„ Ø¹Ø¯Ø¯ Ø±Ø¤ÙˆØ³ Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù…:\n+\n+```py\n+>>> from transformers import AutoConfig\n+\n+>>> my_config = AutoConfig.from_pretrained(\"distilbert/distilbert-base-uncased\", n_heads=12)\n+```\n+\n+<frameworkcontent>\n+<pt>\n+Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† ØªÙƒÙˆÙŠÙ†Ùƒ Ø§Ù„Ù…Ø®ØµØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`AutoModel.from_config`]:\n+\n+```py\n+>>> from transformers import AutoModel\n+\n+>>> my_model = AutoModel.from_config(my_config)\n+```\n+</pt>\n+<tf>\n+Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† ØªÙƒÙˆÙŠÙ†Ùƒ Ø§Ù„Ù…Ø®ØµØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`TFAutoModel.from_config`]:\n+\n+```py\n+>>> from transformers import TFAutoModel\n+\n+>>> my_model = TFAutoModel.from_config(my_config)\n+```\n+</tf>\n+</frameworkcontent>\n+\n+Ø§Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø¯Ù„ÙŠÙ„ [Ø¥Ù†Ø´Ø§Ø¡ Ø¨Ù†ÙŠØ© Ù…Ø®ØµØµØ©](./create_a_model) Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ Ø¨Ù†Ø§Ø¡ Ø§Ù„ØªÙƒÙˆÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø®ØµØµØ©.\n+\n+## Ø§Ù„Ù…Ø¯Ø±Ø¨ - Ø­Ù„Ù‚Ø© ØªØ¯Ø±ÙŠØ¨ Ù…Ø­Ø³Ù†Ø© Ù„Ù€ PyTorch\n+\n+Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† [`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) Ù‚ÙŠØ§Ø³ÙŠØ©ØŒ Ù„Ø°Ø§ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ Ø£ÙŠ Ø­Ù„Ù‚Ø© ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ÙŠØ©. ÙÙŠ Ø­ÙŠÙ† ÙŠÙ…ÙƒÙ†Ùƒ ÙƒØªØ§Ø¨Ø© Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨ÙƒØŒ ÙŠÙˆÙØ± ğŸ¤— Transformers ÙØ¦Ø© [`Trainer`] Ù„Ù€ PyTorchØŒ ÙˆØ§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØªØ¶ÙŠÙ ÙˆØ¸Ø§Ø¦Ù Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù…ÙŠØ²Ø§Øª Ù…Ø«Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ²Ø¹ØŒ ÙˆØ§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…Ø®ØªÙ„Ø·Ø©ØŒ ÙˆØ§Ù„Ù…Ø²ÙŠØ¯.\n+\n+ÙˆÙÙ‚Ù‹Ø§ Ù„Ù…Ù‡Ù…ØªÙƒØŒ Ø³ØªÙ‚ÙˆÙ… Ø¹Ø§Ø¯Ø©Ù‹ Ø¨ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¥Ù„Ù‰ [`Trainer`]:\n+\n+1. Ø³ØªØ¨Ø¯Ø£ Ø¨Ù€ [`PreTrainedModel`] Ø£Ùˆ [`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module):\n+\n+   ```py\n+   >>> from transformers import AutoModelForSequenceClassification\n+\n+   >>> model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n+   ```\n+\n+2. ØªØ­ØªÙˆÙŠ [`TrainingArguments`] Ø¹Ù„Ù‰ ÙØ±Ø· Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ†Ùƒ ØªØºÙŠÙŠØ±Ù‡Ø§ Ù…Ø«Ù„ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…ØŒ ÙˆØ­Ø¬Ù… Ø§Ù„Ø¯ÙØ¹Ø©ØŒ ÙˆØ¹Ø¯Ø¯ Ø§Ù„Ø¹ØµÙˆØ± Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„ÙŠÙ‡Ø§. ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ØªØ­Ø¯Ø¯ Ø£ÙŠ Ø­Ø¬Ø¬ ØªØ¯Ø±ÙŠØ¨:\n+\n+   ```py\n+   >>> from transformers import TrainingArguments\n+\n+   >>> training_args = TrainingArguments(\n+   ...     output_dir=\"path/to/save/folder/\",\n+   ...     learning_rate=2e-5,\n+   ...     per_device_train_batch_size=8,\n+   ...     per_device_eval_batch_size=8,\n+   ...     num_train_epochs=2,\n+   ... )\n+   ```\n+\n+3. Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ ÙØ¦Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ù…Ø«Ù„ Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ²ØŒ Ø£Ùˆ Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ±ØŒ Ø£Ùˆ Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§ØªØŒ Ø£Ùˆ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬:\n+\n+   ```py\n+   >>> from transformers import AutoTokenizer\n+\n+   >>> tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n+   ```\n+\n+4. Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª:\n+\n+   ```py\n+   >>> from datasets import load_dataset\n+\n+   >>> dataset = load_dataset(\"rotten_tomatoes\")  # doctest: +IGNORE_RESULT\n+   ```\n+\n+5. Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù„ØªØ±Ù…ÙŠØ² Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n+\n+   ```py\n+   >>> def tokenize_dataset(dataset):\n+   ...     return tokenizer(dataset[\"text\"])\n+   ```\n+\n+   Ø«Ù… Ù‚Ù… Ø¨ØªØ·Ø¨ÙŠÙ‚Ù‡ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`~datasets.Dataset.map`]:\n+\n+   ```py\n+   >>> dataset = dataset.map(tokenize_dataset, batched=True)\n+   ```\n+\n+6. [`DataCollatorWithPadding`] Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ:\n+\n+   ```py\n+   >>> from transformers import DataCollatorWithPadding\n+\n+   >>> data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n+   ```\n+\n+Ø§Ù„Ø¢Ù† Ù‚Ù… Ø¨ØªØ¬Ù…ÙŠØ¹ Ø¬Ù…ÙŠØ¹ Ù‡Ø°Ù‡ Ø§Ù„ÙØ¦Ø§Øª ÙÙŠ [`Trainer`]:\n+\n+```py\n+>>> from transformers import Trainer\n+\n+>>> trainer = Trainer(\n+...     model=model,\n+...     args=training_args,\n+...     train_dataset=dataset[\"train\"],\n+...     eval_dataset=dataset[\"test\"],\n+...     tokenizer=tokenizer,\n+...     data_collator=data_collator,\n+... )  # doctest: +SKIP\n+```\n+Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† Ù…Ø³ØªØ¹Ø¯Ù‹Ø§ØŒ Ø§Ø³ØªØ¯Ø¹Ù [`~Trainer.train`] Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨:\n+\n+```py\n+>>> trainer.train()  # doctest: +SKIP\n+```\n+\n+<Tip>\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù…Ù‡Ø§Ù… - Ù…Ø«Ù„ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø£Ùˆ Ø§Ù„ØªÙ„Ø®ÙŠØµ - Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬ ØªØ³Ù„Ø³Ù„ Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„ØŒ Ø§Ø³ØªØ®Ø¯Ù… ÙØ¦Ø§Øª [`Seq2SeqTrainer`] Ùˆ [`Seq2SeqTrainingArguments`] Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„Ùƒ.\n+\n+</Tip>\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ ØªØ®ØµÙŠØµ Ø³Ù„ÙˆÙƒ Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø¥Ù†Ø´Ø§Ø¡ ÙØ¦Ø© ÙØ±Ø¹ÙŠØ© Ù…Ù† Ø§Ù„Ø·Ø±Ù‚ Ø¯Ø§Ø®Ù„ [`Trainer`]. ÙŠØ³Ù…Ø­ Ù„Ùƒ Ø°Ù„Ùƒ Ø¨ØªØ®ØµÙŠØµ Ù…ÙŠØ²Ø§Øª Ù…Ø«Ù„ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø©ØŒ ÙˆØ§Ù„Ù…Ø­Ø³Ù†ØŒ ÙˆØ§Ù„Ù…Ø¬Ø¯ÙˆÙ„. Ø±Ø§Ø¬Ø¹ Ù…Ø±Ø¬Ø¹ [`Trainer`] Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ ÙØ¦Ø§Øª ÙØ±Ø¹ÙŠØ© Ù…Ù†Ù‡Ø§.\n+\n+ÙˆØ§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø®Ø±Ù‰ Ù„ØªØ®ØµÙŠØµ Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù‡ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [Ø§Ù„Ù…Ø³ØªØ¯Ø¹ÙŠØ§Øª](./main_classes/callback). ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³ØªØ¯Ø¹ÙŠØ§Øª Ù„Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ ÙˆÙ…Ø±Ø§Ù‚Ø¨Ø© Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù„Ø¥Ø¨Ù„Ø§Øº Ø¹Ù† Ø§Ù„ØªÙ‚Ø¯Ù… Ø£Ùˆ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ø¨ÙƒØ±Ù‹Ø§. Ù„Ø§ ØªØ¹Ø¯Ù„ Ø§Ù„Ù…Ø³ØªØ¯Ø¹ÙŠØ§Øª Ø£ÙŠ Ø´ÙŠØ¡ ÙÙŠ Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù†ÙØ³Ù‡Ø§. Ù„ØªØ®ØµÙŠØµ Ø´ÙŠØ¡ Ù…Ø«Ù„ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø©ØŒ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¥Ù†Ø´Ø§Ø¡ ÙØ¦Ø© ÙØ±Ø¹ÙŠØ© Ù…Ù† [`Trainer`] Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„Ùƒ.\n+\n+## Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… TensorFlow\n+\n+Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) Ù‚ÙŠØ§Ø³ÙŠØ©ØŒ Ù„Ø°Ø§ ÙŠÙ…ÙƒÙ† ØªØ¯Ø±ÙŠØ¨Ù‡Ø§ ÙÙŠ TensorFlow Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Keras. ÙŠÙˆÙØ± ğŸ¤— Transformers Ø·Ø±ÙŠÙ‚Ø© [`~TFPreTrainedModel.prepare_tf_dataset`] Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø¨Ø³Ù‡ÙˆÙ„Ø© ÙƒÙ€ `tf.data.Dataset` Ø­ØªÙ‰ ØªØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¨Ø¯Ø¡ ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„ÙÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„ØªÙŠ `compile` Ùˆ`fit` ÙÙŠ Keras.\n+\n+1. Ø³ØªØ¨Ø¯Ø£ Ø¨Ù€ [`TFPreTrainedModel`] Ø£Ùˆ [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model):\n+\n+   ```py\n+   >>> from transformers import TFAutoModelForSequenceClassification\n+\n+   >>> model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n+   ```\n+\n+2. Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ ÙØ¦Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ù…Ø«Ù„ Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ²ØŒ Ø£Ùˆ Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ±ØŒ Ø£Ùˆ Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§ØªØŒ Ø£Ùˆ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬:\n+\n+   ```py\n+   >>> from transformers import AutoTokenizer\n+\n+   >>> tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n+   ```\n+\n+3. Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù„ØªØ±Ù…ÙŠØ² Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n+\n+   ```py\n+   >>> def tokenize_dataset(dataset):\n+   ...     return tokenizer(dataset[\"text\"])  # doctest: +SKIP\n+   ```\n+\n+4. Ù‚Ù… Ø¨ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ² Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`~datasets.Dataset.map`] Ø«Ù… Ù…Ø±Ø± Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ² Ø¥Ù„Ù‰ [`~TFPreTrainedModel.prepare_tf_dataset`]. ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ØªØºÙŠÙŠØ± Ø­Ø¬Ù… Ø§Ù„Ø¯ÙØ¹Ø© ÙˆØ®Ù„Ø· Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‡Ù†Ø§ Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª:\n+\n+   ```py\n+   >>> dataset = dataset.map(tokenize_dataset)  # doctest: +SKIP\n+   >>> tf_dataset = model.prepare_tf_dataset(\n+   ...     dataset[\"train\"], batch_size=16, shuffle=True, tokenizer=tokenizer\n+   ... )  # doctest: +SKIP\n+   ```\n+\n+5. Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† Ù…Ø³ØªØ¹Ø¯Ù‹Ø§ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ `compile` Ùˆ`fit` Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨. Ù„Ø§Ø­Ø¸ Ø£Ù† Ø¬Ù…ÙŠØ¹ Ù†Ù…Ø§Ø°Ø¬ Transformers Ù„Ø¯ÙŠÙ‡Ø§ Ø¯Ø§Ù„Ø© Ø®Ø³Ø§Ø±Ø© Ø°Ø§Øª ØµÙ„Ø© Ø¨Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠØŒ Ù„Ø°Ø§ ÙØ£Ù†Øª Ù„Ø³Øª Ø¨Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ ØªØ­Ø¯ÙŠØ¯ ÙˆØ§Ø­Ø¯Ø© Ù…Ø§ Ù„Ù… ØªØ±ØºØ¨ ÙÙŠ Ø°Ù„Ùƒ:\n+\n+   ```py\n+   >>> from tensorflow.keras.optimizers import Adam\n+\n+   >>> model.compile(optimizer='adam')  # Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØ³ÙŠØ·Ø© Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø©!\n+   >>> model.fit(tf_dataset)  # doctest: +SKIP\n+   ```\n+\n+## Ù…Ø§Ø°Ø§ Ø¨Ø¹Ø¯ØŸ\n+\n+Ø§Ù„Ø¢Ù† Ø¨Ø¹Ø¯ Ø£Ù† Ø£ÙƒÙ…Ù„Øª Ø§Ù„Ø¬ÙˆÙ„Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø© ÙÙŠ ğŸ¤— TransformersØŒ Ø±Ø§Ø¬Ø¹ Ø£Ø¯Ù„ØªÙ†Ø§ Ù„Ù…Ø¹Ø±ÙØ© ÙƒÙŠÙÙŠØ© Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ø£Ø´ÙŠØ§Ø¡ Ø£ÙƒØ«Ø± ØªØ­Ø¯ÙŠØ¯Ù‹Ø§ Ù…Ø«Ù„ ÙƒØªØ§Ø¨Ø© Ù†Ù…ÙˆØ°Ø¬ Ù…Ø®ØµØµØŒ ÙˆØ¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù…Ø³Ø¨Ù‚ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù…Ù‡Ù…Ø© Ù…Ø¹ÙŠÙ†Ø©ØŒ ÙˆÙƒÙŠÙÙŠØ© ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠ. Ø¥Ø°Ø§ ÙƒÙ†Øª Ù…Ù‡ØªÙ…Ù‹Ø§ Ø¨Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ø¹Ù† Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù€ ğŸ¤— TransformersØŒ ÙØ§Ø­ØµÙ„ Ø¹Ù„Ù‰ ÙÙ†Ø¬Ø§Ù† Ù…Ù† Ø§Ù„Ù‚Ù‡ÙˆØ© ÙˆØ§Ø·Ù„Ø¹ Ø¹Ù„Ù‰ Ø£Ø¯Ù„Ø© Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù†Ø§!"
        },
        {
            "sha": "593d4aec85fc4a788863ba9b0f1d1b18ee98f282",
            "filename": "docs/source/ar/run_scripts.md",
            "status": "added",
            "additions": 351,
            "deletions": 0,
            "changes": 351,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Frun_scripts.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,351 @@\n+# Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Øµ Ø¨Ø±Ù…Ø¬Ù‰\n+\n+Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø¯ÙØ§ØªØ± Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª [notebooks](./notebooks) Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù€ ğŸ¤— TransformersØŒ Ù‡Ù†Ø§Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ù†ØµÙˆØµ Ø¨Ø±Ù…Ø¬ÙŠØ© ØªÙˆØ¶ÙŠØ­ÙŠØ© ØªÙØ¸Ù‡Ø± ÙƒÙŠÙÙŠØ© ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù…Ù‡Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [PyTorch](https://github.com/huggingface/transformers/tree/main/examples/pytorch) Ø£Ùˆ [TensorFlow](https://github.com/huggingface/transformers/tree/main/examples/tensorflow) Ø£Ùˆ [JAX/Flax](https://github.com/huggingface/transformers/tree/main/examples/flax).\n+\n+ÙƒÙ…Ø§ Ø³ØªØ¬Ø¯ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„ØªÙŠ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§Ù‡Ø§ ÙÙŠ [Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„Ø£Ø¨Ø­Ø§Ø«](https://github.com/huggingface/transformers/tree/main/examples/research_projects) Ùˆ [Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©](https://github.com/huggingface/transformers/tree/main/examples/legacy) ÙˆØ§Ù„ØªÙŠ Ø³Ø§Ù‡Ù… Ø¨Ù‡Ø§ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ Ø¨Ø´ÙƒÙ„ Ø£Ø³Ø§Ø³ÙŠ. Ù‡Ø°Ù‡ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø© Ø¨Ø´ÙƒÙ„ Ù†Ø´Ø· ÙˆÙ‚Ø¯ ØªØªØ·Ù„Ø¨ Ø¥ØµØ¯Ø§Ø±Ù‹Ø§ Ù…Ø­Ø¯Ø¯Ù‹Ø§ Ù…Ù† Ù…ÙƒØªØ¨Ø© ğŸ¤— Transformers ÙˆØ§Ù„Ø°ÙŠ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙ…Ù„ Ø£Ù† ÙŠÙƒÙˆÙ† ØºÙŠØ± Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø£Ø­Ø¯Ø« Ù…Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø©.\n+\n+Ù„Ø§ ÙŠÙØªÙˆÙ‚Ø¹ Ø£Ù† ØªØ¹Ù…Ù„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ© Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø§Ø´Ø± Ø¹Ù„Ù‰ ÙƒÙ„ Ù…Ø´ÙƒÙ„Ø©ØŒ ÙˆÙ‚Ø¯ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªÙƒÙŠÙŠÙ Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ù…Ø¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØªÙŠ ØªØ­Ø§ÙˆÙ„ Ø­Ù„Ù‡Ø§. ÙˆÙ„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø°Ù„ÙƒØŒ ØªØ¹Ø±Ø¶ Ù…Ø¹Ø¸Ù… Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© ÙƒÙŠÙÙŠØ© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„ØŒ Ù…Ù…Ø§ ÙŠØªÙŠØ­ Ù„Ùƒ ØªØ­Ø±ÙŠØ±Ù‡Ø§ Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ø­Ø§Ù„ØªÙƒ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù….\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ø£ÙŠ Ù…ÙŠØ²Ø© ØªØ±ØºØ¨ ÙÙŠ ØªÙ†ÙÙŠØ°Ù‡Ø§ ÙÙŠ Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠ ØªÙˆØ¶ÙŠØ­ÙŠØŒ ÙŠØ±Ø¬Ù‰ Ù…Ù†Ø§Ù‚Ø´ØªÙ‡Ø§ ÙÙŠ [Ø§Ù„Ù…Ù†ØªØ¯Ù‰](https://discuss.huggingface.co/) Ø£Ùˆ ÙÙŠ [Ù‚Ø¶ÙŠØ©](https://github.com/huggingface/transformers/issues) Ù‚Ø¨Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ Ø³Ø­Ø¨. ÙˆÙÙŠ Ø­ÙŠÙ† Ø£Ù†Ù†Ø§ Ù†Ø±Ø­Ø¨ Ø¨Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ØŒ ÙÙ…Ù† ØºÙŠØ± Ø§Ù„Ù…Ø±Ø¬Ø­ Ø£Ù† Ù†Ù‚ÙˆÙ… Ø¨Ø¯Ù…Ø¬ Ø·Ù„Ø¨ Ø³Ø­Ø¨ Ø§Ù„Ø°ÙŠ ÙŠØ¶ÙŠÙ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø¹Ù„Ù‰ Ø­Ø³Ø§Ø¨ Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©.\n+\n+Ø³ÙŠÙˆØ¶Ø­ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ ÙƒÙŠÙÙŠØ© ØªØ´ØºÙŠÙ„ Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠ ØªÙˆØ¶ÙŠØ­ÙŠ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ„Ø®ÙŠØµ ÙÙŠ [PyTorch](https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization) Ùˆ [TensorFlow](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/summarization). ÙŠÙØªÙˆÙ‚Ø¹ Ø£Ù† ØªØ¹Ù…Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ù…Ø¹ ÙƒÙ„Ø§ Ø§Ù„Ø¥Ø·Ø§Ø±ÙŠÙ† Ù…Ø§ Ù„Ù… ÙŠÙÙ†Øµ Ø¹Ù„Ù‰ Ø®Ù„Ø§Ù Ø°Ù„Ùƒ.\n+\n+## Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯\n+\n+Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø£Ø­Ø¯Ø« Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­ØŒ ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ **ØªØ«Ø¨ÙŠØª ğŸ¤— Transformers Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø±** ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©:\n+\n+```bash\n+git clone https://github.com/huggingface/transformers\n+cd transformers\n+pip install .\n+```\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ø£Ù‚Ø¯Ù… Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ©ØŒ Ø§Ù†Ù‚Ø± ÙÙˆÙ‚ Ø§Ù„Ø²Ø± Ø£Ø¯Ù†Ø§Ù‡:\n+```bash\n+git clone https://github.com/huggingface/transformers\n+cd transformers\n+pip install .\n+```\n+\n+Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ø£Ù‚Ø¯Ù… Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ©ØŒ Ø§Ù†Ù‚Ø± ÙÙˆÙ‚ Ø§Ù„Ø²Ø± Ø£Ø¯Ù†Ø§Ù‡:\n+\n+<details>\n+  <summary>Ø£Ù…Ø«Ù„Ø© Ù„Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ø£Ù‚Ø¯Ù… Ù…Ù† ğŸ¤— Transformers</summary>\n+\t<ul>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v4.5.1/examples\">v4.5.1</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v4.4.2/examples\">v4.4.2</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v4.3.3/examples\">v4.3.3</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v4.2.2/examples\">v4.2.2</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v4.1.1/examples\">v4.1.1</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v4.0.1/examples\">v4.0.1</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v3.5.1/examples\">v3.5.1</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v3.4.0/examples\">v3.4.0</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v3.3.1/examples\">v3.3.1</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v3.2.0/examples\">v3.2.0</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v3.1.0/examples\">v3.1.0</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v3.0.2/examples\">v3.0.2</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v2.11.0/examples\">v2.11.0</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v2.10.0/examples\">v2.10.0</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v2.9.1/examples\">v2.9.1</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v2.8.0/examples\">v2.8.0</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v2.7.0/examples\">v2.7.0</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v2.6.0/examples\">v2.6.0</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v2.5.1/examples\">v2.5.1</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v2.4.0/examples\">v2.4.0</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v2.3.0/examples\">v2.3.0</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v2.2.0/examples\">v2.2.0</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v2.1.0/examples\">v2.1.1</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v2.0.0/examples\">v2.0.0</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v1.2.0/examples\">v1.2.0</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v1.1.0/examples\">v1.1.0</a></li>\n+\t\t<li><a href=\"https://github.com/huggingface/transformers/tree/v1.0.0/examples\">v1.0.0</a></li>\n+\t</ul>\n+</details>\n+\n+Ø«Ù… Ù‚Ù… Ø¨Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù…Ù† ğŸ¤— Transformers Ø¥Ù„Ù‰ Ø¥ØµØ¯Ø§Ø± Ù…Ø­Ø¯Ø¯ØŒ Ù…Ø«Ù„ v3.5.1 Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„:\n+\n+```bash\n+git checkout tags/v3.5.1\n+```\n+\n+Ø¨Ø¹Ø¯ Ø¥Ø¹Ø¯Ø§Ø¯ Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„ØµØ­ÙŠØ­ØŒ Ø§Ù†ØªÙ‚Ù„ Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ø°ÙŠ ØªØ®ØªØ§Ø±Ù‡ ÙˆÙ‚Ù… Ø¨ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©:\n+\n+```bash\n+pip install -r requirements.txt\n+```\n+\n+## ØªØ´ØºÙŠÙ„ Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠ\n+\n+<frameworkcontent>\n+<pt>\n+    \n+- ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ Ø¨ØªÙ†Ø²ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù…Ù† Ù…ÙƒØªØ¨Ø© ğŸ¤— [Datasets](https://huggingface.co/docs/datasets).\n+- Ø«Ù… ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ø¨Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø¯Ù‚ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) Ø¹Ù„Ù‰ Ø¨Ù†ÙŠØ© ØªØ¯Ø¹Ù… Ø§Ù„Ù…Ù„Ø®Øµ. \n+- ÙŠÙˆØ¶Ø­ Ø§Ù„Ù…Ø«Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ ÙƒÙŠÙÙŠØ© Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ [T5-small](https://huggingface.co/google-t5/t5-small) Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail).\n+- ÙŠØªØ·Ù„Ø¨ Ù†Ù…ÙˆØ°Ø¬ T5 Ù…Ø¹Ø§Ù…Ù„ `source_prefix` Ø¥Ø¶Ø§ÙÙŠØ© Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙŠ ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡ Ø¨Ù‡Ø§. ÙŠØªÙŠØ­ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø© Ù„Ù€ T5 Ù…Ø¹Ø±ÙØ© Ø£Ù† Ù‡Ø°Ù‡ Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙ„Ø®ÙŠØµ.\n+    \n+```bash\n+python examples/pytorch/summarization/run_summarization.py \\\n+    --model_name_or_path google-t5/t5-small \\\n+    --do_train \\\n+    --do_eval \\\n+    --dataset_name cnn_dailymail \\\n+    --dataset_config \"3.0.0\" \\\n+    --source_prefix \"summarize: \" \\\n+    --output_dir /tmp/tst-summarization \\\n+    --per_device_train_batch_size=4 \\\n+    --per_device_eval_batch_size=4 \\\n+    --overwrite_output_dir \\\n+    --predict_with_generate\n+```\n+</pt>\n+<tf>\n+    \n+- ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ Ø¨ØªÙ†Ø²ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù…Ù† Ù…ÙƒØªØ¨Ø© ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/).\n+- Ø«Ù… ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ø¨Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø¯Ù‚ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Keras Ø¹Ù„Ù‰ Ø¨Ù†ÙŠØ© ØªØ¯Ø¹Ù… Ø§Ù„Ù…Ù„Ø®Øµ.\n+- ÙŠÙˆØ¶Ø­ Ø§Ù„Ù…Ø«Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ ÙƒÙŠÙÙŠØ© Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ [T5-small](https://huggingface.co/google-t5/t5-small) Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail).\n+- ÙŠØªØ·Ù„Ø¨ Ù†Ù…ÙˆØ°Ø¬ T5 Ù…Ø§Ø¹Ù…Ù„ `source_prefix` Ø¥Ø¶Ø§ÙÙŠØ© Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙŠ ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡ Ø¨Ù‡Ø§. ÙŠØªÙŠØ­ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨Ø© Ù„Ù€ T5 Ù…Ø¹Ø±ÙØ© Ø£Ù† Ù‡Ø°Ù‡ Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙ„Ø®ÙŠØµ.\n+\n+```bash\n+python examples/tensorflow/summarization/run_summarization.py  \\\n+    --model_name_or_path google-t5/t5-small \\\n+    --dataset_name cnn_dailymail \\\n+    --dataset_config \"3.0.0\" \\\n+    --output_dir /tmp/tst-summarization  \\\n+    --per_device_train_batch_size 8 \\\n+    --per_device_eval_batch_size 16 \\\n+    --num_train_epochs 3 \\\n+    --do_train \\\n+    --do_eval\n+```\n+</tf>\n+</frameworkcontent>\n+\n+## Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ²Ø¹ ÙˆØ§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…Ø®ØªÙ„Ø·Ø©\n+\n+ÙŠØ¯Ø¹Ù… [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ²Ø¹ ÙˆØ§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…Ø®ØªÙ„Ø·Ø©ØŒ Ù…Ù…Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙÙŠ Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠ. Ù„ØªÙ…ÙƒÙŠÙ† ÙƒÙ„ØªØ§ Ø§Ù„Ù…ÙŠØ²ØªÙŠÙ†:\n+\n+- Ø£Ø¶Ù Ù…Ø¹Ø§Ù…Ù„ `fp16` Ù„ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…Ø®ØªÙ„Ø·Ø©.\n+- Ù‚Ù… Ø¨ØªØ¹ÙŠÙŠÙ† Ø¹Ø¯Ø¯ ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPUs) Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø­Ø¬Ø© `nproc_per_node`.\n+\n+```bash\n+torchrun \\\n+    --nproc_per_node 8 pytorch/summarization/run_summarization.py \\\n+    --fp16 \\\n+    --model_name_or_path google-t5/t5-small \\\n+    --do_train \\\n+    --do_eval \\\n+    --dataset_name cnn_dailymail \\\n+    --dataset_config \"3.0.0\" \\\n+    --source_prefix \"summarize: \" \\\n+    --output_dir /tmp/tst-summarization \\\n+    --per_device_train_batch_size=4 \\\n+    --per_device_eval_batch_size=4 \\\n+    --overwrite_output_dir \\\n+    --predict_with_generate\n+```\n+\n+ØªØ³ØªØ®Ø¯Ù… Ù†ØµÙˆØµ TensorFlow Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© [`MirroredStrategy`](https://www.tensorflow.org/guide/distributed_training#mirroredstrategy) Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ²Ø¹ØŒ ÙˆÙ„Ø§ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¥Ø¶Ø§ÙØ© Ø£ÙŠ Ù…Ø¹Ø§Ù…ï»»Øª Ø¥Ø¶Ø§ÙÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠ. Ø³ÙŠØ³ØªØ®Ø¯Ù… Ù†Øµ TensorFlow Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPUs) Ù…ØªØ¹Ø¯Ø¯Ø© Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªÙˆÙØ±Ø©.\n+\n+## ØªØ´ØºÙŠÙ„ Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPU)\n+\n+<frameworkcontent>\n+<pt>\n+    \n+ØªÙØ¹Ø¯ ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPUs) Ù…ØµÙ…Ù…Ø© Ø®ØµÙŠØµÙ‹Ø§ Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø£Ø¯Ø§Ø¡. ÙŠØ¯Ø¹Ù… PyTorch ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPUs) Ù…Ø¹ [XLA](https://www.tensorflow.org/xla) Ù…Ø¬Ù…Ø¹ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ (Ø±Ø§Ø¬Ø¹ [Ù‡Ù†Ø§](https://github.com/pytorch/xla/blob/master/README.md) Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„). Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPU)ØŒ Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ù†Øµ `xla_spawn.py` Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ ÙˆØ§Ø³ØªØ®Ø¯Ù… Ù…Ø¹Ø§Ù…Ù„ `num_cores` Ù„ØªØ¹ÙŠÙŠÙ† Ø¹Ø¯Ø¯ ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPU) Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§.\n+\n+```bash\n+python xla_spawn.py --num_cores 8 \\\n+    summarization/run_summarization.py \\\n+    --model_name_or_path google-t5/t5-small \\\n+    --do_train \\\n+    --do_eval \\\n+    --dataset_name cnn_dailymail \\\n+    --dataset_config \"3.0.0\" \\\n+    --source_prefix \"summarize: \" \\\n+    --output_dir /tmp/tst-summarization \\\n+    --per_device_train_batch_size=4 \\\n+    --per_device_eval_batch_size=4 \\\n+    --overwrite_output_dir \\\n+    --predict_with_generate\n+```\n+</pt>\n+<tf>\n+    \n+ØªÙØ¹Ø¯ ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPUs) Ù…ØµÙ…Ù…Ø© Ø®ØµÙŠØµÙ‹Ø§ Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø£Ø¯Ø§Ø¡. ØªØ³ØªØ®Ø¯Ù… Ù†ØµÙˆØµ TensorFlow Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© [`TPUStrategy`](https://www.tensorflow.org/guide/distributed_training#tpustrategy) Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPUs). Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPU)ØŒ Ù‚Ù… Ø¨ØªÙ…Ø±ÙŠØ± Ø§Ø³Ù… Ù…ÙˆØ±Ø¯ ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPU) Ø¥Ù„Ù‰ Ø­Ø¬Ø© `tpu`.\n+```bash\n+python run_summarization.py  \\\n+    --tpu name_of_tpu_resource \\\n+    --model_name_or_path google-t5/t5-small \\\n+    --dataset_name cnn_dailymail \\\n+    --dataset_config \"3.0.0\" \\\n+    --output_dir /tmp/tst-summarization  \\\n+    --per_device_train_batch_size 8 \\\n+    --per_device_eval_batch_size 16 \\\n+    --num_train_epochs 3 \\\n+    --do_train \\\n+    --do_eval\n+```\n+</tf>\n+</frameworkcontent>\n+\n+## ØªØ´ØºÙŠÙ„ Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ğŸ¤— Accelerate\n+\n+ğŸ¤— [Accelerate](https://huggingface.co/docs/accelerate) Ù‡ÙŠ Ù…ÙƒØªØ¨Ø© Ø®Ø§ØµØ© Ø¨Ù€ PyTorch ÙÙ‚Ø· ØªÙˆÙØ± Ø·Ø±ÙŠÙ‚Ø© Ù…ÙˆØ­Ø¯Ø© Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ø£Ù†ÙˆØ§Ø¹ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© (CPU) ÙÙ‚Ø·ØŒ Ø£Ùˆ ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPUs) Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©ØŒ Ø£Ùˆ ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPUs)) Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù„Ø­Ù„Ù‚Ø© ØªØ¯Ø±ÙŠØ¨ PyTorch. ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª ğŸ¤— Accelerate Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù„Ø¯ÙŠÙƒ Ø¨Ø§Ù„ÙØ¹Ù„:\n+\n+> Ù…Ù„Ø§Ø­Ø¸Ø©: Ù†Ø¸Ø±Ù‹Ø§ Ù„Ø£Ù† Accelerate ÙÙŠ Ø­Ø§Ù„Ø© ØªØ·ÙˆÙŠØ± Ø³Ø±ÙŠØ¹ØŒ ÙŠØ¬Ø¨ ØªØ«Ø¨ÙŠØª Ø¥ØµØ¯Ø§Ø± Git Ù…Ù† Accelerate Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©.\n+```bash\n+pip install git+https://github.com/huggingface/accelerate\n+```\n+\n+Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø¥Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ `run_summarization.py`  ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ `run_summarization_no_trainer.py` . Ø³ØªÙƒÙˆÙ† Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© Ù…Ù† ğŸ¤— Accelerate Ù„Ù‡Ø§ Ù…Ù„Ù `task_no_trainer.py` ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯. Ø§Ø¨Ø¯Ø£ Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ­ÙØ¸ Ù…Ù„Ù ØªÙƒÙˆÙŠÙ†:\n+\n+```bash\n+accelerate config\n+```\n+\n+Ø§Ø®ØªØ¨Ø± Ø¥Ø¹Ø¯Ø§Ø¯Ùƒ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡ ØªÙ… ØªÙƒÙˆÙŠÙ†Ù‡ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­:\n+\n+```bash\n+accelerate test\n+```\n+\n+Ø§Ù„Ø¢Ù† Ø£Ù†Øª Ù…Ø³ØªØ¹Ø¯ Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨:\n+\n+```bash\n+accelerate launch run_summarization_no_trainer.py \\\n+    --model_name_or_path google-t5/t5-small \\\n+    --dataset_name cnn_dailymail \\\n+    --dataset_config \"3.0.0\" \\\n+    --source_prefix \"summarize: \" \\\n+    --output_dir ~/tmp/tst-summarization\n+```\n+\n+## Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø®ØµØµØ©\n+\n+ÙŠØ¯Ø¹Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ù„Ù„ØªÙ„Ø®ÙŠØµ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø®ØµØµØ© Ø·Ø§Ù„Ù…Ø§ Ø£Ù†Ù‡Ø§ Ù…Ù„Ù CSV Ø£Ùˆ JSON Line. Ø¹Ù†Ø¯Ù…Ø§ ØªØ³ØªØ®Ø¯Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø§Ù„Ø®Ø§ØµØ©ØŒ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©:\n+\n+- `train_file` Ùˆ`validation_file` ÙŠØ­Ø¯Ø¯Ø§Ù† Ù…Ø³Ø§Ø± Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ.\n+- `text_column`  Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¯Ø®Ù„ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… ØªÙ„Ø®ÙŠØµÙ‡.\n+- `summary_column`  Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… Ø¥Ø®Ø±Ø§Ø¬Ù‡.\n+\n+Ø³ÙŠØ¨Ø¯Ùˆ Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ù„Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø°ÙŠ ÙŠØ³ØªØ®Ø¯Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø®ØµØµØ© Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø­Ùˆ Ø§Ù„ØªØ§Ù„ÙŠ:\n+\n+```bash\n+python examples/pytorch/summarization/run_summarization.py \\\n+    --model_name_or_path google-t5/t5-small \\\n+    --do_train \\\n+    --do_eval \\\n+    --train_file path_to_csv_or_jsonlines_file \\\n+    --validation_file path_to_csv_or_jsonlines_file \\\n+    --text_column text_column_name \\\n+    --summary_column summary_column_name \\\n+    --source_prefix \"summarize: \" \\\n+    --output_dir /tmp/tst-summarization \\\n+    --overwrite_output_dir \\\n+    --per_device_train_batch_size=4 \\\n+    --per_device_eval_batch_size=4 \\\n+    --predict_with_generate\n+```\n+\n+## Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ù†ØµÙŠ\n+\n+Ù…Ù† Ø§Ù„Ø¬ÙŠØ¯ ØºØ§Ù„Ø¨Ù‹Ø§ ØªØ´ØºÙŠÙ„ Ù†ØµÙƒ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø£Ù‚Ù„ Ù…Ù† Ø£Ù…Ø«Ù„Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† ÙƒÙ„ Ø´ÙŠØ¡ ÙŠØ¹Ù…Ù„ ÙƒÙ…Ø§ Ù‡Ùˆ Ù…ØªÙˆÙ‚Ø¹ Ù‚Ø¨Ù„ Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§Ù…Ù„Ø© ÙˆØ§Ù„ØªÙŠ Ù‚Ø¯ ØªØ³ØªØºØ±Ù‚ Ø³Ø§Ø¹Ø§Øª Ù„Ø¥ÙƒÙ…Ø§Ù„Ù‡Ø§. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„ØªÙ‚Ù„ÙŠØµ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø¹Ø¯Ø¯ Ø£Ù‚ØµÙ‰ Ù…Ù† Ø§Ù„Ø¹ÙŠÙ†Ø§Øª:\n+\n+- `max_train_samples`\n+- `max_eval_samples`\n+- `max_predict_samples`\n+\n+```bash\n+python examples/pytorch/summarization/run_summarization.py \\\n+    --model_name_or_path google-t5/t5-small \\\n+    --max_train_samples 50 \\\n+    --max_eval_samples 50 \\\n+    --max_predict_samples 50 \\\n+    --do_train \\\n+    --do_eval \\\n+    --dataset_name cnn_dailymail \\\n+    --dataset_config \"3.0.0\" \\\n+    --source_prefix \"summarize: \" \\\n+    --output_dir /tmp/tst-summarization \\\n+    --per_device_train_batch_size=4 \\\n+    --per_device_eval_batch_size=4 \\\n+    --overwrite_output_dir \\\n+    --predict_with_generate\n+```\n+\n+Ù„Ø§ ØªØ¯Ø¹Ù… Ø¬Ù…ÙŠØ¹ Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„Ù…Ø¹Ù„Ù…Ø© `max_predict_samples`. Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ù‹Ø§ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù†ØµÙƒ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ ÙŠØ¯Ø¹Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„Ù…Ø©ØŒ ÙØ£Ø¶Ù Ù…Ø¹Ù„Ù…Ø© `-h` Ù„Ù„ØªØ­Ù‚Ù‚:\n+\n+```bash\n+examples/pytorch/summarization/run_summarization.py -h\n+```\n+\n+## Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´\n+\n+Ø®ÙŠØ§Ø± Ø¢Ø®Ø± Ù…ÙÙŠØ¯ Ù„ØªÙ…ÙƒÙŠÙ†Ù‡ Ù‡Ùˆ Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´ Ø³Ø§Ø¨Ù‚Ø©. Ø³ÙŠØ¶Ù…Ù† Ø°Ù„Ùƒ Ø£Ù†Ùƒ ØªØ³ØªØ·ÙŠØ¹ Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø± Ù…Ù† Ø­ÙŠØ« ØªÙˆÙ‚ÙØª Ø¯ÙˆÙ† Ø§Ù„Ø¨Ø¯Ø¡ Ù…Ù† Ø¬Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ØªÙ… Ù…Ù‚Ø§Ø·Ø¹Ø© ØªØ¯Ø±ÙŠØ¨Ùƒ. Ù‡Ù†Ø§Ùƒ Ø·Ø±ÙŠÙ‚ØªØ§Ù† Ù„Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´.\n+\n+ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø§Ù„Ù…Ø¹Ù„Ù…Ø© `output_dir previous_output_dir` Ù„Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† Ø£Ø­Ø¯Ø« Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´ Ù…Ø®Ø²Ù†Ø© ÙÙŠ `output_dir`. ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø©ØŒ ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø¥Ø²Ø§Ù„Ø© `overwrite_output_dir`:\n+\n+```bash\n+python examples/pytorch/summarization/run_summarization.py\n+    --model_name_or_path google-t5/t5-small \\\n+    --do_train \\\n+    --do_eval \\\n+    --dataset_name cnn_dailymail \\\n+    --dataset_config \"3.0.0\" \\\n+    --source_prefix \"summarize: \" \\\n+    --output_dir /tmp/tst-summarization \\\n+    --per_device_train_batch_size=4 \\\n+    --per_device_eval_batch_size=4 \\\n+    --output_dir previous_output_dir \\\n+    --predict_with_generate\n+```\n+\n+ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ù…Ø¹Ù„Ù…Ø© `resume_from_checkpoint path_to_specific_checkpoint` Ù„Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† Ù…Ø¬Ù„Ø¯ Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´ Ù…Ø­Ø¯Ø¯Ø©.\n+\n+```bash\n+python examples/pytorch/summarization/run_summarization.py\n+    --model_name_or_path google-t5/t5-small \\\n+    --do_train \\\n+    --do_eval \\\n+    --dataset_name cnn_dailymail \\\n+    --dataset_config \"3.0.0\" \\\n+    --source_prefix \"summarize: \" \\\n+    --output_dir /tmp/tst-summarization \\\n+    --per_device_train_batch_size=4 \\\n+    --per_device_eval_batch_size=4 \\\n+    --overwrite_output_dir \\\n+    --resume_from_checkpoint path_to_specific_checkpoint \\\n+    --predict_with_generate\n+```\n+\n+## Ø´Ø§Ø±Ùƒ Ù†Ù…ÙˆØ°Ø¬Ùƒ\n+\n+ÙŠÙ…ÙƒÙ† Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø±ÙØ¹ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¥Ù„Ù‰ [Ù…Ø±ÙƒØ² Ø§Ù„Ù†Ù…Ø§Ø°Ø¬](https://huggingface.co/models). ØªØ£ÙƒØ¯ Ù…Ù† ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ Hugging Face Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡:\n+\n+```bash\n+huggingface-cli login\n+```\n+\n+Ø«Ù… Ø£Ø¶Ù Ø§Ù„Ù…Ø¹Ù„Ù…Ø© `push_to_hub` Ø¥Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ . Ø³ØªÙ‚ÙˆÙ… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„Ù…Ø© Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªÙˆØ¯Ø¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³Ù… Ù…Ø³ØªØ®Ø¯Ù… Hugging Face ÙˆØ§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯ ÙÙŠ `output_dir`.\n+\n+Ù„Ø¥Ø¹Ø·Ø§Ø¡ Ù…Ø³ØªÙˆØ¯Ø¹Ùƒ Ø§Ø³Ù…Ù‹Ø§ Ù…Ø­Ø¯Ø¯Ù‹Ø§ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„Ù…Ø© `push_to_hub_model_id` Ù„Ø¥Ø¶Ø§ÙØªÙ‡. Ø³ÙŠØªÙ… Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¶Ù…Ù† Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ.\n+\n+ÙŠÙˆØ¶Ø­ Ø§Ù„Ù…Ø«Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ ÙƒÙŠÙÙŠØ© Ø±ÙØ¹ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³Ù… Ù…Ø³ØªÙˆØ¯Ø¹ Ù…Ø­Ø¯Ø¯:\n+\n+```bash\n+python examples/pytorch/summarization/run_summarization.py\n+    --model_name_or_path google-t5/t5-small \\\n+    --do_train \\\n+    --do_eval \\\n+    --dataset_name cnn_dailymail \\\n+    --dataset_config \"3.0.0\" \\\n+    --source_prefix \"summarize: \" \\\n+    --push_to_hub \\\n+    --push_to_hub_model_id finetuned-t5-cnn_dailymail \\\n+    --output_dir /tmp/tst-summarization \\\n+    --per_device_train_batch_size=4 \\\n+    --per_device_eval_batch_size=4 \\\n+    --overwrite_output_dir \\\n+    --predict_with_generate\n+```"
        },
        {
            "sha": "d3e354ff8b1af3b58a72a7a24070452ac49c5d48",
            "filename": "docs/source/ar/training.md",
            "status": "added",
            "additions": 412,
            "deletions": 0,
            "changes": 412,
            "blob_url": "https://github.com/huggingface/transformers/blob/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Ftraining.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c2d05897bf4e8b34773838accaddd66028bc148d/docs%2Fsource%2Far%2Ftraining.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Ftraining.md?ref=c2d05897bf4e8b34773838accaddd66028bc148d",
            "patch": "@@ -0,0 +1,412 @@\n+# Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§\n+\n+Ù‡Ù†Ø§Ùƒ ÙÙˆØ§Ø¦Ø¯ ÙƒØ¨ÙŠØ±Ø© Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§. ÙÙ‡Ùˆ ÙŠÙ‚Ù„Ù„ Ù…Ù† ØªÙƒØ§Ù„ÙŠÙ Ø§Ù„Ø­ÙˆØ³Ø¨Ø©ØŒ ÙˆÙŠØ­Ø¯ Ù…Ù† Ø£Ø«Ø±Ù†Ø§ Ø§Ù„Ø¨ÙŠØ¦ÙŠØŒ ÙˆÙŠØªÙŠØ­ Ù„Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø­Ø¯Ø« Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¯ÙˆÙ† Ø§Ù„Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ ØªØ¯Ø±ÙŠØ¨Ù‡Ø§ Ù…Ù† Ø§Ù„ØµÙØ±. ØªÙˆÙØ± Ù…ÙƒØªØ¨Ø© ğŸ¤— Transformers Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø¢Ù„Ø§Ù Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§Ø³Ø¹Ø© Ù…Ù† Ø§Ù„Ù…Ù‡Ø§Ù…. Ø¹Ù†Ø¯Ù…Ø§ ØªØ³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ Ù…ÙØ¯Ø±Ø¨Ù‹Ø§ Ù…Ø³Ø¨Ù‚Ù‹Ø§ØŒ ÙØ¥Ù†Ùƒ ØªÙ‚ÙˆÙ… Ø¨ØªØ¯Ø±ÙŠØ¨Ù‡ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø§ØµØ© Ø¨Ù…Ù‡Ù…ØªÙƒ. ÙŠÙØ¹Ø±Ù Ø°Ù„Ùƒ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ø§Ù„Ø¯Ù‚ÙŠÙ‚ØŒ ÙˆÙ‡ÙŠ ØªÙ‚Ù†ÙŠØ© ØªØ¯Ø±ÙŠØ¨ Ù‚ÙˆÙŠØ© Ù„Ù„ØºØ§ÙŠØ©. ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØŒ Ø³ÙˆÙ ØªÙ‚ÙˆÙ… Ø¨Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø§Ù„Ø°ÙŠ ØªØ®ØªØ§Ø±Ù‡:\n+\n+* Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ğŸ¤— Transformers [`Trainer`].\n+* Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ÙÙŠ TensorFlow Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Keras.\n+* Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ÙÙŠ PyTorch Ø§Ù„Ø£ØµÙ„ÙŠ.\n+\n+<a id='data-processing'></a>\n+\n+## Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª\n+\n+Ù‚Ø¨Ù„ Ø£Ù† ØªØªÙ…ÙƒÙ† Ù…Ù† Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ØŒ Ù‚Ù… Ø¨ØªÙ†Ø²ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ø¹Ø¯Ø§Ø¯Ù‡Ø§ Ù„Ù„ØªØ¯Ø±ÙŠØ¨. Ø£Ø¸Ù‡Ø± Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„Ø³Ø§Ø¨Ù‚ ÙƒÙŠÙÙŠØ© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨ØŒ ÙˆØ§Ù„Ø¢Ù† Ù„Ø¯ÙŠÙƒ Ø§Ù„ÙØ±ØµØ© Ù„Ø§Ø®ØªØ¨Ø§Ø± ØªÙ„Ùƒ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª!\n+\n+Ø§Ø¨Ø¯Ø£ Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª [Yelp Reviews](https://huggingface.co/datasets/yelp_review_full):\n+\n+```py\n+>>> from datasets import load_dataset\n+\n+>>> dataset = load_dataset(\"yelp_review_full\")\n+>>> dataset[\"train\"][100]\n+{'label': 0,\n+ 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}\n+```\n+\n+ÙƒÙ…Ø§ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù†ØŒ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø­ÙˆÙ„ Ù†Øµ Ø¥Ù„Ù‰ Ø±Ù…Ø² (tokenizer) Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ ÙˆØªØ¶Ù…ÙŠÙ† Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ù„Ù„Ø­Ø´Ùˆ ÙˆØ§Ù„Ù‚Øµ Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø£ÙŠ Ø£Ø·ÙˆØ§Ù„ Ù…ØªØ³Ù„Ø³Ù„Ø© Ù…ØªØºÙŠØ±Ø©. Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ ÙÙŠ Ø®Ø·ÙˆØ© ÙˆØ§Ø­Ø¯Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø·Ø±ÙŠÙ‚Ø© ğŸ¤— Datasets [`map`](https://huggingface.co/docs/datasets/process#map) Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø§Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§:\n+\n+```py\n+>>> from transformers import AutoTokenizer\n+\n+>>> tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n+\n+\n+>>> def tokenize_function(examples):\n+...     return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n+>>> tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n+\n+\n+>>> def tokenize_function(examples):\n+...     return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n+\n+\n+>>> tokenized_datasets = dataset.map(tokenize_function, batched=True)\n+```\n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ØºØ¨ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© ÙØ±Ø¹ÙŠØ© Ø£ØµØºØ± Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù„Ø¶Ø¨Ø·Ù‡Ø§ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø°ÙŠ ØªØ³ØªØºØ±Ù‚Ù‡:\n+\n+```py\n+>>> small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n+>>> small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n+```\n+\n+<a id='trainer'></a>\n+\n+## Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n+\n+ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©ØŒ ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø§ØªØ¨Ø§Ø¹ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø°ÙŠ ÙŠØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø±ÙˆØ§Ø¨Ø·\n+ÙÙŠ Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ†Ù‚Ù„ Ø§Ù„Ø£ÙŠÙ…Ù† Ù„Ù„Ù‚ÙØ² Ø¥Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯Ù‡ - ÙˆØ¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ø¥Ø®ÙØ§Ø¡ ÙƒÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„Ø¥Ø·Ø§Ø± Ù…Ø¹ÙŠÙ†ØŒ\n+ÙØ§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø²Ø± ÙÙŠ Ø§Ù„Ø±ÙƒÙ† Ø§Ù„Ø¹Ù„ÙˆÙŠ Ø§Ù„Ø£ÙŠÙ…Ù† Ù…Ù† ÙƒØªÙ„Ø© Ø§Ù„Ø¥Ø·Ø§Ø±!\n+\n+<frameworkcontent>\n+<pt>\n+<Youtube id=\"nvBXf7s7vTI\"/>\n+\n+## Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyTorch Trainer\n+\n+ØªÙ‚Ø¯Ù… Ù…ÙƒØªØ¨Ø© ğŸ¤— Transformers ÙØ¦Ø© [`Trainer`] Ù…ÙØ­Ø³Ù‘Ù†Ø© Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ ğŸ¤— TransformersØŒ Ù…Ù…Ø§ ÙŠØ³Ù‡Ù„ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¯ÙˆÙ† Ø§Ù„Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ ÙƒØªØ§Ø¨Ø© Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ ÙŠØ¯ÙˆÙŠÙ‹Ø§. ØªØ¯Ø¹Ù… ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª [`Trainer`] Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§Ø³Ø¹Ø© Ù…Ù† Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ø«Ù„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ØŒ ÙˆØªØ±Ø§ÙƒÙ… Ø§Ù„ØªØ¯Ø±Ø¬Ø§ØªØŒ ÙˆØ§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…Ø®ØªÙ„Ø·Ø©.\n+\n+Ø§Ø¨Ø¯Ø£ Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬Ùƒ ÙˆØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©. Ù…Ù† Ø¨Ø·Ø§Ù‚Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Yelp Review [dataset card](https://huggingface.co/datasets/yelp_review_full#data-fields)ØŒ ØªØ¹Ø±Ù Ø£Ù†Ù‡ ÙŠÙˆØ¬Ø¯ Ø®Ù…Ø³Ø© ØªØµÙ†ÙŠÙØ§Øª:\n+\n+```py\n+>>> from transformers import AutoModelForSequenceClassification\n+\n+>>> model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)\n+```\n+\n+<Tip>\n+\n+Ø³ØªØ±Ù‰ ØªØ­Ø°ÙŠØ±Ù‹Ø§ Ø¨Ø´Ø£Ù† Ø¨Ø¹Ø¶ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù„Ù† ØªÙØ³ØªØ®Ø¯Ù… ÙˆØ¨Ø¹Ø¶ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø£Ø®Ø±Ù‰ Ø³ØªÙØ¨Ø¯Ø¡ Ø¨Ø´ÙƒÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ. Ù„Ø§ ØªÙ‚Ù„Ù‚ØŒ Ù‡Ø°Ø§ Ø£Ù…Ø± Ø·Ø¨ÙŠØ¹ÙŠ ØªÙ…Ø§Ù…Ù‹Ø§! ÙŠØªÙ… Ø§Ù„ØªØ®Ù„Øµ Ù…Ù† Ø±Ø£Ø³ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù„Ø´Ø¨ÙƒØ© BERTØŒ ÙˆÙŠØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡ Ø¨Ø±Ø£Ø³ ØªØµÙ†ÙŠÙ ÙŠÙØ¨Ø¯Ø¡ Ø¨Ø´ÙƒÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ. Ø³ÙˆÙ ØªÙ‚ÙˆÙ… Ø¨Ø¶Ø¨Ø· Ø§Ù„Ø±Ø£Ø³ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯Ù‚Ø© Ø¹Ù„Ù‰ Ù…Ù‡Ù…Ø© ØªØµÙ†ÙŠÙ Ø§Ù„ØªØ³Ù„Ø³Ù„Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨ÙƒØŒ Ù…Ù…Ø§ ÙŠÙ†Ù‚Ù„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¥Ù„ÙŠÙ‡.\n+\n+</Tip>\n+\n+### Ø§Ø®ØªÙŠØ§Ø± Ø£Ø­Ø³Ù† Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ ÙˆØ§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨ (Training hyperparameters)\n+\n+Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù† Ù…Ù† ÙØ¦Ø© [`TrainingArguments`] ÙˆØ§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ ÙˆØ§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ†Ùƒ Ø¶Ø¨Ø·Ù‡Ø§ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø®ÙŠØ§Ø±Ø§Øª ØªÙ†Ø´ÙŠØ· Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©. Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¨Ø¯Ø¡ Ø¨Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© [hyperparameters](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments)ØŒ ÙˆÙ„ÙƒÙ† Ù„Ø§ ØªØªØ±Ø¯Ø¯ ÙÙŠ ØªØ¬Ø±Ø¨ØªÙ‡Ø§ Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø«Ù„Ù‰.\n+\n+Ø­Ø¯Ø¯ Ù…ÙƒØ§Ù† Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø® Ù…Ù† ØªØ¯Ø±ÙŠØ¨Ùƒ:\n+\n+```py\n+>>> from transformers import TrainingArguments\n+\n+>>> training_args = TrainingArguments(output_dir=\"test_trainer\")\n+```\n+\n+### Ø§Ù„ØªÙ‚ÙŠÙŠÙ…\n+\n+Ù„Ø§ ÙŠÙ‚ÙˆÙ… [`Trainer`] ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¨ØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨. Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªÙ…Ø±ÙŠØ± Ø¯Ø§Ù„Ø© Ø¥Ù„Ù‰ [`Trainer`] Ù„Ø­Ø³Ø§Ø¨ ÙˆØ¥Ø¨Ù„Ø§Øº Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³. ØªÙˆÙØ± Ù…ÙƒØªØ¨Ø© [ğŸ¤— Evaluate](https://huggingface.co/docs/evaluate/index) Ø¯Ø§Ù„Ø© [`accuracy`](https://huggingface.co/spaces/evaluate-metric/accuracy) Ø¨Ø³ÙŠØ·Ø© ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„Ù‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© [`evaluate.load`] (Ø±Ø§Ø¬Ø¹ Ù‡Ø°Ø§ [Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹](https://huggingface.co/docs/evaluate/a_quick_tour) Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª):\n+\n+```py\n+>>> import numpy as np\n+>>> import evaluate\n+\n+>>> metric = evaluate.load(\"accuracy\")\n+```\n+\n+Ø§Ø³ØªØ¯Ø¹Ù Ø¯Ø§Ù„Ø© [`~evaluate.compute`] Ø¹Ù„Ù‰ `metric` Ù„Ø­Ø³Ø§Ø¨ Ø¯Ù‚Ø© ØªÙ†Ø¨Ø¤Ø§ØªÙƒ. Ù‚Ø¨Ù„ ØªÙ…Ø±ÙŠØ± ØªÙ†Ø¨Ø¤Ø§ØªÙƒ Ø¥Ù„Ù‰ Ø¯Ø§Ù„Ø© `compute`ØŒ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­ÙˆÙŠÙ„  Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø®Ø§Ù… logits Ø¥Ù„Ù‰ ØªÙ†Ø¨Ø¤Ø§Øª Ù†Ù‡Ø§Ø¦ÙŠØ© (ØªØ°ÙƒØ± Ø£Ù† Ø¬Ù…ÙŠØ¹ Ù†Ù…Ø§Ø°Ø¬ ğŸ¤— Transformers ØªØ¹ÙŠØ¯ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø®Ø§Ù… logits):\n+\n+```py\n+>>> def compute_metrics(eval_pred):\n+...     logitsØŒ labels = eval_pred\n+...     predictions = np.argmax(logits, axis=-1)\n+...     return metric.compute(predictions=predictions, references=labels)\n+```\n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ØºØ¨ ÙÙŠ Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¶Ø¨Ø· Ø§Ù„Ø¯Ù‚ÙŠÙ‚ØŒ ÙØ­Ø¯Ø¯ Ù…Ø¹Ù„Ù…Ø© `eval_strategy` ÙÙŠ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ù„Ø¥Ø¸Ù‡Ø§Ø± Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙÙŠ Ù†Ù‡Ø§ÙŠØ© ÙƒÙ„ Ø­Ù‚Ø¨Ø© ØªØ¯Ø±ÙŠØ¨Ù‡:\n+\n+```py\n+>>> from transformers import TrainingArguments, Trainer\n+\n+>>> training_args = TrainingArguments(output_dir=\"test_trainer\", eval_strategy=\"epoch\")\n+```\n+\n+### Ø§Ù„Ù…Ø¯Ø±Ø¨\n+\n+Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù† [`Trainer`] Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ÙƒØŒ ÙˆÙ…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ ÙˆÙ…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ© ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±ÙŠØ©ØŒ ÙˆØ¯Ø§Ù„Ø© Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:\n+\n+```py\n+>>> trainer = Trainer(\n+...     model=model,\n+...     args=training_args,\n+...     train_dataset=small_train_dataset,\n+...     eval_dataset=small_eval_dataset,\n+...     compute_metrics=compute_metrics,\n+... )\n+```\n+\n+Ø«Ù… Ù‚Ù… Ø¨Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ [`~transformers.Trainer.train`]:\n+\n+```py\n+>>> trainer.train()\n+```\n+</pt>\n+<tf>\n+<a id='keras'></a>\n+\n+<Youtube id=\"rnTGBy2ax1c\"/>\n+\n+## ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ TensorFlow Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Keras\n+\n+ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ ğŸ¤— Transformers ÙÙŠ TensorFlow Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Keras!\n+\n+### ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù€ Keras\n+\n+Ø¹Ù†Ø¯Ù…Ø§ ØªØ±ÙŠØ¯ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ğŸ¤— Transformers Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª KerasØŒ ÙØ£Ù†Øª Ø¨Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ ØªØ­ÙˆÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ ÙŠÙÙ‡Ù…Ù‡\n+Keras. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ ØµØºÙŠØ±Ø©ØŒ ÙÙŠÙ…ÙƒÙ†Ùƒ Ø¨Ø¨Ø³Ø§Ø·Ø© ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ§Øª NumPy ÙˆØ¥Ø±Ø³Ø§Ù„Ù‡Ø§ Ø¥Ù„Ù‰ Keras.\n+Ø¯Ø¹ÙˆÙ†Ø§ Ù†Ø¬Ø±Ø¨ Ø°Ù„Ùƒ Ø£ÙˆÙ„Ø§Ù‹ Ù‚Ø¨Ù„ Ø£Ù† Ù†Ù‚ÙˆÙ… Ø¨Ø£ÙŠ Ø´ÙŠØ¡ Ø£ÙƒØ«Ø± ØªØ¹Ù‚ÙŠØ¯Ù‹Ø§.\n+\n+Ø£ÙˆÙ„Ø§Ù‹ØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª. Ø³Ù†Ø³ØªØ®Ø¯Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª CoLA Ù…Ù† Ù…Ø¹ÙŠØ§Ø± [GLUE benchmark](https://huggingface.co/datasets/glue)ØŒ\n+Ù†Ø¸Ø±Ù‹Ø§ Ù„Ø£Ù†Ù‡ Ù…Ù‡Ù…Ø© ØªØµÙ†ÙŠÙ Ù†Øµ Ø«Ù†Ø§Ø¦ÙŠ Ø¨Ø³ÙŠØ·Ø©ØŒ ÙˆØ³Ù†Ø£Ø®Ø° ÙÙ‚Ø· Ù‚Ø³Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¢Ù†.\n+\n+```py\n+from datasets import load_dataset\n+\n+dataset = load_dataset(\"glue\"ØŒ \"cola\")\n+dataset = dataset [\"train\"] # Ø®Ø° ÙÙ‚Ø· Ù‚Ø³Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¢Ù†\n+```\n+\n+Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø£Ø¯Ø§Ø© Ø§Ù„Ù…ÙØ¬Ø²Ù‘Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ ÙˆÙ‚Ù… Ø¨ØªØ±Ù…ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ…ØµÙÙˆÙØ§Øª NumPy. Ù„Ø§Ø­Ø¸ Ø£Ù† Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ù‡ÙŠ Ø¨Ø§Ù„ÙØ¹Ù„ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† 0 Ùˆ 1ØŒ\n+Ù„Ø°Ø§ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø¨Ø¨Ø³Ø§Ø·Ø© ØªØ­ÙˆÙŠÙ„ Ø°Ù„Ùƒ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© NumPy Ø¨Ø¯ÙˆÙ† ØªØ±Ù…ÙŠØ²!\n+\n+```py\n+from transformers import AutoTokenizer\n+import numpy as np\n+\n+tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n+tokenized_data = tokenizer(dataset[\"sentence\"], return_tensors=\"np\", padding=True)\n+# Tokenizer returns a BatchEncoding, but we convert that to a dict for Keras\n+tokenized_data = dict(tokenized_data)\n+\n+labels = np.array(dataset[\"label\"])  # Label is already an array of 0 and 1\n+```\n+\n+Ø£Ø®ÙŠØ±Ù‹Ø§ØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ ÙˆØªØ¬Ù…ÙŠØ¹ ÙˆØªÙ†Ø§Ø³Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ù„Ø§Ø­Ø¸ Ø£Ù† Ù†Ù…Ø§Ø°Ø¬ Transformers ØªØ­ØªÙˆÙŠ Ø¬Ù…ÙŠØ¹Ù‡Ø§ Ø¹Ù„Ù‰ Ø¯Ø§Ù„Ø© Ø®Ø³Ø§Ø±Ø© Ø°Ø§Øª ØµÙ„Ø© Ø¨Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠØŒ Ù„Ø°Ø§ ÙØ£Ù†Øª Ù„Ø³Øª Ø¨Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ ØªØ­Ø¯ÙŠØ¯ ÙˆØ§Ø­Ø¯Ø© Ù…Ø§ Ù„Ù… ØªØ±ØºØ¨ ÙÙŠ Ø°Ù„Ùƒ:\n+\n+```py\n+from transformers import TFAutoModelForSequenceClassification\n+from tensorflow.keras.optimizers import Adam\n+\n+# ØªØ­Ù…ÙŠÙ„ ÙˆØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø®Ø§Øµ Ø¨Ù†Ø§\n+model = TFAutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\")\n+# Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ù†Ø®ÙØ¶Ø© Ø£ÙØ¶Ù„ ØºØ§Ù„Ø¨Ù‹Ø§ Ù„Ø¶Ø¨Ø· Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©\n+model.compile(optimizer=Adam(3e-5)) # Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¯Ø§Ù„Ø© Ø®Ø³Ø§Ø±Ø©!\n+\n+model.fit(tokenized_data, labels)\n+```\n+\n+<Tip>\n+\n+Ø£Ù†Øª Ù„Ø³Øª Ù…Ø¶Ø·Ø±Ù‹Ø§ Ù„ØªÙ…Ø±ÙŠØ± Ø¯Ø§Ù„Ø© Ø®Ø³Ø§Ø±Ø© Ø¥Ù„Ù‰ Ù†Ù…Ø§Ø°Ø¬Ùƒ Ø¹Ù†Ø¯ ØªØ¬Ù…ÙŠØ¹Ù‡Ø§! ØªØ®ØªØ§Ø± Ù†Ù…Ø§Ø°Ø¬ Hugging Face ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§\n+Ø¯Ø§Ù„Ø© Ø®Ø³Ø§Ø±Ø© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù…Ù‡Ù…ØªÙ‡Ø§ ÙˆÙ‡Ù†Ø¯Ø³Ø© Ù†Ù…ÙˆØ°Ø¬Ù‡Ø§ Ø¥Ø°Ø§ ØªÙØ±ÙƒØª Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø¬Ø© ÙØ§Ø±ØºØ©. ÙŠÙ…ÙƒÙ†Ùƒ Ø¯Ø§Ø¦Ù…Ù‹Ø§\n+ØªØ¬Ø§ÙˆØ² Ø°Ù„Ùƒ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ­Ø¯ÙŠØ¯ Ø¯Ø§Ù„Ø© Ø®Ø³Ø§Ø±Ø© Ø¨Ù†ÙØ³Ùƒ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ø°Ù„Ùƒ!\n+\n+</Tip>\n+\n+ÙŠØ¹Ù…Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù†Ù‡Ø¬ Ø¨Ø´ÙƒÙ„ Ø±Ø§Ø¦Ø¹ Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø©ØŒ ÙˆÙ„ÙƒÙ† Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ÙƒØ¨Ø±ØŒ ÙÙ‚Ø¯ ØªØ¬Ø¯ Ø£Ù†Ù‡ ÙŠØµØ¨Ø­ Ù…Ø´ÙƒÙ„Ø©. Ù„Ù…Ø§Ø°Ø§ØŸ\n+Ù„Ø£Ù† Ø§Ù„Ù…ØµÙÙˆÙØ© Ø§Ù„Ù…Ø±Ù…Ø²Ø© ÙˆØ§Ù„ØªØµÙ†ÙŠÙØ§Øª ÙŠØ¬Ø¨ Ø£Ù† ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡Ø§ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©ØŒ ÙˆÙ„Ø£Ù† NumPy Ù„Ø§ ÙŠØªØ¹Ø§Ù…Ù„ Ù…Ø¹\n+Ø§Ù„Ù…ØµÙÙˆÙØ§Øª\"ØºÙŠØ± Ø§Ù„Ù…Ù†ØªØ¸Ù…Ø©\"ØŒ Ù„Ø°Ø§ Ø­Ø´Ùˆ ÙƒÙ„ Ø¹ÙŠÙ†Ø©  Ø¥Ù„Ù‰ Ø·ÙˆÙ„ Ø£Ø·ÙˆÙ„ Ø¹ÙŠÙ†Ø© ÙÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§. Ø³ÙŠØ¤Ø¯ÙŠ Ø°Ù„Ùƒ Ø¥Ù„Ù‰ Ø²ÙŠØ§Ø¯Ø© Ø­Ø¬Ù… Ø§Ù„Ù…ØµÙÙˆÙØ© Ù„Ø¯ÙŠÙƒØŒ ÙˆØ³ØªØ¨Ø·Ø¦ Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø²Ø§Ø¦Ø¯Ù‡ Ù…Ù† Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø£ÙŠØ¶Ù‹Ø§!\n+\n+### ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ€ tf.data.Dataset\n+\n+Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ ØªØ¬Ù†Ø¨ Ø¥Ø¨Ø·Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ ÙÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ ÙƒÙ€ `tf.data.Dataset` Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„Ùƒ. Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø£Ù†Ù‡ ÙŠÙ…ÙƒÙ†Ùƒ ÙƒØªØ§Ø¨Ø© Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ `tf.data` Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ØŒ Ø¥Ù„Ø§ Ø£Ù† Ù„Ø¯ÙŠÙ†Ø§ Ø·Ø±ÙŠÙ‚ØªÙŠÙ† Ù…Ø®ØªØµØ±ØªÙŠÙ† Ù„Ù„Ù‚ÙŠØ§Ù… Ø¨Ø°Ù„Ùƒ:\n+- [`~TFPreTrainedModel.prepare_tf_dataset`]: Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙŠ Ù†ÙˆØµÙŠ Ø¨Ù‡Ø§ ÙÙŠ Ù…Ø¹Ø¸Ù… Ø§Ù„Ø­Ø§Ù„Ø§Øª. Ù†Ø¸Ø±Ù‹Ø§ Ù„Ø£Ù†Ù‡ Ø·Ø±ÙŠÙ‚Ø©\n+Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ÙƒØŒ ÙÙŠÙ…ÙƒÙ†Ù‡ ÙØ­Øµ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒÙ…Ø¯Ø®Ù„Ø§Øª Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ØŒ\n+ÙˆØ§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø®Ø±Ù‰ Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø¨Ø³Ø· ÙˆØ£ÙƒØ«Ø± ÙƒÙØ§Ø¡Ø©.\n+- [`~datasets.Dataset.to_tf_dataset`]: Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø£ÙƒØ«Ø± Ø£Ø³Ø§Ø³ÙŠØ©ØŒ ÙˆÙ‡ÙŠ Ù…ÙÙŠØ¯Ø© Ø¹Ù†Ø¯Ù…Ø§ ØªØ±ÙŠØ¯ Ø§Ù„ØªØ­ÙƒÙ… Ø¨Ø¯Ù‚Ø© ÙÙŠ ÙƒÙŠÙÙŠØ©\n+Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨ÙƒØŒ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ­Ø¯ÙŠØ¯ Ø£Ø¹Ù…Ø¯Ø© `columns` Ùˆ `label_cols` Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø§Ù„ØªÙŠ Ø³ÙŠØªÙ… ØªØ¶Ù…ÙŠÙ†Ù‡Ø§.\n+\n+Ù‚Ø¨Ù„ Ø£Ù† ØªØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… [`~TFPreTrainedModel.prepare_tf_dataset`]ØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¥Ø¶Ø§ÙØ© Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…ÙØ¬Ø²Ø¦ Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ ÙƒØ£Ø¹Ù…Ø¯Ø©ØŒ ÙƒÙ…Ø§ Ù‡Ùˆ Ù…ÙˆØ¶Ø­ ÙÙŠ\n+Ø¹ÙŠÙ†Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ©:\n+\n+```py\n+def tokenize_dataset (data):\n+# Ø³ØªØªÙ… Ø¥Ø¶Ø§ÙØ© Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ø°ÙŠ ØªÙ…Øª Ø¥Ø¹Ø§Ø¯ØªÙ‡ ÙƒØ£Ø¹Ù…Ø¯Ø© Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n+return tokenizer(data[\"text\"])\n+\n+\n+dataset = dataset.map(tokenize_dataset)\n+```\n+\n+ØªØ°ÙƒØ± Ø£Ù† Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Hugging Face ÙŠØªÙ… ØªØ®Ø²ÙŠÙ†Ù‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø±Øµ Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠØŒ Ù„Ø°Ø§ ÙÙ„Ù† ÙŠØ¤Ø¯ÙŠ Ø°Ù„Ùƒ Ø¥Ù„Ù‰ ØªØ¶Ø®ÙŠÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ø¯ÙŠÙƒ! Ø¨Ù…Ø¬Ø±Ø¯ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø¨Ø« Ø§Ù„Ø¯ÙØ¹Ø§Øª Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„ØªØ±Ù…ÙŠØ² Ø¥Ù„Ù‰ ÙƒÙ„ Ø¯ÙØ¹Ø©ØŒ Ù…Ù…Ø§ ÙŠÙ‚Ù„Ù„ Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ± Ù…Ù† Ø¹Ø¯Ø¯ Ø±Ù…ÙˆØ² Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ØªØ±Ù…ÙŠØ² Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§.\n+\n+\n+```py\n+>>> tf_dataset = model.prepare_tf_dataset(dataset[\"train\"], batch_size=16, shuffle=True, tokenizer=tokenizer)\n+```\n+\n+Ù„Ø§Ø­Ø¸ Ø£Ù†Ù‡ ÙÙŠ Ø¹ÙŠÙ†Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø£Ø¹Ù„Ø§Ù‡ØŒ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù…ÙØ¬Ø²Ø¦ Ø§Ù„Ù„ØºÙˆÙŠ Ø¥Ù„Ù‰ `prepare_tf_dataset` Ø­ØªÙ‰ ØªØªÙ…ÙƒÙ† Ù…Ù† Ø­Ø´Ùˆ Ø§Ù„Ø¯ÙÙØ¹Ø§Øª Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„Ù‡Ø§.\n+Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ÙÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø¨Ù†ÙØ³ Ø§Ù„Ø·ÙˆÙ„ ÙˆÙ„Ù… ÙŠÙƒÙ† Ø§Ù„ØªØ±Ù…ÙŠØ² Ø¶Ø±ÙˆØ±ÙŠÙ‹Ø§ØŒ ÙÙŠÙ…ÙƒÙ†Ùƒ ØªØ®Ø·ÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„.\n+Ø¥Ø°Ø§ ÙƒÙ†Øª Ø¨Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ø´ÙŠØ¡ Ø£ÙƒØ«Ø± ØªØ¹Ù‚ÙŠØ¯Ù‹Ø§ Ù…Ù† Ù…Ø¬Ø±Ø¯ ØªØ±Ù…ÙŠØ² Ø§Ù„Ø¹ÙŠÙ†Ø§Øª (Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¥ÙØ³Ø§Ø¯ Ø§Ù„Ø±Ù…ÙˆØ² Ù„Ù„Ù†Ù…Ø°Ø¬Ø© Ø§Ù„Ù„ØºÙˆÙŠØ© Ø§Ù„Ù…ÙÙ‚Ù†Ø¹Ø©)ØŒ\n+ÙÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù…Ù„ `collate_fn` Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„Ùƒ Ù„ØªÙ…Ø±ÙŠØ± Ø¯Ø§Ù„Ø© ÙŠØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡Ø§ Ù„ØªØ­ÙˆÙŠÙ„\n+Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø¥Ù„Ù‰ Ø¯ÙØ¹Ø© ÙˆØªØ·Ø¨ÙŠÙ‚ Ø£ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© ØªØ±ÙŠØ¯Ù‡Ø§. Ø±Ø§Ø¬Ø¹ Ø£Ù…Ø«Ù„Ø©Ù†Ø§ [examples](https://github.com/huggingface/transformers/tree/main/examples) Ø£Ùˆ\n+[Ø¯ÙØ§ØªØ± Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª](https://huggingface.co/docs/transformers/notebooks) Ù„Ø±Ø¤ÙŠØ© Ù‡Ø°Ø§ Ø§Ù„Ù†Ù‡Ø¬ ÙÙŠ Ø§Ù„Ø¹Ù…Ù„.\n+\n+Ø¨Ù…Ø¬Ø±Ø¯ Ø¥Ù†Ø´Ø§Ø¡ `tf.data.Dataset`ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªÙ†Ø§Ø³Ø¨Ù‡ ÙƒÙ…Ø§ Ù‡Ùˆ Ø§Ù„Ø­Ø§Ù„ Ù…Ù† Ù‚Ø¨Ù„:\n+\n+```py\n+model.compile(optimizer=Adam(3e-5))  # No loss argument!\n+\n+model.fit(tf_dataset)\n+```\n+\n+</tf>\n+</frameworkcontent>\n+\n+<a id='pytorch_native'></a>\n+## ØªØ¯Ø±ÙŠØ¨ ÙÙŠ PyTorch Ø§Ù„Ø£ØµÙ„ÙŠ\n+\n+<frameworkcontent>\n+<pt>\n+<Youtube id=\"Dh9CL8fyG80\"/>\n+\n+[`Trainer`] ÙŠÙ‡ØªÙ… Ø¨Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆÙŠØ³Ù…Ø­ Ù„Ùƒ Ø¨Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©. Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø°ÙŠÙ† ÙŠÙØ¶Ù„ÙˆÙ† ÙƒØªØ§Ø¨Ø© Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ù…ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ ğŸ¤— Transformers ÙÙŠ PyTorch Ø§Ù„Ø£ØµÙ„ÙŠ.\n+\n+ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©ØŒ Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø¯ÙØªØ± Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø£Ùˆ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„ØªØ­Ø±ÙŠØ± Ø¨Ø¹Ø¶ Ø§Ù„Ø°Ø§ÙƒØ±Ø©:\n+\n+```py\n+del model\n+del trainer\n+torch.cuda.empty_cache()\n+```\n+\n+Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ Ù‚Ù… Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© `tokenized_dataset` ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ù‡ Ù„Ù„ØªØ¯Ø±ÙŠØ¨.\n+\n+1. Ø¥Ø²Ø§Ù„Ø© Ø¹Ù…ÙˆØ¯ `text` Ù„Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø§ ÙŠÙ‚Ø¨Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù… ÙƒØ¥Ø¯Ø®Ø§Ù„:\n+\n+    ```py\n+    >>> tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n+    ```\n+\n+2. Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ© Ø¹Ù…ÙˆØ¯ `label` Ø¥Ù„Ù‰ `labels` Ù„Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØªÙˆÙ‚Ø¹ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø§Ø³Ù… `labels`:\n+\n+    ```py\n+    >>> tokenized_datasets = tokenized_datasets.rename_column(\"label\"ØŒ \"labels\")\n+    ```\n+\n+3. Ù‚Ù… Ø¨ØªØ¹ÙŠÙŠÙ† ØªÙ†Ø³ÙŠÙ‚ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø¥Ø±Ø¬Ø§Ø¹ Ù…Ø¤Ø´Ø±Ø§Øª PyTorch Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ø¦Ù…:\n+\n+    ```py\n+    >>> tokenized_datasets.set_format(\"torch\")\n+    ```\n+\n+Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© ÙØ±Ø¹ÙŠØ© Ø£ØµØºØ± Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ…Ø§ Ù‡Ùˆ Ù…ÙˆØ¶Ø­ Ø³Ø§Ø¨Ù‚Ù‹Ø§ Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø¶Ø¨Ø· Ø§Ù„Ø¯Ù‚ÙŠÙ‚:\n+\n+```py\n+>>> small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n+>>> small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n+```\n+\n+### DataLoader\n+\n+Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ `DataLoader` Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø­ØªÙ‰ ØªØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø± Ø¹Ø¨Ø± Ø¯ÙØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n+\n+```py\n+>>> from torch.utils.data import DataLoader\n+\n+>>> train_dataloader = DataLoader(small_train_datasetØŒ shuffle=TrueØŒ batch_size=8)\n+>>> eval_dataloader = DataLoader(small_eval_datasetØŒ batch_size=8)\n+```\n+\n+Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ù…Ø¹ Ø¹Ø¯Ø¯ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©:\n+\n+```py\n+>>> from transformers import AutoModelForSequenceClassification\n+\n+>>> model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\"ØŒ num_labels=5)\n+```\n+\n+### Ø§Ù„Ù…Ø­Ø³Ù† ÙˆÙ…Ø®Ø·Ø· Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…\n+\n+Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø³Ù† ÙˆÙ…Ø®Ø·Ø· Ù…Ø¹Ø¯Ù„ ØªØ¹Ù„Ù… Ù„Ø¶Ø¨Ø· Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¯Ù‚ÙŠÙ‚. Ø¯Ø¹Ù†Ø§ Ù†Ø³ØªØ®Ø¯Ù… [`AdamW`](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html) Ø§Ù„Ù…Ø­Ø³Ù† Ù…Ù† PyTorch:\n+\n+```py\n+>>> from torch.optim import AdamW\n+\n+>>> optimizer = AdamW(model.parameters()ØŒ lr=5e-5)\n+```\n+\n+Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù…Ù† [`Trainer`]:\n+\n+```py\n+>>> from transformers import get_scheduler\n+\n+>>> num_epochs = 3\n+>>> num_training_steps = num_epochs * len(train_dataloader)\n+>>> lr_scheduler = get_scheduler(\n+...     name=\"linear\"ØŒ optimizer=optimizerØŒ num_warmup_steps=0ØŒ num_training_steps=num_training_steps\n+... )\n+```\n+\n+Ø£Ø®ÙŠØ±Ù‹Ø§ØŒ Ø­Ø¯Ø¯ `device` Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (GPU) Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒ Ø­Ù‚ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„ÙŠÙ‡Ø§. ÙˆØ¥Ù„Ø§ØŒ ÙÙ‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© (CPU) Ø¹Ø¯Ø© Ø³Ø§Ø¹Ø§Øª Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø¯Ù‚Ø§Ø¦Ù‚ Ù‚Ù„ÙŠÙ„Ø©.\n+\n+```py\n+>>> import torch\n+\n+>>> device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n+>>> model.to(device)\n+```\n+\n+<Tip>\n+\n+Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ ÙˆØµÙˆÙ„ Ù…Ø¬Ø§Ù†ÙŠ Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³ÙˆÙ…Ø§Øª Ø³Ø­Ø§Ø¨ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù„Ø¯ÙŠÙƒ ÙˆØ§Ø­Ø¯Ø© Ù…Ø¹ Ø¯ÙØªØ± Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ø³ØªØ¶Ø§Ù Ù…Ø«Ù„ [Colaboratory](https://colab.research.google.com/) Ø£Ùˆ [SageMaker StudioLab](https://studiolab.sagemaker.aws/).\n+\n+</Tip>\n+\n+Ø±Ø§Ø¦Ø¹ØŒ Ø§Ù„Ø¢Ù† Ø£Ù†Øª Ù…Ø³ØªØ¹Ø¯ Ù„Ù„ØªØ¯Ø±ÙŠØ¨! ğŸ¥³ \n+\n+### Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n+\n+Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ØªÙ‚Ø¯Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§Øµ Ø¨ÙƒØŒ Ø§Ø³ØªØ®Ø¯Ù… Ù…ÙƒØªØ¨Ø© [tqdm](https://tqdm.github.io/) Ù„Ø¥Ø¶Ø§ÙØ© Ø´Ø±ÙŠØ· ØªÙ‚Ø¯Ù… ÙÙˆÙ‚ Ø¹Ø¯Ø¯ Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨:\n+\n+```py\n+>>> from tqdm.auto import tqdm\n+\n+>>> progress_bar = tqdm(range(num_training_steps))\n+\n+>>> model.train()\n+>>> for epoch in range(num_epochs):\n+...     for batch in train_dataloader:\n+...         batch = {k: v.to(device) for kØŒ v in batch.items()}\n+...         outputs = model(**batch)\n+...         loss = outputs.loss\n+...         loss.backward()\n+\n+...         optimizer.step()\n+...         lr_scheduler.step()\n+...         optimizer.zero_grad()\n+...         progress_bar.update(1)\n+```\n+\n+### ØªÙ‚ÙŠÙŠÙ…\n+\n+ØªÙ…Ø§Ù…Ù‹Ø§ ÙƒÙ…Ø§ Ø£Ø¶ÙØª ÙˆØ¸ÙŠÙØ© ØªÙ‚ÙŠÙŠÙ… Ø¥Ù„Ù‰ [`Trainer`]]ØŒ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù†ÙØ³ Ø§Ù„Ø´ÙŠØ¡ Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒØªØ¨ Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ. ÙˆÙ„ÙƒÙ† Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø¨Ù„Ø§Øº Ø¹Ù† Ø§Ù„Ù…Ù‚ÙŠØ§Ø³ ÙÙŠ Ù†Ù‡Ø§ÙŠØ© ÙƒÙ„ Ø­Ù‚Ø¨Ø©ØŒ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø© Ø³ØªÙ‚ÙˆÙ… Ø¨ØªØ¬Ù…ÙŠØ¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¯ÙØ¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`~evaluate.add_batch`] ÙˆØ­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚ÙŠØ§Ø³ ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©.\n+\n+```py\n+>>> import evaluate\n+\n+>>> metric = evaluate.load(\"accuracy\")\n+>>> model.eval()\n+>>> for batch in eval_dataloader:\n+...     batch = {k: v.to(device) for kØŒ v in batch.items()}\n+...     with torch.no_grad():\n+...         outputs = model(**batch)\n+\n+...     logits = outputs.logits\n+...     predictions = torch.argmax(logitsØŒ dim=-1)\n+...     metric.add_batch(predictions=predictionsØŒ references=batch[\"labels\"])\n+\n+>>> metric.compute()\n+```\n+</pt>\n+</frameworkcontent>\n+\n+<a id='additional-resources'></a>\n+\n+## Ù…ÙˆØ§Ø±Ø¯ Ø¥Ø¶Ø§ÙÙŠØ©\n+\n+Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¶Ø¨Ø· Ø§Ù„Ø¯Ù‚ÙŠÙ‚ØŒ Ø±Ø§Ø¬Ø¹:\n+\n+- [ğŸ¤— Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª](https://github.com/huggingface/transformers/tree/main/examples) ØªØªØ¶Ù…Ù†\n+  Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù‡Ø§Ù… NLP Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ PyTorch ÙˆTensorFlow.\n+\n+- [ğŸ¤— Ø¯ÙØ§ØªØ± Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª](notebooks) ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¯ÙØ§ØªØ± Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ø®ØªÙ„ÙØ© Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ù„Ù…Ù‡Ù…Ø© Ù…Ø­Ø¯Ø¯Ø© ÙÙŠ PyTorch ÙˆTensorFlow.\n\\ No newline at end of file"
        }
    ],
    "stats": {
        "total": 5837,
        "additions": 5835,
        "deletions": 2
    }
}