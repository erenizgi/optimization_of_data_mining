{
    "author": "matthewdouglas",
    "message": "Docs: update bitsandbytes torch.compile compatibility (#38651)",
    "sha": "837ddac1ec236465bb9d14c2f694b82ffa040226",
    "files": [
        {
            "sha": "9c36bb5976eadf61f7e736806396ec3169d4c7d0",
            "filename": "docs/source/en/quantization/overview.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/837ddac1ec236465bb9d14c2f694b82ffa040226/docs%2Fsource%2Fen%2Fquantization%2Foverview.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/837ddac1ec236465bb9d14c2f694b82ffa040226/docs%2Fsource%2Fen%2Fquantization%2Foverview.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fquantization%2Foverview.md?ref=837ddac1ec236465bb9d14c2f694b82ffa040226",
            "patch": "@@ -27,7 +27,7 @@ Use the Space below to help you pick a quantization method depending on your har\n | [AQLM](./aqlm)                            | 游댮                   | 游릭              |     游릭     | 游댮        | 游댮                                 | 游댮              | 游릭              | 1/2          | 游릭               | 游릭                          | 游릭                      | https://github.com/Vahe1994/AQLM            |\n | [AutoRound](./auto_round)                 | 游댮                   | 游릭               | 游릭          |   游댮        |   游댮                                |   游릭              |   游댮               | 2/3/4/8      |    游댮              |       游릭                      |    游릭                       |      https://github.com/intel/auto-round                                       |\n | [AWQ](./awq)                              | 游댮                   | 游릭              | 游릭        | 游릭        | 游댮                                 | 游릭              | ?               | 4            | 游릭               | 游릭                          | 游릭                      | https://github.com/casper-hansen/AutoAWQ    |\n-| [bitsandbytes](./bitsandbytes)            | 游릭                   | 游리 |     游릭     | 游리 | 游댮                    | 游리 | 游댮 | 4/8          | 游릭               | 游릭                          | 游릭                      | https://github.com/bitsandbytes-foundation/bitsandbytes |\n+| [bitsandbytes](./bitsandbytes)            | 游릭                   | 游리 |     游릭     | 游리 | 游댮                    | 游리 | 游릭 | 4/8          | 游릭               | 游릭                          | 游릭                      | https://github.com/bitsandbytes-foundation/bitsandbytes |\n | [compressed-tensors](./compressed_tensors) | 游댮                   | 游릭              |     游릭     | 游릭        | 游댮                                 | 游댮              | 游댮              | 1/8          | 游릭               | 游릭                          | 游릭                      | https://github.com/neuralmagic/compressed-tensors |\n | [EETQ](./eetq)                            | 游릭                   | 游댮              | 游릭        | 游댮        | 游댮                                 | 游댮              | ?               | 8            | 游릭               | 游릭                          | 游릭                      | https://github.com/NetEase-FuXi/EETQ        |\n | [GGUF / GGML (llama.cpp)](../gguf)        | 游릭                   | 游릭              | 游릭        | 游댮        | 游릭                                 | 游댮              | 游댮              | 1/8          | 游댮               | [See Notes](../gguf)     | [See Notes](../gguf) | https://github.com/ggerganov/llama.cpp      |"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}