{
    "author": "alexzms",
    "message": "[add-new-model-like] Robust search & proper outer '),' in tokenizer mapping (#38703)\n\n* [add-new-model-like] Robust search & proper outer '),' in tokenizer mapping\n\n* code-style: arrange the importation in add_new_model_like.py\n\n* Apply style fixes\n\n---------\n\nCo-authored-by: github-actions[bot] <github-actions[bot]@users.noreply.github.com>",
    "sha": "8ff22e9d3b0d14a4ae18890fbabe5ffc2d9a037b",
    "files": [
        {
            "sha": "e6ce398290a2c2096ba22a969515743c8eaee4af",
            "filename": "src/transformers/commands/add_new_model_like.py",
            "status": "modified",
            "additions": 13,
            "deletions": 3,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/8ff22e9d3b0d14a4ae18890fbabe5ffc2d9a037b/src%2Ftransformers%2Fcommands%2Fadd_new_model_like.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8ff22e9d3b0d14a4ae18890fbabe5ffc2d9a037b/src%2Ftransformers%2Fcommands%2Fadd_new_model_like.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fadd_new_model_like.py?ref=8ff22e9d3b0d14a4ae18890fbabe5ffc2d9a037b",
            "patch": "@@ -12,6 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n+# 1. Standard library\n import difflib\n import json\n import os\n@@ -28,7 +29,12 @@\n \n from ..models import auto as auto_module\n from ..models.auto.configuration_auto import model_type_to_module_name\n-from ..utils import is_flax_available, is_tf_available, is_torch_available, logging\n+from ..utils import (\n+    is_flax_available,\n+    is_tf_available,\n+    is_torch_available,\n+    logging,\n+)\n from . import BaseTransformersCLICommand\n from .add_fast_image_processor import add_fast_image_processor\n \n@@ -1009,10 +1015,11 @@ def insert_tokenizer_in_auto_module(old_model_patterns: ModelPatterns, new_model\n     with open(TRANSFORMERS_PATH / \"models\" / \"auto\" / \"tokenization_auto.py\", \"r\", encoding=\"utf-8\") as f:\n         content = f.read()\n \n+    pattern_tokenizer = re.compile(r\"^\\s*TOKENIZER_MAPPING_NAMES\\s*=\\s*OrderedDict\\b\")\n     lines = content.split(\"\\n\")\n     idx = 0\n     # First we get to the TOKENIZER_MAPPING_NAMES block.\n-    while not lines[idx].startswith(\"    TOKENIZER_MAPPING_NAMES = OrderedDict(\"):\n+    while not pattern_tokenizer.search(lines[idx]):\n         idx += 1\n     idx += 1\n \n@@ -1024,9 +1031,12 @@ def insert_tokenizer_in_auto_module(old_model_patterns: ModelPatterns, new_model\n         # Otherwise it takes several lines until we get to a \"),\"\n         else:\n             block = []\n-            while not lines[idx].startswith(\"            ),\"):\n+            # should change to \"        ),\" instead of \"            ),\"\n+            while not lines[idx].startswith(\"        ),\"):\n                 block.append(lines[idx])\n                 idx += 1\n+            # if the lines[idx] does start with \"        ),\" we still need it in our block\n+            block.append(lines[idx])\n             block = \"\\n\".join(block)\n         idx += 1\n "
        }
    ],
    "stats": {
        "total": 16,
        "additions": 13,
        "deletions": 3
    }
}