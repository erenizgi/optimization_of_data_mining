{
    "author": "eljandoubi",
    "message": "Fix ds nvme (#34444)\n\n* skip nested deepspeed.zero.Init call\r\n\r\n* make fixup\r\n\r\n* solve conflict\r\n\r\n* solve conflict\r\n\r\n* put back local\r\n\r\n* use context mangers instead of local thread\r\n\r\n* Skip recursive calls to deepspeed.zero.Init\r\n\r\n* Skip recursive calls to deepspeed.zero.Init\r\n\r\n* back to old notebooks\r\n\r\n* make style",
    "sha": "d6a5c23f71052e5405771ca6dcd3d4acbba49fc6",
    "files": [
        {
            "sha": "a4de8abed03df45495525d329764c991b18380f7",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 22,
            "deletions": 4,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/d6a5c23f71052e5405771ca6dcd3d4acbba49fc6/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d6a5c23f71052e5405771ca6dcd3d4acbba49fc6/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=d6a5c23f71052e5405771ca6dcd3d4acbba49fc6",
            "patch": "@@ -139,6 +139,7 @@\n \n _init_weights = True\n _is_quantized = False\n+_is_ds_init_called = False\n \n \n def is_fsdp_enabled():\n@@ -226,6 +227,19 @@ def set_quantized_state():\n         _is_quantized = False\n \n \n+# Skip recursive calls to deepspeed.zero.Init to avoid pinning errors.\n+# This issue occurs with ZeRO stage 3 when using NVMe offloading.\n+# For more details, refer to issue #34429.\n+@contextmanager\n+def set_zero3_state():\n+    global _is_ds_init_called\n+    _is_ds_init_called = True\n+    try:\n+        yield\n+    finally:\n+        _is_ds_init_called = False\n+\n+\n def get_parameter_device(parameter: Union[nn.Module, \"ModuleUtilsMixin\"]):\n     try:\n         return next(parameter.parameters()).device\n@@ -1473,13 +1487,14 @@ def _from_config(cls, config, **kwargs):\n                 torch_dtype=torch_dtype,\n             )\n \n-        if is_deepspeed_zero3_enabled() and not _is_quantized:\n+        if is_deepspeed_zero3_enabled() and not _is_quantized and not _is_ds_init_called:\n             import deepspeed\n \n             logger.info(\"Detected DeepSpeed ZeRO-3: activating zero.init() for this model\")\n             # this immediately partitions the model across all gpus, to avoid the overhead in time\n             # and memory copying it on CPU or each GPU first\n-            with deepspeed.zero.Init(config_dict_or_path=deepspeed_config()):\n+            init_contexts = [deepspeed.zero.Init(config_dict_or_path=deepspeed_config()), set_zero3_state()]\n+            with ContextManagers(init_contexts):\n                 model = cls(config, **kwargs)\n \n         else:\n@@ -4026,11 +4041,14 @@ def from_pretrained(\n         init_contexts = [no_init_weights(_enable=_fast_init)]\n         tp_device = None\n \n-        if is_deepspeed_zero3_enabled() and not is_quantized:\n+        if is_deepspeed_zero3_enabled() and not is_quantized and not _is_ds_init_called:\n             import deepspeed\n \n             logger.info(\"Detected DeepSpeed ZeRO-3: activating zero.init() for this model\")\n-            init_contexts = [deepspeed.zero.Init(config_dict_or_path=deepspeed_config())] + init_contexts\n+            init_contexts = [\n+                deepspeed.zero.Init(config_dict_or_path=deepspeed_config()),\n+                set_zero3_state(),\n+            ] + init_contexts\n         elif low_cpu_mem_usage:\n             if not is_accelerate_available():\n                 raise ImportError("
        }
    ],
    "stats": {
        "total": 26,
        "additions": 22,
        "deletions": 4
    }
}