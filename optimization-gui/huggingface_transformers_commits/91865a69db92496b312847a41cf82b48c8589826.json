{
    "author": "SunMarc",
    "message": "Fix FSDP bnb error  (#42600)\n\n* fix\n\n* Apply style fixes\n\n* Fix\n\n* Apply style fixes\n\n* rm\n\n---------\n\nCo-authored-by: github-actions[bot] <github-actions[bot]@users.noreply.github.com>\nCo-authored-by: Mohamed Mekkouri <93391238+MekkCyber@users.noreply.github.com>",
    "sha": "91865a69db92496b312847a41cf82b48c8589826",
    "files": [
        {
            "sha": "ed90e659d79fd265cfa17bdf591cc77ba31518cf",
            "filename": "src/transformers/integrations/bitsandbytes.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/91865a69db92496b312847a41cf82b48c8589826/src%2Ftransformers%2Fintegrations%2Fbitsandbytes.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/91865a69db92496b312847a41cf82b48c8589826/src%2Ftransformers%2Fintegrations%2Fbitsandbytes.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Fbitsandbytes.py?ref=91865a69db92496b312847a41cf82b48c8589826",
            "patch": "@@ -223,7 +223,9 @@ def _replace_with_bnb_linear(\n                             if pre_quantized:\n                                 # this is kind of an edge case when supporting both loading and quantization ...\n                                 # we need to set the right dtype as we cast the checkpoint with the dtype of the meta model\n-                                new_module.weight.data = new_module.weight.data.to(dtype=torch.uint8)\n+                                new_module.weight.data = new_module.weight.data.to(\n+                                    dtype=quantization_config.bnb_4bit_quant_storage\n+                                )\n                             model._modules[name] = new_module\n                             has_been_replaced = True\n                     # Store the module class in case we need to transpose the weight later"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 3,
        "deletions": 1
    }
}