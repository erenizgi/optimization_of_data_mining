{
    "author": "qgallouedec",
    "message": "Replace `Tokenizer` with `PreTrainedTokenizerFast` in `ContinuousBatchProcessor` (#39858)\n\nReplace Tokenizer with PreTrainedTokenizerFast in ContinuousBatchProcessor",
    "sha": "e3505cd4dcaad8d49e47b2cd61cfaee6b47cced4",
    "files": [
        {
            "sha": "9470b3f337c61d9dbf2e47d008051ba0f5c70554",
            "filename": "src/transformers/generation/continuous_batching.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/e3505cd4dcaad8d49e47b2cd61cfaee6b47cced4/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e3505cd4dcaad8d49e47b2cd61cfaee6b47cced4/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching.py?ref=e3505cd4dcaad8d49e47b2cd61cfaee6b47cced4",
            "patch": "@@ -25,12 +25,12 @@\n \n import torch\n import torch.nn as nn\n-from tokenizers import Tokenizer\n from tokenizers.decoders import DecodeStream\n from tqdm import tqdm\n \n from ..configuration_utils import PretrainedConfig\n from ..generation.configuration_utils import GenerationConfig\n+from ..tokenization_utils_fast import PreTrainedTokenizerFast\n from ..utils.logging import logging\n from ..utils.metrics import ContinuousBatchProcessorMetrics, attach_tracer, traced\n \n@@ -751,7 +751,7 @@ def __init__(\n \n         self.setup_static_tensors()\n \n-        self.tokenizer = Tokenizer.from_pretrained(self.config._name_or_path)\n+        self.tokenizer = PreTrainedTokenizerFast.from_pretrained(self.config._name_or_path)\n         self.decode_stream = DecodeStream(skip_special_tokens=True)\n \n     @traced(standalone=True)"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}