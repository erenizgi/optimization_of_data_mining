{
    "author": "kylesayrs",
    "message": "Fix `save_pretrained` for partially offloaded models (#34890)\n\n* delete unnecessary reference\n\nSigned-off-by: Kyle Sayers <kylesayrs@gmail.com>\n\n* update comment, explicit delete state_dict\n\n* Update src/transformers/modeling_utils.py\n\nCo-authored-by: Zach Mueller <muellerzr@gmail.com>\n\n* fix style\n\nSigned-off-by: Kyle Sayers <kylesayrs@gmail.com>\n\n---------\n\nSigned-off-by: Kyle Sayers <kylesayrs@gmail.com>\nCo-authored-by: Zach Mueller <muellerzr@gmail.com>",
    "sha": "4f0bf9864c9661e326640c0acbdbde75a40576c6",
    "files": [
        {
            "sha": "3f3b3d337d7119417b7797060aa56137aaf7a3c1",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 8,
            "deletions": 1,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/4f0bf9864c9661e326640c0acbdbde75a40576c6/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4f0bf9864c9661e326640c0acbdbde75a40576c6/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=4f0bf9864c9661e326640c0acbdbde75a40576c6",
            "patch": "@@ -2960,7 +2960,12 @@ def save_pretrained(\n         if module_map:\n             filename_to_tensors = logging.tqdm(filename_to_tensors, desc=\"Saving checkpoint shards\")\n         for shard_file, tensors in filename_to_tensors:\n-            shard = {tensor: state_dict[tensor].contiguous() for tensor in tensors}\n+            shard = {}\n+            for tensor in tensors:\n+                shard[tensor] = state_dict[tensor].contiguous()\n+                # delete reference, see https://github.com/huggingface/transformers/pull/34890\n+                del state_dict[tensor]\n+\n             # remake shard with onloaded parameters if necessary\n             if module_map:\n                 if accelerate_version < version.parse(\"0.31\"):\n@@ -2987,6 +2992,8 @@ def save_pretrained(\n             else:\n                 save_function(shard, os.path.join(save_directory, shard_file))\n \n+        del state_dict\n+\n         if index is None:\n             path_to_weights = os.path.join(save_directory, weights_name)\n             logger.info(f\"Model weights saved in {path_to_weights}\")"
        }
    ],
    "stats": {
        "total": 9,
        "additions": 8,
        "deletions": 1
    }
}