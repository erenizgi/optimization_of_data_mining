{
    "author": "MSt-10",
    "message": "Handle empty change indices in SAM's mask to rle conversion (#35665)\n\n* Handle empty change indices in RLE conversion for masks\r\n\r\n* [test] Add unit tests for RLE encoding of masks in SamProcessor\r\n\r\n* [test] Update RLE conversion tests to use TensorFlow implementation\r\n\r\n* [test] Fix formatting in SamProcessorTest according to check_code_quality action\r\n\r\n* [test] Fix formatting in SamProcessorTest according to check_code_quality\r\n\r\n* [test] Refactored rle test cases into one test and used tf tensors in tf test cases\r\n\r\n* [test] Fix: removed self parameter from refactored methods\r\n\r\n* [test] Removed nested methods in run-length encoding tests for PyTorch and TensorFlow\r\n\r\n* [test] Added description to individual to run-length encoding tests for PyTorch and TensorFlow.",
    "sha": "e4227eb4d4cc1ac279865a12b52f957b818616f7",
    "files": [
        {
            "sha": "ae643b367f4d5f36bd87bf2849e9a55596701c93",
            "filename": "src/transformers/models/sam/image_processing_sam.py",
            "status": "modified",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/e4227eb4d4cc1ac279865a12b52f957b818616f7/src%2Ftransformers%2Fmodels%2Fsam%2Fimage_processing_sam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e4227eb4d4cc1ac279865a12b52f957b818616f7/src%2Ftransformers%2Fmodels%2Fsam%2Fimage_processing_sam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam%2Fimage_processing_sam.py?ref=e4227eb4d4cc1ac279865a12b52f957b818616f7",
            "patch": "@@ -1373,6 +1373,14 @@ def _mask_to_rle_pytorch(input_mask: \"torch.Tensor\"):\n     out = []\n     for i in range(batch_size):\n         cur_idxs = change_indices[change_indices[:, 0] == i, 1] + 1\n+        if len(cur_idxs) == 0:\n+            # No changes => either all 0 or all 1\n+            # If the entire mask is 0, RLE is [height*width] or if the entire mask is 1, RLE is [0, height*width].\n+            if input_mask[i, 0] == 0:\n+                out.append({\"size\": [height, width], \"counts\": [height * width]})\n+            else:\n+                out.append({\"size\": [height, width], \"counts\": [0, height * width]})\n+            continue\n         btw_idxs = cur_idxs[1:] - cur_idxs[:-1]\n         counts = [] if input_mask[i, 0] == 0 else [0]\n         counts += [cur_idxs[0].item()] + btw_idxs.tolist() + [height * width - cur_idxs[-1]]\n@@ -1396,6 +1404,14 @@ def _mask_to_rle_tf(input_mask: \"tf.Tensor\"):\n     out = []\n     for i in range(batch_size):\n         cur_idxs = change_indices[change_indices[:, 0] == i, 1] + 1\n+        if len(cur_idxs) == 0:\n+            # No changes => either all 0 or all 1\n+            # If the entire mask is 0, RLE is [height*width] or if the entire mask is 1, RLE is [0, height*width].\n+            if input_mask[i, 0] == 0:\n+                out.append({\"size\": [height, width], \"counts\": [height * width]})\n+            else:\n+                out.append({\"size\": [height, width], \"counts\": [0, height * width]})\n+            continue\n         btw_idxs = cur_idxs[1:] - cur_idxs[:-1]\n         counts = [] if input_mask[i, 0] == 0 else [0]\n         counts += [cur_idxs[0].item()] + btw_idxs.tolist() + [height * width - cur_idxs[-1]]"
        },
        {
            "sha": "3a2814f8f41402bdc308a7b14fc19e15ed1f513c",
            "filename": "tests/models/sam/test_processor_sam.py",
            "status": "modified",
            "additions": 76,
            "deletions": 0,
            "changes": 76,
            "blob_url": "https://github.com/huggingface/transformers/blob/e4227eb4d4cc1ac279865a12b52f957b818616f7/tests%2Fmodels%2Fsam%2Ftest_processor_sam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e4227eb4d4cc1ac279865a12b52f957b818616f7/tests%2Fmodels%2Fsam%2Ftest_processor_sam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsam%2Ftest_processor_sam.py?ref=e4227eb4d4cc1ac279865a12b52f957b818616f7",
            "patch": "@@ -37,9 +37,13 @@\n if is_torch_available():\n     import torch\n \n+    from transformers.models.sam.image_processing_sam import _mask_to_rle_pytorch\n+\n if is_tf_available():\n     import tensorflow as tf\n \n+    from transformers.models.sam.image_processing_sam import _mask_to_rle_tf\n+\n \n @require_vision\n @require_torchvision\n@@ -161,6 +165,42 @@ def test_post_process_masks(self):\n         with self.assertRaises(ValueError):\n             masks = processor.post_process_masks(dummy_masks, np.array(original_sizes), np.array(reshaped_input_size))\n \n+    def test_rle_encoding(self):\n+        \"\"\"\n+        Test the run-length encoding function.\n+        \"\"\"\n+        # Test that a mask of all zeros returns a single run [height * width].\n+        input_mask = torch.zeros((1, 2, 2), dtype=torch.long)  # shape: 1 x 2 x 2\n+        rle = _mask_to_rle_pytorch(input_mask)\n+\n+        self.assertEqual(len(rle), 1)\n+        self.assertEqual(rle[0][\"size\"], [2, 2])\n+        # For a 2x2 all-zero mask, we expect a single run of length 4:\n+        self.assertEqual(rle[0][\"counts\"], [4])\n+\n+        # Test that a mask of all ones returns [0, height * width].\n+        input_mask = torch.ones((1, 2, 2), dtype=torch.long)  # shape: 1 x 2 x 2\n+        rle = _mask_to_rle_pytorch(input_mask)\n+\n+        self.assertEqual(len(rle), 1)\n+        self.assertEqual(rle[0][\"size\"], [2, 2])\n+        # For a 2x2 all-one mask, we expect two runs: [0, 4].\n+        self.assertEqual(rle[0][\"counts\"], [0, 4])\n+\n+        # Test a mask with mixed 0s and 1s to ensure the run-length encoding is correct.\n+        # Example mask:\n+        # Row 0: [0, 1]\n+        # Row 1: [1, 1]\n+        # This is shape (1, 2, 2).\n+        # Flattened in Fortran order -> [0, 1, 1, 1].\n+        # The RLE for [0,1,1,1] is [1, 3].\n+        input_mask = torch.tensor([[[0, 1], [1, 1]]], dtype=torch.long)\n+        rle = _mask_to_rle_pytorch(input_mask)\n+\n+        self.assertEqual(len(rle), 1)\n+        self.assertEqual(rle[0][\"size\"], [2, 2])\n+        self.assertEqual(rle[0][\"counts\"], [1, 3])  # 1 zero, followed by 3 ones\n+\n \n @require_vision\n @require_tf\n@@ -244,6 +284,42 @@ def test_post_process_masks(self):\n                 dummy_masks, np.array(original_sizes), np.array(reshaped_input_size), return_tensors=\"tf\"\n             )\n \n+    def test_rle_encoding(self):\n+        \"\"\"\n+        Test the run-length encoding function.\n+        \"\"\"\n+        # Test that a mask of all zeros returns a single run [height * width].\n+        input_mask = tf.zeros((1, 2, 2), dtype=tf.int64)  # shape: 1 x 2 x 2\n+        rle = _mask_to_rle_tf(input_mask)\n+\n+        self.assertEqual(len(rle), 1)\n+        self.assertEqual(rle[0][\"size\"], [2, 2])\n+        # For a 2x2 all-zero mask, we expect a single run of length 4:\n+        self.assertEqual(rle[0][\"counts\"], [4])\n+\n+        # Test that a mask of all ones returns [0, height * width].\n+        input_mask = tf.ones((1, 2, 2), dtype=tf.int64)  # shape: 1 x 2 x 2\n+        rle = _mask_to_rle_tf(input_mask)\n+\n+        self.assertEqual(len(rle), 1)\n+        self.assertEqual(rle[0][\"size\"], [2, 2])\n+        # For a 2x2 all-one mask, we expect two runs: [0, 4].\n+        self.assertEqual(rle[0][\"counts\"], [0, 4])\n+\n+        # Test a mask with mixed 0s and 1s to ensure the run-length encoding is correct.\n+        # Example mask:\n+        # Row 0: [0, 1]\n+        # Row 1: [1, 1]\n+        # This is shape (1, 2, 2).\n+        # Flattened in Fortran order -> [0, 1, 1, 1].\n+        # The RLE for [0,1,1,1] is [1, 3].\n+        input_mask = tf.tensor([[[0, 1], [1, 1]]], dtype=tf.int64)\n+        rle = _mask_to_rle_tf(input_mask)\n+\n+        self.assertEqual(len(rle), 1)\n+        self.assertEqual(rle[0][\"size\"], [2, 2])\n+        self.assertEqual(rle[0][\"counts\"], [1, 3])  # 1 zero, followed by 3 ones\n+\n \n @require_vision\n @require_torchvision"
        }
    ],
    "stats": {
        "total": 92,
        "additions": 92,
        "deletions": 0
    }
}