{
    "author": "rlaalsrl0922",
    "message": "[i18n-KO] Translated `keypoint_detection.md` to Korean (#36649)\n\n* fix: manual edits\n\n* fix: manual edits\n\n* fix: manual edits\n\n* Update docs/source/ko/tasks/keypoint_detection.md\r\n\r\nAnchor lower modify\n\nCo-authored-by: Woojun Jung <46880056+jungnerd@users.noreply.github.com>\n\n* Update docs/source/ko/tasks/keypoint_detection.md\r\n\r\nconnect letter\n\nCo-authored-by: Woojun Jung <46880056+jungnerd@users.noreply.github.com>\n\n* Update docs/source/ko/tasks/keypoint_detection.md\r\n\r\nmodify to usual words\n\nCo-authored-by: Woojun Jung <46880056+jungnerd@users.noreply.github.com>\n\n* Update docs/source/ko/tasks/keypoint_detection.md\r\n\r\nmodify extension word\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n* Update docs/source/ko/tasks/keypoint_detection.md\r\n\r\nmodify to usual words\n\nCo-authored-by: Woojun Jung <46880056+jungnerd@users.noreply.github.com>\n\n* Update docs/source/ko/tasks/keypoint_detection.md\r\n\r\nmodify to usual words\n\nCo-authored-by: Woojun Jung <46880056+jungnerd@users.noreply.github.com>\n\n* Update docs/source/ko/tasks/keypoint_detection.md\r\n\r\nmodify to usual representation\n\nCo-authored-by: Woojun Jung <46880056+jungnerd@users.noreply.github.com>\n\n---------\n\nCo-authored-by: Woojun Jung <46880056+jungnerd@users.noreply.github.com>\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
    "sha": "eb4afdd1fbacd632692be1b4809371959d38bff0",
    "files": [
        {
            "sha": "809fedca910f880b877ebbd145e8c217b74c4e20",
            "filename": "docs/source/ko/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/eb4afdd1fbacd632692be1b4809371959d38bff0/docs%2Fsource%2Fko%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/eb4afdd1fbacd632692be1b4809371959d38bff0/docs%2Fsource%2Fko%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2F_toctree.yml?ref=eb4afdd1fbacd632692be1b4809371959d38bff0",
            "patch": "@@ -77,6 +77,8 @@\n         title: 이미지 특징 추출\n       - local: tasks/mask_generation\n         title: 마스크 생성\n+      - local: tasks/keypoint_detection\n+        title: 키포인트 탐지\n       - local: tasks/knowledge_distillation_for_image_classification\n         title: 컴퓨터 비전(이미지 분류)를 위한 지식 증류(knowledge distillation)\n     title: 컴퓨터 비전"
        },
        {
            "sha": "bffca9b284cf75c605ee8b07e599ed05f7fbe534",
            "filename": "docs/source/ko/tasks/keypoint_detection.md",
            "status": "added",
            "additions": 155,
            "deletions": 0,
            "changes": 155,
            "blob_url": "https://github.com/huggingface/transformers/blob/eb4afdd1fbacd632692be1b4809371959d38bff0/docs%2Fsource%2Fko%2Ftasks%2Fkeypoint_detection.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/eb4afdd1fbacd632692be1b4809371959d38bff0/docs%2Fsource%2Fko%2Ftasks%2Fkeypoint_detection.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Fkeypoint_detection.md?ref=eb4afdd1fbacd632692be1b4809371959d38bff0",
            "patch": "@@ -0,0 +1,155 @@\n+<!--Copyright 2023 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n+\n+⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+\n+# 키포인트 탐지 [[keypoint-detection]]\n+\n+[[open-in-colab]]\n+\n+키포인트 감지(Keypoint detection)은 이미지 내의 특정 포인트를 식별하고 위치를 탐지합니다. 이러한 키포인트는 랜드마크라고도 불리며 얼굴 특징이나 물체의 일부와 같은 의미 있는 특징을 나타냅니다.\n+키포인트 감지 모델들은 이미지를 입력으로 받아 아래와 같은 출력을 반환합니다.\n+\n+- **키포인트들과 점수**: 관심 포인트들과 해당 포인트에 대한 신뢰도 점수\n+- **디스크립터(Descriptors)**: 각 키포인트를 둘러싼 이미지 영역의 표현으로 텍스처, 그라데이션, 방향 및 기타 속성을 캡처합니다.\n+\n+이번 가이드에서는 이미지에서 키포인트를 추출하는 방법을 다루어 보겠습니다.\n+\n+이번 튜토리얼에서는 키포인트 감지의 기본이 되는 모델인 [SuperPoint](./model_doc/superpoint)를 사용해보겠습니다.\n+\n+```python\n+from transformers import AutoImageProcessor, SuperPointForKeypointDetection\n+processor = AutoImageProcessor.from_pretrained(\"magic-leap-community/superpoint\")\n+model = SuperPointForKeypointDetection.from_pretrained(\"magic-leap-community/superpoint\")\n+```\n+아래의 이미지로 모델을 테스트 해보겠습니다.\n+\n+<div style=\"display: flex; align-items: center;\">\n+    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\" \n+         alt=\"Bee\" \n+         style=\"height: 200px; object-fit: contain; margin-right: 10px;\">\n+    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/cats.png\" \n+         alt=\"Cats\" \n+         style=\"height: 200px; object-fit: contain;\">\n+</div>\n+\n+\n+```python\n+import torch\n+from PIL import Image\n+import requests\n+import cv2\n+\n+\n+url_image_1 = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\"\n+image_1 = Image.open(requests.get(url_image_1, stream=True).raw)\n+url_image_2 = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/cats.png\"\n+image_2 = Image.open(requests.get(url_image_2, stream=True).raw)\n+\n+images = [image_1, image_2]\n+```\n+\n+이제 입력을 처리하고 추론을 할 수 있습니다.\n+\n+\n+```python\n+inputs = processor(images,return_tensors=\"pt\").to(model.device, model.dtype)\n+outputs = model(**inputs)\n+```\n+모델 출력에는 배치 내의 각 항목에 대한 상대적인 키포인트, 디스크립터, 마스크와 점수가 있습니다. 마스크는 이미지에서 키포인트가 있는 영역을 강조하는 역할을 합니다.\n+\n+```python\n+SuperPointKeypointDescriptionOutput(loss=None, keypoints=tensor([[[0.0437, 0.0167],\n+         [0.0688, 0.0167],\n+         [0.0172, 0.0188],\n+         ...,\n+         [0.5984, 0.9812],\n+         [0.6953, 0.9812]]]), \n+         scores=tensor([[0.0056, 0.0053, 0.0079,  ..., 0.0125, 0.0539, 0.0377],\n+        [0.0206, 0.0058, 0.0065,  ..., 0.0000, 0.0000, 0.0000]],\n+       grad_fn=<CopySlices>), descriptors=tensor([[[-0.0807,  0.0114, -0.1210,  ..., -0.1122,  0.0899,  0.0357],\n+         [-0.0807,  0.0114, -0.1210,  ..., -0.1122,  0.0899,  0.0357],\n+         [-0.0807,  0.0114, -0.1210,  ..., -0.1122,  0.0899,  0.0357],\n+         ...],\n+       grad_fn=<CopySlices>), mask=tensor([[1, 1, 1,  ..., 1, 1, 1],\n+        [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32), hidden_states=None)\n+```\n+\n+이미지에 실제 키포인트를 표시하기 위해선 결과값을 후처리 해야합니다. 이를 위해 실제 이미지 크기를 결과값과 함께 `post_process_keypoint_detection`에 전달해야 합니다.\n+\n+```python\n+image_sizes = [(image.size[1], image.size[0]) for image in images]\n+outputs = processor.post_process_keypoint_detection(outputs, image_sizes)\n+```\n+\n+위 코드를 통해 결과값은 딕셔너리를 갖는 리스트가 되고, 각 딕셔너리들은 후처리된 키포인트, 점수 및 디스크립터로 이루어져있습니다.\n+\n+\n+```python\n+[{'keypoints': tensor([[ 226,   57],\n+          [ 356,   57],\n+          [  89,   64],\n+          ...,\n+          [3604, 3391]], dtype=torch.int32),\n+  'scores': tensor([0.0056, 0.0053, ...], grad_fn=<IndexBackward0>),\n+  'descriptors': tensor([[-0.0807,  0.0114, -0.1210,  ..., -0.1122,  0.0899,  0.0357],\n+          [-0.0807,  0.0114, -0.1210,  ..., -0.1122,  0.0899,  0.0357]],\n+         grad_fn=<IndexBackward0>)},\n+    {'keypoints': tensor([[ 46,   6],\n+          [ 78,   6],\n+          [422,   6],\n+          [206, 404]], dtype=torch.int32),\n+  'scores': tensor([0.0206, 0.0058, 0.0065, 0.0053, 0.0070, ...,grad_fn=<IndexBackward0>),\n+  'descriptors': tensor([[-0.0525,  0.0726,  0.0270,  ...,  0.0389, -0.0189, -0.0211],\n+          [-0.0525,  0.0726,  0.0270,  ...,  0.0389, -0.0189, -0.0211]}]\n+```\n+\n+이제 위 딕셔너리를 사용하여 키포인트를 표시할 수 있습니다.\n+\n+```python\n+import matplotlib.pyplot as plt\n+import torch\n+\n+for i in range(len(images)):\n+  keypoints = outputs[i][\"keypoints\"]\n+  scores = outputs[i][\"scores\"]\n+  descriptors = outputs[i][\"descriptors\"]\n+  keypoints = outputs[i][\"keypoints\"].detach().numpy()\n+  scores = outputs[i][\"scores\"].detach().numpy()\n+  image = images[i]\n+  image_width, image_height = image.size\n+\n+  plt.axis('off')\n+  plt.imshow(image)\n+  plt.scatter(\n+      keypoints[:, 0],\n+      keypoints[:, 1],\n+      s=scores * 100,\n+      c='cyan',\n+      alpha=0.4\n+  )\n+  plt.show()\n+```\n+\n+아래에서 결과를 확인할 수 있습니다.\n+\n+<div style=\"display: flex; align-items: center;\">\n+    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee_keypoint.png\" \n+         alt=\"Bee\" \n+         style=\"height: 200px; object-fit: contain; margin-right: 10px;\">\n+    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/cats_keypoint.png\" \n+         alt=\"Cats\" \n+         style=\"height: 200px; object-fit: contain;\">\n+</div>\n+"
        }
    ],
    "stats": {
        "total": 157,
        "additions": 157,
        "deletions": 0
    }
}