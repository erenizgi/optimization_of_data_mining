{
    "author": "MekkCyber",
    "message": "Fix docker CI : install autogptq from source (#35000)\n\n* Fixed Docker\r\n\r\n* Test ci\r\n\r\n* Finally\r\n\r\n* add comment",
    "sha": "f491096f7d55a72b2ac364ca14668d6f577ad8fc",
    "files": [
        {
            "sha": "089be4a44601015ec1c2063c5f8aa3304a0c77cb",
            "filename": "docker/transformers-quantization-latest-gpu/Dockerfile",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f491096f7d55a72b2ac364ca14668d6f577ad8fc/docker%2Ftransformers-quantization-latest-gpu%2FDockerfile",
            "raw_url": "https://github.com/huggingface/transformers/raw/f491096f7d55a72b2ac364ca14668d6f577ad8fc/docker%2Ftransformers-quantization-latest-gpu%2FDockerfile",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docker%2Ftransformers-quantization-latest-gpu%2FDockerfile?ref=f491096f7d55a72b2ac364ca14668d6f577ad8fc",
            "patch": "@@ -36,8 +36,10 @@ RUN python3 -m pip install --no-cache-dir einops\n # Add bitsandbytes for mixed int8 testing\n RUN python3 -m pip install --no-cache-dir bitsandbytes\n \n-# Add auto-gptq for gtpq quantization testing\n-RUN python3 -m pip install --no-cache-dir auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/\n+# Add auto-gptq for gtpq quantization testing, installed from source for pytorch==2.5.1 compatibility\n+# TORCH_CUDA_ARCH_LIST=\"7.5+PTX\" is added to make the package compile for Tesla T4 gpus available for the CI.\n+RUN pip install gekko\n+RUN git clone https://github.com/PanQiWei/AutoGPTQ.git && cd AutoGPTQ && TORCH_CUDA_ARCH_LIST=\"7.5+PTX\" python3 setup.py install\n \n # Add optimum for gptq quantization testing\n RUN python3 -m pip install --no-cache-dir git+https://github.com/huggingface/optimum@main#egg=optimum"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 4,
        "deletions": 2
    }
}