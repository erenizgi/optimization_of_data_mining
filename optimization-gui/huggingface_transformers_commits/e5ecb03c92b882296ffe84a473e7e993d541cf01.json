{
    "author": "yuanwu2017",
    "message": "Fix the issue that csm model cannot work with pipeline mode. (#39349)\n\n* Fix the issue that csm model cannot work with pipeline mode.\n\nSigned-off-by: yuanwu <yuan.wu@intel.com>\n\n* Remove batching inference\n\nSigned-off-by: yuanwu <yuan.wu@intel.com>\n\n* csm output is list of tensor\n\nSigned-off-by: yuanwu <yuan.wu@intel.com>\n\n* Update src/transformers/pipelines/text_to_audio.py\n\nCo-authored-by: eustlb <94853470+eustlb@users.noreply.github.com>\n\n* Use different waveform key for different model\n\nSigned-off-by: yuanwu <yuan.wu@intel.com>\n\n* Fix make style errors\n\nSigned-off-by: yuanwu <yuan.wu@intel.com>\n\n* Add csm tests\n\nSigned-off-by: yuanwu <yuanwu@habana.ai>\n\n* Update src/transformers/models/auto/tokenization_auto.py\n\n---------\n\nSigned-off-by: yuanwu <yuan.wu@intel.com>\nSigned-off-by: yuanwu <yuanwu@habana.ai>\nCo-authored-by: eustlb <94853470+eustlb@users.noreply.github.com>",
    "sha": "e5ecb03c92b882296ffe84a473e7e993d541cf01",
    "files": [
        {
            "sha": "7b38f2ad8bcb7ed1f8eb9c98fe26974472f1ef8a",
            "filename": "src/transformers/models/auto/tokenization_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/e5ecb03c92b882296ffe84a473e7e993d541cf01/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e5ecb03c92b882296ffe84a473e7e993d541cf01/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py?ref=e5ecb03c92b882296ffe84a473e7e993d541cf01",
            "patch": "@@ -167,6 +167,7 @@\n             ),\n         ),\n         (\"cpmant\", (\"CpmAntTokenizer\", None)),\n+        (\"csm\", (None, \"PreTrainedTokenizerFast\" if is_tokenizers_available() else None)),\n         (\"ctrl\", (\"CTRLTokenizer\", None)),\n         (\"data2vec-audio\", (\"Wav2Vec2CTCTokenizer\", None)),\n         (\"data2vec-text\", (\"RobertaTokenizer\", \"RobertaTokenizerFast\" if is_tokenizers_available() else None)),"
        },
        {
            "sha": "17eaba1466b34811e894064259e2045d330d6b9d",
            "filename": "src/transformers/pipelines/text_to_audio.py",
            "status": "modified",
            "additions": 14,
            "deletions": 2,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/e5ecb03c92b882296ffe84a473e7e993d541cf01/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e5ecb03c92b882296ffe84a473e7e993d541cf01/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py?ref=e5ecb03c92b882296ffe84a473e7e993d541cf01",
            "patch": "@@ -127,6 +127,10 @@ def __init__(self, *args, vocoder=None, sampling_rate=None, no_processor=True, *\n                 sampling_rate = getattr(config, sampling_rate_name, None)\n                 if sampling_rate is not None:\n                     self.sampling_rate = sampling_rate\n+                elif getattr(config, \"codec_config\", None) is not None:\n+                    sampling_rate = getattr(config.codec_config, sampling_rate_name, None)\n+                    if sampling_rate is not None:\n+                        self.sampling_rate = sampling_rate\n \n         # last fallback to get the sampling rate based on processor\n         if self.sampling_rate is None and not self.no_processor and hasattr(self.processor, \"feature_extractor\"):\n@@ -247,10 +251,15 @@ def _sanitize_parameters(\n     def postprocess(self, audio):\n         output_dict = {}\n \n+        if self.model.config.model_type == \"csm\":\n+            waveform_key = \"audio\"\n+        else:\n+            waveform_key = \"waveform\"\n+\n         # We directly get the waveform\n         if self.no_processor:\n             if isinstance(audio, dict):\n-                waveform = audio[\"waveform\"]\n+                waveform = audio[waveform_key]\n             elif isinstance(audio, tuple):\n                 waveform = audio[0]\n             else:\n@@ -259,7 +268,10 @@ def postprocess(self, audio):\n         else:\n             waveform = self.processor.decode(audio)\n \n-        output_dict[\"audio\"] = waveform.to(device=\"cpu\", dtype=torch.float).numpy()\n+        if isinstance(audio, list):\n+            output_dict[\"audio\"] = [el.to(device=\"cpu\", dtype=torch.float).numpy() for el in waveform]\n+        else:\n+            output_dict[\"audio\"] = waveform.to(device=\"cpu\", dtype=torch.float).numpy()\n         output_dict[\"sampling_rate\"] = self.sampling_rate\n \n         return output_dict"
        },
        {
            "sha": "be49e1c7bdc53259a45effe40d2fd509b37beb2c",
            "filename": "tests/pipelines/test_pipelines_text_to_audio.py",
            "status": "modified",
            "additions": 20,
            "deletions": 0,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/e5ecb03c92b882296ffe84a473e7e993d541cf01/tests%2Fpipelines%2Ftest_pipelines_text_to_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e5ecb03c92b882296ffe84a473e7e993d541cf01/tests%2Fpipelines%2Ftest_pipelines_text_to_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_text_to_audio.py?ref=e5ecb03c92b882296ffe84a473e7e993d541cf01",
            "patch": "@@ -247,6 +247,26 @@ def test_generative_model_kwargs(self):\n         outputs = music_generator(\"This is a test\", forward_params=forward_params, generate_kwargs=generate_kwargs)\n         self.assertListEqual(outputs[\"audio\"].tolist(), audio.tolist())\n \n+    @slow\n+    @require_torch\n+    def test_csm_model_pt(self):\n+        speech_generator = pipeline(task=\"text-to-audio\", model=\"sesame/csm-1b\", framework=\"pt\")\n+\n+        outputs = speech_generator(\"[0]This is a test\")\n+        self.assertEqual(outputs[\"sampling_rate\"], 24000)\n+\n+        audio = outputs[\"audio\"]\n+        self.assertEqual(ANY(np.ndarray), audio)\n+\n+        # test two examples side-by-side\n+        outputs = speech_generator([\"[0]This is a test\", \"[0]This is a second test\"])\n+        audio = [output[\"audio\"] for output in outputs]\n+        self.assertEqual([ANY(np.ndarray), ANY(np.ndarray)], audio)\n+\n+        # test batching\n+        outputs = speech_generator([\"[0]This is a test\", \"[0]This is a second test\"], batch_size=2)\n+        self.assertEqual(ANY(np.ndarray), outputs[0][\"audio\"])\n+\n     def get_test_pipeline(\n         self,\n         model,"
        }
    ],
    "stats": {
        "total": 37,
        "additions": 35,
        "deletions": 2
    }
}