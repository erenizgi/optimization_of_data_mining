{
    "author": "Rocketknight1",
    "message": "Fix pipeline+peft interaction (#36480)\n\n* Fix pipeline-peft interaction\n\n* once again you have committed a debug breakpoint\n\n* Remove extra testing line\n\n* Add a test to check adapter loading\n\n* Correct adapter path\n\n* make fixup\n\n* Remove unnecessary check\n\n* Make check a little more stringent",
    "sha": "2aff938992b756a6670f196e589a9ae6aa446b26",
    "files": [
        {
            "sha": "e57e1fac5126e73d5a151aad6dd68ab8a1749c9c",
            "filename": "src/transformers/pipelines/__init__.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2aff938992b756a6670f196e589a9ae6aa446b26/src%2Ftransformers%2Fpipelines%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2aff938992b756a6670f196e589a9ae6aa446b26/src%2Ftransformers%2Fpipelines%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2F__init__.py?ref=2aff938992b756a6670f196e589a9ae6aa446b26",
            "patch": "@@ -824,6 +824,7 @@ def pipeline(\n \n     # Config is the primordial information item.\n     # Instantiate config if needed\n+    adapter_path = None\n     if isinstance(config, str):\n         config = AutoConfig.from_pretrained(\n             config, _from_pipeline=task, code_revision=code_revision, **hub_kwargs, **model_kwargs\n@@ -844,6 +845,7 @@ def pipeline(\n             if maybe_adapter_path is not None:\n                 with open(maybe_adapter_path, \"r\", encoding=\"utf-8\") as f:\n                     adapter_config = json.load(f)\n+                    adapter_path = model\n                     model = adapter_config[\"base_model_name_or_path\"]\n \n         config = AutoConfig.from_pretrained(\n@@ -938,7 +940,7 @@ def pipeline(\n     if isinstance(model, str) or framework is None:\n         model_classes = {\"tf\": targeted_task[\"tf\"], \"pt\": targeted_task[\"pt\"]}\n         framework, model = infer_framework_load_model(\n-            model,\n+            adapter_path if adapter_path is not None else model,\n             model_classes=model_classes,\n             config=config,\n             framework=framework,"
        },
        {
            "sha": "5ebb53c5be4de7b8c38ca0b82a5210281cb47d59",
            "filename": "tests/peft_integration/test_peft_integration.py",
            "status": "modified",
            "additions": 7,
            "deletions": 3,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/2aff938992b756a6670f196e589a9ae6aa446b26/tests%2Fpeft_integration%2Ftest_peft_integration.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2aff938992b756a6670f196e589a9ae6aa446b26/tests%2Fpeft_integration%2Ftest_peft_integration.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpeft_integration%2Ftest_peft_integration.py?ref=2aff938992b756a6670f196e589a9ae6aa446b26",
            "patch": "@@ -526,9 +526,13 @@ def test_peft_pipeline(self):\n         \"\"\"\n         from transformers import pipeline\n \n-        for model_id in self.peft_test_model_ids:\n-            pipe = pipeline(\"text-generation\", model_id)\n-            _ = pipe(\"Hello\")\n+        for adapter_id, base_model_id in zip(self.peft_test_model_ids, self.transformers_test_model_ids):\n+            peft_pipe = pipeline(\"text-generation\", adapter_id)\n+            base_pipe = pipeline(\"text-generation\", base_model_id)\n+            peft_params = list(peft_pipe.model.parameters())\n+            base_params = list(base_pipe.model.parameters())\n+            self.assertNotEqual(len(peft_params), len(base_params))  # Assert we actually loaded the adapter too\n+            _ = peft_pipe(\"Hello\")\n \n     def test_peft_add_adapter_with_state_dict(self):\n         \"\"\""
        }
    ],
    "stats": {
        "total": 14,
        "additions": 10,
        "deletions": 4
    }
}