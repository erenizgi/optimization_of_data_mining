{
    "author": "zucchini-nlp",
    "message": "[Idefics] fix device mismatch (#39981)\n\nfix",
    "sha": "555cbf59178134d1b713a7022129aaddfe6e70cf",
    "files": [
        {
            "sha": "97ad4c7116510c3740fa425bf5388e1eca0ae4ef",
            "filename": "src/transformers/models/idefics2/modeling_idefics2.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/555cbf59178134d1b713a7022129aaddfe6e70cf/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/555cbf59178134d1b713a7022129aaddfe6e70cf/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py?ref=555cbf59178134d1b713a7022129aaddfe6e70cf",
            "patch": "@@ -147,8 +147,8 @@ def forward(self, pixel_values: torch.FloatTensor, patch_attention_mask: torch.B\n             nb_patches_h = p_attn_mask[:, 0].sum()\n             nb_patches_w = p_attn_mask[0].sum()\n \n-            h_indices = torch.arange(nb_patches_h, device=pixel_values.device, dtype=pixel_values.dtype)\n-            w_indices = torch.arange(nb_patches_w, device=pixel_values.device, dtype=pixel_values.dtype)\n+            h_indices = torch.arange(nb_patches_h, device=position_ids.device, dtype=position_ids.dtype)\n+            w_indices = torch.arange(nb_patches_w, device=position_ids.device, dtype=position_ids.dtype)\n \n             fractional_coords_h = h_indices / nb_patches_h * (1 - 1e-6)\n             fractional_coords_w = w_indices / nb_patches_w * (1 - 1e-6)"
        },
        {
            "sha": "a19099d14302f8202216e573daaa1deaa61f4543",
            "filename": "src/transformers/models/idefics3/modeling_idefics3.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/555cbf59178134d1b713a7022129aaddfe6e70cf/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/555cbf59178134d1b713a7022129aaddfe6e70cf/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py?ref=555cbf59178134d1b713a7022129aaddfe6e70cf",
            "patch": "@@ -147,8 +147,8 @@ def forward(self, pixel_values: torch.FloatTensor, patch_attention_mask: torch.B\n             nb_patches_h = p_attn_mask[:, 0].sum()\n             nb_patches_w = p_attn_mask[0].sum()\n \n-            h_indices = torch.arange(nb_patches_h, device=pixel_values.device, dtype=pixel_values.dtype)\n-            w_indices = torch.arange(nb_patches_w, device=pixel_values.device, dtype=pixel_values.dtype)\n+            h_indices = torch.arange(nb_patches_h, device=position_ids.device, dtype=position_ids.dtype)\n+            w_indices = torch.arange(nb_patches_w, device=position_ids.device, dtype=position_ids.dtype)\n \n             fractional_coords_h = h_indices / nb_patches_h * (1 - 1e-6)\n             fractional_coords_w = w_indices / nb_patches_w * (1 - 1e-6)"
        },
        {
            "sha": "23db21c8d68ad692ecdfacd17b07f7c32f918a8a",
            "filename": "src/transformers/models/smolvlm/modeling_smolvlm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/555cbf59178134d1b713a7022129aaddfe6e70cf/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fmodeling_smolvlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/555cbf59178134d1b713a7022129aaddfe6e70cf/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fmodeling_smolvlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fmodeling_smolvlm.py?ref=555cbf59178134d1b713a7022129aaddfe6e70cf",
            "patch": "@@ -142,8 +142,8 @@ def forward(self, pixel_values: torch.FloatTensor, patch_attention_mask: torch.B\n             nb_patches_h = p_attn_mask[:, 0].sum()\n             nb_patches_w = p_attn_mask[0].sum()\n \n-            h_indices = torch.arange(nb_patches_h, device=pixel_values.device, dtype=pixel_values.dtype)\n-            w_indices = torch.arange(nb_patches_w, device=pixel_values.device, dtype=pixel_values.dtype)\n+            h_indices = torch.arange(nb_patches_h, device=position_ids.device, dtype=position_ids.dtype)\n+            w_indices = torch.arange(nb_patches_w, device=position_ids.device, dtype=position_ids.dtype)\n \n             fractional_coords_h = h_indices / nb_patches_h * (1 - 1e-6)\n             fractional_coords_w = w_indices / nb_patches_w * (1 - 1e-6)"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 6,
        "deletions": 6
    }
}