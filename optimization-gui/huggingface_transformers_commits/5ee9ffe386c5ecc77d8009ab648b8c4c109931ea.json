{
    "author": "qihqi",
    "message": "Let transformers know when a model is being traced via jax.jit (torchax) (#42611)\n\n* Let transformers know when a model is being traced via jax.jit\n\nMove check earler\n\n* Add docstring\n\n* add docstring\n\n---------\n\nCo-authored-by: Cyril Vallez <cyril.vallez@gmail.com>",
    "sha": "5ee9ffe386c5ecc77d8009ab648b8c4c109931ea",
    "files": [
        {
            "sha": "af34c54ed305167ab89dfcb76b81030f6e048fcb",
            "filename": "src/transformers/utils/import_utils.py",
            "status": "modified",
            "additions": 31,
            "deletions": 1,
            "changes": 32,
            "blob_url": "https://github.com/huggingface/transformers/blob/5ee9ffe386c5ecc77d8009ab648b8c4c109931ea/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5ee9ffe386c5ecc77d8009ab648b8c4c109931ea/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fimport_utils.py?ref=5ee9ffe386c5ecc77d8009ab648b8c4c109931ea",
            "patch": "@@ -1308,6 +1308,34 @@ def is_torch_fx_proxy(x):\n         return False\n \n \n+def is_jax_jitting(x):\n+    \"\"\"returns True if we are inside of `jax.jit` context, False otherwise.\n+\n+    When a torch model is being compiled with `jax.jit` using torchax,\n+    the tensor that goes through the model would be an instance of\n+    `torchax.tensor.Tensor`, which is a tensor subclass. This tensor has\n+    a `jax` method to return the inner Jax array\n+    (https://github.com/google/torchax/blob/13ce870a1d9adb2430333c27bb623469e3aea34e/torchax/tensor.py#L134).\n+    Here we use ducktyping to detect if the inner jax array is a jax Tracer\n+    then we are in tracing context. (See more at: https://github.com/jax-ml/jax/discussions/9241)\n+\n+    Args:\n+      x: torch.Tensor\n+\n+    Returns:\n+      bool: whether we are inside of jax jit tracing.\n+    \"\"\"\n+\n+    if not hasattr(x, \"jax\"):\n+        return False\n+    try:\n+        import jax\n+\n+        return isinstance(x.jax(), jax.core.Tracer)\n+    except Exception:\n+        return False\n+\n+\n def is_jit_tracing() -> bool:\n     try:\n         import torch\n@@ -1327,12 +1355,14 @@ def is_cuda_stream_capturing() -> bool:\n \n \n def is_tracing(tensor=None) -> bool:\n-    \"\"\"Checks whether we are tracing a graph with dynamo (compile or export), torch.jit, torch.fx or CUDA stream capturing\"\"\"\n+    \"\"\"Checks whether we are tracing a graph with dynamo (compile or export), torch.jit, torch.fx, jax.jit (with torchax) or\n+    CUDA stream capturing\"\"\"\n     # Note that `is_torchdynamo_compiling` checks both compiling and exporting (the export check is stricter and\n     # only checks export)\n     _is_tracing = is_torchdynamo_compiling() or is_jit_tracing() or is_cuda_stream_capturing()\n     if tensor is not None:\n         _is_tracing |= is_torch_fx_proxy(tensor)\n+        _is_tracing |= is_jax_jitting(tensor)\n     return _is_tracing\n \n "
        }
    ],
    "stats": {
        "total": 32,
        "additions": 31,
        "deletions": 1
    }
}