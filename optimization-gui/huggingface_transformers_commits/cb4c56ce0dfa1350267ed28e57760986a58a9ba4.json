{
    "author": "framoncg",
    "message": "Fix typo in Language Modeling example scripts and update TPU type (#38652)\n\n* Fix typo that prevents the examples to be run correctly\n\n* return .TPU in accelerator.distributedtype comparison",
    "sha": "cb4c56ce0dfa1350267ed28e57760986a58a9ba4",
    "files": [
        {
            "sha": "eca05c10dc3584c73a5b40f96ac6fa81339f965a",
            "filename": "examples/pytorch/language-modeling/run_fim.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cb4c56ce0dfa1350267ed28e57760986a58a9ba4/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cb4c56ce0dfa1350267ed28e57760986a58a9ba4/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim.py?ref=cb4c56ce0dfa1350267ed28e57760986a58a9ba4",
            "patch": "@@ -521,7 +521,7 @@ def main():\n \n     # Get the factor by which the embedding layer should be padded based on the device\n     pad_factor = 1\n-    if torch.cuda.is_availble():\n+    if torch.cuda.is_available():\n         pad_factor = 8\n \n     elif is_torch_xla_available(check_is_tpu=True):"
        },
        {
            "sha": "654b870025ba863a39458c43bf19b32eceffd968",
            "filename": "examples/pytorch/language-modeling/run_fim_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cb4c56ce0dfa1350267ed28e57760986a58a9ba4/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cb4c56ce0dfa1350267ed28e57760986a58a9ba4/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py?ref=cb4c56ce0dfa1350267ed28e57760986a58a9ba4",
            "patch": "@@ -488,7 +488,7 @@ def main():\n \n     # Get the factor by which the embedding layer should be padded based on the device\n     pad_factor = 1\n-    if torch.cuda.is_availble():\n+    if torch.cuda.is_available():\n         pad_factor = 8\n \n     elif is_torch_xla_available(check_is_tpu=True):"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}