{
    "author": "gante",
    "message": "[cli] cli usable without torch (#38386)\n\ncli without torch",
    "sha": "cd0f3ce73b462a58fd2ad37188be307cbdd42357",
    "files": [
        {
            "sha": "04a1b11a21ce62ffe07a7d3e298ad46a8eaab150",
            "filename": "src/transformers/commands/chat.py",
            "status": "modified",
            "additions": 3,
            "deletions": 8,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd0f3ce73b462a58fd2ad37188be307cbdd42357/src%2Ftransformers%2Fcommands%2Fchat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd0f3ce73b462a58fd2ad37188be307cbdd42357/src%2Ftransformers%2Fcommands%2Fchat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fchat.py?ref=cd0f3ce73b462a58fd2ad37188be307cbdd42357",
            "patch": "@@ -26,6 +26,7 @@\n \n import yaml\n \n+from transformers import AutoTokenizer, GenerationConfig, TextIteratorStreamer\n from transformers.utils import is_rich_available, is_torch_available\n \n from . import BaseTransformersCLICommand\n@@ -42,13 +43,7 @@\n if is_torch_available():\n     import torch\n \n-    from transformers import (\n-        AutoModelForCausalLM,\n-        AutoTokenizer,\n-        BitsAndBytesConfig,\n-        GenerationConfig,\n-        TextIteratorStreamer,\n-    )\n+    from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n \n \n ALLOWED_KEY_CHARS = set(string.ascii_letters + string.whitespace)\n@@ -547,7 +542,7 @@ def get_quantization_config(model_args: ChatArguments) -> Optional[\"BitsAndBytes\n \n         return quantization_config\n \n-    def load_model_and_tokenizer(self, args: ChatArguments) -> tuple[AutoModelForCausalLM, AutoTokenizer]:\n+    def load_model_and_tokenizer(self, args: ChatArguments) -> tuple[\"AutoModelForCausalLM\", AutoTokenizer]:\n         tokenizer = AutoTokenizer.from_pretrained(\n             args.model_name_or_path_positional,\n             revision=args.model_revision,"
        }
    ],
    "stats": {
        "total": 11,
        "additions": 3,
        "deletions": 8
    }
}