{
    "author": "stevhliu",
    "message": "[docs] dtype (#42883)\n\ndtype",
    "sha": "b93f2e3a9841f1318ef45d8ed213974fb7e163fc",
    "files": [
        {
            "sha": "27ad94c92406545d1e9e45bd25731958e34fd942",
            "filename": "docs/source/en/models.md",
            "status": "modified",
            "additions": 7,
            "deletions": 18,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/b93f2e3a9841f1318ef45d8ed213974fb7e163fc/docs%2Fsource%2Fen%2Fmodels.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/b93f2e3a9841f1318ef45d8ed213974fb7e163fc/docs%2Fsource%2Fen%2Fmodels.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodels.md?ref=b93f2e3a9841f1318ef45d8ed213974fb7e163fc",
            "patch": "@@ -190,33 +190,22 @@ model.hf_device_map\n \n ### Model data type\n \n-PyTorch model weights are initialized in `torch.float32` by default. Loading a model in a different data type, like `torch.float16`, requires additional memory because the model is loaded again in the desired data type.\n+The `dtype` argument controls which PyTorch [dtype](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype) model weights are instantiated in. By default, `dtype=\"auto\"` scans `config.json` for a `dtype` or legacy `torch_dtype` entry and loads weights in that format. If `config.json` lacks this information, Transformers inspects the first floating-point weight in the checkpoint and adopts its data type.\n \n-Explicitly set the [dtype](https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype) parameter to directly initialize the model in the desired data type instead of loading the weights twice (`torch.float32` then `torch.float16`). You could also set `dtype=\"auto\"` to automatically load the weights in the data type they are stored in.\n-\n-<hfoptions id=\"dtype\">\n-<hfoption id=\"specific dtype\">\n+Override the default by passing a specific data type.\n \n ```py\n import torch\n from transformers import AutoModelForCausalLM\n \n-gemma = AutoModelForCausalLM.from_pretrained(\"google/gemma-7b\", dtype=torch.float16)\n-```\n-\n-</hfoption>\n-<hfoption id=\"auto dtype\">\n-\n-```py\n-from transformers import AutoModelForCausalLM\n+# default\n+model = AutoModelForCausalLM.from_pretrained(\"google/gemma-3-1b-it\", dtype=\"auto\")\n \n-gemma = AutoModelForCausalLM.from_pretrained(\"google/gemma-7b\", dtype=\"auto\")\n+# specific dtype\n+model = AutoModelForCausalLM.from_pretrained(\"google/gemma-3-1b-it\", dtype=torch.float16)\n ```\n \n-</hfoption>\n-</hfoptions>\n-\n-The `dtype` parameter can also be configured in [`AutoConfig`] for models instantiated from scratch.\n+[`AutoConfig`] also accepts `dtype` for models instantiated from scratch.\n \n ```py\n import torch"
        },
        {
            "sha": "6d58d0e394aa92d9a8ba52ad3b15dce29bced447",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/b93f2e3a9841f1318ef45d8ed213974fb7e163fc/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b93f2e3a9841f1318ef45d8ed213974fb7e163fc/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=b93f2e3a9841f1318ef45d8ed213974fb7e163fc",
            "patch": "@@ -3687,7 +3687,7 @@ def from_pretrained(\n \n             > Parameters for big model inference\n \n-            dtype (`str` or `torch.dtype`, *optional*):\n+            dtype (`str` or `torch.dtype`, *optional*, defaults to `\"auto\"`):\n                 Override the default `torch_dtype` and load the model under a specific `dtype`. The different options\n                 are:\n "
        }
    ],
    "stats": {
        "total": 27,
        "additions": 8,
        "deletions": 19
    }
}