{
    "author": "ydshieh",
    "message": "Less flaky for `TimmBackboneModelTest::test_batching_equivalence` (#35971)\n\n* fix\r\n\r\n* remove is_flaky\r\n\r\n* fix\r\n\r\n---------\r\n\r\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "575768183759c5d3dc052a0af26818a81521e82a",
    "files": [
        {
            "sha": "737b1ea3c5d9b12f3a71f8bcbcc7730de0e7f1aa",
            "filename": "tests/models/timm_backbone/test_modeling_timm_backbone.py",
            "status": "modified",
            "additions": 4,
            "deletions": 6,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/575768183759c5d3dc052a0af26818a81521e82a/tests%2Fmodels%2Ftimm_backbone%2Ftest_modeling_timm_backbone.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/575768183759c5d3dc052a0af26818a81521e82a/tests%2Fmodels%2Ftimm_backbone%2Ftest_modeling_timm_backbone.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ftimm_backbone%2Ftest_modeling_timm_backbone.py?ref=575768183759c5d3dc052a0af26818a81521e82a",
            "patch": "@@ -18,7 +18,7 @@\n import unittest\n \n from transformers import AutoBackbone\n-from transformers.testing_utils import is_flaky, require_timm, require_torch, torch_device\n+from transformers.testing_utils import require_timm, require_torch, torch_device\n from transformers.utils.import_utils import is_torch_available\n \n from ...test_backbone_common import BackboneTesterMixin\n@@ -115,11 +115,9 @@ def setUp(self):\n     def test_config(self):\n         self.config_tester.run_common_tests()\n \n-    @is_flaky(\n-        description=\"`TimmBackbone` has no `_init_weights`. Timm's way of weight init. seems to give larger magnitude in the intermediate values during `forward`.\"\n-    )\n-    def test_batching_equivalence(self):\n-        super().test_batching_equivalence()\n+    # `TimmBackbone` has no `_init_weights`. Timm's way of weight init. seems to give larger magnitude in the intermediate values during `forward`.\n+    def test_batching_equivalence(self, atol=1e-4, rtol=1e-4):\n+        super().test_batching_equivalence(atol=atol, rtol=rtol)\n \n     def test_timm_transformer_backbone_equivalence(self):\n         timm_checkpoint = \"resnet18\""
        },
        {
            "sha": "0f47767e4141d854fd64bb13c836d35cfba6604b",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/575768183759c5d3dc052a0af26818a81521e82a/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/575768183759c5d3dc052a0af26818a81521e82a/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=575768183759c5d3dc052a0af26818a81521e82a",
            "patch": "@@ -768,7 +768,7 @@ def check_determinism(first, second):\n             else:\n                 check_determinism(first, second)\n \n-    def test_batching_equivalence(self):\n+    def test_batching_equivalence(self, atol=1e-5, rtol=1e-5):\n         \"\"\"\n         Tests that the model supports batching and that the output is the nearly the same for the same input in\n         different batch sizes.\n@@ -812,7 +812,7 @@ def recursive_check(batched_object, single_row_object, model_name, key):\n                     torch.isinf(single_row_object).any(), f\"Single row output has `inf` in {model_name} for key={key}\"\n                 )\n                 try:\n-                    torch.testing.assert_close(batched_row, single_row_object, atol=1e-5, rtol=1e-5)\n+                    torch.testing.assert_close(batched_row, single_row_object, atol=atol, rtol=rtol)\n                 except AssertionError as e:\n                     msg = f\"Batched and Single row outputs are not equal in {model_name} for key={key}.\\n\\n\"\n                     msg += str(e)"
        }
    ],
    "stats": {
        "total": 14,
        "additions": 6,
        "deletions": 8
    }
}