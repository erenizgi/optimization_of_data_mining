{
    "author": "ydshieh",
    "message": "byebye torch 2.0 (#37277)\n\n* bump Torch 2.1 with broken compatibility `torch.compile`\n\n* dep table\n\n* remove usage of is_torch_greater_or_equal_than_2_1\n\n* remove usage of is_torch_greater_or_equal_than_2_1\n\n* remove if is_torch_greater_or_equal(\"2.1.0\")\n\n* remove torch >= \"2.1.0\"\n\n* deal with 2.0.0\n\n* PyTorch 2.0+ --> PyTorch 2.1+\n\n* ruff 1\n\n* difficult ruff\n\n* address comment\n\n* address comment\n\n---------\n\nCo-authored-by: Jirka B <j.borovec+github@gmail.com>\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "e7ad0770127c0e23e576681b10216f94c70ee1da",
    "files": [
        {
            "sha": "e3a42595ddeb2c6534a20369c6d319b0b953331f",
            "filename": "README.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/README.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/README.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/README.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -70,7 +70,7 @@ Explore the [Hub](https://huggingface.com/) today to find a model and use Transf\n \n ## Installation\n \n-Transformers works with Python 3.9+ [PyTorch](https://pytorch.org/get-started/locally/) 2.0+, [TensorFlow](https://www.tensorflow.org/install/pip) 2.6+, and [Flax](https://flax.readthedocs.io/en/latest/) 0.4.1+.\n+Transformers works with Python 3.9+ [PyTorch](https://pytorch.org/get-started/locally/) 2.1+, [TensorFlow](https://www.tensorflow.org/install/pip) 2.6+, and [Flax](https://flax.readthedocs.io/en/latest/) 0.4.1+.\n \n Create and activate a virtual environment with [venv](https://docs.python.org/3/library/venv.html) or [uv](https://docs.astral.sh/uv/), a fast Rust-based Python package and project manager.\n "
        },
        {
            "sha": "911c84858f9ef6ce9c92f4ef9996e0e19209fdc2",
            "filename": "docs/source/en/installation.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/docs%2Fsource%2Fen%2Finstallation.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/docs%2Fsource%2Fen%2Finstallation.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Finstallation.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -20,7 +20,7 @@ rendered properly in your Markdown viewer.\n \n # Installation\n \n-Transformers works with [PyTorch](https://pytorch.org/get-started/locally/), [TensorFlow 2.0](https://www.tensorflow.org/install/pip), and [Flax](https://flax.readthedocs.io/en/latest/). It has been tested on Python 3.9+, PyTorch 2.0+, TensorFlow 2.6+, and Flax 0.4.1+.\n+Transformers works with [PyTorch](https://pytorch.org/get-started/locally/), [TensorFlow 2.0](https://www.tensorflow.org/install/pip), and [Flax](https://flax.readthedocs.io/en/latest/). It has been tested on Python 3.9+, PyTorch 2.1+, TensorFlow 2.6+, and Flax 0.4.1+.\n \n ## Virtual environment\n "
        },
        {
            "sha": "cdf813445d6f2d43cf10cc327d92b9f108009728",
            "filename": "i18n/README_ar.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_ar.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_ar.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_ar.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -245,7 +245,7 @@ limitations under the License.\n \n ### Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pip\n \n-ØªÙ… Ø§Ø®ØªØ¨Ø§Ø± Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø¹Ù„Ù‰ Python 3.9+ØŒ Flax 0.4.1+ØŒ PyTorch 2.0+ØŒ Ùˆ TensorFlow 2.6+.\n+ØªÙ… Ø§Ø®ØªØ¨Ø§Ø± Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø¹Ù„Ù‰ Python 3.9+ØŒ Flax 0.4.1+ØŒ PyTorch 2.1+ØŒ Ùˆ TensorFlow 2.6+.\n \n ÙŠØ¬Ø¨ ØªØ«Ø¨ÙŠØª ğŸ¤— Transformers ÙÙŠ [Ø¨ÙŠØ¦Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©](https://docs.python.org/3/library/venv.html). Ø¥Ø°Ø§ ÙƒÙ†Øª ØºÙŠØ± Ù…Ø¹ØªØ§Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ¦Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© PythonØŒ ÙØ±Ø§Ø¬Ø¹ [Ø¯Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).\n "
        },
        {
            "sha": "b913df894dc147d575a8d283b7eab7265306bbb2",
            "filename": "i18n/README_de.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_de.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_de.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_de.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -246,7 +246,7 @@ Das Modell selbst ist ein regulÃ¤res [PyTorch `nn.Module`](https://pytorch.org/d\n \n ### Mit pip\n \n-Dieses Repository wurde mit Python 3.9+, Flax 0.4.1+, PyTorch 2.0+ und TensorFlow 2.6+ getestet.\n+Dieses Repository wurde mit Python 3.9+, Flax 0.4.1+, PyTorch 2.1+ und TensorFlow 2.6+ getestet.\n \n Sie sollten ğŸ¤— Transformers in einer [virtuellen Umgebung](https://docs.python.org/3/library/venv.html) installieren. Wenn Sie mit virtuellen Python-Umgebungen nicht vertraut sind, schauen Sie sich den [Benutzerleitfaden](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/) an.\n "
        },
        {
            "sha": "36bb3e71ef4771aa88b12feaf0b66becd42b70f0",
            "filename": "i18n/README_es.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_es.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_es.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_es.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -222,7 +222,7 @@ El modelo en si es un [Pytorch `nn.Module`](https://pytorch.org/docs/stable/nn.h\n \n ### Con pip\n \n-Este repositorio estÃ¡ probado en Python 3.9+, Flax 0.4.1+, PyTorch 2.0+ y TensorFlow 2.6+.\n+Este repositorio estÃ¡ probado en Python 3.9+, Flax 0.4.1+, PyTorch 2.1+ y TensorFlow 2.6+.\n \n DeberÃ­as instalar ğŸ¤— Transformers en un [entorno virtual](https://docs.python.org/3/library/venv.html). Si no estas familiarizado con los entornos virtuales de Python, consulta la [guÃ­a de usuario](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).\n "
        },
        {
            "sha": "6512b4af0700fac4422121432e8619ff25fbc3e5",
            "filename": "i18n/README_fr.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_fr.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_fr.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_fr.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -243,7 +243,7 @@ Le modÃ¨le lui-mÃªme est un module [`nn.Module` PyTorch](https://pytorch.org/doc\n \n ### Avec pip\n \n-Ce rÃ©fÃ©rentiel est testÃ© sur Python 3.9+, Flax 0.4.1+, PyTorch 2.0+ et TensorFlow 2.6+.\n+Ce rÃ©fÃ©rentiel est testÃ© sur Python 3.9+, Flax 0.4.1+, PyTorch 2.1+ et TensorFlow 2.6+.\n \n Vous devriez installer ğŸ¤— Transformers dans un [environnement virtuel](https://docs.python.org/3/library/venv.html). Si vous n'Ãªtes pas familier avec les environnements virtuels Python, consultez le [guide utilisateur](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).\n "
        },
        {
            "sha": "76ee4355bd55a572a031145849c8481f4da98de3",
            "filename": "i18n/README_hd.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_hd.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_hd.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_hd.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -198,7 +198,7 @@ checkpoint: à¤œà¤¾à¤à¤š à¤¬à¤¿à¤‚à¤¦à¥\n \n ### à¤ªà¤¿à¤ª à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤°à¤¨à¤¾\n \n-à¤‡à¤¸ à¤°à¤¿à¤ªà¥‰à¤œà¤¿à¤Ÿà¤°à¥€ à¤•à¤¾ à¤ªà¤°à¥€à¤•à¥à¤·à¤£ Python 3.9+, Flax 0.4.1+, PyTorch 2.0+ à¤”à¤° TensorFlow 2.6+ à¤•à¥‡ à¤¤à¤¹à¤¤ à¤•à¤¿à¤¯à¤¾ à¤—à¤¯à¤¾ à¤¹à¥ˆà¥¤\n+à¤‡à¤¸ à¤°à¤¿à¤ªà¥‰à¤œà¤¿à¤Ÿà¤°à¥€ à¤•à¤¾ à¤ªà¤°à¥€à¤•à¥à¤·à¤£ Python 3.9+, Flax 0.4.1+, PyTorch 2.1+ à¤”à¤° TensorFlow 2.6+ à¤•à¥‡ à¤¤à¤¹à¤¤ à¤•à¤¿à¤¯à¤¾ à¤—à¤¯à¤¾ à¤¹à¥ˆà¥¤\n \n à¤†à¤ª [à¤µà¤°à¥à¤šà¥à¤…à¤² à¤à¤¨à¤µà¤¾à¤¯à¤°à¤¨à¤®à¥‡à¤‚à¤Ÿ](https://docs.python.org/3/library/venv.html) à¤®à¥‡à¤‚ ğŸ¤— à¤Ÿà¥à¤°à¤¾à¤‚à¤¸à¤«à¥‰à¤°à¥à¤®à¤° à¤‡à¤‚à¤¸à¥à¤Ÿà¥‰à¤² à¤•à¤° à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤ à¤¯à¤¦à¤¿ à¤†à¤ª à¤…à¤­à¥€ à¤¤à¤• à¤ªà¤¾à¤¯à¤¥à¤¨ à¤•à¥‡ à¤µà¤°à¥à¤šà¥à¤…à¤² à¤à¤¨à¤µà¤¾à¤¯à¤°à¤¨à¤®à¥‡à¤‚à¤Ÿ à¤¸à¥‡ à¤ªà¤°à¤¿à¤šà¤¿à¤¤ à¤¨à¤¹à¥€à¤‚ à¤¹à¥ˆà¤‚, à¤¤à¥‹ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤‡à¤¸à¥‡ [à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤¨à¤¿à¤°à¥à¤¦à¥‡à¤¶](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/) à¤ªà¤¢à¤¼à¥‡à¤‚à¥¤\n "
        },
        {
            "sha": "c57a07b56b6c4dfc6265670f1f4033c369039752",
            "filename": "i18n/README_ja.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_ja.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_ja.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_ja.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -256,7 +256,7 @@ Hugging Faceãƒãƒ¼ãƒ ã«ã‚ˆã£ã¦ä½œã‚‰ã‚ŒãŸ **[ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’\n \n ### pipã«ã¦\n \n-ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ã€Python 3.9+, Flax 0.4.1+, PyTorch 2.0+, TensorFlow 2.6+ ã§ãƒ†ã‚¹ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n+ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ã€Python 3.9+, Flax 0.4.1+, PyTorch 2.1+, TensorFlow 2.6+ ã§ãƒ†ã‚¹ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n \n ğŸ¤—Transformersã¯[ä»®æƒ³ç’°å¢ƒ](https://docs.python.org/3/library/venv.html)ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Pythonã®ä»®æƒ³ç’°å¢ƒã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€[ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¬ã‚¤ãƒ‰](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n "
        },
        {
            "sha": "fded56a37c9bd626b249955577cb75ab59598662",
            "filename": "i18n/README_ko.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_ko.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_ko.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_ko.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -242,7 +242,7 @@ Transformersì— ë‹¬ë¦° 100,000ê°œì˜ ë³„ì„ ì¶•í•˜í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì»¤\n \n ### pipë¡œ ì„¤ì¹˜í•˜ê¸°\n \n-ì´ ì €ì¥ì†ŒëŠ” Python 3.9+, Flax 0.4.1+, PyTorch 2.0+, TensorFlow 2.6+ì—ì„œ í…ŒìŠ¤íŠ¸ ë˜ì—ˆìŠµë‹ˆë‹¤.\n+ì´ ì €ì¥ì†ŒëŠ” Python 3.9+, Flax 0.4.1+, PyTorch 2.1+, TensorFlow 2.6+ì—ì„œ í…ŒìŠ¤íŠ¸ ë˜ì—ˆìŠµë‹ˆë‹¤.\n \n [ê°€ìƒ í™˜ê²½](https://docs.python.org/3/library/venv.html)ì— ğŸ¤— Transformersë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”. Python ê°€ìƒ í™˜ê²½ì— ìµìˆ™í•˜ì§€ ì•Šë‹¤ë©´, [ì‚¬ìš©ì ê°€ì´ë“œ](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n "
        },
        {
            "sha": "e3c71c6a3f353531014adabc9cb824d2e39799c9",
            "filename": "i18n/README_pt-br.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_pt-br.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_pt-br.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_pt-br.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -253,7 +253,7 @@ O modelo em si Ã© um [Pytorch `nn.Module`](https://pytorch.org/docs/stable/nn.ht\n \n ### Com pip\n \n-Este repositÃ³rio Ã© testado no Python 3.9+, Flax 0.4.1+, PyTorch 2.0+ e TensorFlow 2.6+.\n+Este repositÃ³rio Ã© testado no Python 3.9+, Flax 0.4.1+, PyTorch 2.1+ e TensorFlow 2.6+.\n \n VocÃª deve instalar o ğŸ¤— Transformers em um [ambiente virtual](https://docs.python.org/3/library/venv.html). Se vocÃª nÃ£o estÃ¡ familiarizado com ambientes virtuais em Python, confira o [guia do usuÃ¡rio](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).\n "
        },
        {
            "sha": "c30237fef88580201ca30139a8f21e4839a76724",
            "filename": "i18n/README_ru.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_ru.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_ru.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_ru.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -244,7 +244,7 @@ Hugging Face Hub. ĞœÑ‹ Ñ…Ğ¾Ñ‚Ğ¸Ğ¼, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Transformers Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»Ğ¸Ğ» Ñ€Ğ°\n \n ### Ğ¡ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ pip\n \n-Ğ”Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ½Ğ° Python 3.9+, Flax 0.4.1+, PyTorch 2.0+ Ğ¸ TensorFlow 2.6+.\n+Ğ”Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ½Ğ° Python 3.9+, Flax 0.4.1+, PyTorch 2.1+ Ğ¸ TensorFlow 2.6+.\n \n Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°Ñ‚ÑŒ ğŸ¤— Transformers ÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ² [Ğ²Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ€ĞµĞ´Ğµ](https://docs.python.org/3/library/venv.html). Ğ•ÑĞ»Ğ¸ Ğ²Ñ‹ Ğ½Ğµ Ğ·Ğ½Ğ°ĞºĞ¾Ğ¼Ñ‹ Ñ Ğ²Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ ÑÑ€ĞµĞ´Ğ°Ğ¼Ğ¸ Python, Ğ¾Ğ·Ğ½Ğ°ĞºĞ¾Ğ¼ÑŒÑ‚ĞµÑÑŒ Ñ [Ñ€ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾Ğ¼ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).\n "
        },
        {
            "sha": "aee579b52abdc8fd4f0a20fc5d90177ad6d1c496",
            "filename": "i18n/README_te.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_te.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_te.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_te.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -246,7 +246,7 @@ limitations under the License.\n \n ### à°ªà°¿à°ªà± à°¤à±‹\n \n-à°ˆ à°°à°¿à°ªà±‹à°œà°¿à°Ÿà°°à±€ à°ªà±ˆà°¥à°¾à°¨à± 3.9+, à°«à±à°²à°¾à°•à±à°¸à± 0.4.1+, PyTorch 2.0+ à°®à°°à°¿à°¯à± TensorFlow 2.6+à°²à±‹ à°ªà°°à±€à°•à±à°·à°¿à°‚à°šà°¬à°¡à°¿à°‚à°¦à°¿.\n+à°ˆ à°°à°¿à°ªà±‹à°œà°¿à°Ÿà°°à±€ à°ªà±ˆà°¥à°¾à°¨à± 3.9+, à°«à±à°²à°¾à°•à±à°¸à± 0.4.1+, PyTorch 2.1+ à°®à°°à°¿à°¯à± TensorFlow 2.6+à°²à±‹ à°ªà°°à±€à°•à±à°·à°¿à°‚à°šà°¬à°¡à°¿à°‚à°¦à°¿.\n \n à°®à±€à°°à± [à°µà°°à±à°šà±à°µà°²à± à°µà°¾à°¤à°¾à°µà°°à°£à°‚](https://docs.python.org/3/library/venv.html)à°²à±‹ ğŸ¤— à°Ÿà±à°°à°¾à°¨à±à°¸à±â€Œà°«à°¾à°°à±à°®à°°à±â€Œà°²à°¨à± à°‡à°¨à±â€Œà°¸à±à°Ÿà°¾à°²à± à°šà±‡à°¯à°¾à°²à°¿. à°®à±€à°•à± à°ªà±ˆà°¥à°¾à°¨à± à°µà°°à±à°šà±à°µà°²à± à°ªà°°à°¿à°¸à°°à°¾à°² à°—à±à°°à°¿à°‚à°šà°¿ à°¤à±†à°²à°¿à°¯à°•à±à°‚à°Ÿà±‡, [à°¯à±‚à°œà°°à± à°—à±ˆà°¡à±](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/) à°šà±‚à°¡à°‚à°¡à°¿.\n "
        },
        {
            "sha": "bba5988e77174dbde7787acdd474ccca293816a4",
            "filename": "i18n/README_ur.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_ur.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_ur.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_ur.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -259,7 +259,7 @@ limitations under the License.\n \n #### &#8207; pip Ú©Û’ Ø³Ø§ØªÚ¾\n \n-ÛŒÛ Ø±ÛŒÙ¾ÙˆØ²Ù¹Ø±ÛŒ Python 3.9+ØŒ Flax 0.4.1+ØŒ PyTorch 2.0+ØŒ Ø§ÙˆØ± TensorFlow 2.6+ Ù¾Ø± Ù¹ÛŒØ³Ù¹ Ú©ÛŒ Ú¯Ø¦ÛŒ ÛÛ’Û”\n+ÛŒÛ Ø±ÛŒÙ¾ÙˆØ²Ù¹Ø±ÛŒ Python 3.9+ØŒ Flax 0.4.1+ØŒ PyTorch 2.1+ØŒ Ø§ÙˆØ± TensorFlow 2.6+ Ù¾Ø± Ù¹ÛŒØ³Ù¹ Ú©ÛŒ Ú¯Ø¦ÛŒ ÛÛ’Û”\n \n Ø¢Ù¾ Ú©Ùˆ ğŸ¤— Transformers Ú©Ùˆ Ø§ÛŒÚ© [ÙˆØ±Ú†ÙˆØ¦Ù„ Ù…Ø§Ø­ÙˆÙ„](https://docs.python.org/3/library/venv.html) Ù…ÛŒÚº Ø§Ù†Ø³Ù¹Ø§Ù„ Ú©Ø±Ù†Ø§ Ú†Ø§ÛÛŒÛ’Û” Ø§Ú¯Ø± Ø¢Ù¾ Python ÙˆØ±Ú†ÙˆØ¦Ù„ Ù…Ø§Ø­ÙˆÙ„ Ø³Û’ ÙˆØ§Ù‚Ù Ù†ÛÛŒÚº ÛÛŒÚºØŒ ØªÙˆ [ÛŒÙˆØ²Ø± Ú¯Ø§Ø¦ÛŒÚˆ](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/) Ø¯ÛŒÚ©Ú¾ÛŒÚºÛ”\n "
        },
        {
            "sha": "f78e3b6d4e9b1d2379fecd4c14b691bc805b2f6a",
            "filename": "i18n/README_vi.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_vi.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_vi.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_vi.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -245,7 +245,7 @@ ChÃ­nh mÃ´ hÃ¬nh lÃ  má»™t [Pytorch `nn.Module`](https://pytorch.org/docs/stable\n \n ### Sá»­ dá»¥ng pip\n \n-ThÆ° viá»‡n nÃ y Ä‘Æ°á»£c kiá»ƒm tra trÃªn Python 3.9+, Flax 0.4.1+, PyTorch 2.0+ vÃ  TensorFlow 2.6+.\n+ThÆ° viá»‡n nÃ y Ä‘Æ°á»£c kiá»ƒm tra trÃªn Python 3.9+, Flax 0.4.1+, PyTorch 2.1+ vÃ  TensorFlow 2.6+.\n \n Báº¡n nÃªn cÃ i Ä‘áº·t ğŸ¤— Transformers trong má»™t [mÃ´i trÆ°á»ng áº£o Python](https://docs.python.org/3/library/venv.html). Náº¿u báº¡n chÆ°a quen vá»›i mÃ´i trÆ°á»ng áº£o Python, hÃ£y xem [hÆ°á»›ng dáº«n sá»­ dá»¥ng](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).\n "
        },
        {
            "sha": "22e7db3918c439e81d8696c910c7a2eef48b4764",
            "filename": "i18n/README_zh-hans.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_zh-hans.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_zh-hans.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_zh-hans.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -198,7 +198,7 @@ checkpoint: æ£€æŸ¥ç‚¹\n \n ### ä½¿ç”¨ pip\n \n-è¿™ä¸ªä»“åº“å·²åœ¨ Python 3.9+ã€Flax 0.4.1+ã€PyTorch 2.0+ å’Œ TensorFlow 2.6+ ä¸‹ç»è¿‡æµ‹è¯•ã€‚\n+è¿™ä¸ªä»“åº“å·²åœ¨ Python 3.9+ã€Flax 0.4.1+ã€PyTorch 2.1+ å’Œ TensorFlow 2.6+ ä¸‹ç»è¿‡æµ‹è¯•ã€‚\n \n ä½ å¯ä»¥åœ¨[è™šæ‹Ÿç¯å¢ƒ](https://docs.python.org/3/library/venv.html)ä¸­å®‰è£… ğŸ¤— Transformersã€‚å¦‚æœä½ è¿˜ä¸ç†Ÿæ‚‰ Python çš„è™šæ‹Ÿç¯å¢ƒï¼Œè¯·é˜…æ­¤[ç”¨æˆ·è¯´æ˜](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)ã€‚\n "
        },
        {
            "sha": "9bd494552ce218e8987846ebadddd41f8e56550a",
            "filename": "i18n/README_zh-hant.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_zh-hant.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/i18n%2FREADME_zh-hant.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/i18n%2FREADME_zh-hant.md?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -210,7 +210,7 @@ Tokenizer ç‚ºæ‰€æœ‰çš„é è¨“ç·´æ¨¡å‹æä¾›äº†é è™•ç†ï¼Œä¸¦å¯ä»¥ç›´æ¥è½‰æ›\n \n ### ä½¿ç”¨ pip\n \n-é€™å€‹ Repository å·²åœ¨ Python 3.9+ã€Flax 0.4.1+ã€PyTorch 2.0+ å’Œ TensorFlow 2.6+ ä¸‹ç¶“éæ¸¬è©¦ã€‚\n+é€™å€‹ Repository å·²åœ¨ Python 3.9+ã€Flax 0.4.1+ã€PyTorch 2.1+ å’Œ TensorFlow 2.6+ ä¸‹ç¶“éæ¸¬è©¦ã€‚\n \n ä½ å¯ä»¥åœ¨[è™›æ“¬ç’°å¢ƒ](https://docs.python.org/3/library/venv.html)ä¸­å®‰è£ ğŸ¤— Transformersã€‚å¦‚æœä½ é‚„ä¸ç†Ÿæ‚‰ Python çš„è™›æ“¬ç’°å¢ƒï¼Œè«‹é–±æ­¤[ä½¿ç”¨è€…æŒ‡å¼•](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)ã€‚\n "
        },
        {
            "sha": "10dd08651d83109efcd7b2d4aed2949ea386350d",
            "filename": "setup.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/setup.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/setup.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/setup.py?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -187,7 +187,7 @@\n     \"tiktoken\",\n     \"timm<=1.0.11\",\n     \"tokenizers>=0.21,<0.22\",\n-    \"torch>=2.0\",\n+    \"torch>=2.1\",\n     \"torchaudio\",\n     \"torchvision\",\n     \"pyctcdecode>=0.4.0\","
        },
        {
            "sha": "aac2d9da3d3ffe14227b342d5f231078a6a05d9d",
            "filename": "src/transformers/dependency_versions_table.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Fdependency_versions_table.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Fdependency_versions_table.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdependency_versions_table.py?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -92,7 +92,7 @@\n     \"tiktoken\": \"tiktoken\",\n     \"timm\": \"timm<=1.0.11\",\n     \"tokenizers\": \"tokenizers>=0.21,<0.22\",\n-    \"torch\": \"torch>=2.0\",\n+    \"torch\": \"torch>=2.1\",\n     \"torchaudio\": \"torchaudio\",\n     \"torchvision\": \"torchvision\",\n     \"pyctcdecode\": \"pyctcdecode>=0.4.0\","
        },
        {
            "sha": "470bbe4ad944843c62f8f66345eccf69b9aa7809",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 12,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -485,20 +485,15 @@ def load_sharded_checkpoint(model, folder, strict=True, prefer_safe=True):\n     \"F64\": torch.float64,\n     \"I64\": torch.int64,\n     \"F8_E4M3\": torch.float8_e4m3fn,\n+    \"F8_E5M2\": torch.float8_e5m2,\n }\n \n-if is_torch_greater_or_equal(\"2.1.0\"):\n-    str_to_torch_dtype[\"F8_E4M3\"] = torch.float8_e4m3fn\n \n if is_torch_greater_or_equal(\"2.3.0\"):\n     str_to_torch_dtype[\"U16\"] = torch.uint16\n     str_to_torch_dtype[\"U32\"] = torch.uint32\n     str_to_torch_dtype[\"U64\"] = torch.uint64\n \n-if is_torch_greater_or_equal(\"2.1.0\"):\n-    str_to_torch_dtype[\"F8_E4M3\"] = torch.float8_e4m3fn\n-    str_to_torch_dtype[\"F8_E5M2\"] = torch.float8_e5m2\n-\n \n def load_state_dict(\n     checkpoint_file: Union[str, os.PathLike],\n@@ -546,12 +541,7 @@ def load_state_dict(\n                 map_location = \"cpu\"\n         extra_args = {}\n         # mmap can only be used with files serialized with zipfile-based format.\n-        if (\n-            isinstance(checkpoint_file, str)\n-            and map_location != \"meta\"\n-            and version.parse(torch.__version__) >= version.parse(\"2.1.0\")\n-            and is_zipfile(checkpoint_file)\n-        ):\n+        if isinstance(checkpoint_file, str) and map_location != \"meta\" and is_zipfile(checkpoint_file):\n             extra_args = {\"mmap\": True}\n         return torch.load(\n             checkpoint_file,"
        },
        {
            "sha": "60d37ff35bcc1abe4fb17c92c8d619c7d4ba4327",
            "filename": "src/transformers/models/mask2former/modeling_mask2former.py",
            "status": "modified",
            "additions": 1,
            "deletions": 13,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Fmodels%2Fmask2former%2Fmodeling_mask2former.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Fmodels%2Fmask2former%2Fmodeling_mask2former.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmask2former%2Fmodeling_mask2former.py?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -34,10 +34,8 @@\n )\n from ...modeling_outputs import BaseModelOutput, BaseModelOutputWithCrossAttentions\n from ...modeling_utils import PreTrainedModel\n-from ...pytorch_utils import is_torch_greater_or_equal_than_2_1\n from ...utils import is_accelerate_available, logging\n from ...utils.backbone_utils import load_backbone\n-from ...utils.import_utils import is_torchdynamo_compiling\n from .configuration_mask2former import Mask2FormerConfig\n \n \n@@ -2018,18 +2016,8 @@ def forward(\n     ):\n         mask_embeddings = self.mask_embedder(outputs.transpose(0, 1))\n \n-        is_tracing = torch.jit.is_tracing() or isinstance(outputs, torch.fx.Proxy) or is_torchdynamo_compiling()\n         # Sum up over the channels\n-        if is_tracing and not is_torch_greater_or_equal_than_2_1:\n-            # Equivalent to einsum('bqc, bchw -> bqhw') but jit friendly\n-            batch_size, num_queries, num_channels = mask_embeddings.shape\n-            _, _, height, width = pixel_embeddings.shape\n-            outputs_mask = torch.zeros((batch_size, num_queries, height, width), device=mask_embeddings.device)\n-            for c in range(num_channels):\n-                outputs_mask += mask_embeddings[..., c][..., None, None] * pixel_embeddings[:, None, c]\n-\n-        else:\n-            outputs_mask = torch.einsum(\"bqc, bchw -> bqhw\", mask_embeddings, pixel_embeddings)\n+        outputs_mask = torch.einsum(\"bqc, bchw -> bqhw\", mask_embeddings, pixel_embeddings)\n \n         attention_mask = nn.functional.interpolate(\n             outputs_mask, size=attention_mask_target_size, mode=\"bilinear\", align_corners=False"
        },
        {
            "sha": "4f83cc59dadbcf5e0caba12dbf65361297283594",
            "filename": "src/transformers/models/maskformer/modeling_maskformer.py",
            "status": "modified",
            "additions": 2,
            "deletions": 27,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fmodeling_maskformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fmodeling_maskformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fmodeling_maskformer.py?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -27,7 +27,6 @@\n from ...modeling_attn_mask_utils import _prepare_4d_attention_mask\n from ...modeling_outputs import BaseModelOutputWithCrossAttentions\n from ...modeling_utils import PreTrainedModel\n-from ...pytorch_utils import is_torch_greater_or_equal_than_2_1\n from ...utils import (\n     ModelOutput,\n     add_start_docstrings,\n@@ -39,7 +38,6 @@\n     requires_backends,\n )\n from ...utils.backbone_utils import load_backbone\n-from ...utils.import_utils import is_torchdynamo_compiling\n from ..detr import DetrConfig\n from .configuration_maskformer import MaskFormerConfig\n from .configuration_maskformer_swin import MaskFormerSwinConfig\n@@ -1685,26 +1683,14 @@ def get_logits(self, outputs: MaskFormerModelOutput) -> Tuple[Tensor, Tensor, Di\n         # get the auxiliary predictions (one for each decoder's layer)\n         auxiliary_logits: List[str, Tensor] = []\n \n-        is_tracing = torch.jit.is_tracing() or isinstance(outputs, torch.fx.Proxy) or is_torchdynamo_compiling()\n         # This code is a little bit cumbersome, an improvement can be to return a list of predictions. If we have auxiliary loss then we are going to return more than one element in the list\n         if self.config.use_auxiliary_loss:\n             stacked_transformer_decoder_outputs = torch.stack(outputs.transformer_decoder_hidden_states)\n             classes = self.class_predictor(stacked_transformer_decoder_outputs)\n             class_queries_logits = classes[-1]\n             # get the masks\n             mask_embeddings = self.mask_embedder(stacked_transformer_decoder_outputs)\n-\n-            if is_tracing and not is_torch_greater_or_equal_than_2_1:\n-                # Equivalent to einsum('lbqc, bchw -> lbqhw') but jit friendly\n-                num_embeddings, batch_size, num_queries, num_channels = mask_embeddings.shape\n-                _, _, height, width = pixel_embeddings.shape\n-                binaries_masks = torch.zeros(\n-                    (num_embeddings, batch_size, num_queries, height, width), device=mask_embeddings.device\n-                )\n-                for c in range(num_channels):\n-                    binaries_masks += mask_embeddings[..., c][..., None, None] * pixel_embeddings[None, :, None, c]\n-            else:\n-                binaries_masks = torch.einsum(\"lbqc, bchw -> lbqhw\", mask_embeddings, pixel_embeddings)\n+            binaries_masks = torch.einsum(\"lbqc, bchw -> lbqhw\", mask_embeddings, pixel_embeddings)\n \n             masks_queries_logits = binaries_masks[-1]\n             # go til [:-1] because the last one is always used\n@@ -1720,18 +1706,7 @@ def get_logits(self, outputs: MaskFormerModelOutput) -> Tuple[Tensor, Tensor, Di\n             # get the masks\n             mask_embeddings = self.mask_embedder(transformer_decoder_hidden_states)\n             # sum up over the channels\n-\n-            if is_tracing and not is_torch_greater_or_equal_than_2_1:\n-                # Equivalent to einsum('bqc, bchw -> bqhw') but jit friendly\n-                batch_size, num_queries, num_channels = mask_embeddings.shape\n-                _, _, height, width = pixel_embeddings.shape\n-                masks_queries_logits = torch.zeros(\n-                    (batch_size, num_queries, height, width), device=mask_embeddings.device\n-                )\n-                for c in range(num_channels):\n-                    masks_queries_logits += mask_embeddings[..., c][..., None, None] * pixel_embeddings[:, None, c]\n-            else:\n-                masks_queries_logits = torch.einsum(\"bqc, bchw -> bqhw\", mask_embeddings, pixel_embeddings)\n+            masks_queries_logits = torch.einsum(\"bqc, bchw -> bqhw\", mask_embeddings, pixel_embeddings)\n \n         return class_queries_logits, masks_queries_logits, auxiliary_logits\n "
        },
        {
            "sha": "b2fe91253576724e52e5b4642137d59f0f588805",
            "filename": "src/transformers/pytorch_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Fpytorch_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Fpytorch_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpytorch_utils.py?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -32,9 +32,9 @@\n is_torch_greater_or_equal_than_2_4 = is_torch_greater_or_equal(\"2.4\", accept_dev=True)\n is_torch_greater_or_equal_than_2_3 = is_torch_greater_or_equal(\"2.3\", accept_dev=True)\n is_torch_greater_or_equal_than_2_2 = is_torch_greater_or_equal(\"2.2\", accept_dev=True)\n-is_torch_greater_or_equal_than_2_1 = is_torch_greater_or_equal(\"2.1\", accept_dev=True)\n \n # For backwards compatibility (e.g. some remote codes on Hub using those variables).\n+is_torch_greater_or_equal_than_2_1 = is_torch_greater_or_equal(\"2.1\", accept_dev=True)\n is_torch_greater_or_equal_than_2_0 = is_torch_greater_or_equal(\"2.0\", accept_dev=True)\n is_torch_greater_or_equal_than_1_13 = is_torch_greater_or_equal(\"1.13\", accept_dev=True)\n is_torch_greater_or_equal_than_1_12 = is_torch_greater_or_equal(\"1.12\", accept_dev=True)"
        },
        {
            "sha": "7b84c4685c96df7261b6d9769814aaf7801ab0e5",
            "filename": "src/transformers/quantizers/quantizer_fbgemm_fp8.py",
            "status": "modified",
            "additions": 2,
            "deletions": 5,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Fquantizers%2Fquantizer_fbgemm_fp8.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Fquantizers%2Fquantizer_fbgemm_fp8.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizer_fbgemm_fp8.py?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -11,11 +11,8 @@\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.\n-import importlib\n from typing import TYPE_CHECKING, Any, Dict, List, Optional\n \n-from packaging import version\n-\n from .base import HfQuantizer\n \n \n@@ -48,9 +45,9 @@ def __init__(self, quantization_config, **kwargs):\n         self.quantization_config = quantization_config\n \n     def validate_environment(self, *args, **kwargs):\n-        if not is_torch_available() or version.parse(importlib.metadata.version(\"torch\")) < version.parse(\"2.1.0\"):\n+        if not is_torch_available():\n             raise ImportError(\n-                \"Using fbgemm fp8 quantization requires torch > 2.1.0\"\n+                \"Using fbgemm fp8 quantization requires torch >= 2.1.0\"\n                 \"Please install the latest version of torch ( pip install --upgrade torch )\"\n             )\n         if not is_fbgemm_gpu_available():"
        },
        {
            "sha": "cbfc2167b3ef3e1249b58a52f53af4628e4a2bc9",
            "filename": "src/transformers/quantizers/quantizer_finegrained_fp8.py",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Fquantizers%2Fquantizer_finegrained_fp8.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Fquantizers%2Fquantizer_finegrained_fp8.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizer_finegrained_fp8.py?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -1,8 +1,5 @@\n-import importlib\n from typing import TYPE_CHECKING, Any, Dict, List, Optional\n \n-from packaging import version\n-\n from ..utils import is_accelerate_available, is_torch_available, logging\n from .base import HfQuantizer\n from .quantizers_utils import get_module_from_name\n@@ -32,7 +29,7 @@ def __init__(self, quantization_config, **kwargs):\n         self.quantization_config = quantization_config\n \n     def validate_environment(self, *args, **kwargs):\n-        if not is_torch_available() or version.parse(importlib.metadata.version(\"torch\")) < version.parse(\"2.1.0\"):\n+        if not is_torch_available():\n             raise ImportError(\n                 \"Using fp8 quantization requires torch >= 2.1.0\"\n                 \"Please install the latest version of torch ( pip install --upgrade torch )\""
        },
        {
            "sha": "d6915345fa7768415272849f27f10b8586c84bbe",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 7,
            "deletions": 15,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -1902,22 +1902,14 @@ def torch_jit_model_eval(self, model, dataloader, training=False):\n                     jit_model.forward = original_forward\n                 autocast_handler = AutocastKwargs(cache_enabled=False)\n                 with self.accelerator.autocast(autocast_handler=autocast_handler), torch.no_grad():\n-                    if version.parse(version.parse(torch.__version__).base_version) >= version.parse(\"2.0.0\"):\n-                        if isinstance(example_batch, dict):\n-                            jit_model = torch.jit.trace(jit_model, example_kwarg_inputs=example_batch, strict=False)\n-                        else:\n-                            jit_model = torch.jit.trace(\n-                                jit_model,\n-                                example_kwarg_inputs={key: example_batch[key] for key in example_batch},\n-                                strict=False,\n-                            )\n+                    if isinstance(example_batch, dict):\n+                        jit_model = torch.jit.trace(jit_model, example_kwarg_inputs=example_batch, strict=False)\n                     else:\n-                        jit_inputs = []\n-                        for key in example_batch:\n-                            example_tensor = torch.ones_like(example_batch[key])\n-                            jit_inputs.append(example_tensor)\n-                        jit_inputs = tuple(jit_inputs)\n-                        jit_model = torch.jit.trace(jit_model, jit_inputs, strict=False)\n+                        jit_model = torch.jit.trace(\n+                            jit_model,\n+                            example_kwarg_inputs={key: example_batch[key] for key in example_batch},\n+                            strict=False,\n+                        )\n                 jit_model = torch.jit.freeze(jit_model)\n                 with torch.no_grad():\n                     jit_model(**example_batch)"
        },
        {
            "sha": "4fc3a763298ab7987bde3e121fa46deaa22f3871",
            "filename": "src/transformers/training_args.py",
            "status": "modified",
            "additions": 1,
            "deletions": 8,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Ftraining_args.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Ftraining_args.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftraining_args.py?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -24,7 +24,6 @@\n from typing import Any, Optional, Union\n \n from huggingface_hub import get_full_repo_name\n-from packaging import version\n \n from .debug_utils import DebugOption\n from .trainer_utils import (\n@@ -1290,7 +1289,7 @@ class TrainingArguments:\n \n     default_optim = \"adamw_torch\"\n     # XXX: enable when pytorch==2.0.1 comes out - we want to give it time to get all the bugs sorted out\n-    # if is_torch_available() and version.parse(version.parse(torch.__version__).base_version) >= version.parse(\"2.1.0\"):\n+    # if is_torch_available():\n     #     default_optim = \"adamw_torch_fused\"\n     # and update the doc above to:\n     # optim (`str` or [`training_args.OptimizerNames`], *optional*, defaults to `\"adamw_torch_fused\"` (for torch<2.1.0 `\"adamw_torch\"`):\n@@ -1732,12 +1731,6 @@ def __post_init__(self):\n                 FutureWarning,\n             )\n             self.optim = OptimizerNames.ADAFACTOR\n-        if self.optim == OptimizerNames.ADAMW_TORCH_FUSED and is_torch_available():\n-            if version.parse(version.parse(torch.__version__).base_version) < version.parse(\"2.0.0\"):\n-                raise ValueError(\"--optim adamw_torch_fused requires PyTorch 2.0 or higher\")\n-            # there is a bug in fp16/AMP in pt-2.0.0\n-            if version.parse(version.parse(torch.__version__).base_version) == version.parse(\"2.0.0\") and self.fp16:\n-                raise ValueError(\"--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\")\n \n         # We need to setup the accelerator config here *before* the first call to `self.device`\n         if is_accelerate_available():"
        },
        {
            "sha": "184b618e7e4c0171e5a16f63863c171771630920",
            "filename": "src/transformers/utils/import_utils.py",
            "status": "modified",
            "additions": 3,
            "deletions": 6,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fimport_utils.py?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -379,15 +379,12 @@ def is_torch_sdpa_available():\n     elif _torch_version == \"N/A\":\n         return False\n \n-    # NOTE: We require torch>=2.1 (and not torch>=2.0) to use SDPA in Transformers for two reasons:\n-    # - Allow the global use of the `scale` argument introduced in https://github.com/pytorch/pytorch/pull/95259\n-    # - Memory-efficient attention supports arbitrary attention_mask: https://github.com/pytorch/pytorch/pull/104310\n     # NOTE: MLU is OK with non-contiguous inputs.\n     if is_torch_mlu_available():\n-        return version.parse(_torch_version) >= version.parse(\"2.1.0\")\n+        return True\n     # NOTE: NPU can use SDPA in Transformers with torch>=2.1.0.\n     if is_torch_npu_available():\n-        return version.parse(_torch_version) >= version.parse(\"2.1.0\")\n+        return True\n     # NOTE: We require torch>=2.1.1 to avoid a numerical issue in SDPA with non-contiguous inputs: https://github.com/pytorch/pytorch/issues/112577\n     return version.parse(_torch_version) >= version.parse(\"2.1.1\")\n \n@@ -833,7 +830,7 @@ def is_torchdynamo_available():\n     if not is_torch_available():\n         return False\n \n-    return version.parse(_torch_version) >= version.parse(\"2.0.0\")\n+    return True\n \n \n def is_torch_compile_available():"
        },
        {
            "sha": "68309d94ea57daeff2f9830bb35e308a35dcf3ff",
            "filename": "tests/fsdp/test_fsdp.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7ad0770127c0e23e576681b10216f94c70ee1da/tests%2Ffsdp%2Ftest_fsdp.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7ad0770127c0e23e576681b10216f94c70ee1da/tests%2Ffsdp%2Ftest_fsdp.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ffsdp%2Ftest_fsdp.py?ref=e7ad0770127c0e23e576681b10216f94c70ee1da",
            "patch": "@@ -47,10 +47,7 @@\n \n \n if is_torch_available():\n-    from transformers.pytorch_utils import is_torch_greater_or_equal_than_2_1\n     from transformers.trainer import FSDP_MODEL_NAME\n-else:\n-    is_torch_greater_or_equal_than_2_1 = False\n \n # default torch.distributed port\n DEFAULT_MASTER_PORT = \"10999\"\n@@ -260,7 +257,6 @@ def test_basic_run_with_gradient_accumulation(self, sharding_strategy, dtype):\n     @require_torch_multi_accelerator\n     @run_first\n     @slow\n-    @unittest.skipIf(not is_torch_greater_or_equal_than_2_1, reason=\"This test on pytorch 2.0 takes 4 hours.\")\n     def test_basic_run_with_cpu_offload(self, dtype):\n         launcher = get_launcher(distributed=True, use_accelerate=False)\n         output_dir = self.get_auto_remove_tmp_dir()"
        }
    ],
    "stats": {
        "total": 151,
        "additions": 38,
        "deletions": 113
    }
}