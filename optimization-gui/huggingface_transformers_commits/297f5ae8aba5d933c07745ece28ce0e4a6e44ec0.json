{
    "author": "JuanFKurucz",
    "message": "Fix broken link to dataset food101 (#42495)",
    "sha": "297f5ae8aba5d933c07745ece28ce0e4a6e44ec0",
    "files": [
        {
            "sha": "b9113064804bd89de88487d1f7a2e6e0390ef7b1",
            "filename": "docs/source/ar/preprocessing.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Far%2Fpreprocessing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Far%2Fpreprocessing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fpreprocessing.md?ref=297f5ae8aba5d933c07745ece28ce0e4a6e44ec0",
            "patch": "@@ -302,7 +302,7 @@ pip install datasets\n \n </Tip>\n \n-Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª [food101](https://huggingface.co/datasets/food101) (Ø±Ø§Ø¬Ø¹ Ø¯Ù„ÙŠÙ„ ğŸ¤— [Datasets tutorial](https://huggingface.co/docs/datasets/load_hub) Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª) Ù„Ù…Ø¹Ø±ÙØ© ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ± Ù…Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³Ø¨:\n+Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª [food101](https://huggingface.co/datasets/ethz/food101) (Ø±Ø§Ø¬Ø¹ Ø¯Ù„ÙŠÙ„ ğŸ¤— [Datasets tutorial](https://huggingface.co/docs/datasets/load_hub) Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª) Ù„Ù…Ø¹Ø±ÙØ© ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ± Ù…Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³Ø¨:\n \n <Tip>\n \n@@ -313,7 +313,7 @@ pip install datasets\n ```py\n >>> from datasets import load_dataset\n \n->>> dataset = load_dataset(\"food101\", split=\"train[:100]\")\n+>>> dataset = load_dataset(\"ethz/food101\", split=\"train[:100]\")\n ```\n \n Ø¨Ø¹Ø¯ Ø°Ù„ÙƒØŒ Ø§Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ù…ÙŠØ²Ø© ğŸ¤— Datasets [`Image`](https://huggingface.co/docs/datasets/package_reference/main_classes?highlight=image#datasets.Image):"
        },
        {
            "sha": "d686acd0cc6c33ed3659b526f257ed2191feea5e",
            "filename": "docs/source/de/preprocessing.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fde%2Fpreprocessing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fde%2Fpreprocessing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fde%2Fpreprocessing.md?ref=297f5ae8aba5d933c07745ece28ce0e4a6e44ec0",
            "patch": "@@ -308,12 +308,12 @@ Die LÃ¤nge der ersten beiden Beispiele entspricht nun der von Ihnen angegebenen\n \n Ein Merkmalsextraktor wird auch verwendet, um Bilder fÃ¼r Bildverarbeitungsaufgaben zu verarbeiten. Auch hier besteht das Ziel darin, das Rohbild in eine Reihe von Tensoren als Eingabe zu konvertieren.\n \n-Laden wir den [food101](https://huggingface.co/datasets/food101) Datensatz fÃ¼r dieses Tutorial. Verwenden Sie den Parameter ğŸ¤— Datasets `split`, um nur eine kleine Stichprobe aus dem Trainingssplit zu laden, da der Datensatz recht groÃŸ ist:\n+Laden wir den [food101](https://huggingface.co/datasets/ethz/food101) Datensatz fÃ¼r dieses Tutorial. Verwenden Sie den Parameter ğŸ¤— Datasets `split`, um nur eine kleine Stichprobe aus dem Trainingssplit zu laden, da der Datensatz recht groÃŸ ist:\n \n ```py\n >>> from datasets import load_dataset\n \n->>> dataset = load_dataset(\"food101\", split=\"train[:100]\")\n+>>> dataset = load_dataset(\"ethz/food101\", split=\"train[:100]\")\n ```\n \n Als NÃ¤chstes sehen Sie sich das Bild mit dem Merkmal ğŸ¤— DatensÃ¤tze [Bild](https://huggingface.co/docs/datasets/package_reference/main_classes?highlight=image#datasets.Image) an:"
        },
        {
            "sha": "b043ab541dc54812c9f55373cbf2e89edef08f15",
            "filename": "docs/source/en/image_processors.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fen%2Fimage_processors.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fen%2Fimage_processors.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fimage_processors.md?ref=297f5ae8aba5d933c07745ece28ce0e4a6e44ec0",
            "patch": "@@ -145,7 +145,7 @@ Start by loading a small sample of the [food101](https://hf.co/datasets/food101)\n ```py\n from datasets import load_dataset\n \n-dataset = load_dataset(\"food101\", split=\"train[:100]\")\n+dataset = load_dataset(\"ethz/food101\", split=\"train[:100]\")\n ```\n \n From the [transforms](https://pytorch.org/vision/stable/transforms.html) module, use the [Compose](https://pytorch.org/vision/master/generated/torchvision.transforms.Compose.html) API to chain together [RandomResizedCrop](https://pytorch.org/vision/main/generated/torchvision.transforms.RandomResizedCrop.html) and [ColorJitter](https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html). These transforms randomly crop and resize an image, and randomly adjusts an images colors."
        },
        {
            "sha": "e4cae438c299457e748a731c8679b11d8427d8dd",
            "filename": "docs/source/en/tasks/image_classification.md",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fen%2Ftasks%2Fimage_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fen%2Ftasks%2Fimage_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftasks%2Fimage_classification.md?ref=297f5ae8aba5d933c07745ece28ce0e4a6e44ec0",
            "patch": "@@ -26,7 +26,7 @@ after a natural disaster, monitoring crop health, or helping screen medical imag\n \n This guide illustrates how to:\n \n-1. Fine-tune [ViT](../model_doc/vit) on the [Food-101](https://huggingface.co/datasets/food101) dataset to classify a food item in an image.\n+1. Fine-tune [ViT](../model_doc/vit) on the [Food-101](https://huggingface.co/datasets/ethz/food101) dataset to classify a food item in an image.\n 2. Use your fine-tuned model for inference.\n \n <Tip>\n@@ -57,7 +57,7 @@ experiment and make sure everything works before spending more time training on\n ```py\n >>> from datasets import load_dataset\n \n->>> food = load_dataset(\"food101\", split=\"train[:5000]\")\n+>>> food = load_dataset(\"ethz/food101\", split=\"train[:5000]\")\n ```\n \n Split the dataset's `train` split into a train and test set with the [`~datasets.Dataset.train_test_split`] method:\n@@ -250,7 +250,7 @@ Great, now that you've fine-tuned a model, you can use it for inference!\n Load an image you'd like to run inference on:\n \n ```py\n->>> ds = load_dataset(\"food101\", split=\"validation[:10]\")\n+>>> ds = load_dataset(\"ethz/food101\", split=\"validation[:10]\")\n >>> image = ds[\"image\"][0]\n ```\n "
        },
        {
            "sha": "3d9d9e653fa52f26f88806a2afec5b096a074783",
            "filename": "docs/source/es/preprocessing.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fes%2Fpreprocessing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fes%2Fpreprocessing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Fpreprocessing.md?ref=297f5ae8aba5d933c07745ece28ce0e4a6e44ec0",
            "patch": "@@ -321,12 +321,12 @@ Las longitudes de las dos primeras muestras coinciden ahora con la longitud mÃ¡x\n \n TambiÃ©n se utiliza un extractor de caracterÃ­sticas para procesar imÃ¡genes para tareas de visiÃ³n por computadora. Una vez mÃ¡s, el objetivo es convertir la imagen en bruto en un batch de tensores como entrada.\n \n-Vamos a cargar el dataset [food101](https://huggingface.co/datasets/food101) para este tutorial. Usa el parÃ¡metro ğŸ¤— Datasets `split` para cargar solo una pequeÃ±a muestra de la divisiÃ³n de entrenamiento ya que el dataset es bastante grande:\n+Vamos a cargar el dataset [food101](https://huggingface.co/datasets/ethz/food101) para este tutorial. Usa el parÃ¡metro ğŸ¤— Datasets `split` para cargar solo una pequeÃ±a muestra de la divisiÃ³n de entrenamiento ya que el dataset es bastante grande:\n \n ```py\n >>> from datasets import load_dataset\n \n->>> dataset = load_dataset(\"food101\", split=\"train[:100]\")\n+>>> dataset = load_dataset(\"ethz/food101\", split=\"train[:100]\")\n ```\n \n A continuaciÃ³n, observa la imagen con la funciÃ³n ğŸ¤— Datasets [`Image`](https://huggingface.co/docs/datasets/package_reference/main_classes?highlight=image#datasets.Image):"
        },
        {
            "sha": "dc0ecabde411ac9a863ab6211700955ce01922ce",
            "filename": "docs/source/es/tasks/image_classification.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fes%2Ftasks%2Fimage_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fes%2Ftasks%2Fimage_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Ftasks%2Fimage_classification.md?ref=297f5ae8aba5d933c07745ece28ce0e4a6e44ec0",
            "patch": "@@ -20,7 +20,7 @@ rendered properly in your Markdown viewer.\n \n La clasificaciÃ³n de imÃ¡genes asigna una etiqueta o clase a una imagen. A diferencia de la clasificaciÃ³n de texto o audio, las entradas son los valores de los pÃ­xeles que representan una imagen. La clasificaciÃ³n de imÃ¡genes tiene muchos usos, como la detecciÃ³n de daÃ±os tras una catÃ¡strofe, el control de la salud de los cultivos o la bÃºsqueda de signos de enfermedad en imÃ¡genes mÃ©dicas.\n \n-Esta guÃ­a te mostrarÃ¡ como hacer fine-tune al [ViT](https://huggingface.co/docs/transformers/v4.16.2/en/model_doc/vit) en el dataset [Food-101](https://huggingface.co/datasets/food101) para clasificar un alimento en una imagen.\n+Esta guÃ­a te mostrarÃ¡ como hacer fine-tune al [ViT](https://huggingface.co/docs/transformers/v4.16.2/en/model_doc/vit) en el dataset [Food-101](https://huggingface.co/datasets/ethz/food101) para clasificar un alimento en una imagen.\n \n <Tip>\n \n@@ -35,7 +35,7 @@ Carga solo las primeras 5000 imÃ¡genes del dataset Food-101 de la biblioteca \n ```py\n >>> from datasets import load_dataset\n \n->>> food = load_dataset(\"food101\", split=\"train[:5000]\")\n+>>> food = load_dataset(\"ethz/food101\", split=\"train[:5000]\")\n ```\n \n Divide el dataset en un train y un test set:"
        },
        {
            "sha": "d7d35ee0b154865148101c6f293434c9eb6b5a74",
            "filename": "docs/source/it/preprocessing.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fit%2Fpreprocessing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fit%2Fpreprocessing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fit%2Fpreprocessing.md?ref=297f5ae8aba5d933c07745ece28ce0e4a6e44ec0",
            "patch": "@@ -321,12 +321,12 @@ La lunghezza dei campioni adesso coincide con la massima lunghezza impostata nel\n \n Un estrattore di caratteristiche si puÃ² usare anche per processare immagini e per compiti di visione. Ancora una volta, l'obiettivo Ã¨ convertire l'immagine grezza in un lotto di tensori come input.\n \n-Carica il dataset [food101](https://huggingface.co/datasets/food101) per questa esercitazione. Usa il parametro `split` di ğŸ¤— Datasets  per caricare solo un piccolo campione dal dataset di addestramento poichÃ¨ il set di dati Ã¨ molto grande:\n+Carica il dataset [food101](https://huggingface.co/datasets/ethz/food101) per questa esercitazione. Usa il parametro `split` di ğŸ¤— Datasets  per caricare solo un piccolo campione dal dataset di addestramento poichÃ¨ il set di dati Ã¨ molto grande:\n \n ```py\n >>> from datasets import load_dataset\n \n->>> dataset = load_dataset(\"food101\", split=\"train[:100]\")\n+>>> dataset = load_dataset(\"ethz/food101\", split=\"train[:100]\")\n ```\n \n Secondo passo, dai uno sguardo alle immagini usando la caratteristica [`Image`](https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=image#datasets.Image) di ğŸ¤— Datasets:"
        },
        {
            "sha": "99ce9aff7534e920147e57bddae392df02ba6e4d",
            "filename": "docs/source/ja/preprocessing.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fja%2Fpreprocessing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fja%2Fpreprocessing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fpreprocessing.md?ref=297f5ae8aba5d933c07745ece28ce0e4a6e44ec0",
            "patch": "@@ -321,7 +321,7 @@ pip install datasets\n \n </Tip>\n \n-ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ãŸã‚ã«ã€[food101](https://huggingface.co/datasets/food101)ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰æ–¹æ³•ã®è©³ç´°ã«ã¤ã„ã¦ã¯ğŸ¤—[Datasetsãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/datasets/load_hub)ã‚’å‚ç…§ï¼‰ï¼š\n+ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ãŸã‚ã«ã€[food101](https://huggingface.co/datasets/ethz/food101)ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰æ–¹æ³•ã®è©³ç´°ã«ã¤ã„ã¦ã¯ğŸ¤—[Datasetsãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/datasets/load_hub)ã‚’å‚ç…§ï¼‰ï¼š\n \n <Tip>\n \n@@ -332,7 +332,7 @@ pip install datasets\n ```python\n >>> from datasets import load_dataset\n \n->>> dataset = load_dataset(\"food101\", split=\"train[:100]\")\n+>>> dataset = load_dataset(\"ethz/food101\", split=\"train[:100]\")\n ```\n \n æ¬¡ã«ã€ğŸ¤— Datasetsã® [`Image`](https://huggingface.co/docs/datasets/package_reference/main_classes?highlight=image#datasets.Image) æ©Ÿèƒ½ã§ç”»åƒã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼š"
        },
        {
            "sha": "9d8d391b5cc9e6d7ead161738061422558234f83",
            "filename": "docs/source/ja/tasks/image_classification.md",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fja%2Ftasks%2Fimage_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fja%2Ftasks%2Fimage_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Ftasks%2Fimage_classification.md?ref=297f5ae8aba5d933c07745ece28ce0e4a6e44ec0",
            "patch": "@@ -27,7 +27,7 @@ rendered properly in your Markdown viewer.\n \n ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€æ¬¡ã®æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚\n \n-1. [Food-101](https://huggingface.co/datasets/food101) ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã® [ViT](model_doc/vit) ã‚’å¾®èª¿æ•´ã—ã¦ã€ç”»åƒå†…ã®é£Ÿå“ã‚’åˆ†é¡ã—ã¾ã™ã€‚\n+1. [Food-101](https://huggingface.co/datasets/ethz/food101) ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã® [ViT](model_doc/vit) ã‚’å¾®èª¿æ•´ã—ã¦ã€ç”»åƒå†…ã®é£Ÿå“ã‚’åˆ†é¡ã—ã¾ã™ã€‚\n 2. å¾®èª¿æ•´ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’æ¨è«–ã«ä½¿ç”¨ã—ã¾ã™ã€‚\n \n <Tip>\n@@ -58,7 +58,7 @@ Datasetsã€ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ Food-101 ãƒ‡ãƒ¼ã‚¿ã‚»\n ```py\n >>> from datasets import load_dataset\n \n->>> food = load_dataset(\"food101\", split=\"train[:5000]\")\n+>>> food = load_dataset(\"ethz/food101\", split=\"train[:5000]\")\n ```\n \n [`~datasets.Dataset.train_test_split`] ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã® `train` åˆ†å‰²ã‚’ãƒˆãƒ¬ã‚¤ãƒ³ ã‚»ãƒƒãƒˆã¨ãƒ†ã‚¹ãƒˆ ã‚»ãƒƒãƒˆã«åˆ†å‰²ã—ã¾ã™ã€‚\n@@ -255,7 +255,7 @@ Datasetsã€ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ Food-101 ãƒ‡ãƒ¼ã‚¿ã‚»\n æ¨è«–ã‚’å®Ÿè¡Œã—ãŸã„ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚\n \n ```py\n->>> ds = load_dataset(\"food101\", split=\"validation[:10]\")\n+>>> ds = load_dataset(\"ethz/food101\", split=\"validation[:10]\")\n >>> image = ds[\"image\"][0]\n ```\n "
        },
        {
            "sha": "39a3f6869f527f01449ede40e25af7921854f2a2",
            "filename": "docs/source/ko/image_processors.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fko%2Fimage_processors.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fko%2Fimage_processors.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fimage_processors.md?ref=297f5ae8aba5d933c07745ece28ce0e4a6e44ec0",
            "patch": "@@ -146,7 +146,7 @@ Transformersì˜ ë¹„ì „ ëª¨ë¸ì€ ì…ë ¥ê°’ìœ¼ë¡œ PyTorch í…ì„œ í˜•íƒœì˜ í”½ì…€\n ```py\n from datasets import load_dataset\n \n-dataset = load_dataset(\"food101\", split=\"train[:100]\")\n+dataset = load_dataset(\"ethz/food101\", split=\"train[:100]\")\n ```\n \n [transforms](https://pytorch.org/vision/stable/transforms.html) ëª¨ë“ˆì˜ [Compose](https://pytorch.org/vision/master/generated/torchvision.transforms.Compose.html)APIëŠ” ì—¬ëŸ¬ ë³€í™˜ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì´ë¯¸ì§€ë¥¼ ë¬´ì‘ìœ„ë¡œ ìë¥´ê³  ë¦¬ì‚¬ì´ì¦ˆí•˜ëŠ” [RandomResizedCrop](https://pytorch.org/vision/main/generated/torchvision.transforms.RandomResizedCrop.html)ê³¼ ìƒ‰ìƒì„ ë¬´ì‘ìœ„ë¡œ ë°”ê¾¸ëŠ” [ColorJitter](https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html)ë¥¼ í•¨ê»˜ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤."
        },
        {
            "sha": "88051cae80a5d2b4cf70a8a65e0533c84c388fc9",
            "filename": "docs/source/ko/tasks/image_classification.md",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fko%2Ftasks%2Fimage_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fko%2Ftasks%2Fimage_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Fimage_classification.md?ref=297f5ae8aba5d933c07745ece28ce0e4a6e44ec0",
            "patch": "@@ -26,7 +26,7 @@ rendered properly in your Markdown viewer.\n \n ì´ ê°€ì´ë“œì—ì„œëŠ” ë‹¤ìŒì„ ì„¤ëª…í•©ë‹ˆë‹¤:\n \n-1. [Food-101](https://huggingface.co/datasets/food101) ë°ì´í„° ì„¸íŠ¸ì—ì„œ [ViT](model_doc/vit)ë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ì‹í’ˆ í•­ëª©ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.\n+1. [Food-101](https://huggingface.co/datasets/ethz/food101) ë°ì´í„° ì„¸íŠ¸ì—ì„œ [ViT](model_doc/vit)ë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ì‹í’ˆ í•­ëª©ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.\n 2. ì¶”ë¡ ì„ ìœ„í•´ ë¯¸ì„¸ ì¡°ì • ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n \n <Tip>\n@@ -57,7 +57,7 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n ```py\n >>> from datasets import load_dataset\n \n->>> food = load_dataset(\"food101\", split=\"train[:5000]\")\n+>>> food = load_dataset(\"ethz/food101\", split=\"train[:5000]\")\n ```\n \n ë°ì´í„° ì„¸íŠ¸ì˜ `train`ì„ [`~datasets.Dataset.train_test_split`] ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• í•˜ì„¸ìš”:\n@@ -252,7 +252,7 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³ ì í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì™€ë´…ì‹œë‹¤:\n \n ```py\n->>> ds = load_dataset(\"food101\", split=\"validation[:10]\")\n+>>> ds = load_dataset(\"ethz/food101\", split=\"validation[:10]\")\n >>> image = ds[\"image\"][0]\n ```\n "
        },
        {
            "sha": "aad163ec40bb727330afc881101baad4467930ab",
            "filename": "docs/source/zh/preprocessing.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fzh%2Fpreprocessing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/297f5ae8aba5d933c07745ece28ce0e4a6e44ec0/docs%2Fsource%2Fzh%2Fpreprocessing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fpreprocessing.md?ref=297f5ae8aba5d933c07745ece28ce0e4a6e44ec0",
            "patch": "@@ -323,7 +323,7 @@ pip install datasets\n \n </Tip>\n \n-åŠ è½½[food101](https://huggingface.co/datasets/food101)æ•°æ®é›†ï¼ˆæœ‰å…³å¦‚ä½•åŠ è½½æ•°æ®é›†çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…ğŸ¤— [Datasetsæ•™ç¨‹](https://huggingface.co/docs/datasets/load_hub)ï¼‰ä»¥äº†è§£å¦‚ä½•åœ¨è®¡ç®—æœºè§†è§‰æ•°æ®é›†ä¸­ä½¿ç”¨å›¾åƒå¤„ç†å™¨ï¼š\n+åŠ è½½[food101](https://huggingface.co/datasets/ethz/food101)æ•°æ®é›†ï¼ˆæœ‰å…³å¦‚ä½•åŠ è½½æ•°æ®é›†çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…ğŸ¤— [Datasetsæ•™ç¨‹](https://huggingface.co/docs/datasets/load_hub)ï¼‰ä»¥äº†è§£å¦‚ä½•åœ¨è®¡ç®—æœºè§†è§‰æ•°æ®é›†ä¸­ä½¿ç”¨å›¾åƒå¤„ç†å™¨ï¼š\n \n <Tip>\n \n@@ -335,7 +335,7 @@ pip install datasets\n ```py\n >>> from datasets import load_dataset\n \n->>> dataset = load_dataset(\"food101\", split=\"train[:100]\")\n+>>> dataset = load_dataset(\"ethz/food101\", split=\"train[:100]\")\n ```\n \n æ¥ä¸‹æ¥ï¼Œä½¿ç”¨ğŸ¤— Datasetsçš„[`Image`](https://huggingface.co/docs/datasets/package_reference/main_classes?highlight=image#datasets.Image)åŠŸèƒ½æŸ¥çœ‹å›¾åƒï¼š"
        }
    ],
    "stats": {
        "total": 50,
        "additions": 25,
        "deletions": 25
    }
}