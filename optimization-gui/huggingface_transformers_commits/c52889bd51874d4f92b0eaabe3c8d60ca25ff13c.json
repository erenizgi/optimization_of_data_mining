{
    "author": "cyyever",
    "message": "Remove reference of video_load_backend and video_fps for processor (#40719)\n\n* Remove reference of video_load_backend and video_fps for processor\n\nSigned-off-by: cyy <cyyever@outlook.com>\n\n* Restore changes\n\nSigned-off-by: cyy <cyyever@outlook.com>\n\n---------\n\nSigned-off-by: cyy <cyyever@outlook.com>",
    "sha": "c52889bd51874d4f92b0eaabe3c8d60ca25ff13c",
    "files": [
        {
            "sha": "79d01a96d9ad5afaeafbc0701f4881fe6c3f4cf2",
            "filename": "docs/source/en/chat_templating_multimodal.md",
            "status": "modified",
            "additions": 2,
            "deletions": 8,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/c52889bd51874d4f92b0eaabe3c8d60ca25ff13c/docs%2Fsource%2Fen%2Fchat_templating_multimodal.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c52889bd51874d4f92b0eaabe3c8d60ca25ff13c/docs%2Fsource%2Fen%2Fchat_templating_multimodal.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fchat_templating_multimodal.md?ref=c52889bd51874d4f92b0eaabe3c8d60ca25ff13c",
            "patch": "@@ -195,10 +195,6 @@ messages = [\n \n Pass `messages` to [`~ProcessorMixin.apply_chat_template`] to tokenize the input content. There are a few extra parameters to include in [`~ProcessorMixin.apply_chat_template`] that controls the sampling process.\n \n-The `video_load_backend` parameter refers to a specific framework to load a video. It supports [PyAV](https://pyav.basswood-io.com/docs/stable/), [Decord](https://github.com/dmlc/decord), [OpenCV](https://github.com/opencv/opencv), and [torchvision](https://pytorch.org/vision/stable/index.html).\n-\n-The examples below use Decord as the backend because it is a bit faster than PyAV.\n-\n <hfoptions id=\"sampling\">\n <hfoption id=\"fixed number of frames\">\n \n@@ -213,7 +209,6 @@ processed_chat = processor.apply_chat_template(\n     return_dict=True,\n     return_tensors=\"pt\",\n     num_frames=32,\n-    video_load_backend=\"decord\",\n )\n print(processed_chat.keys())\n ```\n@@ -223,16 +218,15 @@ These inputs are now ready to be used in [`~GenerationMixin.generate`].\n </hfoption>\n <hfoption id=\"fps\">\n \n-For longer videos, it may be better to sample more frames for better representation with the `video_fps` parameter. This determines how many frames per second to extract. As an example, if a video is 10 seconds long and `video_fps=2`, then the model samples 20 frames. In other words, 2 frames are uniformly sampled every 10 seconds.\n+For longer videos, it may be better to sample more frames for better representation with the `fps` parameter. This determines how many frames per second to extract. As an example, if a video is 10 seconds long and `fps=2`, then the model samples 20 frames. In other words, 2 frames are uniformly sampled every 10 seconds.\n \n ```py\n processed_chat = processor.apply_chat_template(\n     messages,\n     add_generation_prompt=True,\n     tokenize=True,\n     return_dict=True,\n-    video_fps=16,\n-    video_load_backend=\"decord\",\n+    fps=16,\n )\n print(processed_chat.keys())\n ```"
        },
        {
            "sha": "e124f7cdb421c1528dc9b99dd17644b7e2b699a8",
            "filename": "docs/source/en/model_doc/qwen2_5_omni.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/c52889bd51874d4f92b0eaabe3c8d60ca25ff13c/docs%2Fsource%2Fen%2Fmodel_doc%2Fqwen2_5_omni.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c52889bd51874d4f92b0eaabe3c8d60ca25ff13c/docs%2Fsource%2Fen%2Fmodel_doc%2Fqwen2_5_omni.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fqwen2_5_omni.md?ref=c52889bd51874d4f92b0eaabe3c8d60ca25ff13c",
            "patch": "@@ -83,7 +83,7 @@ inputs = processor.apply_chat_template(\n     tokenize=True,\n     return_dict=True,\n     return_tensors=\"pt\",\n-    video_fps=1,\n+    fps=1,\n \n     # kwargs to be passed to `Qwen2-5-OmniProcessor`\n     padding=True,"
        },
        {
            "sha": "62527ea4963a9ea37afa36c8f46be67be44a8852",
            "filename": "docs/source/en/model_doc/qwen2_5_vl.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/c52889bd51874d4f92b0eaabe3c8d60ca25ff13c/docs%2Fsource%2Fen%2Fmodel_doc%2Fqwen2_5_vl.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c52889bd51874d4f92b0eaabe3c8d60ca25ff13c/docs%2Fsource%2Fen%2Fmodel_doc%2Fqwen2_5_vl.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fqwen2_5_vl.md?ref=c52889bd51874d4f92b0eaabe3c8d60ca25ff13c",
            "patch": "@@ -146,7 +146,7 @@ model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n     \n     inputs = processor.apply_chat_template(\n         conversation,\n-        video_fps=1,\n+        fps=1,\n         add_generation_prompt=True,\n         tokenize=True,\n         return_dict=True,"
        },
        {
            "sha": "8ff09ca572381b9d9ac70f3d659db35ff4ff6413",
            "filename": "docs/source/en/model_doc/qwen2_vl.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/c52889bd51874d4f92b0eaabe3c8d60ca25ff13c/docs%2Fsource%2Fen%2Fmodel_doc%2Fqwen2_vl.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c52889bd51874d4f92b0eaabe3c8d60ca25ff13c/docs%2Fsource%2Fen%2Fmodel_doc%2Fqwen2_vl.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fqwen2_vl.md?ref=c52889bd51874d4f92b0eaabe3c8d60ca25ff13c",
            "patch": "@@ -99,7 +99,7 @@ conversation = [\n \n inputs = processor.apply_chat_template(\n     conversation,\n-    video_fps=1,\n+    fps=1,\n     add_generation_prompt=True,\n     tokenize=True,\n     return_dict=True,\n@@ -169,7 +169,7 @@ conversations = [conversation1, conversation2, conversation3, conversation4]\n # Preparation for batch inference\n ipnuts = processor.apply_chat_template(\n     conversations,\n-    video_fps=1,\n+    fps=1,\n     add_generation_prompt=True,\n     tokenize=True,\n     return_dict=True,"
        },
        {
            "sha": "4f102cfc821846aca8a593ebf0c8145898b2c2b4",
            "filename": "docs/source/ko/model_doc/qwen2_vl.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/c52889bd51874d4f92b0eaabe3c8d60ca25ff13c/docs%2Fsource%2Fko%2Fmodel_doc%2Fqwen2_vl.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c52889bd51874d4f92b0eaabe3c8d60ca25ff13c/docs%2Fsource%2Fko%2Fmodel_doc%2Fqwen2_vl.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fqwen2_vl.md?ref=c52889bd51874d4f92b0eaabe3c8d60ca25ff13c",
            "patch": "@@ -97,7 +97,7 @@ conversation = [\n \n inputs = processor.apply_chat_template(\n     conversation,\n-    video_fps=1,\n+    fps=1,\n     add_generation_prompt=True,\n     tokenize=True,\n     return_dict=True,\n@@ -167,7 +167,7 @@ conversations = [conversation1, conversation2, conversation3, conversation4]\n # 배치 추론을 위한 준비\n ipnuts = processor.apply_chat_template(\n     conversations,\n-    video_fps=1,\n+    fps=1,\n     add_generation_prompt=True,\n     tokenize=True,\n     return_dict=True,"
        },
        {
            "sha": "86e988026235d130e15fe34b2ee5fa992d214705",
            "filename": "src/transformers/processing_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/c52889bd51874d4f92b0eaabe3c8d60ca25ff13c/src%2Ftransformers%2Fprocessing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c52889bd51874d4f92b0eaabe3c8d60ca25ff13c/src%2Ftransformers%2Fprocessing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fprocessing_utils.py?ref=c52889bd51874d4f92b0eaabe3c8d60ca25ff13c",
            "patch": "@@ -1622,7 +1622,7 @@ def apply_chat_template(\n             if self.tokenizer.bos_token is not None and single_prompt.startswith(self.tokenizer.bos_token):\n                 kwargs[\"add_special_tokens\"] = False\n \n-            # Always sample frames by default unless explicitly set to `False` by users. If users do not pass `num_frames`/`video_fps`\n+            # Always sample frames by default unless explicitly set to `False` by users. If users do not pass `num_frames`/`fps`\n             # sampling should not done for BC.\n             if \"do_sample_frames\" not in kwargs and (\n                 kwargs.get(\"fps\") is not None or kwargs.get(\"num_frames\") is not None"
        },
        {
            "sha": "b9afe167dc4105f19217c1a5e35fd57963c694db",
            "filename": "tests/models/perception_lm/test_modeling_perception_lm.py",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/c52889bd51874d4f92b0eaabe3c8d60ca25ff13c/tests%2Fmodels%2Fperception_lm%2Ftest_modeling_perception_lm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c52889bd51874d4f92b0eaabe3c8d60ca25ff13c/tests%2Fmodels%2Fperception_lm%2Ftest_modeling_perception_lm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fperception_lm%2Ftest_modeling_perception_lm.py?ref=c52889bd51874d4f92b0eaabe3c8d60ca25ff13c",
            "patch": "@@ -436,7 +436,6 @@ def test_small_model_integration_test(self):\n             tokenize=True,\n             return_dict=True,\n             return_tensors=\"pt\",\n-            video_load_backend=\"decord\",\n             padding=True,\n             padding_side=\"left\",\n         ).to(torch_device)\n@@ -462,7 +461,6 @@ def test_small_model_integration_test_batched(self):\n             tokenize=True,\n             return_dict=True,\n             return_tensors=\"pt\",\n-            video_load_backend=\"decord\",\n             padding=True,\n             padding_side=\"left\",\n         ).to(torch_device)"
        }
    ],
    "stats": {
        "total": 26,
        "additions": 9,
        "deletions": 17
    }
}