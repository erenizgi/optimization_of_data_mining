{
    "author": "yao-matrix",
    "message": "enable new model uts to xpu and fix some failures on xpu (#41386)\n\n* enable new model uts to xpu and fix some failures on xpu\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>\n\n* add more\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>\n\n* fix style\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>\n\n* Update test_modeling_internvl.py\n\n* Update test_modeling_llava.py\n\n* Update test_modeling_qwen2_5_omni.py\n\n* Update test_modeling_llava_next_video.py\n\n* Update test_modeling_qwen3.py\n\n* Update test_modeling_whisper.py\n\n* Update test_modeling_whisper.py\n\n* Update test_modeling_llava.py\n\n* Update test_modeling_llava.py\n\n* Update test_modeling_qwen2_5_omni.py\n\n* fix style\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>\n\n---------\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>",
    "sha": "b13ee63b5a2a59fd76ec87608b685dfbf5605ff4",
    "files": [
        {
            "sha": "7f289d3bf833d1f2330cdef95c69c7666bf6636c",
            "filename": "tests/models/cohere2_vision/test_modeling_cohere2_vision.py",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fcohere2_vision%2Ftest_modeling_cohere2_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fcohere2_vision%2Ftest_modeling_cohere2_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fcohere2_vision%2Ftest_modeling_cohere2_vision.py?ref=b13ee63b5a2a59fd76ec87608b685dfbf5605ff4",
            "patch": "@@ -223,7 +223,7 @@ def test_model_integration_forward(self):\n \n         EXPECTED_LOGITS = Expectations(\n             {\n-                (\"xpu\", 3): [0.4109, 0.1532, 0.8018, 2.1328, 0.5483],\n+                (\"xpu\", 3): [2.4297, 1.6836, 1.8779, 2.1895, 1.9395],\n                 # 4-bit\n                 (\"cuda\", 7): [0.1097, 0.3481, 3.8340, 9.7969, 2.0488],\n                 (\"cuda\", 8): [2.4277, 1.6875, 1.8789, 2.1875, 1.9375],\n@@ -264,6 +264,7 @@ def test_model_integration_generate_text_only(self):\n \n         expected_outputs = Expectations(\n             {\n+                (\"xpu\", 3): \"<|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|>\",\n                 (\"cuda\", 8): \"<|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|>\",\n             }\n         )  # fmt: skip\n@@ -298,6 +299,7 @@ def test_model_integration_generate_chat_template(self):\n \n         expected_outputs = Expectations(\n             {\n+                (\"xpu\", 3): '<|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|>',\n                 (\"cuda\", 8): '<|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|>',\n             }\n         )  # fmt: skip\n@@ -344,6 +346,7 @@ def test_model_integration_batched_generate(self):\n         decoded_output = processor.decode(output[0, inputs[\"input_ids\"].shape[1] :], skip_special_tokens=True)\n         expected_outputs = Expectations(\n             {\n+                (\"xpu\", 3): 'Dock stretches to calm',\n                 (\"cuda\", 8): 'Dock stretches to calm',\n             }\n         )  # fmt: skip\n@@ -360,6 +363,7 @@ def test_model_integration_batched_generate(self):\n \n         expected_outputs = Expectations(\n             {\n+                (\"xpu\", 3): 'The image depicts a',\n                 (\"cuda\", 8): 'The image depicts a',\n             }\n         )  # fmt: skip\n@@ -418,6 +422,7 @@ def test_model_integration_batched_generate_multi_image(self):\n         # Batching seems to alter the output slightly, but it is also the case in the original implementation. This seems to be expected: https://github.com/huggingface/transformers/issues/23017#issuecomment-1649630232\n         expected_outputs = Expectations(\n             {\n+                (\"xpu\", 3): '<|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|>',\n                 (\"cuda\", 8): '<|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|>',\n             }\n         )  # fmt: skip\n@@ -433,6 +438,7 @@ def test_model_integration_batched_generate_multi_image(self):\n         decoded_output = processor.decode(output[1, inputs[\"input_ids\"].shape[1] :], skip_special_tokens=True)\n         expected_outputs = Expectations(\n             {\n+                (\"xpu\", 3): '<|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|>',\n                 (\"cuda\", 8): '<|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|><|CHATBOT_TOKEN|>',\n             }\n         )  # fmt: skip"
        },
        {
            "sha": "bb897a5a2a10c38d1c328a4e83883825089cf522",
            "filename": "tests/models/ernie4_5/test_modeling_ernie4_5.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fernie4_5%2Ftest_modeling_ernie4_5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fernie4_5%2Ftest_modeling_ernie4_5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fernie4_5%2Ftest_modeling_ernie4_5.py?ref=b13ee63b5a2a59fd76ec87608b685dfbf5605ff4",
            "patch": "@@ -79,6 +79,7 @@ def test_ernie4_5_0p3B(self):\n         \"\"\"\n         expected_texts = Expectations(\n             {\n+                (\"xpu\", 3): \"User: Hey, are you conscious? Can you talk to me?\\nAssistant: Hey! I'm here to help you with whatever you need. Are you feeling a bit overwhelmed or stressed? I'm here to listen and provide support.\",\n                 (\"cuda\", None): \"User: Hey, are you conscious? Can you talk to me?\\nAssistant: Hey! I'm here to help you with whatever you need. Are you feeling a bit overwhelmed or stressed? I'm here to listen and provide support.\",\n             }\n         )  # fmt: skip"
        },
        {
            "sha": "8445a3fe7b7c59d7c3abf92863158d5f29a82a28",
            "filename": "tests/models/internvl/test_modeling_internvl.py",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py?ref=b13ee63b5a2a59fd76ec87608b685dfbf5605ff4",
            "patch": "@@ -645,7 +645,7 @@ def test_llama_small_model_integration_forward(self):\n \n         expected_logits_all = Expectations(\n             {\n-                (\"xpu\", 3): [-9.8750, -0.5703, 1.4297, -10.3125, -10.3125],\n+                (\"xpu\", 3): [-9.8828,  -0.4954,   1.4561, -10.3438, -10.3438],\n                 (\"cuda\", 7): [-9.8750,  -0.4861,   1.4648, -10.3359, -10.3359],\n                 (\"cuda\", 8): [-9.8906,  -0.4995,   1.4473, -10.3359, -10.3438],\n                 (\"rocm\", (9, 4)): [ -9.8828,  -0.5005,   1.4697, -10.3438, -10.3438],\n@@ -680,6 +680,7 @@ def test_llama_small_model_integration_generate_text_only(self):\n \n         expected_outputs = Expectations(\n             {\n+                (\"xpu\", 3): \"Autumn leaves fall,\\nNature's breath, a season's sigh,\\nSilent woods awake.\",\n                 (\"cuda\", 7): \"Autumn leaves fall,\\nNature's breath, a gentle sigh,\\nSilent whispers.\",\n                 (\"cuda\", 8): \"Autumn leaves fall,\\nNature's breath, a silent sigh,\\nWinter's chill approaches.\",\n             }\n@@ -920,7 +921,7 @@ def test_llama_small_model_integration_interleaved_images_videos(self):\n         # Batching seems to alter the output slightly, but it is also the case in the original implementation. This seems to be expected: https://github.com/huggingface/transformers/issues/23017#issuecomment-1649630232\n         expected_outputs = Expectations(\n             {\n-                (\"xpu\", 3): \"user\\n\\n\\nWhat are the difference between these two images?\\nassistant\\nI apologize for the confusion in my previous response. After re-examining the images, I can see that they are actually\",\n+                (\"xpu\", 3): \"user\\n\\n\\nWhat are the difference between these two images?\\nassistant\\nI apologize for the confusion in my previous response. Upon closer inspection, the differences between the two images are:\\n\\n1. **\",\n                 (\"cuda\", 7): 'user\\n\\n\\nWhat are the difference between these two images?\\nassistant\\nI apologize for the confusion in my previous response. Upon closer inspection, the differences between the two images are:\\n\\n1. **',\n                 (\"cuda\", 8): 'user\\n\\n\\nWhat are the difference between these two images?\\nassistant\\nI apologize for the confusion in my previous response. After re-examining the images, I can see that there are no',\n                 (\"rocm\", (9, 4)): 'user\\n\\n\\nWhat are the difference between these two images?\\nassistant\\nI apologize for the confusion in my previous response. Upon closer inspection, the differences between the two images are:\\n\\n1. **',\n@@ -938,7 +939,7 @@ def test_llama_small_model_integration_interleaved_images_videos(self):\n         decoded_output = processor.decode(output[1], skip_special_tokens=True)\n         expected_outputs = Expectations(\n             {\n-                (\"xpu\", 3): \"user\\nFrame1: \\nFrame2: \\nFrame3: \\nFrame4: \\nFrame5: \\nFrame6: \\nFrame7: \\nFrame8: \\nWhat type of shot is the man performing?\\nassistant\\nThe man is performing a forehand shot. This is a common shot in tennis where the player swings the racket across their\",\n+                (\"xpu\", 3): \"user\\nFrame1: \\nFrame2: \\nFrame3: \\nFrame4: \\nFrame5: \\nFrame6: \\nFrame7: \\nFrame8: \\nWhat type of shot is the man performing?\\nassistant\\nThe man is performing a forehand shot. This is a common stroke in tennis where the player swings the racket across their\",\n                 (\"cuda\", 7): 'user\\nFrame1: \\nFrame2: \\nFrame3: \\nFrame4: \\nFrame5: \\nFrame6: \\nFrame7: \\nFrame8: \\nWhat type of shot is the man performing?\\nassistant\\nThe man is performing a forehand shot. This is a common stroke in tennis where the player swings the racket across their',\n                 (\"cuda\", 8): 'user\\nFrame1: \\nFrame2: \\nFrame3: \\nFrame4: \\nFrame5: \\nFrame6: \\nFrame7: \\nFrame8: \\nWhat type of shot is the man performing?\\nassistant\\nThe man is performing a forehand shot. This is a common stroke in tennis where the player swings the racket across their',\n             }"
        },
        {
            "sha": "6a6c4f893023458e0b5b441d4d6af1dfe0857a08",
            "filename": "tests/models/llava/test_modeling_llava.py",
            "status": "modified",
            "additions": 37,
            "deletions": 6,
            "changes": 43,
            "blob_url": "https://github.com/huggingface/transformers/blob/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fllava%2Ftest_modeling_llava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fllava%2Ftest_modeling_llava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fllava%2Ftest_modeling_llava.py?ref=b13ee63b5a2a59fd76ec87608b685dfbf5605ff4",
            "patch": "@@ -300,6 +300,7 @@ def test_small_model_integration_test(self):\n \n         output = model.generate(**inputs, max_new_tokens=20)\n         expected_decoded_texts = Expectations({\n+            (\"xpu\", 3): \"\\nUSER: What are the things I should be cautious about when I visit this place?\\nASSISTANT: When visiting this place, there are a few things one should be cautious about. Firstly,\",\n             (\"cuda\", None): \"\\nUSER: What are the things I should be cautious about when I visit this place?\\nASSISTANT: When visiting this place, there are a few things one should be cautious about. Firstly,\",\n             (\"rocm\", (9, 5)): \"\\nUSER: What are the things I should be cautious about when I visit this place?\\nASSISTANT: When visiting this place, there are a few things one should be cautious about. First, the\",\n         })  # fmt: skip\n@@ -328,17 +329,16 @@ def test_small_model_integration_test_llama_single(self):\n \n         EXPECTED_DECODED_TEXTS = Expectations(\n             {\n+                (\"xpu\", 3): 'USER:  \\nWhat are the things I should be cautious about when I visit this place? ASSISTANT: When visiting this place, which is a pier or dock extending over a body of water, there are a few things to be cautious about. First, be aware of the weather conditions, as sudden changes in weather can make the pier unsafe to walk on. Second, be mindful of the water depth and any potential hazards, such as submerged rocks or debris, that could cause accidents or injuries. Additionally, be cautious of the tides and currents, as they can change rapidly and pose a risk to swimmers or those who venture too close to the edge of the pier. Lastly, be respectful of the environment and other visitors, as the pier is a shared space where people can enjoy the view, relax, or engage in recreational activities.',\n                 (\"cuda\", 7): 'USER:  \\nWhat are the things I should be cautious about when I visit this place? ASSISTANT: When visiting this place, which is a pier or dock extending over a body of water, there are a few things to be cautious about. First, be aware of the weather conditions, as sudden changes in weather can make the pier unsafe to walk on. Second, be mindful of the water depth and any potential hazards, such as submerged rocks or debris, that could cause accidents or injuries. Additionally, be cautious of the tides and currents, as they can change rapidly and pose a risk to swimmers or those who venture too close to the edge of the pier. Lastly, be respectful of the environment and other visitors, as the pier is a shared space where people can enjoy the view, relax, or engage in recreational activities.',\n                 (\"cuda\", 8): 'USER:  \\nWhat are the things I should be cautious about when I visit this place? ASSISTANT: When visiting this place, which is a pier or dock extending over a body of water, there are a few things to be cautious about. First, be aware of the weather conditions, as sudden changes in weather can make the pier unsafe to walk on. Second, be mindful of the water depth and any potential hazards, such as submerged rocks or debris, that could cause accidents or injuries. Additionally, be cautious of the tides and currents, as they can change rapidly and pose a risk to swimmers or those who venture too close to the edge of the pier. Lastly, be respectful of the environment and other visitors, as the pier is a shared space where people can enjoy the view, relax, or engage in recreational activities.',\n                 (\"rocm\", (9, 5)): 'USER:  \\nWhat are the things I should be cautious about when I visit this place? ASSISTANT: When visiting this place, which is a pier or dock overlooking a lake, you should be cautious about the following:\\n\\n1. Safety: Ensure that the pier or dock is stable and secure before stepping onto it. Avoid walking on the edge of the pier or dock, as it could be unstable or unsafe.\\n\\n2. Weather conditions: Be aware of the weather forecast before visiting the area. Strong winds, heavy rain, or storms can make the pier or dock unsafe to use.\\n\\n3. Wildlife: Be mindful of the wildlife in the area, such as birds or aquatic animals. Avoid disturbing their natural habitat or causing harm to the local ecosystem.\\n\\n4. Water safety: If you plan to go swimming or engage in water activities, be aware of the water conditions, such as currents, tides, or potential hazards like submerged objects.\\n\\n5. Personal belongings: Keep an eye on your personal belongings, such as bags or backpacks, to prevent theft or loss.\\n\\n6. Leave no trace: When visiting the area, make sure to clean up after yourself and leave no trace of your presence to preserve the natural environment.',\n             }\n         )  # fmt: skip\n         EXPECTED_DECODED_TEXT = EXPECTED_DECODED_TEXTS.get_expectation()\n+        decoded_text = processor.decode(output[0], skip_special_tokens=True)\n \n-        self.assertEqual(\n-            processor.decode(output[0], skip_special_tokens=True),\n-            EXPECTED_DECODED_TEXT,\n-        )\n+        self.assertEqual(decoded_text, EXPECTED_DECODED_TEXT)\n \n     @slow\n     @require_bitsandbytes\n@@ -362,6 +362,13 @@ def test_small_model_integration_test_llama_batched(self):\n \n         expected_decoded_texts = Expectations(\n             {\n+                (\"xpu\", 3): [\n+                    \"USER:  \\nWhat are the things I should be cautious about when I visit this place? What should I bring \"\n+                    \"with me? ASSISTANT: When visiting this place, which is a pier or dock extending over a body of water, \"\n+                    \"you\",\n+                    \"USER:  \\nWhat is this? ASSISTANT: The image features two cats lying down on a pink couch. One cat \"\n+                    \"is located on\",\n+                ],\n                 (\"cuda\", None): [\n                     \"USER:  \\nWhat are the things I should be cautious about when I visit this place? What should I bring \"\n                     \"with me? ASSISTANT: When visiting this place, which is a pier or dock extending over a body of water, \"\n@@ -404,6 +411,10 @@ def test_small_model_integration_test_batch(self):\n \n         EXPECTED_DECODED_TEXTS = Expectations(\n             {\n+                (\"xpu\", 3): [\n+                    'USER:  \\nWhat are the things I should be cautious about when I visit this place? What should I bring with me?\\nASSISTANT: When visiting this place, there are a few things to be cautious about and items to bring along',\n+                    'USER:  \\nWhat is this?\\nASSISTANT: Cats',\n+                ],\n                 (\"cuda\", 7): [\n                     'USER:  \\nWhat are the things I should be cautious about when I visit this place? What should I bring with me?\\nASSISTANT: When visiting this place, there are a few things to be cautious about and items to bring along',\n                     'USER:  \\nWhat is this?\\nASSISTANT: Cats',\n@@ -452,6 +463,13 @@ def test_small_model_integration_test_llama_batched_regression(self):\n \n         expected_decoded_texts = Expectations(\n             {\n+                (\"xpu\", 3): [\n+                    \"USER:  \\nWhat are the things I should be cautious about when I visit this place? What should I bring \"\n+                    \"with me?\\nASSISTANT: When visiting this place, which appears to be a dock or pier extending over a \"\n+                    \"body of water\",\n+                    \"USER:  \\nWhat is this?\\nASSISTANT: Two cats lying on a bed!\\nUSER:  \\nAnd this?\\nASSISTANT: A cat \"\n+                    \"sleeping on a bed.\",\n+                ],\n                 (\"cuda\", None): [\n                     \"USER:  \\nWhat are the things I should be cautious about when I visit this place? What should I bring \"\n                     \"with me?\\nASSISTANT: When visiting this place, which appears to be a dock or pier extending over a \"\n@@ -501,6 +519,11 @@ def test_batched_generation(self):\n \n         EXPECTED_OUTPUTS = Expectations(\n             {\n+                (\"xpu\", 3): [\n+                    \"\\n \\nUSER: What's the difference of two images?\\nASSISTANT: The difference between the two images is that one shows a dog standing on a grassy field, while\",\n+                    '\\nUSER: Describe the image.\\nASSISTANT: The image features a brown and white dog sitting on a sidewalk. The dog is holding a small',\n+                    '\\nUSER: Describe the image.\\nASSISTANT: The image features a lone llama standing on a grassy hill. The llama is the'\n+                ],\n                 (\"cuda\", 7): [\n                     \"\\n \\nUSER: What's the difference of two images?\\nASSISTANT: The difference between the two images is that one of them has a dog standing on a field, while\",\n                     \"\\nUSER: Describe the image.\\nASSISTANT: The image features a brown and white dog sitting on a sidewalk. The dog is holding a small\",\n@@ -573,8 +596,16 @@ def test_generation_siglip_backbone(self):\n         # Make sure that `generate` works\n         output = model.generate(**inputs, max_new_tokens=30)\n \n-        EXPECTED_DECODED_TEXT = \"user\\n\\nWhat are these?\\nassistant The image shows two cats, one on the left and one on the right. They appear to be resting or sleeping on a pink blanket. The cat\"\n-        self.assertTrue(processor.batch_decode(output, skip_special_tokens=True)[0] == EXPECTED_DECODED_TEXT)\n+        EXPECTED_DECODED_TEXTS = Expectations(\n+            {\n+                (\"xpu\", 3): \"user\\n\\nWhat are these?\\nassistant These are two cats, one with a green collar and the other with a black collar. They are lying on a pink blanket and appear to be sleeping\",\n+                (\"cuda\", None): \"user\\n\\nWhat are these?\\nassistant The image shows two cats, one on the left and one on the right. They appear to be resting or sleeping on a pink blanket. The cat\",\n+            }\n+        )  # fmt: skip\n+        EXPECTED_DECODED_TEXT = EXPECTED_DECODED_TEXTS.get_expectation()\n+\n+        decoded_text = processor.batch_decode(output, skip_special_tokens=True)[0]\n+        self.assertEqual(decoded_text, EXPECTED_DECODED_TEXT)\n \n     @slow\n     def test_pixtral(self):"
        },
        {
            "sha": "fec81be2bfcfa121ac4b4dc53b476a0d309a024a",
            "filename": "tests/models/llava_next_video/test_modeling_llava_next_video.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fllava_next_video%2Ftest_modeling_llava_next_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fllava_next_video%2Ftest_modeling_llava_next_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fllava_next_video%2Ftest_modeling_llava_next_video.py?ref=b13ee63b5a2a59fd76ec87608b685dfbf5605ff4",
            "patch": "@@ -365,7 +365,7 @@ def test_small_model_integration_test(self):\n         expected_decoded_text = Expectations(\n             {\n                 (\"cuda\", None): \"USER: \\nWhy is this video funny? ASSISTANT: The humor in this video comes from the unexpected and somewhat comical situation of a young child reading a book while another child is attempting to read the same book. The child who is reading the book seems\",\n-                (\"xpu\", None): \"USER: \\nWhy is this video funny? ASSISTANT: The humor in this video comes from the unexpected and somewhat comical situation of a young child reading a book while wearing a pair of glasses that are too large for them. The glasses are\",\n+                (\"xpu\", None): \"USER: \\nWhy is this video funny? ASSISTANT: The humor in this video comes from the unexpected and somewhat comical situation of a young child reading a book while another child is attempting to read the same book. The child who is reading the book seems\",\n                 (\"rocm\", (9, 5)): \"USER: \\nWhy is this video funny? ASSISTANT: The humor in this video comes from the unexpected and adorable behavior of the young child. The child is seen reading a book, but instead of turning the pages like one would typically do, they\",\n             }\n         ).get_expectation()  # fmt: off\n@@ -392,6 +392,7 @@ def test_small_model_integration_test_batch(self):\n \n         expected_decoded_text = Expectations(\n             {\n+                (\"xpu\", None): \"USER: \\nWhy is this video funny? ASSISTANT: The humor in this video comes from the unexpected and somewhat comical situation of a young child reading a\",\n                 (\"cuda\", None): \"USER: \\nWhy is this video funny? ASSISTANT: The humor in this video comes from the unexpected and somewhat comical situation of a young child reading a\",\n                 (\"rocm\", (9, 5)): \"USER: \\nWhy is this video funny? ASSISTANT: The humor in this video comes from the unexpected and adorable behavior of the young child. The\",\n             }\n@@ -427,6 +428,7 @@ def test_small_model_integration_test_batch_different_vision_types(self):\n         output = model.generate(**inputs, do_sample=False, max_new_tokens=50)\n         EXPECTED_DECODED_TEXT = Expectations(\n             {\n+                (\"xpu\", None): 'USER: \\nWhat is shown in this image? ASSISTANT: The image appears to be a graphical representation of a machine learning model\\'s performance on a task, likely related to natural language processing or text understanding. It shows a scatter plot with two axes, one labeled \"BLIP-2\"',\n                 (\"rocm\", (9, 5)): \"USER: \\nWhat is shown in this image? ASSISTANT: The image displays a chart that appears to be a comparison of different models or versions of a machine learning (ML) model, likely a neural network, based on their performance on a task or dataset. The chart is a scatter plot with axes labeled\",\n                 (\"cuda\", None): 'USER: \\nWhat is shown in this image? ASSISTANT: The image appears to be a graphical representation of a machine learning model\\'s performance on a task, likely related to natural language processing or text understanding. It shows a scatter plot with two axes, one labeled \"BLIP-2\"',\n             }"
        },
        {
            "sha": "74edb875e42a914fa9ce8f33a607069f38b3953f",
            "filename": "tests/models/phi3/test_modeling_phi3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fphi3%2Ftest_modeling_phi3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fphi3%2Ftest_modeling_phi3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fphi3%2Ftest_modeling_phi3.py?ref=b13ee63b5a2a59fd76ec87608b685dfbf5605ff4",
            "patch": "@@ -350,6 +350,7 @@ def test_export_static_cache(self):\n \n         expected_text_completions = Expectations(\n             {\n+                (\"xpu\", None): [\"You are a helpful digital assistant. Please provide safe, ethical and accurate information to the user. A 45-year-old patient with a 10-year history of type 2 diabetes mellitus, who is currently on metformin and a SGLT2 inhibitor, presents with a 2-year history\"],\n                 (\"rocm\", (9, 5)): [\"You are a helpful digital assistant. Please provide safe, ethical and accurate information to the user. A 45-year-old patient with a 10-year history of type 2 diabetes mellitus presents with a 2-year history of progressive, non-healing, and painful, 2.5 cm\"],\n                 (\"cuda\", None): [\"You are a helpful digital assistant. Please provide safe, ethical and accurate information to the user. A 45-year-old patient with a 10-year history of type 2 diabetes mellitus, who is currently on metformin and a SGLT2 inhibitor, presents with a 2-year history\"],\n             }"
        },
        {
            "sha": "e35ab1f16d92e80305573cdaf7215ef0ae574627",
            "filename": "tests/models/qwen2_5_omni/test_modeling_qwen2_5_omni.py",
            "status": "modified",
            "additions": 8,
            "deletions": 4,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_modeling_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_modeling_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_modeling_qwen2_5_omni.py?ref=b13ee63b5a2a59fd76ec87608b685dfbf5605ff4",
            "patch": "@@ -667,6 +667,7 @@ def test_small_model_integration_test(self):\n         )\n \n         EXPECTED_DECODED_TEXT = Expectations({\n+            (\"xpu\", None): \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is glass shattering, and the dog is a Labrador Retriever.\",\n             (\"cuda\", (8, 6)): \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is glass shattering, and the dog is a Labrador Retriever.\",\n             (\"rocm\", (9, 4)): \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is glass shattering, and the dog is a Labrador Retriever.\",\n         }).get_expectation()  # fmt: skip\n@@ -694,6 +695,10 @@ def test_small_model_integration_test_batch(self):\n \n         EXPECTED_DECODED_TEXTS = Expectations(\n             {\n+                (\"xpu\", 3): [\n+                    \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is glass shattering, and the dog is a Labrador Retriever.\",\n+                    \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is glass shattering, and the dog is a Labrador Retriever.\",\n+                ],\n                 (\"cuda\", 7) : [\n                     \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is of glass shattering, and the dog in the picture is a Labrador Retriever\",\n                     \"system\\nYou are a helpful assistant.\\nuser\\nWhat's that sound and what kind of dog is this?\\nassistant\\nThe sound is of glass shattering, and the dog in the picture is a Labrador Retriever\",\n@@ -797,16 +802,15 @@ def test_small_model_integration_test_w_audio(self):\n \n         EXPECTED_DECODED_TEXTS = Expectations(\n             {\n+                (\"xpu\", None): \"system\\nYou are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\\nuser\\n\\nassistant\\nWell, I can't really guess your age and gender just from your voice. There are so many\",\n                 (\"cuda\", 7): \"system\\nYou are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\\nuser\\n\\nassistant\\nWell, I can try. But it's not always that accurate. I might be able to make\",\n                 (\"cuda\", 8): \"system\\nYou are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\\nuser\\n\\nassistant\\nWell, I can't really guess your age and gender just from your voice. There are so many\",\n             }\n         )  # fmt: skip\n         EXPECTED_DECODED_TEXT = EXPECTED_DECODED_TEXTS.get_expectation()\n \n-        self.assertEqual(\n-            self.processor.decode(output[0][0], skip_special_tokens=True),\n-            EXPECTED_DECODED_TEXT,\n-        )\n+        decoded_text = self.processor.decode(output[0][0], skip_special_tokens=True)\n+        self.assertEqual(decoded_text, EXPECTED_DECODED_TEXT)\n         self.assertFalse(torch.isnan(output[1]).any().item())\n \n     @slow"
        },
        {
            "sha": "3d12cd10a4820054bd0163303122282108845cbb",
            "filename": "tests/models/qwen3/test_modeling_qwen3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fqwen3%2Ftest_modeling_qwen3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fqwen3%2Ftest_modeling_qwen3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen3%2Ftest_modeling_qwen3.py?ref=b13ee63b5a2a59fd76ec87608b685dfbf5605ff4",
            "patch": "@@ -225,6 +225,7 @@ def test_export_static_cache(self):\n \n         expected_text_completions = Expectations(\n             {\n+                (\"xpu\", None): [\"My favourite condiment is 100% plain, unflavoured, and unadulterated. It is\"],\n                 (\"rocm\", (9, 5)): [\"My favourite condiment is 100% plain, unflavoured, and unadulterated.\"],\n                 (\"cuda\", None): cuda_expectation,\n             }"
        },
        {
            "sha": "58f9164c61d4894f6d6d6266a82af7e78fd0039a",
            "filename": "tests/models/whisper/test_modeling_whisper.py",
            "status": "modified",
            "additions": 65,
            "deletions": 4,
            "changes": 69,
            "blob_url": "https://github.com/huggingface/transformers/blob/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py?ref=b13ee63b5a2a59fd76ec87608b685dfbf5605ff4",
            "patch": "@@ -1833,6 +1833,56 @@ def test_small_longform_timestamps_generation(self):\n         input_features = input_features.to(torch_device)\n         generated_ids = model.generate(input_features, return_timestamps=True, return_segments=True)\n         # fmt: off\n+        EXPECTED_XPU = [\n+                {\n+                    'text': ' Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.',\n+                    'timestamp': (0.0, 6.38),\n+                },\n+                {\n+                    'text': \" Nor is Mr. Quilter's manner less interesting than his matter.\",\n+                    'timestamp': (6.38, 11.32),\n+                },\n+                {\n+                    'text': ' He tells us that at this festive season of the year,',\n+                    'timestamp': (11.32, 15.0),\n+                },\n+                {\n+                    'text': ' With Christmas and roast beef looming before us, similes drawn from eating and its results',\n+                    'timestamp': (30.0, 36.76),\n+                },\n+                {\n+                    'text': ' occur most readily to the mind.',\n+                    'timestamp': (36.76, 39.8),\n+                },\n+                {\n+                    'text': \" He has grave doubts whether Sir Frederick Layton's work is really Greek after all and\",\n+                    'timestamp': (39.8, 45.38),\n+                },\n+                {\n+                    'text': ' can discover in it but little of rocky Ithaca.',\n+                    'timestamp': (45.38, 49.0),\n+                },\n+                {\n+                    'text': \" Lenell's pictures are a sort of up-guards-and-atom paintings, and Mason's exquisite ittles\",\n+                    'timestamp': (49.0, 56.28),\n+                },\n+                {\n+                    'text': \" are as national as a jingo poem. Mr. Burkett fosters landscape's smile at one much in\",\n+                    'timestamp': (56.28, 64.12),\n+                },\n+                {\n+                    'text': ' the same way that Mr. Karker used to flash his teeth. And Mr. John Collier gives his',\n+                    'timestamp': (64.12, 70.76),\n+                },\n+                {\n+                    'text': ' sitter a cheerful slap on the back before he says, like a shampoo or in a Turkish bath,',\n+                    'timestamp': (70.76, 77.16),\n+                },\n+                {\n+                    'text': ' Next Man',\n+                    'timestamp': (77.16, 78.16),\n+                },\n+        ]\n         EXPECTED_CUDA = [\n             {\n                 \"text\": \" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.\",\n@@ -1936,7 +1986,7 @@ def test_small_longform_timestamps_generation(self):\n         # fmt: on\n \n         expected_output = Expectations(\n-            {(\"cuda\", None): EXPECTED_CUDA, (\"rocm\", (9, 4)): EXPECTED_ROCM}\n+            {(\"xpu\", None): EXPECTED_XPU, (\"cuda\", None): EXPECTED_CUDA, (\"rocm\", (9, 4)): EXPECTED_ROCM}\n         ).get_expectation()\n \n         transcript = processor.batch_decode(generated_ids[\"sequences\"], skip_special_tokens=True, output_offsets=True)\n@@ -2578,15 +2628,16 @@ def test_whisper_longform_single_batch_prev_cond(self):\n     @slow\n     def test_whisper_shortform_single_batch_prev_cond(self):\n         # fmt: off\n+        xpu_expectation = [\" Folks, I spend a lot of time right over there, night after night after night, actually. Carefully selecting for you the day's noosiest, most aerodynamic headlines, stress testing, and those topical anti-lock breaks and power steering, painstakingly stitching, leather seating, so soft, it would make JD power and her associates blush to create the luxury sedan that is my nightly monologue. But sometimes, you sometimes, folks, I lurched a consciousness in the back of an abandoned school bus and slap myself awake.\"]\n         cuda_expectation = [\" Folks, I spend a lot of time right over there, night after night after night, actually. Carefully selecting for you the day's noosiest, most aerodynamic headlines, stress testing, and those topical anti-lock breaks and power steering, painstakingly stitching, leather seating so soft, it would make JD power and her associates blush to create the luxury sedan that is my nightly monologue. But sometimes, you sometimes, folks. I lurched a consciousness in the back of an abandoned school bus and slap myself awake.\"]\n         cuda_expectation2 = [\" Folks, I spend a lot of time right over there, night after night after night, actually. Carefully selecting for you the day's noosiest, most aerodynamic headlines, stress testing, and those topical anti-lock breaks and power steering, painstakingly stitching, leather seating so soft, it would make JD power and her associates blush to create the luxury sedan that is my nightly monologue. But sometimes, you sometimes, folks. I lurched a consciousness in the back of an abandoned school bus and slap myself a wig.\"]\n         rocm_expectation = [\" Folks, I spend a lot of time right over there, night after night after night, actually. Carefully selecting for you the day's noosiest, most aerodynamic headlines, stress testing, and those topical anti-lock breaks and power steering, painstakingly stitching, leather seating, so soft, it would make JD power and her associates blush to create the luxury sedan that is my nightly monologue. But sometimes, you sometimes, folks, I lurched a consciousness in the back of an abandoned school bus and slap myself awake.\"]\n         # fmt: on\n         expected_output = Expectations(\n-            {(\"cuda\", None): cuda_expectation, (\"rocm\", (9, 4)): rocm_expectation}\n+            {(\"xpu\", None): xpu_expectation, (\"cuda\", None): cuda_expectation, (\"rocm\", (9, 4)): rocm_expectation}\n         ).get_expectation()\n         expected_output2 = Expectations(\n-            {(\"cuda\", None): cuda_expectation2, (\"rocm\", (9, 4)): rocm_expectation}\n+            {(\"xpu\", None): xpu_expectation, (\"cuda\", None): cuda_expectation2, (\"rocm\", (9, 4)): rocm_expectation}\n         ).get_expectation()\n \n         processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\")\n@@ -2765,6 +2816,16 @@ def test_whisper_longform_multi_batch_prev_cond(self):\n     @slow\n     def test_whisper_longform_multi_batch_hard(self):\n         # fmt: off\n+        EXPECTED_XPU = [\n+            \" Folks, if you watch the show, you know, I spent a lot of time right over there. Patiently and astutely scrutinizing the boxwood and mahogany chest set of the day's biggest stories developing the central headline pawns, definitely maneuvering an oso topical night to F6, fainting of classics, Sicilian, nade door variation on the news, all the while seeing eight moves deep and patiently marshalling the latest press releases into a fisher's shows in Lipnitsky attack that culminates in the elegant lethal slow-played It's an all-passant checkmate that is my nightly monologue, but sometimes sometimes folks, I... APPLAUSE Sometimes I... Startle away, cubside down in the monkey bars of a condemned playground on a super fun site. Get all hept up on goofballs, rummage that were discarded tag bag of defective toys. Yank out a fist bowl of disembodied doll limbs, toss them on a stained kid's place mat from a defunct denny's, set up a table inside a rusty cargo container down by the wharf and challenged toothless drifters to the godless, bug-house blitz of tournament that is my segment. Meanwhile!\",\n+            \" Folks, I spend a lot of time right over there, night after night after night, actually. Carefully selecting for you the day's noosiest, most aerodynamic headlines, stress testing, and those topical anti-lock breaks and power steering, painstakingly stitching, leather seating, so soft, it would make JD power and her associates blush to create the luxury sedan that is my nightly monologue. But sometimes, you sometimes, folks, I lurched a consciousness in the back of an abandoned school bus and slap myself awake with a crusty floor mat. Before using a mouse-bitten timing belt to strap some old plywood to a couple of discarded oil drums, then by the light of a heathen moon, render a gas tank out of an empty big gulp, fill with white claw and denatured alcohol, then light a match and let her rip and the demented one man soapboxed her be of news that is my segment. We need one!\",\n+            \" Ladies and gentlemen, you know, I spent a lot of time right over there Raising the finest Holstein news cattle firmly yet tenderly milking the latest headlines from their jokes swollen teats Churning the daily stories into the decadent proven-style style triple cream breed that is my nightly monologue But sometimes sometimes folks I stagger home hungry after being released by the police and Root around in the neighbor's trash can for an old milk carton scrape out the blooming dairy residue into the remains of a wet cheese rod I won from a rat in a pre-donned street fight. Put it in a discarded paint can to leave it to ferment next to a trash fire then hunker down and hallucinate while eating the listeria laden demon custard of news that is my segment. You mean one of them.\",\n+            \" Folks, if you watch this show, you know I spend most of my time right over there carefully sorting through the day's biggest stories and selecting only the most subtle and unblemished ostrich and crocodile news leather, which I then entrust to artisan graduates of the Ichol Gregoire Ferrandi, who carefully dye them in a palette of bright zesty shades and adorn them in the finest and most topical inlay work using hand tools and double magnifying glasses, then assemble them according to now classic and elegant geometry using our signature saddles stitching. In line it with bees, wax coated linen, finely attached a mallet hammer strap, pearl hardware, and close shed to create for you the one of a kind hoke couture, Erme's Birkin bag that is my monologue, but sometimes, sometimes folks, sometimes. Sometimes I wake up in the last car of an abandoned roller coaster at Coney Island where I'm I'm hiding from the triads. I have some engine lubricants out of a safe way bag and stagger down the shore to tear the sail off a beach schooner. Then I rip the coaxial cable out of an RV and elderly couple from Utah, Hank, and Mabel lovely folks. And use it to stitch the sail into a loose pouch like a rock sack. And I stow away in the back of a garbage truck to the junkyard where I pick through to the debris for only the broken toys that make me the saddest until I have loaded for you. The Hobo Fugitives bug out, bindle of news that is my segment. Me one!\",\n+            \" You know, folks, I spent a lot of time crafting for you a bespoke playlist of the day's biggest stories right over there. Meticulously selecting the most topical chakra affirming scented candles, and using Feng Shui to perfectly align the joke energy in the exclusive boutique yoga retreat that is my monologue. But sometimes just sometimes I go to the dumpster behind the waffle house at three in the morning, take off my shirt, cover myself, and used fry oil, wrap my hands with some double-duct tape by stole from the broken car window. Pound a six-pack of blueberry hard-seltzer and a sack of pills I stole from a parked ambulance. Then arm wrestle a raccoon in the back alley vision quest of news that is my segment. Meanwhile!\",\n+            \" You know, folks, I spend most of my time right over there. Mining the day's biggest, most important stories, collecting the finest, most topical iron or hand hammering it into joke panels. Then I craft sheets of bronze and blazing with patterns that tell an epic tale of conquest and glory. Then, using the Germanic tradition press black process, I place thin sheets of foil against the scenes and by hammering or otherwise applying pressure from the back, I project these scenes into a pair of cheat cards in a faceplate and finally using fluted strips of white alloyed molding, I divide the designs into framed panels and hold it all together using bronze rivets to create the beautiful and intimidating, Anglo-Saxon battle helm that is my nightly monologue. Sometimes, sometimes folks. Sometimes, just sometimes, I come into my sense as fully naked on the deck of a pirate-be-seag'd, melee container ship that picked me up floating on the detached door of a portapotty in the Indian Ocean. Then after a sun stroke-induced realization of the crew of this ship plans to sell me an exchange for a bag of oranges to fight off scurvy, I lead a mutiny using only a PVC pipe at a pool chain that accepting my new role as Captain and declaring myself king of the windarc seas. I grab a dirty mop bucket covered in barnacles and adorn it with the teeth of the vanquished to create the sopping wet pirate crown of news that is my segment. Meanwhile!\",\n+            \" Folks, if you watch this show, you know I spend most of my time right over there carefully blending for you the day's Newsiest most topical flower eggs milk and butter and Stranding into a fine batter to make delicate and informative comedy pancakes Then I glaze them in the juice and zest of the most relevant midnight Valencia oranges and douse it all and a fine Dela main de voyage cognac Before from bang and basting them tables. I deserve for you the James Beard award worthy crepe suzzette That is my nightly monologue, but sometimes just sometimes folks. I wake up in the baggage hold of Greyhound bus. It's being hoisted by the scrap yard claw toward the burn pit. Escape to a nearby abandoned price chopper where I scrounge for old bread scraps and busted open bags of starfruit candies and expired eggs. Chuck it all on a dirty hubcap and slap it over a tire fire before using the legs of a strain, pair of sweatpants and as oven mitts to extract and serve the demented transience poundcake of news that is my segment. Me, Guadalupe!\",\n+            ' Folks, if you watched the show and I hope you do, I spent a lot of time right over there. Tiredlessly studying the lineage of the days most important thoroughbred stories and wholesome or headlines, working with the best trainers, money can buy to rear their comedy offspring with a hand that is stern yet gentle into the triple crown winning equine specimen. That is my nightly monologue, but sometimes, sometimes, folks, I break into an unincorporated veterinary genetics lab, and grab whatever test tubes I can find, and then under a grow light I got from a discarded chia pet. I mixed the pilfer DNA of a horse and whatever was in a tube labeled Keith Colan extra. Slurrying the concoction with caffeine pills and a microwave red bull, I screamed, sing a prayer to Janice, initiator of human life and God of transformation as a half horse, half man, freak. Seasons to life before me and the hideous collection of loose animal parts and corrupted man tissue that is my segment. Meanwhile!'\n+        ]\n         EXPECTED_CUDA = [\n             \" Folks, if you watch the show, you know, I spent a lot of time right over there. Patiently and astutely scrutinizing the boxwood and mahogany chest set of the day's biggest stories developing the central headline pawns, definitely maneuvering an oso topical night to F6, fainting a classic Sicilian, nade door variation on the news, all the while seeing eight moves deep and patiently marshalling the latest press releases into a fisher's shows in Lip Nitsky attack that culminates in the elegant lethal slow-played, all-passant checkmate that is my nightly monologue. But sometimes, sometimes, folks, I. CHEERING AND APPLAUSE Sometimes I startle away, cubside down in the monkey bars of a condemned playground on a super fun site. Get all hept up on goofballs. Rummage that were discarded tag bag of defective toys. Yank out a fist bowl of disembodied doll limbs, toss them on a stained kid's place mat from a defunct dennies. set up a table inside a rusty cargo container down by the Wharf and challenged toothless drifters to the godless bughouse blitz of tournament that is my segment. Meanwhile.\",\n             \" Folks, I spend a lot of time right over there, night after night after night, actually. Carefully selecting for you the day's noosiest, most aerodynamic headlines, stress testing, and those topical anti-lock breaks and power steering, painstakingly stitching, leather seating so soft, it would make JD power and her associates blush to create the luxury sedan that is my nightly monologue. But sometimes, you sometimes, folks. I lurched a consciousness in the back of an abandoned school and slap myself awake with a crusty floor mat. Before using a mouse-bitten timing belt to strap some old plywood to a couple of discarded oil drums, then by the light of a heathen moon, render a gas tank out of an empty big gulp, fill with white claw and denatured alcohol, then light a match and let her rip and the demented one man soapbox derby of news that is my segment. Me, Guadalupe! No!\",\n@@ -2788,7 +2849,7 @@ def test_whisper_longform_multi_batch_hard(self):\n         # fmt: on\n \n         expected_output = Expectations(\n-            {(\"cuda\", None): EXPECTED_CUDA, (\"rocm\", (9, 4)): EXPECTED_ROCM}\n+            {(\"xpu\", None): EXPECTED_XPU, (\"cuda\", None): EXPECTED_CUDA, (\"rocm\", (9, 4)): EXPECTED_ROCM}\n         ).get_expectation()\n \n         processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\")"
        },
        {
            "sha": "9c63c80efecdb516ac2c3382ad71f3e0258a5f3f",
            "filename": "tests/models/xglm/test_modeling_xglm.py",
            "status": "modified",
            "additions": 17,
            "deletions": 7,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fxglm%2Ftest_modeling_xglm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fmodels%2Fxglm%2Ftest_modeling_xglm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fxglm%2Ftest_modeling_xglm.py?ref=b13ee63b5a2a59fd76ec87608b685dfbf5605ff4",
            "patch": "@@ -389,13 +389,22 @@ def test_batch_generation(self):\n         non_padded_sentence = tokenizer.decode(output_non_padded[0], skip_special_tokens=True)\n         padded_sentence = tokenizer.decode(output_padded[0], skip_special_tokens=True)\n \n-        expected_output_sentence = [\n-            \"This is an extremely long sentence that only exists to test the ability of the model to cope with \"\n-            \"left-padding, such as in batched generation. The output for the sequence below should be the same \"\n-            \"regardless of whether left padding is applied or not. When left padding is applied, the sequence will be \"\n-            \"a single\",\n-            \"Hello, my dog is a little bit of a shy one, but he is very friendly\",\n-        ]\n+        #  fmt: off\n+        expected_output_sentences = Expectations(\n+            {\n+                (\"xpu\", None): [\n+                    'This is an extremely long sentence that only exists to test the ability of the model to cope with left-padding, such as in batched generation. The output for the sequence below should be the same regardless of whether left padding is applied or not. When left padding is applied, the model will not be able',\n+                 'Hello, my dog is a little bit of a shy one, but he is very friendly'\n+                ],\n+                (\"cuda\", None): [\n+                    \"This is an extremely long sentence that only exists to test the ability of the model to cope with left-padding, such as in batched generation. The output for the sequence below should be the same regardless of whether left padding is applied or not. When left padding is applied, the sequence will be a single\",\n+                    \"Hello, my dog is a little bit of a shy one, but he is very friendly\",\n+                ],\n+            }\n+        )\n+        #  fmt: on\n+        expected_output_sentence = expected_output_sentences.get_expectation()\n+\n         self.assertListEqual(expected_output_sentence, batch_out_sentence)\n         self.assertListEqual(expected_output_sentence, [non_padded_sentence, padded_sentence])\n \n@@ -427,6 +436,7 @@ def test_xglm_sample(self):\n \n         expected_output_strings = Expectations(\n             {\n+                (\"xpu\", None): \"Today is a nice day and the sun is shining. A nice day with warm rainy and windy weather today.\",\n                 (\"rocm\", (9, 5)): \"Today is a nice day and the sun is shining. A nice day with warm rainy and windy weather today.\",\n                 (\"cuda\", None): cuda_expectation,\n             }"
        },
        {
            "sha": "07ce9c5d91caf7d3c2a3ec2b48db300257c236e3",
            "filename": "tests/pipelines/test_pipelines_mask_generation.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fpipelines%2Ftest_pipelines_mask_generation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b13ee63b5a2a59fd76ec87608b685dfbf5605ff4/tests%2Fpipelines%2Ftest_pipelines_mask_generation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_mask_generation.py?ref=b13ee63b5a2a59fd76ec87608b685dfbf5605ff4",
            "patch": "@@ -107,6 +107,7 @@ def test_small_model_pt(self):\n \n         # fmt: off\n         last_output = Expectations({\n+            (\"xpu\", None): {'mask': {'hash': 'b5f47c9191', 'shape': (480, 640)}, 'scores': 0.8872},\n             (\"cuda\", None): {'mask': {'hash': 'b5f47c9191', 'shape': (480, 640)}, 'scores': 0.8871},\n             (\"rocm\", (9, 5)): {'mask': {'hash': 'b5f47c9191', 'shape': (480, 640)}, 'scores': 0.8872}\n         }).get_expectation()"
        }
    ],
    "stats": {
        "total": 171,
        "additions": 145,
        "deletions": 26
    }
}