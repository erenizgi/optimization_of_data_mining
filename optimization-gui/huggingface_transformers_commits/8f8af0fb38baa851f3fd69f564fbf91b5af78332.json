{
    "author": "ylacombe",
    "message": "Correct Whisper's beam search scores computation (#32336)\n\nfix proposal",
    "sha": "8f8af0fb38baa851f3fd69f564fbf91b5af78332",
    "files": [
        {
            "sha": "c67aa0cd01f019a880ad55ec3dcbd459dd906f94",
            "filename": "src/transformers/models/whisper/generation_whisper.py",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/8f8af0fb38baa851f3fd69f564fbf91b5af78332/src%2Ftransformers%2Fmodels%2Fwhisper%2Fgeneration_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8f8af0fb38baa851f3fd69f564fbf91b5af78332/src%2Ftransformers%2Fmodels%2Fwhisper%2Fgeneration_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Fgeneration_whisper.py?ref=8f8af0fb38baa851f3fd69f564fbf91b5af78332",
            "patch": "@@ -954,7 +954,9 @@ def _postprocess_outputs(\n \n         seek_outputs[\"sequences\"] = seek_outputs[\"sequences\"][:, start_idx:]\n \n-        def split_by_batch_index(values, key, batch_idx, is_shortform):\n+        def split_by_batch_index(values, key, batch_idx, is_shortform, beam_indices=None):\n+            if beam_indices is not None and key == \"scores\":\n+                return [v[beam_idx].cpu() for (v, beam_idx) in zip(values, beam_indices[batch_idx][: len(values)])]\n             if key in [\"scores\", \"encoder_attentions\", \"encoder_hidden_states\", \"logits\"]:\n                 return [v[batch_idx].cpu() for v in values]\n             if key in [\"decoder_attentions\", \"decoder_hidden_states\", \"cross_attentions\"]:\n@@ -985,7 +987,10 @@ def split_by_batch_index(values, key, batch_idx, is_shortform):\n \n         sequence_tokens = seek_outputs[\"sequences\"]\n         seek_outputs = [\n-            {k: split_by_batch_index(v, k, i, is_shortform) for k, v in seek_outputs.items()}\n+            {\n+                k: split_by_batch_index(v, k, i, is_shortform, beam_indices=seek_outputs.get(\"beam_indices\"))\n+                for k, v in seek_outputs.items()\n+            }\n             for i in range(sequence_tokens.shape[0])\n         ]\n "
        }
    ],
    "stats": {
        "total": 9,
        "additions": 7,
        "deletions": 2
    }
}