{
    "author": "Vaibhavs10",
    "message": "ðŸ”´ Update default `dtype` for pipelines to `auto` (#38882)\n\n* check typing\n\n* Fallback to fp32 if auto not supported.\n\n* up.\n\n* feedback from review.\n\n* make style.",
    "sha": "2e4c045540c3bd1eed226babd20af3941f956c58",
    "files": [
        {
            "sha": "fe829d51ea020718a0cc33219e31834706a24de3",
            "filename": "src/transformers/pipelines/__init__.py",
            "status": "modified",
            "additions": 31,
            "deletions": 31,
            "changes": 62,
            "blob_url": "https://github.com/huggingface/transformers/blob/2e4c045540c3bd1eed226babd20af3941f956c58/src%2Ftransformers%2Fpipelines%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2e4c045540c3bd1eed226babd20af3941f956c58/src%2Ftransformers%2Fpipelines%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2F__init__.py?ref=2e4c045540c3bd1eed226babd20af3941f956c58",
            "patch": "@@ -577,65 +577,65 @@ def clean_custom_task(task_info):\n \n \n @overload\n-def pipeline(task: Literal[None], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> Pipeline: ...\n+def pipeline(task: Literal[None], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> Pipeline: ...\n @overload\n-def pipeline(task: Literal[\"audio-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> AudioClassificationPipeline: ...\n+def pipeline(task: Literal[\"audio-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> AudioClassificationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"automatic-speech-recognition\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> AutomaticSpeechRecognitionPipeline: ...\n+def pipeline(task: Literal[\"automatic-speech-recognition\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> AutomaticSpeechRecognitionPipeline: ...\n @overload\n-def pipeline(task: Literal[\"depth-estimation\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> DepthEstimationPipeline: ...\n+def pipeline(task: Literal[\"depth-estimation\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> DepthEstimationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"document-question-answering\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> DocumentQuestionAnsweringPipeline: ...\n+def pipeline(task: Literal[\"document-question-answering\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> DocumentQuestionAnsweringPipeline: ...\n @overload\n-def pipeline(task: Literal[\"feature-extraction\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> FeatureExtractionPipeline: ...\n+def pipeline(task: Literal[\"feature-extraction\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> FeatureExtractionPipeline: ...\n @overload\n-def pipeline(task: Literal[\"fill-mask\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> FillMaskPipeline: ...\n+def pipeline(task: Literal[\"fill-mask\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> FillMaskPipeline: ...\n @overload\n-def pipeline(task: Literal[\"image-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ImageClassificationPipeline: ...\n+def pipeline(task: Literal[\"image-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ImageClassificationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"image-feature-extraction\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ImageFeatureExtractionPipeline: ...\n+def pipeline(task: Literal[\"image-feature-extraction\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ImageFeatureExtractionPipeline: ...\n @overload\n-def pipeline(task: Literal[\"image-segmentation\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ImageSegmentationPipeline: ...\n+def pipeline(task: Literal[\"image-segmentation\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ImageSegmentationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"image-text-to-text\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ImageTextToTextPipeline: ...\n+def pipeline(task: Literal[\"image-text-to-text\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ImageTextToTextPipeline: ...\n @overload\n-def pipeline(task: Literal[\"image-to-image\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ImageToImagePipeline: ...\n+def pipeline(task: Literal[\"image-to-image\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ImageToImagePipeline: ...\n @overload\n-def pipeline(task: Literal[\"image-to-text\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ImageToTextPipeline: ...\n+def pipeline(task: Literal[\"image-to-text\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ImageToTextPipeline: ...\n @overload\n-def pipeline(task: Literal[\"mask-generation\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> MaskGenerationPipeline: ...\n+def pipeline(task: Literal[\"mask-generation\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> MaskGenerationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"object-detection\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ObjectDetectionPipeline: ...\n+def pipeline(task: Literal[\"object-detection\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ObjectDetectionPipeline: ...\n @overload\n-def pipeline(task: Literal[\"question-answering\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> QuestionAnsweringPipeline: ...\n+def pipeline(task: Literal[\"question-answering\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> QuestionAnsweringPipeline: ...\n @overload\n-def pipeline(task: Literal[\"summarization\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> SummarizationPipeline: ...\n+def pipeline(task: Literal[\"summarization\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> SummarizationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"table-question-answering\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> TableQuestionAnsweringPipeline: ...\n+def pipeline(task: Literal[\"table-question-answering\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> TableQuestionAnsweringPipeline: ...\n @overload\n-def pipeline(task: Literal[\"text-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> TextClassificationPipeline: ...\n+def pipeline(task: Literal[\"text-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> TextClassificationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"text-generation\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> TextGenerationPipeline: ...\n+def pipeline(task: Literal[\"text-generation\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> TextGenerationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"text-to-audio\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> TextToAudioPipeline: ...\n+def pipeline(task: Literal[\"text-to-audio\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> TextToAudioPipeline: ...\n @overload\n-def pipeline(task: Literal[\"text2text-generation\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> Text2TextGenerationPipeline: ...\n+def pipeline(task: Literal[\"text2text-generation\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> Text2TextGenerationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"token-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> TokenClassificationPipeline: ...\n+def pipeline(task: Literal[\"token-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> TokenClassificationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"translation\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> TranslationPipeline: ...\n+def pipeline(task: Literal[\"translation\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> TranslationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"video-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> VideoClassificationPipeline: ...\n+def pipeline(task: Literal[\"video-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> VideoClassificationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"visual-question-answering\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> VisualQuestionAnsweringPipeline: ...\n+def pipeline(task: Literal[\"visual-question-answering\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> VisualQuestionAnsweringPipeline: ...\n @overload\n-def pipeline(task: Literal[\"zero-shot-audio-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ZeroShotAudioClassificationPipeline: ...\n+def pipeline(task: Literal[\"zero-shot-audio-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ZeroShotAudioClassificationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"zero-shot-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ZeroShotClassificationPipeline: ...\n+def pipeline(task: Literal[\"zero-shot-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ZeroShotClassificationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"zero-shot-image-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ZeroShotImageClassificationPipeline: ...\n+def pipeline(task: Literal[\"zero-shot-image-classification\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ZeroShotImageClassificationPipeline: ...\n @overload\n-def pipeline(task: Literal[\"zero-shot-object-detection\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None, trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ZeroShotObjectDetectionPipeline: ...\n+def pipeline(task: Literal[\"zero-shot-object-detection\"], model: Optional[Union[str, \"PreTrainedModel\", \"TFPreTrainedModel\"]] = None, config: Optional[Union[str, PretrainedConfig]] = None, tokenizer: Optional[Union[str, PreTrainedTokenizer, \"PreTrainedTokenizerFast\"]] = None, feature_extractor: Optional[Union[str, PreTrainedFeatureExtractor]] = None, image_processor: Optional[Union[str, BaseImageProcessor]] = None, processor: Optional[Union[str, ProcessorMixin]] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, token: Optional[Union[str, bool]] = None, device: Optional[Union[int, str, \"torch.device\"]] = None, device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None, torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\", trust_remote_code: Optional[bool] = None, model_kwargs: Optional[dict[str, Any]] = None, pipeline_class: Optional[Any] = None, **kwargs: Any) -> ZeroShotObjectDetectionPipeline: ...\n \n #                ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨ðŸš¨\n #                       The part of the file above was automatically generated from the code.\n@@ -658,7 +658,7 @@ def pipeline(\n     token: Optional[Union[str, bool]] = None,\n     device: Optional[Union[int, str, \"torch.device\"]] = None,\n     device_map: Optional[Union[str, dict[str, Union[int, str]]]] = None,\n-    torch_dtype: Optional[Union[str, \"torch.dtype\"]] = None,\n+    torch_dtype: Optional[Union[str, \"torch.dtype\"]] = \"auto\",\n     trust_remote_code: Optional[bool] = None,\n     model_kwargs: Optional[dict[str, Any]] = None,\n     pipeline_class: Optional[Any] = None,"
        },
        {
            "sha": "8665519263728a3362b5914f67a33908fee0c897",
            "filename": "src/transformers/pipelines/base.py",
            "status": "modified",
            "additions": 30,
            "deletions": 2,
            "changes": 32,
            "blob_url": "https://github.com/huggingface/transformers/blob/2e4c045540c3bd1eed226babd20af3941f956c58/src%2Ftransformers%2Fpipelines%2Fbase.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2e4c045540c3bd1eed226babd20af3941f956c58/src%2Ftransformers%2Fpipelines%2Fbase.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fbase.py?ref=2e4c045540c3bd1eed226babd20af3941f956c58",
            "patch": "@@ -294,8 +294,35 @@ def infer_framework_load_model(\n                     model = model.eval()\n                 # Stop loading on the first successful load.\n                 break\n-            except (OSError, ValueError):\n-                all_traceback[model_class.__name__] = traceback.format_exc()\n+            except (OSError, ValueError, TypeError, RuntimeError):\n+                # `from_pretrained` may raise a `TypeError` or `RuntimeError` when the requested `torch_dtype`\n+                # is not supported on the execution device (e.g. bf16 on a consumer GPU). We capture those so\n+                # we can transparently retry the load in float32 before surfacing an error to the user.\n+                fallback_tried = False\n+                if is_torch_available() and (\"torch_dtype\" in kwargs):\n+                    import torch  # local import to avoid unnecessarily importing torch for TF/JAX users\n+\n+                    fallback_tried = True\n+                    fp32_kwargs = kwargs.copy()\n+                    fp32_kwargs[\"torch_dtype\"] = torch.float32\n+\n+                    try:\n+                        model = model_class.from_pretrained(model, **fp32_kwargs)\n+                        if hasattr(model, \"eval\"):\n+                            model = model.eval()\n+                        logger.warning(\n+                            \"Falling back to torch.float32 because loading with the original dtype failed on the\"\n+                            \" target device.\"\n+                        )\n+                        break\n+                    except Exception:\n+                        # If it still fails, capture the traceback and continue to the next class.\n+                        all_traceback[model_class.__name__] = traceback.format_exc()\n+                        continue\n+\n+                # If no fallback was attempted or it also failed, record the original traceback.\n+                if not fallback_tried:\n+                    all_traceback[model_class.__name__] = traceback.format_exc()\n                 continue\n \n         if isinstance(model, str):\n@@ -1011,6 +1038,7 @@ def __init__(\n         logger.warning(f\"Device set to use {self.device}\")\n \n         self.binary_output = binary_output\n+\n         # We shouldn't call `model.to()` for models loaded with accelerate as well as the case that model is already on device\n         if (\n             self.framework == \"pt\""
        }
    ],
    "stats": {
        "total": 94,
        "additions": 61,
        "deletions": 33
    }
}