{
    "author": "ydshieh",
    "message": "Skip some export tests on torch 2.7 (#38677)\n\n* skip\n\n* fix\n\n* better check\n\n* Update import_utils.py\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>\nCo-authored-by: Cyril Vallez <cyril.vallez@gmail.com>",
    "sha": "89c46b648d82b670cc7286a25fa64d2d92770418",
    "files": [
        {
            "sha": "a9c14bd5bb1e90d501088c4cb7ead58c8758ef9b",
            "filename": "src/transformers/utils/import_utils.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/89c46b648d82b670cc7286a25fa64d2d92770418/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/89c46b648d82b670cc7286a25fa64d2d92770418/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fimport_utils.py?ref=89c46b648d82b670cc7286a25fa64d2d92770418",
            "patch": "@@ -393,6 +393,13 @@ def get_torch_version():\n     return _torch_version\n \n \n+def get_torch_major_and_minor_version() -> str:\n+    if _torch_version == \"N/A\":\n+        return \"N/A\"\n+    parsed_version = version.parse(_torch_version)\n+    return str(parsed_version.major) + \".\" + str(parsed_version.minor)\n+\n+\n def is_torch_sdpa_available():\n     if not is_torch_available():\n         return False"
        },
        {
            "sha": "93a24c672898b063050416c868122a8b29bd89e8",
            "filename": "tests/models/depth_anything/test_modeling_depth_anything.py",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Fmodels%2Fdepth_anything%2Ftest_modeling_depth_anything.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Fmodels%2Fdepth_anything%2Ftest_modeling_depth_anything.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdepth_anything%2Ftest_modeling_depth_anything.py?ref=89c46b648d82b670cc7286a25fa64d2d92770418",
            "patch": "@@ -19,6 +19,7 @@\n from transformers.file_utils import is_torch_available, is_vision_available\n from transformers.pytorch_utils import is_torch_greater_or_equal_than_2_4\n from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n+from transformers.utils.import_utils import get_torch_major_and_minor_version\n \n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n@@ -146,6 +147,7 @@ class DepthAnythingModelTest(ModelTesterMixin, PipelineTesterMixin, unittest.Tes\n     test_resize_embeddings = False\n     test_head_masking = False\n     test_torch_exportable = True\n+    test_torch_exportable_strictly = not get_torch_major_and_minor_version() == \"2.7\"\n \n     def setUp(self):\n         self.model_tester = DepthAnythingModelTester(self)\n@@ -285,8 +287,11 @@ def test_inference(self):\n         torch.testing.assert_close(predicted_depth[0, :3, :3], expected_slice, rtol=1e-4, atol=1e-4)\n \n     def test_export(self):\n-        for strict in [True, False]:\n+        for strict in [False, True]:\n             with self.subTest(strict=strict):\n+                if strict and get_torch_major_and_minor_version() == \"2.7\":\n+                    self.skipTest(reason=\"`strict=True` is currently failing with torch 2.7.\")\n+\n                 if not is_torch_greater_or_equal_than_2_4:\n                     self.skipTest(reason=\"This test requires torch >= 2.4 to run.\")\n                 model = ("
        },
        {
            "sha": "5ef6c11c3758acae468868fabebba27f9781b1db",
            "filename": "tests/models/dpt/test_modeling_dpt_auto_backbone.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_auto_backbone.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_auto_backbone.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_auto_backbone.py?ref=89c46b648d82b670cc7286a25fa64d2d92770418",
            "patch": "@@ -18,6 +18,7 @@\n from transformers import Dinov2Config, DPTConfig\n from transformers.file_utils import is_torch_available, is_vision_available\n from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n+from transformers.utils.import_utils import get_torch_major_and_minor_version\n \n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n@@ -140,6 +141,7 @@ class DPTModelTest(ModelTesterMixin, PipelineTesterMixin, unittest.TestCase):\n     test_resize_embeddings = False\n     test_head_masking = False\n     test_torch_exportable = True\n+    test_torch_exportable_strictly = not get_torch_major_and_minor_version() == \"2.7\"\n \n     def setUp(self):\n         self.model_tester = DPTModelTester(self)"
        },
        {
            "sha": "697557b6ac018a3cbdfd6c8c9b57fbdcae7f33ca",
            "filename": "tests/models/prompt_depth_anything/test_modeling_prompt_depth_anything.py",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Fmodels%2Fprompt_depth_anything%2Ftest_modeling_prompt_depth_anything.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Fmodels%2Fprompt_depth_anything%2Ftest_modeling_prompt_depth_anything.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fprompt_depth_anything%2Ftest_modeling_prompt_depth_anything.py?ref=89c46b648d82b670cc7286a25fa64d2d92770418",
            "patch": "@@ -21,6 +21,7 @@\n from transformers.file_utils import is_torch_available, is_vision_available\n from transformers.pytorch_utils import is_torch_greater_or_equal_than_2_4\n from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n+from transformers.utils.import_utils import get_torch_major_and_minor_version\n \n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n@@ -284,7 +285,10 @@ def test_inference(self):\n         self.assertTrue(torch.allclose(predicted_depth[0, :3, :3], expected_slice, atol=1e-3))\n \n     def test_export(self):\n-        for strict in [True, False]:\n+        for strict in [False, True]:\n+            if strict and get_torch_major_and_minor_version() == \"2.7\":\n+                self.skipTest(reason=\"`strict=True` is currently failing with torch 2.7.\")\n+\n             with self.subTest(strict=strict):\n                 if not is_torch_greater_or_equal_than_2_4:\n                     self.skipTest(reason=\"This test requires torch >= 2.4 to run.\")"
        },
        {
            "sha": "fc62b3232529f0c43fad6a4524786356120e341e",
            "filename": "tests/models/upernet/test_modeling_upernet.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Fmodels%2Fupernet%2Ftest_modeling_upernet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Fmodels%2Fupernet%2Ftest_modeling_upernet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fupernet%2Ftest_modeling_upernet.py?ref=89c46b648d82b670cc7286a25fa64d2d92770418",
            "patch": "@@ -27,6 +27,7 @@\n     torch_device,\n )\n from transformers.utils import is_torch_available, is_vision_available\n+from transformers.utils.import_utils import get_torch_major_and_minor_version\n \n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n@@ -157,6 +158,7 @@ class UperNetModelTest(ModelTesterMixin, PipelineTesterMixin, unittest.TestCase)\n     test_torchscript = False\n     has_attentions = False\n     test_torch_exportable = True\n+    test_torch_exportable_strictly = not get_torch_major_and_minor_version() == \"2.7\"\n \n     def setUp(self):\n         self.model_tester = UperNetModelTester(self)"
        },
        {
            "sha": "3e6ef0bb4813cc81199a6c3888f4616a337644cc",
            "filename": "tests/models/vitmatte/test_modeling_vitmatte.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Fmodels%2Fvitmatte%2Ftest_modeling_vitmatte.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Fmodels%2Fvitmatte%2Ftest_modeling_vitmatte.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvitmatte%2Ftest_modeling_vitmatte.py?ref=89c46b648d82b670cc7286a25fa64d2d92770418",
            "patch": "@@ -25,6 +25,7 @@\n     torch_device,\n )\n from transformers.utils import is_torch_available, is_vision_available\n+from transformers.utils.import_utils import get_torch_major_and_minor_version\n \n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import ModelTesterMixin, floats_tensor\n@@ -143,6 +144,7 @@ class VitMatteModelTest(ModelTesterMixin, PipelineTesterMixin, unittest.TestCase\n     test_resize_embeddings = False\n     test_head_masking = False\n     test_torch_exportable = True\n+    test_torch_exportable_strictly = not get_torch_major_and_minor_version() == \"2.7\"\n \n     def setUp(self):\n         self.model_tester = VitMatteModelTester(self)"
        },
        {
            "sha": "6f4ac621327aeb92a555feefce690cca12addac6",
            "filename": "tests/models/vitpose/test_modeling_vitpose.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Fmodels%2Fvitpose%2Ftest_modeling_vitpose.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Fmodels%2Fvitpose%2Ftest_modeling_vitpose.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvitpose%2Ftest_modeling_vitpose.py?ref=89c46b648d82b670cc7286a25fa64d2d92770418",
            "patch": "@@ -21,6 +21,7 @@\n from transformers import VitPoseBackboneConfig, VitPoseConfig\n from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n from transformers.utils import cached_property, is_torch_available, is_vision_available\n+from transformers.utils.import_utils import get_torch_major_and_minor_version\n \n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n@@ -154,6 +155,7 @@ class VitPoseModelTest(ModelTesterMixin, unittest.TestCase):\n     test_resize_embeddings = False\n     test_head_masking = False\n     test_torch_exportable = True\n+    test_torch_exportable_strictly = not get_torch_major_and_minor_version() == \"2.7\"\n \n     def setUp(self):\n         self.model_tester = VitPoseModelTester(self)"
        },
        {
            "sha": "7a19bc7b5b14dc3e6fa6630e61671cf1485171e4",
            "filename": "tests/models/zoedepth/test_modeling_zoedepth.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Fmodels%2Fzoedepth%2Ftest_modeling_zoedepth.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Fmodels%2Fzoedepth%2Ftest_modeling_zoedepth.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fzoedepth%2Ftest_modeling_zoedepth.py?ref=89c46b648d82b670cc7286a25fa64d2d92770418",
            "patch": "@@ -20,6 +20,7 @@\n from transformers import Dinov2Config, ZoeDepthConfig\n from transformers.file_utils import is_torch_available, is_vision_available\n from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n+from transformers.utils.import_utils import get_torch_major_and_minor_version\n \n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n@@ -146,7 +147,8 @@ class ZoeDepthModelTest(ModelTesterMixin, PipelineTesterMixin, unittest.TestCase\n     test_pruning = False\n     test_resize_embeddings = False\n     test_head_masking = False\n-    test_torch_exportable = True\n+    # `strict=True/False` are both failing with torch 2.7, see #38677\n+    test_torch_exportable = not get_torch_major_and_minor_version() == \"2.7\"\n \n     def setUp(self):\n         self.model_tester = ZoeDepthModelTester(self)"
        },
        {
            "sha": "6ebf91d3f504a9f5385e72bf53439b31eb5c8421",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/89c46b648d82b670cc7286a25fa64d2d92770418/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=89c46b648d82b670cc7286a25fa64d2d92770418",
            "patch": "@@ -4569,10 +4569,7 @@ def recursively_check(eager_outputs, exported_outputs):\n \n                 # Export model\n                 exported_model = torch.export.export(\n-                    model,\n-                    args=(),\n-                    kwargs=inputs_dict,\n-                    strict=True,\n+                    model, args=(), kwargs=inputs_dict, strict=getattr(self, \"test_torch_exportable_strictly\", True)\n                 )\n \n                 # Run exported model and eager model"
        }
    ],
    "stats": {
        "total": 37,
        "additions": 30,
        "deletions": 7
    }
}