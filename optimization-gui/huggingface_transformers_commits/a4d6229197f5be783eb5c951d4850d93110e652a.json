{
    "author": "eustlb",
    "message": "fix concat order (#42946)",
    "sha": "a4d6229197f5be783eb5c951d4850d93110e652a",
    "files": [
        {
            "sha": "9ad722a3073987d039ddeb5c095d91ffb00343ca",
            "filename": "src/transformers/models/pe_audio_video/modeling_pe_audio_video.py",
            "status": "modified",
            "additions": 16,
            "deletions": 8,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/a4d6229197f5be783eb5c951d4850d93110e652a/src%2Ftransformers%2Fmodels%2Fpe_audio_video%2Fmodeling_pe_audio_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a4d6229197f5be783eb5c951d4850d93110e652a/src%2Ftransformers%2Fmodels%2Fpe_audio_video%2Fmodeling_pe_audio_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpe_audio_video%2Fmodeling_pe_audio_video.py?ref=a4d6229197f5be783eb5c951d4850d93110e652a",
            "patch": "@@ -830,24 +830,32 @@ def forward(\n             raise ValueError(\"At least two of input_ids, pixel_values_videos, or input_values must be provided\")\n \n         if pixel_values_videos is None:\n-            audio_outputs = self.audio_model(\n+            outputs = self.audio_model(\n                 input_ids=input_ids,\n                 input_values=input_values,\n                 attention_mask=attention_mask,\n                 padding_mask=padding_mask,\n                 return_dict=True,\n             )\n-            return PeAudioVideoOutput(**audio_outputs)\n+            audio_plus_text_embeds = torch.cat(\n+                [outputs.audio_outputs.pooler_output, outputs.text_outputs.hidden_states[-1][:, 0]], dim=-1\n+            )\n+            audio_plus_text_embeds = self.audio_plus_text_head(audio_plus_text_embeds)\n+            return PeAudioVideoOutput(audio_plus_text_embeds=audio_plus_text_embeds, **outputs)\n \n         if input_values is None:\n-            video_outputs = self.video_model(\n+            outputs = self.video_model(\n                 input_ids=input_ids,\n                 pixel_values_videos=pixel_values_videos,\n                 attention_mask=attention_mask,\n                 padding_mask_videos=padding_mask_videos,\n                 return_dict=True,\n             )\n-            return PeAudioVideoOutput(**video_outputs)\n+            video_plus_text_embeds = torch.cat(\n+                [outputs.video_outputs.pooler_output, outputs.text_outputs.hidden_states[-1][:, 0]], dim=-1\n+            )\n+            video_plus_text_embeds = self.video_plus_text_head(video_plus_text_embeds)\n+            return PeAudioVideoOutput(video_plus_text_embeds=video_plus_text_embeds, **outputs)\n \n         audio_video_outputs = self.audio_video_encoder(\n             input_values=input_values,\n@@ -880,8 +888,8 @@ def forward(\n         kwargs[\"output_hidden_states\"] = True\n         text_outputs = self.text_model(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n         text_embeds = text_outputs.hidden_states[-1][:, 0]\n-        audio_plus_text_embeds = torch.cat([text_embeds, audio_video_outputs.audio_model_output.pooler_output], dim=-1)\n-        video_plus_text_embeds = torch.cat([text_embeds, audio_video_outputs.video_model_output.pooler_output], dim=-1)\n+        audio_plus_text_embeds = torch.cat([audio_video_outputs.audio_model_output.pooler_output, text_embeds], dim=-1)\n+        video_plus_text_embeds = torch.cat([audio_video_outputs.video_model_output.pooler_output, text_embeds], dim=-1)\n \n         text_audio_embeds = self.audio_model.text_audio_head(text_embeds)\n         text_video_embeds = self.video_model.text_video_head(text_embeds)\n@@ -893,8 +901,8 @@ def forward(\n         logits_video_text = video_embeds @ text_video_embeds.T\n         logits_audio_video_text = audio_video_embeds @ text_audio_video_embeds.T\n \n-        logits_audio_plus_text_video = audio_plus_text_embeds @ video_embeds.T  # TODO: check this\n-        logits_video_plus_text_audio = video_plus_text_embeds @ audio_embeds.T  # TODO: check this\n+        logits_audio_plus_text_video = audio_plus_text_embeds @ video_embeds.T\n+        logits_video_plus_text_audio = video_plus_text_embeds @ audio_embeds.T\n \n         logits_audio_text = (\n             logits_audio_text * self.audio_model.text_audio_logit_scale + self.audio_model.text_audio_logit_bias"
        },
        {
            "sha": "75881b0c7c0417c31102d6958f14b08ddcd8c52b",
            "filename": "src/transformers/models/pe_audio_video/modular_pe_audio_video.py",
            "status": "modified",
            "additions": 16,
            "deletions": 8,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/a4d6229197f5be783eb5c951d4850d93110e652a/src%2Ftransformers%2Fmodels%2Fpe_audio_video%2Fmodular_pe_audio_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a4d6229197f5be783eb5c951d4850d93110e652a/src%2Ftransformers%2Fmodels%2Fpe_audio_video%2Fmodular_pe_audio_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpe_audio_video%2Fmodular_pe_audio_video.py?ref=a4d6229197f5be783eb5c951d4850d93110e652a",
            "patch": "@@ -619,24 +619,32 @@ def forward(\n             raise ValueError(\"At least two of input_ids, pixel_values_videos, or input_values must be provided\")\n \n         if pixel_values_videos is None:\n-            audio_outputs = self.audio_model(\n+            outputs = self.audio_model(\n                 input_ids=input_ids,\n                 input_values=input_values,\n                 attention_mask=attention_mask,\n                 padding_mask=padding_mask,\n                 return_dict=True,\n             )\n-            return PeAudioVideoOutput(**audio_outputs)\n+            audio_plus_text_embeds = torch.cat(\n+                [outputs.audio_outputs.pooler_output, outputs.text_outputs.hidden_states[-1][:, 0]], dim=-1\n+            )\n+            audio_plus_text_embeds = self.audio_plus_text_head(audio_plus_text_embeds)\n+            return PeAudioVideoOutput(audio_plus_text_embeds=audio_plus_text_embeds, **outputs)\n \n         if input_values is None:\n-            video_outputs = self.video_model(\n+            outputs = self.video_model(\n                 input_ids=input_ids,\n                 pixel_values_videos=pixel_values_videos,\n                 attention_mask=attention_mask,\n                 padding_mask_videos=padding_mask_videos,\n                 return_dict=True,\n             )\n-            return PeAudioVideoOutput(**video_outputs)\n+            video_plus_text_embeds = torch.cat(\n+                [outputs.video_outputs.pooler_output, outputs.text_outputs.hidden_states[-1][:, 0]], dim=-1\n+            )\n+            video_plus_text_embeds = self.video_plus_text_head(video_plus_text_embeds)\n+            return PeAudioVideoOutput(video_plus_text_embeds=video_plus_text_embeds, **outputs)\n \n         audio_video_outputs = self.audio_video_encoder(\n             input_values=input_values,\n@@ -669,8 +677,8 @@ def forward(\n         kwargs[\"output_hidden_states\"] = True\n         text_outputs = self.text_model(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n         text_embeds = text_outputs.hidden_states[-1][:, 0]\n-        audio_plus_text_embeds = torch.cat([text_embeds, audio_video_outputs.audio_model_output.pooler_output], dim=-1)\n-        video_plus_text_embeds = torch.cat([text_embeds, audio_video_outputs.video_model_output.pooler_output], dim=-1)\n+        audio_plus_text_embeds = torch.cat([audio_video_outputs.audio_model_output.pooler_output, text_embeds], dim=-1)\n+        video_plus_text_embeds = torch.cat([audio_video_outputs.video_model_output.pooler_output, text_embeds], dim=-1)\n \n         text_audio_embeds = self.audio_model.text_audio_head(text_embeds)\n         text_video_embeds = self.video_model.text_video_head(text_embeds)\n@@ -682,8 +690,8 @@ def forward(\n         logits_video_text = video_embeds @ text_video_embeds.T\n         logits_audio_video_text = audio_video_embeds @ text_audio_video_embeds.T\n \n-        logits_audio_plus_text_video = audio_plus_text_embeds @ video_embeds.T  # TODO: check this\n-        logits_video_plus_text_audio = video_plus_text_embeds @ audio_embeds.T  # TODO: check this\n+        logits_audio_plus_text_video = audio_plus_text_embeds @ video_embeds.T\n+        logits_video_plus_text_audio = video_plus_text_embeds @ audio_embeds.T\n \n         logits_audio_text = (\n             logits_audio_text * self.audio_model.text_audio_logit_scale + self.audio_model.text_audio_logit_bias"
        }
    ],
    "stats": {
        "total": 48,
        "additions": 32,
        "deletions": 16
    }
}