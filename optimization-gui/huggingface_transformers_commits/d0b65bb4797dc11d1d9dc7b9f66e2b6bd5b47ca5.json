{
    "author": "huismiling",
    "message": "[MLU] Fix FA2 check error, remove deepspeed-mlu deps. (#36159)\n\n* add Cambricon MLUs support\n\n* fix mlu device rng state\n\n* up for quality check\n\n* up mlu to support fp16\n\n* fix mlu device dependency error\n\n* fix mlu device dependency error\n\n* enable mlu device for bf16\n\n* fix mlu device memory tracker\n\n* Cambricon support SDPA and flash_attn\n\n* MLU devices : Checks if `mlu` is available via an `cndev-based` check which won't trigger the drivers and leave mlu\n\n* Fix mlu FA2 check. Remove deepspeed-mlu check. add mlu tests support.\n\n* fix testing errors.\n\n* Merge branch 'hf/main' into main\n\n* fix get_device_count error.\n\n* fix mlu testing utils.\n\n* fix code quality and style.\n\n* switch to @require_torch_multi_accelerator",
    "sha": "d0b65bb4797dc11d1d9dc7b9f66e2b6bd5b47ca5",
    "files": [
        {
            "sha": "696e284b748c7329e92ed29ead782a1ba4986b0e",
            "filename": "src/transformers/integrations/deepspeed.py",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0b65bb4797dc11d1d9dc7b9f66e2b6bd5b47ca5/src%2Ftransformers%2Fintegrations%2Fdeepspeed.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0b65bb4797dc11d1d9dc7b9f66e2b6bd5b47ca5/src%2Ftransformers%2Fintegrations%2Fdeepspeed.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Fdeepspeed.py?ref=d0b65bb4797dc11d1d9dc7b9f66e2b6bd5b47ca5",
            "patch": "@@ -22,7 +22,7 @@\n from functools import partialmethod\n \n from ..dependency_versions_check import dep_version_check\n-from ..utils import is_accelerate_available, is_torch_available, is_torch_mlu_available, logging\n+from ..utils import is_accelerate_available, is_torch_available, logging\n \n \n if is_torch_available():\n@@ -40,9 +40,6 @@ def is_deepspeed_available():\n     # AND checking it has an author field in the metadata that is HuggingFace.\n     if package_exists:\n         try:\n-            if is_torch_mlu_available():\n-                _ = importlib_metadata.metadata(\"deepspeed-mlu\")\n-                return True\n             _ = importlib_metadata.metadata(\"deepspeed\")\n             return True\n         except importlib_metadata.PackageNotFoundError:"
        },
        {
            "sha": "c279ae391c1a3199175f1f7b5d8eed4638bf80ed",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0b65bb4797dc11d1d9dc7b9f66e2b6bd5b47ca5/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0b65bb4797dc11d1d9dc7b9f66e2b6bd5b47ca5/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=d0b65bb4797dc11d1d9dc7b9f66e2b6bd5b47ca5",
            "patch": "@@ -103,6 +103,7 @@\n     is_safetensors_available,\n     is_torch_flex_attn_available,\n     is_torch_greater_or_equal,\n+    is_torch_mlu_available,\n     is_torch_npu_available,\n     is_torch_sdpa_available,\n     is_torch_xla_available,\n@@ -2323,12 +2324,17 @@ def _check_and_enable_flash_attn_2(\n \n         # The check `torch.empty(0).device.type != \"cuda\"` is needed as the model may be initialized after `torch.set_default_device` has been called,\n         # or the model may be initialized under the context manager `with torch.device(\"cuda\"):`.\n-        if check_device_map and device_map is None and torch.empty(0).device.type != \"cuda\":\n+        if check_device_map and device_map is None and torch.empty(0).device.type not in [\"cuda\", \"mlu\"]:\n             if torch.cuda.is_available():\n                 logger.warning_once(\n                     \"You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU\"\n                     \" after initializing it on CPU with `model.to('cuda')`.\"\n                 )\n+            elif is_torch_mlu_available():\n+                logger.warning_once(\n+                    \"You are attempting to use Flash Attention 2.0 with a model not initialized on MLU. Make sure to move the model to MLU\"\n+                    \" after initializing it on CPU with `model.to('mlu')`.\"\n+                )\n             else:\n                 raise ValueError(\n                     \"You are attempting to use Flash Attention 2.0 with a model not initialized on GPU and with no GPU available. \""
        },
        {
            "sha": "8a92a9211ce5acaa7d6ff480fe0163cf8a1142a1",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 27,
            "deletions": 3,
            "changes": 30,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0b65bb4797dc11d1d9dc7b9f66e2b6bd5b47ca5/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0b65bb4797dc11d1d9dc7b9f66e2b6bd5b47ca5/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=d0b65bb4797dc11d1d9dc7b9f66e2b6bd5b47ca5",
            "patch": "@@ -144,6 +144,7 @@\n     is_torch_fp16_available_on_device,\n     is_torch_greater_or_equal,\n     is_torch_hpu_available,\n+    is_torch_mlu_available,\n     is_torch_neuroncore_available,\n     is_torch_npu_available,\n     is_torch_sdpa_available,\n@@ -940,6 +941,10 @@ def require_torch_multi_hpu(test_case):\n             raise ValueError(\n                 f\"TRANSFORMERS_TEST_DEVICE={torch_device}, but NPU is unavailable. Please double-check your testing environment.\"\n             )\n+        if torch_device == \"mlu\" and not is_torch_mlu_available():\n+            raise ValueError(\n+                f\"TRANSFORMERS_TEST_DEVICE={torch_device}, but MLU is unavailable. Please double-check your testing environment.\"\n+            )\n         if torch_device == \"hpu\" and not is_torch_hpu_available():\n             raise ValueError(\n                 f\"TRANSFORMERS_TEST_DEVICE={torch_device}, but HPU is unavailable. Please double-check your testing environment.\"\n@@ -956,6 +961,8 @@ def require_torch_multi_hpu(test_case):\n         torch_device = \"cuda\"\n     elif _run_third_party_device_tests and is_torch_npu_available():\n         torch_device = \"npu\"\n+    elif _run_third_party_device_tests and is_torch_mlu_available():\n+        torch_device = \"mlu\"\n     elif _run_third_party_device_tests and is_torch_hpu_available():\n         torch_device = \"hpu\"\n     elif _run_third_party_device_tests and is_torch_xpu_available():\n@@ -2927,9 +2934,21 @@ def _device_agnostic_dispatch(device: str, dispatch_table: dict[str, Callable],\n if is_torch_available():\n     # Mappings from device names to callable functions to support device agnostic\n     # testing.\n-    BACKEND_MANUAL_SEED = {\"cuda\": torch.cuda.manual_seed, \"cpu\": torch.manual_seed, \"default\": torch.manual_seed}\n-    BACKEND_EMPTY_CACHE = {\"cuda\": torch.cuda.empty_cache, \"cpu\": None, \"default\": None}\n-    BACKEND_DEVICE_COUNT = {\"cuda\": torch.cuda.device_count, \"cpu\": lambda: 0, \"default\": lambda: 1}\n+    BACKEND_MANUAL_SEED = {\n+        \"cuda\": torch.cuda.manual_seed,\n+        \"cpu\": torch.manual_seed,\n+        \"default\": torch.manual_seed,\n+    }\n+    BACKEND_EMPTY_CACHE = {\n+        \"cuda\": torch.cuda.empty_cache,\n+        \"cpu\": None,\n+        \"default\": None,\n+    }\n+    BACKEND_DEVICE_COUNT = {\n+        \"cuda\": torch.cuda.device_count,\n+        \"cpu\": lambda: 0,\n+        \"default\": lambda: 1,\n+    }\n else:\n     BACKEND_MANUAL_SEED = {\"default\": None}\n     BACKEND_EMPTY_CACHE = {\"default\": None}\n@@ -2939,6 +2958,11 @@ def _device_agnostic_dispatch(device: str, dispatch_table: dict[str, Callable],\n     BACKEND_MANUAL_SEED[\"hpu\"] = torch.hpu.manual_seed\n     BACKEND_DEVICE_COUNT[\"hpu\"] = torch.hpu.device_count\n \n+if is_torch_mlu_available():\n+    BACKEND_EMPTY_CACHE[\"mlu\"] = torch.mlu.empty_cache\n+    BACKEND_MANUAL_SEED[\"mlu\"] = torch.mlu.manual_seed\n+    BACKEND_DEVICE_COUNT[\"mlu\"] = torch.mlu.device_count\n+\n if is_torch_npu_available():\n     BACKEND_EMPTY_CACHE[\"npu\"] = torch.npu.empty_cache\n     BACKEND_MANUAL_SEED[\"npu\"] = torch.npu.manual_seed"
        },
        {
            "sha": "2f4c77078f8c9963161a1f29f9e5f167a8c69c15",
            "filename": "tests/generation/test_fsdp.py",
            "status": "modified",
            "additions": 28,
            "deletions": 10,
            "changes": 38,
            "blob_url": "https://github.com/huggingface/transformers/blob/d0b65bb4797dc11d1d9dc7b9f66e2b6bd5b47ca5/tests%2Fgeneration%2Ftest_fsdp.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d0b65bb4797dc11d1d9dc7b9f66e2b6bd5b47ca5/tests%2Fgeneration%2Ftest_fsdp.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fgeneration%2Ftest_fsdp.py?ref=d0b65bb4797dc11d1d9dc7b9f66e2b6bd5b47ca5",
            "patch": "@@ -15,12 +15,12 @@\n import argparse\n from typing import Any, Callable\n \n-from transformers import is_torch_available\n+from transformers import is_torch_available, is_torch_mlu_available\n from transformers.testing_utils import (\n     TestCasePlus,\n     execute_subprocess_async,\n     get_torch_dist_unique_port,\n-    require_torch_multi_gpu,\n+    require_torch_multi_accelerator,\n )\n \n \n@@ -46,7 +46,11 @@ def manage_process_group(func: Callable[..., Any]) -> Callable[..., Any]:\n         \"\"\"Manage the creation and destruction of the distributed process group for the wrapped function.\"\"\"\n \n         def wrapped(*args: Any, **kwargs: Any) -> Any:\n-            torch.distributed.init_process_group(world_size=torch.cuda.device_count())\n+            if is_torch_mlu_available():\n+                device_count = torch.mlu.device_count()\n+            else:\n+                device_count = torch.cuda.device_count()\n+            torch.distributed.init_process_group(world_size=device_count)\n             try:\n                 return func(*args, **kwargs)\n             finally:\n@@ -56,7 +60,10 @@ def wrapped(*args: Any, **kwargs: Any) -> Any:\n \n     @manage_process_group\n     def fsdp_generate():\n-        torch.cuda.set_device(device := torch.device(rank := torch.distributed.get_rank()))\n+        if is_torch_mlu_available():\n+            torch.mlu.set_device(device := torch.device(rank := torch.distributed.get_rank()))\n+        else:\n+            torch.cuda.set_device(device := torch.device(rank := torch.distributed.get_rank()))\n \n         model = AutoModelForCausalLM.from_pretrained(\"hf-internal-testing/tiny-random-gpt2\").to(device)\n \n@@ -79,11 +86,14 @@ def fsdp_generate():\n \n     @manage_process_group\n     def fsdp2_generate():\n-        torch.cuda.set_device(device := torch.device(rank := torch.distributed.get_rank()))\n+        if is_torch_mlu_available():\n+            torch.mlu.set_device(device := torch.device(rank := torch.distributed.get_rank()))\n+        else:\n+            torch.cuda.set_device(device := torch.device(rank := torch.distributed.get_rank()))\n \n         model = AutoModelForCausalLM.from_pretrained(\"hf-internal-testing/tiny-random-gpt2\").to(device)\n \n-        mesh = init_device_mesh(\"cuda\", (torch.distributed.get_world_size(),))\n+        mesh = init_device_mesh(device.type, (torch.distributed.get_world_size(),))\n         for submodule in model.modules():\n             if isinstance(submodule, GPT2Block):\n                 fully_shard(submodule, mesh=mesh)\n@@ -102,9 +112,13 @@ def fsdp2_generate():\n \n \n class TestFSDPGeneration(TestCasePlus):\n-    @require_torch_multi_gpu\n+    @require_torch_multi_accelerator\n     def test_fsdp_generate(self):\n-        distributed_args = f\"\"\"--nproc_per_node={torch.cuda.device_count()}\n+        if is_torch_mlu_available():\n+            device_count = torch.mlu.device_count()\n+        else:\n+            device_count = torch.cuda.device_count()\n+        distributed_args = f\"\"\"--nproc_per_node={device_count}\n             --master_port={get_torch_dist_unique_port()}\n             {self.test_file_dir}/test_fsdp.py\n         \"\"\".split()\n@@ -113,9 +127,13 @@ def test_fsdp_generate(self):\n         execute_subprocess_async(cmd, env=self.get_env())\n         # successful return here == success - any errors would have caused an error in the sub-call\n \n-    @require_torch_multi_gpu\n+    @require_torch_multi_accelerator\n     def test_fsdp2_generate(self):\n-        distributed_args = f\"\"\"--nproc_per_node={torch.cuda.device_count()}\n+        if is_torch_mlu_available():\n+            device_count = torch.mlu.device_count()\n+        else:\n+            device_count = torch.cuda.device_count()\n+        distributed_args = f\"\"\"--nproc_per_node={device_count}\n             --master_port={get_torch_dist_unique_port()}\n             {self.test_file_dir}/test_fsdp.py\n         \"\"\".split()"
        }
    ],
    "stats": {
        "total": 81,
        "additions": 63,
        "deletions": 18
    }
}