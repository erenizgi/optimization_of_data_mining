{
    "author": "GeLee-Q",
    "message": "add self.head_dim for VisionAttention in Qwen2-VL (#33211)\n\n* add self.head_dim for VisionAttention in Qwen2-VL\r\n\r\n* add self.head_dim for VisionAttention in Qwen2-VL\r\n\r\n* fix ci\r\n\r\n* black the test_modeling_qwen2_vl.py\r\n\r\n* use ruff to format test_modeling_qwen2_vl.py\r\n\r\n* [run-slow] qwen2_vl\r\n\r\n* use tying for python3.8\r\n\r\n* fix the import format\r\n\r\n* use ruff to fix the ci error I001\r\n\r\n* [run-slow] qwen2_vl\r\n\r\n* remove unused import\r\n\r\n* commit for rebase\r\n\r\n* use ruff fix ci\r\n\r\n* [run-slow] qwen2_vl\r\n\r\n---------\r\n\r\nCo-authored-by: root <liji>",
    "sha": "2b183541060b88f693a301effcb2f838f0c12833",
    "files": [
        {
            "sha": "4bd85f06a4f952c002ec4ba7de0deb5fb4569d84",
            "filename": "tests/models/qwen2_vl/test_modeling_qwen2_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2b183541060b88f693a301effcb2f838f0c12833/tests%2Fmodels%2Fqwen2_vl%2Ftest_modeling_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2b183541060b88f693a301effcb2f838f0c12833/tests%2Fmodels%2Fqwen2_vl%2Ftest_modeling_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_vl%2Ftest_modeling_qwen2_vl.py?ref=2b183541060b88f693a301effcb2f838f0c12833",
            "patch": "@@ -164,7 +164,9 @@ def prepare_config_and_inputs_for_common(self):\n         attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=torch_device)\n         input_ids[:, torch.arange(vision_seqlen, device=torch_device) + 1] = self.image_token_id\n         labels = torch.zeros(\n-            (self.batch_size, self.seq_length - 1 + vision_seqlen), dtype=torch.long, device=torch_device\n+            (self.batch_size, self.seq_length - 1 + vision_seqlen),\n+            dtype=torch.long,\n+            device=torch_device,\n         )\n         patch_size = self.vision_config[\"patch_size\"]\n         inputs_dict = {"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 3,
        "deletions": 1
    }
}