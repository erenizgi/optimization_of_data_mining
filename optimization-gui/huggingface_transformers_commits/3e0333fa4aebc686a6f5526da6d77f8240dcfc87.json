{
    "author": "ydshieh",
    "message": "Update expected output values after #39885 (part 2) (#40015)\n\nupdate\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "3e0333fa4aebc686a6f5526da6d77f8240dcfc87",
    "files": [
        {
            "sha": "0f9d6ea3e469e0fe2244fc603c3b945b0e277054",
            "filename": "tests/models/dac/test_modeling_dac.py",
            "status": "modified",
            "additions": 225,
            "deletions": 341,
            "changes": 566,
            "blob_url": "https://github.com/huggingface/transformers/blob/3e0333fa4aebc686a6f5526da6d77f8240dcfc87/tests%2Fmodels%2Fdac%2Ftest_modeling_dac.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3e0333fa4aebc686a6f5526da6d77f8240dcfc87/tests%2Fmodels%2Fdac%2Ftest_modeling_dac.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdac%2Ftest_modeling_dac.py?ref=3e0333fa4aebc686a6f5526da6d77f8240dcfc87",
            "patch": "@@ -417,117 +417,82 @@ def compute_rmse(arr1, arr2):\n     \"dac_44khz\": torch.tensor([1, 1, 258560]),\n }\n EXPECTED_ENC_LOSS = {\n-    \"dac_16khz\": 24.889205932617188,\n-    \"dac_24khz\": 27.661380767822266,\n-    \"dac_44khz\": 23.87179183959961,\n+    \"dac_16khz\": 24.8767,\n+    \"dac_24khz\": 27.6831,\n+    \"dac_44khz\": 23.8870,\n }\n EXPECTED_QUANT_CODES = {\n-    \"dac_16khz\": torch.tensor([[[ 804,   25,  536,   52,   68,  867,  388,  653,  484,  706,  301,\n-        305,  752,   25,   40],\n-        [  77,  955,  134,  601,  431,  375,  967,   56,  684,  261,  871,\n-        552,  232,  341,  228],\n-        [ 355,  701,  172,  927,  617,  765,  790,  149,  117,  707,  511,\n-        226,  254,  883,  644],\n-        [ 184,   85,  828,   54,  211, 1007,  906,  253,  406, 1007,  302,\n-        577,  644,  330,  601],\n-        [ 763,  865,  586,  321,  116,  357,  911,  865,  234,  234,    6,\n-        630,    6,  174,  895],\n-        [ 454,  241,   67,  622,  487,  426,  749,  833,  639,  900,  372,\n-        481,  622,  418,  964],\n-        [ 203,  609,  730,  307,  961,  609,  318, 1011,  747,  949,  343,\n-        548,  657,  824,   21],\n-        [  82,   92,  692,   83,  131,  866,  483,  362,  596,  531,  853,\n-        121,  404,  512,  373],\n-        [1003,  260,  431,  460,  827,  927,   81,   76,  444,  298,  168,\n-        673,  466,  613,  383],\n-        [ 571,  203,  594,  394,  198,  560,  952,  437,  343,  992,  934,\n-        316,  497,  123,  305],\n-        [ 686,  715,  393,  635,  246,  716,  908,  384,   98,  873,   92,\n-        878,  592,  496,  104],\n-        [ 721,  502,  606,  204,  993,  428,  176,  395,  617,  323,  342,\n-        530,  226,    8,  600]]]).to(torch_device),\n-    \"dac_24khz\": torch.tensor([[[ 252,  851,  919,  204,  239,  360,   90,  103,  851,  876,  160,\n-        160,  103,  234,  665],\n-        [ 908,  658,  479,  556,  847,  265,  496,   32,  847,  773,  623,\n-        375,    9,  497,  117],\n-        [ 385,  278,  221,  778,  408,  330,  562,  215,   80,   84,  320,\n-        728,  931,  470,  944],\n-        [ 383,  134,  271,  494,  179,  304,  150,  804,  788,  780,  356,\n-        416,  297,  903,  623],\n-        [ 487,  263,  414,  947,  608,  810,  140,   74,  372,  129,  417,\n-        592,  671,  479,  901],\n-        [ 692,  953,  508,  359,   85,  396,  545,  375,  382,  382,  511,\n-        382,  383,  643,  134],\n-        [ 652,  213,  210,  385,  326,  899,  341,  925,  908,   68,  216,\n-        21,  568, 1008,  635],\n-        [ 938,  848,  570,  515,  574,  693,  382,   71,   42,  742,  603,\n-        109,  193,  629,   79],\n-        [ 847,  101,  874,  894,  384,  832,  378,  658,    1,  487,  976,\n-        993,  932,  886,  860],\n-        [ 220,  344,  307,   69,  705,  974,  895,  438,    8,  806,  573,\n-        690,  543,  709,  303],\n-        [ 394,  594,  144,   10,  832,    4,  588,  659,  501,  218,  351,\n-        861,  915,  148,  141],\n-        [ 447,  763,  930,  894,  196,  668,  528,  862,   70,  598,  136,\n-        119,  395,  474, 1000],\n-        [ 677,  178,  637,  874,  471,  113,   23,  534,  333,    6,  821,\n-        777,  635,  932,  475],\n-        [ 932,  345,  436,  335,  555,  355,  103,  436,  277,  816,  400,\n-        356,   73,   23,  450],\n-        [ 592,  402,  177,   31,  693,  459,  442,  193,  615,  940,  927,\n-        917,  676,  327,  658],\n-        [ 192,  458,  540,  808,  626,  340,  290,  700,  190,  345,  381,\n-        137,  280,  611,  794],\n-        [ 834,    5,  522,  685,  146,  754,   37,  580,   78,    2, 1008,\n-        808,  281,  375,  366],\n-        [ 892,  790,  948,  662,  355,  437,  444,  790,  450,  850,  316,\n-        529,  385,  480,  178],\n-        [  36,  696,  125,  753,  143,  562,  368,  824,  491,  507,  892,\n-        880,  355,  152,  253],\n-        [ 934,  829,  457,  261,  668, 1014,  185,  464,   78,  332,  374,\n-        869,  530,   67,  884],\n-        [ 567,  914,  334,   38,  313,  744,    6,  210,  489,  867,  200,\n-        799,  540,  318,  706],\n-        [ 178,  882,  776,  992,  651,  800,  163,  470,  687,  906,  508,\n-        260,   36,  783,   64],\n-        [ 169,   66,  179,  711,  598,  938,  346,  251,  773,  108,  873,\n-        813,  479,  425,  669],\n-        [ 981,  692,  143,  589,  224,  282,   86,  712,  689,  907,  586,\n-        595,  444,  265,  198],\n-        [ 856,  540,  556,  302,  883,   96,  856,  560,  529,   91,  707,\n-        286,  142,  553,  252],\n-        [ 103,  868,  879,  779,  882,   34,  340,  603,  186,  808,  397,\n-        673,  919,  989,  626],\n-        [ 933,  215,  775,  747,  842,  836,  744,  272,  604,  202,  288,\n-        164,  242,  542,  207],\n-        [ 969,  373,  999,  524,  927,  879, 1017,   14,  526,  385,  478,\n-        690,  347,  589,   10],\n-        [ 716,  503,  781,  119,  176,  316,  212,  836,  850,   26,  685,\n-        973,  606,  796,  593],\n-        [ 164,  418,  929,  523,  571,  917,  364,  964,  480, 1021,    0,\n-        994,  876,  887,  379],\n-        [ 416,  957,  819,  478,  640,  479,  217,  842,  926,  771,  129,\n-        537,  899,  680,  547],\n-        [ 623,  596,  332,  517,  947,  376,  699,  918, 1012,  995,  858,\n-        516,   56,   43,  268]]]).to(torch_device),\n-    \"dac_44khz\": torch.tensor([[[ 698,  315,  105,  315,  330,  105,  105,  698,  315,  481,  330,\n-            93,  629,  315,  105],\n-         [  30,  232,  249,  881,  962,  365,   56,  881,  186,  402,  311,\n-           521,  558,  778,  254],\n-         [1022,   22,  361,  491,  233,  419,  909,  456,  456,  471,  420,\n-           569,  455,  491,   16],\n-         [ 599,  143,  641,  352,   40,  556,  860,  780,  138,  137,  304,\n-           563,  863,  174,  370],\n-         [ 485,  350,  242,  555,  174,  581,  666,  744,  559,  810,  127,\n-           558,  453,   90,  124],\n-         [ 851,  423,  706,  178,   36,  564,  650,  539,  733,  720,   18,\n-           265,  619,  545,  581],\n-         [ 755,  891,  628,  674,  724,  764,  420,   51,  566,  315,  178,\n-           881,  461,  111,  675],\n-         [  52,  995,  512,  139,  538,  666, 1017,  868,  619,    0,  449,\n-          1005,  982,  106,  139],\n-         [ 357,  180,  368,  892,  856,  567,  960,  148,   36,  708,  945,\n-           285,  531,  331,  440]]]).to(torch_device),\n+    \"dac_16khz\": torch.tensor(\n+        [\n+            [\n+                [804, 25, 536, 52, 68, 867, 388, 653, 315, 706, 301, 305, 752, 25, 40],\n+                [955, 955, 134, 601, 431, 375, 967, 56, 54, 261, 871, 552, 232, 341, 228],\n+                [977, 701, 172, 927, 617, 765, 790, 149, 403, 707, 511, 226, 254, 883, 644],\n+                [467, 85, 828, 54, 211, 1007, 906, 253, 677, 1007, 302, 577, 644, 330, 778],\n+                [189, 865, 586, 321, 116, 357, 911, 865, 1000, 234, 6, 901, 6, 470, 895],\n+                [454, 241, 67, 622, 487, 426, 749, 833, 382, 900, 372, 959, 622, 305, 964],\n+                [175, 609, 730, 307, 961, 609, 318, 1011, 386, 949, 343, 899, 657, 609, 38],\n+                [82, 92, 692, 83, 131, 866, 483, 362, 519, 531, 853, 121, 404, 224, 710],\n+                [1003, 260, 431, 460, 827, 927, 81, 76, 629, 298, 168, 177, 466, 741, 762],\n+                [196, 203, 594, 394, 198, 560, 952, 437, 222, 992, 934, 316, 497, 31, 538],\n+                [129, 715, 393, 635, 246, 716, 908, 384, 962, 873, 92, 254, 592, 496, 83],\n+                [257, 502, 606, 204, 993, 428, 176, 395, 901, 323, 342, 849, 226, 453, 513],\n+            ]\n+        ]\n+    ).to(torch_device),\n+    \"dac_24khz\": torch.tensor(\n+        [\n+            [\n+                [252, 851, 919, 204, 239, 360, 160, 103, 851, 876, 160, 793, 103, 234, 665],\n+                [908, 658, 479, 556, 847, 738, 395, 124, 847, 496, 623, 77, 9, 497, 117],\n+                [385, 278, 221, 1020, 408, 330, 70, 215, 80, 84, 320, 998, 931, 470, 944],\n+                [383, 259, 271, 348, 179, 304, 634, 282, 788, 542, 356, 760, 297, 903, 623],\n+                [487, 159, 414, 947, 608, 685, 101, 74, 372, 823, 417, 866, 671, 589, 901],\n+                [692, 175, 508, 54, 85, 383, 787, 629, 844, 7, 511, 382, 383, 643, 134],\n+                [652, 895, 846, 766, 326, 640, 852, 365, 887, 126, 216, 224, 568, 1008, 635],\n+                [938, 285, 570, 515, 574, 515, 862, 644, 845, 207, 603, 830, 193, 158, 79],\n+                [847, 825, 874, 991, 384, 509, 1008, 308, 579, 487, 976, 651, 932, 692, 860],\n+                [220, 392, 307, 397, 705, 876, 273, 438, 411, 449, 573, 393, 543, 709, 303],\n+                [394, 773, 144, 254, 832, 586, 790, 941, 501, 502, 351, 907, 915, 148, 141],\n+                [447, 985, 930, 175, 196, 854, 968, 494, 899, 637, 136, 937, 395, 364, 1000],\n+                [677, 690, 428, 756, 471, 225, 763, 124, 333, 23, 821, 644, 635, 130, 475],\n+                [932, 589, 436, 548, 555, 53, 466, 280, 598, 689, 400, 194, 73, 619, 450],\n+                [592, 402, 177, 731, 693, 618, 871, 177, 761, 222, 927, 986, 676, 197, 658],\n+                [192, 560, 368, 729, 626, 656, 174, 271, 383, 345, 381, 567, 467, 970, 794],\n+                [834, 92, 990, 380, 146, 286, 644, 929, 173, 292, 1008, 948, 281, 973, 366],\n+                [892, 533, 350, 589, 355, 163, 561, 229, 655, 240, 316, 926, 385, 624, 178],\n+                [36, 385, 589, 342, 143, 517, 648, 94, 457, 217, 892, 60, 355, 46, 253],\n+                [934, 939, 457, 5, 668, 323, 312, 825, 448, 697, 374, 199, 98, 955, 884],\n+                [567, 297, 40, 498, 313, 86, 832, 270, 21, 609, 200, 688, 168, 616, 706],\n+                [178, 559, 922, 627, 651, 19, 589, 475, 312, 898, 508, 969, 36, 783, 64],\n+                [169, 981, 86, 4, 598, 988, 670, 480, 68, 235, 873, 130, 479, 543, 669],\n+                [981, 575, 827, 149, 224, 572, 470, 265, 504, 654, 586, 835, 444, 497, 198],\n+                [856, 913, 658, 664, 883, 771, 646, 56, 440, 482, 707, 229, 864, 286, 252],\n+                [103, 568, 68, 904, 882, 239, 67, 112, 941, 457, 397, 412, 634, 1018, 626],\n+                [933, 908, 96, 316, 842, 842, 241, 600, 504, 765, 288, 520, 312, 847, 207],\n+                [969, 255, 492, 868, 927, 951, 170, 607, 720, 234, 478, 482, 119, 376, 10],\n+                [716, 727, 375, 904, 176, 667, 729, 590, 391, 364, 685, 975, 186, 195, 593],\n+                [164, 923, 485, 139, 571, 968, 718, 305, 62, 828, 0, 177, 827, 368, 379],\n+                [416, 151, 83, 822, 640, 414, 969, 128, 667, 297, 129, 907, 938, 142, 547],\n+                [623, 263, 408, 922, 947, 916, 705, 475, 360, 68, 858, 679, 601, 737, 268],\n+            ]\n+        ]\n+    ).to(torch_device),\n+    \"dac_44khz\": torch.tensor(\n+        [\n+            [\n+                [698, 315, 105, 315, 330, 105, 105, 698, 315, 481, 330, 93, 629, 315, 105],\n+                [30, 232, 249, 881, 962, 365, 56, 881, 186, 402, 311, 521, 558, 778, 254],\n+                [1022, 22, 361, 491, 233, 419, 909, 456, 456, 471, 420, 569, 455, 491, 16],\n+                [599, 143, 641, 352, 40, 556, 860, 780, 138, 137, 304, 563, 863, 174, 370],\n+                [485, 350, 242, 555, 174, 581, 666, 744, 559, 810, 127, 558, 453, 90, 124],\n+                [851, 423, 706, 178, 36, 564, 650, 539, 733, 720, 18, 265, 619, 545, 581],\n+                [755, 891, 628, 674, 724, 764, 420, 51, 566, 315, 178, 881, 461, 111, 675],\n+                [52, 995, 512, 139, 538, 666, 1017, 868, 619, 0, 449, 1005, 982, 106, 139],\n+                [357, 180, 368, 892, 856, 567, 960, 148, 36, 708, 945, 285, 531, 331, 440],\n+            ]\n+        ]\n+    ).to(torch_device),\n }\n EXPECTED_DEC_OUTPUTS = {\n     \"dac_16khz\": torch.tensor([[ 0.0002,  0.0007,  0.0012,  0.0015,  0.0017,  0.0011,  0.0004, -0.0002,\n@@ -559,9 +524,9 @@ def compute_rmse(arr1, arr2):\n          -6.9382e-04, -7.0792e-04, -5.6856e-04, -2.6751e-04,  1.5914e-04]]).to(torch_device),\n }\n EXPECTED_QUANT_CODEBOOK_LOSS = {\n-    \"dac_16khz\": 20.62909698486328,\n-    \"dac_24khz\": 22.47393798828125,\n-    \"dac_44khz\": 16.229290008544922,\n+    \"dac_16khz\": 20.7299,\n+    \"dac_24khz\": 22.6652,\n+    \"dac_44khz\": 16.2168,\n }\n EXPECTED_CODEC_ERROR = {\n     \"dac_16khz\": 0.003831653157249093,\n@@ -575,223 +540,142 @@ def compute_rmse(arr1, arr2):\n     \"dac_44khz\": torch.tensor([2, 1, 313856]),\n }\n EXPECTED_ENC_LOSS_BATCH = {\n-    \"dac_16khz\": 20.3460636138916,\n-    \"dac_24khz\": 23.54486846923828,\n-    \"dac_44khz\": 19.58145523071289,\n+    \"dac_16khz\": 20.3752,\n+    \"dac_24khz\": 23.5663,\n+    \"dac_44khz\": 19.5858,\n }\n EXPECTED_QUANT_CODES_BATCH = {\n-    \"dac_16khz\": torch.tensor([[[ 490,  664,  726,  166,   55,  379,  367,  664,  661,  726,  592,\n-        301,  130,  198,  129],\n-        [1020,  734,   23,   53,  134,  648,  549,  589,  790, 1000,  420,\n-        271, 1021,  740,   36],\n-        [ 701,  344,  955,   19,  927,  212,  212,  667,  212,  627,  837,\n-        954,  777,  706,  496],\n-        [ 526,  805,  444,  474,  870,  920,  394,  823,  814, 1021,  319,\n-        677,  251,  485, 1021],\n-        [ 721,  134,  280,  439,  287,   77,  175,  902,  973,  412,  548,\n-        953,  130,   75,  543],\n-        [ 675,  316,  285,  341,  783,  850,  131,  487,  701,  150,  674,\n-        730,  900,  481,  498],\n-        [ 377,   37,  237,  489,   55,  246,  427,  456,  755, 1011,  171,\n-        631,  695,  576,  804],\n-        [ 601,  557,  681,   52,   10,  299,  284,  216,  869,  276,  907,\n-        364,  955,   41,  497],\n-        [ 465,  553,  697,   59,  701,  195,  335,  225,  896,  804,  240,\n-        928,  392,  192,  332],\n-        [ 807,  306,  977,  801,   77,  172,  760,  747,  445,   38,  395,\n-        31,  924,  724,  835],\n-        [ 903,  561,  205,  421,  231,  873,  931,  361,  679,  854,  248,\n-        884, 1011,  857,  248],\n-        [ 490,  993,  122,  787,  178,  307,  141,  468,  652,  786,  959,\n-        885,  226,  343,  501]],\n-        [[ 140,  320,  140,  489,  444,  320,  210,   73,  821, 1004,  388,\n-        686,  405,  563,  517],\n-        [ 725,  449,  715,   85,  761,  532,  620,   28,  620,  418,  146,\n-        532,  418,  453,  565],\n-        [ 695,  725,  994,  371,  829, 1008,  911,  927,  181,  707,  306,\n-        337,  254,  577,  857],\n-        [  51,  648,  474,  129,  781,  968,  737,  718,  400,  839,  674,\n-        689,  544,  767,  540],\n-        [1007,  234,  865,  966,  734,  748,   68,  454,  473,  973,  414,\n-        586,  618,    6,  612],\n-        [ 410,  566,  692,  756,  307, 1008,  269,  743,  549,  320,  303,\n-        729,  507,  741,  362],\n-        [ 172,  102,  959,  714,  292,  173,  149,  308,  307,  527,  844,\n-        102,  747,   76,  295],\n-        [ 656,  144,  994,  245,  686,  925,   48,  356,  126,  418,  112,\n-        674,  582,  916,  296],\n-        [ 776,  971,  967,  781,  174,  688,  817,  278,  937,  467,  352,\n-        463,  530,  804,  619],\n-        [1009,  284,  966,  907,  397,  875,  279,  643,  878,  315,  734,\n-        751,  337,  699,  382],\n-        [ 389,  748,   50,  585,   69,  565,  555,  931,  154,  443,   16,\n-        139,  905,  172,  361],\n-        [ 884,   34,  945, 1013,  212,  493,  724,  775,  356,  199,  728,\n-        552,  755,  223,  378]]]).to(torch_device),\n-    \"dac_24khz\": torch.tensor([[[ 234,  322,  826,  360,  204,  208,  766,  826,  458,  322,  919,\n-           999,  360,  772,  204],\n-         [ 780,  201,  229,  497,    9,  663, 1002,  243,  556,  300,  781,\n-           496,   77,  780,  781],\n-         [ 714,  342,  401,  553,  728,  196,  181,  109,  949,  528,   39,\n-           558,  180,    5,  197],\n-         [ 112,  408,  186,  933,  543,  829,  724, 1001,  425,   39,  163,\n-           517,  986,  348,  653],\n-         [1001,  207,  671,  551,  742,  231,  870,  577,  353, 1016,  259,\n-           282,  247,  126,   63],\n-         [ 924,   59,  799,  739,  771,  568,  280,  673,  639, 1002,   35,\n-           143,  270,  749,  571],\n-         [ 310,  982,  904,  666,  819,   67,  161,  373,  945,  871,  597,\n-           466,  388,  898,  584],\n-         [  69,  357,  188,  969,  213,  162,  376,   35,  638,  657,  731,\n-           991,  625,  833,  801],\n-         [ 333,  885,  343,  621,  752,  319,  292,  389,  947,  776,   78,\n-           585,  193,  834,  622],\n-         [ 958,  144,  680,  819,  303,  832,   56,  683,  366,  996,  609,\n-           784,  305,  621,   36],\n-         [ 561,  766,   69,  768,  219,  126,  945,  798,  568,  554,  115,\n-           245,   31,  384,  167],\n-         [ 727,  684,  371,  447,   50,  309,  407,  121,  839, 1019,  816,\n-           423,  604,  489,  738],\n-         [ 598,  490,  578,  353,  517,  283,  927,  432,  464,  608,  927,\n-            32,  240,  852,  326],\n-         [ 337,  226,  450,  862,  549,  799,  887,  925,  392,  841,  539,\n-           633,  351,    7,  386],\n-         [ 668,  497,  586,  937,  516,  898,  768, 1014,  420,  173,  116,\n-           602,  786,  940,   56],\n-         [ 575,  927,  322,  885,  367,  175,  691,  337,   21,  796,  317,\n-           826,  109,  604,   54],\n-         [  50,  854,  118,  231,  567,  332,  827,  422,  339,  958,  529,\n-            63,  992,  597,  428],\n-         [ 480,  619,  605,  598,  912, 1012,  365,  926,  538,  915,   22,\n-           675,  460,  667,  255],\n-         [ 578,  373,  355,   92,  920,  454,  979,  536,  645,  442,  783,\n-           956,  693,  457,  842],\n-         [1019,    0,  998,  958,  159,  159,  332,   94,  886,    1,  455,\n-           981,  418,  758,  358],\n-         [ 698,  843, 1008,  626,  776,  342,   53,  518,  636,  997,   22,\n-            36,  997,   12,  374],\n-         [ 904,  408,  802,  456,  645,  899,   15,  447,  857,  265,  185,\n-           983, 1018,  282,  607],\n-         [ 459,  467,  461,  358,  389,  792,  385,  678,   50,  888,   63,\n-             3,  792,  588,  972],\n-         [ 877,  180,  212,  656,   60,   73,  261,  644,  755,  496,  137,\n-           948,  879,  361,  863],\n-         [ 172,  588,  948,  452,  297, 1009,   49,  426,  853,  843,  249,\n-           957, 1008,  730,  860],\n-         [ 677,  125,  519,  975,  686,  404,  321,  310,   38,  138,  424,\n-           457,   98,  736, 1004],\n-         [ 784,  262,  289,  299, 1022,  170,  865,  869,  951,  839,  100,\n-           301,  828,   62,  511],\n-         [ 726,  693,  235,  208,  668,  777,  284,   61,  376,  203,  784,\n-           101,  344,  587,  736],\n-         [ 851,   83,  484,  951,  839,  180,  801,  525,  890,  373,  206,\n-           467,  524,  572,  614],\n-         [  48,  297,  674,  895,  740,  179,  782,  242,  721,  815,   85,\n-            74,  179,  650,  554],\n-         [ 336,  166,  203, 1021,   89,  991,  410,  518, 1019,  742,  235,\n-           810,  782,  623,  176],\n-         [ 110,  999,  360,  260,  278,  582,  921,  470,  242,  667,   21,\n-           463,  335,  566,  897]],\n-        [[ 851,  160,  851,  877,  665,  110,  581,  936,  826,  910,  110,\n-           110,  160,  103,  160],\n-         [ 325,  342,  722,  260,  549,  617,  508,    0,  221,  631,  846,\n-           446,  457,  124,   23],\n-         [ 529,  921,  767,  408,  628,  980,   80,  460,  255,  209,  768,\n-           255,  773,  759,  861],\n-         [ 344,  600,  255,  271,  402,  228,  805,  662,  497,   94,  852,\n-           337,  812,  140,  760],\n-         [ 415,  423,  322,  337,  599,  703,  520,  332,  377,  539,  511,\n-           511,  124,  110,  638],\n-         [ 514,  501,  660, 1014,  678,   77,  563,  793,  608,  464,  405,\n-            24,  630,  176,  692],\n-         [ 768,  497,  276,  353,  968,  214,  527,  447,  680,  746,  281,\n-           972,  681,  708,  907],\n-         [ 461,  802,   81,  411,  271,  186,  530,  670,  952, 1001,  828,\n-           270,  568,   74,  606],\n-         [ 539,  178,  451,  343,  235,  336,  346,  272,  992,  958,  924,\n-            91,  606,  408,  104],\n-         [ 668,  629,  817,  872,  526,  369,  889,  265,  297,  140,  229,\n-           240,  360,  811,  189],\n-         [ 973,  419,  164,  855,  767,  168,  378,  968,  698,   10,  610,\n-           297,  236,  976,  668],\n-         [ 162,  291,   66,   67,  749,  433,  428,  573,  421,  467,  202,\n-           838,  125,  452,  873],\n-         [   5,  949,  393,  322,  563,  679,  306,  467,  779,  326,  624,\n-            27,  447,  142,  965],\n-         [ 981,  105,  116,   51,  674,  584,  351,  322,   81,  320,  476,\n-           527,  668,  212,  944],\n-         [ 813,  156, 1013,  675,  964,  788,  137,  475,  436,  109,  400,\n-           899,  599,  820,  746],\n-         [ 398,   21,   63,  720,  304, 1017, 1009,  889,  475,  619,  684,\n-           571,  430,  642,   69],\n-         [ 405,  140,  531,  526,  657,  991,  624, 1014,  818,  256,  300,\n-          1013,  255,  567,    0],\n-         [ 153,  469,   23,  553,  210,  812,  327,  527,  251,  406,   38,\n-           893,  974,  777,   58],\n-         [ 324,  399,    4,  563,  703,  499,  256,  136,  112,  164,  979,\n-           524,  975,  596,  520],\n-         [ 792,  511,  224,  225,  229,  424,  436,  124,   27,  267,  806,\n-             8,  657,  914,  808],\n-         [ 595,  491,  993,  961,  722,  756,  937,  723,  195,  991,  436,\n-           392,  464,  837,  604],\n-         [ 918,  647,  931,  658,  594,  677,  106,  194,  466,   92,  728,\n-           575,  302,  864,  930],\n-         [ 672,  685,  997,   36,  344,  956,  260,  781,  108,  348,  755,\n-           142,   65,  754,  284],\n-         [ 327,  987,  859,  525,  115,  551,  384,  202,   10,  669,   84,\n-           481,  193,  392,  246],\n-         [ 206,  432, 1018,  954,  534,  350,  902,   30,  428,  701,  913,\n-           408,  456,  135,  726],\n-         [ 483,  953,  684,  843,  478,  406,  931,  189,  426,  596,  459,\n-            34,  306,  140,   22],\n-         [ 508,  990,  988,  862,  265,  437,  277,  876,  874,  301,  759,\n-           759,  989,   85,  292],\n-         [ 586,  487,  860,  525,   90,  436,   15,  475,  625,  714,  697,\n-           180,  453,  279,  524],\n-         [ 639,  844,  513,  487,  853,  185,  690,  664,  688,  842,  439,\n-          1002,  468,  745,  298],\n-         [ 551,  764,  383,  422,  768,  760,  244,  332,  722,  567,  352,\n-           654,  579, 1019,  787],\n-         [ 207,  365,  766,  423,  792,  470,  582,  978,  692,  408,  573,\n-            19,  314,  471,  587],\n-         [ 776,  854,  529,  113,  927,  187,  362,  791,  131,  570,  559,\n-            61,  763,   83, 1015]]]).to(torch_device),\n-    \"dac_44khz\": torch.tensor([[[ 330,  315,  315,  619,  481,  315,  197,  315,  315,  105,  481,\n-           315,  481,  481,  481],\n-         [ 718, 1007,  929,    6,  906,  944,  402,  750,  675,  854,  336,\n-           426,  609,  356,  329],\n-         [ 417,  266,  697,  456,  300,  941,  325,  923, 1022,  605,  991,\n-             7,  939,  329,  456],\n-         [ 813,  811,  271,  148,  184,  838,  723,  497,  330,  922,   12,\n-           333,  918,  963,  285],\n-         [ 832,  307,  635,  794,  334,  114,   32,  505,  344,  170,  161,\n-           907,  193,  180,  585],\n-         [  91,  941,  912, 1001,  507,  486,  362, 1006,  228,  640,  760,\n-           215,  577,  633,  371],\n-         [ 676,   27,  903,  472,  473,  219,  860,  477,  969,  385,  533,\n-           911,  701,  241,  825],\n-         [ 326,  399,  116,  443,  605,  373,  534,  199,  748,  538,  516,\n-           983,  372,  565,  167],\n-         [ 776,  843,  185,  326,  723,  756,  318,   34,  818,  674,  728,\n-           554,  721,  369,  267]],\n-        [[ 578,  698,  330,  330,  330,  578,  330,  801,  330,  330,  330,\n-           330,  330,  330,  330],\n-         [ 171,  503,  725,  215,  814,  861,  139,  684,  880,  905,  937,\n-           418,  359,  190,  823],\n-         [ 141,  482,  780,  489,  845,  499,   59,  480,  296,   30,  631,\n-           540,  399,   23,  385],\n-         [ 402,  837,  216,  116,  535,  456, 1006,  969,  994,  125, 1011,\n-           285,  851,  832,  197],\n-         [  46,  950,  728,  645,  850,  839,  527,  850,   81,  205,  590,\n-           166,   22,  148,  402],\n-         [  98,  758,  474,  941,  217,  667,  681,  109,  719,  824,  162,\n-           160,  329,  627,  716],\n-         [ 999,  228,  752,  639,  404,  333,  993,  177,  888,  158,  644,\n-           221, 1011,  302,   79],\n-         [ 669,  535,  164,  665,  809,  798,  448,  800,  123,  936,  639,\n-           361,  353,  402,  160],\n-         [ 345,  355,  940,  261,   71,  946,  750,  120,  565,  164,  813,\n-           976,  946,   50,  516]]]).to(torch_device),\n+    \"dac_16khz\": torch.tensor(\n+        [\n+            [\n+                [490, 664, 726, 166, 55, 379, 367, 664, 661, 726, 592, 301, 130, 198, 129],\n+                [1020, 734, 23, 53, 134, 648, 549, 589, 790, 1000, 449, 271, 1021, 740, 36],\n+                [701, 344, 955, 19, 927, 212, 212, 667, 212, 627, 453, 954, 777, 706, 496],\n+                [526, 805, 444, 474, 870, 920, 394, 823, 814, 1021, 763, 677, 251, 485, 1021],\n+                [721, 134, 280, 439, 287, 77, 175, 902, 973, 412, 739, 953, 130, 75, 543],\n+                [675, 316, 285, 341, 783, 850, 131, 487, 701, 150, 749, 730, 900, 481, 498],\n+                [377, 37, 237, 489, 55, 246, 427, 456, 755, 1011, 712, 631, 695, 576, 804],\n+                [601, 557, 681, 52, 10, 299, 284, 216, 869, 276, 424, 364, 955, 41, 497],\n+                [465, 553, 697, 59, 701, 195, 335, 225, 896, 804, 776, 928, 392, 192, 332],\n+                [807, 306, 977, 801, 77, 172, 760, 747, 445, 38, 731, 31, 924, 724, 835],\n+                [903, 561, 205, 421, 231, 873, 931, 361, 679, 854, 471, 884, 1011, 857, 248],\n+                [490, 993, 122, 787, 178, 307, 141, 468, 652, 786, 879, 885, 226, 343, 501],\n+            ],\n+            [\n+                [140, 320, 210, 489, 444, 320, 210, 73, 821, 1004, 388, 686, 405, 563, 407],\n+                [725, 449, 802, 85, 36, 532, 620, 28, 620, 418, 146, 532, 418, 453, 565],\n+                [695, 725, 600, 371, 829, 1008, 911, 927, 181, 707, 306, 337, 254, 577, 289],\n+                [51, 648, 186, 129, 781, 968, 737, 563, 400, 839, 674, 689, 544, 767, 577],\n+                [1007, 234, 145, 966, 734, 748, 68, 272, 473, 973, 414, 586, 618, 6, 909],\n+                [410, 566, 507, 756, 943, 1008, 269, 349, 549, 320, 303, 729, 507, 741, 76],\n+                [172, 102, 548, 714, 225, 173, 149, 423, 307, 527, 844, 102, 747, 76, 586],\n+                [656, 144, 407, 245, 140, 925, 48, 197, 126, 418, 112, 674, 582, 916, 223],\n+                [776, 971, 291, 781, 833, 688, 817, 261, 937, 467, 352, 463, 530, 804, 683],\n+                [1009, 284, 427, 907, 900, 875, 279, 285, 878, 315, 734, 751, 337, 699, 966],\n+                [389, 748, 203, 585, 609, 565, 555, 64, 154, 443, 16, 139, 905, 172, 86],\n+                [884, 34, 477, 1013, 335, 493, 724, 202, 356, 199, 728, 552, 755, 223, 371],\n+            ],\n+\n+        ]\n+    ).to(torch_device),\n+    \"dac_24khz\": torch.tensor(\n+        [\n+            [\n+                [234, 322, 826, 360, 204, 208, 766, 826, 458, 322, 919, 999, 360, 772, 204],\n+                [117, 201, 229, 497, 9, 663, 1002, 243, 556, 300, 781, 496, 77, 780, 781],\n+                [554, 342, 401, 553, 728, 196, 181, 109, 949, 528, 39, 558, 180, 5, 197],\n+                [112, 408, 186, 933, 543, 829, 724, 1001, 425, 39, 163, 517, 986, 348, 653],\n+                [ 88, 207, 671, 551, 742, 231, 870, 577, 353, 1016, 259, 282, 247, 126, 63],\n+                [924, 59, 799, 739, 771, 568, 280, 673, 639, 1002, 35, 143, 270, 749, 571],\n+                [214, 982, 904, 666, 819, 67, 161, 373, 945, 871, 597, 466, 388, 898, 584],\n+                [696, 357, 188, 969, 213, 162, 376, 35, 638, 657, 731, 991, 625, 833, 801],\n+                [559, 885, 343, 621, 752, 319, 292, 389, 947, 776, 78, 585, 193, 834, 622],\n+                [642, 144, 680, 819, 303, 832, 56, 683, 366, 996, 609, 784, 305, 621, 36],\n+                [517, 766, 69, 768, 219, 126, 945, 798, 568, 554, 115, 245, 31, 384, 167],\n+                [424, 684, 371, 447, 50, 309, 407, 121, 839, 1019, 816, 423, 604, 489, 738],\n+                [274, 490, 578, 353, 517, 283, 927, 432, 464, 608, 927, 32, 240, 852, 326],\n+                [737, 226, 450, 862, 549, 799, 887, 925, 392, 841, 539, 633, 351, 7, 386],\n+                [624, 497, 586, 937, 516, 898, 768, 188, 420, 173, 116, 602, 786, 940, 56],\n+                [430, 927, 322, 885, 367, 175, 691, 337, 21, 796, 317, 826, 109, 604, 54],\n+                [917, 854, 118, 231, 567, 332, 827, 422, 339, 958, 529, 63, 992, 597, 428],\n+                [468, 619, 605, 598, 912, 1012, 365, 60, 538, 915, 22, 675, 460, 667, 255],\n+                [912, 373, 355, 92, 920, 454, 979, 414, 645, 442, 783, 956, 693, 457, 842],\n+                [230, 0, 998, 958, 159, 159, 332, 94, 886, 1, 455, 981, 418, 758, 358],\n+                [132, 843, 1008, 626, 776, 342, 53, 362, 636, 997, 22, 36, 997, 12, 374],\n+                [135, 408, 802, 456, 645, 899, 15, 447, 857, 265, 185, 983, 1018, 282, 607],\n+                [272, 467, 461, 358, 389, 792, 385, 339, 50, 888, 63, 3, 792, 588, 972],\n+                [179, 180, 212, 656, 60, 73, 261, 644, 755, 496, 137, 948, 879, 361, 863],\n+                [739, 588, 948, 452, 297, 1009, 49, 725, 853, 843, 249, 957, 1008, 730, 860],\n+                [174, 125, 519, 975, 686, 404, 321, 668, 38, 138, 424, 457, 98, 736, 1004],\n+                [ 68, 262, 289, 299, 1022, 170, 865, 869, 951, 839, 100, 301, 828, 62, 511],\n+                [509, 693, 235, 208, 668, 777, 284, 832, 376, 203, 784, 101, 344, 587, 736],\n+                [121, 83, 484, 951, 839, 180, 801, 363, 890, 373, 206, 467, 524, 572, 614],\n+                [146, 297, 674, 895, 740, 179, 782, 521, 721, 815, 85, 74, 179, 650, 554],\n+                [708, 166, 203, 1021, 89, 991, 410, 117, 1019, 742, 235, 810, 782, 623, 176],\n+                [358, 999, 360, 260, 278, 582, 921, 314, 242, 667, 21, 463, 335, 566, 897],\n+            ],\n+            [\n+                [851, 360, 851, 877, 665, 322, 581, 936, 826, 910, 110, 110, 160, 103, 204],\n+                [325, 260, 722, 260, 549, 20, 508, 455, 221, 631, 846, 658, 457, 124, 496],\n+                [529, 367, 767, 408, 628, 190, 80, 460, 351, 209, 768, 255, 655, 759, 605],\n+                [344, 192, 255, 271, 402, 930, 805, 939, 497, 94, 843, 38, 96, 140, 760],\n+                [415, 65, 953, 337, 599, 358, 520, 477, 602, 539, 443, 703, 124, 110, 92],\n+                [514, 847, 606, 1014, 678, 806, 563, 408, 520, 4, 208, 83, 630, 176, 423],\n+                [768, 741, 546, 353, 968, 371, 527, 447, 21, 746, 343, 100, 286, 708, 781],\n+                [461, 499, 836, 411, 271, 279, 530, 882, 345, 1001, 828, 270, 733, 74, 709],\n+                [539, 706, 278, 343, 235, 754, 346, 272, 52, 987, 151, 74, 757, 408, 623],\n+                [668, 754, 817, 872, 526, 479, 889, 24, 297, 482, 162, 414, 128, 811, 488],\n+                [973, 938, 874, 855, 767, 419, 378, 832, 745, 820, 957, 364, 389, 976, 301],\n+                [162, 174, 830, 67, 749, 433, 428, 405, 63, 632, 391, 750, 518, 452, 743],\n+                [ 5, 694, 393, 322, 563, 425, 306, 211, 870, 302, 491, 694, 324, 142, 997],\n+                [981, 953, 116, 51, 674, 451, 351, 335, 285, 44, 591, 147, 124, 212, 957],\n+                [813, 80, 700, 675, 964, 355, 137, 104, 679, 151, 88, 553, 815, 820, 21],\n+                [398, 102, 563, 720, 304, 299, 1009, 606, 186, 52, 1012, 807, 999, 642, 901],\n+                [405, 522, 668, 526, 657, 762, 624, 636, 358, 570, 572, 169, 580, 567, 939],\n+                [153, 712, 786, 553, 210, 472, 327, 759, 51, 153, 833, 22, 800, 777, 283],\n+                [324, 45, 757, 563, 703, 888, 256, 447, 515, 313, 94, 345, 295, 596, 132],\n+                [792, 242, 242, 225, 229, 1004, 436, 61, 869, 757, 945, 1004, 122, 914, 989],\n+                [595, 902, 56, 961, 722, 731, 937, 332, 706, 30, 372, 479, 1023, 837, 513],\n+                [918, 972, 772, 658, 594, 12, 106, 225, 678, 920, 971, 724, 181, 864, 837],\n+                [672, 237, 87, 36, 344, 866, 260, 473, 915, 203, 385, 23, 561, 754, 71],\n+                [327, 65, 330, 525, 115, 837, 384, 734, 113, 178, 982, 285, 678, 392, 50],\n+                [206, 317, 201, 954, 534, 692, 902, 773, 399, 215, 766, 143, 35, 135, 672],\n+                [483, 984, 864, 843, 478, 811, 931, 656, 561, 636, 638, 326, 141, 140, 632],\n+                [508, 315, 204, 862, 265, 444, 277, 658, 281, 1009, 453, 283, 387, 85, 677],\n+                [586, 992, 528, 525, 90, 288, 15, 370, 939, 894, 791, 819, 879, 279, 222],\n+                [639, 896, 792, 487, 853, 852, 690, 886, 141, 988, 889, 29, 899, 745, 864],\n+                [551, 167, 982, 422, 768, 495, 244, 956, 991, 242, 353, 622, 168, 1019, 735],\n+                [207, 155, 674, 423, 792, 755, 582, 541, 612, 429, 460, 947, 173, 471, 79],\n+                [776, 304, 401, 113, 927, 439, 362, 612, 527, 343, 845, 326, 708, 83, 473],\n+            ],\n+        ]\n+    ).to(torch_device),\n+    \"dac_44khz\": torch.tensor(\n+        [\n+            [\n+                [330, 315, 315, 619, 481, 315, 197, 315, 315, 105, 481, 315, 481, 481, 481],\n+                [718, 1007, 929, 6, 906, 944, 402, 750, 396, 854, 336, 426, 609, 356, 329],\n+                [417, 266, 697, 456, 300, 941, 325, 923, 1022, 605, 991, 7, 939, 217, 456],\n+                [813, 811, 271, 148, 184, 838, 723, 497, 678, 922, 12, 333, 918, 842, 285],\n+                [832, 307, 635, 794, 334, 828, 32, 505, 610, 170, 161, 907, 193, 372, 585],\n+                [ 91, 941, 912, 1001, 507, 486, 362, 1006, 157, 640, 760, 215, 577, 256, 371],\n+                [676, 27, 903, 472, 473, 881, 860, 477, 514, 385, 533, 911, 701, 102, 825],\n+                [326, 399, 116, 443, 605, 807, 534, 199, 559, 538, 516, 983, 372, 861, 167],\n+                [776, 843, 185, 326, 723, 390, 318, 34, 191, 674, 728, 554, 721, 354, 267],\n+            ],\n+            [\n+                [578, 698, 330, 330, 330, 578, 330, 801, 330, 330, 330, 330, 330, 330, 330],\n+                [171, 503, 725, 215, 814, 861, 139, 684, 880, 905, 937, 418, 359, 190, 823],\n+                [141, 482, 780, 489, 845, 499, 59, 480, 296, 30, 631, 540, 399, 23, 385],\n+                [402, 837, 216, 116, 535, 456, 1006, 969, 994, 125, 1011, 285, 851, 832, 197],\n+                [46, 950, 728, 645, 850, 839, 527, 850, 81, 449, 590, 166, 22, 148, 402],\n+                [98, 758, 474, 941, 217, 667, 681, 109, 719, 233, 162, 160, 329, 627, 716],\n+                [999, 228, 752, 639, 404, 333, 993, 177, 888, 158, 644, 221, 1011, 302, 79],\n+                [669, 535, 164, 665, 809, 798, 448, 800, 123, 936, 639, 361, 353, 402, 160],\n+                [345, 355, 940, 261, 71, 946, 750, 120, 565, 692, 813, 976, 946, 50, 516],\n+            ],\n+        ]\n+    ).to(torch_device),\n }\n EXPECTED_DEC_OUTPUTS_BATCH = {\n     \"dac_16khz\": torch.tensor([[-1.9537e-04,  1.9159e-04,  3.1591e-04,  2.0804e-04, -3.1973e-05,\n@@ -856,9 +740,9 @@ def compute_rmse(arr1, arr2):\n           8.8849e-04, -3.6330e-04, -3.9405e-04,  6.1344e-04,  1.4316e-03]]).to(torch_device),\n }\n EXPECTED_QUANT_CODEBOOK_LOSS_BATCH = {\n-    \"dac_16khz\": 20.685312271118164,\n-    \"dac_24khz\": 23.66303253173828,\n-    \"dac_44khz\": 16.129348754882812,\n+    \"dac_16khz\": 20.6472,\n+    \"dac_24khz\": 23.5954,\n+    \"dac_44khz\": 16.1380,\n }\n EXPECTED_CODEC_ERROR_BATCH = {\n     \"dac_16khz\": 0.0019726448226720095,\n@@ -895,33 +779,33 @@ def test_integration(self, model_name):\n             # compare encoder loss\n             encoder_outputs = model.encode(inputs[\"input_values\"])\n             torch.testing.assert_close(\n-                EXPECTED_ENC_LOSS[model_name], encoder_outputs[0].squeeze().item(), rtol=1e-3, atol=1e-3\n+                encoder_outputs[0].squeeze().item(), EXPECTED_ENC_LOSS[model_name], rtol=1e-3, atol=1e-3\n             )\n \n             # compare quantizer outputs\n             quantizer_outputs = model.quantizer(encoder_outputs[1])\n             torch.testing.assert_close(\n-                EXPECTED_QUANT_CODES[model_name],\n                 quantizer_outputs[1][..., : EXPECTED_QUANT_CODES[model_name].shape[-1]],\n+                EXPECTED_QUANT_CODES[model_name],\n                 rtol=1e-6,\n                 atol=1e-6,\n             )\n             torch.testing.assert_close(\n-                EXPECTED_QUANT_CODEBOOK_LOSS[model_name], quantizer_outputs[4].squeeze().item(), rtol=1e-6, atol=1e-6\n+                quantizer_outputs[4].squeeze().item(), EXPECTED_QUANT_CODEBOOK_LOSS[model_name], rtol=1e-6, atol=1e-6\n             )\n \n             # compare decoder outputs\n             decoded_outputs = model.decode(encoder_outputs[1])\n             torch.testing.assert_close(\n-                EXPECTED_DEC_OUTPUTS[model_name],\n                 decoded_outputs[\"audio_values\"][..., : EXPECTED_DEC_OUTPUTS[model_name].shape[-1]],\n+                EXPECTED_DEC_OUTPUTS[model_name],\n                 rtol=1e-3,\n                 atol=1e-3,\n             )\n \n             # compare codec error / lossiness\n             codec_err = compute_rmse(decoded_outputs[\"audio_values\"], inputs[\"input_values\"])\n-            torch.testing.assert_close(EXPECTED_CODEC_ERROR[model_name], codec_err, rtol=1e-5, atol=1e-5)\n+            torch.testing.assert_close(codec_err, EXPECTED_CODEC_ERROR[model_name], rtol=1e-5, atol=1e-5)\n \n             # make sure forward and decode gives same result\n             enc_dec = model(inputs[\"input_values\"])[1]\n@@ -952,22 +836,22 @@ def test_integration_batch(self, model_name):\n             # compare encoder loss\n             encoder_outputs = model.encode(inputs[\"input_values\"])\n             torch.testing.assert_close(\n-                EXPECTED_ENC_LOSS_BATCH[model_name], encoder_outputs[0].mean().item(), rtol=1e-3, atol=1e-3\n+                encoder_outputs[0].mean().item(), EXPECTED_ENC_LOSS_BATCH[model_name], rtol=1e-3, atol=1e-3\n             )\n \n             # compare quantizer outputs\n             quantizer_outputs = model.quantizer(encoder_outputs[1])\n             torch.testing.assert_close(\n-                EXPECTED_QUANT_CODES_BATCH[model_name],\n                 quantizer_outputs[1][..., : EXPECTED_QUANT_CODES_BATCH[model_name].shape[-1]],\n+                EXPECTED_QUANT_CODES_BATCH[model_name],\n                 rtol=1e-6,\n                 atol=1e-6,\n             )\n             torch.testing.assert_close(\n-                EXPECTED_QUANT_CODEBOOK_LOSS_BATCH[model_name],\n                 quantizer_outputs[4].mean().item(),\n-                rtol=1e-6,\n-                atol=1e-6,\n+                EXPECTED_QUANT_CODEBOOK_LOSS_BATCH[model_name],\n+                rtol=1e-4,\n+                atol=1e-4,\n             )\n \n             # compare decoder outputs\n@@ -981,7 +865,7 @@ def test_integration_batch(self, model_name):\n \n             # compare codec error / lossiness\n             codec_err = compute_rmse(decoded_outputs[\"audio_values\"], inputs[\"input_values\"])\n-            torch.testing.assert_close(EXPECTED_CODEC_ERROR_BATCH[model_name], codec_err, rtol=1e-6, atol=1e-6)\n+            torch.testing.assert_close(codec_err, EXPECTED_CODEC_ERROR_BATCH[model_name], rtol=1e-6, atol=1e-6)\n \n             # make sure forward and decode gives same result\n             enc_dec = model(inputs[\"input_values\"])[1]"
        },
        {
            "sha": "05e13f9482d9e2aa0cba8ce1ae2c0e15e88ca757",
            "filename": "tests/models/encodec/test_modeling_encodec.py",
            "status": "modified",
            "additions": 406,
            "deletions": 588,
            "changes": 994,
            "blob_url": "https://github.com/huggingface/transformers/blob/3e0333fa4aebc686a6f5526da6d77f8240dcfc87/tests%2Fmodels%2Fencodec%2Ftest_modeling_encodec.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3e0333fa4aebc686a6f5526da6d77f8240dcfc87/tests%2Fmodels%2Fencodec%2Ftest_modeling_encodec.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fencodec%2Ftest_modeling_encodec.py?ref=3e0333fa4aebc686a6f5526da6d77f8240dcfc87",
            "patch": "@@ -479,66 +479,91 @@ def compute_rmse(arr1, arr2):\n     \"facebook/encodec_24khz\": {\n         \"1.5\": torch.tensor([[[  62,  835,  835,  835,  835,  835,  835,  835,  408,  408],\n          [1007, 1007, 1007,  544,  424,  424, 1007,  424,  302,  424]]]),\n-        \"3.0\": torch.tensor([[[  62,  835,  835,  835,  835,  835,  835,  835,  408,  408],\n-            [1007, 1007, 1007,  544,  424,  424, 1007,  424,  302,  424],\n-            [ 786,  678,  821,  786,   36,   36,  786,  212,  937,  937],\n-            [ 741,  741,  741,  993,  741, 1018,  993,  919, 1018,  741]]]),\n-        \"6.0\": torch.tensor([[[  62,  835,  835,  835,  835,  835,  835,  835,  408,  408],\n-            [1007, 1007, 1007,  544,  424,  424, 1007,  424,  302,  424],\n-            [ 786,  678,  821,  786,   36,   36,  786,  212,  937,  937],\n-            [ 741,  741,  741,  993,  741, 1018,  993,  919, 1018,  741],\n-            [ 528,  446,  198,  190,  446,  622,  646,  448,  646,  448],\n-            [1011,  140,  185,  986,  683,  986,  435,   41,   41,  939],\n-            [ 896,  772,  562,  772,  485,  528,  896,  853,  570,  772],\n-            [ 899,  975,  468,  468,  468,  701, 1013,  828,  701,  899]]]),\n-        \"12.0\": torch.tensor([[[  62,  835,  835,  835,  835,  835,  835,  835,  408,  408],\n-            [1007, 1007, 1007,  544,  424,  424, 1007,  424,  302,  424],\n-            [ 786,  678,  821,  786,   36,   36,  786,  212,  937,  937],\n-            [ 741,  741,  741,  993,  741, 1018,  993,  919, 1018,  741],\n-            [ 528,  446,  198,  190,  446,  622,  646,  448,  646,  448],\n-            [1011,  140,  185,  986,  683,  986,  435,   41,   41,  939],\n-            [ 896,  772,  562,  772,  485,  528,  896,  853,  570,  772],\n-            [ 899,  975,  468,  468,  468,  701, 1013,  828,  701,  899],\n-            [ 827,  807,  938,  320,  699,  470,  909,  628,  827,  827],\n-            [ 963,  801,  630,  477,  717,  354,  205,  359,  963,  979],\n-            [1000, 1000,  388, 1000,  408,  740,  568,  364,  408,  875],\n-            [ 413,  835,  382,  840,  742, 1019,  375,  962,  890,  866],\n-            [ 971,  410,  998,  485,  798,  410,  351,  485,  828,  485],\n-            [ 848,  694,  662,  784,  848,  427, 1022,  848,  809,  795],\n-            [ 420,  911,  889,  911,  993,  776,  948,  477,  911,  847],\n-            [ 587,  755,  834,  962,  860,  425,  982,  982,  962,  962]]]),\n-        \"24.0\": torch.tensor([[[  62,  835,  835,  835,  835,  835,  835,  835,  408,  408],\n-            [1007, 1007, 1007,  544,  424,  424, 1007,  424,  302,  424],\n-            [ 786,  678,  821,  786,   36,   36,  786,  212,  937,  937],\n-            [ 741,  741,  741,  993,  741, 1018,  993,  919, 1018,  741],\n-            [ 528,  446,  198,  190,  446,  622,  646,  448,  646,  448],\n-            [1011,  140,  185,  986,  683,  986,  435,   41,   41,  939],\n-            [ 896,  772,  562,  772,  485,  528,  896,  853,  570,  772],\n-            [ 899,  975,  468,  468,  468,  701, 1013,  828,  701,  899],\n-            [ 827,  807,  938,  320,  699,  470,  909,  628,  827,  827],\n-            [ 963,  801,  630,  477,  717,  354,  205,  359,  963,  979],\n-            [1000, 1000,  388, 1000,  408,  740,  568,  364,  408,  875],\n-            [ 413,  835,  382,  840,  742, 1019,  375,  962,  890,  866],\n-            [ 971,  410,  998,  485,  798,  410,  351,  485,  828,  485],\n-            [ 848,  694,  662,  784,  848,  427, 1022,  848,  809,  795],\n-            [ 420,  911,  889,  911,  993,  776,  948,  477,  911,  847],\n-            [ 587,  755,  834,  962,  860,  425,  982,  982,  962,  962],\n-            [ 270,  160,   26,  131,  597,  506,  670,  637,  506,  885],\n-            [  15,  215,  134,   69,  215,  155, 1012, 1009,   10, 1009],\n-            [ 580,  561,  686,  896,  497,  637,  580,  245,  612,  940],\n-            [ 511,  239,  560,  691,  571,  627,  571,  571,  619,  560],\n-            [ 591,  942,  591,  251,  250,  250,  857,  486,  552,  519],\n-            [ 565,  546,  654,  301,  301,  623,  639,  568,  512,  282],\n-            [ 539,  317,  639,  539,  651,  539,  538,  640,  630,  651],\n-            [ 637,  556,  637,  582,  640,  515,  515,  632,  450,  632],\n-            [ 601,  643,  500,  550,  522,  500,  550,  561,  653,  305],\n-            [ 603,  456,  584,  755,  505,  782,  661,  671,  608,  608],\n-            [ 577,  464,  637,  647,  552,  552,  624,  647,  687,  689],\n-            [ 256,  748,  931,  608,  538, 1015,  294,  294,  530,  606],\n-            [ 906,  535,  666,  665,  655,  979,  574,  535,  781,  908],\n-            [ 719,  620,  557,  566,  511,  910,  672,  623,  382,  639],\n-            [ 894,  556,  947,  474,  610,  752, 1002,  597,  895,  621],\n-            [ 935,  948,  657,  588,  485,  633,  459,  968,  665,  683]]]),\n+        \"3.0\": torch.tensor(\n+            [\n+                [\n+                    [62, 835, 835, 835, 835, 835, 835, 835, 408, 408],\n+                    [1007, 1007, 1007, 544, 424, 424, 1007, 424, 302, 424],\n+                    [786, 678, 821, 786, 36, 36, 786, 212, 937, 937],\n+                    [741, 741, 741, 993, 741, 1018, 993, 919, 741, 741],\n+                ],\n+            ]\n+        ),\n+        \"6.0\": torch.tensor(\n+            [\n+                [\n+                    [62, 835, 835, 835, 835, 835, 835, 835, 408, 408],\n+                    [1007, 1007, 1007, 544, 424, 424, 1007, 424, 302, 424],\n+                    [786, 678, 821, 786, 36, 36, 786, 212, 937, 937],\n+                    [741, 741, 741, 993, 741, 1018, 993, 919, 741, 741],\n+                    [528, 446, 198, 190, 446, 622, 646, 448, 646, 448],\n+                    [1011, 140, 185, 986, 683, 986, 435, 41, 140, 939],\n+                    [896, 772, 562, 772, 485, 528, 896, 853, 562, 772],\n+                    [899, 975, 468, 468, 468, 701, 1013, 828, 518, 899],\n+\n+                ],\n+            ]\n+        ),\n+        \"12.0\": torch.tensor(\n+            [\n+                [\n+                    [62, 835, 835, 835, 835, 835, 835, 835, 408, 408],\n+                    [1007, 1007, 1007, 544, 424, 424, 1007, 424, 302, 424],\n+                    [786, 678, 821, 786, 36, 36, 786, 212, 937, 937],\n+                    [741, 741, 741, 993, 741, 1018, 993, 919, 741, 741],\n+                    [528, 446, 198, 190, 446, 622, 646, 448, 646, 448],\n+                    [1011, 140, 185, 986, 683, 986, 435, 41, 140, 939],\n+                    [896, 772, 562, 772, 485, 528, 896, 853, 562, 772],\n+                    [899, 975, 468, 468, 468, 701, 1013, 828, 518, 899],\n+                    [827, 807, 938, 320, 699, 470, 909, 628, 301, 827],\n+                    [963, 801, 630, 477, 717, 354, 205, 359, 874, 744],\n+                    [1000, 1000, 388, 1000, 408, 740, 568, 364, 709, 843],\n+                    [413, 835, 382, 840, 742, 1019, 375, 962, 835, 742],\n+                    [971, 410, 998, 485, 798, 410, 351, 485, 485, 920],\n+                    [848, 694, 662, 784, 848, 427, 1022, 848, 920, 694],\n+                    [420, 911, 889, 911, 993, 776, 948, 477, 911, 911],\n+                    [587, 755, 834, 962, 860, 425, 982, 982, 425, 461],\n+                ],\n+            ]\n+        ),\n+        \"24.0\": torch.tensor(\n+            [\n+                [\n+                    [62, 835, 835, 835, 835, 835, 835, 835, 408, 408],\n+                    [1007, 1007, 1007, 544, 424, 424, 1007, 424, 302, 424],\n+                    [786, 678, 821, 786, 36, 36, 786, 212, 937, 937],\n+                    [741, 741, 741, 993, 741, 1018, 993, 919, 741, 741],\n+                    [528, 446, 198, 190, 446, 622, 646, 448, 646, 448],\n+                    [1011, 140, 185, 986, 683, 986, 435, 41, 140, 939],\n+                    [896, 772, 562, 772, 485, 528, 896, 853, 562, 772],\n+                    [899, 975, 468, 468, 468, 701, 1013, 828, 518, 899],\n+                    [827, 807, 938, 320, 699, 470, 909, 628, 301, 827],\n+                    [963, 801, 630, 477, 717, 354, 205, 359, 874, 744],\n+                    [1000, 1000, 388, 1000, 408, 740, 568, 364, 709, 843],\n+                    [413, 835, 382, 840, 742, 1019, 375, 962, 835, 742],\n+                    [971, 410, 998, 485, 798, 410, 351, 485, 485, 920],\n+                    [848, 694, 662, 784, 848, 427, 1022, 848, 920, 694],\n+                    [420, 911, 889, 911, 993, 776, 948, 477, 911, 911],\n+                    [587, 755, 834, 962, 860, 425, 982, 982, 425, 461],\n+                    [270, 160, 26, 131, 597, 506, 670, 637, 248, 160],\n+                    [ 15, 215, 134, 69, 215, 155, 1012, 1009, 260, 417],\n+                    [580, 561, 686, 896, 497, 637, 580, 245, 896, 264],\n+                    [511, 239, 560, 691, 571, 627, 571, 571, 258, 619],\n+                    [591, 942, 591, 251, 250, 250, 857, 486, 295, 295],\n+                    [565, 546, 654, 301, 301, 623, 639, 568, 565, 282],\n+                    [539, 317, 639, 539, 651, 539, 538, 640, 615, 615],\n+                    [637, 556, 637, 582, 640, 515, 515, 632, 254, 613],\n+                    [305, 643, 500, 550, 522, 500, 550, 561, 522, 305],\n+                    [954, 456, 584, 755, 505, 782, 661, 671, 497, 505],\n+                    [577, 464, 637, 647, 552, 552, 624, 647, 624, 647],\n+                    [728, 748, 931, 608, 538, 1015, 294, 294, 666, 538],\n+                    [602, 535, 666, 665, 655, 979, 574, 535, 571, 781],\n+                    [321, 620, 557, 566, 511, 910, 672, 623, 853, 674],\n+                    [621, 556, 947, 474, 610, 752, 1002, 597, 474, 474],\n+                    [605, 948, 657, 588, 485, 633, 459, 968, 939, 325],\n+                ],\n+            ]\n+        ),\n         },\n     \"facebook/encodec_48khz\": {\n         \"3.0\": torch.tensor([[[214, 214, 214, 214, 214, 118, 214, 214, 214, 214],\n@@ -594,186 +619,56 @@ def compute_rmse(arr1, arr2):\n }\n EXPECTED_DECODER_OUTPUTS = {\n     \"facebook/encodec_24khz\": {\n-        \"1.5\": torch.tensor([[ 3.056301e-04, -2.294573e-04, -3.020899e-05, -4.292619e-04,\n-            3.791883e-04,  3.222890e-04, -1.665603e-05,  6.199384e-05,\n-            5.418282e-04,  1.127315e-04, -1.513894e-03, -7.437104e-04,\n-            -1.939548e-04, -1.769757e-03, -2.991516e-04,  1.262947e-03,\n-            1.065292e-03,  8.047937e-04,  7.637125e-04,  7.814290e-04,\n-            7.752634e-04,  1.931059e-04, -3.030567e-04, -3.925464e-04,\n-            -5.605159e-04, -8.649211e-04, -1.017525e-03, -1.221021e-03,\n-            -1.085280e-03, -6.197088e-04, -5.832562e-04, -4.587304e-04,\n-            -6.436021e-07,  1.417585e-04,  3.170979e-04,  2.138594e-04,\n-            -6.644148e-05, -1.998628e-04, -7.629311e-04, -1.226724e-03,\n-            -1.050805e-03, -1.244168e-03, -1.353798e-03, -3.162603e-04,\n-            1.544256e-04,  5.580785e-04,  5.737708e-04,  6.141020e-04,\n-            9.168734e-04,  1.021451e-03]]),\n-        \"3.0\": torch.tensor([[ 3.430230e-04, -1.974964e-04, -8.868257e-06, -3.983610e-04,\n-            4.049843e-04,  3.256911e-04, -3.534020e-06,  7.844555e-05,\n-            5.699758e-04,  1.579160e-04, -1.523166e-03, -7.784909e-04,\n-            -2.133542e-04, -1.849779e-03, -3.413393e-04,  1.320168e-03,\n-            1.116602e-03,  8.482400e-04,  8.102945e-04,  8.109839e-04,\n-            8.152442e-04,  2.181861e-04, -2.957153e-04, -3.824264e-04,\n-            -5.446460e-04, -8.399304e-04, -9.981393e-04, -1.219286e-03,\n-            -1.088848e-03, -6.320921e-04, -6.211858e-04, -4.838089e-04,\n-            -1.198697e-05,  1.339871e-04,  3.412343e-04,  2.453858e-04,\n-            -5.110371e-05, -1.825418e-04, -7.844020e-04, -1.302047e-03,\n-            -1.088563e-03, -1.274385e-03, -1.394893e-03, -2.863593e-04,\n-            2.007140e-04,  6.101970e-04,  6.220027e-04,  6.411646e-04,\n-            9.431313e-04,  1.043309e-03]]),\n-        \"6.0\": torch.tensor([[ 4.088855e-04, -1.371783e-04,  1.125461e-04, -3.196917e-04,\n-            4.155872e-04,  2.935473e-04,  2.364875e-05,  1.307382e-04,\n-            6.571874e-04,  2.389775e-04, -1.273537e-03, -6.629376e-04,\n-            -2.135642e-04, -1.544964e-03, -5.670189e-05,  1.426314e-03,\n-            1.388175e-03,  1.144287e-03,  1.050642e-03,  1.011542e-03,\n-            8.831486e-04,  3.966885e-04,  2.225157e-05,  4.268771e-05,\n-            9.737996e-06, -4.151848e-05, -1.147421e-04, -3.800407e-04,\n-            -4.047132e-04, -1.322415e-04, -1.690500e-04, -1.933190e-04,\n-            2.477352e-04,  4.624013e-04,  8.870429e-04,  9.560444e-04,\n-            8.012604e-04,  7.237180e-04,  1.963026e-04, -3.059993e-04,\n-            -4.499901e-04, -7.528977e-04, -7.926694e-04,  4.640088e-05,\n-            6.461736e-04,  1.040987e-03,  1.237046e-03,  1.172458e-03,\n-            1.288751e-03,  1.373816e-03]]),\n-        \"12.0\": torch.tensor([[ 3.565805e-04, -1.256613e-04,  1.183582e-04, -3.802291e-04,\n-            3.105091e-04,  1.865535e-04, -3.158048e-05,  6.227761e-05,\n-            5.698238e-04,  1.771630e-04, -1.315420e-03, -6.301778e-04,\n-            -1.109489e-04, -1.438975e-03,  1.272207e-04,  1.787294e-03,\n-            1.767908e-03,  1.386056e-03,  1.240669e-03,  1.263517e-03,\n-            1.145012e-03,  5.560494e-04,  3.531562e-05,  7.189781e-06,\n-            -2.154731e-05, -6.776350e-05, -1.317324e-04, -3.872732e-04,\n-            -3.627957e-04, -3.565862e-05, -3.500617e-05, -2.835042e-05,\n-            4.534650e-04,  6.828858e-04,  1.077655e-03,  1.075044e-03,\n-            8.644137e-04,  7.499007e-04,  1.920709e-04, -3.076390e-04,\n-            -4.374438e-04, -7.099393e-04, -7.090216e-04,  1.603039e-04,\n-            8.542560e-04,  1.280865e-03,  1.477922e-03,  1.395745e-03,\n-            1.525514e-03,  1.630586e-03]]),\n-        \"24.0\": torch.tensor([[ 6.521065e-04,  1.462785e-04,  4.178514e-04, -9.152008e-05,\n-            3.388160e-04,  1.948662e-04,  3.285942e-05,  4.549955e-05,\n-            6.631347e-04,  5.097367e-04, -8.947809e-04, -2.004263e-04,\n-            1.424710e-04, -1.474944e-03,  2.018428e-04,  2.041453e-03,\n-            1.890756e-03,  1.319265e-03,  1.126390e-03,  1.198248e-03,\n-            1.223775e-03,  6.064996e-04,  2.491259e-06, -1.607838e-05,\n-            -3.411068e-05, -7.650320e-05, -2.201070e-04, -5.680668e-04,\n-            -4.701227e-04, -4.808547e-05, -7.972040e-05, -1.437212e-04,\n-            1.945771e-04,  3.294060e-04,  7.038435e-04,  6.572424e-04,\n-            5.256998e-04,  6.208976e-04,  1.087499e-04, -3.501410e-04,\n-            -2.960531e-04, -5.618031e-04, -5.817775e-04,  3.950241e-04,\n-            1.112244e-03,  1.454558e-03,  1.633313e-03,  1.501600e-03,\n-            1.647069e-03,  1.844205e-03]])\n+        \"1.5\": torch.tensor(\n+            [[ 0.0003, -0.0002, -0.0000, -0.0004, 0.0004, 0.0003, -0.0000, 0.0001, 0.0005, 0.0001, -0.0015, -0.0007, -0.0002, -0.0018, -0.0003, 0.0013, 0.0011, 0.0008, 0.0008, 0.0008, 0.0008, 0.0002, -0.0003, -0.0004, -0.0006, -0.0009, -0.0010, -0.0012, -0.0011, -0.0006, -0.0006, -0.0005, 0.0000, 0.0001, 0.0003, 0.0002, -0.0001, -0.0002, -0.0008, -0.0012, -0.0011, -0.0012, -0.0013, -0.0003, 0.0002, 0.0006, 0.0006, 0.0006, 0.0009, 0.0010]]\n+        ),\n+        \"3.0\": torch.tensor(\n+            [[ 0.0003, -0.0002, -0.0000, -0.0004, 0.0004, 0.0003, -0.0000, 0.0001, 0.0006, 0.0002, -0.0015, -0.0008, -0.0002, -0.0018, -0.0003, 0.0013, 0.0011, 0.0008, 0.0008, 0.0008, 0.0008, 0.0002, -0.0003, -0.0004, -0.0005, -0.0008, -0.0010, -0.0012, -0.0011, -0.0006, -0.0006, -0.0005, -0.0000, 0.0001, 0.0003, 0.0002, -0.0001, -0.0002, -0.0008, -0.0013, -0.0011, -0.0013, -0.0014, -0.0003, 0.0002, 0.0006, 0.0006, 0.0006, 0.0009, 0.0010]]\n+        ),\n+        \"6.0\": torch.tensor(\n+            [[ 0.0004, -0.0001, 0.0001, -0.0003, 0.0004, 0.0003, 0.0000, 0.0001, 0.0007, 0.0002, -0.0013, -0.0007, -0.0002, -0.0015, -0.0001, 0.0014, 0.0014, 0.0011, 0.0010, 0.0010, 0.0009, 0.0004, 0.0000, 0.0000, 0.0000, -0.0000, -0.0001, -0.0004, -0.0004, -0.0001, -0.0002, -0.0002, 0.0002, 0.0005, 0.0009, 0.0010, 0.0008, 0.0007, 0.0002, -0.0003, -0.0004, -0.0008, -0.0008, 0.0000, 0.0006, 0.0010, 0.0012, 0.0012, 0.0013, 0.0014]]\n+        ),\n+        \"12.0\": torch.tensor(\n+            [[ 0.0004, -0.0001, 0.0001, -0.0004, 0.0003, 0.0002, -0.0000, 0.0001, 0.0006, 0.0002, -0.0013, -0.0006, -0.0001, -0.0014, 0.0001, 0.0018, 0.0018, 0.0014, 0.0012, 0.0013, 0.0011, 0.0006, 0.0000, 0.0000, -0.0000, -0.0001, -0.0001, -0.0004, -0.0004, -0.0000, -0.0000, -0.0000, 0.0005, 0.0007, 0.0011, 0.0011, 0.0009, 0.0007, 0.0002, -0.0003, -0.0004, -0.0007, -0.0007, 0.0002, 0.0009, 0.0013, 0.0015, 0.0014, 0.0015, 0.0016]]\n+        ),\n+        \"24.0\": torch.tensor(\n+            [[ 0.0005, 0.0001, 0.0004, -0.0001, 0.0003, 0.0002, 0.0000, 0.0001, 0.0007, 0.0005, -0.0011, -0.0005, -0.0001, -0.0018, -0.0000, 0.0021, 0.0019, 0.0013, 0.0011, 0.0012, 0.0012, 0.0006, -0.0000, -0.0001, -0.0000, -0.0000, -0.0001, -0.0004, -0.0004, -0.0000, -0.0001, -0.0002, 0.0003, 0.0004, 0.0008, 0.0007, 0.0006, 0.0007, 0.0001, -0.0004, -0.0003, -0.0006, -0.0008, 0.0004, 0.0011, 0.0015, 0.0016, 0.0015, 0.0016, 0.0018]]\n+        )\n     },\n     \"facebook/encodec_48khz\": {\n-        \"3.0\": torch.tensor([[ 3.421399e-03,  2.767177e-03,  3.679344e-03,  4.105699e-03,\n-            2.954683e-03,  2.205276e-03,  2.080471e-03,  2.056918e-03,\n-            2.154729e-03,  2.350491e-03,  2.121290e-03,  1.820178e-03,\n-            1.905338e-03,  2.031058e-03,  1.975896e-03,  1.966428e-03,\n-            2.083673e-03,  2.299904e-03,  2.455741e-03,  2.231116e-03,\n-            1.710531e-03,  1.505401e-03,  1.740449e-03,  2.041681e-03,\n-            2.411023e-03,  3.114638e-03,  3.952288e-03,  4.527538e-03,\n-            4.587314e-03,  4.173194e-03,  3.427407e-03,  2.716710e-03,\n-            2.295787e-03,  2.228371e-03,  2.352679e-03,  2.366424e-03,\n-            2.248363e-03,  2.262248e-03,  2.448819e-03,  2.660614e-03,\n-            2.714025e-03,  2.665069e-03,  2.513370e-03,  2.362525e-03,\n-            2.399625e-03,  2.638135e-03,  2.804853e-03,  2.678576e-03,\n-            2.367081e-03,  2.178720e-03],\n-            [-3.063047e-03, -2.638480e-03, -1.766547e-03, -1.701481e-03,\n-            -2.411626e-03, -2.900740e-03, -2.973366e-03, -2.590348e-03,\n-            -2.133189e-03, -1.788050e-03, -1.816614e-03, -1.865663e-03,\n-            -1.691747e-03, -1.395518e-03, -1.162460e-03, -1.018245e-03,\n-            -8.084248e-04, -3.690177e-04, -6.121923e-05, -4.288579e-04,\n-            -1.177161e-03, -1.501295e-03, -1.437047e-03, -1.317845e-03,\n-            -1.043418e-03, -4.573818e-04,  2.442654e-04,  7.509330e-04,\n-            8.065446e-04,  4.348168e-04, -2.790179e-04, -9.373407e-04,\n-            -1.221163e-03, -1.132101e-03, -9.305986e-04, -8.578329e-04,\n-            -8.647345e-04, -7.599542e-04, -5.832259e-04, -4.528739e-04,\n-            -4.498020e-04, -4.891171e-04, -6.177537e-04, -7.899741e-04,\n-            -8.085046e-04, -6.180131e-04, -5.291702e-04, -7.121218e-04,\n-            -1.025226e-03, -1.194155e-03]]),\n-        \"6.0\": torch.tensor([[ 5.183834e-03,  4.922199e-03,  5.712765e-03,  5.767826e-03,\n-            4.764559e-03,  4.272173e-03,  4.187430e-03,  4.126165e-03,\n-            4.070717e-03,  4.158136e-03,  4.004896e-03,  3.798555e-03,\n-            3.818621e-03,  3.807201e-03,  3.731028e-03,  3.691535e-03,\n-            3.679592e-03,  3.702547e-03,  3.755184e-03,  3.697157e-03,\n-            3.442832e-03,  3.343916e-03,  3.587424e-03,  3.915675e-03,\n-            4.244468e-03,  4.730398e-03,  5.294672e-03,  5.685351e-03,\n-            5.719899e-03,  5.452487e-03,  4.998159e-03,  4.573921e-03,\n-            4.255848e-03,  4.113816e-03,  4.152164e-03,  4.156371e-03,\n-            4.076165e-03,  4.054819e-03,  4.161702e-03,  4.308389e-03,\n-            4.327485e-03,  4.268819e-03,  4.130954e-03,  4.022694e-03,\n-            4.025757e-03,  4.111586e-03,  4.196581e-03,  4.163777e-03,\n-            4.013349e-03,  3.859121e-03],\n-            [ 9.986385e-05,  6.035285e-04,  1.278289e-03,  1.103130e-03,\n-            5.065203e-04,  1.420692e-04, -5.583515e-05,  1.171659e-04,\n-            3.325473e-04,  5.255137e-04,  5.093975e-04,  4.916678e-04,\n-            5.654445e-04,  6.826124e-04,  8.327903e-04,  9.292346e-04,\n-            1.025232e-03,  1.269074e-03,  1.494992e-03,  1.367540e-03,\n-            9.706235e-04,  8.264333e-04,  9.686989e-04,  1.189562e-03,\n-            1.478643e-03,  1.854350e-03,  2.276287e-03,  2.610488e-03,\n-            2.642312e-03,  2.402747e-03,  1.961545e-03,  1.555783e-03,\n-            1.330312e-03,  1.307877e-03,  1.400181e-03,  1.455139e-03,\n-            1.481637e-03,  1.551525e-03,  1.653218e-03,  1.722582e-03,\n-            1.685665e-03,  1.614454e-03,  1.477865e-03,  1.344581e-03,\n-            1.283732e-03,  1.309977e-03,  1.310035e-03,  1.202490e-03,\n-            1.025640e-03,  8.722545e-04]]),\n-        \"12.0\": torch.tensor([[ 1.417050e-03,  1.195599e-03,  2.148881e-03,  2.430070e-03,\n-            1.667009e-03,  1.319421e-03,  1.218356e-03,  1.110883e-03,\n-            1.099051e-03,  1.238893e-03,  1.155451e-03,  9.674123e-04,\n-            9.350046e-04,  8.997207e-04,  8.409658e-04,  8.443243e-04,\n-            8.905136e-04,  1.015474e-03,  1.172707e-03,  1.157671e-03,\n-            9.229409e-04,  8.257366e-04,  1.024314e-03,  1.340962e-03,\n-            1.755373e-03,  2.399419e-03,  3.118549e-03,  3.603548e-03,\n-            3.644178e-03,  3.300740e-03,  2.771868e-03,  2.328330e-03,\n-            2.058953e-03,  2.020736e-03,  2.163280e-03,  2.253478e-03,\n-            2.219024e-03,  2.207887e-03,  2.285866e-03,  2.393416e-03,\n-            2.388977e-03,  2.294205e-03,  2.154690e-03,  2.082772e-03,\n-            2.143109e-03,  2.311750e-03,  2.459197e-03,  2.437135e-03,\n-            2.246915e-03,  2.068990e-03],\n-            [-3.375588e-03, -2.897897e-03, -2.025333e-03, -1.962973e-03,\n-            -2.388406e-03, -2.702280e-03, -2.997186e-03, -2.935561e-03,\n-            -2.737680e-03, -2.520869e-03, -2.479992e-03, -2.513727e-03,\n-            -2.525166e-03, -2.464779e-03, -2.324497e-03, -2.187293e-03,\n-            -2.016043e-03, -1.649815e-03, -1.302245e-03, -1.357212e-03,\n-            -1.714788e-03, -1.859774e-03, -1.743472e-03, -1.504268e-03,\n-            -1.121202e-03, -5.718216e-04,  2.681626e-05,  4.638432e-04,\n-            4.985461e-04,  1.769693e-04, -3.378438e-04, -7.619419e-04,\n-            -9.499526e-04, -8.920243e-04, -7.171941e-04, -5.944666e-04,\n-            -5.548476e-04, -5.183255e-04, -4.699390e-04, -4.465780e-04,\n-            -5.256415e-04, -6.554916e-04, -8.091091e-04, -8.993596e-04,\n-            -8.751084e-04, -7.542582e-04, -6.850655e-04, -7.684064e-04,\n-            -9.683588e-04, -1.120312e-03]]),\n-        \"24.0\": torch.tensor([[ 1.015330e-03,  7.517930e-04,  1.750802e-03,  2.059409e-03,\n-            1.387880e-03,  1.055567e-03,  8.877711e-04,  7.357977e-04,\n-            5.890218e-04,  5.826160e-04,  4.915163e-04,  3.416525e-04,\n-            2.642466e-04,  1.622533e-04,  8.463636e-05,  6.309848e-05,\n-            9.271067e-05,  1.569983e-04,  1.916545e-04,  7.911284e-05,\n-            -2.259081e-04, -4.107158e-04, -2.825049e-04,  4.928968e-05,\n-            5.086431e-04,  1.120238e-03,  1.779455e-03,  2.203519e-03,\n-            2.164778e-03,  1.761619e-03,  1.199984e-03,  7.168681e-04,\n-            3.980001e-04,  3.086457e-04,  4.383908e-04,  5.838434e-04,\n-            6.371416e-04,  6.650661e-04,  7.486284e-04,  8.544383e-04,\n-            8.188231e-04,  6.707238e-04,  4.971933e-04,  4.102938e-04,\n-            4.446815e-04,  5.581054e-04,  6.658332e-04,  6.565506e-04,\n-            5.135337e-04,  3.599684e-04],\n-            [-3.854680e-03, -3.501036e-03, -2.705938e-03, -2.560762e-03,\n-            -2.802748e-03, -3.067505e-03, -3.441265e-03, -3.461784e-03,\n-            -3.374955e-03, -3.247010e-03, -3.211432e-03, -3.182278e-03,\n-            -3.126218e-03, -3.045159e-03, -2.912694e-03, -2.791017e-03,\n-            -2.635398e-03, -2.349891e-03, -2.093153e-03, -2.119673e-03,\n-            -2.396084e-03, -2.523703e-03, -2.396373e-03, -2.087480e-03,\n-            -1.643065e-03, -1.122686e-03, -6.005570e-04, -2.057775e-04,\n-            -1.537185e-04, -4.185138e-04, -8.705640e-04, -1.277440e-03,\n-            -1.510734e-03, -1.531543e-03, -1.400770e-03, -1.251901e-03,\n-            -1.146744e-03, -1.067357e-03, -1.001837e-03, -9.721050e-04,\n-            -1.060992e-03, -1.216881e-03, -1.376308e-03, -1.456002e-03,\n-            -1.448194e-03, -1.379923e-03, -1.339557e-03, -1.399116e-03,\n-            -1.560851e-03, -1.712047e-03]])\n+        \"3.0\": torch.tensor(\n+            [\n+                [0.0034, 0.0028, 0.0037, 0.0041, 0.0029, 0.0022, 0.0021, 0.0020, 0.0021, 0.0023, 0.0021, 0.0018, 0.0019, 0.0020, 0.0020, 0.0020, 0.0021, 0.0023, 0.0025, 0.0022, 0.0017, 0.0015, 0.0017, 0.0020, 0.0024, 0.0031, 0.0039, 0.0045, 0.0046, 0.0042, 0.0034, 0.0027, 0.0023, 0.0022, 0.0023, 0.0024, 0.0022, 0.0023, 0.0024, 0.0027, 0.0027, 0.0027, 0.0025, 0.0024, 0.0024, 0.0026, 0.0028, 0.0027, 0.0024, 0.0022],\n+                [ -0.0031, -0.0027, -0.0018, -0.0017, -0.0024, -0.0029, -0.0030, -0.0026, -0.0021, -0.0018, -0.0018, -0.0019, -0.0017, -0.0014, -0.0012, -0.0010, -0.0008, -0.0004, -0.0001, -0.0004, -0.0012, -0.0015, -0.0014, -0.0013, -0.0011, -0.0005, 0.0002, 0.0007, 0.0008, 0.0004, -0.0003, -0.0010, -0.0012, -0.0011, -0.0009, -0.0009, -0.0009, -0.0008, -0.0006, -0.0005, -0.0005, -0.0005, -0.0006, -0.0008, -0.0008, -0.0006, -0.0005, -0.0007, -0.0010, -0.0012],\n+            ]\n+        ),\n+        \"6.0\": torch.tensor(\n+            [\n+                [0.0052, 0.0049, 0.0057, 0.0058, 0.0048, 0.0043, 0.0042, 0.0041, 0.0041, 0.0042, 0.0040, 0.0038, 0.0038, 0.0038, 0.0037, 0.0037, 0.0037, 0.0037, 0.0038, 0.0037, 0.0035, 0.0034, 0.0036, 0.0039, 0.0043, 0.0047, 0.0053, 0.0057, 0.0057, 0.0055, 0.0050, 0.0046, 0.0043, 0.0041, 0.0042, 0.0042, 0.0041, 0.0041, 0.0042, 0.0043, 0.0043, 0.0043, 0.0041, 0.0040, 0.0040, 0.0041, 0.0042, 0.0042, 0.0040, 0.0039],\n+                [ 0.0001, 0.0006, 0.0013, 0.0011, 0.0005, 0.0001, -0.0001, 0.0001, 0.0003, 0.0005, 0.0005, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.0010, 0.0013, 0.0015, 0.0014, 0.0010, 0.0008, 0.0010, 0.0012, 0.0015, 0.0019, 0.0023, 0.0026, 0.0026, 0.0024, 0.0020, 0.0016, 0.0013, 0.0013, 0.0014, 0.0015, 0.0015, 0.0016, 0.0017, 0.0017, 0.0017, 0.0016, 0.0015, 0.0013, 0.0013, 0.0013, 0.0013, 0.0012, 0.0010, 0.0009],\n+            ]\n+        ),\n+        \"12.0\": torch.tensor(\n+            [\n+                [0.0014, 0.0012, 0.0021, 0.0024, 0.0017, 0.0013, 0.0012, 0.0011, 0.0011, 0.0012, 0.0011, 0.0010, 0.0009, 0.0009, 0.0008, 0.0008, 0.0009, 0.0010, 0.0012, 0.0012, 0.0009, 0.0008, 0.0010, 0.0013, 0.0017, 0.0024, 0.0031, 0.0036, 0.0036, 0.0033, 0.0028, 0.0023, 0.0020, 0.0020, 0.0022, 0.0022, 0.0022, 0.0022, 0.0023, 0.0024, 0.0024, 0.0023, 0.0021, 0.0021, 0.0021, 0.0023, 0.0024, 0.0024, 0.0022, 0.0021],\n+                [ -0.0034, -0.0029, -0.0020, -0.0020, -0.0024, -0.0027, -0.0030, -0.0030, -0.0028, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0023, -0.0022, -0.0020, -0.0017, -0.0013, -0.0014, -0.0017, -0.0019, -0.0018, -0.0015, -0.0011, -0.0006, 0.0000, 0.0005, 0.0005, 0.0002, -0.0003, -0.0008, -0.0010, -0.0009, -0.0007, -0.0006, -0.0006, -0.0005, -0.0005, -0.0005, -0.0005, -0.0007, -0.0008, -0.0009, -0.0009, -0.0008, -0.0007, -0.0008, -0.0010, -0.0011],\n+            ]\n+        ),\n+        \"24.0\": torch.tensor(\n+            [\n+                [ 0.0010, 0.0008, 0.0018, 0.0021, 0.0014, 0.0011, 0.0009, 0.0007, 0.0006, 0.0006, 0.0005, 0.0003, 0.0003, 0.0002, 0.0001, 0.0001, 0.0001, 0.0002, 0.0002, 0.0001, -0.0002, -0.0004, -0.0003, 0.0000, 0.0005, 0.0011, 0.0018, 0.0022, 0.0022, 0.0018, 0.0012, 0.0007, 0.0004, 0.0003, 0.0004, 0.0006, 0.0006, 0.0007, 0.0007, 0.0009, 0.0008, 0.0007, 0.0005, 0.0004, 0.0004, 0.0006, 0.0007, 0.0007, 0.0005, 0.0004],\n+                [-0.0039, -0.0035, -0.0027, -0.0026, -0.0028, -0.0031, -0.0035, -0.0035, -0.0034, -0.0033, -0.0032, -0.0032, -0.0031, -0.0031, -0.0029, -0.0028, -0.0026, -0.0024, -0.0021, -0.0021, -0.0024, -0.0025, -0.0024, -0.0021, -0.0017, -0.0011, -0.0006, -0.0002, -0.0002, -0.0004, -0.0009, -0.0013, -0.0015, -0.0015, -0.0014, -0.0013, -0.0012, -0.0011, -0.0010, -0.0010, -0.0011, -0.0012, -0.0014, -0.0015, -0.0015, -0.0014, -0.0013, -0.0014, -0.0016, -0.0017],\n+            ]\n+        )\n     }\n }\n EXPECTED_CODEC_ERROR = {\n     \"facebook/encodec_24khz\": {\n         \"1.5\": 0.0022229827009141445,\n         \"3.0\": 0.001862662611529231,\n         \"6.0\": 0.0015231302240863442,\n-        \"12.0\": 0.0013085737591609359,\n-        \"24.0\": 0.001231506816111505,\n+        \"12.0\": 0.0013,\n+        \"24.0\": 0.0012,\n     },\n     \"facebook/encodec_48khz\": {\n         \"3.0\": 0.000840399123262614,\n@@ -785,130 +680,187 @@ def compute_rmse(arr1, arr2):\n # -- test_batch\n EXPECTED_ENCODER_CODES_BATCH = {\n     \"facebook/encodec_24khz\": {\n-        \"1.5\": torch.tensor([[[  62,  106,  475,  475,  404,  404,  475,  404,  404,  475],\n-            [ 424,  969,  913, 1007,  544, 1007, 1007, 1007,  969, 1007]],\n-            [[ 835,  835,  835,  835,  835,  835,  835,  835,  835,  835],\n-            [ 857,  857,  544,  518,  937,  518,  913,  913,  518,  913]]]),\n-        \"3.0\": torch.tensor([[[  62,  106,  475,  475,  404,  404,  475,  404,  404,  475],\n-            [ 424,  969,  913, 1007,  544, 1007, 1007, 1007,  969, 1007],\n-            [ 212,  832,  212,   36,   36,   36,  767,  653,  982, 1016],\n-            [ 956,  741,  838, 1019,  739,  780,  838, 1019, 1014, 1019]],\n-            [[ 835,  835,  835,  835,  835,  835,  835,  835,  835,  835],\n-            [ 857,  857,  544,  518,  937,  518,  913,  913,  518,  913],\n-            [ 705,  989,  934,  821,  678,  934,  934,  786,  934,  786],\n-            [ 366, 1018,  398,  398,  398,  398,  673,  741,  398,  741]]]),\n-        \"6.0\": torch.tensor([[[  62,  106,  475,  475,  404,  404,  475,  404,  404,  475],\n-            [ 424,  969,  913, 1007,  544, 1007, 1007, 1007,  969, 1007],\n-            [ 212,  832,  212,   36,   36,   36,  767,  653,  982, 1016],\n-            [ 956,  741,  838, 1019,  739,  780,  838, 1019, 1014, 1019],\n-            [ 712,  862,  712,  448,  528,  646,  446,  373,  694,  373],\n-            [ 939,  881,  939,   19,  334,  881, 1005,  763,  632,  781],\n-            [ 853,  464,  772,  782,  782,  983,  890,  874,  983,  782],\n-            [ 899,  475,  173,  701,  701,  947,  468, 1019,  882,  518]],\n-            [[ 835,  835,  835,  835,  835,  835,  835,  835,  835,  835],\n-            [ 857,  857,  544,  518,  937,  518,  913,  913,  518,  913],\n-            [ 705,  989,  934,  821,  678,  934,  934,  786,  934,  786],\n-            [ 366, 1018,  398,  398,  398,  398,  673,  741,  398,  741],\n-            [ 373,  373,  375,  373,  373,  222,  862,  373,  190,  373],\n-            [ 293,  949,  435,  140,  435,  293,  949,  881,  632,  986],\n-            [ 800,  528,  528,  853,  782,  485,  772,  900,  528,  853],\n-            [ 916,  237,  828,  948,  518,  835,  948,  315,  948,  315]]]),\n-        \"12.0\": torch.tensor([[[  62,  106,  475,  475,  404,  404,  475,  404,  404,  475],\n-            [ 424,  969,  913, 1007,  544, 1007, 1007, 1007,  969, 1007],\n-            [ 212,  832,  212,   36,   36,   36,  767,  653,  982, 1016],\n-            [ 956,  741,  838, 1019,  739,  780,  838, 1019, 1014, 1019],\n-            [ 712,  862,  712,  448,  528,  646,  446,  373,  694,  373],\n-            [ 939,  881,  939,   19,  334,  881, 1005,  763,  632,  781],\n-            [ 853,  464,  772,  782,  782,  983,  890,  874,  983,  782],\n-            [ 899,  475,  173,  701,  701,  947,  468, 1019,  882,  518],\n-            [ 817,  470,  588,  675,  675,  588,  960,  927,  909,  466],\n-            [ 953,  776,  717,  630,  359,  717,  861,  630,  861,  359],\n-            [ 623,  740, 1000,  388,  420,  388,  740,  818,  958,  743],\n-            [ 413,  835,  742,  249,  892,  352,  190,  498,  866,  890],\n-            [ 817,  486,  804,  751,  938,  535,  434,  879,  351,  971],\n-            [ 792,  495,  935,  848,  792,  795,  942,  935,  723,  531],\n-            [ 622,  681,  477,  906,  752,  871,  713,  514,  993,  777],\n-            [ 928,  799,  962, 1005,  860,  439,  312,  922,  982,  922]],\n-            [[ 835,  835,  835,  835,  835,  835,  835,  835,  835,  835],\n-            [ 857,  857,  544,  518,  937,  518,  913,  913,  518,  913],\n-            [ 705,  989,  934,  821,  678,  934,  934,  786,  934,  786],\n-            [ 366, 1018,  398,  398,  398,  398,  673,  741,  398,  741],\n-            [ 373,  373,  375,  373,  373,  222,  862,  373,  190,  373],\n-            [ 293,  949,  435,  140,  435,  293,  949,  881,  632,  986],\n-            [ 800,  528,  528,  853,  782,  485,  772,  900,  528,  853],\n-            [ 916,  237,  828,  948,  518,  835,  948,  315,  948,  315],\n-            [ 420,  628,  918,  628,  628,  628,  248,  628,  909,  811],\n-            [ 736,  717,  994,  974,  477,  874,  963,  979,  355,  979],\n-            [1002, 1002,  894,  709,  388,  709,  534,  408,  881,  709],\n-            [ 735,  828,  763,  742,  640,  835,  828,  375,  840,  375],\n-            [ 898,  938,  556,  658,  410,  951,  486,  658,  877,  877],\n-            [   0,  797,  428,  694,  428,  920, 1022, 1022,  809,  797],\n-            [ 622,  421,  422,  911,  911,  911,  958,  421,  776,  421],\n-            [1005,  312,  922,  755,  834,  461,  461,  702,  597,  974]]]),\n-        \"24.0\": torch.tensor([[[  62,  106,  475,  475,  404,  404,  475,  404,  404,  475],\n-            [ 424,  969,  913, 1007,  544, 1007, 1007, 1007,  969, 1007],\n-            [ 212,  832,  212,   36,   36,   36,  767,  653,  982, 1016],\n-            [ 956,  741,  838, 1019,  739,  780,  838, 1019, 1014, 1019],\n-            [ 712,  862,  712,  448,  528,  646,  446,  373,  694,  373],\n-            [ 939,  881,  939,   19,  334,  881, 1005,  763,  632,  781],\n-            [ 853,  464,  772,  782,  782,  983,  890,  874,  983,  782],\n-            [ 899,  475,  173,  701,  701,  947,  468, 1019,  882,  518],\n-            [ 817,  470,  588,  675,  675,  588,  960,  927,  909,  466],\n-            [ 953,  776,  717,  630,  359,  717,  861,  630,  861,  359],\n-            [ 623,  740, 1000,  388,  420,  388,  740,  818,  958,  743],\n-            [ 413,  835,  742,  249,  892,  352,  190,  498,  866,  890],\n-            [ 817,  486,  804,  751,  938,  535,  434,  879,  351,  971],\n-            [ 792,  495,  935,  848,  792,  795,  942,  935,  723,  531],\n-            [ 622,  681,  477,  906,  752,  871,  713,  514,  993,  777],\n-            [ 928,  799,  962, 1005,  860,  439,  312,  922,  982,  922],\n-            [ 939,  637,  861,  160,  861,   61,  475,  264, 1019,  260],\n-            [ 166,   69,   69,  839,  890,   69,  284,  828,  396,  180],\n-            [ 561,  696,  841,  144,  580,  659,  886,  514,  686,  451],\n-            [ 691,  691,  239,  239,   62,  287,  383,  972,  550,  505],\n-            [ 451,  486,  238,  295,  250,  841,  734,  329,  551,  846],\n-            [ 313,  639,  494,  784,  811,  565,  748,  441,  601,  480],\n-            [ 653,  609,  630,  807,  701,  973,  632,  374,  561,  521],\n-            [ 984,  745,  419,  635,  386,  507,  532,  636,  515,  671],\n-            [ 647,  491,  515,  677,  876, 1011,  719,  549,  691,  911],\n-            [ 683,  995,  656,  716,  698,  867,  987,  857,  886,  491],\n-            [ 444,  620,  826,  613,  585,  710,  466,  852,  655,  591],\n-            [ 658,  310,  903,  778,  739,  596,  420,  721,  464,  306],\n-            [ 665,  957,  765,  270,  618,  278,  836,  838,  517,  597],\n-            [ 613,  689,  596,  775,  987,  977,  938,  739,  672,  776],\n-            [ 689,  417,  749,  314,  250,  869,  957,  806,  750,  659],\n-            [ 652,  819,  910,  868,  566,  622,  951,  477,  900,  895]],\n-            [[ 835,  835,  835,  835,  835,  835,  835,  835,  835,  835],\n-            [ 857,  857,  544,  518,  937,  518,  913,  913,  518,  913],\n-            [ 705,  989,  934,  821,  678,  934,  934,  786,  934,  786],\n-            [ 366, 1018,  398,  398,  398,  398,  673,  741,  398,  741],\n-            [ 373,  373,  375,  373,  373,  222,  862,  373,  190,  373],\n-            [ 293,  949,  435,  140,  435,  293,  949,  881,  632,  986],\n-            [ 800,  528,  528,  853,  782,  485,  772,  900,  528,  853],\n-            [ 916,  237,  828,  948,  518,  835,  948,  315,  948,  315],\n-            [ 420,  628,  918,  628,  628,  628,  248,  628,  909,  811],\n-            [ 736,  717,  994,  974,  477,  874,  963,  979,  355,  979],\n-            [1002, 1002,  894,  709,  388,  709,  534,  408,  881,  709],\n-            [ 735,  828,  763,  742,  640,  835,  828,  375,  840,  375],\n-            [ 898,  938,  556,  658,  410,  951,  486,  658,  877,  877],\n-            [   0,  797,  428,  694,  428,  920, 1022, 1022,  809,  797],\n-            [ 622,  421,  422,  911,  911,  911,  958,  421,  776,  421],\n-            [1005,  312,  922,  755,  834,  461,  461,  702,  597,  974],\n-            [ 248,  248,  637,  248,  977,  506,  546,  270,  670,  506],\n-            [ 547,  447,   15,   15, 1009,  215,  134,  396,  260,  160],\n-            [ 635,  497,  686,  765,  264,  497,  244,  675,  624,  656],\n-            [ 864,  571,  616,  511,  588,  781,  525,  258,  674,  503],\n-            [ 449,  757,  857,  630,  658,  486,  299,  299,  251,  596],\n-            [ 809,  628,  255,  505,  623,  301,  639,  546,  617,  623],\n-            [ 551,  497,  908,  640,  661,  710,  640,  539,  646,  315],\n-            [ 689,  507,  875,  582,  613,  637,  527,  515,  662,  637],\n-            [ 983,  686,  456,  768,  601,  561,  768,  653,  500,  688],\n-            [ 493,  566,  664,  505,  683,  683,  721,  603,  323,  497],\n-            [1015,  552,  411,  963,  607,  646,  687, 1018,  689,  607],\n-            [ 516,  293,  471,  294,  293,  294,  608,  538,  803,  717],\n-            [ 974,  994,  952, 1013,  637,  927,  535,  571,  602,  535],\n-            [ 776,  789,  476,  652,  652,  959,  589,  679,  321,  623],\n-            [ 776,  931,  952,  670,  676,  731,  386,  676,  701,  676],\n-            [ 684,  543, 1007,  567,  661,  517,  792,  588,  922,  676]]])\n+        \"1.5\": torch.tensor(\n+            [\n+                [\n+                    [62, 106, 475, 475, 404, 404, 475, 404, 404, 475, 475, 404, 475, 475, 475, 835, 475, 475, 835, 835,\n+                     106, 106, 738, 106, 738, 106, 408, 408, 738, 408, 408, 408, 738, 408, 408, 408, 408, 738, 408,\n+                     1017, 604, 64, 303, 394, 5, 570, 991, 570, 969, 814],\n+                    [424, 969, 913, 1007, 544, 1007, 1007, 1007, 969, 1007, 729, 1007, 961, 1007, 1007, 961, 969, 1007,\n+                     1007, 424, 518, 1007, 544, 1007, 518, 913, 424, 424, 544, 424, 518, 518, 518, 302, 424, 424, 424,\n+                     544, 424, 114, 200, 787, 931, 343, 434, 315, 487, 872, 769, 463],\n+\n+                ],\n+                [\n+                    [835, 835, 835, 835, 835, 835, 835, 835, 835, 835, 835, 835, 408, 835, 738, 408, 408, 408, 408, 408,\n+                     408, 738, 408, 408, 408, 408, 408, 408, 408, 408, 738, 408, 408, 408, 408, 408, 408, 408, 408, 408,\n+                     339, 834, 819, 875, 957, 670, 811, 670, 237, 53],\n+                    [857, 857, 544, 518, 937, 518, 913, 913, 518, 913, 518, 913, 518, 518, 544, 424, 424, 518, 424, 424,\n+                     424, 544, 424, 424, 424, 518, 424, 518, 518, 937, 544, 424, 518, 302, 518, 424, 424, 518, 424, 424,\n+                     913, 857, 841, 363, 463, 78, 176, 645, 255, 571],\n+\n+                ],\n+\n+            ]\n+\n+        ),\n+        \"3.0\": torch.tensor(\n+            [\n+                [\n+                    [62, 106, 475, 475, 404, 404, 475, 404, 404, 475],\n+                    [424, 969, 913, 1007, 544, 1007, 1007, 1007, 969, 1007],\n+                    [212, 832, 212, 36, 36, 36, 767, 653, 982, 1016],\n+                    [956, 741, 838, 1019, 739, 780, 838, 1019, 1014, 1019],\n+\n+                ],\n+                [\n+                    [835, 835, 835, 835, 835, 835, 835, 835, 835, 835],\n+                    [857, 857, 544, 518, 937, 518, 913, 913, 518, 913],\n+                    [705, 989, 934, 989, 678, 934, 934, 786, 934, 786],\n+                    [366, 1018, 398, 398, 398, 398, 673, 741, 398, 741],\n+\n+                ],\n+            ]\n+        ),\n+        \"6.0\": torch.tensor(\n+            [\n+                [\n+                    [62, 106, 475, 475, 404, 404, 475, 404, 404, 475],\n+                    [424, 969, 913, 1007, 544, 1007, 1007, 1007, 969, 1007],\n+                    [212, 832, 212, 36, 36, 36, 767, 653, 982, 1016],\n+                    [956, 741, 838, 1019, 739, 780, 838, 1019, 1014, 1019],\n+                    [712, 862, 712, 448, 528, 646, 446, 373, 694, 373],\n+                    [939, 881, 939, 19, 334, 881, 1005, 763, 632, 781],\n+                    [853, 464, 772, 782, 782, 983, 890, 874, 983, 782],\n+                    [899, 475, 173, 701, 701, 947, 468, 1019, 882, 518],\n+\n+                ],\n+                [\n+                    [835, 835, 835, 835, 835, 835, 835, 835, 835, 835],\n+                    [857, 857, 544, 518, 937, 518, 913, 913, 518, 913],\n+                    [705, 989, 934, 989, 678, 934, 934, 786, 934, 786],\n+                    [366, 1018, 398, 398, 398, 398, 673, 741, 398, 741],\n+                    [373, 373, 375, 373, 373, 222, 862, 373, 190, 373],\n+                    [293, 949, 435, 435, 435, 293, 949, 881, 632, 986],\n+                    [800, 528, 528, 853, 782, 485, 772, 900, 528, 853],\n+                    [916, 237, 828, 701, 518, 835, 948, 315, 948, 315],\n+\n+                ],\n+            ]\n+        ),\n+        \"12.0\": torch.tensor(\n+            [\n+                [\n+                    [62, 106, 475, 475, 404, 404, 475, 404, 404, 475],\n+                    [424, 969, 913, 1007, 544, 1007, 1007, 1007, 969, 1007],\n+                    [212, 832, 212, 36, 36, 36, 767, 653, 982, 1016],\n+                    [956, 741, 838, 1019, 739, 780, 838, 1019, 1014, 1019],\n+                    [712, 862, 712, 448, 528, 646, 446, 373, 694, 373],\n+                    [939, 881, 939, 19, 334, 881, 1005, 763, 632, 781],\n+                    [853, 464, 772, 782, 782, 983, 890, 874, 983, 782],\n+                    [899, 475, 173, 701, 701, 947, 468, 1019, 882, 518],\n+                    [817, 470, 588, 675, 675, 588, 960, 927, 909, 466],\n+                    [953, 776, 717, 630, 359, 717, 861, 630, 861, 359],\n+                    [623, 740, 1000, 388, 420, 388, 740, 818, 958, 743],\n+                    [413, 835, 742, 249, 892, 352, 190, 498, 866, 890],\n+                    [817, 351, 804, 751, 938, 535, 434, 879, 351, 971],\n+                    [792, 495, 935, 848, 792, 795, 942, 935, 723, 531],\n+                    [622, 681, 477, 713, 752, 871, 713, 514, 993, 777],\n+                    [928, 799, 962, 1005, 860, 439, 312, 922, 982, 922],\n+                ],\n+                [\n+                    [835, 835, 835, 835, 835, 835, 835, 835, 835, 835],\n+                    [857, 857, 544, 518, 937, 518, 913, 913, 518, 913],\n+                    [705, 989, 934, 989, 678, 934, 934, 786, 934, 786],\n+                    [366, 1018, 398, 398, 398, 398, 673, 741, 398, 741],\n+                    [373, 373, 375, 373, 373, 222, 862, 373, 190, 373],\n+                    [293, 949, 435, 435, 435, 293, 949, 881, 632, 986],\n+                    [800, 528, 528, 853, 782, 485, 772, 900, 528, 853],\n+                    [916, 237, 828, 701, 518, 835, 948, 315, 948, 315],\n+                    [420, 628, 918, 628, 628, 628, 248, 628, 909, 811],\n+                    [736, 717, 994, 974, 477, 874, 963, 979, 355, 979],\n+                    [1002, 1002, 894, 875, 388, 709, 534, 408, 881, 709],\n+                    [735, 828, 763, 742, 640, 835, 828, 375, 840, 375],\n+                    [898, 938, 556, 658, 410, 951, 486, 658, 877, 877],\n+                    [ 0, 797, 428, 694, 428, 920, 1022, 1022, 809, 797],\n+                    [622, 421, 422, 776, 911, 911, 958, 421, 776, 421],\n+                    [1005, 312, 922, 755, 834, 461, 461, 702, 597, 974],\n+\n+                ],\n+            ]\n+        ),\n+        \"24.0\": torch.tensor(\n+            [\n+                [\n+                    [62, 106, 475, 475, 404, 404, 475, 404, 404, 475],\n+                    [424, 969, 913, 1007, 544, 1007, 1007, 1007, 969, 1007],\n+                    [212, 832, 212, 36, 36, 36, 767, 653, 982, 1016],\n+                    [956, 741, 838, 1019, 739, 780, 838, 1019, 1014, 1019],\n+                    [712, 862, 712, 448, 528, 646, 446, 373, 694, 373],\n+                    [939, 881, 939, 19, 334, 881, 1005, 763, 632, 781],\n+                    [853, 464, 772, 782, 782, 983, 890, 874, 983, 782],\n+                    [899, 475, 173, 701, 701, 947, 468, 1019, 882, 518],\n+                    [817, 470, 588, 675, 675, 588, 960, 927, 909, 466],\n+                    [953, 776, 717, 630, 359, 717, 861, 630, 861, 359],\n+                    [623, 740, 1000, 388, 420, 388, 740, 818, 958, 743],\n+                    [413, 835, 742, 249, 892, 352, 190, 498, 866, 890],\n+                    [817, 351, 804, 751, 938, 535, 434, 879, 351, 971],\n+                    [792, 495, 935, 848, 792, 795, 942, 935, 723, 531],\n+                    [622, 681, 477, 713, 752, 871, 713, 514, 993, 777],\n+                    [928, 799, 962, 1005, 860, 439, 312, 922, 982, 922],\n+                    [939, 637, 861, 506, 861, 61, 475, 264, 1019, 260],\n+                    [166, 215, 69, 69, 890, 69, 284, 828, 396, 180],\n+                    [561, 896, 841, 144, 580, 659, 886, 514, 686, 451],\n+                    [691, 691, 239, 735, 62, 287, 383, 972, 550, 505],\n+                    [451, 811, 238, 251, 250, 841, 734, 329, 551, 846],\n+                    [313, 601, 494, 763, 811, 565, 748, 441, 601, 480],\n+                    [653, 242, 630, 572, 701, 973, 632, 374, 561, 521],\n+                    [984, 987, 419, 454, 386, 507, 532, 636, 515, 671],\n+                    [647, 550, 515, 292, 876, 1011, 719, 549, 691, 911],\n+                    [683, 536, 656, 603, 698, 867, 987, 857, 886, 491],\n+                    [444, 937, 826, 555, 585, 710, 466, 852, 655, 591],\n+                    [658, 952, 903, 508, 739, 596, 420, 721, 464, 306],\n+                    [665, 334, 765, 532, 618, 278, 836, 838, 517, 597],\n+                    [613, 674, 596, 904, 987, 977, 938, 615, 672, 776],\n+                    [689, 386, 749, 658, 250, 869, 957, 806, 750, 659],\n+                    [652, 509, 910, 826, 566, 622, 951, 696, 900, 895],\n+                ],\n+                [\n+                    [835, 835, 835, 835, 835, 835, 835, 835, 835, 835],\n+                    [857, 857, 544, 518, 937, 518, 913, 913, 518, 913],\n+                    [705, 989, 934, 989, 678, 934, 934, 786, 934, 786],\n+                    [366, 1018, 398, 398, 398, 398, 673, 741, 398, 741],\n+                    [373, 373, 375, 373, 373, 222, 862, 373, 190, 373],\n+                    [293, 949, 435, 435, 435, 293, 949, 881, 632, 986],\n+                    [800, 528, 528, 853, 782, 485, 772, 900, 528, 853],\n+                    [916, 237, 828, 701, 518, 835, 948, 315, 948, 315],\n+                    [420, 628, 918, 628, 628, 628, 248, 628, 909, 811],\n+                    [736, 717, 994, 974, 477, 874, 963, 979, 355, 979],\n+                    [1002, 1002, 894, 875, 388, 709, 534, 408, 881, 709],\n+                    [735, 828, 763, 742, 640, 835, 828, 375, 840, 375],\n+                    [898, 938, 556, 658, 410, 951, 486, 658, 877, 877],\n+                    [ 0, 797, 428, 694, 428, 920, 1022, 1022, 809, 797],\n+                    [622, 421, 422, 776, 911, 911, 958, 421, 776, 421],\n+                    [1005, 312, 922, 755, 834, 461, 461, 702, 597, 974],\n+                    [248, 248, 637, 248, 977, 506, 546, 270, 670, 506],\n+                    [547, 447, 15, 134, 1009, 215, 134, 396, 260, 160],\n+                    [635, 497, 686, 765, 264, 497, 244, 675, 624, 656],\n+                    [864, 571, 616, 511, 588, 781, 525, 258, 674, 503],\n+                    [449, 757, 857, 451, 658, 486, 299, 299, 251, 596],\n+                    [809, 628, 255, 568, 623, 301, 639, 546, 617, 623],\n+                    [551, 497, 908, 539, 661, 710, 640, 539, 646, 315],\n+                    [689, 507, 875, 515, 613, 637, 527, 515, 662, 637],\n+                    [983, 686, 456, 768, 601, 561, 768, 653, 500, 688],\n+                    [493, 566, 664, 782, 683, 683, 721, 603, 323, 497],\n+                    [1015, 552, 411, 423, 607, 646, 687, 1018, 689, 607],\n+                    [516, 293, 471, 294, 293, 294, 608, 538, 803, 717],\n+                    [974, 994, 952, 637, 637, 927, 535, 571, 602, 535],\n+                    [776, 789, 476, 944, 652, 959, 589, 679, 321, 623],\n+                    [776, 931, 720, 1009, 676, 731, 386, 676, 701, 676],\n+                    [684, 543, 716, 392, 661, 517, 792, 588, 922, 676],\n+                ],\n+            ]\n+        )\n     },\n     \"facebook/encodec_48khz\": {\n         \"3.0\": torch.tensor([[[790, 790, 790, 214, 214, 214, 799, 214, 214, 214],\n@@ -940,39 +892,47 @@ def compute_rmse(arr1, arr2):\n             [1018,  794,  762,  444,  485,  485,  974,  548,  548, 1018],\n             [ 679,  243,  679, 1005, 1005,  973, 1014, 1005, 1005, 1014],\n             [ 810,   13, 1017,  537,  522,  702,  202, 1017, 1017,   15]]]),\n-        \"24.0\": torch.tensor([[[ 790,  790,  790,  214,  214,  214,  799,  214,  214,  214],\n-            [ 989,  989,   77,  546,  989,  546,  989,  160,  546,  989],\n-            [ 977,  977,  977,  977,  538,  977,  977,  960,  977,  977],\n-            [ 376,  376,  962,  962,  607,  962,  963,  896,  962,  376],\n-            [ 979,  979,  979, 1012,  979, 1012,  921,    0, 1002,  695],\n-            [ 824, 1018,  762,  957,  824,  762,  762, 1007,  957,  336],\n-            [ 681,  973,  973,  452,  211,  681,  802,  679,  547,  884],\n-            [ 950, 1017, 1016, 1017,  986, 1017,  229,  607, 1017,  689],\n-            [1004, 1011,  669, 1023, 1023, 1023,  905,  297,  810,  970],\n-            [ 982,  681,  982,  629,  662,  919,  878,  476,  629,  982],\n-            [ 727,  727,  959,  959,  979,  959,  530,  959,  337,  961],\n-            [ 924,  456,  924,  486,  924,  959,  102,  924,  805,  924],\n-            [ 649,  542,  712,  993,  949,  787,   56,  886,  949,  405],\n-            [ 864, 1022, 1022, 1022,  460,  753,  805,  309, 1022,   32],\n-            [ 953,    0,  169,  180,  352,   10,  581,  516,  322,  452],\n-            [ 300,    0,  175,  307,    0,  543,  924,  627,  258,  262]],\n-            [[ 214,  214,  214,  214,  214,  214,  214,  214,  214,  214],\n-            [ 289,  289,  989,  764,  289,  289,  882,  882,  882,  882],\n-            [1022, 1022,  471,  925,  821,  821,  267,  925,  925,  267],\n-            [ 979,  992,  914,  921,    0,    0, 1023,  963,  963, 1023],\n-            [ 403,  940,  976, 1018,  677, 1002,  979,  677,  677,  677],\n-            [1018,  794,  762,  444,  485,  485,  974,  548,  548, 1018],\n-            [ 679,  243,  679, 1005, 1005,  973, 1014, 1005, 1005, 1014],\n-            [ 810,   13, 1017,  537,  522,  702,  202, 1017, 1017,   15],\n-            [ 728,  252,  970,  984,  971,  950,  673,  902, 1011,  810],\n-            [ 332, 1014,  476,  854, 1014,  861,  332,  411,  411,  408],\n-            [ 959,  727,  611,  979,  611,  727,  999,  497,  821,    0],\n-            [ 995,  698,  924,  688,  102,  510,  924,  970,  344,  961],\n-            [  81,  516,  847,  924,   10,  240, 1005,  726,  993,  378],\n-            [ 467,  496,  484,  496,  456, 1022,  337,  600,  456, 1022],\n-            [ 789,   65,  937,  976,  159,  953,  343,  764,  179,  159],\n-            [  10,  790,  483,   10, 1020,  352,  848,  333,   83,  848]]])\n-        }\n+        \"24.0\": torch.tensor(\n+            [\n+                [\n+                    [790, 790, 790, 214, 214, 214, 799, 214, 214, 214],\n+                    [989, 989, 77, 546, 989, 546, 989, 160, 546, 989],\n+                    [977, 977, 977, 977, 538, 977, 977, 960, 977, 977],\n+                    [376, 376, 962, 962, 607, 962, 963, 896, 962, 376],\n+                    [979, 979, 979, 1012, 979, 1012, 921, 0, 1002, 695],\n+                    [824, 1018, 762, 957, 824, 762, 762, 1007, 957, 336],\n+                    [681, 973, 973, 452, 211, 681, 802, 679, 547, 884],\n+                    [950, 1017, 1016, 1017, 986, 1017, 229, 607, 1017, 689],\n+                    [1004, 1011, 669, 1023, 1023, 1023, 905, 297, 810, 970],\n+                    [982, 681, 982, 629, 662, 919, 878, 476, 629, 982],\n+                    [727, 727, 959, 959, 979, 959, 530, 959, 337, 961],\n+                    [924, 456, 924, 486, 924, 959, 102, 924, 805, 924],\n+                    [649, 542, 993, 993, 949, 787, 56, 886, 949, 405],\n+                    [864, 1022, 1022, 1022, 460, 753, 805, 309, 1022, 32],\n+                    [953, 0, 0, 180, 352, 10, 581, 516, 322, 452],\n+                    [300, 0, 1020, 307, 0, 543, 924, 627, 258, 262],\n+                ],\n+                [\n+                    [214, 214, 214, 214, 214, 214, 214, 214, 214, 214],\n+                    [289, 289, 989, 764, 289, 289, 882, 882, 882, 882],\n+                    [1022, 1022, 471, 925, 821, 821, 267, 925, 925, 267],\n+                    [979, 992, 914, 921, 0, 0, 1023, 963, 963, 1023],\n+                    [403, 940, 976, 1018, 677, 1002, 979, 677, 677, 677],\n+                    [1018, 794, 762, 444, 485, 485, 974, 548, 548, 1018],\n+                    [679, 243, 679, 1005, 1005, 973, 1014, 1005, 1005, 1014],\n+                    [810, 13, 1017, 537, 522, 702, 202, 1017, 1017, 15],\n+                    [728, 252, 970, 984, 971, 950, 673, 902, 1011, 810],\n+                    [332, 1014, 476, 854, 1014, 861, 332, 411, 411, 408],\n+                    [959, 727, 611, 979, 611, 727, 999, 497, 821, 0],\n+                    [995, 698, 924, 688, 102, 510, 924, 970, 344, 961],\n+                    [ 81, 516, 847, 924, 10, 240, 1005, 726, 993, 378],\n+                    [467, 496, 484, 496, 456, 1022, 337, 600, 456, 1022],\n+                    [789, 65, 937, 976, 159, 953, 343, 764, 179, 159],\n+                    [ 10, 790, 483, 10, 1020, 352, 848, 333, 83, 848],\n+                ],\n+            ]\n+        )\n+    }\n }\n EXPECTED_ENCODER_SCALES_BATCH = {\n     \"facebook/encodec_24khz\": {\n@@ -1059,137 +1019,36 @@ def compute_rmse(arr1, arr2):\n }\n EXPECTED_DECODER_OUTPUTS_BATCH = {\n     \"facebook/encodec_24khz\": {\n-        \"1.5\": torch.tensor([[[ 1.015406e-03,  4.409323e-04,  5.578916e-04,  2.484718e-04,\n-            4.704772e-04, -6.017360e-05, -2.822662e-04, -1.388252e-04,\n-            3.233083e-04,  1.241941e-04, -1.417649e-03, -8.976125e-04,\n-            -7.173615e-04, -2.332820e-03, -8.672470e-04,  7.940278e-04,\n-            7.449319e-04,  3.104414e-04,  1.298610e-04,  1.055387e-04,\n-            3.066540e-04, -4.989185e-05, -3.316122e-04, -4.116625e-04,\n-            -4.928584e-04, -7.005100e-04, -8.710265e-04, -1.055412e-03,\n-            -9.676196e-04, -6.152788e-04, -6.637399e-04, -7.234373e-04,\n-            -4.880424e-04, -4.966940e-04, -2.750417e-04, -2.340126e-04,\n-            -2.653633e-04, -1.364550e-04, -4.579989e-04, -7.613528e-04,\n-            -5.069966e-04, -6.894516e-04, -8.559920e-04, -1.647449e-04,\n-            3.009870e-04,  5.231842e-04,  3.762495e-04,  1.114787e-04,\n-            2.954131e-04,  4.176459e-04]],\n-            [[-9.372865e-05, -4.741669e-05,  2.616798e-04,  8.390514e-05,\n-            5.100360e-04,  7.359711e-05, -6.300798e-04, -2.403192e-04,\n-            2.246777e-04,  2.192185e-04, -3.122726e-03, -4.450452e-04,\n-            5.519075e-04, -6.607595e-03, -3.172569e-03,  4.339385e-03,\n-            2.489541e-03, -1.871432e-03, -1.661340e-03,  8.300164e-05,\n-            1.917491e-03, -1.009984e-03, -1.409455e-03, -9.432622e-04,\n-            -7.141122e-04, -9.612503e-04, -1.933691e-03, -2.354796e-03,\n-            -1.934643e-03, -8.267385e-05, -1.731471e-03, -2.189173e-03,\n-            -3.764036e-04,  4.844134e-04, -1.413215e-03, -2.356641e-03,\n-            1.774143e-04,  1.462373e-03, -2.157657e-03, -3.303485e-03,\n-            2.418862e-03,  9.119306e-04, -4.145604e-03,  4.465994e-05,\n-            2.961541e-03,  2.039100e-03, -1.467751e-03, -1.740925e-03,\n-            1.431166e-03,  6.965169e-04]]]),\n-        \"3.0\": torch.tensor([[[ 1.357599e-03,  7.177630e-04,  9.501720e-04,  4.596626e-04,\n-            6.146217e-04,  1.876430e-04, -5.819596e-05,  2.802655e-05,\n-            4.696309e-04,  3.317151e-04, -1.167380e-03, -6.051323e-04,\n-            -3.142844e-04, -1.957247e-03, -2.977881e-04,  1.495555e-03,\n-            1.332421e-03,  9.019304e-04,  7.672418e-04,  7.254211e-04,\n-            8.057931e-04,  3.575641e-04,  1.007026e-04, -1.377281e-06,\n-            -8.514666e-05, -2.402567e-04, -3.076097e-04, -4.096351e-04,\n-            -3.563285e-04,  5.303012e-05, -2.094661e-05, -5.301213e-05,\n-            2.393314e-04,  2.619583e-04,  4.957400e-04,  4.517243e-04,\n-            3.618106e-04,  4.857509e-04,  8.780634e-05, -3.247033e-04,\n-            -1.547708e-04, -4.343171e-04, -6.365582e-04,  2.680052e-04,\n-            8.752965e-04,  1.233456e-03,  1.270164e-03,  1.162403e-03,\n-            1.408067e-03,  1.518249e-03]],\n-            [[ 2.841285e-05, -2.997299e-04,  4.693681e-04,  3.772416e-04,\n-            1.128323e-03,  1.313188e-03,  2.279155e-04,  4.814252e-04,\n-            1.918601e-04,  5.752881e-04, -2.471404e-03, -5.213539e-04,\n-            4.082847e-04, -6.954804e-03, -2.728585e-03,  3.854635e-03,\n-            1.285948e-03, -1.521951e-03, -4.605813e-04,  2.396853e-04,\n-            1.429605e-03, -6.529675e-04, -2.044221e-04, -1.008462e-03,\n-            -8.369141e-04, -9.029446e-05, -5.603022e-04, -1.216394e-03,\n-            -1.564525e-03,  9.558922e-04,  6.491297e-05, -1.022518e-03,\n-            -1.954101e-04,  1.297267e-03, -2.417829e-04, -1.731238e-03,\n-            5.415535e-04,  1.932815e-03, -1.856094e-03, -3.499788e-03,\n-            2.234745e-03, -1.268075e-04, -4.044378e-03,  1.185370e-03,\n-            1.460594e-03,  1.236437e-03,  6.592137e-05, -1.020869e-03,\n-            5.275116e-04,  3.785653e-04]]]),\n-        \"6.0\": torch.tensor([[[ 1.007863e-03,  4.803724e-04,  7.220620e-04,  9.717804e-05,\n-            3.341401e-04, -1.732289e-05, -2.430840e-04, -1.288875e-04,\n-            3.264732e-04,  1.040195e-04, -1.345546e-03, -7.366082e-04,\n-            -3.820651e-04, -1.921868e-03, -3.512964e-04,  1.271279e-03,\n-            1.162949e-03,  8.450735e-04,  7.428044e-04,  7.391014e-04,\n-            7.614516e-04,  3.500883e-04,  9.413072e-05,  6.255026e-05,\n-            -2.385155e-05, -1.516611e-04, -1.437048e-04, -2.094361e-04,\n-            -1.343357e-04,  2.379516e-04,  2.019592e-04,  1.486097e-04,\n-            4.553733e-04,  5.007046e-04,  7.773977e-04,  7.455623e-04,\n-            6.810887e-04,  8.052849e-04,  4.363654e-04,  9.348725e-05,\n-            2.015569e-04, -4.657949e-05, -1.684410e-04,  6.471434e-04,\n-            1.204230e-03,  1.514807e-03,  1.568722e-03,  1.443268e-03,\n-            1.624384e-03,  1.755650e-03]],\n-\n-            [[-5.040500e-04, -7.500057e-05,  3.432350e-04,  7.585183e-05,\n-            1.007758e-03,  1.215896e-03,  1.471319e-04,  3.840830e-04,\n-            1.166091e-03,  2.766009e-04, -2.313319e-03, -3.110896e-04,\n-            -4.609615e-04, -6.267163e-03, -2.630252e-03,  3.998943e-03,\n-            2.404146e-03, -1.858970e-03, -5.218897e-04,  1.601377e-03,\n-            4.158776e-04, -7.833088e-04,  9.324983e-04,  1.551436e-04,\n-            -1.521105e-03, -3.481676e-04,  4.216506e-04, -1.121348e-03,\n-            -1.299326e-03,  1.146347e-03,  6.182901e-05, -1.950876e-03,\n-            6.824440e-04,  2.065210e-03, -8.677789e-04, -1.619447e-03,\n-            1.448340e-03,  1.339393e-03, -2.216001e-03, -1.529161e-03,\n-            1.584936e-03, -1.379265e-03, -3.270211e-03,  1.677168e-03,\n-            2.466952e-03, -3.435279e-04, -4.871176e-04,  1.014611e-03,\n-            5.374953e-04,  1.307726e-04]]]),\n-        \"12.0\": torch.tensor([[[ 3.103970e-04,  1.718526e-04,  3.963242e-04, -4.005958e-04,\n-            -3.466274e-04, -7.386556e-04, -7.721620e-04, -6.288703e-04,\n-            -1.459882e-04, -1.813814e-04, -1.617745e-03, -8.679354e-04,\n-            -3.858946e-04, -2.048092e-03, -3.258780e-04,  1.532118e-03,\n-            1.537561e-03,  1.201916e-03,  1.104101e-03,  9.631108e-04,\n-            9.732356e-04,  5.041601e-04,  1.511772e-04,  1.424436e-04,\n-            1.040599e-05, -1.402132e-04, -1.823406e-04, -3.658867e-04,\n-            -3.545182e-04,  4.148879e-05, -2.921480e-05, -1.673283e-04,\n-            8.278032e-05,  9.666858e-05,  3.829630e-04,  3.541503e-04,\n-            2.538824e-04,  3.753502e-04, -6.034327e-05, -5.178389e-04,\n-            -3.488946e-04, -6.063512e-04, -7.188834e-04,  2.672309e-04,\n-            9.224468e-04,  1.301268e-03,  1.474700e-03,  1.476285e-03,\n-            1.670685e-03,  1.795500e-03]],\n-            [[-7.502900e-04, -2.903775e-04,  3.207237e-04, -1.086803e-04,\n-            8.309091e-04,  1.238285e-03,  4.058254e-04,  7.459326e-04,\n-            1.489041e-03,  6.104580e-04, -2.142654e-03, -1.257654e-04,\n-            -3.319643e-04, -6.216155e-03, -2.212105e-03,  4.322743e-03,\n-            2.766707e-03, -1.286682e-03, -1.615412e-04,  1.713766e-03,\n-            9.857146e-04, -1.025513e-04,  8.074318e-04,  9.228788e-05,\n-            -1.035900e-03,  2.633175e-04,  8.113031e-04, -6.291629e-04,\n-            -7.344860e-04,  1.194915e-03,  2.727826e-04, -1.356129e-03,\n-            6.721524e-04,  1.923417e-03, -1.536551e-04, -1.273793e-03,\n-            1.068798e-03,  1.609214e-03, -1.638849e-03, -1.751525e-03,\n-            1.388134e-03, -6.229028e-04, -2.925864e-03,  1.105338e-03,\n-            2.797877e-03,  6.639463e-04, -3.657676e-04,  4.763596e-04,\n-            8.416761e-04,  3.298864e-04]]]),\n-        \"24.0\": torch.tensor([[[ 9.242969e-04,  4.937627e-04,  7.780819e-04,  2.061855e-04,\n-            3.750036e-04, -9.654555e-05, -3.621468e-04, -2.651380e-04,\n-            2.107890e-04,  1.148967e-04, -1.426978e-03, -8.614004e-04,\n-            -5.184905e-04, -2.335706e-03, -5.205711e-04,  1.529287e-03,\n-            1.381371e-03,  9.376337e-04,  8.259727e-04,  7.332105e-04,\n-            8.068624e-04,  3.546134e-04,  6.042556e-05,  4.315715e-05,\n-            -5.853554e-05, -1.533397e-04, -3.033156e-04, -5.854663e-04,\n-            -5.964030e-04, -2.603002e-04, -4.284764e-04, -5.482464e-04,\n-            -3.201824e-04, -3.872704e-04, -1.382349e-04, -1.986485e-04,\n-            -3.178230e-04, -1.286153e-04, -5.805814e-04, -1.071009e-03,\n-            -7.647169e-04, -1.004325e-03, -1.147952e-03, -2.592948e-06,\n-            7.057333e-04,  1.017309e-03,  1.161786e-03,  1.086416e-03,\n-            1.240234e-03,  1.387943e-03]],\n-            [[-8.428877e-04, -3.411243e-04,  1.537931e-04, -2.877330e-04,\n-            7.671653e-04,  1.194977e-03,  2.594253e-04,  6.105254e-04,\n-            1.729668e-03,  7.667911e-04, -2.009268e-03,  1.097925e-04,\n-            -1.933483e-04, -6.340677e-03, -2.260815e-03,  4.694434e-03,\n-            2.885622e-03, -1.569604e-03, -3.301174e-04,  1.891403e-03,\n-            1.038981e-03, -2.145469e-04,  7.553302e-04, -5.211149e-05,\n-            -1.223673e-03,  5.253934e-04,  1.211844e-03, -6.929165e-04,\n-            -8.178860e-04,  1.344839e-03, -1.325927e-04, -2.194005e-03,\n-            4.055744e-04,  2.095247e-03, -4.059107e-04, -1.368863e-03,\n-            1.726558e-03,  2.021377e-03, -1.819283e-03, -1.551372e-03,\n-            1.494524e-03, -1.507171e-03, -3.609777e-03,  1.388692e-03,\n-            2.961012e-03,  4.211143e-04,  2.292285e-04,  1.469882e-03,\n-            1.089076e-03,  6.743671e-04]]])\n+        \"1.5\": torch.tensor(\n+            [\n+                [[ 0.0010, 0.0004, 0.0005, 0.0002, 0.0005, -0.0001, -0.0003, -0.0001, 0.0003, 0.0001, -0.0014, -0.0009, -0.0007, -0.0023, -0.0009, 0.0008, 0.0007, 0.0003, 0.0001, 0.0001, 0.0003, -0.0001, -0.0003, -0.0004, -0.0005, -0.0007, -0.0009, -0.0011, -0.0010, -0.0006, -0.0007, -0.0007, -0.0005, -0.0005, -0.0003, -0.0002, -0.0002, -0.0001, -0.0005, -0.0008, -0.0005, -0.0007, -0.0009, -0.0002, 0.0003, 0.0005, 0.0004, 0.0001, 0.0003, 0.0004]],\n+                [[ -0.0001, -0.0000, 0.0003, 0.0001, 0.0005, 0.0001, -0.0006, -0.0002, 0.0002, 0.0002, -0.0031, -0.0004, 0.0006, -0.0066, -0.0032, 0.0044, 0.0025, -0.0019, -0.0017, 0.0001, 0.0019, -0.0010, -0.0014, -0.0009, -0.0007, -0.0009, -0.0019, -0.0024, -0.0019, -0.0001, -0.0017, -0.0022, -0.0004, 0.0005, -0.0014, -0.0023, 0.0002, 0.0015, -0.0022, -0.0033, 0.0024, 0.0009, -0.0041, 0.0000, 0.0030, 0.0020, -0.0015, -0.0018, 0.0014, 0.0007]],\n+            ]\n+        ),\n+        \"3.0\": torch.tensor(\n+            [\n+                [[ 0.0013, 0.0007, 0.0009, 0.0005, 0.0006, 0.0002, -0.0001, 0.0000, 0.0005, 0.0003, -0.0012, -0.0006, -0.0003, -0.0019, -0.0003, 0.0015, 0.0013, 0.0009, 0.0008, 0.0007, 0.0008, 0.0004, 0.0001, -0.0000, -0.0001, -0.0002, -0.0003, -0.0004, -0.0004, 0.0001, -0.0000, -0.0000, 0.0003, 0.0003, 0.0005, 0.0005, 0.0004, 0.0005, 0.0001, -0.0003, -0.0002, -0.0004, -0.0006, 0.0003, 0.0009, 0.0012, 0.0013, 0.0012, 0.0014, 0.0015]],\n+                [[ 0.0000, -0.0003, 0.0005, 0.0004, 0.0011, 0.0013, 0.0002, 0.0005, 0.0002, 0.0006, -0.0025, -0.0005, 0.0004, -0.0069, -0.0027, 0.0038, 0.0013, -0.0015, -0.0005, 0.0003, 0.0014, -0.0006, -0.0002, -0.0010, -0.0008, -0.0001, -0.0006, -0.0012, -0.0016, 0.0010, 0.0001, -0.0010, -0.0002, 0.0013, -0.0002, -0.0017, 0.0005, 0.0019, -0.0019, -0.0035, 0.0022, -0.0001, -0.0040, 0.0012, 0.0015, 0.0012, 0.0001, -0.0010, 0.0005, 0.0004]],\n+            ]\n+        ),\n+        \"6.0\": torch.tensor(\n+            [\n+                [[ 0.0010, 0.0005, 0.0007, 0.0001, 0.0003, -0.0000, -0.0002, -0.0001, 0.0003, 0.0001, -0.0014, -0.0007, -0.0004, -0.0019, -0.0004, 0.0013, 0.0012, 0.0008, 0.0007, 0.0007, 0.0008, 0.0003, 0.0001, 0.0001, -0.0000, -0.0001, -0.0001, -0.0002, -0.0001, 0.0002, 0.0002, 0.0001, 0.0005, 0.0005, 0.0008, 0.0008, 0.0007, 0.0008, 0.0004, 0.0001, 0.0002, -0.0001, -0.0002, 0.0006, 0.0012, 0.0015, 0.0016, 0.0014, 0.0016, 0.0017]],\n+                [[ -0.0005, -0.0001, 0.0003, 0.0001, 0.0010, 0.0012, 0.0002, 0.0004, 0.0012, 0.0003, -0.0023, -0.0003, -0.0005, -0.0063, -0.0026, 0.0040, 0.0024, -0.0018, -0.0005, 0.0016, 0.0004, -0.0008, 0.0009, 0.0002, -0.0015, -0.0003, 0.0004, -0.0011, -0.0013, 0.0012, 0.0001, -0.0019, 0.0007, 0.0021, -0.0009, -0.0016, 0.0015, 0.0013, -0.0022, -0.0015, 0.0016, -0.0014, -0.0033, 0.0017, 0.0025, -0.0004, -0.0005, 0.0010, 0.0005, 0.0001]],\n+            ]\n+        ),\n+        \"12.0\": torch.tensor(\n+            [\n+                [[ 0.0003, 0.0002, 0.0004, -0.0004, -0.0003, -0.0007, -0.0008, -0.0006, -0.0001, -0.0002, -0.0016, -0.0009, -0.0004, -0.0021, -0.0003, 0.0015, 0.0016, 0.0012, 0.0011, 0.0010, 0.0010, 0.0005, 0.0002, 0.0001, 0.0000, -0.0001, -0.0002, -0.0004, -0.0004, 0.0000, -0.0000, -0.0002, 0.0001, 0.0001, 0.0004, 0.0003, 0.0002, 0.0004, -0.0001, -0.0005, -0.0004, -0.0006, -0.0007, 0.0003, 0.0009, 0.0013, 0.0015, 0.0015, 0.0017, 0.0018]],\n+                [[ -0.0008, -0.0003, 0.0003, -0.0001, 0.0008, 0.0013, 0.0004, 0.0008, 0.0015, 0.0006, -0.0021, -0.0001, -0.0003, -0.0062, -0.0022, 0.0043, 0.0028, -0.0013, -0.0002, 0.0017, 0.0010, -0.0001, 0.0008, 0.0001, -0.0010, 0.0003, 0.0008, -0.0006, -0.0007, 0.0012, 0.0003, -0.0013, 0.0007, 0.0019, -0.0002, -0.0013, 0.0011, 0.0016, -0.0016, -0.0017, 0.0014, -0.0006, -0.0029, 0.0011, 0.0028, 0.0006, -0.0004, 0.0005, 0.0008, 0.0003]],\n+            ]\n+        ),\n+        \"24.0\": torch.tensor(\n+            [\n+                [[ 0.0009, 0.0004, 0.0007, 0.0002, 0.0004, -0.0001, -0.0003, -0.0002, 0.0002, 0.0001, -0.0015, -0.0009, -0.0006, -0.0024, -0.0005, 0.0016, 0.0014, 0.0010, 0.0009, 0.0008, 0.0008, 0.0004, 0.0001, 0.0000, -0.0001, -0.0002, -0.0003, -0.0006, -0.0006, -0.0003, -0.0005, -0.0006, -0.0003, -0.0004, -0.0001, -0.0002, -0.0003, -0.0001, -0.0006, -0.0011, -0.0008, -0.0010, -0.0012, -0.0000, 0.0007, 0.0011, 0.0012, 0.0011, 0.0013, 0.0014]],\n+                [[ -0.0009, -0.0004, 0.0001, -0.0003, 0.0007, 0.0012, 0.0003, 0.0006, 0.0017, 0.0008, -0.0020, 0.0001, -0.0002, -0.0064, -0.0023, 0.0047, 0.0029, -0.0016, -0.0004, 0.0019, 0.0010, -0.0002, 0.0007, -0.0001, -0.0013, 0.0005, 0.0012, -0.0007, -0.0008, 0.0013, -0.0001, -0.0022, 0.0004, 0.0020, -0.0004, -0.0014, 0.0017, 0.0020, -0.0018, -0.0016, 0.0015, -0.0015, -0.0036, 0.0014, 0.0030, 0.0004, 0.0002, 0.0015, 0.0011, 0.0007]],\n+            ]\n+        )\n     },\n     \"facebook/encodec_48khz\": {\n         \"3.0\": torch.tensor([[[ 0.005083,  0.004669,  0.005723,  0.005600,  0.004231,  0.003830,\n@@ -1332,67 +1191,26 @@ def compute_rmse(arr1, arr2):\n             -7.051138e-04, -1.102020e-03, -1.577104e-03, -1.846151e-03,\n             -1.623901e-03, -8.853760e-04, -1.772702e-04, -4.866864e-05,\n             -4.633263e-04, -1.017192e-03]]]),\n-        \"24.0\": torch.tensor([[[ 2.389381e-04,  7.304788e-04,  2.318475e-03,  2.314276e-03,\n-            1.195776e-03,  1.109080e-03,  1.158527e-03,  8.118532e-04,\n-            3.876419e-04,  3.642214e-04,  4.200035e-04,  3.689272e-04,\n-            2.853447e-04,  1.302699e-04,  3.499522e-05,  1.479641e-05,\n-            -6.733820e-05, -1.120797e-04, -1.246113e-05,  9.823417e-05,\n-            1.189398e-04,  2.543949e-04,  6.172496e-04,  1.024013e-03,\n-            1.312335e-03,  1.619842e-03,  1.932851e-03,  2.083474e-03,\n-            1.988995e-03,  1.768510e-03,  1.483699e-03,  1.267774e-03,\n-            1.137496e-03,  1.104772e-03,  1.140211e-03,  1.178907e-03,\n-            1.182056e-03,  1.218074e-03,  1.308932e-03,  1.436098e-03,\n-            1.459555e-03,  1.329746e-03,  1.137641e-03,  1.040303e-03,\n-            1.015108e-03,  1.032592e-03,  1.068031e-03,  1.050149e-03,\n-            9.438695e-04,  8.093917e-04],\n-            [-5.717200e-03, -4.239893e-03, -2.606834e-03, -2.800771e-03,\n-            -3.319753e-03, -3.388754e-03, -3.833471e-03, -4.048424e-03,\n-            -4.046101e-03, -3.699714e-03, -3.318990e-03, -3.079318e-03,\n-            -3.022295e-03, -2.990498e-03, -2.878775e-03, -2.776379e-03,\n-            -2.704474e-03, -2.445347e-03, -2.098053e-03, -2.000739e-03,\n-            -2.133043e-03, -2.082517e-03, -1.828181e-03, -1.540523e-03,\n-            -1.327203e-03, -1.156533e-03, -1.002377e-03, -8.585668e-04,\n-            -8.299644e-04, -8.459353e-04, -9.541380e-04, -1.025390e-03,\n-            -9.484394e-04, -7.587125e-04, -5.696753e-04, -3.943948e-04,\n-            -2.459019e-04, -7.849799e-05,  3.195518e-05,  9.533055e-05,\n-            1.072361e-04,  1.333459e-05, -1.280077e-04, -1.757752e-04,\n-            -1.964647e-04, -2.026716e-04, -2.436878e-04, -3.400938e-04,\n-            -4.811458e-04, -6.233592e-04]],\n-\n-            [[-2.415175e-03, -2.840925e-03, -9.335573e-04,  2.147308e-04,\n-            -1.733824e-04, -6.608180e-04, -1.230045e-03, -1.369990e-03,\n-            -1.254643e-03, -1.136640e-03, -1.081308e-03, -1.195997e-03,\n-            -1.616077e-03, -2.120167e-03, -2.415121e-03, -2.611547e-03,\n-            -2.419366e-03, -1.783933e-03, -1.260341e-03, -1.443838e-03,\n-            -2.183469e-03, -2.886888e-03, -3.537277e-03, -3.776790e-03,\n-            -3.130976e-03, -1.543215e-03,  8.065015e-04,  2.461564e-03,\n-            2.234322e-03,  5.683853e-04, -1.561458e-03, -2.982677e-03,\n-            -3.198907e-03, -2.435089e-03, -1.426444e-03, -9.499102e-04,\n-            -9.053986e-04, -1.037043e-03, -1.021375e-03, -8.417129e-04,\n-            -9.670848e-04, -1.417213e-03, -1.976826e-03, -2.261206e-03,\n-            -2.003314e-03, -1.136256e-03, -1.563174e-04,  1.054653e-04,\n-            -2.968917e-04, -8.761443e-04],\n-            [-8.589497e-03, -8.123170e-03, -5.924117e-03, -4.988470e-03,\n-            -5.313673e-03, -6.075567e-03, -7.079029e-03, -7.155661e-03,\n-            -6.886983e-03, -6.725700e-03, -6.609572e-03, -6.629347e-03,\n-            -7.001162e-03, -7.319664e-03, -7.364435e-03, -7.332079e-03,\n-            -6.879019e-03, -5.968860e-03, -5.286893e-03, -5.438344e-03,\n-            -6.114542e-03, -6.649041e-03, -7.180326e-03, -7.361221e-03,\n-            -6.696421e-03, -5.188371e-03, -3.031369e-03, -1.490936e-03,\n-            -1.566249e-03, -2.911505e-03, -4.735173e-03, -5.908214e-03,\n-            -5.935543e-03, -5.082982e-03, -4.077103e-03, -3.547108e-03,\n-            -3.373849e-03, -3.407303e-03, -3.377914e-03, -3.285105e-03,\n-            -3.472756e-03, -3.877119e-03, -4.330097e-03, -4.543182e-03,\n-            -4.291726e-03, -3.495801e-03, -2.641042e-03, -2.465559e-03,\n-            -2.870498e-03, -3.396702e-03]]])\n+        \"24.0\": torch.tensor(\n+            [\n+                [\n+                    [0.0004, 0.0008, 0.0024, 0.0024, 0.0013, 0.0013, 0.0013, 0.0009, 0.0005, 0.0005, 0.0006, 0.0005, 0.0005, 0.0003, 0.0003, 0.0003, 0.0002, 0.0002, 0.0003, 0.0004, 0.0003, 0.0004, 0.0008, 0.0012, 0.0015, 0.0018, 0.0021, 0.0022, 0.0021, 0.0019, 0.0016, 0.0014, 0.0012, 0.0011, 0.0012, 0.0012, 0.0012, 0.0012, 0.0013, 0.0014, 0.0014, 0.0013, 0.0011, 0.0009, 0.0009, 0.0010, 0.0010, 0.0010, 0.0009, 0.0007],\n+                    [ -0.0055, -0.0040, -0.0024, -0.0026, -0.0031, -0.0031, -0.0036, -0.0039, -0.0039, -0.0035, -0.0031, -0.0029, -0.0028, -0.0027, -0.0026, -0.0024, -0.0023, -0.0020, -0.0017, -0.0016, -0.0017, -0.0017, -0.0015, -0.0012, -0.0010, -0.0008, -0.0006, -0.0004, -0.0004, -0.0005, -0.0006, -0.0007, -0.0006, -0.0004, -0.0002, -0.0001, 0.0001, 0.0002, 0.0003, 0.0004, 0.0004, 0.0003, 0.0001, 0.0001, 0.0000, 0.0001, 0.0000, -0.0001, -0.0002, -0.0004],\n+                ],\n+                [\n+                    [-0.0024, -0.0029, -0.0009, 0.0002, -0.0002, -0.0007, -0.0012, -0.0013, -0.0012, -0.0011, -0.0011, -0.0012, -0.0016, -0.0021, -0.0024, -0.0026, -0.0024, -0.0018, -0.0013, -0.0015, -0.0022, -0.0029, -0.0035, -0.0038, -0.0031, -0.0015, 0.0008, 0.0025, 0.0023, 0.0006, -0.0016, -0.0030, -0.0032, -0.0024, -0.0015, -0.0010, -0.0009, -0.0011, -0.0010, -0.0009, -0.0010, -0.0014, -0.0020, -0.0023, -0.0020, -0.0011, -0.0001, 0.0001, -0.0003, -0.0009],\n+                    [-0.0086, -0.0081, -0.0059, -0.0050, -0.0053, -0.0061, -0.0071, -0.0071, -0.0069, -0.0067, -0.0066, -0.0066, -0.0070, -0.0073, -0.0074, -0.0073, -0.0069, -0.0060, -0.0053, -0.0055, -0.0061, -0.0067, -0.0072, -0.0074, -0.0067, -0.0052, -0.0031, -0.0015, -0.0016, -0.0029, -0.0048, -0.0059, -0.0059, -0.0051, -0.0041, -0.0036, -0.0034, -0.0034, -0.0034, -0.0033, -0.0035, -0.0039, -0.0043, -0.0046, -0.0043, -0.0035, -0.0027, -0.0025, -0.0029, -0.0034],\n+                ],\n+            ]\n+        )\n     }\n }\n # ---- error over whole batch\n EXPECTED_CODEC_ERROR_BATCH = {\n     \"facebook/encodec_24khz\": {\n         \"1.5\": 0.0011174238752573729,\n         \"3.0\": 0.0009308119188062847,\n-        \"6.0\": 0.0007683791918680072,\n+        \"6.0\": 0.0008,\n         \"12.0\": 0.0006830253987573087,\n         \"24.0\": 0.000642190920189023,\n     },\n@@ -1442,12 +1260,12 @@ def test_integration(self, name, model_id, bandwidth):\n             torch.testing.assert_close(\n                 codes[..., : EXPECTED_ENCODER_CODES[model_id][bandwidth].shape[-1]],\n                 EXPECTED_ENCODER_CODES[model_id][bandwidth].to(torch_device),\n-                rtol=1e-6,\n-                atol=1e-6,\n+                rtol=1e-4,\n+                atol=1e-4,\n             )\n             if EXPECTED_ENCODER_SCALES[model_id][bandwidth] is not None:\n                 scales = torch.tensor([encoded[0].squeeze() for encoded in encoded_frames[\"audio_scales\"]])\n-                torch.testing.assert_close(scales, EXPECTED_ENCODER_SCALES[model_id][bandwidth], rtol=1e-6, atol=1e-6)\n+                torch.testing.assert_close(scales, EXPECTED_ENCODER_SCALES[model_id][bandwidth], rtol=1e-4, atol=1e-4)\n \n             # Compare decoder outputs with expected values\n             decoded_frames = model.decode(\n@@ -1459,21 +1277,21 @@ def test_integration(self, name, model_id, bandwidth):\n             torch.testing.assert_close(\n                 decoded_frames[\"audio_values\"][0][..., : EXPECTED_DECODER_OUTPUTS[model_id][bandwidth].shape[-1]],\n                 EXPECTED_DECODER_OUTPUTS[model_id][bandwidth].to(torch_device),\n-                rtol=1e-6,\n-                atol=1e-6,\n+                rtol=1e-4,\n+                atol=1e-4,\n             )\n \n             # Compare codec error with expected values\n             codec_error = compute_rmse(decoded_frames[\"audio_values\"], inputs[\"input_values\"])\n-            torch.testing.assert_close(codec_error, EXPECTED_CODEC_ERROR[model_id][bandwidth], rtol=1e-6, atol=1e-6)\n+            torch.testing.assert_close(codec_error, EXPECTED_CODEC_ERROR[model_id][bandwidth], rtol=1e-4, atol=1e-4)\n \n             # make sure forward and enc-dec give same result\n             full_enc = model(inputs[\"input_values\"], inputs[\"padding_mask\"], bandwidth=float(bandwidth))\n             torch.testing.assert_close(\n                 full_enc[\"audio_values\"],\n                 decoded_frames[\"audio_values\"],\n-                rtol=1e-6,\n-                atol=1e-6,\n+                rtol=1e-4,\n+                atol=1e-4,\n             )\n \n     @parameterized.expand(\n@@ -1517,13 +1335,13 @@ def test_batch(self, name, model_id, bandwidth):\n             torch.testing.assert_close(\n                 codes[..., : EXPECTED_ENCODER_CODES_BATCH[model_id][bandwidth].shape[-1]],\n                 EXPECTED_ENCODER_CODES_BATCH[model_id][bandwidth].to(torch_device),\n-                rtol=1e-6,\n-                atol=1e-6,\n+                rtol=1e-4,\n+                atol=1e-4,\n             )\n             if EXPECTED_ENCODER_SCALES_BATCH[model_id][bandwidth] is not None:\n                 scales = torch.stack(encoded_frames[\"audio_scales\"])\n                 torch.testing.assert_close(\n-                    scales, EXPECTED_ENCODER_SCALES_BATCH[model_id][bandwidth].to(torch_device), rtol=1e-6, atol=1e-6\n+                    scales, EXPECTED_ENCODER_SCALES_BATCH[model_id][bandwidth].to(torch_device), rtol=1e-4, atol=1e-4\n                 )\n \n             # Compare decoder outputs with expected values\n@@ -1536,18 +1354,18 @@ def test_batch(self, name, model_id, bandwidth):\n             torch.testing.assert_close(\n                 decoded_frames[\"audio_values\"][..., : EXPECTED_DECODER_OUTPUTS_BATCH[model_id][bandwidth].shape[-1]],\n                 EXPECTED_DECODER_OUTPUTS_BATCH[model_id][bandwidth].to(torch_device),\n-                rtol=1e-6,\n-                atol=1e-6,\n+                rtol=1e-4,\n+                atol=1e-4,\n             )\n \n             # Compare codec error with expected values\n             codec_error = compute_rmse(decoded_frames[\"audio_values\"], inputs[\"input_values\"])\n             torch.testing.assert_close(\n-                codec_error, EXPECTED_CODEC_ERROR_BATCH[model_id][bandwidth], rtol=1e-6, atol=1e-6\n+                codec_error, EXPECTED_CODEC_ERROR_BATCH[model_id][bandwidth], rtol=1e-4, atol=1e-4\n             )\n \n             # make sure forward and enc-dec give same result\n             input_values_dec = model(inputs[\"input_values\"], inputs[\"padding_mask\"], bandwidth=float(bandwidth))\n             torch.testing.assert_close(\n-                input_values_dec[\"audio_values\"], decoded_frames[\"audio_values\"], rtol=1e-6, atol=1e-6\n+                input_values_dec[\"audio_values\"], decoded_frames[\"audio_values\"], rtol=1e-4, atol=1e-4\n             )"
        }
    ],
    "stats": {
        "total": 1560,
        "additions": 631,
        "deletions": 929
    }
}