{
    "author": "Cyrilvallez",
    "message": "Fix CI (hunyuan moe does not support fullgraph) (#40423)\n\nfix flag",
    "sha": "40299134a8cdd0f8c9a2cafbeb4c91d8eb490b80",
    "files": [
        {
            "sha": "043d1f8243a35638747f3ff44946748dc472fcf1",
            "filename": "src/transformers/models/hunyuan_v1_moe/modeling_hunyuan_v1_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/40299134a8cdd0f8c9a2cafbeb4c91d8eb490b80/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodeling_hunyuan_v1_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/40299134a8cdd0f8c9a2cafbeb4c91d8eb490b80/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodeling_hunyuan_v1_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodeling_hunyuan_v1_moe.py?ref=40299134a8cdd0f8c9a2cafbeb4c91d8eb490b80",
            "patch": "@@ -355,8 +355,7 @@ class HunYuanMoEV1PreTrainedModel(PreTrainedModel):\n     _supports_flash_attn = True\n     _supports_sdpa = True\n     _supports_flex_attn = True\n-\n-    _can_compile_fullgraph = True\n+    _can_compile_fullgraph = False\n     _supports_attention_backend = True\n     _can_record_outputs = {\n         \"hidden_states\": HunYuanMoEV1DecoderLayer,"
        },
        {
            "sha": "12a460b3108d0576d8712ff9eca32871a300b3b9",
            "filename": "src/transformers/models/hunyuan_v1_moe/modular_hunyuan_v1_moe.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/40299134a8cdd0f8c9a2cafbeb4c91d8eb490b80/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodular_hunyuan_v1_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/40299134a8cdd0f8c9a2cafbeb4c91d8eb490b80/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodular_hunyuan_v1_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodular_hunyuan_v1_moe.py?ref=40299134a8cdd0f8c9a2cafbeb4c91d8eb490b80",
            "patch": "@@ -197,6 +197,8 @@ def __init__(self, config: HunYuanMoEV1Config, layer_idx: int):\n \n \n class HunYuanMoEV1PreTrainedModel(LlamaPreTrainedModel):\n+    _can_compile_fullgraph = False\n+\n     def _init_weights(self, module):\n         std = self.config.initializer_range\n         if isinstance(module, nn.Linear):"
        }
    ],
    "stats": {
        "total": 5,
        "additions": 3,
        "deletions": 2
    }
}