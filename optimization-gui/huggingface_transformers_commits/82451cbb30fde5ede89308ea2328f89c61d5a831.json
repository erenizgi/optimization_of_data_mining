{
    "author": "yao-matrix",
    "message": "extend bitnet cases to xpu, all 8 cases pass (#41831)\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>",
    "sha": "82451cbb30fde5ede89308ea2328f89c61d5a831",
    "files": [
        {
            "sha": "1e4e4ba2a291ec5d99fd51465e064c82b20ebe13",
            "filename": "tests/quantization/bitnet_integration/test_bitnet.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/82451cbb30fde5ede89308ea2328f89c61d5a831/tests%2Fquantization%2Fbitnet_integration%2Ftest_bitnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/82451cbb30fde5ede89308ea2328f89c61d5a831/tests%2Fquantization%2Fbitnet_integration%2Ftest_bitnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fquantization%2Fbitnet_integration%2Ftest_bitnet.py?ref=82451cbb30fde5ede89308ea2328f89c61d5a831",
            "patch": "@@ -25,7 +25,7 @@\n from transformers.testing_utils import (\n     backend_empty_cache,\n     require_accelerate,\n-    require_torch_gpu,\n+    require_torch_accelerator,\n     slow,\n     torch_device,\n )\n@@ -39,7 +39,7 @@\n     from accelerate import init_empty_weights\n \n \n-@require_torch_gpu\n+@require_torch_accelerator\n class BitNetQuantConfigTest(unittest.TestCase):\n     def test_to_dict(self):\n         \"\"\"\n@@ -53,7 +53,7 @@ def test_to_dict(self):\n \n \n @slow\n-@require_torch_gpu\n+@require_torch_accelerator\n @require_accelerate\n class BitNetTest(unittest.TestCase):\n     model_name = \"HF1BitLLM/Llama3-8B-1.58-100B-tokens\"\n@@ -197,7 +197,7 @@ def forward(self, x):\n \n \n @slow\n-@require_torch_gpu\n+@require_torch_accelerator\n @require_accelerate\n class BitNetSerializationTest(unittest.TestCase):\n     def test_model_serialization(self):"
        }
    ],
    "stats": {
        "total": 8,
        "additions": 4,
        "deletions": 4
    }
}