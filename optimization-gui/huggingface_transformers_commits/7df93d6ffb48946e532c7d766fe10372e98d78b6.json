{
    "author": "ecyht2",
    "message": "fix: Wrong task mentioned in docs (#34757)",
    "sha": "7df93d6ffb48946e532c7d766fe10372e98d78b6",
    "files": [
        {
            "sha": "1cc60ba096f04f56f6461db262f2721c5fbd3fd7",
            "filename": "docs/source/en/tasks_explained.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/7df93d6ffb48946e532c7d766fe10372e98d78b6/docs%2Fsource%2Fen%2Ftasks_explained.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/7df93d6ffb48946e532c7d766fe10372e98d78b6/docs%2Fsource%2Fen%2Ftasks_explained.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftasks_explained.md?ref=7df93d6ffb48946e532c7d766fe10372e98d78b6",
            "patch": "@@ -182,7 +182,7 @@ There are three main components to Mask2Former:\n \n     The mask predictions are generated by combining the pixel-embeddings with the final decoder hidden states. The sigmoid cross-entropy and dice loss is calculated between the logits and the ground truth mask to find the most likely mask.\n \n-Ready to try your hand at object detection? Check out our complete [image segmentation guide](tasks/semantic_segmentation) to learn how to finetune SegFormer and use it for inference!\n+Ready to try your hand at image segmentation? Check out our complete [image segmentation guide](tasks/semantic_segmentation) to learn how to finetune SegFormer and use it for inference!\n \n ### Depth estimation\n \n@@ -292,4 +292,4 @@ Ready to try your hand at translation? Check out our complete [translation guide\n \n For more information about text generation, check out the [text generation strategies](generation_strategies) guide!\n \n-</Tip>\n\\ No newline at end of file\n+</Tip>"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}