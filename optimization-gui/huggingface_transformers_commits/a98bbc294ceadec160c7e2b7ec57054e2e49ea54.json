{
    "author": "Cyrilvallez",
    "message": "Add missing flag for CacheLayer (#39678)\n\n* fix\n\n* Update cache_utils.py",
    "sha": "a98bbc294ceadec160c7e2b7ec57054e2e49ea54",
    "files": [
        {
            "sha": "26e2ae54230465c9ad731916b4d524ca53b2e25e",
            "filename": "src/transformers/cache_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/a98bbc294ceadec160c7e2b7ec57054e2e49ea54/src%2Ftransformers%2Fcache_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a98bbc294ceadec160c7e2b7ec57054e2e49ea54/src%2Ftransformers%2Fcache_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcache_utils.py?ref=a98bbc294ceadec160c7e2b7ec57054e2e49ea54",
            "patch": "@@ -73,6 +73,8 @@ class DynamicLayer(CacheLayerMixin):\n     See `CacheLayerMixin` for details on common methods that are implemented by all cache layers.\n     \"\"\"\n \n+    is_sliding = False\n+\n     def update(\n         self,\n         key_states: torch.Tensor,\n@@ -307,6 +309,8 @@ class SlidingWindowLayer(StaticLayer):\n     See `CacheLayerMixin` for details on common methods that are implemented by all cache layers.\n     \"\"\"\n \n+    is_sliding = True\n+\n     def __init__(self, sliding_window, *args, **kwargs):\n         \"\"\"\n         Args:"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 4,
        "deletions": 0
    }
}