{
    "author": "kaixuanliu",
    "message": "remove duplicate code (#37991)\n\nSigned-off-by: Liu, Kaixuan <kaixuan.liu@intel.com>",
    "sha": "fb1e3a4daa650cf9f21924bf6fb7d2e220955b47",
    "files": [
        {
            "sha": "7977f2e01cfaefdd4c8a375fb24c466f8c593c7e",
            "filename": "src/transformers/models/video_llava/processing_video_llava.py",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/fb1e3a4daa650cf9f21924bf6fb7d2e220955b47/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fprocessing_video_llava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fb1e3a4daa650cf9f21924bf6fb7d2e220955b47/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fprocessing_video_llava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fprocessing_video_llava.py?ref=fb1e3a4daa650cf9f21924bf6fb7d2e220955b47",
            "patch": "@@ -177,11 +177,6 @@ def __call__(\n                 height, width = get_image_size(one_video[0])\n                 num_frames = one_video.shape[0]  # frame dim is always after batch dim\n \n-            num_image_tokens = (height // self.patch_size) * (\n-                width // self.patch_size\n-            ) + self.num_additional_image_tokens\n-            num_video_tokens = num_image_tokens * num_frames\n-\n             num_image_tokens = (height // self.patch_size) * (\n                 width // self.patch_size\n             ) + self.num_additional_image_tokens"
        }
    ],
    "stats": {
        "total": 5,
        "additions": 0,
        "deletions": 5
    }
}