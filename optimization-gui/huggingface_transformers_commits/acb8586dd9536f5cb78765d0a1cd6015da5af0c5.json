{
    "author": "co63oc",
    "message": "Fix some typos in docs (#36502)\n\nCo-authored-by: Matt <Rocketknight1@users.noreply.github.com>",
    "sha": "acb8586dd9536f5cb78765d0a1cd6015da5af0c5",
    "files": [
        {
            "sha": "f9676f29b28c13953bd7ae203d19702a79d0a4e7",
            "filename": "awesome-transformers.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/acb8586dd9536f5cb78765d0a1cd6015da5af0c5/awesome-transformers.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/acb8586dd9536f5cb78765d0a1cd6015da5af0c5/awesome-transformers.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/awesome-transformers.md?ref=acb8586dd9536f5cb78765d0a1cd6015da5af0c5",
            "patch": "@@ -29,7 +29,7 @@ Keywords: inpainting, SD, Stable Diffusion\n \n ## [flair](https://github.com/flairNLP/flair)\n \n-FLAIR is a powerful PyTorch NLP framework, convering several important tasks: NER, sentiment-analysis, part-of-speech tagging, text and document embeddings, among other things.\n+FLAIR is a powerful PyTorch NLP framework, covering several important tasks: NER, sentiment-analysis, part-of-speech tagging, text and document embeddings, among other things.\n \n Keywords: NLP, text embedding, document embedding, biomedical, NER, PoS, sentiment-analysis\n "
        },
        {
            "sha": "df348b08523847a8688b2bd52bb3b25f568bd3d2",
            "filename": "benchmark/benchmarks_entrypoint.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/acb8586dd9536f5cb78765d0a1cd6015da5af0c5/benchmark%2Fbenchmarks_entrypoint.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/acb8586dd9536f5cb78765d0a1cd6015da5af0c5/benchmark%2Fbenchmarks_entrypoint.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/benchmark%2Fbenchmarks_entrypoint.py?ref=acb8586dd9536f5cb78765d0a1cd6015da5af0c5",
            "patch": "@@ -136,7 +136,7 @@ def import_from_path(module_name, file_path):\n                 continue\n             logger.debug(f\"loading: {entry.name}\")\n             module = import_from_path(entry.name.split(\".\")[0], entry.path)\n-            logger.info(f\"runnning benchmarks in: {entry.name}\")\n+            logger.info(f\"running benchmarks in: {entry.name}\")\n             module.run_benchmark(logger, branch, commit_id, commit_msg)\n         except ImportModuleException as e:\n             logger.error(e)"
        },
        {
            "sha": "c7efd8f02f48c07471ea699b4fe57f685e3c8dfa",
            "filename": "docs/source/ar/agents.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/acb8586dd9536f5cb78765d0a1cd6015da5af0c5/docs%2Fsource%2Far%2Fagents.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/acb8586dd9536f5cb78765d0a1cd6015da5af0c5/docs%2Fsource%2Far%2Fagents.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fagents.md?ref=acb8586dd9536f5cb78765d0a1cd6015da5af0c5",
            "patch": "@@ -195,7 +195,7 @@ You have access to the following tools:\n To solve the task, you must plan forward to proceed in a series of steps, in a cycle of 'Thought:', 'Code:', and 'Observation:' sequences.\n \n At each step, in the 'Thought:' sequence, you should first explain your reasoning towards solving the task, then the tools that you want to use.\n-Then in the 'Code:' sequence, you shold write the code in simple Python. The code sequence must end with '/End code' sequence.\n+Then in the 'Code:' sequence, you should write the code in simple Python. The code sequence must end with '/End code' sequence.\n During each intermediate step, you can use 'print()' to save whatever important information you will then need.\n These print outputs will then be available in the 'Observation:' field, for using this information as input for the next step.\n \n@@ -205,7 +205,7 @@ Here are a few examples using notional tools:\n ---\n {examples}\n \n-Above example were using notional tools that might not exist for you. You only have acces to those tools:\n+Above example were using notional tools that might not exist for you. You only have access to those tools:\n <<tool_names>>\n You also can perform computations in the python code you generate.\n "
        },
        {
            "sha": "6f437dea0681ba787b3f62aafd0f5ee723388f63",
            "filename": "docs/source/ar/serialization.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/acb8586dd9536f5cb78765d0a1cd6015da5af0c5/docs%2Fsource%2Far%2Fserialization.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/acb8586dd9536f5cb78765d0a1cd6015da5af0c5/docs%2Fsource%2Far%2Fserialization.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fserialization.md?ref=acb8586dd9536f5cb78765d0a1cd6015da5af0c5",
            "patch": "@@ -116,11 +116,11 @@ optimum-cli export onnx --model keras-io/transformers-qa distilbert_base_cased_s\n \n <Tip warning={true}>\n \n-Ù„Ù… ÙŠØ¹Ø¯ ÙŠØªÙ… Ø¯Ø¹Ù… `tranformers.onnx`  ÙŠÙØ±Ø¬Ù‰ ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ğŸ¤— Optimum ÙƒÙ…Ø§ Ù‡Ùˆ Ù…ÙˆØ¶Ø­ Ø£Ø¹Ù„Ø§Ù‡. Ø³ÙŠØªÙ… Ø¥Ø²Ø§Ù„Ø© Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù… ÙÙŠ Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©.\n+Ù„Ù… ÙŠØ¹Ø¯ ÙŠØªÙ… Ø¯Ø¹Ù… `transformers.onnx`  ÙŠÙØ±Ø¬Ù‰ ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ğŸ¤— Optimum ÙƒÙ…Ø§ Ù‡Ùˆ Ù…ÙˆØ¶Ø­ Ø£Ø¹Ù„Ø§Ù‡. Ø³ÙŠØªÙ… Ø¥Ø²Ø§Ù„Ø© Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù… ÙÙŠ Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©.\n \n </Tip>\n \n-Ù„ØªØµØ¯ÙŠØ± Ù†Ù…ÙˆØ°Ø¬ ğŸ¤— Transformers Ø¥Ù„Ù‰ ONNX Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `tranformers.onnx`ØŒ Ø«Ø¨Ù‘Øª Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©:\n+Ù„ØªØµØ¯ÙŠØ± Ù†Ù…ÙˆØ°Ø¬ ğŸ¤— Transformers Ø¥Ù„Ù‰ ONNX Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `transformers.onnx`ØŒ Ø«Ø¨Ù‘Øª Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©:\n \n ```bash\n pip install transformers[onnx]"
        },
        {
            "sha": "6885ae30c470a454dc1518d53188326f8109f649",
            "filename": "docs/source/zh/serialization.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/acb8586dd9536f5cb78765d0a1cd6015da5af0c5/docs%2Fsource%2Fzh%2Fserialization.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/acb8586dd9536f5cb78765d0a1cd6015da5af0c5/docs%2Fsource%2Fzh%2Fserialization.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fserialization.md?ref=acb8586dd9536f5cb78765d0a1cd6015da5af0c5",
            "patch": "@@ -128,11 +128,11 @@ optimum-cli export onnx --model keras-io/transformers-qa distilbert_base_cased_s\n \n <Tip warning={true}>\n \n-`tranformers.onnx` ä¸å†è¿›è¡Œç»´æŠ¤ï¼Œè¯·å¦‚ä¸Šæ‰€è¿°ï¼Œä½¿ç”¨ ğŸ¤— Optimum å¯¼å‡ºæ¨¡å‹ã€‚è¿™éƒ¨åˆ†å†…å®¹å°†åœ¨æœªæ¥ç‰ˆæœ¬ä¸­åˆ é™¤ã€‚\n+`transformers.onnx` ä¸å†è¿›è¡Œç»´æŠ¤ï¼Œè¯·å¦‚ä¸Šæ‰€è¿°ï¼Œä½¿ç”¨ ğŸ¤— Optimum å¯¼å‡ºæ¨¡å‹ã€‚è¿™éƒ¨åˆ†å†…å®¹å°†åœ¨æœªæ¥ç‰ˆæœ¬ä¸­åˆ é™¤ã€‚\n \n </Tip>\n \n-è¦ä½¿ç”¨ `tranformers.onnx` å°† ğŸ¤— Transformers æ¨¡å‹å¯¼å‡ºä¸º ONNXï¼Œè¯·å®‰è£…é¢å¤–çš„ä¾èµ–é¡¹ï¼š\n+è¦ä½¿ç”¨ `transformers.onnx` å°† ğŸ¤— Transformers æ¨¡å‹å¯¼å‡ºä¸º ONNXï¼Œè¯·å®‰è£…é¢å¤–çš„ä¾èµ–é¡¹ï¼š\n \n ```bash\n pip install transformers[onnx]"
        }
    ],
    "stats": {
        "total": 16,
        "additions": 8,
        "deletions": 8
    }
}