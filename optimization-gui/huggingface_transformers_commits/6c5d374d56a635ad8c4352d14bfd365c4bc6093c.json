{
    "author": "tibor-reiss",
    "message": "uniformize kwargs for VisionTextDualEncoder (#34563)\n\n* Make kwargs uniform for VisionTextDualEncoder\n\n* Add bc for flipped args",
    "sha": "6c5d374d56a635ad8c4352d14bfd365c4bc6093c",
    "files": [
        {
            "sha": "48952dc60b974dde42f2c271358d39de02041410",
            "filename": "src/transformers/models/vision_text_dual_encoder/processing_vision_text_dual_encoder.py",
            "status": "modified",
            "additions": 30,
            "deletions": 6,
            "changes": 36,
            "blob_url": "https://github.com/huggingface/transformers/blob/6c5d374d56a635ad8c4352d14bfd365c4bc6093c/src%2Ftransformers%2Fmodels%2Fvision_text_dual_encoder%2Fprocessing_vision_text_dual_encoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6c5d374d56a635ad8c4352d14bfd365c4bc6093c/src%2Ftransformers%2Fmodels%2Fvision_text_dual_encoder%2Fprocessing_vision_text_dual_encoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvision_text_dual_encoder%2Fprocessing_vision_text_dual_encoder.py?ref=6c5d374d56a635ad8c4352d14bfd365c4bc6093c",
            "patch": "@@ -17,9 +17,15 @@\n \"\"\"\n \n import warnings\n+from typing import List, Optional, Union\n \n-from ...processing_utils import ProcessorMixin\n-from ...tokenization_utils_base import BatchEncoding\n+from ...image_utils import ImageInput\n+from ...processing_utils import ProcessingKwargs, ProcessorMixin, Unpack, _validate_images_text_input_order\n+from ...tokenization_utils_base import BatchEncoding, PreTokenizedInput, TextInput\n+\n+\n+class VisionTextDualEncoderProcessorKwargs(ProcessingKwargs, total=False):\n+    _defaults = {}\n \n \n class VisionTextDualEncoderProcessor(ProcessorMixin):\n@@ -61,7 +67,14 @@ def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n         super().__init__(image_processor, tokenizer)\n         self.current_processor = self.image_processor\n \n-    def __call__(self, text=None, images=None, return_tensors=None, **kwargs):\n+    def __call__(\n+        self,\n+        images: Optional[ImageInput] = None,\n+        text: Union[TextInput, PreTokenizedInput, List[TextInput], List[PreTokenizedInput]] = None,\n+        audio=None,\n+        videos=None,\n+        **kwargs: Unpack[VisionTextDualEncoderProcessorKwargs],\n+    ) -> BatchEncoding:\n         \"\"\"\n         Main method to prepare for the model one or several sequences(s) and image(s). This method forwards the `text`\n         and `kwargs` arguments to VisionTextDualEncoderTokenizer's [`~PreTrainedTokenizer.__call__`] if `text` is not\n@@ -98,20 +111,31 @@ def __call__(self, text=None, images=None, return_tensors=None, **kwargs):\n \n         if text is None and images is None:\n             raise ValueError(\"You have to specify either text or images. Both cannot be none.\")\n+        # check if images and text inputs are reversed for BC\n+        images, text = _validate_images_text_input_order(images, text)\n+\n+        output_kwargs = self._merge_kwargs(\n+            VisionTextDualEncoderProcessorKwargs,\n+            tokenizer_init_kwargs=self.tokenizer.init_kwargs,\n+            **kwargs,\n+        )\n \n         if text is not None:\n-            encoding = self.tokenizer(text, return_tensors=return_tensors, **kwargs)\n+            encoding = self.tokenizer(text, **output_kwargs[\"text_kwargs\"])\n \n         if images is not None:\n-            image_features = self.image_processor(images, return_tensors=return_tensors, **kwargs)\n+            image_features = self.image_processor(images, **output_kwargs[\"images_kwargs\"])\n \n         if text is not None and images is not None:\n             encoding[\"pixel_values\"] = image_features.pixel_values\n             return encoding\n         elif text is not None:\n             return encoding\n         else:\n-            return BatchEncoding(data=dict(**image_features), tensor_type=return_tensors)\n+            return BatchEncoding(\n+                data=dict(**image_features),\n+                tensor_type=output_kwargs[\"common_kwargs\"].get(\"return_tensors\"),\n+            )\n \n     def batch_decode(self, *args, **kwargs):\n         \"\"\""
        }
    ],
    "stats": {
        "total": 36,
        "additions": 30,
        "deletions": 6
    }
}