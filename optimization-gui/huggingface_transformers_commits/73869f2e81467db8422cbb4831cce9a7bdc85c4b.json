{
    "author": "Tavish9",
    "message": "Fix typing order (#39467)\n\n* fix type order\n\n* change all Union[str, dict] to Union[dict, str]\n\n* add hf_parser test && fix test order\n\n* add deepspeed dependency\n\n* replace deepspeed with accelerator",
    "sha": "73869f2e81467db8422cbb4831cce9a7bdc85c4b",
    "files": [
        {
            "sha": "a97ba8511d54538ead90df13babbde0648c42d16",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/73869f2e81467db8422cbb4831cce9a7bdc85c4b/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/73869f2e81467db8422cbb4831cce9a7bdc85c4b/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=73869f2e81467db8422cbb4831cce9a7bdc85c4b",
            "patch": "@@ -1395,7 +1395,7 @@ def _get_torch_dtype(\n \n def _get_device_map(\n     model: \"PreTrainedModel\",\n-    device_map: Optional[Union[str, dict]],\n+    device_map: Optional[Union[dict, str]],\n     max_memory: Optional[dict],\n     hf_quantizer: Optional[HfQuantizer],\n     torch_dtype: Optional[torch.dtype],\n@@ -2273,7 +2273,7 @@ def _from_config(cls, config, **kwargs):\n         return model\n \n     @classmethod\n-    def _check_attn_implementation(cls, attn_implementation: Union[str, dict]) -> Union[str, dict]:\n+    def _check_attn_implementation(cls, attn_implementation: Union[dict, str]) -> Union[dict, str]:\n         \"\"\"\n         Checks that the requested attention implementation exists and tries to get the kernel from hub\n         if `attn_implementation` matches hf kernels pattern.\n@@ -2321,7 +2321,7 @@ def _check_attn_implementation(cls, attn_implementation: Union[str, dict]) -> Un\n \n         return attn_implementation\n \n-    def set_attention_implementation(self, attn_implementation: Union[str, dict]):\n+    def set_attention_implementation(self, attn_implementation: Union[dict, str]):\n         \"\"\"\n         Checks and dispatches to the requested attention implementation.\n         \"\"\""
        },
        {
            "sha": "a76a6fead76d508f818da3710c8e058ce8eaf632",
            "filename": "src/transformers/models/modernbert/modeling_modernbert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/73869f2e81467db8422cbb4831cce9a7bdc85c4b/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodeling_modernbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/73869f2e81467db8422cbb4831cce9a7bdc85c4b/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodeling_modernbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodeling_modernbert.py?ref=73869f2e81467db8422cbb4831cce9a7bdc85c4b",
            "patch": "@@ -611,7 +611,7 @@ def init_weight(module: nn.Module, std: float):\n             if module.bias is not None:\n                 module.bias.data.zero_()\n \n-    def set_attention_implementation(self, attn_implementation: Union[str, dict]):\n+    def set_attention_implementation(self, attn_implementation: Union[dict, str]):\n         \"\"\"\n         Checks and dispatches to hhe requested attention implementation.\n         \"\"\""
        },
        {
            "sha": "254b5d3163f70120b66dc3ab9b41217fc246a9fc",
            "filename": "src/transformers/models/modernbert/modular_modernbert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/73869f2e81467db8422cbb4831cce9a7bdc85c4b/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodular_modernbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/73869f2e81467db8422cbb4831cce9a7bdc85c4b/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodular_modernbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodular_modernbert.py?ref=73869f2e81467db8422cbb4831cce9a7bdc85c4b",
            "patch": "@@ -811,7 +811,7 @@ def init_weight(module: nn.Module, std: float):\n             if module.bias is not None:\n                 module.bias.data.zero_()\n \n-    def set_attention_implementation(self, attn_implementation: Union[str, dict]):\n+    def set_attention_implementation(self, attn_implementation: Union[dict, str]):\n         \"\"\"\n         Checks and dispatches to hhe requested attention implementation.\n         \"\"\""
        },
        {
            "sha": "27ecb84306af9454bd35d438844d58b18b4a2d8f",
            "filename": "tests/utils/test_hf_argparser.py",
            "status": "modified",
            "additions": 27,
            "deletions": 20,
            "changes": 47,
            "blob_url": "https://github.com/huggingface/transformers/blob/73869f2e81467db8422cbb4831cce9a7bdc85c4b/tests%2Futils%2Ftest_hf_argparser.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/73869f2e81467db8422cbb4831cce9a7bdc85c4b/tests%2Futils%2Ftest_hf_argparser.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_hf_argparser.py?ref=73869f2e81467db8422cbb4831cce9a7bdc85c4b",
            "patch": "@@ -23,6 +23,7 @@\n from enum import Enum\n from pathlib import Path\n from typing import Literal, Optional, Union, get_args, get_origin\n+from unittest.mock import patch\n \n import yaml\n \n@@ -160,7 +161,7 @@ def argparsersEqual(self, a: argparse.ArgumentParser, b: argparse.ArgumentParser\n \n             self.assertEqual(xx, yy)\n \n-    def test_basic(self):\n+    def test_00_basic(self):\n         parser = HfArgumentParser(BasicExample)\n \n         expected = argparse.ArgumentParser()\n@@ -174,15 +175,15 @@ def test_basic(self):\n         (example,) = parser.parse_args_into_dataclasses(args, look_for_args_file=False)\n         self.assertFalse(example.flag)\n \n-    def test_with_default(self):\n+    def test_01_with_default(self):\n         parser = HfArgumentParser(WithDefaultExample)\n \n         expected = argparse.ArgumentParser()\n         expected.add_argument(\"--foo\", default=42, type=int)\n         expected.add_argument(\"--baz\", default=\"toto\", type=str, help=\"help message\")\n         self.argparsersEqual(parser, expected)\n \n-    def test_with_default_bool(self):\n+    def test_02_with_default_bool(self):\n         expected = argparse.ArgumentParser()\n         expected.add_argument(\"--foo\", type=string_to_bool, default=False, const=True, nargs=\"?\")\n         expected.add_argument(\"--baz\", type=string_to_bool, default=True, const=True, nargs=\"?\")\n@@ -217,7 +218,7 @@ def test_with_default_bool(self):\n             args = parser.parse_args([\"--foo\", \"False\", \"--baz\", \"False\", \"--opt\", \"False\"])\n             self.assertEqual(args, Namespace(foo=False, baz=False, opt=False))\n \n-    def test_with_enum(self):\n+    def test_03_with_enum(self):\n         parser = HfArgumentParser(MixedTypeEnumExample)\n \n         expected = argparse.ArgumentParser()\n@@ -244,7 +245,7 @@ def test_with_enum(self):\n         enum_ex = parser.parse_args_into_dataclasses([\"--foo\", \"42\"])[0]\n         self.assertEqual(enum_ex.foo, MixedTypeEnum.fourtytwo)\n \n-    def test_with_literal(self):\n+    def test_04_with_literal(self):\n         @dataclass\n         class LiteralExample:\n             foo: Literal[\"titi\", \"toto\", 42] = \"toto\"\n@@ -269,7 +270,7 @@ class LiteralExample:\n         args = parser.parse_args([\"--foo\", \"42\"])\n         self.assertEqual(args.foo, 42)\n \n-    def test_with_list(self):\n+    def test_05_with_list(self):\n         parser = HfArgumentParser(ListExample)\n \n         expected = argparse.ArgumentParser()\n@@ -292,7 +293,7 @@ def test_with_list(self):\n         args = parser.parse_args(\"--foo-int 1 --bar-int 2 3 --foo-str a b c --foo-float 0.1 0.7\".split())\n         self.assertEqual(args, Namespace(foo_int=[1], bar_int=[2, 3], foo_str=[\"a\", \"b\", \"c\"], foo_float=[0.1, 0.7]))\n \n-    def test_with_optional(self):\n+    def test_06_with_optional(self):\n         expected = argparse.ArgumentParser()\n         expected.add_argument(\"--foo\", default=None, type=int)\n         expected.add_argument(\"--bar\", default=None, type=float, help=\"help message\")\n@@ -315,7 +316,7 @@ def test_with_optional(self):\n             args = parser.parse_args(\"--foo 12 --bar 3.14 --baz 42 --ces a b c --des 1 2 3\".split())\n             self.assertEqual(args, Namespace(foo=12, bar=3.14, baz=\"42\", ces=[\"a\", \"b\", \"c\"], des=[1, 2, 3]))\n \n-    def test_with_required(self):\n+    def test_07_with_required(self):\n         parser = HfArgumentParser(RequiredExample)\n \n         expected = argparse.ArgumentParser()\n@@ -330,7 +331,7 @@ def test_with_required(self):\n         )\n         self.argparsersEqual(parser, expected)\n \n-    def test_with_string_literal_annotation(self):\n+    def test_08_with_string_literal_annotation(self):\n         parser = HfArgumentParser(StringLiteralAnnotationExample)\n \n         expected = argparse.ArgumentParser()\n@@ -347,7 +348,7 @@ def test_with_string_literal_annotation(self):\n         expected.add_argument(\"--foo_str\", \"--foo-str\", nargs=\"+\", default=[\"Hallo\", \"Bonjour\", \"Hello\"], type=str)\n         self.argparsersEqual(parser, expected)\n \n-    def test_parse_dict(self):\n+    def test_09_parse_dict(self):\n         parser = HfArgumentParser(BasicExample)\n \n         args_dict = {\n@@ -361,7 +362,7 @@ def test_parse_dict(self):\n         args = BasicExample(**args_dict)\n         self.assertEqual(parsed_args, args)\n \n-    def test_parse_dict_extra_key(self):\n+    def test_10_parse_dict_extra_key(self):\n         parser = HfArgumentParser(BasicExample)\n \n         args_dict = {\n@@ -374,7 +375,7 @@ def test_parse_dict_extra_key(self):\n \n         self.assertRaises(ValueError, parser.parse_dict, args_dict, allow_extra_keys=False)\n \n-    def test_parse_json(self):\n+    def test_11_parse_json(self):\n         parser = HfArgumentParser(BasicExample)\n \n         args_dict_for_json = {\n@@ -393,7 +394,7 @@ def test_parse_json(self):\n         args = BasicExample(**args_dict_for_json)\n         self.assertEqual(parsed_args, args)\n \n-    def test_parse_yaml(self):\n+    def test_12_parse_yaml(self):\n         parser = HfArgumentParser(BasicExample)\n \n         args_dict_for_yaml = {\n@@ -411,12 +412,7 @@ def test_parse_yaml(self):\n         args = BasicExample(**args_dict_for_yaml)\n         self.assertEqual(parsed_args, args)\n \n-    def test_z_integration_training_args(self):\n-        # make sure that this test executes last in the test suite\n-        parser = HfArgumentParser(TrainingArguments)\n-        self.assertIsNotNone(parser)\n-\n-    def test_valid_dict_annotation(self):\n+    def test_13_valid_dict_annotation(self):\n         \"\"\"\n         Tests to make sure that `dict` based annotations\n         are correctly made in the `TrainingArguments`.\n@@ -475,11 +471,22 @@ def test_valid_dict_annotation(self):\n             )\n \n     @require_torch\n-    def test_valid_dict_input_parsing(self):\n+    def test_14_valid_dict_input_parsing(self):\n         with tempfile.TemporaryDirectory() as tmp_dir:\n             args = TrainingArguments(\n                 output_dir=tmp_dir,\n                 accelerator_config='{\"split_batches\": \"True\", \"gradient_accumulation_kwargs\": {\"num_steps\": 2}}',\n             )\n             self.assertEqual(args.accelerator_config.split_batches, True)\n             self.assertEqual(args.accelerator_config.gradient_accumulation_kwargs[\"num_steps\"], 2)\n+\n+    def test_15_integration_training_args(self):\n+        parser = HfArgumentParser(TrainingArguments)\n+        self.assertIsNotNone(parser)\n+\n+    @require_torch\n+    @patch(\"sys.argv\", [\"test.py\", \"--accelerator_config\", '{\"gradient_accumulation_kwargs\": {\"num_steps\": 2}}'])\n+    def test_16_cli_input_parsing(self):\n+        parser = HfArgumentParser(TrainingArguments)\n+        training_args = parser.parse_args_into_dataclasses()[0]\n+        self.assertEqual(training_args.accelerator_config.gradient_accumulation_kwargs[\"num_steps\"], 2)"
        }
    ],
    "stats": {
        "total": 57,
        "additions": 32,
        "deletions": 25
    }
}