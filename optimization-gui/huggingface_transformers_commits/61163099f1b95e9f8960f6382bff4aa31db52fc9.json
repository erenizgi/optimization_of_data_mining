{
    "author": "cyyever",
    "message": "Remove runtime conditions for type checking (#37340)\n\nRemove dynamic conditions for type checking\n\nSigned-off-by: cyy <cyyever@outlook.com>\nCo-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>",
    "sha": "61163099f1b95e9f8960f6382bff4aa31db52fc9",
    "files": [
        {
            "sha": "aeb448ab1e64e225979d3725d346ddf587a3dfa9",
            "filename": "src/transformers/__init__.py",
            "status": "modified",
            "additions": 167,
            "deletions": 236,
            "changes": 403,
            "blob_url": "https://github.com/huggingface/transformers/blob/61163099f1b95e9f8960f6382bff4aa31db52fc9/src%2Ftransformers%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/61163099f1b95e9f8960f6382bff4aa31db52fc9/src%2Ftransformers%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2F__init__.py?ref=61163099f1b95e9f8960f6382bff4aa31db52fc9",
            "patch": "@@ -565,7 +565,28 @@\n # Direct imports for type-checking\n if TYPE_CHECKING:\n     # All modeling imports\n+    from .cache_utils import (\n+        Cache,\n+        CacheConfig,\n+        DynamicCache,\n+        EncoderDecoderCache,\n+        HQQQuantizedCache,\n+        HybridCache,\n+        MambaCache,\n+        OffloadedCache,\n+        OffloadedStaticCache,\n+        QuantizedCache,\n+        QuantizedCacheConfig,\n+        QuantoQuantizedCache,\n+        SinkCache,\n+        SlidingWindowCache,\n+        StaticCache,\n+    )\n     from .configuration_utils import PretrainedConfig\n+    from .convert_slow_tokenizer import (\n+        SLOW_TO_FAST_CONVERTERS,\n+        convert_slow_tokenizer,\n+    )\n \n     # Data\n     from .data import (\n@@ -602,21 +623,117 @@\n         DefaultDataCollator,\n         default_data_collator,\n     )\n+    from .data.datasets import (\n+        GlueDataset,\n+        GlueDataTrainingArguments,\n+        LineByLineTextDataset,\n+        LineByLineWithRefDataset,\n+        LineByLineWithSOPTextDataset,\n+        SquadDataset,\n+        SquadDataTrainingArguments,\n+        TextDataset,\n+        TextDatasetForNextSentencePrediction,\n+    )\n     from .feature_extraction_sequence_utils import SequenceFeatureExtractor\n \n     # Feature Extractor\n     from .feature_extraction_utils import BatchFeature, FeatureExtractionMixin\n \n     # Generation\n     from .generation import (\n+        AlternatingCodebooksLogitsProcessor,\n         AsyncTextIteratorStreamer,\n+        BayesianDetectorConfig,\n+        BayesianDetectorModel,\n+        BeamScorer,\n+        BeamSearchScorer,\n+        ClassifierFreeGuidanceLogitsProcessor,\n         CompileConfig,\n+        ConstrainedBeamSearchScorer,\n+        Constraint,\n+        ConstraintListState,\n+        DisjunctiveConstraint,\n+        EncoderNoRepeatNGramLogitsProcessor,\n+        EncoderRepetitionPenaltyLogitsProcessor,\n+        EosTokenCriteria,\n+        EpsilonLogitsWarper,\n+        EtaLogitsWarper,\n+        ExponentialDecayLengthPenalty,\n+        FlaxForcedBOSTokenLogitsProcessor,\n+        FlaxForcedEOSTokenLogitsProcessor,\n+        FlaxForceTokensLogitsProcessor,\n+        FlaxGenerationMixin,\n+        FlaxLogitsProcessor,\n+        FlaxLogitsProcessorList,\n+        FlaxLogitsWarper,\n+        FlaxMinLengthLogitsProcessor,\n+        FlaxSuppressTokensAtBeginLogitsProcessor,\n+        FlaxSuppressTokensLogitsProcessor,\n+        FlaxTemperatureLogitsWarper,\n+        FlaxTopKLogitsWarper,\n+        FlaxTopPLogitsWarper,\n+        FlaxWhisperTimeStampLogitsProcessor,\n+        ForcedBOSTokenLogitsProcessor,\n+        ForcedEOSTokenLogitsProcessor,\n         GenerationConfig,\n+        GenerationMixin,\n+        HammingDiversityLogitsProcessor,\n+        InfNanRemoveLogitsProcessor,\n+        LogitNormalization,\n+        LogitsProcessor,\n+        LogitsProcessorList,\n+        MaxLengthCriteria,\n+        MaxTimeCriteria,\n+        MinLengthLogitsProcessor,\n+        MinNewTokensLengthLogitsProcessor,\n+        MinPLogitsWarper,\n+        NoBadWordsLogitsProcessor,\n+        NoRepeatNGramLogitsProcessor,\n+        PhrasalConstraint,\n+        PrefixConstrainedLogitsProcessor,\n+        RepetitionPenaltyLogitsProcessor,\n+        SequenceBiasLogitsProcessor,\n+        StoppingCriteria,\n+        StoppingCriteriaList,\n+        StopStringCriteria,\n+        SuppressTokensAtBeginLogitsProcessor,\n+        SuppressTokensLogitsProcessor,\n+        SynthIDTextWatermarkDetector,\n+        SynthIDTextWatermarkingConfig,\n+        SynthIDTextWatermarkLogitsProcessor,\n+        TemperatureLogitsWarper,\n         TextIteratorStreamer,\n         TextStreamer,\n+        TFForcedBOSTokenLogitsProcessor,\n+        TFForcedEOSTokenLogitsProcessor,\n+        TFForceTokensLogitsProcessor,\n+        TFGenerationMixin,\n+        TFLogitsProcessor,\n+        TFLogitsProcessorList,\n+        TFLogitsWarper,\n+        TFMinLengthLogitsProcessor,\n+        TFNoBadWordsLogitsProcessor,\n+        TFNoRepeatNGramLogitsProcessor,\n+        TFRepetitionPenaltyLogitsProcessor,\n+        TFSuppressTokensAtBeginLogitsProcessor,\n+        TFSuppressTokensLogitsProcessor,\n+        TFTemperatureLogitsWarper,\n+        TFTopKLogitsWarper,\n+        TFTopPLogitsWarper,\n+        TopKLogitsWarper,\n+        TopPLogitsWarper,\n+        TypicalLogitsWarper,\n+        UnbatchedClassifierFreeGuidanceLogitsProcessor,\n+        WatermarkDetector,\n         WatermarkingConfig,\n+        WatermarkLogitsProcessor,\n+        WhisperTimeStampLogitsProcessor,\n     )\n     from .hf_argparser import HfArgumentParser\n+    from .image_processing_base import ImageProcessingMixin\n+    from .image_processing_utils import BaseImageProcessor\n+    from .image_processing_utils_fast import BaseImageProcessorFast\n+    from .image_utils import ImageFeatureExtractionMixin\n \n     # Integrations\n     from .integrations import (\n@@ -632,9 +749,21 @@\n         is_tensorboard_available,\n         is_wandb_available,\n     )\n+    from .integrations.executorch import (\n+        TorchExportableModuleWithStaticCache,\n+        convert_and_export_with_cache,\n+    )\n+    from .keras_callbacks import KerasMetricCallback, PushToHubCallback\n+    from .masking_utils import AttentionMaskInterface\n+    from .model_debugging_utils import (\n+        model_addition_debugger_context,\n+    )\n \n     # Model Cards\n     from .modelcard import ModelCard\n+    from .modeling_flax_utils import FlaxPreTrainedModel\n+    from .modeling_layers import GradientCheckpointingLayer\n+    from .modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update\n \n     # TF 2.0 <=> PyTorch conversion utilities\n     from .modeling_tf_pytorch_utils import (\n@@ -646,7 +775,37 @@\n         load_tf2_model_in_pytorch_model,\n         load_tf2_weights_in_pytorch_model,\n     )\n+    from .modeling_tf_utils import (\n+        TFPreTrainedModel,\n+        TFSequenceSummary,\n+        TFSharedEmbeddings,\n+        shape_list,\n+    )\n+    from .modeling_utils import AttentionInterface, PreTrainedModel\n     from .models import *\n+    from .models.timm_wrapper import TimmWrapperImageProcessor\n+\n+    # Optimization\n+    from .optimization import (\n+        Adafactor,\n+        get_constant_schedule,\n+        get_constant_schedule_with_warmup,\n+        get_cosine_schedule_with_warmup,\n+        get_cosine_with_hard_restarts_schedule_with_warmup,\n+        get_inverse_sqrt_schedule,\n+        get_linear_schedule_with_warmup,\n+        get_polynomial_decay_schedule_with_warmup,\n+        get_scheduler,\n+        get_wsd_schedule,\n+    )\n+\n+    # Optimization\n+    from .optimization_tf import (\n+        AdamWeightDecay,\n+        GradientAccumulator,\n+        WarmUp,\n+        create_optimizer,\n+    )\n \n     # Pipelines\n     from .pipelines import (\n@@ -688,6 +847,7 @@\n         pipeline,\n     )\n     from .processing_utils import ProcessorMixin\n+    from .pytorch_utils import Conv1D, apply_chunking_to_forward, prune_layer\n \n     # Tokenization\n     from .tokenization_utils import PreTrainedTokenizer\n@@ -699,6 +859,10 @@\n         SpecialTokensMixin,\n         TokenSpan,\n     )\n+    from .tokenization_utils_fast import PreTrainedTokenizerFast\n+\n+    # Trainer\n+    from .trainer import Trainer\n \n     # Trainer\n     from .trainer_callback import (\n@@ -710,6 +874,8 @@\n         TrainerControl,\n         TrainerState,\n     )\n+    from .trainer_pt_utils import torch_distributed_zero_first\n+    from .trainer_seq2seq import Seq2SeqTrainer\n     from .trainer_utils import (\n         EvalPrediction,\n         IntervalStrategy,\n@@ -790,242 +956,7 @@\n         TorchAoConfig,\n         VptqConfig,\n     )\n-\n-    try:\n-        if not is_tokenizers_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        from .utils.dummy_tokenizers_objects import *\n-    else:\n-        from .tokenization_utils_fast import PreTrainedTokenizerFast\n-\n-    try:\n-        if not (is_sentencepiece_available() and is_tokenizers_available()):\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        from .utils.dummies_sentencepiece_and_tokenizers_objects import *\n-    else:\n-        from .convert_slow_tokenizer import (\n-            SLOW_TO_FAST_CONVERTERS,\n-            convert_slow_tokenizer,\n-        )\n-\n-    try:\n-        if not is_vision_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        from .utils.dummy_vision_objects import *\n-    else:\n-        from .image_processing_base import ImageProcessingMixin\n-        from .image_processing_utils import BaseImageProcessor\n-        from .image_utils import ImageFeatureExtractionMixin\n-\n-    try:\n-        if not is_torchvision_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        from .utils.dummy_torchvision_objects import *\n-    else:\n-        from .image_processing_utils_fast import BaseImageProcessorFast\n-        from .video_processing_utils import BaseVideoProcessor\n-\n-    try:\n-        if not (is_torchvision_available() and is_timm_available()):\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        from .utils.dummy_timm_and_torchvision_objects import *\n-    else:\n-        from .models.timm_wrapper import TimmWrapperImageProcessor\n-\n-    # Modeling\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        from .utils.dummy_pt_objects import *\n-    else:\n-        # Debugging\n-        from .cache_utils import (\n-            Cache,\n-            CacheConfig,\n-            DynamicCache,\n-            EncoderDecoderCache,\n-            HQQQuantizedCache,\n-            HybridCache,\n-            MambaCache,\n-            OffloadedCache,\n-            OffloadedStaticCache,\n-            QuantizedCache,\n-            QuantizedCacheConfig,\n-            QuantoQuantizedCache,\n-            SinkCache,\n-            SlidingWindowCache,\n-            StaticCache,\n-        )\n-        from .data.datasets import (\n-            GlueDataset,\n-            GlueDataTrainingArguments,\n-            LineByLineTextDataset,\n-            LineByLineWithRefDataset,\n-            LineByLineWithSOPTextDataset,\n-            SquadDataset,\n-            SquadDataTrainingArguments,\n-            TextDataset,\n-            TextDatasetForNextSentencePrediction,\n-        )\n-        from .generation import (\n-            AlternatingCodebooksLogitsProcessor,\n-            BayesianDetectorConfig,\n-            BayesianDetectorModel,\n-            BeamScorer,\n-            BeamSearchScorer,\n-            ClassifierFreeGuidanceLogitsProcessor,\n-            ConstrainedBeamSearchScorer,\n-            Constraint,\n-            ConstraintListState,\n-            DisjunctiveConstraint,\n-            EncoderNoRepeatNGramLogitsProcessor,\n-            EncoderRepetitionPenaltyLogitsProcessor,\n-            EosTokenCriteria,\n-            EpsilonLogitsWarper,\n-            EtaLogitsWarper,\n-            ExponentialDecayLengthPenalty,\n-            ForcedBOSTokenLogitsProcessor,\n-            ForcedEOSTokenLogitsProcessor,\n-            GenerationMixin,\n-            HammingDiversityLogitsProcessor,\n-            InfNanRemoveLogitsProcessor,\n-            LogitNormalization,\n-            LogitsProcessor,\n-            LogitsProcessorList,\n-            MaxLengthCriteria,\n-            MaxTimeCriteria,\n-            MinLengthLogitsProcessor,\n-            MinNewTokensLengthLogitsProcessor,\n-            MinPLogitsWarper,\n-            NoBadWordsLogitsProcessor,\n-            NoRepeatNGramLogitsProcessor,\n-            PhrasalConstraint,\n-            PrefixConstrainedLogitsProcessor,\n-            RepetitionPenaltyLogitsProcessor,\n-            SequenceBiasLogitsProcessor,\n-            StoppingCriteria,\n-            StoppingCriteriaList,\n-            StopStringCriteria,\n-            SuppressTokensAtBeginLogitsProcessor,\n-            SuppressTokensLogitsProcessor,\n-            SynthIDTextWatermarkDetector,\n-            SynthIDTextWatermarkingConfig,\n-            SynthIDTextWatermarkLogitsProcessor,\n-            TemperatureLogitsWarper,\n-            TopKLogitsWarper,\n-            TopPLogitsWarper,\n-            TypicalLogitsWarper,\n-            UnbatchedClassifierFreeGuidanceLogitsProcessor,\n-            WatermarkDetector,\n-            WatermarkLogitsProcessor,\n-            WhisperTimeStampLogitsProcessor,\n-        )\n-        from .integrations.executorch import (\n-            TorchExportableModuleWithStaticCache,\n-            convert_and_export_with_cache,\n-        )\n-        from .masking_utils import AttentionMaskInterface\n-        from .model_debugging_utils import (\n-            model_addition_debugger_context,\n-        )\n-        from .modeling_layers import GradientCheckpointingLayer\n-        from .modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update\n-        from .modeling_utils import AttentionInterface, PreTrainedModel\n-\n-        # Optimization\n-        from .optimization import (\n-            Adafactor,\n-            get_constant_schedule,\n-            get_constant_schedule_with_warmup,\n-            get_cosine_schedule_with_warmup,\n-            get_cosine_with_hard_restarts_schedule_with_warmup,\n-            get_inverse_sqrt_schedule,\n-            get_linear_schedule_with_warmup,\n-            get_polynomial_decay_schedule_with_warmup,\n-            get_scheduler,\n-            get_wsd_schedule,\n-        )\n-        from .pytorch_utils import Conv1D, apply_chunking_to_forward, prune_layer\n-\n-        # Trainer\n-        from .trainer import Trainer\n-        from .trainer_pt_utils import torch_distributed_zero_first\n-        from .trainer_seq2seq import Seq2SeqTrainer\n-\n-    # TensorFlow\n-    try:\n-        if not is_tf_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        # Import the same objects as dummies to get them in the namespace.\n-        # They will raise an import error if the user tries to instantiate / use them.\n-        from .utils.dummy_tf_objects import *\n-    else:\n-        from .generation import (\n-            TFForcedBOSTokenLogitsProcessor,\n-            TFForcedEOSTokenLogitsProcessor,\n-            TFForceTokensLogitsProcessor,\n-            TFGenerationMixin,\n-            TFLogitsProcessor,\n-            TFLogitsProcessorList,\n-            TFLogitsWarper,\n-            TFMinLengthLogitsProcessor,\n-            TFNoBadWordsLogitsProcessor,\n-            TFNoRepeatNGramLogitsProcessor,\n-            TFRepetitionPenaltyLogitsProcessor,\n-            TFSuppressTokensAtBeginLogitsProcessor,\n-            TFSuppressTokensLogitsProcessor,\n-            TFTemperatureLogitsWarper,\n-            TFTopKLogitsWarper,\n-            TFTopPLogitsWarper,\n-        )\n-        from .keras_callbacks import KerasMetricCallback, PushToHubCallback\n-        from .modeling_tf_utils import (\n-            TFPreTrainedModel,\n-            TFSequenceSummary,\n-            TFSharedEmbeddings,\n-            shape_list,\n-        )\n-\n-        # Optimization\n-        from .optimization_tf import (\n-            AdamWeightDecay,\n-            GradientAccumulator,\n-            WarmUp,\n-            create_optimizer,\n-        )\n-\n-    try:\n-        if not is_flax_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        # Import the same objects as dummies to get them in the namespace.\n-        # They will raise an import error if the user tries to instantiate / use them.\n-        from .utils.dummy_flax_objects import *\n-    else:\n-        from .generation import (\n-            FlaxForcedBOSTokenLogitsProcessor,\n-            FlaxForcedEOSTokenLogitsProcessor,\n-            FlaxForceTokensLogitsProcessor,\n-            FlaxGenerationMixin,\n-            FlaxLogitsProcessor,\n-            FlaxLogitsProcessorList,\n-            FlaxLogitsWarper,\n-            FlaxMinLengthLogitsProcessor,\n-            FlaxSuppressTokensAtBeginLogitsProcessor,\n-            FlaxSuppressTokensLogitsProcessor,\n-            FlaxTemperatureLogitsWarper,\n-            FlaxTopKLogitsWarper,\n-            FlaxTopPLogitsWarper,\n-            FlaxWhisperTimeStampLogitsProcessor,\n-        )\n-        from .modeling_flax_utils import FlaxPreTrainedModel\n+    from .video_processing_utils import BaseVideoProcessor\n \n else:\n     import sys"
        }
    ],
    "stats": {
        "total": 403,
        "additions": 167,
        "deletions": 236
    }
}