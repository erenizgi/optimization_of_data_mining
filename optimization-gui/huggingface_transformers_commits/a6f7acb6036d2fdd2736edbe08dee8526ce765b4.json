{
    "author": "yaswanth19",
    "message": "[Tests] Clean up test cases for few models (#38315)\n\n* Update tests\n\n* revert aria change\n\n* too slow hence revert",
    "sha": "a6f7acb6036d2fdd2736edbe08dee8526ce765b4",
    "files": [
        {
            "sha": "52ce99c86ff94028b0a78a2a9856faea59457a2b",
            "filename": "tests/models/qwen2_5_omni/test_processor_qwen2_5_omni.py",
            "status": "modified",
            "additions": 3,
            "deletions": 7,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/a6f7acb6036d2fdd2736edbe08dee8526ce765b4/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_processor_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a6f7acb6036d2fdd2736edbe08dee8526ce765b4/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_processor_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_processor_qwen2_5_omni.py?ref=a6f7acb6036d2fdd2736edbe08dee8526ce765b4",
            "patch": "@@ -204,8 +204,7 @@ def test_kwargs_overrides_default_tokenizer_kwargs_audio(self):\n     @classmethod\n     def setUpClass(cls):\n         cls.tmpdirname = tempfile.mkdtemp()\n-        processor_kwargs = cls.prepare_processor_dict()\n-        processor = Qwen2_5OmniProcessor.from_pretrained(\"Qwen/Qwen2.5-Omni-7B\", **processor_kwargs)\n+        processor = Qwen2_5OmniProcessor.from_pretrained(\"Qwen/Qwen2.5-Omni-7B\")\n         processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n@@ -220,11 +219,8 @@ def get_video_processor(self, **kwargs):\n     def get_feature_extractor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).feature_extractor\n \n-    @staticmethod\n-    def prepare_processor_dict():\n-        return {\n-            \"chat_template\": \"{% set audio_count = namespace(value=0) %}{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n{% endif %}<|im_start|>{{ message['role'] }}\\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\\n{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_bos|><|IMAGE|><|vision_eos|>{% elif content['type'] == 'audio' or 'audio' in content or 'audio_url' in content %}{% set audio_count.value = audio_count.value + 1 %}{% if add_audio_id %}Audio {{ audio_count.value }}: {% endif %}<|audio_bos|><|AUDIO|><|audio_eos|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_bos|><|VIDEO|><|vision_eos|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\"\n-        }\n+    def get_processor(self, **kwargs):\n+        return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs)\n \n     @classmethod\n     def tearDownClass(cls):"
        },
        {
            "sha": "2fc284c638bc74e5232faa02254a69dbe043cf27",
            "filename": "tests/models/qwen2_5_vl/test_processor_qwen2_5_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 11,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/a6f7acb6036d2fdd2736edbe08dee8526ce765b4/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_processor_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a6f7acb6036d2fdd2736edbe08dee8526ce765b4/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_processor_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_processor_qwen2_5_vl.py?ref=a6f7acb6036d2fdd2736edbe08dee8526ce765b4",
            "patch": "@@ -58,11 +58,8 @@ def get_image_processor(self, **kwargs):\n     def get_video_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).video_processor\n \n-    @staticmethod\n-    def prepare_processor_dict():\n-        return {\n-            \"chat_template\": \"{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n{% endif %}<|im_start|>{{ message['role'] }}\\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\\n{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\",\n-        }  # fmt: skip\n+    def get_processor(self, **kwargs):\n+        return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs)\n \n     @classmethod\n     def tearDownClass(cls):\n@@ -340,12 +337,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n         self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 160)\n \n     def test_kwargs_overrides_custom_image_processor_kwargs(self):\n-        processor_components = self.prepare_components()\n-        processor_components[\"image_processor\"] = self.get_component(\"image_processor\")\n-        processor_components[\"tokenizer\"] = self.get_component(\"tokenizer\")\n-        processor_kwargs = self.prepare_processor_dict()\n-\n-        processor = self.processor_class(**processor_components, **processor_kwargs, use_fast=True)\n+        processor = self.get_processor()\n         self.skip_processor_without_typed_kwargs(processor)\n \n         input_str = self.prepare_text_inputs()"
        },
        {
            "sha": "007b0d3c7ab03406b63e16fef97f6a9f8e54fecf",
            "filename": "tests/models/qwen2_audio/test_processor_qwen2_audio.py",
            "status": "modified",
            "additions": 4,
            "deletions": 8,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/a6f7acb6036d2fdd2736edbe08dee8526ce765b4/tests%2Fmodels%2Fqwen2_audio%2Ftest_processor_qwen2_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a6f7acb6036d2fdd2736edbe08dee8526ce765b4/tests%2Fmodels%2Fqwen2_audio%2Ftest_processor_qwen2_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_audio%2Ftest_processor_qwen2_audio.py?ref=a6f7acb6036d2fdd2736edbe08dee8526ce765b4",
            "patch": "@@ -36,8 +36,7 @@ def setUpClass(cls):\n         cls.checkpoint = \"Qwen/Qwen2-Audio-7B-Instruct\"\n         cls.tmpdirname = tempfile.mkdtemp()\n \n-        processor_kwargs = cls.prepare_processor_dict()\n-        processor = Qwen2AudioProcessor.from_pretrained(cls.checkpoint, **processor_kwargs)\n+        processor = Qwen2AudioProcessor.from_pretrained(cls.checkpoint)\n         processor.save_pretrained(cls.tmpdirname)\n         cls.audio_token = processor.audio_token\n \n@@ -47,16 +46,13 @@ def get_tokenizer(self, **kwargs):\n     def get_audio_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).audio_processor\n \n+    def get_processor(self, **kwargs):\n+        return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs)\n+\n     @classmethod\n     def tearDownClass(cls):\n         shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n-    @staticmethod\n-    def prepare_processor_dict():\n-        return {\n-            \"chat_template\": \"{% set audio_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n{% endif %}<|im_start|>{{ message['role'] }}\\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\\n{% else %}{% for content in message['content'] %}{% if 'audio' in content or 'audio_url' in content or content['type'] == 'audio' %}{% set audio_count.value = audio_count.value + 1 %}Audio {{ audio_count.value }}: <|audio_bos|><|AUDIO|><|audio_eos|>\\n{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\",\n-        }\n-\n     def test_can_load_various_tokenizers(self):\n         processor = Qwen2AudioProcessor.from_pretrained(self.checkpoint)\n         tokenizer = AutoTokenizer.from_pretrained(self.checkpoint)"
        },
        {
            "sha": "b109fbe078c188737b23c3f618c304f5065c348c",
            "filename": "tests/models/qwen2_vl/test_processor_qwen2_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 9,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/a6f7acb6036d2fdd2736edbe08dee8526ce765b4/tests%2Fmodels%2Fqwen2_vl%2Ftest_processor_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a6f7acb6036d2fdd2736edbe08dee8526ce765b4/tests%2Fmodels%2Fqwen2_vl%2Ftest_processor_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_vl%2Ftest_processor_qwen2_vl.py?ref=a6f7acb6036d2fdd2736edbe08dee8526ce765b4",
            "patch": "@@ -61,9 +61,8 @@ def get_image_processor(self, **kwargs):\n     def get_video_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).video_processor\n \n-    @staticmethod\n-    def prepare_processor_dict():\n-        return {\"chat_template\": \"{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n{% endif %}<|im_start|>{{ message['role'] }}\\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\\n{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\"}  # fmt: skip\n+    def get_processor(self, **kwargs):\n+        return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs)\n \n     @classmethod\n     def tearDownClass(cls):\n@@ -406,12 +405,7 @@ def _process_messages_for_chat_template(\n         self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 21960)\n \n     def test_kwargs_overrides_custom_image_processor_kwargs(self):\n-        processor_components = self.prepare_components()\n-        processor_components[\"image_processor\"] = self.get_component(\"image_processor\")\n-        processor_components[\"tokenizer\"] = self.get_component(\"tokenizer\")\n-        processor_kwargs = self.prepare_processor_dict()\n-\n-        processor = self.processor_class(**processor_components, **processor_kwargs, use_fast=True)\n+        processor = self.get_processor()\n         self.skip_processor_without_typed_kwargs(processor)\n \n         input_str = self.prepare_text_inputs()"
        }
    ],
    "stats": {
        "total": 48,
        "additions": 13,
        "deletions": 35
    }
}