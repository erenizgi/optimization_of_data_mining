{
    "author": "edwko",
    "message": "Handle DAC conversion when using weight_norm with newer PyTorch versions (#36393)\n\n* Update convert_dac_checkpoint.py\n\n* Update convert_dac_checkpoint.py\n\n* Apply style fixes\n\n---------\n\nCo-authored-by: github-actions[bot] <github-actions[bot]@users.noreply.github.com>\nCo-authored-by: Anton Vlasjuk <73884904+vasqu@users.noreply.github.com>",
    "sha": "6b09c8eab05820d480f4da97d23456428d410082",
    "files": [
        {
            "sha": "e69fcf96fb97f9bf044912f997a023950815f5bd",
            "filename": "src/transformers/models/dac/convert_dac_checkpoint.py",
            "status": "modified",
            "additions": 34,
            "deletions": 1,
            "changes": 35,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b09c8eab05820d480f4da97d23456428d410082/src%2Ftransformers%2Fmodels%2Fdac%2Fconvert_dac_checkpoint.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b09c8eab05820d480f4da97d23456428d410082/src%2Ftransformers%2Fmodels%2Fdac%2Fconvert_dac_checkpoint.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdac%2Fconvert_dac_checkpoint.py?ref=6b09c8eab05820d480f4da97d23456428d410082",
            "patch": "@@ -17,6 +17,7 @@\n import re\n \n import torch\n+import torch.nn as nn\n \n from transformers import (\n     DacConfig,\n@@ -185,6 +186,38 @@ def recursively_load_weights(orig_dict, hf_model, model_name):\n     logger.warning(f\"Unused weights: {unused_weights}\")\n \n \n+def apply_weight_norm(model):\n+    weight_norm = nn.utils.weight_norm\n+\n+    for layer in model.quantizer.quantizers:\n+        weight_norm(layer.in_proj)\n+        weight_norm(layer.out_proj)\n+\n+    weight_norm(model.encoder.conv1)\n+    weight_norm(model.encoder.conv2)\n+\n+    for layer in model.encoder.block:\n+        weight_norm(layer.conv1)\n+        weight_norm(layer.res_unit1.conv1)\n+        weight_norm(layer.res_unit1.conv2)\n+        weight_norm(layer.res_unit2.conv1)\n+        weight_norm(layer.res_unit2.conv2)\n+        weight_norm(layer.res_unit3.conv1)\n+        weight_norm(layer.res_unit3.conv2)\n+\n+    weight_norm(model.decoder.conv1)\n+    weight_norm(model.decoder.conv2)\n+\n+    for layer in model.decoder.block:\n+        weight_norm(layer.conv_t1)\n+        weight_norm(layer.res_unit1.conv1)\n+        weight_norm(layer.res_unit1.conv2)\n+        weight_norm(layer.res_unit2.conv1)\n+        weight_norm(layer.res_unit2.conv2)\n+        weight_norm(layer.res_unit3.conv1)\n+        weight_norm(layer.res_unit3.conv2)\n+\n+\n @torch.no_grad()\n def convert_checkpoint(\n     model_name,\n@@ -214,7 +247,7 @@ def convert_checkpoint(\n \n     original_checkpoint = model_dict[\"state_dict\"]\n \n-    model.apply_weight_norm()\n+    apply_weight_norm(model)\n     recursively_load_weights(original_checkpoint, model, model_name)\n     model.remove_weight_norm()\n "
        }
    ],
    "stats": {
        "total": 35,
        "additions": 34,
        "deletions": 1
    }
}