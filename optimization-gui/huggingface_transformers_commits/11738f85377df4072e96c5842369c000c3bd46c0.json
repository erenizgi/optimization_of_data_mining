{
    "author": "eustlb",
    "message": "[phi-4] use mel filters from audio utils (#36966)\n\n* use mel_filter_bank from audio utils\n\n* Apply style fixes\n\n---------\n\nCo-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>\nCo-authored-by: github-actions[bot] <github-actions[bot]@users.noreply.github.com>",
    "sha": "11738f85377df4072e96c5842369c000c3bd46c0",
    "files": [
        {
            "sha": "71ada3a8c62a27db1a31eecc5942ea55880ee950",
            "filename": "src/transformers/models/phi4_multimodal/feature_extraction_phi4_multimodal.py",
            "status": "modified",
            "additions": 10,
            "deletions": 74,
            "changes": 84,
            "blob_url": "https://github.com/huggingface/transformers/blob/11738f85377df4072e96c5842369c000c3bd46c0/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Ffeature_extraction_phi4_multimodal.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/11738f85377df4072e96c5842369c000c3bd46c0/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Ffeature_extraction_phi4_multimodal.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Ffeature_extraction_phi4_multimodal.py?ref=11738f85377df4072e96c5842369c000c3bd46c0",
            "patch": "@@ -20,7 +20,7 @@\n \n import numpy as np\n \n-from ...audio_utils import AudioInput\n+from ...audio_utils import AudioInput, mel_filter_bank\n from ...feature_extraction_sequence_utils import SequenceFeatureExtractor\n from ...image_processing_utils import BatchFeature\n from ...utils import TensorType, is_torch_available, logging\n@@ -33,66 +33,6 @@\n logger = logging.get_logger(__name__)\n \n \n-# TODO: @eustlb, remove this once #36603 is merged.\n-def speechlib_mel(sample_rate, n_fft, n_mels, fmin=None, fmax=None):\n-    \"\"\"Create a Mel filter-bank the same as SpeechLib FbankFC.\n-\n-    Args:\n-        sample_rate (int): Sample rate in Hz. number > 0 [scalar]\n-        n_fft (int): FFT size. int > 0 [scalar]\n-        n_mel (int): Mel filter size. int > 0 [scalar]\n-        fmin (float): lowest frequency (in Hz). If None use 0.0.\n-            float >= 0 [scalar]\n-        fmax: highest frequency (in Hz). If None use sample_rate / 2.\n-            float >= 0 [scalar]\n-\n-    Returns\n-        out (numpy.ndarray): Mel transform matrix\n-            [shape=(n_mels, 1 + n_fft/2)]\n-    \"\"\"\n-\n-    bank_width = int(n_fft // 2 + 1)\n-    if fmax is None:\n-        fmax = sample_rate / 2\n-    if fmin is None:\n-        fmin = 0\n-    assert fmin >= 0, \"fmin cannot be negative\"\n-    assert fmin < fmax <= sample_rate / 2, \"fmax must be between (fmin, samplerate / 2]\"\n-\n-    def mel(f):\n-        return 1127.0 * np.log(1.0 + f / 700.0)\n-\n-    def bin2mel(fft_bin):\n-        return 1127.0 * np.log(1.0 + fft_bin * sample_rate / (n_fft * 700.0))\n-\n-    def f2bin(f):\n-        return int((f * n_fft / sample_rate) + 0.5)\n-\n-    # Spec 1: FFT bin range [f2bin(fmin) + 1, f2bin(fmax) - 1]\n-    klo = f2bin(fmin) + 1\n-    khi = f2bin(fmax)\n-\n-    khi = max(khi, klo)\n-\n-    # Spec 2: SpeechLib uses triangles in Mel space\n-    mlo = mel(fmin)\n-    mhi = mel(fmax)\n-    m_centers = np.linspace(mlo, mhi, n_mels + 2)\n-    ms = (mhi - mlo) / (n_mels + 1)\n-\n-    matrix = np.zeros((n_mels, bank_width), dtype=np.float32)\n-    for m in range(0, n_mels):\n-        left = m_centers[m]\n-        center = m_centers[m + 1]\n-        right = m_centers[m + 2]\n-        for fft_bin in range(klo, khi):\n-            mbin = bin2mel(fft_bin)\n-            if left < mbin < right:\n-                matrix[m, fft_bin] = 1.0 - abs(center - mbin) / ms\n-\n-    return matrix\n-\n-\n class Phi4MultimodalFeatureExtractor(SequenceFeatureExtractor):\n     model_input_names = [\"audio_input_features\", \"audio_embed_sizes\", \"audio_attention_mask\"]\n \n@@ -123,19 +63,15 @@ def __init__(\n         self.audio_downsample_rate = audio_downsample_rate\n         self.audio_feat_stride = audio_feat_stride\n \n-        # TODO: @eustlb, uncomment and remove speechlib_mel once #36603 is merged.\n-        # self.mel_filters = mel_filter_bank(\n-        #     num_frequency_bins=self.n_fft // 2 + 1,\n-        #     num_mel_filters=self.feature_size,\n-        #     min_frequency=mel_min_frequency,\n-        #     max_frequency=mel_max_frequency,\n-        #     sampling_rate=self.sampling_rate,\n-        #     triangularize_in_mel_space=True,\n-        #     mel_scale=\"kaldi\",\n-        # )\n-        self.mel_filters = speechlib_mel(\n-            self.sampling_rate, self.n_fft, self.feature_size, mel_min_frequency, mel_max_frequency\n-        ).T\n+        self.mel_filters = mel_filter_bank(\n+            num_frequency_bins=self.n_fft // 2 + 1,\n+            num_mel_filters=self.feature_size,\n+            min_frequency=mel_min_frequency,\n+            max_frequency=mel_max_frequency,\n+            sampling_rate=self.sampling_rate,\n+            triangularize_in_mel_space=True,\n+            mel_scale=\"kaldi\",\n+        )\n \n     def __call__(\n         self,"
        }
    ],
    "stats": {
        "total": 84,
        "additions": 10,
        "deletions": 74
    }
}