{
    "author": "chelsseeey",
    "message": "ğŸŒ [i18n-KO] Translated `optimizers.md` to Korean (#40011)\n\n* docs: ko: optimizers.md\n\n* feat: optimizers draft\n\n* fix: manual edits\n\n* docs: ko: update optimizers.md\n\n* Update docs/source/ko/optimizers.md\n\nCo-authored-by: Minseo Kim <75977640+luckyvickyricky@users.noreply.github.com>\n\n* Update docs/source/ko/optimizers.md\n\nCo-authored-by: Minseo Kim <75977640+luckyvickyricky@users.noreply.github.com>\n\n* Update docs/source/ko/optimizers.md\n\nCo-authored-by: Jaehyeon Shin <108786184+skwh54@users.noreply.github.com>\n\n* docs: ko: final updates to optimizers and toctree\n\n---------\n\nCo-authored-by: Minseo Kim <75977640+luckyvickyricky@users.noreply.github.com>\nCo-authored-by: Jaehyeon Shin <108786184+skwh54@users.noreply.github.com>",
    "sha": "127e33f759ee86571b01d3d2e6ea7d684aed4e15",
    "files": [
        {
            "sha": "586c11e006cff8278006ff108749719bb681a27f",
            "filename": "docs/source/ko/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/127e33f759ee86571b01d3d2e6ea7d684aed4e15/docs%2Fsource%2Fko%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/127e33f759ee86571b01d3d2e6ea7d684aed4e15/docs%2Fsource%2Fko%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2F_toctree.yml?ref=127e33f759ee86571b01d3d2e6ea7d684aed4e15",
            "patch": "@@ -117,8 +117,8 @@\n       title: íŠ¸ë ˆì´ë„ˆ(Trainer)\n     - local: training\n       title: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¯¸ì„¸ ì¡°ì •í•˜ê¸°\n-    - local: in_translation\n-      title: (ë²ˆì—­ì¤‘) Optimizers\n+    - local: optimizers\n+      title: ì˜µí‹°ë§ˆì´ì €(Optimizers)\n     - local: hpo_train\n       title: Trainer APIë¥¼ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰\n     title: Trainer API"
        },
        {
            "sha": "64d5e4e2def83320c7c23970ad8664f09ec07559",
            "filename": "docs/source/ko/optimizers.md",
            "status": "added",
            "additions": 201,
            "deletions": 0,
            "changes": 201,
            "blob_url": "https://github.com/huggingface/transformers/blob/127e33f759ee86571b01d3d2e6ea7d684aed4e15/docs%2Fsource%2Fko%2Foptimizers.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/127e33f759ee86571b01d3d2e6ea7d684aed4e15/docs%2Fsource%2Fko%2Foptimizers.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Foptimizers.md?ref=127e33f759ee86571b01d3d2e6ea7d684aed4e15",
            "patch": "@@ -0,0 +1,201 @@\n+<!--Copyright 2024 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n+\n+âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+\n+# ì˜µí‹°ë§ˆì´ì €[[optimizers]]\n+\n+TransformersëŠ” AdamW ë° AdaFactorì™€ ê°™ì€ ë‘ ê°€ì§€ ê¸°ë³¸ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ë³´ë‹¤ íŠ¹í™”ëœ ì˜µí‹°ë§ˆì´ì €ì™€ì˜ í†µí•©ë„ ì§€ì›í•©ë‹ˆë‹¤. ì›í•˜ëŠ” ì˜µí‹°ë§ˆì´ì €ë¥¼ ì œê³µí•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œ í›„, [`TrainingArguments`]ì˜ `optim` íŒŒë¼ë¯¸í„°ì— í•´ë‹¹ ì˜µí‹°ë§ˆì´ì €ëª…ì„ ì§€ì •í•˜ì‹œë©´ ë©ë‹ˆë‹¤. \n+\n+ì´ ê°€ì´ë“œì—ì„œëŠ” ì•„ë˜ì— ì œì‹œëœ [`TrainingArguments`]ì™€ í•¨ê»˜ [`Trainer`]ì—ì„œ ì´ëŸ¬í•œ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤. \n+\n+```py\n+import torch\n+from transformers import TrainingArguments, AutoTokenizer, AutoModelForCausalLM, Trainer\n+\n+args = TrainingArguments(\n+    output_dir=\"./test-optimizer\",\n+    max_steps=1000,\n+    per_device_train_batch_size=4,\n+    logging_strategy=\"steps\",\n+    logging_steps=1,\n+    learning_rate=2e-5,\n+    save_strategy=\"no\",\n+    run_name=\"optimizer-name\",\n+)\n+```\n+\n+## APOLLO[[apollo]]\n+\n+```bash\n+pip install apollo-torch\n+```\n+\n+[Approximated Gradient Scaling for Memory Efficient LLM Optimization (APOLLO)](https://github.com/zhuhanqing/APOLLO) ëŠ” ì‚¬ì „ í•™ìŠµê³¼ ë¯¸ì„¸ ì¡°ì • ëª¨ë‘ì— ëŒ€í•´ ì „ì²´ íŒŒë¼ë¯¸í„° í•™ìŠµì„ ì§€ì›í•˜ëŠ”, ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì˜µí‹°ë§ˆì´ì €ì…ë‹ˆë‹¤. ì´ ì˜µí‹°ë§ˆì´ì €ëŠ” SGDì™€ ìœ ì‚¬í•œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ìœ¼ë¡œ AdamW ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤. ê·¹í•œì˜ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì´ í•„ìš”í•˜ë‹¤ë©´ APOLLOì˜ rank 1 ë³€í˜•ì¸ APOLLO-Minië¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. APOLLO ì˜µí‹°ë§ˆì´ì €ëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ì§€ì›í•©ë‹ˆë‹¤. \n+\n+* ì´ˆì €ë­í¬(rank) íš¨ìœ¨ì„±. [GaLoRE](./trainer#galore)ë³´ë‹¤ í›¨ì”¬ ë‚®ì€ ë­í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ë­í¬ 1ë¡œë„ ì¶©ë¶„í•©ë‹ˆë‹¤.\n+* ê³ ë¹„ìš© SVD ì—°ì‚° íšŒí”¼. APOLLOëŠ” í•™ìŠµ ì¤‘ë‹¨(training stalls)ì„ í”¼í•˜ê¸° ìœ„í•´ ë¬´ì‘ìœ„ íˆ¬ì˜(random projections)ì„ í™œìš©í•©ë‹ˆë‹¤.\n+\n+í•™ìŠµí•  ë ˆì´ì–´ë¥¼ ì§€ì •í•˜ë ¤ë©´ `optim_target_modules` íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. \n+\n+```diff\n+import torch\n+from transformers import TrainingArguments\n+\n+args = TrainingArguments(\n+    output_dir=\"./test-apollo\",\n+    max_steps=100,\n+    per_device_train_batch_size=2,\n++   optim=\"apollo_adamw\",\n++   optim_target_modules=[r\".*.attn.*\", r\".*.mlp.*\"],\n+    logging_strategy=\"steps\",\n+    logging_steps=1,\n+    learning_rate=2e-5,\n+    save_strategy=\"no\",\n+    run_name=\"apollo_adamw\",\n+)\n+```\n+\n+ì¶”ê°€ì ì¸ í•™ìŠµ ì˜µì…˜ì´ í•„ìš”í•˜ë‹¤ë©´, `optim_args`ë¥¼ ì‚¬ìš©í•˜ì—¬ `rank`, `scale` ë“±ê³¼ ê°™ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ëª©ë¡ì€ ì•„ë˜ í‘œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n+\n+> [!TIP]\n+> `scale` íŒŒë¼ë¯¸í„°ëŠ” `n/r`ìœ¼ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë•Œ, `n`ì€ ì›ë³¸ ê³µê°„ ì°¨ì›ì´ê³  `r`ì€ ì €ë­í¬(low-rank) ê³µê°„ ì°¨ì›ì…ë‹ˆë‹¤. `scale`ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ìœ ì§€í•˜ë©´ì„œ í•™ìŠµë¥ ë§Œ ì¡°ì •í•´ë„ ë¹„ìŠ·í•œ íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+| ë§¤ê°œ ë³€ìˆ˜ | ì„¤ëª… | APOLLO | APOLLO-Mini |\n+|---|---|---|---|\n+| rank | ê·¸ë˜ë””ì–¸íŠ¸ ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•œ ë³´ì¡° ë¶€ë¶„ ê³µê°„(sub-space)ì˜ ë­í¬ | 256 | 1 |\n+| scale_type | ìŠ¤ì¼€ì¼ë§ ì¸ì(factor)ë¥¼ ì ìš©í•˜ëŠ” ë°©ë²• | `channel` (ì±„ë„ë³„ ìŠ¤ì¼€ì¼ë§) | `tensor` (í…ì„œë³„ ìŠ¤ì¼€ì¼ë§) |\n+| scale | ê·¸ë˜ë””ì–¸íŠ¸ ì—…ë°ì´íŠ¸ë¥¼ ì¡°ì •í•˜ì—¬ í•™ìŠµì„ ì•ˆì •í™” | 1.0 | 128 |\n+| update_proj_gap | íˆ¬ì˜ í–‰ë ¬(projection matrices)ì„ ì—…ë°ì´íŠ¸í•˜ê¸° ì „ ë‹¨ê³„(step) ìˆ˜ | 200 | 200 |\n+| proj | íˆ¬ì˜(projection) ìœ í˜• | `random` | `random` |\n+\n+ì•„ë˜ ì˜ˆì‹œëŠ” APOLLO-Mini ì˜µí‹°ë§ˆì´ì €ë¥¼ í™œì„±í™”í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n+\n+```py\n+from transformers import TrainingArguments\n+\n+args = TrainingArguments(\n+    output_dir=\"./test-apollo_mini\",\n+    max_steps=100,\n+    per_device_train_batch_size=2,\n+    optim=\"apollo_adamw\",\n+    optim_target_modules=[r\".*.attn.*\", r\".*.mlp.*\"],\n+    optim_args=\"proj=random,rank=1,scale=128.0,scale_type=tensor,update_proj_gap=200\",\n+)\n+```\n+\n+## GrokAdamW[[grokadamw]]\n+\n+```bash\n+pip install grokadamw\n+```\n+\n+[GrokAdamW](https://github.com/cognitivecomputations/grokadamw)ëŠ” *grokking* í˜„ìƒ(ê¸°ìš¸ê¸°ê°€ ì²œì²œíˆ ë³€í™”í•´ ì¼ë°˜í™”ê°€ ì§€ì—°ë˜ëŠ” í˜„ìƒ)ì—ì„œ ì„±ëŠ¥ì´ í–¥ìƒë˜ëŠ” ëª¨ë¸ë“¤ì—ê²Œ ì í•©í•˜ë„ë¡ ì„¤ê³„ëœ ì˜µí‹°ë§ˆì´ì €ì…ë‹ˆë‹¤. GrokAdamWëŠ” ë” ë›°ì–´ë‚œ ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì„ ìœ„í•´ ê³ ê¸‰ ìµœì í™” ê¸°ìˆ ì´ í•„ìš”í•œ ëª¨ë¸ì— íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤. \n+\n+```diff\n+import torch\n+from transformers import TrainingArguments\n+\n+args = TrainingArguments(\n+    output_dir=\"./test-grokadamw\",\n+    max_steps=1000,\n+    per_device_train_batch_size=4,\n++   optim=\"grokadamw\",\n+    logging_strategy=\"steps\",\n+    logging_steps=1,\n+    learning_rate=2e-5,\n+    save_strategy=\"no\",\n+    run_name=\"grokadamw\",\n+)\n+```\n+\n+## LOMO[[lomo]]\n+\n+```bash\n+pip install lomo-optim\n+```\n+\n+[Low-Memory Optimization (LOMO)](https://github.com/OpenLMLab/LOMO)ëŠ” LLMì˜ ì „ì²´ íŒŒë¼ë¯¸í„°ë¥¼ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ì˜µí‹°ë§ˆì´ì € ì œí’ˆêµ°ì´ë©°, [LOMO](https://huggingface.co/papers/2306.09782)ì™€ [AdaLomo](https://hf.co/papers/2310.10195) ë‘ ê°€ì§€ ë²„ì „ì´ ìˆìŠµë‹ˆë‹¤. ë‘ LOMO ì˜µí‹°ë§ˆì´ì €ëŠ” ëª¨ë‘ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ê³¼ ë§¤ê°œë³€ìˆ˜ ì—…ë°ì´íŠ¸ë¥¼ í•œ ë‹¨ê³„ë¡œ í†µí•©í•©ë‹ˆë‹¤. AdaLomoëŠ” LOMOë¥¼ ê¸°ë°˜ìœ¼ë¡œ, Adam ì˜µí‹°ë§ˆì´ì €ì²˜ëŸ¼ ê° ë§¤ê°œë³€ìˆ˜ì— ëŒ€í•´ ì ì‘í˜• í•™ìŠµë¥ ì„ ì ìš©í•˜ëŠ” ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.\n+\n+> [!TIP]\n+> ë” ë‚˜ì€ ì„±ëŠ¥ê³¼ ë†’ì€ ì²˜ë¦¬ëŸ‰ì„ ìœ„í•´ì„œëŠ” `grad_norm` ì—†ì´ AdaLomoë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n+\n+```diff\n+args = TrainingArguments(\n+    output_dir=\"./test-lomo\",\n+    max_steps=1000,\n+    per_device_train_batch_size=4,\n++   optim=\"adalomo\",\n+    gradient_checkpointing=True,\n+    logging_strategy=\"steps\",\n+    logging_steps=1,\n+    learning_rate=2e-6,\n+    save_strategy=\"no\",\n+    run_name=\"adalomo\",\n+)\n+```\n+\n+## Schedule Free[[schedule-free]]\n+\n+```bash\n+pip install schedulefree\n+```\n+\n+[Schedule Free optimizer (SFO)](https://hf.co/papers/2405.15682)ëŠ” ê¸°ë³¸ ì˜µí‹°ë§ˆì´ì €ì˜ ëª¨ë©˜í…€ ëŒ€ì‹  í‰ê· í™”(averaging)ì™€ ë³´ê°„(interpolation)ì„ ì¡°í•©í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤. ë•ë¶„ì— ê¸°ì¡´ì˜ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ì™€ ë‹¬ë¦¬, SFOëŠ” í•™ìŠµë¥ ì„ ì ì§„ì ìœ¼ë¡œ ë‚®ì¶”ëŠ” ì ˆì°¨ê°€ ì•„ì˜ˆ í•„ìš” ì—†ìŠµë‹ˆë‹¤.\n+\n+SFOëŠ” RAdam(`schedule_free_radam`), AdamW(`schedule_free_adamw`), SGD(`schedule_free_sgd`) ì˜µí‹°ë§ˆì´ì €ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. RAdam ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” `warmup_steps`ë‚˜ `warmup_ratio` ì„¤ì •ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. \n+\n+ê¸°ë³¸ì ìœ¼ë¡œ `lr_scheduler_type=\"constant\"`ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤. ë‹¤ë¥¸ `lr_scheduler_type` ê°’ë„ ë™ì‘í•  ìˆœ ìˆìœ¼ë‚˜, SFO ì˜µí‹°ë§ˆì´ì €ì™€ ë‹¤ë¥¸ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ì„ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ SFOì˜ ì˜ë„ëœ ë™ì‘ê³¼ ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n+\n+```diff\n+args = TrainingArguments(\n+    output_dir=\"./test-schedulefree\",\n+    max_steps=1000,\n+    per_device_train_batch_size=4,\n++   optim=\"schedule_free_radamw\",\n++   lr_scheduler_type=\"constant\",\n+    gradient_checkpointing=True,\n+    logging_strategy=\"steps\",\n+    logging_steps=1,\n+    learning_rate=2e-6,\n+    save_strategy=\"no\",\n+    run_name=\"sfo\",\n+)\n+```\n+\n+## StableAdamW[[stableadamw]]\n+\n+```bash\n+pip install torch-optimi\n+```\n+\n+[StableAdamW](https://arxiv.org/pdf/2304.13013)ëŠ” AdamWì™€ AdaFactorë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì˜µí‹°ë§ˆì´ì €ì…ë‹ˆë‹¤. AdaFactorì˜ ì—…ë°ì´íŠ¸ í´ë¦¬í•‘(update clipping)ì´ AdamWì— ë„ì…ë˜ì–´ ë³„ë„ì˜ ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘(gradient clipping)ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤. ê·¸ ì™¸ì˜ ë™ì‘ì—ì„œëŠ” AdamWì™€ ì™„ë²½íˆ í˜¸í™˜ë˜ëŠ” ëŒ€ì²´ì œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+> [!TIP]\n+> ë°°ì¹˜(batch) í¬ê¸°ê°€ í¬ê±°ë‚˜ í›ˆë ¨ ì†ì‹¤(training loss)ì´ ê³„ì†í•´ì„œ ê¸‰ê²©í•˜ê²Œ ë³€ë™í•œë‹¤ë©´, beta_2 ê°’ì„ [0.95, 0.99] ì‚¬ì´ë¡œ ì¤„ì—¬ë³´ì„¸ìš”.\n+\n+```diff\n+args = TrainingArguments(\n+    output_dir=\"./test-stable-adamw\",\n+    max_steps=1000,\n+    per_device_train_batch_size=4,\n++   optim=\"stable_adamw\",\n+    gradient_checkpointing=True,\n+    logging_strategy=\"steps\",\n+    logging_steps=1,\n+    learning_rate=2e-6,\n+    save_strategy=\"no\",\n+    run_name=\"stable-adamw\",\n+)\n+```\n\\ No newline at end of file"
        }
    ],
    "stats": {
        "total": 205,
        "additions": 203,
        "deletions": 2
    }
}