{
    "author": "zucchini-nlp",
    "message": "ðŸš¨ [v5] Toggle the serialization format in processors (#41474)\n\n* toggle the serialization\n\n* prob this fixes it\n\n* fix tests\n\n* typo\n\n* delete legacy save entirely\n\n* remove extra nesting in if\n\n* revert test and serialzie a public attr instead of private",
    "sha": "7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
    "files": [
        {
            "sha": "0ef7f2edb689878734628dc786b178ac05a03846",
            "filename": "src/transformers/feature_extraction_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/src%2Ftransformers%2Ffeature_extraction_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/src%2Ftransformers%2Ffeature_extraction_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ffeature_extraction_utils.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -512,7 +512,10 @@ def get_feature_extractor_dict(\n             with open(resolved_feature_extractor_file, encoding=\"utf-8\") as reader:\n                 text = reader.read()\n             feature_extractor_dict = json.loads(text)\n-            feature_extractor_dict = feature_extractor_dict.get(\"feature_extractor\", feature_extractor_dict)\n+            if \"audio_processor\" in feature_extractor_dict:\n+                feature_extractor_dict = feature_extractor_dict[\"audio_processor\"]\n+            else:\n+                feature_extractor_dict = feature_extractor_dict.get(\"feature_extractor\", feature_extractor_dict)\n \n         except json.JSONDecodeError:\n             raise OSError("
        },
        {
            "sha": "82ea2dcfc632c6bd65974cd8c25983f38e622567",
            "filename": "src/transformers/models/auto/processing_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/src%2Ftransformers%2Fmodels%2Fauto%2Fprocessing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/src%2Ftransformers%2Fmodels%2Fauto%2Fprocessing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fprocessing_auto.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -300,7 +300,7 @@ def from_pretrained(cls, pretrained_model_name_or_path, **kwargs):\n         processor_config_file = cached_file(pretrained_model_name_or_path, PROCESSOR_NAME, **cached_file_kwargs)\n         if processor_config_file is not None:\n             config_dict, _ = ProcessorMixin.get_processor_dict(pretrained_model_name_or_path, **kwargs)\n-            processor_class = config_dict.get(\"processor_class\", None)\n+            processor_class = config_dict.get(\"processor_class\")\n             if \"AutoProcessor\" in config_dict.get(\"auto_map\", {}):\n                 processor_auto_map = config_dict[\"auto_map\"][\"AutoProcessor\"]\n "
        },
        {
            "sha": "cdef6c183795d54ac1e770bc0eac11480e9d4339",
            "filename": "src/transformers/processing_utils.py",
            "status": "modified",
            "additions": 55,
            "deletions": 99,
            "changes": 154,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/src%2Ftransformers%2Fprocessing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/src%2Ftransformers%2Fprocessing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fprocessing_utils.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -524,7 +524,6 @@ class ProcessorMixin(PushToHubMixin):\n     \"\"\"\n \n     attributes = [\"feature_extractor\", \"tokenizer\"]\n-    optional_attributes = [\"chat_template\", \"audio_tokenizer\"]\n     optional_call_args: list[str] = []\n     # Names need to be attr_class for attr in attributes\n     feature_extractor_class = None\n@@ -534,21 +533,18 @@ class ProcessorMixin(PushToHubMixin):\n \n     # args have to match the attributes class attribute\n     def __init__(self, *args, **kwargs):\n-        # First, extract optional attributes from kwargs if present\n-        # Optional attributes can never be positional arguments\n-        for optional_attribute in self.optional_attributes:\n-            optional_attribute_value = kwargs.pop(optional_attribute, None)\n-            setattr(self, optional_attribute, optional_attribute_value)\n+        # First, extract chat template from kwargs. It can never be a positional arg\n+        setattr(self, \"chat_template\", kwargs.pop(\"chat_template\", None))\n \n-            # Check audio tokenizer for its class but do not treat it as attr to avoid saving weights\n-            if optional_attribute == \"audio_tokenizer\" and optional_attribute_value is not None:\n-                proper_class = self.check_argument_for_proper_class(optional_attribute, optional_attribute_value)\n-\n-                if not (is_torch_available() and isinstance(optional_attribute_value, PreTrainedAudioTokenizerBase)):\n-                    raise ValueError(\n-                        f\"Tried to use `{proper_class}` for audio tokenization. However, this class is not\"\n-                        \" registered for audio tokenization.\"\n-                    )\n+        # Check audio tokenizer for its class but do not treat it as attr to avoid saving weights\n+        if (audio_tokenizer := kwargs.pop(\"audio_tokenizer\", None)) is not None:\n+            proper_class = self.check_argument_for_proper_class(\"audio_tokenizer\", audio_tokenizer)\n+            if not (is_torch_available() and isinstance(audio_tokenizer, PreTrainedAudioTokenizerBase)):\n+                raise ValueError(\n+                    f\"Tried to use `{proper_class}` for audio tokenization. However, this class is not\"\n+                    \" registered for audio tokenization.\"\n+                )\n+            setattr(self, \"audio_tokenizer\", audio_tokenizer)\n \n         # Sanitize args and kwargs\n         for key in kwargs:\n@@ -652,7 +648,7 @@ def check_argument_for_proper_class(self, argument_name, argument):\n \n         return proper_class\n \n-    def to_dict(self, legacy_serialization=True) -> dict[str, Any]:\n+    def to_dict(self) -> dict[str, Any]:\n         \"\"\"\n         Serializes this instance to a Python dictionary.\n \n@@ -664,23 +660,33 @@ def to_dict(self, legacy_serialization=True) -> dict[str, Any]:\n         # Get the kwargs in `__init__`.\n         sig = inspect.signature(self.__init__)\n         # Only save the attributes that are presented in the kwargs of `__init__`.\n-        attrs_to_save = list(sig.parameters)\n+        # or in the attributes\n+        attrs_to_save = list(sig.parameters) + self.__class__.attributes\n         # extra attributes to be kept\n         attrs_to_save += [\"auto_map\"]\n \n-        if legacy_serialization:\n-            # Don't save attributes like `tokenizer`, `image processor` etc. in processor config if `legacy=True`\n-            attrs_to_save = [x for x in attrs_to_save if x not in self.__class__.attributes]\n-\n         if \"tokenizer\" in output:\n             del output[\"tokenizer\"]\n         if \"qformer_tokenizer\" in output:\n             del output[\"qformer_tokenizer\"]\n         if \"protein_tokenizer\" in output:\n             del output[\"protein_tokenizer\"]\n+        if \"char_tokenizer\" in output:\n+            del output[\"char_tokenizer\"]\n         if \"chat_template\" in output:\n             del output[\"chat_template\"]\n \n+        def save_public_processor_class(dictionary):\n+            # make sure private name \"_processor_class\" is correctly\n+            # saved as \"processor_class\"\n+            _processor_class = dictionary.pop(\"_processor_class\", None)\n+            if _processor_class is not None:\n+                dictionary[\"processor_class\"] = _processor_class\n+            for value in dictionary.values():\n+                if isinstance(value, dict):\n+                    save_public_processor_class(value)\n+            return dictionary\n+\n         def cast_array_to_list(dictionary):\n             \"\"\"\n             Numpy arrays are not serialiazable but can be in pre-processing dicts.\n@@ -693,45 +699,41 @@ def cast_array_to_list(dictionary):\n                     dictionary[key] = cast_array_to_list(value)\n             return dictionary\n \n+        # Special case, add `audio_tokenizer` dict which points to model weights and path\n+        if \"audio_tokenizer\" in output:\n+            audio_tokenizer_dict = {\n+                \"audio_tokenizer_class\": self.audio_tokenizer.__class__.__name__,\n+                \"audio_tokenizer_name_or_path\": self.audio_tokenizer.name_or_path,\n+            }\n+            output[\"audio_tokenizer\"] = audio_tokenizer_dict\n+\n         # Serialize attributes as a dict\n         output = {\n             k: v.to_dict() if isinstance(v, PushToHubMixin) else v\n             for k, v in output.items()\n             if (\n                 k in attrs_to_save  # keep all attributes that have to be serialized\n                 and v.__class__.__name__ != \"BeamSearchDecoderCTC\"  # remove attributes with that are objects\n-                and (\n-                    (legacy_serialization and not isinstance(v, PushToHubMixin)) or not legacy_serialization\n-                )  # remove `PushToHubMixin` objects\n             )\n         }\n         output = cast_array_to_list(output)\n-\n-        # Special case, add `audio_tokenizer` dict which points to model weights and path\n-        if not legacy_serialization and \"audio_tokenizer\" in output:\n-            audio_tokenizer_dict = {\n-                \"audio_tokenizer_class\": self.audio_tokenizer.__class__.__name__,\n-                \"audio_tokenizer_name_or_path\": self.audio_tokenizer.name_or_path,\n-            }\n-            # Update or overwrite, what do audio tokenizers expect when loading?\n-            output[\"audio_tokenizer\"] = audio_tokenizer_dict\n-\n+        output = save_public_processor_class(output)\n         output[\"processor_class\"] = self.__class__.__name__\n \n         return output\n \n-    def to_json_string(self, legacy_serialization=True) -> str:\n+    def to_json_string(self) -> str:\n         \"\"\"\n         Serializes this instance to a JSON string.\n \n         Returns:\n             `str`: String containing all the attributes that make up this feature_extractor instance in JSON format.\n         \"\"\"\n-        dictionary = self.to_dict(legacy_serialization=legacy_serialization)\n+        dictionary = self.to_dict()\n \n         return json.dumps(dictionary, indent=2, sort_keys=True) + \"\\n\"\n \n-    def to_json_file(self, json_file_path: Union[str, os.PathLike], legacy_serialization=True):\n+    def to_json_file(self, json_file_path: Union[str, os.PathLike]):\n         \"\"\"\n         Save this instance to a JSON file.\n \n@@ -740,14 +742,14 @@ def to_json_file(self, json_file_path: Union[str, os.PathLike], legacy_serializa\n                 Path to the JSON file in which this processor instance's parameters will be saved.\n         \"\"\"\n         with open(json_file_path, \"w\", encoding=\"utf-8\") as writer:\n-            writer.write(self.to_json_string(legacy_serialization=legacy_serialization))\n+            writer.write(self.to_json_string())\n \n     def __repr__(self):\n         attributes_repr = [f\"- {name}: {repr(getattr(self, name))}\" for name in self.attributes]\n         attributes_repr = \"\\n\".join(attributes_repr)\n         return f\"{self.__class__.__name__}:\\n{attributes_repr}\\n\\n{self.to_json_string()}\"\n \n-    def save_pretrained(self, save_directory, push_to_hub: bool = False, legacy_serialization: bool = True, **kwargs):\n+    def save_pretrained(self, save_directory, push_to_hub: bool = False, **kwargs):\n         \"\"\"\n         Saves the attributes of this processor (feature extractor, tokenizer...) in the specified directory so that it\n         can be reloaded using the [`~ProcessorMixin.from_pretrained`] method.\n@@ -768,10 +770,6 @@ def save_pretrained(self, save_directory, push_to_hub: bool = False, legacy_seri\n                 Whether or not to push your model to the Hugging Face model hub after saving it. You can specify the\n                 repository you want to push to with `repo_id` (will default to the name of `save_directory` in your\n                 namespace).\n-            legacy_serialization (`bool`, *optional*, defaults to `True`):\n-                Whether or not to save processor attributes in separate config files (legacy) or in processor's config\n-                file as a nested dict. Saving all attributes in a single dict will become the default in future versions.\n-                Set to `legacy_serialization=True` until then.\n             kwargs (`dict[str, Any]`, *optional*):\n                 Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.\n         \"\"\"\n@@ -805,20 +803,16 @@ def save_pretrained(self, save_directory, push_to_hub: bool = False, legacy_seri\n             custom_object_save(self, save_directory, config=configs)\n \n         for attribute_name in self.attributes:\n+            attribute = getattr(self, attribute_name)\n+            if hasattr(attribute, \"_set_processor_class\"):\n+                attribute._set_processor_class(self.__class__.__name__)\n+\n             # Save the tokenizer in its own vocab file. The other attributes are saved as part of `processor_config.json`\n             if attribute_name == \"tokenizer\":\n-                attribute = getattr(self, attribute_name)\n-                if hasattr(attribute, \"_set_processor_class\"):\n-                    attribute._set_processor_class(self.__class__.__name__)\n-\n                 # Propagate save_jinja_files to tokenizer to ensure we don't get conflicts\n                 attribute.save_pretrained(save_directory, save_jinja_files=save_jinja_files)\n-            elif legacy_serialization:\n-                attribute = getattr(self, attribute_name)\n-                # Include the processor class in attribute config so this processor can then be reloaded with `AutoProcessor` API.\n-                if hasattr(attribute, \"_set_processor_class\"):\n-                    attribute._set_processor_class(self.__class__.__name__)\n-                attribute.save_pretrained(save_directory)\n+            elif attribute._auto_class is not None:\n+                custom_object_save(attribute, save_directory, config=attribute)\n \n         if self._auto_class is not None:\n             # We added an attribute to the init_kwargs of the tokenizers, which needs to be cleaned up.\n@@ -831,9 +825,7 @@ def save_pretrained(self, save_directory, push_to_hub: bool = False, legacy_seri\n         # plus we save chat_template in its own file\n         output_processor_file = os.path.join(save_directory, PROCESSOR_NAME)\n         output_chat_template_file_jinja = os.path.join(save_directory, CHAT_TEMPLATE_FILE)\n-        output_chat_template_file_legacy = os.path.join(\n-            save_directory, LEGACY_PROCESSOR_CHAT_TEMPLATE_FILE\n-        )  # Legacy filename\n+        output_chat_template_file_legacy = os.path.join(save_directory, LEGACY_PROCESSOR_CHAT_TEMPLATE_FILE)\n         chat_template_dir = os.path.join(save_directory, CHAT_TEMPLATE_DIR)\n \n         # Save `chat_template` in its own file. We can't get it from `processor_dict` as we popped it in `to_dict`\n@@ -875,39 +867,10 @@ def save_pretrained(self, save_directory, push_to_hub: bool = False, legacy_seri\n                     \"separate files using the `save_jinja_files` argument.\"\n                 )\n \n-        if legacy_serialization:\n-            output_audio_tokenizer_file = os.path.join(save_directory, AUDIO_TOKENIZER_NAME)\n-            processor_dict = self.to_dict()\n-\n-            # For now, let's not save to `processor_config.json` if the processor doesn't have extra attributes and\n-            # `auto_map` is not specified.\n-            if set(processor_dict.keys()) != {\"processor_class\"}:\n-                self.to_json_file(output_processor_file)\n-                logger.info(f\"processor saved in {output_processor_file}\")\n-\n-            if set(processor_dict.keys()) == {\"processor_class\"}:\n-                return_files = []\n-            else:\n-                return_files = [output_processor_file]\n-\n-            if self.audio_tokenizer is not None:\n-                audio_tokenizer_class = self.audio_tokenizer.__class__.__name__\n-                audio_tokenizer_name_or_path = self.audio_tokenizer.name_or_path\n-                audio_tokenizer_dict = {\n-                    \"audio_tokenizer_class\": audio_tokenizer_class,\n-                    \"audio_tokenizer_name_or_path\": audio_tokenizer_name_or_path,\n-                }\n-                audio_tokenizer_json = json.dumps(audio_tokenizer_dict, indent=2, sort_keys=True) + \"\\n\"\n-                with open(output_audio_tokenizer_file, \"w\", encoding=\"utf-8\") as writer:\n-                    writer.write(audio_tokenizer_json)\n-\n         # Create a unified `preprocessor_config.json` and save all attributes as a composite config, except for tokenizers\n-        # NOTE: this will become the default way to save all processor attrbiutes in future versions. Toggled off for now to give\n-        # us time for smoother transition\n-        else:\n-            self.to_json_file(output_processor_file, legacy_serialization=False)\n-            logger.info(f\"processor saved in {output_processor_file}\")\n-            return_files = [output_processor_file]\n+        self.to_json_file(output_processor_file)\n+        logger.info(f\"processor saved in {output_processor_file}\")\n+        return_files = [output_processor_file]\n \n         if push_to_hub:\n             self._upload_modified_files(\n@@ -1168,10 +1131,6 @@ def get_processor_dict(\n                 audio_tokenizer_path, **audio_tokenizer_kwargs\n             )\n \n-        # Pop attributes if saved in a single processor dict, they are loaded in `_get_arguments_from_pretrained`\n-        for attribute in cls.attributes:\n-            processor_dict.pop(attribute, None)\n-\n         return processor_dict, kwargs\n \n     @classmethod\n@@ -1195,12 +1154,9 @@ def from_args_and_dict(cls, args, processor_dict: dict[str, Any], **kwargs):\n         return_unused_kwargs = kwargs.pop(\"return_unused_kwargs\", False)\n \n         # We have to pop up some unused (but specific) kwargs and then validate that it doesn't contain unused kwargs\n-        # If we don't pop, some specific kwargs will raise a warning\n-        if \"processor_class\" in processor_dict:\n-            del processor_dict[\"processor_class\"]\n-\n-        if \"auto_map\" in processor_dict:\n-            del processor_dict[\"auto_map\"]\n+        # If we don't pop, some specific kwargs will raise a warning or error\n+        for unused_kwarg in cls.attributes + [\"auto_map\", \"processor_class\"]:\n+            processor_dict.pop(unused_kwarg, None)\n \n         # override processor_dict with given kwargs\n         processor_dict.update(kwargs)\n@@ -1460,8 +1416,8 @@ def from_pretrained(\n         if token is not None:\n             kwargs[\"token\"] = token\n \n-        args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)\n         processor_dict, kwargs = cls.get_processor_dict(pretrained_model_name_or_path, **kwargs)\n+        args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)\n         return cls.from_args_and_dict(args, processor_dict, **kwargs)\n \n     @classmethod"
        },
        {
            "sha": "01190c247a22020468310154ed235f7565aa99ff",
            "filename": "tests/models/align/test_processing_align.py",
            "status": "modified",
            "additions": 4,
            "deletions": 5,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Falign%2Ftest_processing_align.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Falign%2Ftest_processing_align.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Falign%2Ftest_processing_align.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -12,7 +12,6 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-import json\n import os\n import shutil\n import tempfile\n@@ -23,7 +22,7 @@\n from transformers import BertTokenizer, BertTokenizerFast\n from transformers.models.bert.tokenization_bert import VOCAB_FILES_NAMES\n from transformers.testing_utils import require_vision\n-from transformers.utils import IMAGE_PROCESSOR_NAME, is_vision_available\n+from transformers.utils import is_vision_available\n \n from ...test_processing_common import ProcessorTesterMixin\n \n@@ -67,9 +66,9 @@ def setUp(self):\n             \"image_mean\": [0.48145466, 0.4578275, 0.40821073],\n             \"image_std\": [0.26862954, 0.26130258, 0.27577711],\n         }\n-        self.image_processor_file = os.path.join(self.tmpdirname, IMAGE_PROCESSOR_NAME)\n-        with open(self.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n-            json.dump(image_processor_map, fp)\n+        image_processor = EfficientNetImageProcessor(**image_processor_map)\n+        processor = AlignProcessor(tokenizer=self.get_tokenizer(), image_processor=image_processor)\n+        processor.save_pretrained(self.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return BertTokenizer.from_pretrained(self.tmpdirname, **kwargs)"
        },
        {
            "sha": "c61700fe7e7487fc5a946af798c7f6f2f9a8437e",
            "filename": "tests/models/auto/test_processor_auto.py",
            "status": "modified",
            "additions": 3,
            "deletions": 44,
            "changes": 47,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fauto%2Ftest_processor_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fauto%2Ftest_processor_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fauto%2Ftest_processor_auto.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -126,37 +126,6 @@ def test_processor_from_processor_class(self):\n \n         self.assertIsInstance(processor, Wav2Vec2Processor)\n \n-    def test_processor_from_feat_extr_processor_class(self):\n-        with tempfile.TemporaryDirectory() as tmpdirname:\n-            feature_extractor = Wav2Vec2FeatureExtractor()\n-            tokenizer = AutoTokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n-\n-            processor = Wav2Vec2Processor(feature_extractor, tokenizer)\n-\n-            # save in new folder\n-            processor.save_pretrained(tmpdirname)\n-\n-            if os.path.isfile(os.path.join(tmpdirname, PROCESSOR_NAME)):\n-                # drop `processor_class` in processor\n-                with open(os.path.join(tmpdirname, PROCESSOR_NAME)) as f:\n-                    config_dict = json.load(f)\n-                    config_dict.pop(\"processor_class\")\n-\n-                with open(os.path.join(tmpdirname, PROCESSOR_NAME), \"w\") as f:\n-                    f.write(json.dumps(config_dict))\n-\n-            # drop `processor_class` in tokenizer\n-            with open(os.path.join(tmpdirname, TOKENIZER_CONFIG_FILE)) as f:\n-                config_dict = json.load(f)\n-                config_dict.pop(\"processor_class\")\n-\n-            with open(os.path.join(tmpdirname, TOKENIZER_CONFIG_FILE), \"w\") as f:\n-                f.write(json.dumps(config_dict))\n-\n-            processor = AutoProcessor.from_pretrained(tmpdirname)\n-\n-        self.assertIsInstance(processor, Wav2Vec2Processor)\n-\n     def test_processor_from_tokenizer_processor_class(self):\n         with tempfile.TemporaryDirectory() as tmpdirname:\n             feature_extractor = Wav2Vec2FeatureExtractor()\n@@ -167,21 +136,11 @@ def test_processor_from_tokenizer_processor_class(self):\n             # save in new folder\n             processor.save_pretrained(tmpdirname)\n \n-            if os.path.isfile(os.path.join(tmpdirname, PROCESSOR_NAME)):\n-                # drop `processor_class` in processor\n-                with open(os.path.join(tmpdirname, PROCESSOR_NAME)) as f:\n-                    config_dict = json.load(f)\n-                    config_dict.pop(\"processor_class\")\n-\n-                with open(os.path.join(tmpdirname, PROCESSOR_NAME), \"w\") as f:\n-                    f.write(json.dumps(config_dict))\n-\n-            # drop `processor_class` in feature extractor\n-            with open(os.path.join(tmpdirname, FEATURE_EXTRACTOR_NAME)) as f:\n+            # drop `processor_class` in processor\n+            with open(os.path.join(tmpdirname, PROCESSOR_NAME)) as f:\n                 config_dict = json.load(f)\n                 config_dict.pop(\"processor_class\")\n-\n-            with open(os.path.join(tmpdirname, FEATURE_EXTRACTOR_NAME), \"w\") as f:\n+            with open(os.path.join(tmpdirname, PROCESSOR_NAME), \"w\") as f:\n                 f.write(json.dumps(config_dict))\n \n             processor = AutoProcessor.from_pretrained(tmpdirname)"
        },
        {
            "sha": "dab0d37773c9f6a836815193adf3c3b03d7e3cd4",
            "filename": "tests/models/chinese_clip/test_processing_chinese_clip.py",
            "status": "modified",
            "additions": 2,
            "deletions": 7,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fchinese_clip%2Ftest_processing_chinese_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fchinese_clip%2Ftest_processing_chinese_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fchinese_clip%2Ftest_processing_chinese_clip.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -12,7 +12,6 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-import json\n import os\n import shutil\n import tempfile\n@@ -23,7 +22,7 @@\n from transformers import BertTokenizer, BertTokenizerFast\n from transformers.models.bert.tokenization_bert import VOCAB_FILES_NAMES\n from transformers.testing_utils import require_vision\n-from transformers.utils import FEATURE_EXTRACTOR_NAME, is_vision_available\n+from transformers.utils import is_vision_available\n \n from ...test_processing_common import ProcessorTesterMixin\n \n@@ -74,12 +73,8 @@ def setUpClass(cls):\n             \"image_std\": [0.26862954, 0.26130258, 0.27577711],\n             \"do_convert_rgb\": True,\n         }\n-        cls.image_processor_file = os.path.join(cls.tmpdirname, FEATURE_EXTRACTOR_NAME)\n-        with open(cls.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n-            json.dump(image_processor_map, fp)\n-\n         tokenizer = cls.get_tokenizer()\n-        image_processor = cls.get_image_processor()\n+        image_processor = ChineseCLIPImageProcessor(**image_processor_map)\n         processor = ChineseCLIPProcessor(tokenizer=tokenizer, image_processor=image_processor)\n         processor.save_pretrained(cls.tmpdirname)\n "
        },
        {
            "sha": "98b59373c42967f5822fe08aa0563408fad93cc4",
            "filename": "tests/models/clipseg/test_processing_clipseg.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fclipseg%2Ftest_processing_clipseg.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fclipseg%2Ftest_processing_clipseg.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fclipseg%2Ftest_processing_clipseg.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -23,7 +23,7 @@\n from transformers import CLIPTokenizer, CLIPTokenizerFast\n from transformers.models.clip.tokenization_clip import VOCAB_FILES_NAMES\n from transformers.testing_utils import require_vision\n-from transformers.utils import IMAGE_PROCESSOR_NAME, is_vision_available\n+from transformers.utils import is_vision_available\n \n from ...test_processing_common import ProcessorTesterMixin\n \n@@ -60,9 +60,9 @@ def setUp(self):\n             \"image_mean\": [0.48145466, 0.4578275, 0.40821073],\n             \"image_std\": [0.26862954, 0.26130258, 0.27577711],\n         }\n-        self.image_processor_file = os.path.join(self.tmpdirname, IMAGE_PROCESSOR_NAME)\n-        with open(self.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n-            json.dump(image_processor_map, fp)\n+        image_processor = ViTImageProcessor(**image_processor_map)\n+        processor = CLIPSegProcessor(tokenizer=self.get_tokenizer(), image_processor=image_processor)\n+        processor.save_pretrained(self.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return CLIPTokenizer.from_pretrained(self.tmpdirname, **kwargs)"
        },
        {
            "sha": "b50da8e244fa0df5ae4fe300228fed8b39744fac",
            "filename": "tests/models/flava/test_processing_flava.py",
            "status": "modified",
            "additions": 4,
            "deletions": 5,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fflava%2Ftest_processing_flava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fflava%2Ftest_processing_flava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fflava%2Ftest_processing_flava.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -12,7 +12,6 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-import json\n import os\n import random\n import shutil\n@@ -24,7 +23,7 @@\n from transformers import BertTokenizer, BertTokenizerFast\n from transformers.models.bert.tokenization_bert import VOCAB_FILES_NAMES\n from transformers.testing_utils import require_vision\n-from transformers.utils import IMAGE_PROCESSOR_NAME, is_vision_available\n+from transformers.utils import is_vision_available\n \n from ...test_processing_common import ProcessorTesterMixin\n \n@@ -76,9 +75,9 @@ def setUp(self):\n             \"codebook_image_std\": FLAVA_CODEBOOK_STD,\n         }\n \n-        self.image_processor_file = os.path.join(self.tmpdirname, IMAGE_PROCESSOR_NAME)\n-        with open(self.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n-            json.dump(image_processor_map, fp)\n+        image_processor = FlavaImageProcessor(**image_processor_map)\n+        processor = FlavaProcessor(tokenizer=self.get_tokenizer(), image_processor=image_processor)\n+        processor.save_pretrained(self.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return BertTokenizer.from_pretrained(self.tmpdirname, **kwargs)"
        },
        {
            "sha": "ca849ba10103682c11d7bb7c2c6ca922e8218b9b",
            "filename": "tests/models/granite_speech/test_processing_granite_speech.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fgranite_speech%2Ftest_processing_granite_speech.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fgranite_speech%2Ftest_processing_granite_speech.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgranite_speech%2Ftest_processing_granite_speech.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -44,10 +44,10 @@ def setUp(self):\n         processor.save_pretrained(self.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n-        return AutoTokenizer.from_pretrained(self.checkpoint, **kwargs)\n+        return AutoTokenizer.from_pretrained(self.tmpdirname, **kwargs)\n \n     def get_audio_processor(self, **kwargs):\n-        return GraniteSpeechFeatureExtractor.from_pretrained(self.checkpoint, **kwargs)\n+        return GraniteSpeechFeatureExtractor.from_pretrained(self.tmpdirname, **kwargs)\n \n     def tearDown(self):\n         shutil.rmtree(self.tmpdirname)"
        },
        {
            "sha": "9a116e54c9a769a9042fbf732cd751a8342644da",
            "filename": "tests/models/layoutlmv2/test_processing_layoutlmv2.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Flayoutlmv2%2Ftest_processing_layoutlmv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Flayoutlmv2%2Ftest_processing_layoutlmv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flayoutlmv2%2Ftest_processing_layoutlmv2.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -12,7 +12,6 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-import json\n import os\n import shutil\n import tempfile\n@@ -23,7 +22,7 @@\n from transformers.models.layoutlmv2 import LayoutLMv2Processor, LayoutLMv2Tokenizer, LayoutLMv2TokenizerFast\n from transformers.models.layoutlmv2.tokenization_layoutlmv2 import VOCAB_FILES_NAMES\n from transformers.testing_utils import require_pytesseract, require_tokenizers, require_torch, slow\n-from transformers.utils import FEATURE_EXTRACTOR_NAME, is_pytesseract_available\n+from transformers.utils import is_pytesseract_available\n \n from ...test_processing_common import ProcessorTesterMixin\n \n@@ -68,9 +67,10 @@ def setUp(self):\n         self.vocab_file = os.path.join(self.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n         with open(self.vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n             vocab_writer.write(\"\".join([x + \"\\n\" for x in vocab_tokens]))\n-        self.image_processing_file = os.path.join(self.tmpdirname, FEATURE_EXTRACTOR_NAME)\n-        with open(self.image_processing_file, \"w\", encoding=\"utf-8\") as fp:\n-            fp.write(json.dumps(image_processor_map) + \"\\n\")\n+\n+        image_processor = LayoutLMv2ImageProcessor(**image_processor_map)\n+        processor = LayoutLMv2Processor(tokenizer=self.get_tokenizer(), image_processor=image_processor)\n+        processor.save_pretrained(self.tmpdirname)\n \n     def get_tokenizer(self, **kwargs) -> PreTrainedTokenizer:\n         return self.tokenizer_class.from_pretrained(self.tmpdirname, **kwargs)"
        },
        {
            "sha": "b7a51a940a5b604f4385365d5e2bec9dbd215784",
            "filename": "tests/models/layoutlmv3/test_processing_layoutlmv3.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Flayoutlmv3%2Ftest_processing_layoutlmv3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Flayoutlmv3%2Ftest_processing_layoutlmv3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flayoutlmv3%2Ftest_processing_layoutlmv3.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -23,7 +23,7 @@\n from transformers.models.layoutlmv3 import LayoutLMv3Processor, LayoutLMv3Tokenizer, LayoutLMv3TokenizerFast\n from transformers.models.layoutlmv3.tokenization_layoutlmv3 import VOCAB_FILES_NAMES\n from transformers.testing_utils import require_pytesseract, require_tokenizers, require_torch, slow\n-from transformers.utils import FEATURE_EXTRACTOR_NAME, is_pytesseract_available\n+from transformers.utils import is_pytesseract_available\n \n from ...test_processing_common import ProcessorTesterMixin\n \n@@ -81,9 +81,9 @@ def setUp(self):\n             \"apply_ocr\": True,\n         }\n \n-        self.feature_extraction_file = os.path.join(self.tmpdirname, FEATURE_EXTRACTOR_NAME)\n-        with open(self.feature_extraction_file, \"w\", encoding=\"utf-8\") as fp:\n-            fp.write(json.dumps(image_processor_map) + \"\\n\")\n+        image_processor = LayoutLMv3ImageProcessor(**image_processor_map)\n+        processor = LayoutLMv3Processor(tokenizer=self.get_tokenizer(), image_processor=image_processor)\n+        processor.save_pretrained(self.tmpdirname)\n \n     def get_tokenizer(self, **kwargs) -> PreTrainedTokenizer:\n         return self.tokenizer_class.from_pretrained(self.tmpdirname, **kwargs)"
        },
        {
            "sha": "42674ad61fb3d5327638b2459cb491a4628ec378",
            "filename": "tests/models/markuplm/test_processing_markuplm.py",
            "status": "modified",
            "additions": 4,
            "deletions": 5,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fmarkuplm%2Ftest_processing_markuplm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fmarkuplm%2Ftest_processing_markuplm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmarkuplm%2Ftest_processing_markuplm.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -28,7 +28,7 @@\n )\n from transformers.models.markuplm.tokenization_markuplm import VOCAB_FILES_NAMES\n from transformers.testing_utils import require_bs4, require_tokenizers, require_torch, slow\n-from transformers.utils import FEATURE_EXTRACTOR_NAME, is_bs4_available, is_tokenizers_available\n+from transformers.utils import is_bs4_available, is_tokenizers_available\n \n \n if is_bs4_available():\n@@ -64,10 +64,9 @@ def setUp(self):\n         with open(self.tokenizer_config_file, \"w\", encoding=\"utf-8\") as fp:\n             fp.write(json.dumps({\"tags_dict\": self.tags_dict}))\n \n-        feature_extractor_map = {\"feature_extractor_type\": \"MarkupLMFeatureExtractor\"}\n-        self.feature_extraction_file = os.path.join(self.tmpdirname, FEATURE_EXTRACTOR_NAME)\n-        with open(self.feature_extraction_file, \"w\", encoding=\"utf-8\") as fp:\n-            fp.write(json.dumps(feature_extractor_map) + \"\\n\")\n+        feature_extractor = MarkupLMFeatureExtractor()\n+        processor = MarkupLMProcessor(tokenizer=self.get_tokenizer(), feature_extractor=feature_extractor)\n+        processor.save_pretrained(self.tmpdirname)\n \n     def get_tokenizer(self, **kwargs) -> PreTrainedTokenizer:\n         return self.tokenizer_class.from_pretrained(self.tmpdirname, **kwargs)"
        },
        {
            "sha": "17336d3512115a9f3166445ceaddcdb4ce270dbd",
            "filename": "tests/models/mgp_str/test_processing_mgp_str.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fmgp_str%2Ftest_processing_mgp_str.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fmgp_str%2Ftest_processing_mgp_str.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmgp_str%2Ftest_processing_mgp_str.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -25,7 +25,7 @@\n from transformers import MgpstrTokenizer\n from transformers.models.mgp_str.tokenization_mgp_str import VOCAB_FILES_NAMES\n from transformers.testing_utils import require_torch, require_vision\n-from transformers.utils import IMAGE_PROCESSOR_NAME, is_torch_available, is_vision_available\n+from transformers.utils import is_torch_available, is_vision_available\n \n \n if is_torch_available():\n@@ -65,9 +65,9 @@ def setUp(self):\n             \"resample\": 3,\n             \"size\": {\"height\": 32, \"width\": 128},\n         }\n-        self.image_processor_file = os.path.join(self.tmpdirname, IMAGE_PROCESSOR_NAME)\n-        with open(self.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n-            json.dump(image_processor_map, fp)\n+        image_processor = ViTImageProcessor(**image_processor_map)\n+        processor = MgpstrProcessor(tokenizer=self.get_tokenizer(), image_processor=image_processor)\n+        processor.save_pretrained(self.tmpdirname)\n \n     # We copy here rather than use the ProcessorTesterMixin as this processor has a `char_tokenizer` instead of a\n     # tokenizer attribute, which means all the tests would need to be overridden."
        },
        {
            "sha": "fbae546997272bb9e545f1bdd46697c309b663af",
            "filename": "tests/models/oneformer/test_processing_oneformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Foneformer%2Ftest_processing_oneformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Foneformer%2Ftest_processing_oneformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Foneformer%2Ftest_processing_oneformer.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -406,7 +406,7 @@ def test_feat_extract_from_and_save_pretrained(self):\n \n         with tempfile.TemporaryDirectory() as tmpdirname:\n             feat_extract_first.save_pretrained(tmpdirname)\n-            check_json_file_has_correct_format(os.path.join(tmpdirname, \"preprocessor_config.json\"))\n+            check_json_file_has_correct_format(os.path.join(tmpdirname, \"processor_config.json\"))\n             feat_extract_second = self.feature_extraction_class.from_pretrained(tmpdirname)\n \n         self.assertEqual(feat_extract_second.image_processor.to_dict(), feat_extract_first.image_processor.to_dict())"
        },
        {
            "sha": "5370c38d33f47a4e027dfafd597cc70a5b9d7e20",
            "filename": "tests/models/owlvit/test_processing_owlvit.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fowlvit%2Ftest_processing_owlvit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fowlvit%2Ftest_processing_owlvit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fowlvit%2Ftest_processing_owlvit.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -23,7 +23,7 @@\n from transformers import CLIPTokenizer, CLIPTokenizerFast\n from transformers.models.clip.tokenization_clip import VOCAB_FILES_NAMES\n from transformers.testing_utils import require_vision\n-from transformers.utils import IMAGE_PROCESSOR_NAME, is_vision_available\n+from transformers.utils import is_vision_available\n \n from ...test_processing_common import ProcessorTesterMixin\n \n@@ -60,9 +60,9 @@ def setUp(self):\n             \"image_mean\": [0.48145466, 0.4578275, 0.40821073],\n             \"image_std\": [0.26862954, 0.26130258, 0.27577711],\n         }\n-        self.image_processor_file = os.path.join(self.tmpdirname, IMAGE_PROCESSOR_NAME)\n-        with open(self.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n-            json.dump(image_processor_map, fp)\n+        image_processor = OwlViTImageProcessor(**image_processor_map)\n+        processor = OwlViTProcessor(tokenizer=self.get_tokenizer(), image_processor=image_processor)\n+        processor.save_pretrained(self.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return CLIPTokenizer.from_pretrained(self.tmpdirname, pad_token=\"!\", **kwargs)"
        },
        {
            "sha": "0116445c91b19ef2605f7d31d55d8d1a2af9c3b1",
            "filename": "tests/models/speech_to_text/test_processing_speech_to_text.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fspeech_to_text%2Ftest_processing_speech_to_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fspeech_to_text%2Ftest_processing_speech_to_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fspeech_to_text%2Ftest_processing_speech_to_text.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -21,7 +21,6 @@\n from transformers import Speech2TextFeatureExtractor, Speech2TextProcessor, Speech2TextTokenizer\n from transformers.models.speech_to_text.tokenization_speech_to_text import VOCAB_FILES_NAMES, save_json\n from transformers.testing_utils import get_tests_dir, require_sentencepiece, require_torch, require_torchaudio\n-from transformers.utils import FEATURE_EXTRACTOR_NAME\n \n from .test_feature_extraction_speech_to_text import floats_list\n \n@@ -55,7 +54,10 @@ def setUpClass(cls):\n             \"return_attention_mask\": False,\n             \"do_normalize\": True,\n         }\n-        save_json(feature_extractor_map, save_dir / FEATURE_EXTRACTOR_NAME)\n+        feature_extractor = Speech2TextFeatureExtractor(**feature_extractor_map)\n+        tokenizer = Speech2TextTokenizer.from_pretrained(cls.tmpdirname)\n+        processor = Speech2TextProcessor(tokenizer=tokenizer, feature_extractor=feature_extractor)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return Speech2TextTokenizer.from_pretrained(self.tmpdirname, **kwargs)"
        },
        {
            "sha": "a6736132a39058ea0a2d44ced37fb269e0594a6d",
            "filename": "tests/models/speecht5/test_processing_speecht5.py",
            "status": "modified",
            "additions": 4,
            "deletions": 6,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fspeecht5%2Ftest_processing_speecht5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fspeecht5%2Ftest_processing_speecht5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fspeecht5%2Ftest_processing_speecht5.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -13,16 +13,13 @@\n # limitations under the License.\n \"\"\"Tests for the SpeechT5 processors.\"\"\"\n \n-import json\n-import os\n import shutil\n import tempfile\n import unittest\n \n from transformers import is_speech_available, is_torch_available\n from transformers.models.speecht5 import SpeechT5Tokenizer\n from transformers.testing_utils import get_tests_dir, require_speech, require_torch\n-from transformers.utils import FEATURE_EXTRACTOR_NAME\n \n \n if is_speech_available() and is_torch_available():\n@@ -60,9 +57,10 @@ def setUpClass(cls):\n             \"return_attention_mask\": True,\n         }\n \n-        cls.feature_extraction_file = os.path.join(cls.tmpdirname, FEATURE_EXTRACTOR_NAME)\n-        with open(cls.feature_extraction_file, \"w\", encoding=\"utf-8\") as fp:\n-            fp.write(json.dumps(feature_extractor_map) + \"\\n\")\n+        feature_extractor = SpeechT5FeatureExtractor(**feature_extractor_map)\n+        tokenizer = SpeechT5Tokenizer.from_pretrained(cls.tmpdirname)\n+        processor = SpeechT5Processor(tokenizer=tokenizer, feature_extractor=feature_extractor)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return SpeechT5Tokenizer.from_pretrained(self.tmpdirname, **kwargs)"
        },
        {
            "sha": "ef9699ff4f289d57b45da3baccb0c0c24e293e99",
            "filename": "tests/models/vision_text_dual_encoder/test_processing_vision_text_dual_encoder.py",
            "status": "modified",
            "additions": 2,
            "deletions": 7,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fvision_text_dual_encoder%2Ftest_processing_vision_text_dual_encoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fvision_text_dual_encoder%2Ftest_processing_vision_text_dual_encoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvision_text_dual_encoder%2Ftest_processing_vision_text_dual_encoder.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -12,7 +12,6 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-import json\n import os\n import shutil\n import tempfile\n@@ -21,7 +20,7 @@\n from transformers import BertTokenizerFast\n from transformers.models.bert.tokenization_bert import VOCAB_FILES_NAMES, BertTokenizer\n from transformers.testing_utils import require_tokenizers, require_vision\n-from transformers.utils import IMAGE_PROCESSOR_NAME, is_torchvision_available, is_vision_available\n+from transformers.utils import is_torchvision_available, is_vision_available\n \n from ...test_processing_common import ProcessorTesterMixin\n \n@@ -51,12 +50,8 @@ def setUpClass(cls):\n             \"image_mean\": [0.5, 0.5, 0.5],\n             \"image_std\": [0.5, 0.5, 0.5],\n         }\n-        cls.image_processor_file = os.path.join(cls.tmpdirname, IMAGE_PROCESSOR_NAME)\n-        with open(cls.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n-            json.dump(image_processor_map, fp)\n-\n+        image_processor = ViTImageProcessor(**image_processor_map)\n         tokenizer = cls.get_tokenizer()\n-        image_processor = cls.get_image_processor()\n         processor = VisionTextDualEncoderProcessor(tokenizer=tokenizer, image_processor=image_processor)\n         processor.save_pretrained(cls.tmpdirname)\n "
        },
        {
            "sha": "0ecf6d00e01277e28201373ce256d7c931ee84cd",
            "filename": "tests/models/wav2vec2/test_processing_wav2vec2.py",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fwav2vec2%2Ftest_processing_wav2vec2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fwav2vec2%2Ftest_processing_wav2vec2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwav2vec2%2Ftest_processing_wav2vec2.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -20,7 +20,6 @@\n \n from transformers.models.wav2vec2 import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, Wav2Vec2Processor\n from transformers.models.wav2vec2.tokenization_wav2vec2 import VOCAB_FILES_NAMES\n-from transformers.utils import FEATURE_EXTRACTOR_NAME\n \n from ...test_processing_common import ProcessorTesterMixin\n from .test_feature_extraction_wav2vec2 import floats_list\n@@ -52,15 +51,13 @@ def setUpClass(cls):\n \n         cls.tmpdirname = tempfile.mkdtemp()\n         cls.vocab_file = os.path.join(cls.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n-        cls.feature_extraction_file = os.path.join(cls.tmpdirname, FEATURE_EXTRACTOR_NAME)\n         with open(cls.vocab_file, \"w\", encoding=\"utf-8\") as fp:\n             fp.write(json.dumps(vocab_tokens) + \"\\n\")\n-\n-        with open(cls.feature_extraction_file, \"w\", encoding=\"utf-8\") as fp:\n-            fp.write(json.dumps(feature_extractor_map) + \"\\n\")\n-\n         tokenizer = cls.get_tokenizer()\n-        tokenizer.save_pretrained(cls.tmpdirname)\n+\n+        feature_extractor = Wav2Vec2FeatureExtractor(**feature_extractor_map)\n+        processor = Wav2Vec2Processor(tokenizer=tokenizer, feature_extractor=feature_extractor)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     @classmethod\n     def get_tokenizer(cls, **kwargs_init):"
        },
        {
            "sha": "fbdb73fff4ca7a5308b11db0754cea3a12fc48d7",
            "filename": "tests/models/wav2vec2_bert/test_processing_wav2vec2_bert.py",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fwav2vec2_bert%2Ftest_processing_wav2vec2_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fwav2vec2_bert%2Ftest_processing_wav2vec2_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwav2vec2_bert%2Ftest_processing_wav2vec2_bert.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -22,7 +22,6 @@\n from transformers.models.wav2vec2 import Wav2Vec2CTCTokenizer\n from transformers.models.wav2vec2.tokenization_wav2vec2 import VOCAB_FILES_NAMES\n from transformers.models.wav2vec2_bert import Wav2Vec2BertProcessor\n-from transformers.utils import FEATURE_EXTRACTOR_NAME\n \n from ...test_processing_common import ProcessorTesterMixin\n from ..wav2vec2.test_feature_extraction_wav2vec2 import floats_list\n@@ -53,15 +52,13 @@ def setUpClass(cls):\n \n         cls.tmpdirname = tempfile.mkdtemp()\n         cls.vocab_file = os.path.join(cls.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n-        cls.feature_extraction_file = os.path.join(cls.tmpdirname, FEATURE_EXTRACTOR_NAME)\n         with open(cls.vocab_file, \"w\", encoding=\"utf-8\") as fp:\n             fp.write(json.dumps(vocab_tokens) + \"\\n\")\n-\n-        with open(cls.feature_extraction_file, \"w\", encoding=\"utf-8\") as fp:\n-            fp.write(json.dumps(feature_extractor_map) + \"\\n\")\n-\n         tokenizer = cls.get_tokenizer()\n-        tokenizer.save_pretrained(cls.tmpdirname)\n+\n+        feature_extractor = SeamlessM4TFeatureExtractor(**feature_extractor_map)\n+        processor = Wav2Vec2BertProcessor(tokenizer=tokenizer, feature_extractor=feature_extractor)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     @classmethod\n     def get_tokenizer(cls, **kwargs_init):"
        },
        {
            "sha": "d23f84735f3d39d6aca37b41573fb893e74a77bb",
            "filename": "tests/models/wav2vec2_with_lm/test_processing_wav2vec2_with_lm.py",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fwav2vec2_with_lm%2Ftest_processing_wav2vec2_with_lm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Fmodels%2Fwav2vec2_with_lm%2Ftest_processing_wav2vec2_with_lm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwav2vec2_with_lm%2Ftest_processing_wav2vec2_with_lm.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -29,7 +29,7 @@\n from transformers.models.wav2vec2 import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor\n from transformers.models.wav2vec2.tokenization_wav2vec2 import VOCAB_FILES_NAMES\n from transformers.testing_utils import require_pyctcdecode, require_torch, require_torchaudio, slow\n-from transformers.utils import FEATURE_EXTRACTOR_NAME, is_pyctcdecode_available, is_torch_available\n+from transformers.utils import is_pyctcdecode_available, is_torch_available\n \n from ..wav2vec2.test_feature_extraction_wav2vec2 import floats_list\n \n@@ -66,16 +66,18 @@ def setUp(self):\n \n         self.tmpdirname = tempfile.mkdtemp()\n         self.vocab_file = os.path.join(self.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n-        self.feature_extraction_file = os.path.join(self.tmpdirname, FEATURE_EXTRACTOR_NAME)\n         with open(self.vocab_file, \"w\", encoding=\"utf-8\") as fp:\n             fp.write(json.dumps(vocab_tokens) + \"\\n\")\n \n-        with open(self.feature_extraction_file, \"w\", encoding=\"utf-8\") as fp:\n-            fp.write(json.dumps(feature_extractor_map) + \"\\n\")\n-\n         # load decoder from hub\n         self.decoder_name = \"hf-internal-testing/ngram-beam-search-decoder\"\n \n+        feature_extractor = Wav2Vec2FeatureExtractor(**feature_extractor_map)\n+        processor = Wav2Vec2ProcessorWithLM(\n+            tokenizer=self.get_tokenizer(), feature_extractor=feature_extractor, decoder=self.get_decoder()\n+        )\n+        processor.save_pretrained(self.tmpdirname)\n+\n     def get_tokenizer(self, **kwargs_init):\n         kwargs = self.add_kwargs_tokens_map.copy()\n         kwargs.update(kwargs_init)"
        },
        {
            "sha": "924efe2db6bf5ff299cda66c25da37439fb30ddc",
            "filename": "tests/test_processing_common.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Ftest_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/tests%2Ftest_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_processing_common.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -222,8 +222,7 @@ def test_processor_from_and_save_pretrained_as_nested_dict(self):\n         processor_first = self.get_processor()\n \n         with tempfile.TemporaryDirectory() as tmpdirname:\n-            # Save with `legacy_serialization=False` so that all attrbiutes are saved in one json file\n-            saved_files = processor_first.save_pretrained(tmpdirname, legacy_serialization=False)\n+            saved_files = processor_first.save_pretrained(tmpdirname)\n             check_json_file_has_correct_format(saved_files[0])\n \n             # Load it back and check if loaded correctly"
        },
        {
            "sha": "c4c79df3c7bc369786785fc85b8fead362c02270",
            "filename": "time_eval.py",
            "status": "added",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/time_eval.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe/time_eval.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/time_eval.py?ref=7b7d17f9bfbfaa703fbb03aa854a345c20c8aefe",
            "patch": "@@ -0,0 +1,10 @@\n+from transformers import AutoConfig, LlavaConfig\n+\n+\n+remote_text_config = AutoConfig.from_pretrained(\"AI4Chem/ChemLLM-7B-Chat\" trust_remote_code=True)\n+local_vision_config = AutoConfig.from_pretrained(\"google/siglip2-so400m-patch14-384\")\n+config = LlavaConfig(text_config=remote_text_config, vision_config=local_vision_config, image_token_id=92544)\n+config.save_pretrained(\"local_llava\")\n+\n+\n+config = LlavaConfig.from_pretrained(\"local_llava\", trust_remote_code=True)"
        }
    ],
    "stats": {
        "total": 364,
        "additions": 137,
        "deletions": 227
    }
}