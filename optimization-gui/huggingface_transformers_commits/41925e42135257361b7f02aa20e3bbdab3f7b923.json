{
    "author": "muellerzr",
    "message": "Add retry hf hub decorator (#35213)\n\n* Add retry torch decorator\n\n* New approach\n\n* Empty commit\n\n* Empty commit\n\n* Style\n\n* Use logger.error\n\n* Add a test\n\n* Update src/transformers/testing_utils.py\n\nCo-authored-by: Lucain <lucainp@gmail.com>\n\n* Fix err\n\n* Update tests/utils/test_modeling_utils.py\n\n---------\n\nCo-authored-by: Lucain <lucainp@gmail.com>\nCo-authored-by: Yih-Dar <2521628+ydshieh@users.noreply.github.com>",
    "sha": "41925e42135257361b7f02aa20e3bbdab3f7b923",
    "files": [
        {
            "sha": "17223278eb110bb5e287a39d9b655e4bbd551ee7",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 46,
            "deletions": 1,
            "changes": 47,
            "blob_url": "https://github.com/huggingface/transformers/blob/41925e42135257361b7f02aa20e3bbdab3f7b923/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/41925e42135257361b7f02aa20e3bbdab3f7b923/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=41925e42135257361b7f02aa20e3bbdab3f7b923",
            "patch": "@@ -43,6 +43,7 @@\n from unittest.mock import patch\n \n import huggingface_hub.utils\n+import requests\n import urllib3\n from huggingface_hub import delete_repo\n from packaging import version\n@@ -200,6 +201,8 @@\n     IS_ROCM_SYSTEM = False\n     IS_CUDA_SYSTEM = False\n \n+logger = transformers_logging.get_logger(__name__)\n+\n \n def parse_flag_from_env(key, default=False):\n     try:\n@@ -2497,7 +2500,49 @@ def wrapper(*args, **kwargs):\n                     return test_func_ref(*args, **kwargs)\n \n                 except Exception as err:\n-                    print(f\"Test failed with {err} at try {retry_count}/{max_attempts}.\", file=sys.stderr)\n+                    logger.error(f\"Test failed with {err} at try {retry_count}/{max_attempts}.\")\n+                    if wait_before_retry is not None:\n+                        time.sleep(wait_before_retry)\n+                    retry_count += 1\n+\n+            return test_func_ref(*args, **kwargs)\n+\n+        return wrapper\n+\n+    return decorator\n+\n+\n+def hub_retry(max_attempts: int = 5, wait_before_retry: Optional[float] = 2):\n+    \"\"\"\n+    To decorate tests that download from the Hub. They can fail due to a\n+    variety of network issues such as timeouts, connection resets, etc.\n+\n+    Args:\n+        max_attempts (`int`, *optional*, defaults to 5):\n+            The maximum number of attempts to retry the flaky test.\n+        wait_before_retry (`float`, *optional*, defaults to 2):\n+            If provided, will wait that number of seconds before retrying the test.\n+    \"\"\"\n+\n+    def decorator(test_func_ref):\n+        @functools.wraps(test_func_ref)\n+        def wrapper(*args, **kwargs):\n+            retry_count = 1\n+\n+            while retry_count < max_attempts:\n+                try:\n+                    return test_func_ref(*args, **kwargs)\n+                # We catch all exceptions related to network issues from requests\n+                except (\n+                    requests.exceptions.ConnectionError,\n+                    requests.exceptions.Timeout,\n+                    requests.exceptions.ReadTimeout,\n+                    requests.exceptions.HTTPError,\n+                    requests.exceptions.RequestException,\n+                ) as err:\n+                    logger.error(\n+                        f\"Test failed with {err} at try {retry_count}/{max_attempts} as it couldn't connect to the specied Hub repository.\"\n+                    )\n                     if wait_before_retry is not None:\n                         time.sleep(wait_before_retry)\n                     retry_count += 1"
        },
        {
            "sha": "8de8b0584c0db03b55e1e78f7f51e44488f2dddc",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/41925e42135257361b7f02aa20e3bbdab3f7b923/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/41925e42135257361b7f02aa20e3bbdab3f7b923/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=41925e42135257361b7f02aa20e3bbdab3f7b923",
            "patch": "@@ -74,6 +74,7 @@\n )\n from transformers.testing_utils import (\n     CaptureLogger,\n+    hub_retry,\n     is_flaky,\n     require_accelerate,\n     require_bitsandbytes,\n@@ -214,6 +215,16 @@ class ModelTesterMixin:\n     _is_composite = False\n     model_split_percents = [0.5, 0.7, 0.9]\n \n+    # Note: for all mixins that utilize the Hub in some way, we should ensure that\n+    # they contain the `hub_retry` decorator in case of failures.\n+    def __init_subclass__(cls, **kwargs):\n+        super().__init_subclass__(**kwargs)\n+        for attr_name in dir(cls):\n+            if attr_name.startswith(\"test_\"):\n+                attr = getattr(cls, attr_name)\n+                if callable(attr):\n+                    setattr(cls, attr_name, hub_retry(attr))\n+\n     @property\n     def all_generative_model_classes(self):\n         return tuple(model_class for model_class in self.all_model_classes if model_class.can_generate())"
        },
        {
            "sha": "7d8906fa593684468573fac83f167c1ddb588202",
            "filename": "tests/utils/test_modeling_utils.py",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/41925e42135257361b7f02aa20e3bbdab3f7b923/tests%2Futils%2Ftest_modeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/41925e42135257361b7f02aa20e3bbdab3f7b923/tests%2Futils%2Ftest_modeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_modeling_utils.py?ref=41925e42135257361b7f02aa20e3bbdab3f7b923",
            "patch": "@@ -51,6 +51,7 @@\n     LoggingLevel,\n     TemporaryHubRepo,\n     TestCasePlus,\n+    hub_retry,\n     is_staging_test,\n     require_accelerate,\n     require_flax,\n@@ -327,6 +328,18 @@ def tearDown(self):\n         torch.set_default_dtype(self.old_dtype)\n         super().tearDown()\n \n+    def test_hub_retry(self):\n+        @hub_retry(max_attempts=2)\n+        def test_func():\n+            # First attempt will fail with a connection error\n+            if not hasattr(test_func, \"attempt\"):\n+                test_func.attempt = 1\n+                raise requests.exceptions.ConnectionError(\"Connection failed\")\n+            # Second attempt will succeed\n+            return True\n+\n+        self.assertTrue(test_func())\n+\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"google-bert/bert-base-uncased\""
        }
    ],
    "stats": {
        "total": 71,
        "additions": 70,
        "deletions": 1
    }
}