{
    "author": "Cyrilvallez",
    "message": "Rework check_config_attributes.py (#43191)\n\n* rework\n\n* fix",
    "sha": "90b90fc0d9d8a6b0dd2be52d158caa5dd2f68bbe",
    "files": [
        {
            "sha": "817fca967cd997ff82a95301eb1e75dfbf958cf7",
            "filename": "utils/check_config_attributes.py",
            "status": "modified",
            "additions": 113,
            "deletions": 360,
            "changes": 473,
            "blob_url": "https://github.com/huggingface/transformers/blob/90b90fc0d9d8a6b0dd2be52d158caa5dd2f68bbe/utils%2Fcheck_config_attributes.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/90b90fc0d9d8a6b0dd2be52d158caa5dd2f68bbe/utils%2Fcheck_config_attributes.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_config_attributes.py?ref=90b90fc0d9d8a6b0dd2be52d158caa5dd2f68bbe",
            "patch": "@@ -30,340 +30,138 @@\n \n CONFIG_MAPPING = transformers.models.auto.configuration_auto.CONFIG_MAPPING\n \n+# Usually of small list of allowed attrs, but can be True to allow all\n SPECIAL_CASES_TO_ALLOW = {\n-    \"AfmoeConfig\": [\n-        \"global_attn_every_n_layers\",  # used internally in config to generate `layer_types`\n-        \"rope_scaling\",  # used internally in config to generate `rope_parameters`\n-    ],\n+    \"AfmoeConfig\": [\"global_attn_every_n_layers\", \"rope_scaling\"],\n     \"xLSTMConfig\": [\"add_out_norm\", \"chunkwise_kernel\", \"sequence_kernel\", \"step_kernel\"],\n-    \"Ernie4_5Config\": [\"tie_word_embeddings\"],\n-    \"Ernie4_5_MoeConfig\": [\"tie_word_embeddings\"],\n-    \"Ernie4_5_VL_MoeTextConfig\": [\"tie_word_embeddings\"],\n-    \"Lfm2Config\": [\"full_attn_idxs\", \"tie_word_embeddings\"],\n-    \"Lfm2MoeConfig\": [\"tie_word_embeddings\"],\n-    # used internally during generation to provide the custom logit processors with their necessary information\n-    \"DiaConfig\": [\n-        \"delay_pattern\",\n-    ],\n-    # 'max_position_embeddings' is not used in modeling file, but needed for eval frameworks like Huggingface's lighteval (https://github.com/huggingface/lighteval/blob/af24080ea4f16eaf1683e353042a2dfc9099f038/src/lighteval/models/base_model.py#L264).\n-    # periods and offsets are not used in modeling file, but used in the configuration file to define `layers_block_type` and `layers_num_experts`.\n-    \"BambaConfig\": [\n-        \"attn_layer_indices\",\n-    ],\n+    \"Lfm2Config\": [\"full_attn_idxs\"],\n+    \"DiaConfig\": [\"delay_pattern\"],\n+    \"BambaConfig\": [\"attn_layer_indices\"],\n     \"Dots1Config\": [\"max_window_layers\"],\n-    \"JambaConfig\": [\n-        \"max_position_embeddings\",\n-        \"attn_layer_offset\",\n-        \"attn_layer_period\",\n-        \"expert_layer_offset\",\n-        \"expert_layer_period\",\n-    ],\n-    \"PaddleOCRTextConfig\": [\"tie_word_embeddings\"],\n-    \"Qwen2Config\": [\"use_sliding_window\", \"max_window_layers\"],\n-    \"Qwen2MoeConfig\": [\"use_sliding_window\", \"max_window_layers\"],\n-    \"Qwen2VLTextConfig\": [\"use_sliding_window\", \"max_window_layers\"],\n-    \"Qwen2_5_VLTextConfig\": [\"use_sliding_window\", \"max_window_layers\"],\n-    \"Qwen2_5OmniTextConfig\": [\"use_sliding_window\", \"max_window_layers\"],\n-    \"Qwen2_5OmniTalkerConfig\": [\"use_sliding_window\", \"max_window_layers\"],\n-    \"Qwen3Config\": [\"max_window_layers\", \"use_sliding_window\"],  # now use `layer_types` instead\n-    \"Qwen3MoeConfig\": [\"max_window_layers\", \"use_sliding_window\"],\n-    # `cache_implementation` should be in the default generation config, but we don't yet support per-model\n-    # generation configs (TODO joao)\n-    \"Gemma2Config\": [\"tie_word_embeddings\", \"cache_implementation\"],\n-    \"Cohere2Config\": [\"cache_implementation\"],\n+    \"JambaConfig\": [\"attn_layer_offset\", \"attn_layer_period\", \"expert_layer_offset\", \"expert_layer_period\"],\n     \"JetMoeConfig\": [\"output_router_logits\"],\n-    # Dropout with this value was declared but never used\n     \"Phi3Config\": [\"embd_pdrop\"],\n-    \"PhimoeConfig\": [\"max_position_embeddings\"],\n-    # used to compute the property `self.chunk_length`\n     \"EncodecConfig\": [\"overlap\"],\n-    # used to compute `frame_rate`\n     \"XcodecConfig\": [\"sample_rate\", \"audio_channels\"],\n-    # used to compute the property `self.layers_block_type`\n     \"RecurrentGemmaConfig\": [\"block_types\"],\n-    # used as in the config to define `intermediate_size`\n     \"MambaConfig\": [\"expand\"],\n-    # used as in the config to define `intermediate_size`\n     \"FalconMambaConfig\": [\"expand\"],\n-    # used as `self.bert_model = BertModel(config, ...)`\n-    \"DPRConfig\": True,\n-    \"FuyuConfig\": True,\n-    # not used in modeling files, but it's an important information\n-    \"FSMTConfig\": [\"langs\"],\n-    # used internally in the configuration class file\n+    \"FSMTConfig\": [\"langs\", \"common_kwargs\", \"early_stopping\", \"length_penalty\", \"max_length\", \"num_beams\"],\n     \"GPTNeoConfig\": [\"attention_types\"],\n-    # used internally in the configuration class file\n+    \"BlenderbotConfig\": [\"encoder_no_repeat_ngram_size\"],\n     \"EsmConfig\": [\"is_folding_model\"],\n-    # used during training (despite we don't have training script for these models yet)\n     \"Mask2FormerConfig\": [\"ignore_value\"],\n-    # `ignore_value` used during training (despite we don't have training script for these models yet)\n-    # `norm` used in conversion script (despite not using in the modeling file)\n     \"OneFormerConfig\": [\"ignore_value\", \"norm\"],\n-    # used internally in the configuration class file\n     \"T5Config\": [\"feed_forward_proj\"],\n-    # used internally in the configuration class file\n-    # `tokenizer_class` get default value `T5Tokenizer` intentionally\n     \"MT5Config\": [\"feed_forward_proj\", \"tokenizer_class\"],\n     \"UMT5Config\": [\"feed_forward_proj\", \"tokenizer_class\"],\n-    # used internally in the configuration class file\n     \"LongT5Config\": [\"feed_forward_proj\"],\n-    # used internally in the configuration class file\n     \"Pop2PianoConfig\": [\"feed_forward_proj\"],\n-    # used internally in the configuration class file\n-    \"SwitchTransformersConfig\": [\"feed_forward_proj\"],\n-    # having default values other than `1e-5` - we can't fix them without breaking\n     \"BioGptConfig\": [\"layer_norm_eps\"],\n-    # having default values other than `1e-5` - we can't fix them without breaking\n     \"GLPNConfig\": [\"layer_norm_eps\"],\n-    # having default values other than `1e-5` - we can't fix them without breaking\n     \"SegformerConfig\": [\"layer_norm_eps\"],\n-    # having default values other than `1e-5` - we can't fix them without breaking\n     \"CvtConfig\": [\"layer_norm_eps\"],\n-    # having default values other than `1e-5` - we can't fix them without breaking\n     \"PerceiverConfig\": [\"layer_norm_eps\"],\n-    # used internally to calculate the feature size\n     \"InformerConfig\": [\"num_static_real_features\", \"num_time_features\"],\n-    # used internally to calculate the feature size\n     \"TimeSeriesTransformerConfig\": [\"num_static_real_features\", \"num_time_features\"],\n-    # used internally to calculate the feature size\n     \"AutoformerConfig\": [\"num_static_real_features\", \"num_time_features\"],\n-    # used internally to calculate `mlp_dim`\n     \"SamVisionConfig\": [\"mlp_ratio\"],\n-    # used by sam3 video, kept here for consistency with sam2\n     \"Sam3VisionConfig\": [\"backbone_feature_sizes\"],\n-    # used internally to calculate `mlp_dim`\n     \"SamHQVisionConfig\": [\"mlp_ratio\"],\n-    # For (head) training, but so far not implemented\n     \"ClapAudioConfig\": [\"num_classes\"],\n-    # Not used, but providing useful information to users\n     \"SpeechT5HifiGanConfig\": [\"sampling_rate\"],\n-    # used internally in the configuration class file\n     \"UdopConfig\": [\"feed_forward_proj\"],\n-    # Actually used in the config or generation config, in that case necessary for the sub-components generation\n-    \"SeamlessM4TConfig\": [\n-        \"max_new_tokens\",\n-        \"t2u_max_new_tokens\",\n-        \"t2u_decoder_attention_heads\",\n-        \"t2u_decoder_ffn_dim\",\n-        \"t2u_decoder_layers\",\n-        \"t2u_encoder_attention_heads\",\n-        \"t2u_encoder_ffn_dim\",\n-        \"t2u_encoder_layers\",\n-        \"t2u_max_position_embeddings\",\n-    ],\n-    # Actually used in the config or generation config, in that case necessary for the sub-components generation\n-    \"SeamlessM4Tv2Config\": [\n-        \"max_new_tokens\",\n-        \"t2u_decoder_attention_heads\",\n-        \"t2u_decoder_ffn_dim\",\n-        \"t2u_decoder_layers\",\n-        \"t2u_encoder_attention_heads\",\n-        \"t2u_encoder_ffn_dim\",\n-        \"t2u_encoder_layers\",\n-        \"t2u_max_position_embeddings\",\n-        \"t2u_variance_pred_dropout\",\n-        \"t2u_variance_predictor_embed_dim\",\n-        \"t2u_variance_predictor_hidden_dim\",\n-        \"t2u_variance_predictor_kernel_size\",\n-    ],\n-    \"ZambaConfig\": [\n-        \"tie_word_embeddings\",\n-        \"attn_layer_offset\",\n-        \"attn_layer_period\",\n-    ],\n-    \"MllamaTextConfig\": [\n-        \"initializer_range\",\n-    ],\n-    \"MllamaVisionConfig\": [\n-        \"initializer_range\",\n-        \"supported_aspect_ratios\",\n-    ],\n-    \"ConditionalDetrConfig\": [\n-        \"bbox_cost\",\n-        \"bbox_loss_coefficient\",\n-        \"class_cost\",\n-        \"cls_loss_coefficient\",\n-        \"dice_loss_coefficient\",\n-        \"focal_alpha\",\n-        \"giou_cost\",\n-        \"giou_loss_coefficient\",\n-        \"mask_loss_coefficient\",\n-    ],\n-    \"DabDetrConfig\": [\n-        \"dilation\",\n-        \"bbox_cost\",\n-        \"bbox_loss_coefficient\",\n-        \"class_cost\",\n-        \"cls_loss_coefficient\",\n-        \"focal_alpha\",\n-        \"giou_cost\",\n-        \"giou_loss_coefficient\",\n-    ],\n-    \"DetrConfig\": [\n-        \"bbox_cost\",\n-        \"bbox_loss_coefficient\",\n-        \"class_cost\",\n-        \"dice_loss_coefficient\",\n-        \"eos_coefficient\",\n-        \"giou_cost\",\n-        \"giou_loss_coefficient\",\n-        \"mask_loss_coefficient\",\n-    ],\n-    \"DFineConfig\": [\n-        \"eos_coefficient\",\n-        \"focal_loss_alpha\",\n-        \"focal_loss_gamma\",\n-        \"matcher_alpha\",\n-        \"matcher_bbox_cost\",\n-        \"matcher_class_cost\",\n-        \"matcher_gamma\",\n-        \"matcher_giou_cost\",\n-        \"use_focal_loss\",\n-        \"weight_loss_bbox\",\n-        \"weight_loss_giou\",\n-        \"weight_loss_vfl\",\n-        \"weight_loss_fgl\",\n-        \"weight_loss_ddf\",\n-    ],\n-    \"GroundingDinoConfig\": [\n-        \"bbox_cost\",\n-        \"bbox_loss_coefficient\",\n-        \"class_cost\",\n-        \"focal_alpha\",\n-        \"giou_cost\",\n-        \"giou_loss_coefficient\",\n-    ],\n-    \"MMGroundingDinoConfig\": [\n-        \"bbox_cost\",\n-        \"bbox_loss_coefficient\",\n-        \"class_cost\",\n-        \"focal_alpha\",\n-        \"giou_cost\",\n-        \"giou_loss_coefficient\",\n-    ],\n-    \"RTDetrConfig\": [\n-        \"eos_coefficient\",\n-        \"focal_loss_alpha\",\n-        \"focal_loss_gamma\",\n-        \"matcher_alpha\",\n-        \"matcher_bbox_cost\",\n-        \"matcher_class_cost\",\n-        \"matcher_gamma\",\n-        \"matcher_giou_cost\",\n-        \"use_focal_loss\",\n-        \"weight_loss_bbox\",\n-        \"weight_loss_giou\",\n-        \"weight_loss_vfl\",\n-    ],\n-    \"RTDetrV2Config\": [\n-        \"eos_coefficient\",\n-        \"focal_loss_alpha\",\n-        \"focal_loss_gamma\",\n-        \"matcher_alpha\",\n-        \"matcher_bbox_cost\",\n-        \"matcher_class_cost\",\n-        \"matcher_gamma\",\n-        \"matcher_giou_cost\",\n-        \"use_focal_loss\",\n-        \"weight_loss_bbox\",\n-        \"weight_loss_giou\",\n-        \"weight_loss_vfl\",\n-    ],\n-    \"YolosConfig\": [\n-        \"bbox_cost\",\n-        \"bbox_loss_coefficient\",\n-        \"class_cost\",\n-        \"eos_coefficient\",\n-        \"giou_cost\",\n-        \"giou_loss_coefficient\",\n-    ],\n+    \"ZambaConfig\": [\"attn_layer_offset\", \"attn_layer_period\"],\n+    \"MllamaVisionConfig\": [\"supported_aspect_ratios\"],\n     \"GPTNeoXConfig\": [\"rotary_emb_base\"],\n-    \"Gemma3Config\": [\"boi_token_index\", \"eoi_token_index\"],\n-    \"Gemma3TextConfig\": [\"cache_implementation\", \"tie_word_embeddings\"],\n-    \"T5Gemma2TextConfig\": [\"tie_word_embeddings\"],\n-    \"T5Gemma2DecoderConfig\": [\"tie_word_embeddings\"],\n-    \"ShieldGemma2Config\": [\n-        \"boi_token_index\",\n-        \"eoi_token_index\",\n-        \"initializer_range\",\n-        \"mm_tokens_per_image\",\n-        \"text_config\",\n-        \"vision_config\",\n-    ],\n-    \"Llama4Config\": [\"boi_token_index\", \"eoi_token_index\"],\n-    \"Llama4TextConfig\": [\n-        \"interleave_moe_layer_step\",\n-        \"no_rope_layer_interval\",\n-        \"no_rope_layers\",\n-        \"output_router_logits\",\n-        \"router_aux_loss_coef\",\n-        \"router_jitter_noise\",\n-        \"cache_implementation\",\n-        \"attention_chunk_size\",\n-    ],\n+    \"ShieldGemma2Config\": [\"mm_tokens_per_image\", \"vision_config\"],\n     \"Llama4VisionConfig\": [\"multi_modal_projector_bias\", \"norm_eps\"],\n-    \"ModernBertDecoderConfig\": [\n-        \"embedding_dropout\",\n-        \"hidden_activation\",\n-        \"initializer_cutoff_factor\",\n-        \"intermediate_size\",\n-        \"max_position_embeddings\",\n-        \"mlp_bias\",\n-        \"mlp_dropout\",\n-        \"classifier_activation\",\n-        \"global_attn_every_n_layers\",\n-        \"local_attention\",\n-        \"local_rope_theta\",\n-    ],\n+    \"ModernBertDecoderConfig\": [\"global_attn_every_n_layers\", \"local_attention\", \"local_rope_theta\"],\n     \"SmolLM3Config\": [\"no_rope_layer_interval\"],\n-    \"Gemma3nVisionConfig\": [\"architecture\", \"do_pooling\", \"model_args\"],  # this is for use in `timm`\n-    \"VaultGemmaConfig\": [\"tie_word_embeddings\"],\n-    \"GemmaConfig\": [\"tie_word_embeddings\"],\n+    \"Gemma3nVisionConfig\": [\"architecture\", \"do_pooling\", \"model_args\"],\n     \"CsmConfig\": [\"tie_codebooks_embeddings\"],\n-    \"LayoutXLMConfig\": True,\n     \"DeepseekV2Config\": [\"norm_topk_prob\"],\n+    \"SeamlessM4TConfig\": True,\n+    \"SeamlessM4Tv2Config\": True,\n+    \"ConditionalDetrConfig\": True,\n+    \"DabDetrConfig\": True,\n+    \"SwitchTransformersConfig\": True,\n+    \"DetrConfig\": True,\n+    \"DFineConfig\": True,\n+    \"GroundingDinoConfig\": True,\n+    \"MMGroundingDinoConfig\": True,\n+    \"RTDetrConfig\": True,\n+    \"RTDetrV2Config\": True,\n+    \"YolosConfig\": True,\n+    \"Llama4TextConfig\": True,\n+    \"DPRConfig\": True,\n+    \"FuyuConfig\": True,\n+    \"LayoutXLMConfig\": True,\n+    \"CLIPSegConfig\": True,\n+    \"DeformableDetrConfig\": True,\n+    \"DinatConfig\": True,\n+    \"DonutSwinConfig\": True,\n+    \"FastSpeech2ConformerConfig\": True,\n+    \"LayoutLMv2Config\": True,\n+    \"MaskFormerSwinConfig\": True,\n+    \"MptConfig\": True,\n+    \"MptAttentionConfig\": True,\n+    \"RagConfig\": True,\n+    \"SpeechT5Config\": True,\n+    \"SwinConfig\": True,\n+    \"Swin2SRConfig\": True,\n+    \"Swinv2Config\": True,\n+    \"TableTransformerConfig\": True,\n+    \"TapasConfig\": True,\n+    \"UniSpeechConfig\": True,\n+    \"UniSpeechSatConfig\": True,\n+    \"WavLMConfig\": True,\n+    \"WhisperConfig\": True,\n+    \"JukeboxPriorConfig\": True,\n+    \"Pix2StructTextConfig\": True,\n+    \"IdeficsConfig\": True,\n+    \"IdeficsVisionConfig\": True,\n+    \"IdeficsPerceiverConfig\": True,\n+    \"GptOssConfig\": True,\n }\n \n-\n-# TODO (ydshieh): Check the failing cases, try to fix them or move some cases to the above block once we are sure\n-SPECIAL_CASES_TO_ALLOW.update(\n-    {\n-        \"CLIPSegConfig\": True,\n-        \"DeformableDetrConfig\": True,\n-        \"DinatConfig\": True,\n-        \"DonutSwinConfig\": True,\n-        \"FastSpeech2ConformerConfig\": True,\n-        \"FSMTConfig\": True,\n-        \"LayoutLMv2Config\": True,\n-        \"MaskFormerSwinConfig\": True,\n-        \"MT5Config\": True,\n-        # For backward compatibility with trust remote code models\n-        \"MptConfig\": True,\n-        \"MptAttentionConfig\": True,\n-        \"OneFormerConfig\": True,\n-        \"PerceiverConfig\": True,\n-        \"RagConfig\": True,\n-        \"SpeechT5Config\": True,\n-        \"SwinConfig\": True,\n-        \"Swin2SRConfig\": True,\n-        \"Swinv2Config\": True,\n-        \"SwitchTransformersConfig\": True,\n-        \"TableTransformerConfig\": True,\n-        \"TapasConfig\": True,\n-        \"UniSpeechConfig\": True,\n-        \"UniSpeechSatConfig\": True,\n-        \"WavLMConfig\": True,\n-        \"WhisperConfig\": True,\n-        # TODO: @Arthur (for `alignment_head` and `alignment_layer`)\n-        \"JukeboxPriorConfig\": True,\n-        # TODO: @Younes (for `is_decoder`)\n-        \"Pix2StructTextConfig\": True,\n-        \"IdeficsConfig\": True,\n-        \"IdeficsVisionConfig\": True,\n-        \"IdeficsPerceiverConfig\": True,\n-        # TODO: @Arthur/Joao (`hidden_act` unused)\n-        \"GptOssConfig\": True,\n-    }\n+# Common and important attributes, even if they do not always appear in the modeling files (can be a regex pattern)\n+ATTRIBUTES_TO_ALLOW = (\n+    # Inits related\n+    \"initializer_range\",\n+    \"init_std\",\n+    \"initializer_factor\",\n+    \"tie_word_embeddings\",\n+    # Special tokens\n+    \"bos_index\",\n+    \"eos_index\",\n+    \"pad_index\",\n+    \"unk_index\",\n+    \"mask_index\",\n+    r\".+_token_id\",\n+    r\".+_token_index\",\n+    # Processors\n+    \"image_seq_length\",\n+    \"video_seq_length\",\n+    \"image_size\",\n+    \"text_config\",  # may appear as `get_text_config()`\n+    \"use_cache\",\n+    \"out_features\",\n+    \"out_indices\",\n+    \"sampling_rate\",\n+    # backbone related arguments passed to load_backbone\n+    \"use_pretrained_backbone\",\n+    \"backbone\",\n+    \"backbone_config\",\n+    \"use_timm_backbone\",\n+    \"backbone_kwargs\",\n+    # rope attributes may not appear directly in the modeling but are used\n+    \"rope_theta\",\n+    \"partial_rotary_factor\",\n+    \"max_position_embeddings\",\n+    \"pretraining_tp\",\n+    \"use_sliding_window\",\n+    \"max_window_layers\",\n )\n \n \n@@ -381,7 +179,7 @@ def check_attribute_being_used(config_class, attributes, default_value, source_s\n             The python source code strings in the same modeling directory where `config_class` is defined. The file\n             containing the definition of `config_class` should be excluded.\n     \"\"\"\n-    attribute_used = False\n+    # If we can find the attribute used, then it's all good\n     for attribute in attributes:\n         for modeling_source in source_strings:\n             # check if we can find `config.xxx`, `getattr(config, \"xxx\", ...)` or `getattr(self.config, \"xxx\", ...)`\n@@ -394,7 +192,7 @@ def check_attribute_being_used(config_class, attributes, default_value, source_s\n                     and f\"config.get_text_config().{attribute}\" in modeling_source\n                 )\n             ):\n-                attribute_used = True\n+                return True\n             # Deal with multi-line cases\n             elif (\n                 re.search(\n@@ -403,71 +201,26 @@ def check_attribute_being_used(config_class, attributes, default_value, source_s\n                 )\n                 is not None\n             ):\n-                attribute_used = True\n-            if attribute_used:\n-                break\n-        if attribute_used:\n-            break\n-\n-    # common and important attributes, even if they do not always appear in the modeling files\n-    attributes_to_allow = [\n-        \"initializer_range\",\n-        \"init_std\",\n-        \"initializer_factor\",\n-        \"tie_word_embeddings\",\n-        \"bos_index\",\n-        \"eos_index\",\n-        \"pad_index\",\n-        \"unk_index\",\n-        \"mask_index\",\n-        \"image_token_id\",  # for VLMs\n-        \"video_token_id\",\n-        \"image_seq_length\",\n-        \"video_seq_length\",\n-        \"image_size\",\n-        \"text_config\",  # may appear as `get_text_config()`\n-        \"use_cache\",\n-        \"out_features\",\n-        \"out_indices\",\n-        \"sampling_rate\",\n-        # backbone related arguments passed to load_backbone\n-        \"use_pretrained_backbone\",\n-        \"backbone\",\n-        \"backbone_config\",\n-        \"use_timm_backbone\",\n-        \"backbone_kwargs\",\n-        # rope attributes may not appear directly in the modeling but are used\n-        \"rope_theta\",\n-        \"partial_rotary_factor\",\n-        \"pretraining_tp\",\n-        \"boi_token_id\",\n-        \"eoi_token_id\",\n-    ]\n-    attributes_used_in_generation = [\"encoder_no_repeat_ngram_size\"]\n-\n-    # Special cases to be allowed\n-    case_allowed = True\n-    if not attribute_used:\n-        case_allowed = False\n-        for attribute in attributes:\n-            # Allow if the default value in the configuration class is different from the one in `PreTrainedConfig`\n-            if attribute == \"is_encoder_decoder\" and default_value is True:\n-                case_allowed = True\n-            elif attribute == \"tie_word_embeddings\" and default_value is False:\n-                case_allowed = True\n+                return True\n \n-            # Allow cases without checking the default value in the configuration class\n-            elif attribute in attributes_to_allow + attributes_used_in_generation:\n-                case_allowed = True\n-            elif attribute.endswith(\"_token_id\"):\n-                case_allowed = True\n-\n-            # configuration class specific cases\n-            if not case_allowed:\n-                allowed_cases = SPECIAL_CASES_TO_ALLOW.get(config_class.__name__, [])\n-                case_allowed = allowed_cases is True or attribute in allowed_cases\n-\n-    return attribute_used or case_allowed\n+    # Special cases to be allowed even if not found as used\n+    for attribute in attributes:\n+        # Allow if the default value in the configuration class is different from the one in `PreTrainedConfig`\n+        if (attribute == \"is_encoder_decoder\" and default_value is True) or (\n+            attribute == \"tie_word_embeddings\" and default_value is False\n+        ):\n+            return True\n+        # General exceptions for all models\n+        elif any(re.search(exception, attribute) for exception in ATTRIBUTES_TO_ALLOW):\n+            return True\n+        # Model-specific exceptions\n+        elif config_class.__name__ in SPECIAL_CASES_TO_ALLOW:\n+            model_exceptions = SPECIAL_CASES_TO_ALLOW[config_class.__name__]\n+            # Can be true to allow all attributes, or a list of specific allowed attributes\n+            if (isinstance(model_exceptions, bool) and model_exceptions) or attribute in model_exceptions:\n+                return True\n+\n+    return False\n \n \n def check_config_attributes_being_used(config_class):"
        }
    ],
    "stats": {
        "total": 473,
        "additions": 113,
        "deletions": 360
    }
}