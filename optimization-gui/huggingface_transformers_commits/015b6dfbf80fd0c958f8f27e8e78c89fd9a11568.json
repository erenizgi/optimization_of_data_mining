{
    "author": "sebasv",
    "message": "Fix `pad` image transform for batched inputs (#37544)\n\n* fix\n\n* add batch dimension to expected output",
    "sha": "015b6dfbf80fd0c958f8f27e8e78c89fd9a11568",
    "files": [
        {
            "sha": "c8a7edd985c21e138a8fe598f2aacd136e55d6e3",
            "filename": "src/transformers/image_transforms.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/015b6dfbf80fd0c958f8f27e8e78c89fd9a11568/src%2Ftransformers%2Fimage_transforms.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/015b6dfbf80fd0c958f8f27e8e78c89fd9a11568/src%2Ftransformers%2Fimage_transforms.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fimage_transforms.py?ref=015b6dfbf80fd0c958f8f27e8e78c89fd9a11568",
            "patch": "@@ -751,7 +751,7 @@ def _expand_for_data_format(values):\n         values = ((0, 0), *values) if input_data_format == ChannelDimension.FIRST else (*values, (0, 0))\n \n         # Add additional padding if there's a batch dimension\n-        values = (0, *values) if image.ndim == 4 else values\n+        values = ((0, 0), *values) if image.ndim == 4 else values\n         return values\n \n     padding = _expand_for_data_format(padding)"
        },
        {
            "sha": "3d3b84c7e81b5be833dd69122f9ca7ca8696841a",
            "filename": "tests/test_image_transforms.py",
            "status": "modified",
            "additions": 19,
            "deletions": 0,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/015b6dfbf80fd0c958f8f27e8e78c89fd9a11568/tests%2Ftest_image_transforms.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/015b6dfbf80fd0c958f8f27e8e78c89fd9a11568/tests%2Ftest_image_transforms.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_image_transforms.py?ref=015b6dfbf80fd0c958f8f27e8e78c89fd9a11568",
            "patch": "@@ -578,6 +578,25 @@ def test_pad(self):\n             )\n         )\n \n+        # Test that padding works on batched images\n+        image = np.array(\n+            [\n+                [[0, 1], [2, 3]],\n+            ]\n+        )[None, ...]\n+        expected_image = np.array(\n+            [\n+                [[0, 0], [0, 1], [2, 3]],\n+                [[0, 0], [0, 0], [0, 0]],\n+            ]\n+        )[None, ...]\n+        # fmt: on\n+        self.assertTrue(\n+            np.allclose(\n+                expected_image, pad(image, ((0, 1), (1, 0)), mode=\"constant\", input_data_format=\"channels_last\")\n+            )\n+        )\n+\n     @require_vision\n     def test_convert_to_rgb(self):\n         # Test that an RGBA image is converted to RGB"
        }
    ],
    "stats": {
        "total": 21,
        "additions": 20,
        "deletions": 1
    }
}