{
    "author": "ydshieh",
    "message": "Avoid pipeline test failing related to Hub call (#37170)\n\n* cls\n\n* cls\n\n* cls\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "35253076f4f8ef12630dcc3a9618221a2c0a4f40",
    "files": [
        {
            "sha": "2e87b4c2e1a8642b4fb5aeb6474fc727f0aa0782",
            "filename": ".circleci/create_circleci_config.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/35253076f4f8ef12630dcc3a9618221a2c0a4f40/.circleci%2Fcreate_circleci_config.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/35253076f4f8ef12630dcc3a9618221a2c0a4f40/.circleci%2Fcreate_circleci_config.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.circleci%2Fcreate_circleci_config.py?ref=35253076f4f8ef12630dcc3a9618221a2c0a4f40",
            "patch": "@@ -171,6 +171,7 @@ def to_dict(self):\n                     \"command\": f\"TESTS=$(circleci tests split  --split-by=timings {self.job_name}_test_list.txt) && echo $TESTS > splitted_tests.txt && echo $TESTS | tr ' ' '\\n'\" if self.parallelism else f\"awk '{{printf \\\"%s \\\", $0}}' {self.job_name}_test_list.txt > splitted_tests.txt\"\n                     }\n             },\n+            {\"run\": {\"name\": \"fetch hub objects before pytest\", \"command\": \"python3 utils/fetch_hub_objects_for_ci.py\"}},\n             {\"run\": {\n                 \"name\": \"Run tests\",\n                 \"command\": f\"({timeout_cmd} python3 -m pytest {marker_cmd} -n {self.pytest_num_workers} {junit_flags} {repeat_on_failure_flags} {' '.join(pytest_flags)} $(cat splitted_tests.txt) | tee tests_output.txt)\"}"
        },
        {
            "sha": "08a361add7f3199f137054000cf615b8e8c3bc27",
            "filename": "tests/pipelines/test_pipelines_audio_classification.py",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/35253076f4f8ef12630dcc3a9618221a2c0a4f40/tests%2Fpipelines%2Ftest_pipelines_audio_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/35253076f4f8ef12630dcc3a9618221a2c0a4f40/tests%2Fpipelines%2Ftest_pipelines_audio_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_audio_classification.py?ref=35253076f4f8ef12630dcc3a9618221a2c0a4f40",
            "patch": "@@ -14,6 +14,7 @@\n \n import unittest\n \n+import datasets\n import numpy as np\n from huggingface_hub import AudioClassificationOutputElement\n \n@@ -24,6 +25,7 @@\n )\n from transformers.pipelines import AudioClassificationPipeline, pipeline\n from transformers.testing_utils import (\n+    _run_pipeline_tests,\n     compare_pipeline_output_to_hub_spec,\n     is_pipeline_test,\n     nested_simplify,\n@@ -45,6 +47,9 @@ class AudioClassificationPipelineTests(unittest.TestCase):\n     model_mapping = MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING\n     tf_model_mapping = TF_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING\n \n+    if _run_pipeline_tests:\n+        _dataset = datasets.load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n+\n     def get_test_pipeline(\n         self,\n         model,\n@@ -94,11 +99,8 @@ def run_pipeline_test(self, audio_classifier, examples):\n \n     @require_torchaudio\n     def run_torchaudio(self, audio_classifier):\n-        import datasets\n-\n         # test with a local file\n-        dataset = datasets.load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n-        audio = dataset[0][\"audio\"][\"array\"]\n+        audio = self._dataset[0][\"audio\"][\"array\"]\n         output = audio_classifier(audio)\n         self.assertEqual(\n             output,\n@@ -168,8 +170,6 @@ def test_small_model_pt_fp16(self):\n     @require_torch\n     @slow\n     def test_large_model_pt(self):\n-        import datasets\n-\n         model = \"superb/wav2vec2-base-superb-ks\"\n \n         audio_classifier = pipeline(\"audio-classification\", model=model)"
        },
        {
            "sha": "73176a43837edbde3648de8eb8a5bf86a6ccb759",
            "filename": "tests/pipelines/test_pipelines_depth_estimation.py",
            "status": "modified",
            "additions": 12,
            "deletions": 7,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/35253076f4f8ef12630dcc3a9618221a2c0a4f40/tests%2Fpipelines%2Ftest_pipelines_depth_estimation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/35253076f4f8ef12630dcc3a9618221a2c0a4f40/tests%2Fpipelines%2Ftest_pipelines_depth_estimation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_depth_estimation.py?ref=35253076f4f8ef12630dcc3a9618221a2c0a4f40",
            "patch": "@@ -14,12 +14,14 @@\n \n import unittest\n \n+import datasets\n from huggingface_hub import DepthEstimationOutput\n from huggingface_hub.utils import insecure_hashlib\n \n from transformers import MODEL_FOR_DEPTH_ESTIMATION_MAPPING, is_torch_available, is_vision_available\n from transformers.pipelines import DepthEstimationPipeline, pipeline\n from transformers.testing_utils import (\n+    _run_pipeline_tests,\n     compare_pipeline_output_to_hub_spec,\n     is_pipeline_test,\n     nested_simplify,\n@@ -58,6 +60,13 @@ def hashimage(image: Image) -> str:\n class DepthEstimationPipelineTests(unittest.TestCase):\n     model_mapping = MODEL_FOR_DEPTH_ESTIMATION_MAPPING\n \n+    if _run_pipeline_tests:\n+        # we use revision=\"refs/pr/1\" until the PR is merged\n+        # https://hf.co/datasets/hf-internal-testing/fixtures_image_utils/discussions/1\n+        _dataset = datasets.load_dataset(\n+            \"hf-internal-testing/fixtures_image_utils\", split=\"test\", revision=\"refs/pr/1\"\n+        )\n+\n     def get_test_pipeline(\n         self,\n         model,\n@@ -83,21 +92,17 @@ def get_test_pipeline(\n     def run_pipeline_test(self, depth_estimator, examples):\n         outputs = depth_estimator(\"./tests/fixtures/tests_samples/COCO/000000039769.png\")\n         self.assertEqual({\"predicted_depth\": ANY(torch.Tensor), \"depth\": ANY(Image.Image)}, outputs)\n-        import datasets\n \n-        # we use revision=\"refs/pr/1\" until the PR is merged\n-        # https://hf.co/datasets/hf-internal-testing/fixtures_image_utils/discussions/1\n-        dataset = datasets.load_dataset(\"hf-internal-testing/fixtures_image_utils\", split=\"test\", revision=\"refs/pr/1\")\n         outputs = depth_estimator(\n             [\n                 Image.open(\"./tests/fixtures/tests_samples/COCO/000000039769.png\"),\n                 \"http://images.cocodataset.org/val2017/000000039769.jpg\",\n                 # RGBA\n-                dataset[0][\"image\"],\n+                self._dataset[0][\"image\"],\n                 # LA\n-                dataset[1][\"image\"],\n+                self._dataset[1][\"image\"],\n                 # L\n-                dataset[2][\"image\"],\n+                self._dataset[2][\"image\"],\n             ]\n         )\n         self.assertEqual("
        },
        {
            "sha": "e5dce2a03dc76ca57d889009382ceb22961ffd57",
            "filename": "tests/pipelines/test_pipelines_image_classification.py",
            "status": "modified",
            "additions": 12,
            "deletions": 9,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/35253076f4f8ef12630dcc3a9618221a2c0a4f40/tests%2Fpipelines%2Ftest_pipelines_image_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/35253076f4f8ef12630dcc3a9618221a2c0a4f40/tests%2Fpipelines%2Ftest_pipelines_image_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_image_classification.py?ref=35253076f4f8ef12630dcc3a9618221a2c0a4f40",
            "patch": "@@ -14,6 +14,7 @@\n \n import unittest\n \n+import datasets\n from huggingface_hub import ImageClassificationOutputElement\n \n from transformers import (\n@@ -25,6 +26,7 @@\n )\n from transformers.pipelines import ImageClassificationPipeline, pipeline\n from transformers.testing_utils import (\n+    _run_pipeline_tests,\n     compare_pipeline_output_to_hub_spec,\n     is_pipeline_test,\n     nested_simplify,\n@@ -58,6 +60,13 @@ class ImageClassificationPipelineTests(unittest.TestCase):\n     model_mapping = MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING\n     tf_model_mapping = TF_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING\n \n+    if _run_pipeline_tests:\n+        # we use revision=\"refs/pr/1\" until the PR is merged\n+        # https://hf.co/datasets/hf-internal-testing/fixtures_image_utils/discussions/1\n+        _dataset = datasets.load_dataset(\n+            \"hf-internal-testing/fixtures_image_utils\", split=\"test\", revision=\"refs/pr/1\"\n+        )\n+\n     def get_test_pipeline(\n         self,\n         model,\n@@ -93,23 +102,17 @@ def run_pipeline_test(self, image_classifier, examples):\n             ],\n         )\n \n-        import datasets\n-\n-        # we use revision=\"refs/pr/1\" until the PR is merged\n-        # https://hf.co/datasets/hf-internal-testing/fixtures_image_utils/discussions/1\n-        dataset = datasets.load_dataset(\"hf-internal-testing/fixtures_image_utils\", split=\"test\", revision=\"refs/pr/1\")\n-\n         # Accepts URL + PIL.Image + lists\n         outputs = image_classifier(\n             [\n                 Image.open(\"./tests/fixtures/tests_samples/COCO/000000039769.png\"),\n                 \"http://images.cocodataset.org/val2017/000000039769.jpg\",\n                 # RGBA\n-                dataset[0][\"image\"],\n+                self._dataset[0][\"image\"],\n                 # LA\n-                dataset[1][\"image\"],\n+                self._dataset[1][\"image\"],\n                 # L\n-                dataset[2][\"image\"],\n+                self._dataset[2][\"image\"],\n             ]\n         )\n         self.assertEqual("
        },
        {
            "sha": "af251230a6e754d7178cc57e3fd2df4a764f5bfc",
            "filename": "tests/pipelines/test_pipelines_image_segmentation.py",
            "status": "modified",
            "additions": 17,
            "deletions": 7,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/35253076f4f8ef12630dcc3a9618221a2c0a4f40/tests%2Fpipelines%2Ftest_pipelines_image_segmentation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/35253076f4f8ef12630dcc3a9618221a2c0a4f40/tests%2Fpipelines%2Ftest_pipelines_image_segmentation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_image_segmentation.py?ref=35253076f4f8ef12630dcc3a9618221a2c0a4f40",
            "patch": "@@ -37,6 +37,7 @@\n     pipeline,\n )\n from transformers.testing_utils import (\n+    _run_pipeline_tests,\n     compare_pipeline_output_to_hub_spec,\n     is_pipeline_test,\n     nested_simplify,\n@@ -89,6 +90,13 @@ class ImageSegmentationPipelineTests(unittest.TestCase):\n         + (MODEL_FOR_INSTANCE_SEGMENTATION_MAPPING.items() if MODEL_FOR_INSTANCE_SEGMENTATION_MAPPING else [])\n     )\n \n+    if _run_pipeline_tests:\n+        # we use revision=\"refs/pr/1\" until the PR is merged\n+        # https://hf.co/datasets/hf-internal-testing/fixtures_image_utils/discussions/1\n+        _dataset = datasets.load_dataset(\n+            \"hf-internal-testing/fixtures_image_utils\", split=\"test\", revision=\"refs/pr/1\"\n+        )\n+\n     def get_test_pipeline(\n         self,\n         model,\n@@ -130,20 +138,22 @@ def run_pipeline_test(self, image_segmenter, examples):\n         # to make it work\n         self.assertEqual([{\"score\": ANY(float, type(None)), \"label\": ANY(str), \"mask\": ANY(Image.Image)}] * n, outputs)\n \n-        # we use revision=\"refs/pr/1\" until the PR is merged\n-        # https://hf.co/datasets/hf-internal-testing/fixtures_image_utils/discussions/1\n-        dataset = datasets.load_dataset(\"hf-internal-testing/fixtures_image_utils\", split=\"test\", revision=\"refs/pr/1\")\n-\n         # RGBA\n-        outputs = image_segmenter(dataset[0][\"image\"], threshold=0.0, mask_threshold=0, overlap_mask_area_threshold=0)\n+        outputs = image_segmenter(\n+            self._dataset[0][\"image\"], threshold=0.0, mask_threshold=0, overlap_mask_area_threshold=0\n+        )\n         m = len(outputs)\n         self.assertEqual([{\"score\": ANY(float, type(None)), \"label\": ANY(str), \"mask\": ANY(Image.Image)}] * m, outputs)\n         # LA\n-        outputs = image_segmenter(dataset[1][\"image\"], threshold=0.0, mask_threshold=0, overlap_mask_area_threshold=0)\n+        outputs = image_segmenter(\n+            self._dataset[1][\"image\"], threshold=0.0, mask_threshold=0, overlap_mask_area_threshold=0\n+        )\n         m = len(outputs)\n         self.assertEqual([{\"score\": ANY(float, type(None)), \"label\": ANY(str), \"mask\": ANY(Image.Image)}] * m, outputs)\n         # L\n-        outputs = image_segmenter(dataset[2][\"image\"], threshold=0.0, mask_threshold=0, overlap_mask_area_threshold=0)\n+        outputs = image_segmenter(\n+            self._dataset[2][\"image\"], threshold=0.0, mask_threshold=0, overlap_mask_area_threshold=0\n+        )\n         m = len(outputs)\n         self.assertEqual([{\"score\": ANY(float, type(None)), \"label\": ANY(str), \"mask\": ANY(Image.Image)}] * m, outputs)\n "
        },
        {
            "sha": "c6fa2c1ec1d4cc283bf09d1c39b907723edefdbb",
            "filename": "tests/pipelines/test_pipelines_object_detection.py",
            "status": "modified",
            "additions": 12,
            "deletions": 9,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/35253076f4f8ef12630dcc3a9618221a2c0a4f40/tests%2Fpipelines%2Ftest_pipelines_object_detection.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/35253076f4f8ef12630dcc3a9618221a2c0a4f40/tests%2Fpipelines%2Ftest_pipelines_object_detection.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_object_detection.py?ref=35253076f4f8ef12630dcc3a9618221a2c0a4f40",
            "patch": "@@ -14,6 +14,7 @@\n \n import unittest\n \n+import datasets\n from huggingface_hub import ObjectDetectionOutputElement\n \n from transformers import (\n@@ -25,6 +26,7 @@\n     pipeline,\n )\n from transformers.testing_utils import (  #\n+    _run_pipeline_tests,\n     compare_pipeline_output_to_hub_spec,\n     is_pipeline_test,\n     nested_simplify,\n@@ -56,6 +58,13 @@ def open(*args, **kwargs):\n class ObjectDetectionPipelineTests(unittest.TestCase):\n     model_mapping = MODEL_FOR_OBJECT_DETECTION_MAPPING\n \n+    if _run_pipeline_tests:\n+        # we use revision=\"refs/pr/1\" until the PR is merged\n+        # https://hf.co/datasets/hf-internal-testing/fixtures_image_utils/discussions/1\n+        _dataset = datasets.load_dataset(\n+            \"hf-internal-testing/fixtures_image_utils\", split=\"test\", revision=\"refs/pr/1\"\n+        )\n+\n     def get_test_pipeline(\n         self,\n         model,\n@@ -89,21 +98,15 @@ def run_pipeline_test(self, object_detector, examples):\n                 },\n             )\n \n-        import datasets\n-\n-        # we use revision=\"refs/pr/1\" until the PR is merged\n-        # https://hf.co/datasets/hf-internal-testing/fixtures_image_utils/discussions/1\n-        dataset = datasets.load_dataset(\"hf-internal-testing/fixtures_image_utils\", split=\"test\", revision=\"refs/pr/1\")\n-\n         batch = [\n             Image.open(\"./tests/fixtures/tests_samples/COCO/000000039769.png\"),\n             \"http://images.cocodataset.org/val2017/000000039769.jpg\",\n             # RGBA\n-            dataset[0][\"image\"],\n+            self._dataset[0][\"image\"],\n             # LA\n-            dataset[1][\"image\"],\n+            self._dataset[1][\"image\"],\n             # L\n-            dataset[2][\"image\"],\n+            self._dataset[2][\"image\"],\n         ]\n         batch_outputs = object_detector(batch, threshold=0.0)\n "
        },
        {
            "sha": "3975921a84a16cc81cfa24f868391e796fdc3347",
            "filename": "utils/fetch_hub_objects_for_ci.py",
            "status": "added",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/35253076f4f8ef12630dcc3a9618221a2c0a4f40/utils%2Ffetch_hub_objects_for_ci.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/35253076f4f8ef12630dcc3a9618221a2c0a4f40/utils%2Ffetch_hub_objects_for_ci.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Ffetch_hub_objects_for_ci.py?ref=35253076f4f8ef12630dcc3a9618221a2c0a4f40",
            "patch": "@@ -0,0 +1,9 @@\n+from transformers.testing_utils import _run_pipeline_tests\n+\n+\n+if __name__ == \"__main__\":\n+    if _run_pipeline_tests:\n+        import datasets\n+\n+        _ = datasets.load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n+        _ = datasets.load_dataset(\"hf-internal-testing/fixtures_image_utils\", split=\"test\", revision=\"refs/pr/1\")"
        }
    ],
    "stats": {
        "total": 107,
        "additions": 69,
        "deletions": 38
    }
}