{
    "author": "ivarflakstad",
    "message": "Disable report callbacks for certain training tests (#38088)\n\n* Disable report callbacks for certain training tests\n\n* Disable report callbacks for test_auto_batch_size_finder",
    "sha": "e27d230ddde58ca4d040129135a31f9daddd455a",
    "files": [
        {
            "sha": "6708c484eb6f67338330b08276c06a8414f8af27",
            "filename": "tests/trainer/test_trainer.py",
            "status": "modified",
            "additions": 5,
            "deletions": 3,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/e27d230ddde58ca4d040129135a31f9daddd455a/tests%2Ftrainer%2Ftest_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e27d230ddde58ca4d040129135a31f9daddd455a/tests%2Ftrainer%2Ftest_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_trainer.py?ref=e27d230ddde58ca4d040129135a31f9daddd455a",
            "patch": "@@ -1368,6 +1368,7 @@ def test_torch_compile_loss_func_compatibility(self):\n             per_device_train_batch_size=2,\n             torch_compile=True,\n             max_steps=1,  # compile happens on the first step\n+            report_to=\"none\",\n         )\n         trainer = Trainer(model=tiny_llama, args=args, train_dataset=train_dataset)  # noqa\n         trainer.train()\n@@ -3300,6 +3301,7 @@ def test_auto_batch_size_finder(self):\n                 --num_train_epochs 1\n                 --output_dir {tmpdir}\n                 --auto_find_batch_size 0\n+                --report_to none\n                 \"\"\".split()\n             with self.assertRaises(RuntimeError):\n                 with patch.object(sys, \"argv\", testargs):\n@@ -4560,7 +4562,7 @@ def test_trainer_saves_image_processor(self):\n             config = RegressionModelConfig(a=1.5, b=2.5)\n             trainer = Trainer(\n                 model=RegressionPreTrainedModel(config),\n-                args=TrainingArguments(output_dir=tmp_dir),\n+                args=TrainingArguments(output_dir=tmp_dir, report_to=\"none\"),\n                 processing_class=image_processor,\n             )\n             trainer.save_model()\n@@ -4576,7 +4578,7 @@ def test_trainer_saves_feature_extractor(self):\n             config = RegressionModelConfig(a=1.5, b=2.5)\n             trainer = Trainer(\n                 model=RegressionPreTrainedModel(config),\n-                args=TrainingArguments(output_dir=tmp_dir),\n+                args=TrainingArguments(output_dir=tmp_dir, report_to=\"none\"),\n                 processing_class=feature_extractor,\n             )\n             trainer.save_model()\n@@ -4596,7 +4598,7 @@ def test_trainer_saves_processor(self):\n             config = RegressionModelConfig(a=1.5, b=2.5)\n             trainer = Trainer(\n                 model=RegressionPreTrainedModel(config),\n-                args=TrainingArguments(output_dir=tmp_dir),\n+                args=TrainingArguments(output_dir=tmp_dir, report_to=\"none\"),\n                 processing_class=processor,\n             )\n             trainer.save_model()"
        }
    ],
    "stats": {
        "total": 8,
        "additions": 5,
        "deletions": 3
    }
}