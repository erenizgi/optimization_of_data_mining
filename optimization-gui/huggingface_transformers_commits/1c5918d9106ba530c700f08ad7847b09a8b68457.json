{
    "author": "michaelbenayoun",
    "message": "Fix `torch.fx` issue related to the new `loss_kwargs` keyword argument (#34380)\n\n* Fix FX\r\n\r\n* Unskip tests",
    "sha": "1c5918d9106ba530c700f08ad7847b09a8b68457",
    "files": [
        {
            "sha": "3764f1ee4cef761fb39a9c6555442dca1b52977b",
            "filename": "src/transformers/utils/fx.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/1c5918d9106ba530c700f08ad7847b09a8b68457/src%2Ftransformers%2Futils%2Ffx.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1c5918d9106ba530c700f08ad7847b09a8b68457/src%2Ftransformers%2Futils%2Ffx.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Ffx.py?ref=1c5918d9106ba530c700f08ad7847b09a8b68457",
            "patch": "@@ -1416,7 +1416,7 @@ def keys(self, obj: \"Proxy\") -> Any:\n         your custom tracer.\n         \"\"\"\n         attribute = HFAttribute(obj, \"keys\")()\n-        if obj.node.target == \"**kwargs\":\n+        if obj.node.target.startswith(\"**\"):\n             return attribute._metadata\n         return attribute\n "
        },
        {
            "sha": "3a05867dfdfc8cd209341e169bb17eaf80cd5d15",
            "filename": "tests/models/cohere/test_modeling_cohere.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/1c5918d9106ba530c700f08ad7847b09a8b68457/tests%2Fmodels%2Fcohere%2Ftest_modeling_cohere.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1c5918d9106ba530c700f08ad7847b09a8b68457/tests%2Fmodels%2Fcohere%2Ftest_modeling_cohere.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fcohere%2Ftest_modeling_cohere.py?ref=1c5918d9106ba530c700f08ad7847b09a8b68457",
            "patch": "@@ -304,7 +304,6 @@ def test_model_various_embeddings(self):\n             config_and_inputs[0].position_embedding_type = type\n             self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    @unittest.skip(reason=\"PR #34283 made changes to the forward function.\")\n     def test_torch_fx_output_loss(self):\n         super().test_torch_fx_output_loss()\n "
        },
        {
            "sha": "600c4ffa14b0d0bb75ee7e613ad395f0297b8319",
            "filename": "tests/models/mistral/test_modeling_mistral.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/1c5918d9106ba530c700f08ad7847b09a8b68457/tests%2Fmodels%2Fmistral%2Ftest_modeling_mistral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1c5918d9106ba530c700f08ad7847b09a8b68457/tests%2Fmodels%2Fmistral%2Ftest_modeling_mistral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmistral%2Ftest_modeling_mistral.py?ref=1c5918d9106ba530c700f08ad7847b09a8b68457",
            "patch": "@@ -356,7 +356,6 @@ def test_model_various_embeddings(self):\n             config_and_inputs[0].position_embedding_type = type\n             self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    @unittest.skip(reason=\"PR #34283 made changes to the forward function.\")\n     def test_torch_fx_output_loss(self):\n         super().test_torch_fx_output_loss()\n "
        },
        {
            "sha": "0688435e81423cdc0e968f6ffee64abafa8211b8",
            "filename": "tests/models/mixtral/test_modeling_mixtral.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/1c5918d9106ba530c700f08ad7847b09a8b68457/tests%2Fmodels%2Fmixtral%2Ftest_modeling_mixtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1c5918d9106ba530c700f08ad7847b09a8b68457/tests%2Fmodels%2Fmixtral%2Ftest_modeling_mixtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmixtral%2Ftest_modeling_mixtral.py?ref=1c5918d9106ba530c700f08ad7847b09a8b68457",
            "patch": "@@ -356,7 +356,6 @@ def test_model_various_embeddings(self):\n             config_and_inputs[0].position_embedding_type = type\n             self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    @unittest.skip(reason=\"PR #34283 made changes to the forward function.\")\n     def test_torch_fx_output_loss(self):\n         super().test_torch_fx_output_loss()\n "
        },
        {
            "sha": "301937079ae694db620c53abee66343ed96dd74e",
            "filename": "tests/models/qwen2/test_modeling_qwen2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/1c5918d9106ba530c700f08ad7847b09a8b68457/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1c5918d9106ba530c700f08ad7847b09a8b68457/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py?ref=1c5918d9106ba530c700f08ad7847b09a8b68457",
            "patch": "@@ -368,7 +368,6 @@ def test_model_various_embeddings(self):\n             config_and_inputs[0].position_embedding_type = type\n             self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    @unittest.skip(reason=\"PR #34283 made changes to the forward function.\")\n     def test_torch_fx_output_loss(self):\n         super().test_torch_fx_output_loss()\n "
        },
        {
            "sha": "30d7996d7e7b0929e26d3ee82be9a72f48536f42",
            "filename": "tests/models/qwen2_moe/test_modeling_qwen2_moe.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/1c5918d9106ba530c700f08ad7847b09a8b68457/tests%2Fmodels%2Fqwen2_moe%2Ftest_modeling_qwen2_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1c5918d9106ba530c700f08ad7847b09a8b68457/tests%2Fmodels%2Fqwen2_moe%2Ftest_modeling_qwen2_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_moe%2Ftest_modeling_qwen2_moe.py?ref=1c5918d9106ba530c700f08ad7847b09a8b68457",
            "patch": "@@ -391,7 +391,6 @@ def test_model_various_embeddings(self):\n             config_and_inputs[0].position_embedding_type = type\n             self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    @unittest.skip(reason=\"PR #34283 made changes to the forward function.\")\n     def test_torch_fx_output_loss(self):\n         super().test_torch_fx_output_loss()\n "
        }
    ],
    "stats": {
        "total": 7,
        "additions": 1,
        "deletions": 6
    }
}