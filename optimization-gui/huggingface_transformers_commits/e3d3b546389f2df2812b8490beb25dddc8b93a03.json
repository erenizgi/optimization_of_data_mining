{
    "author": "BowenBao",
    "message": "Keep Quark loading through meta device (#37538)",
    "sha": "e3d3b546389f2df2812b8490beb25dddc8b93a03",
    "files": [
        {
            "sha": "b1ec6896be894e83da5a42620b3a9bb06a5f1435",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 6,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/e3d3b546389f2df2812b8490beb25dddc8b93a03/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e3d3b546389f2df2812b8490beb25dddc8b93a03/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=e3d3b546389f2df2812b8490beb25dddc8b93a03",
            "patch": "@@ -725,12 +725,11 @@ def _load_state_dict_into_meta_model(\n         device_map_regex = \"|\".join([re.escape(k) for k in sorted(device_map.keys(), reverse=True)])\n \n     is_quantized = hf_quantizer is not None\n-    is_hqq_or_bnb_or_quark = is_quantized and hf_quantizer.quantization_config.quant_method in {\n+    is_hqq_or_bnb = is_quantized and hf_quantizer.quantization_config.quant_method in {\n         QuantizationMethod.HQQ,\n         QuantizationMethod.BITS_AND_BYTES,\n-        QuantizationMethod.QUARK,\n     }\n-    is_meta_state_dict = shard_file.endswith(\".safetensors\") and not is_hqq_or_bnb_or_quark\n+    is_meta_state_dict = shard_file.endswith(\".safetensors\") and not is_hqq_or_bnb\n     file_pointer = None\n     if is_meta_state_dict:\n         file_pointer = safe_open(shard_file, framework=\"pt\", device=tensor_device)\n@@ -4701,10 +4700,9 @@ def _load_pretrained_model(\n             QuantizationMethod.HQQ,\n             QuantizationMethod.QUARK,\n         }\n-        is_hqq_or_bnb_or_quark = is_quantized and hf_quantizer.quantization_config.quant_method in {\n+        is_hqq_or_bnb = is_quantized and hf_quantizer.quantization_config.quant_method in {\n             QuantizationMethod.HQQ,\n             QuantizationMethod.BITS_AND_BYTES,\n-            QuantizationMethod.QUARK,\n         }\n \n         # Get all the keys of the state dicts that we have to initialize the model\n@@ -4881,7 +4879,7 @@ def _load_pretrained_model(\n             map_location = \"cpu\"\n             if (\n                 shard_file.endswith(\".safetensors\")\n-                and not is_hqq_or_bnb_or_quark\n+                and not is_hqq_or_bnb\n                 and not (is_deepspeed_zero3_enabled() and not is_quantized)\n             ):\n                 map_location = \"meta\""
        }
    ],
    "stats": {
        "total": 10,
        "additions": 4,
        "deletions": 6
    }
}