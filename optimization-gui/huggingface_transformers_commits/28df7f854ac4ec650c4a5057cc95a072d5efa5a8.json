{
    "author": "Isotr0py",
    "message": "Fix multimodal processor get duplicate arguments when receive kwargs for initialization (#39125)\n\n* fix processor tokenizer override\n\nSigned-off-by: Isotr0py <2037008807@qq.com>\n\n* code format\n\nSigned-off-by: Isotr0py <2037008807@qq.com>\n\n* add regression test\n\nSigned-off-by: Isotr0py <2037008807@qq.com>\n\n* fix\n\nSigned-off-by: Isotr0py <2037008807@qq.com>\n\n* check image processor same\n\nSigned-off-by: Isotr0py <2037008807@qq.com>\n\n---------\n\nSigned-off-by: Isotr0py <2037008807@qq.com>",
    "sha": "28df7f854ac4ec650c4a5057cc95a072d5efa5a8",
    "files": [
        {
            "sha": "9dd9d9ce008604a45f50b89eb7c7e5b36ad44049",
            "filename": "src/transformers/processing_utils.py",
            "status": "modified",
            "additions": 7,
            "deletions": 3,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/28df7f854ac4ec650c4a5057cc95a072d5efa5a8/src%2Ftransformers%2Fprocessing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28df7f854ac4ec650c4a5057cc95a072d5efa5a8/src%2Ftransformers%2Fprocessing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fprocessing_utils.py?ref=28df7f854ac4ec650c4a5057cc95a072d5efa5a8",
            "patch": "@@ -1097,9 +1097,13 @@ def from_args_and_dict(cls, args, processor_dict: dict[str, Any], **kwargs):\n             processor_config=processor_dict, valid_kwargs=accepted_args_and_kwargs\n         )\n \n-        # remove args that are in processor_dict to avoid duplicate arguments\n-        args_to_remove = [i for i, arg in enumerate(accepted_args_and_kwargs) if arg in processor_dict]\n-        args = [arg for i, arg in enumerate(args) if i not in args_to_remove]\n+        # update args that are already in processor_dict to avoid duplicate arguments\n+        args_to_update = {\n+            i: valid_kwargs.pop(arg)\n+            for i, arg in enumerate(accepted_args_and_kwargs)\n+            if (arg in valid_kwargs and i < len(args))\n+        }\n+        args = [arg if i not in args_to_update else args_to_update[i] for i, arg in enumerate(args)]\n \n         # instantiate processor with used (and valid) kwargs only\n         processor = cls(*args, **valid_kwargs)"
        },
        {
            "sha": "855bcaaf27ad4db4b5a4e462be67deb83fc3e097",
            "filename": "tests/test_processing_common.py",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/28df7f854ac4ec650c4a5057cc95a072d5efa5a8/tests%2Ftest_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28df7f854ac4ec650c4a5057cc95a072d5efa5a8/tests%2Ftest_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_processing_common.py?ref=28df7f854ac4ec650c4a5057cc95a072d5efa5a8",
            "patch": "@@ -351,6 +351,18 @@ def test_doubly_passed_kwargs(self):\n                 return_tensors=\"pt\",\n             )\n \n+    def test_args_overlap_kwargs(self):\n+        if \"image_processor\" not in self.processor_class.attributes:\n+            self.skipTest(f\"image_processor attribute not present in {self.processor_class}\")\n+        processor_first = self.get_processor()\n+        image_processor = processor_first.image_processor\n+        image_processor.is_override = True\n+\n+        with tempfile.TemporaryDirectory() as tmpdirname:\n+            processor_first.save_pretrained(tmpdirname)\n+            processor_second = self.processor_class.from_pretrained(tmpdirname, image_processor=image_processor)\n+            self.assertTrue(processor_second.image_processor.is_override)\n+\n     def test_structured_kwargs_nested(self):\n         if \"image_processor\" not in self.processor_class.attributes:\n             self.skipTest(f\"image_processor attribute not present in {self.processor_class}\")"
        }
    ],
    "stats": {
        "total": 22,
        "additions": 19,
        "deletions": 3
    }
}