{
    "author": "Rocketknight1",
    "message": ":rotating_light: :rotating_light: Setup -> setupclass conversion (#37282)\n\n* More limited setup -> setupclass conversion\n\n* make fixup\n\n* Trigger tests\n\n* Fixup UDOP\n\n* Missed a spot\n\n* tearDown -> tearDownClass where appropriate\n\n* Couple more class fixes\n\n* Fixups for UDOP and VisionTextDualEncoder\n\n* Ignore errors when removing the tmpdir, in case it already got cleaned up somewhere\n\n* CLIP fixes\n\n* More correct classmethods\n\n* Wav2Vec2Bert fixes\n\n* More methods become static\n\n* More class methods\n\n* More class methods\n\n* Revert changes for integration tests / modeling files\n\n* Use a different tempdir for tests that actually write to it\n\n* Remove addClassCleanup and just use teardownclass\n\n* Remove changes in modeling files\n\n* Cleanup get_processor_dict() for got_ocr2\n\n* Fix regression on Wav2Vec2BERT test that was masked by this before\n\n* Rework tests that modify the tmpdir\n\n* make fix-copies\n\n* revert clvp modeling test changes\n\n* Fix CLIP processor test\n\n* make fix-copies",
    "sha": "4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
    "files": [
        {
            "sha": "f498ce4aa87c23e950c46ade5ddd5c56717f67cb",
            "filename": "tests/models/altclip/test_processor_altclip.py",
            "status": "modified",
            "additions": 7,
            "deletions": 6,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Faltclip%2Ftest_processor_altclip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Faltclip%2Ftest_processor_altclip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faltclip%2Ftest_processor_altclip.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -26,15 +26,16 @@\n class AltClipProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = AltCLIPProcessor\n \n-    def setUp(self):\n-        self.model_id = \"BAAI/AltCLIP\"\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.model_id = \"BAAI/AltCLIP\"\n+        cls.tmpdirname = tempfile.mkdtemp()\n         image_processor = CLIPImageProcessor()\n-        tokenizer = XLMRobertaTokenizer.from_pretrained(self.model_id)\n+        tokenizer = XLMRobertaTokenizer.from_pretrained(cls.model_id)\n \n-        processor = self.processor_class(image_processor, tokenizer)\n+        processor = cls.processor_class(image_processor, tokenizer)\n \n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return XLMRobertaTokenizer.from_pretrained(self.model_id, **kwargs)"
        },
        {
            "sha": "836563e109d1cae0e77dd063843080465302b2b1",
            "filename": "tests/models/aria/test_processor_aria.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Faria%2Ftest_processor_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Faria%2Ftest_processor_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faria%2Ftest_processor_aria.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -87,7 +87,7 @@ def get_processor(self, **kwargs):\n \n     @classmethod\n     def tearDownClass(cls):\n-        shutil.rmtree(cls.tmpdirname)\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_kwargs_overrides_default_image_processor_kwargs(self):\n         if \"image_processor\" not in self.processor_class.attributes:"
        },
        {
            "sha": "7e6e080b717d2c9a4bb59de5e000925932e42d42",
            "filename": "tests/models/aya_vision/test_processor_aya_vision.py",
            "status": "modified",
            "additions": 10,
            "deletions": 7,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Faya_vision%2Ftest_processor_aya_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Faya_vision%2Ftest_processor_aya_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faya_vision%2Ftest_processor_aya_vision.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -37,8 +37,9 @@\n class AyaVisionProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = AyaVisionProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         image_processor = GotOcr2ImageProcessor(\n             do_resize=True,\n@@ -52,16 +53,17 @@ def setUp(self):\n             do_convert_rgb=True,\n         )\n         tokenizer = AutoTokenizer.from_pretrained(\"CohereForAI/aya-vision-8b\", padding_side=\"left\")\n-        processor_kwargs = self.prepare_processor_dict()\n+        processor_kwargs = cls.prepare_processor_dict()\n         processor = AyaVisionProcessor.from_pretrained(\n             \"CohereForAI/aya-vision-8b\",\n             image_processor=image_processor,\n             tokenizer=tokenizer,\n             **processor_kwargs,\n         )\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-    def prepare_processor_dict(self):\n+    @staticmethod\n+    def prepare_processor_dict():\n         return {\"patch_size\": 10, \"img_size\": 20}\n \n     def get_tokenizer(self, **kwargs):\n@@ -73,8 +75,9 @@ def get_image_processor(self, **kwargs):\n     def get_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     # todo: yoni, fix this test\n     @unittest.skip(\"Chat template has long system prompt\")"
        },
        {
            "sha": "6ff81e991a1ff69f8a9f4b0c23c618180528c88f",
            "filename": "tests/models/blip/test_processor_blip.py",
            "status": "modified",
            "additions": 15,
            "deletions": 12,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fblip%2Ftest_processor_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fblip%2Ftest_processor_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fblip%2Ftest_processor_blip.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -31,35 +31,38 @@\n class BlipProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = BlipProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         image_processor = BlipImageProcessor()\n         tokenizer = BertTokenizer.from_pretrained(\"hf-internal-testing/tiny-random-BertModel\")\n \n         processor = BlipProcessor(image_processor, tokenizer)\n \n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n \n     def get_image_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).image_processor\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = BlipProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n-        processor.save_pretrained(self.tmpdirname)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = BlipProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n+            processor.save_pretrained(tmpdir)\n \n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n+            tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n \n-        processor = BlipProcessor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+            processor = BlipProcessor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, PreTrainedTokenizerFast)"
        },
        {
            "sha": "5d125dc57e959dd4c1174706d9909fa4667d9379",
            "filename": "tests/models/blip_2/test_processor_blip_2.py",
            "status": "modified",
            "additions": 15,
            "deletions": 12,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fblip_2%2Ftest_processor_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fblip_2%2Ftest_processor_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fblip_2%2Ftest_processor_blip_2.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -31,35 +31,38 @@\n class Blip2ProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = Blip2Processor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         image_processor = BlipImageProcessor()\n         tokenizer = GPT2Tokenizer.from_pretrained(\"hf-internal-testing/tiny-random-GPT2Model\")\n \n         processor = Blip2Processor(image_processor, tokenizer)\n \n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n \n     def get_image_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).image_processor\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = Blip2Processor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n-        processor.save_pretrained(self.tmpdirname)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = Blip2Processor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n+            processor.save_pretrained(tmpdir)\n \n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n+            tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n \n-        processor = Blip2Processor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+            processor = Blip2Processor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, PreTrainedTokenizerFast)"
        },
        {
            "sha": "4b3bb0716fa466a521fa68afc6501ac86210fe0b",
            "filename": "tests/models/bridgetower/test_processor_bridgetower.py",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fbridgetower%2Ftest_processor_bridgetower.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fbridgetower%2Ftest_processor_bridgetower.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbridgetower%2Ftest_processor_bridgetower.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -34,24 +34,26 @@\n class BridgeTowerProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = BridgeTowerProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         image_processor = BridgeTowerImageProcessor()\n         tokenizer = RobertaTokenizerFast.from_pretrained(\"BridgeTower/bridgetower-large-itm-mlm-itc\")\n \n         processor = BridgeTowerProcessor(image_processor, tokenizer)\n \n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n \n     def get_image_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).image_processor\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     # Some kwargs tests are overriden from common tests to handle shortest_edge\n     # and size_divisor behaviour"
        },
        {
            "sha": "2256d1cb0cb5a63c9bba4000193d283e2312d814",
            "filename": "tests/models/chameleon/test_processor_chameleon.py",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fchameleon%2Ftest_processor_chameleon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fchameleon%2Ftest_processor_chameleon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fchameleon%2Ftest_processor_chameleon.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -33,11 +33,12 @@\n class ChameleonProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = ChameleonProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n         image_processor = ChameleonImageProcessor()\n         tokenizer = LlamaTokenizer(vocab_file=SAMPLE_VOCAB)\n         tokenizer.pad_token_id = 0\n         tokenizer.sep_token_id = 1\n-        processor = self.processor_class(image_processor=image_processor, tokenizer=tokenizer)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor = cls.processor_class(image_processor=image_processor, tokenizer=tokenizer)\n+        processor.save_pretrained(cls.tmpdirname)"
        },
        {
            "sha": "3c2a2247c5a2194f3d4a914ebdd3426f79eab70d",
            "filename": "tests/models/chinese_clip/test_processor_chinese_clip.py",
            "status": "modified",
            "additions": 41,
            "deletions": 32,
            "changes": 73,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fchinese_clip%2Ftest_processor_chinese_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fchinese_clip%2Ftest_processor_chinese_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fchinese_clip%2Ftest_processor_chinese_clip.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -36,8 +36,9 @@\n class ChineseCLIPProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = ChineseCLIPProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         vocab_tokens = [\n             \"[UNK]\",\n@@ -59,8 +60,8 @@ def setUp(self):\n             \"t\",\n             \"shirt\",\n         ]\n-        self.vocab_file = os.path.join(self.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n-        with open(self.vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n+        cls.vocab_file = os.path.join(cls.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n+        with open(cls.vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n             vocab_writer.write(\"\".join([x + \"\\n\" for x in vocab_tokens]))\n \n         image_processor_map = {\n@@ -73,39 +74,44 @@ def setUp(self):\n             \"image_std\": [0.26862954, 0.26130258, 0.27577711],\n             \"do_convert_rgb\": True,\n         }\n-        self.image_processor_file = os.path.join(self.tmpdirname, FEATURE_EXTRACTOR_NAME)\n-        with open(self.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n+        cls.image_processor_file = os.path.join(cls.tmpdirname, FEATURE_EXTRACTOR_NAME)\n+        with open(cls.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n             json.dump(image_processor_map, fp)\n \n-        tokenizer = self.get_tokenizer()\n-        image_processor = self.get_image_processor()\n+        tokenizer = cls.get_tokenizer()\n+        image_processor = cls.get_image_processor()\n         processor = ChineseCLIPProcessor(tokenizer=tokenizer, image_processor=image_processor)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-    def get_tokenizer(self, **kwargs):\n-        return BertTokenizer.from_pretrained(self.tmpdirname, **kwargs)\n+    @classmethod\n+    def get_tokenizer(cls, **kwargs):\n+        return BertTokenizer.from_pretrained(cls.tmpdirname, **kwargs)\n \n-    def get_rust_tokenizer(self, **kwargs):\n-        return BertTokenizerFast.from_pretrained(self.tmpdirname, **kwargs)\n+    @classmethod\n+    def get_rust_tokenizer(cls, **kwargs):\n+        return BertTokenizerFast.from_pretrained(cls.tmpdirname, **kwargs)\n \n-    def get_image_processor(self, **kwargs):\n-        return ChineseCLIPImageProcessor.from_pretrained(self.tmpdirname, **kwargs)\n+    @classmethod\n+    def get_image_processor(cls, **kwargs):\n+        return ChineseCLIPImageProcessor.from_pretrained(cls.tmpdirname, **kwargs)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_default(self):\n         tokenizer_slow = self.get_tokenizer()\n         tokenizer_fast = self.get_rust_tokenizer()\n         image_processor = self.get_image_processor()\n \n-        processor_slow = ChineseCLIPProcessor(tokenizer=tokenizer_slow, image_processor=image_processor)\n-        processor_slow.save_pretrained(self.tmpdirname)\n-        processor_slow = ChineseCLIPProcessor.from_pretrained(self.tmpdirname, use_fast=False)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor_slow = ChineseCLIPProcessor(tokenizer=tokenizer_slow, image_processor=image_processor)\n+            processor_slow.save_pretrained(tmpdir)\n+            processor_slow = ChineseCLIPProcessor.from_pretrained(self.tmpdirname, use_fast=False)\n \n-        processor_fast = ChineseCLIPProcessor(tokenizer=tokenizer_fast, image_processor=image_processor)\n-        processor_fast.save_pretrained(self.tmpdirname)\n-        processor_fast = ChineseCLIPProcessor.from_pretrained(self.tmpdirname)\n+            processor_fast = ChineseCLIPProcessor(tokenizer=tokenizer_fast, image_processor=image_processor)\n+            processor_fast.save_pretrained(tmpdir)\n+            processor_fast = ChineseCLIPProcessor.from_pretrained(self.tmpdirname)\n \n         self.assertEqual(processor_slow.tokenizer.get_vocab(), tokenizer_slow.get_vocab())\n         self.assertEqual(processor_fast.tokenizer.get_vocab(), tokenizer_fast.get_vocab())\n@@ -119,15 +125,18 @@ def test_save_load_pretrained_default(self):\n         self.assertIsInstance(processor_fast.image_processor, ChineseCLIPImageProcessor)\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = ChineseCLIPProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n-        processor.save_pretrained(self.tmpdirname)\n-\n-        tokenizer_add_kwargs = self.get_tokenizer(cls_token=\"(CLS)\", sep_token=\"(SEP)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False)\n-\n-        processor = ChineseCLIPProcessor.from_pretrained(\n-            self.tmpdirname, cls_token=\"(CLS)\", sep_token=\"(SEP)\", do_normalize=False\n-        )\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = ChineseCLIPProcessor(\n+                tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor()\n+            )\n+            processor.save_pretrained(tmpdir)\n+\n+            tokenizer_add_kwargs = self.get_tokenizer(cls_token=\"(CLS)\", sep_token=\"(SEP)\")\n+            image_processor_add_kwargs = self.get_image_processor(do_normalize=False)\n+\n+            processor = ChineseCLIPProcessor.from_pretrained(\n+                tmpdir, cls_token=\"(CLS)\", sep_token=\"(SEP)\", do_normalize=False\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, BertTokenizerFast)"
        },
        {
            "sha": "1b6eed7534885034a99ceba28c1e50d1bc1b31d7",
            "filename": "tests/models/clip/test_processor_clip.py",
            "status": "modified",
            "additions": 41,
            "deletions": 32,
            "changes": 73,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fclip%2Ftest_processor_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fclip%2Ftest_processor_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fclip%2Ftest_processor_clip.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -36,19 +36,20 @@\n class CLIPProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = CLIPProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         vocab = [\"l\", \"o\", \"w\", \"e\", \"r\", \"s\", \"t\", \"i\", \"d\", \"n\", \"lo\", \"l</w>\", \"w</w>\", \"r</w>\", \"t</w>\", \"low</w>\", \"er</w>\", \"lowest</w>\", \"newer</w>\", \"wider\", \"<unk>\", \"<|startoftext|>\", \"<|endoftext|>\"]  # fmt: skip\n         vocab_tokens = dict(zip(vocab, range(len(vocab))))\n         merges = [\"#version: 0.2\", \"l o\", \"lo w</w>\", \"e r</w>\", \"\"]\n-        self.special_tokens_map = {\"unk_token\": \"<unk>\"}\n+        cls.special_tokens_map = {\"unk_token\": \"<unk>\"}\n \n-        self.vocab_file = os.path.join(self.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n-        self.merges_file = os.path.join(self.tmpdirname, VOCAB_FILES_NAMES[\"merges_file\"])\n-        with open(self.vocab_file, \"w\", encoding=\"utf-8\") as fp:\n+        cls.vocab_file = os.path.join(cls.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n+        cls.merges_file = os.path.join(cls.tmpdirname, VOCAB_FILES_NAMES[\"merges_file\"])\n+        with open(cls.vocab_file, \"w\", encoding=\"utf-8\") as fp:\n             fp.write(json.dumps(vocab_tokens) + \"\\n\")\n-        with open(self.merges_file, \"w\", encoding=\"utf-8\") as fp:\n+        with open(cls.merges_file, \"w\", encoding=\"utf-8\") as fp:\n             fp.write(\"\\n\".join(merges))\n \n         image_processor_map = {\n@@ -60,34 +61,39 @@ def setUp(self):\n             \"image_mean\": [0.48145466, 0.4578275, 0.40821073],\n             \"image_std\": [0.26862954, 0.26130258, 0.27577711],\n         }\n-        self.image_processor_file = os.path.join(self.tmpdirname, IMAGE_PROCESSOR_NAME)\n-        with open(self.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n+        cls.image_processor_file = os.path.join(cls.tmpdirname, IMAGE_PROCESSOR_NAME)\n+        with open(cls.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n             json.dump(image_processor_map, fp)\n \n-    def get_tokenizer(self, **kwargs):\n-        return CLIPTokenizer.from_pretrained(self.tmpdirname, **kwargs)\n+    @classmethod\n+    def get_tokenizer(cls, **kwargs):\n+        return CLIPTokenizer.from_pretrained(cls.tmpdirname, **kwargs)\n \n-    def get_rust_tokenizer(self, **kwargs):\n-        return CLIPTokenizerFast.from_pretrained(self.tmpdirname, **kwargs)\n+    @classmethod\n+    def get_rust_tokenizer(cls, **kwargs):\n+        return CLIPTokenizerFast.from_pretrained(cls.tmpdirname, **kwargs)\n \n-    def get_image_processor(self, **kwargs):\n-        return CLIPImageProcessor.from_pretrained(self.tmpdirname, **kwargs)\n+    @classmethod\n+    def get_image_processor(cls, **kwargs):\n+        return CLIPImageProcessor.from_pretrained(cls.tmpdirname, **kwargs)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname)\n \n     def test_save_load_pretrained_default(self):\n         tokenizer_slow = self.get_tokenizer()\n         tokenizer_fast = self.get_rust_tokenizer()\n         image_processor = self.get_image_processor()\n \n-        processor_slow = CLIPProcessor(tokenizer=tokenizer_slow, image_processor=image_processor)\n-        processor_slow.save_pretrained(self.tmpdirname)\n-        processor_slow = CLIPProcessor.from_pretrained(self.tmpdirname, use_fast=False)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor_slow = CLIPProcessor(tokenizer=tokenizer_slow, image_processor=image_processor)\n+            processor_slow.save_pretrained(tmpdir)\n+            processor_slow = CLIPProcessor.from_pretrained(tmpdir, use_fast=False)\n \n-        processor_fast = CLIPProcessor(tokenizer=tokenizer_fast, image_processor=image_processor)\n-        processor_fast.save_pretrained(self.tmpdirname)\n-        processor_fast = CLIPProcessor.from_pretrained(self.tmpdirname)\n+            processor_fast = CLIPProcessor(tokenizer=tokenizer_fast, image_processor=image_processor)\n+            processor_fast.save_pretrained(tmpdir)\n+            processor_fast = CLIPProcessor.from_pretrained(tmpdir)\n \n         self.assertEqual(processor_slow.tokenizer.get_vocab(), tokenizer_slow.get_vocab())\n         self.assertEqual(processor_fast.tokenizer.get_vocab(), tokenizer_fast.get_vocab())\n@@ -101,15 +107,18 @@ def test_save_load_pretrained_default(self):\n         self.assertIsInstance(processor_fast.image_processor, CLIPImageProcessor)\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = CLIPProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n-        processor.save_pretrained(self.tmpdirname)\n-\n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n-\n-        processor = CLIPProcessor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = CLIPProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n+            processor.save_pretrained(tmpdir)\n+\n+            tokenizer_add_kwargs = CLIPTokenizer.from_pretrained(tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = CLIPImageProcessor.from_pretrained(\n+                tmpdir, do_normalize=False, padding_value=1.0\n+            )\n+\n+            processor = CLIPProcessor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, CLIPTokenizerFast)"
        },
        {
            "sha": "709b5cf079400b43e804bc4547500bc3978b731d",
            "filename": "tests/models/colpali/test_processing_colpali.py",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fcolpali%2Ftest_processing_colpali.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fcolpali%2Ftest_processing_colpali.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fcolpali%2Ftest_processing_colpali.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -27,16 +27,18 @@\n class ColPaliProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = ColPaliProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n         image_processor = SiglipImageProcessor.from_pretrained(\"google/siglip-so400m-patch14-384\")\n         image_processor.image_seq_length = 0\n         tokenizer = GemmaTokenizer(SAMPLE_VOCAB, keep_accents=True)\n         processor = PaliGemmaProcessor(image_processor=image_processor, tokenizer=tokenizer)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     @require_torch\n     @require_vision"
        },
        {
            "sha": "272f1fd823414885ecf1e3fdfb7a8f63c476a08b",
            "filename": "tests/models/donut/test_processor_donut.py",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fdonut%2Ftest_processor_donut.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fdonut%2Ftest_processor_donut.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdonut%2Ftest_processor_donut.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -25,16 +25,17 @@ class DonutProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     from_pretrained_id = \"naver-clova-ix/donut-base\"\n     processor_class = DonutProcessor\n \n-    def setUp(self):\n-        self.processor = DonutProcessor.from_pretrained(self.from_pretrained_id)\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.processor = DonutProcessor.from_pretrained(cls.from_pretrained_id)\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         image_processor = DonutImageProcessor()\n-        tokenizer = XLMRobertaTokenizerFast.from_pretrained(self.from_pretrained_id)\n+        tokenizer = XLMRobertaTokenizerFast.from_pretrained(cls.from_pretrained_id)\n \n         processor = DonutProcessor(image_processor, tokenizer)\n \n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def test_token2json(self):\n         expected_json = {"
        },
        {
            "sha": "90696b17b4b0241208605fab02167925b08fa657",
            "filename": "tests/models/emu3/test_processor_emu3.py",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Femu3%2Ftest_processor_emu3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Femu3%2Ftest_processor_emu3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Femu3%2Ftest_processor_emu3.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -31,8 +31,9 @@\n class Emu3ProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = Emu3Processor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n         image_processor = Emu3ImageProcessor()\n         extra_special_tokens = extra_special_tokens = {\n             \"image_token\": \"<image>\",\n@@ -46,10 +47,10 @@ def setUp(self):\n         )\n         tokenizer.pad_token_id = 0\n         tokenizer.sep_token_id = 1\n-        processor = self.processor_class(\n+        processor = cls.processor_class(\n             image_processor=image_processor, tokenizer=tokenizer, chat_template=\"dummy_template\"\n         )\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def prepare_processor_dict(self):\n         return {"
        },
        {
            "sha": "763e283670bfcd1d181f2b510ec5081948e94565",
            "filename": "tests/models/fuyu/test_processor_fuyu.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Ffuyu%2Ftest_processor_fuyu.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Ffuyu%2Ftest_processor_fuyu.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ffuyu%2Ftest_processor_fuyu.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -36,8 +36,6 @@ class FuyuProcessingTest(ProcessorTesterMixin, unittest.TestCase):\n     @classmethod\n     def setUpClass(cls):\n         cls.tmpdirname = tempfile.mkdtemp()\n-        # Ensure tempdir is cleaned up even if there's a failure\n-        cls.addClassCleanup(lambda tempdir=cls.tmpdirname: rmtree(tempdir))\n \n         image_processor = FuyuImageProcessor()\n         tokenizer = AutoTokenizer.from_pretrained(\"adept/fuyu-8b\")\n@@ -49,6 +47,10 @@ def setUpClass(cls):\n         bus_image_url = \"https://huggingface.co/datasets/hf-internal-testing/fixtures-captioning/resolve/main/bus.png\"\n         cls.bus_image_pil = Image.open(io.BytesIO(requests.get(bus_image_url).content))\n \n+    @classmethod\n+    def tearDownClass(cls):\n+        rmtree(cls.tmpdirname)\n+\n     def get_processor(self):\n         image_processor = FuyuImageProcessor()\n         tokenizer = AutoTokenizer.from_pretrained(\"adept/fuyu-8b\")"
        },
        {
            "sha": "e583ca6db20becc9a503862d20f267f7afebff2a",
            "filename": "tests/models/gemma3/test_processing_gemma3.py",
            "status": "modified",
            "additions": 10,
            "deletions": 7,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fgemma3%2Ftest_processing_gemma3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fgemma3%2Ftest_processing_gemma3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgemma3%2Ftest_processing_gemma3.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -34,8 +34,9 @@\n class Gemma3ProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = Gemma3Processor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n         gemma3_image_processor_kwargs = {\n             \"do_pan_and_scan\": True,\n             \"pan_and_scan_min_crop_size\": 256,\n@@ -52,15 +53,17 @@ def setUp(self):\n             \"eoi_token\": \"<end_of_image>\",\n         }\n         tokenizer = GemmaTokenizer(SAMPLE_VOCAB, keep_accents=True, extra_special_tokens=extra_special_tokens)\n-        processor_kwargs = self.prepare_processor_dict()\n+        processor_kwargs = cls.prepare_processor_dict()\n         processor = Gemma3Processor(image_processor=image_processor, tokenizer=tokenizer, **processor_kwargs)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     # TODO: raushan or arthur: add the real chat template\n-    def prepare_processor_dict(self):\n+    @staticmethod\n+    def prepare_processor_dict():\n         return {\n             \"chat_template\": \"{{ bos_token }}\\n{%- if messages[0]['role'] == 'system' -%}\\n    {%- set first_user_prefix = messages[0]['content'][0]['text'] + '\\n\\n' -%}\\n    {%- set loop_messages = messages[1:] -%}\\n{%- else -%}\\n    {%- set first_user_prefix = \\\"\\\" -%}\\n    {%- set loop_messages = messages -%}\\n{%- endif -%}\\n{%- for message in loop_messages -%}\\n    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) -%}\\n        {{ raise_exception(\\\"Conversation roles must alternate user/assistant/user/assistant/...\\\") }}\\n    {%- endif -%}\\n    {%- if (message['role'] == 'assistant') -%}\\n        {%- set role = \\\"model\\\" -%}\\n    {%- else -%}\\n        {%- set role = message['role'] -%}\\n    {%- endif -%}\\n    {{ '<start_of_turn>' + role + '\\n' + (first_user_prefix if loop.first else \\\"\\\") }}\\n    {%- if message['content'] is string -%}\\n        {{ message['content'] | trim }}\\n    {%- elif message['content'] is iterable -%}\\n        {%- for item in message['content'] -%}\\n            {%- if item['type'] == 'image' -%}\\n                {{ '<start_of_image>' }}\\n            {%- elif item['type'] == 'text' -%}\\n                {{ item['text'] | trim }}\\n            {%- endif -%}\\n        {%- endfor -%}\\n    {%- else -%}\\n        {{ raise_exception(\\\"Invalid content type\\\") }}\\n    {%- endif -%}\\n    {{ '<end_of_turn>\\n' }}\\n{%- endfor -%}\\n{%- if add_generation_prompt -%}\\n    {{'<start_of_turn>model\\n'}}\\n{%- endif -%}\\n\",            \"image_seq_length\": 3,\n         }  # fmt: skip"
        },
        {
            "sha": "c15301a5875ac3a2df226d86fece3f975b2802c0",
            "filename": "tests/models/git/test_processor_git.py",
            "status": "modified",
            "additions": 15,
            "deletions": 12,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fgit%2Ftest_processor_git.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fgit%2Ftest_processor_git.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgit%2Ftest_processor_git.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -31,8 +31,9 @@\n class GitProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = GitProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         image_processor = CLIPImageProcessor()\n         tokenizer = BertTokenizer.from_pretrained(\n@@ -41,27 +42,29 @@ def setUp(self):\n \n         processor = GitProcessor(image_processor, tokenizer)\n \n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n \n     def get_image_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).image_processor\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = GitProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n-        processor.save_pretrained(self.tmpdirname)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = GitProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n+            processor.save_pretrained(tmpdir)\n \n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n+            tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n \n-        processor = GitProcessor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+            processor = GitProcessor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, PreTrainedTokenizerFast)"
        },
        {
            "sha": "3e7e7cb054a8731c66459b18ea2d66d59a25ed26",
            "filename": "tests/models/got_ocr2/test_processor_got_ocr2.py",
            "status": "modified",
            "additions": 8,
            "deletions": 6,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fgot_ocr2%2Ftest_processor_got_ocr2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fgot_ocr2%2Ftest_processor_got_ocr2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgot_ocr2%2Ftest_processor_got_ocr2.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -31,23 +31,25 @@\n class GotOcr2ProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = GotOcr2Processor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         image_processor = GotOcr2ImageProcessor()\n         tokenizer = PreTrainedTokenizerFast.from_pretrained(\"stepfun-ai/GOT-OCR-2.0-hf\")\n-        processor_kwargs = self.prepare_processor_dict()\n+        processor_kwargs = {}\n         processor = GotOcr2Processor(image_processor, tokenizer, **processor_kwargs)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n \n     def get_image_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).image_processor\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_ocr_queries(self):\n         processor = self.get_processor()"
        },
        {
            "sha": "0b0174de45b7a67aa7454351955407609f0a9f09",
            "filename": "tests/models/grounding_dino/test_processor_grounding_dino.py",
            "status": "modified",
            "additions": 46,
            "deletions": 36,
            "changes": 82,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fgrounding_dino%2Ftest_processor_grounding_dino.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fgrounding_dino%2Ftest_processor_grounding_dino.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgrounding_dino%2Ftest_processor_grounding_dino.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -44,12 +44,13 @@ class GroundingDinoProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     from_pretrained_id = \"IDEA-Research/grounding-dino-base\"\n     processor_class = GroundingDinoProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         vocab_tokens = [\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[PAD]\",\"[MASK]\",\"want\",\"##want\",\"##ed\",\"wa\",\"un\",\"runn\",\"##ing\",\",\",\"low\",\"lowest\"]  # fmt: skip\n-        self.vocab_file = os.path.join(self.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n-        with open(self.vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n+        cls.vocab_file = os.path.join(cls.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n+        with open(cls.vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n             vocab_writer.write(\"\".join([x + \"\\n\" for x in vocab_tokens]))\n \n         image_processor_map = {\n@@ -62,21 +63,21 @@ def setUp(self):\n             \"rescale_factor\": 1 / 255,\n             \"do_pad\": True,\n         }\n-        self.image_processor_file = os.path.join(self.tmpdirname, IMAGE_PROCESSOR_NAME)\n-        with open(self.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n+        cls.image_processor_file = os.path.join(cls.tmpdirname, IMAGE_PROCESSOR_NAME)\n+        with open(cls.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n             json.dump(image_processor_map, fp)\n \n         image_processor = GroundingDinoImageProcessor()\n-        tokenizer = BertTokenizer.from_pretrained(self.from_pretrained_id)\n+        tokenizer = BertTokenizer.from_pretrained(cls.from_pretrained_id)\n \n         processor = GroundingDinoProcessor(image_processor, tokenizer)\n \n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-        self.batch_size = 7\n-        self.num_queries = 5\n-        self.embed_dim = 5\n-        self.seq_length = 5\n+        cls.batch_size = 7\n+        cls.num_queries = 5\n+        cls.embed_dim = 5\n+        cls.seq_length = 5\n \n     def prepare_text_inputs(self, batch_size: Optional[int] = None):\n         labels = [\"a cat\", \"remote control\"]\n@@ -92,21 +93,24 @@ def prepare_text_inputs(self, batch_size: Optional[int] = None):\n             return [labels]\n         return [labels, labels_longer] + [labels] * (batch_size - 2)\n \n+    @classmethod\n     # Copied from tests.models.clip.test_processor_clip.CLIPProcessorTest.get_tokenizer with CLIP->Bert\n-    def get_tokenizer(self, **kwargs):\n-        return BertTokenizer.from_pretrained(self.tmpdirname, **kwargs)\n+    def get_tokenizer(cls, **kwargs):\n+        return BertTokenizer.from_pretrained(cls.tmpdirname, **kwargs)\n \n+    @classmethod\n     # Copied from tests.models.clip.test_processor_clip.CLIPProcessorTest.get_rust_tokenizer with CLIP->Bert\n-    def get_rust_tokenizer(self, **kwargs):\n-        return BertTokenizerFast.from_pretrained(self.tmpdirname, **kwargs)\n+    def get_rust_tokenizer(cls, **kwargs):\n+        return BertTokenizerFast.from_pretrained(cls.tmpdirname, **kwargs)\n \n+    @classmethod\n     # Copied from tests.models.clip.test_processor_clip.CLIPProcessorTest.get_image_processor with CLIP->GroundingDino\n-    def get_image_processor(self, **kwargs):\n-        return GroundingDinoImageProcessor.from_pretrained(self.tmpdirname, **kwargs)\n+    def get_image_processor(cls, **kwargs):\n+        return GroundingDinoImageProcessor.from_pretrained(cls.tmpdirname, **kwargs)\n \n-    # Copied from tests.models.clip.test_processor_clip.CLIPProcessorTest.tearDown\n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def get_fake_grounding_dino_output(self):\n         torch.manual_seed(42)\n@@ -147,13 +151,14 @@ def test_save_load_pretrained_default(self):\n         tokenizer_fast = self.get_rust_tokenizer()\n         image_processor = self.get_image_processor()\n \n-        processor_slow = GroundingDinoProcessor(tokenizer=tokenizer_slow, image_processor=image_processor)\n-        processor_slow.save_pretrained(self.tmpdirname)\n-        processor_slow = GroundingDinoProcessor.from_pretrained(self.tmpdirname, use_fast=False)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor_slow = GroundingDinoProcessor(tokenizer=tokenizer_slow, image_processor=image_processor)\n+            processor_slow.save_pretrained(tmpdir)\n+            processor_slow = GroundingDinoProcessor.from_pretrained(tmpdir, use_fast=False)\n \n-        processor_fast = GroundingDinoProcessor(tokenizer=tokenizer_fast, image_processor=image_processor)\n-        processor_fast.save_pretrained(self.tmpdirname)\n-        processor_fast = GroundingDinoProcessor.from_pretrained(self.tmpdirname)\n+            processor_fast = GroundingDinoProcessor(tokenizer=tokenizer_fast, image_processor=image_processor)\n+            processor_fast.save_pretrained(tmpdir)\n+            processor_fast = GroundingDinoProcessor.from_pretrained(tmpdir)\n \n         self.assertEqual(processor_slow.tokenizer.get_vocab(), tokenizer_slow.get_vocab())\n         self.assertEqual(processor_fast.tokenizer.get_vocab(), tokenizer_fast.get_vocab())\n@@ -168,15 +173,20 @@ def test_save_load_pretrained_default(self):\n \n     # Copied from tests.models.clip.test_processor_clip.CLIPProcessorTest.test_save_load_pretrained_additional_features with CLIP->GroundingDino,GroundingDinoTokenizer->BertTokenizer\n     def test_save_load_pretrained_additional_features(self):\n-        processor = GroundingDinoProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n-        processor.save_pretrained(self.tmpdirname)\n-\n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n-\n-        processor = GroundingDinoProcessor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = GroundingDinoProcessor(\n+                tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor()\n+            )\n+            processor.save_pretrained(tmpdir)\n+\n+            tokenizer_add_kwargs = BertTokenizer.from_pretrained(tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = GroundingDinoImageProcessor.from_pretrained(\n+                tmpdir, do_normalize=False, padding_value=1.0\n+            )\n+\n+            processor = GroundingDinoProcessor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, BertTokenizerFast)"
        },
        {
            "sha": "e161549166b0becfde8e47141c9a43168e03b57c",
            "filename": "tests/models/idefics/test_processor_idefics.py",
            "status": "modified",
            "additions": 16,
            "deletions": 13,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fidefics%2Ftest_processor_idefics.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fidefics%2Ftest_processor_idefics.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fidefics%2Ftest_processor_idefics.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -43,26 +43,28 @@\n class IdeficsProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = IdeficsProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         image_processor = IdeficsImageProcessor(return_tensors=\"pt\")\n         tokenizer = LlamaTokenizerFast.from_pretrained(\"HuggingFaceM4/tiny-random-idefics\")\n \n         processor = IdeficsProcessor(image_processor, tokenizer)\n \n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-        self.input_keys = [\"pixel_values\", \"input_ids\", \"attention_mask\", \"image_attention_mask\"]\n+        cls.input_keys = [\"pixel_values\", \"input_ids\", \"attention_mask\", \"image_attention_mask\"]\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n \n     def get_image_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).image_processor\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def prepare_prompts(self):\n         \"\"\"This function prepares a list of PIL images\"\"\"\n@@ -107,15 +109,16 @@ def prepare_prompts(self):\n         return prompts\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = IdeficsProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n-        processor.save_pretrained(self.tmpdirname)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = IdeficsProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n+            processor.save_pretrained(tmpdir)\n \n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n+            tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n \n-        processor = IdeficsProcessor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+            processor = IdeficsProcessor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, PreTrainedTokenizerFast)"
        },
        {
            "sha": "99373005c9eac00778d85927a29e12a93ba97945",
            "filename": "tests/models/idefics2/test_processor_idefics2.py",
            "status": "modified",
            "additions": 17,
            "deletions": 15,
            "changes": 32,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fidefics2%2Ftest_processor_idefics2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fidefics2%2Ftest_processor_idefics2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fidefics2%2Ftest_processor_idefics2.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -41,38 +41,39 @@\n class Idefics2ProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = Idefics2Processor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         processor = Idefics2Processor.from_pretrained(\"HuggingFaceM4/idefics2-8b\", image_seq_len=2)\n \n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-        self.image1 = Image.open(\n+        cls.image1 = Image.open(\n             BytesIO(\n                 requests.get(\n                     \"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\"\n                 ).content\n             )\n         )\n-        self.image2 = Image.open(\n+        cls.image2 = Image.open(\n             BytesIO(requests.get(\"https://cdn.britannica.com/59/94459-050-DBA42467/Skyline-Chicago.jpg\").content)\n         )\n-        self.image3 = Image.open(\n+        cls.image3 = Image.open(\n             BytesIO(\n                 requests.get(\n                     \"https://thumbs.dreamstime.com/b/golden-gate-bridge-san-francisco-purple-flowers-california-echium-candicans-36805947.jpg\"\n                 ).content\n             )\n         )\n-        self.bos_token = processor.tokenizer.bos_token\n-        self.image_token = processor.image_token.content\n-        self.fake_image_token = processor.fake_image_token.content\n+        cls.bos_token = processor.tokenizer.bos_token\n+        cls.image_token = processor.image_token.content\n+        cls.fake_image_token = processor.fake_image_token.content\n \n-        self.bos_token_id = processor.tokenizer.convert_tokens_to_ids(self.bos_token)\n-        self.image_token_id = processor.tokenizer.convert_tokens_to_ids(self.image_token)\n-        self.fake_image_token_id = processor.tokenizer.convert_tokens_to_ids(self.fake_image_token)\n-        self.image_seq_len = processor.image_seq_len\n+        cls.bos_token_id = processor.tokenizer.convert_tokens_to_ids(cls.bos_token)\n+        cls.image_token_id = processor.tokenizer.convert_tokens_to_ids(cls.image_token)\n+        cls.fake_image_token_id = processor.tokenizer.convert_tokens_to_ids(cls.fake_image_token)\n+        cls.image_seq_len = processor.image_seq_len\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n@@ -83,8 +84,9 @@ def get_image_processor(self, **kwargs):\n     def get_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_process_interleaved_images_prompts_no_image_splitting(self):\n         tokenizer = self.get_tokenizer()"
        },
        {
            "sha": "5ff0eff9461d513b29a336a24ff24d39876891ae",
            "filename": "tests/models/idefics3/test_processor_idefics3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fidefics3%2Ftest_processor_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fidefics3%2Ftest_processor_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fidefics3%2Ftest_processor_idefics3.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -104,7 +104,7 @@ def get_split_image_expected_tokens(self, processor, image_rows, image_cols):\n \n     @classmethod\n     def tearDownClass(cls):\n-        shutil.rmtree(cls.tmpdirname)\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_process_interleaved_images_prompts_no_image_splitting(self):\n         processor = self.get_processor()"
        },
        {
            "sha": "6675390e0b2f88237958b7f8817bbb0f93e5a85e",
            "filename": "tests/models/instructblip/test_processor_instructblip.py",
            "status": "modified",
            "additions": 14,
            "deletions": 11,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Finstructblip%2Ftest_processor_instructblip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Finstructblip%2Ftest_processor_instructblip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Finstructblip%2Ftest_processor_instructblip.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -38,16 +38,17 @@\n class InstructBlipProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = InstructBlipProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         image_processor = BlipImageProcessor()\n         tokenizer = GPT2Tokenizer.from_pretrained(\"hf-internal-testing/tiny-random-GPT2Model\")\n         qformer_tokenizer = BertTokenizerFast.from_pretrained(\"hf-internal-testing/tiny-random-bert\")\n \n         processor = InstructBlipProcessor(image_processor, tokenizer, qformer_tokenizer)\n \n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n@@ -58,23 +59,25 @@ def get_image_processor(self, **kwargs):\n     def get_qformer_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).qformer_tokenizer\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_additional_features(self):\n         processor = InstructBlipProcessor(\n             tokenizer=self.get_tokenizer(),\n             image_processor=self.get_image_processor(),\n             qformer_tokenizer=self.get_qformer_tokenizer(),\n         )\n-        processor.save_pretrained(self.tmpdirname)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor.save_pretrained(tmpdir)\n \n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n+            tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n \n-        processor = InstructBlipProcessor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+            processor = InstructBlipProcessor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, PreTrainedTokenizerFast)"
        },
        {
            "sha": "3e65811b73e42b11821973143a79b065820ad833",
            "filename": "tests/models/instructblipvideo/test_processor_instructblipvideo.py",
            "status": "modified",
            "additions": 14,
            "deletions": 11,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Finstructblipvideo%2Ftest_processor_instructblipvideo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Finstructblipvideo%2Ftest_processor_instructblipvideo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Finstructblipvideo%2Ftest_processor_instructblipvideo.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -39,16 +39,17 @@\n class InstructBlipVideoProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = InstructBlipVideoProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         image_processor = InstructBlipVideoImageProcessor()\n         tokenizer = GPT2Tokenizer.from_pretrained(\"hf-internal-testing/tiny-random-GPT2Model\")\n         qformer_tokenizer = BertTokenizerFast.from_pretrained(\"hf-internal-testing/tiny-random-bert\")\n \n         processor = InstructBlipVideoProcessor(image_processor, tokenizer, qformer_tokenizer)\n \n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n@@ -59,23 +60,25 @@ def get_image_processor(self, **kwargs):\n     def get_qformer_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).qformer_tokenizer\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_additional_features(self):\n         processor = InstructBlipVideoProcessor(\n             tokenizer=self.get_tokenizer(),\n             image_processor=self.get_image_processor(),\n             qformer_tokenizer=self.get_qformer_tokenizer(),\n         )\n-        processor.save_pretrained(self.tmpdirname)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor.save_pretrained(tmpdir)\n \n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n+            tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n \n-        processor = InstructBlipVideoProcessor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+            processor = InstructBlipVideoProcessor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, PreTrainedTokenizerFast)"
        },
        {
            "sha": "587db26ef18a04b767fe75ed6f6e590ab9981337",
            "filename": "tests/models/kosmos2/test_processor_kosmos2.py",
            "status": "modified",
            "additions": 15,
            "deletions": 12,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fkosmos2%2Ftest_processor_kosmos2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fkosmos2%2Ftest_processor_kosmos2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fkosmos2%2Ftest_processor_kosmos2.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -57,8 +57,9 @@\n class Kosmos2ProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = Kosmos2Processor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         image_processor = CLIPImageProcessor(do_center_crop=False)\n \n@@ -67,7 +68,7 @@ def setUp(self):\n         fast_tokenizer = XLMRobertaTokenizerFast(__slow_tokenizer=slow_tokenizer)\n \n         processor = Kosmos2Processor(image_processor, fast_tokenizer)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     # We override this method to take the fast tokenizer by default\n     def get_component(self, attribute, **kwargs):\n@@ -92,8 +93,9 @@ def get_tokenizer(self, **kwargs):\n     def get_image_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).image_processor\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_image_procesor_load_save_reload(self):\n         # make sure load from Hub repo. -> save -> reload locally work\n@@ -105,15 +107,16 @@ def test_image_procesor_load_save_reload(self):\n             assert image_processor.to_json_string() == reloaded_image_processor.to_json_string()\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = Kosmos2Processor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n-        processor.save_pretrained(self.tmpdirname)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = Kosmos2Processor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n+            processor.save_pretrained(tmpdir)\n \n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n+            tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n \n-        processor = Kosmos2Processor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+            processor = Kosmos2Processor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, PreTrainedTokenizerFast)"
        },
        {
            "sha": "57872eda807133cfd4306d5c14c2dce6b31af73a",
            "filename": "tests/models/layoutxlm/test_processor_layoutxlm.py",
            "status": "modified",
            "additions": 43,
            "deletions": 35,
            "changes": 78,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Flayoutxlm%2Ftest_processor_layoutxlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Flayoutxlm%2Ftest_processor_layoutxlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flayoutxlm%2Ftest_processor_layoutxlm.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -46,49 +46,56 @@ class LayoutXLMProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     rust_tokenizer_class = LayoutXLMTokenizerFast\n     processor_class = LayoutXLMProcessor\n \n-    def setUp(self):\n+    @classmethod\n+    def setUpClass(cls):\n         image_processor_map = {\n             \"do_resize\": True,\n             \"size\": 224,\n             \"apply_ocr\": True,\n         }\n \n-        self.tmpdirname = tempfile.mkdtemp()\n-        self.feature_extraction_file = os.path.join(self.tmpdirname, FEATURE_EXTRACTOR_NAME)\n-        with open(self.feature_extraction_file, \"w\", encoding=\"utf-8\") as fp:\n+        cls.tmpdirname = tempfile.mkdtemp()\n+        cls.feature_extraction_file = os.path.join(cls.tmpdirname, FEATURE_EXTRACTOR_NAME)\n+        with open(cls.feature_extraction_file, \"w\", encoding=\"utf-8\") as fp:\n             fp.write(json.dumps(image_processor_map) + \"\\n\")\n \n         # taken from `test_tokenization_layoutxlm.LayoutXLMTokenizationTest.test_save_pretrained`\n-        self.tokenizer_pretrained_name = \"hf-internal-testing/tiny-random-layoutxlm\"\n+        cls.tokenizer_pretrained_name = \"hf-internal-testing/tiny-random-layoutxlm\"\n \n-        tokenizer = self.get_tokenizer()\n-        image_processor = self.get_image_processor()\n+        tokenizer = cls.get_tokenizer()\n+        image_processor = cls.get_image_processor()\n         processor = LayoutXLMProcessor(tokenizer=tokenizer, image_processor=image_processor)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-    def get_tokenizer(self, **kwargs) -> PreTrainedTokenizer:\n-        return self.tokenizer_class.from_pretrained(self.tokenizer_pretrained_name, **kwargs)\n+    @classmethod\n+    def get_tokenizer(cls, **kwargs) -> PreTrainedTokenizer:\n+        return cls.tokenizer_class.from_pretrained(cls.tokenizer_pretrained_name, **kwargs)\n \n-    def get_rust_tokenizer(self, **kwargs) -> PreTrainedTokenizerFast:\n-        return self.rust_tokenizer_class.from_pretrained(self.tokenizer_pretrained_name, **kwargs)\n+    @classmethod\n+    def get_rust_tokenizer(cls, **kwargs) -> PreTrainedTokenizerFast:\n+        return cls.rust_tokenizer_class.from_pretrained(cls.tokenizer_pretrained_name, **kwargs)\n \n-    def get_tokenizers(self, **kwargs) -> list[PreTrainedTokenizerBase]:\n-        return [self.get_tokenizer(**kwargs), self.get_rust_tokenizer(**kwargs)]\n+    @classmethod\n+    def get_tokenizers(cls, **kwargs) -> list[PreTrainedTokenizerBase]:\n+        return [cls.get_tokenizer(**kwargs), cls.get_rust_tokenizer(**kwargs)]\n \n-    def get_image_processor(self, **kwargs):\n-        return LayoutLMv2ImageProcessor.from_pretrained(self.tmpdirname, **kwargs)\n+    @classmethod\n+    def get_image_processor(cls, **kwargs):\n+        return LayoutLMv2ImageProcessor.from_pretrained(cls.tmpdirname, **kwargs)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_default(self):\n         image_processor = self.get_image_processor()\n         tokenizers = self.get_tokenizers()\n         for tokenizer in tokenizers:\n             processor = LayoutXLMProcessor(image_processor=image_processor, tokenizer=tokenizer)\n \n-            processor.save_pretrained(self.tmpdirname)\n-            processor = LayoutXLMProcessor.from_pretrained(self.tmpdirname)\n+            with tempfile.TemporaryDirectory() as tmpdir:\n+                processor.save_pretrained(tmpdir)\n+                processor = LayoutXLMProcessor.from_pretrained(tmpdir)\n \n             self.assertEqual(processor.tokenizer.get_vocab(), tokenizer.get_vocab())\n             self.assertIsInstance(processor.tokenizer, (LayoutXLMTokenizer, LayoutXLMTokenizerFast))\n@@ -97,21 +104,22 @@ def test_save_load_pretrained_default(self):\n             self.assertIsInstance(processor.image_processor, LayoutLMv2ImageProcessor)\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = LayoutXLMProcessor(image_processor=self.get_image_processor(), tokenizer=self.get_tokenizer())\n-        processor.save_pretrained(self.tmpdirname)\n-\n-        # slow tokenizer\n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_resize=False, size=30)\n-\n-        processor = LayoutXLMProcessor.from_pretrained(\n-            self.tmpdirname,\n-            use_fast=False,\n-            bos_token=\"(BOS)\",\n-            eos_token=\"(EOS)\",\n-            do_resize=False,\n-            size=30,\n-        )\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = LayoutXLMProcessor(image_processor=self.get_image_processor(), tokenizer=self.get_tokenizer())\n+            processor.save_pretrained(tmpdir)\n+\n+            # slow tokenizer\n+            tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = self.get_image_processor(do_resize=False, size=30)\n+\n+            processor = LayoutXLMProcessor.from_pretrained(\n+                tmpdir,\n+                use_fast=False,\n+                bos_token=\"(BOS)\",\n+                eos_token=\"(EOS)\",\n+                do_resize=False,\n+                size=30,\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, LayoutXLMTokenizer)"
        },
        {
            "sha": "56c854f4a486fd2d55bd6d1ee69b7b2b1484b9b3",
            "filename": "tests/models/llava/test_processor_llava.py",
            "status": "modified",
            "additions": 10,
            "deletions": 7,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fllava%2Ftest_processor_llava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fllava%2Ftest_processor_llava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fllava%2Ftest_processor_llava.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -34,25 +34,28 @@\n class LlavaProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = LlavaProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         image_processor = CLIPImageProcessor(do_center_crop=False)\n         tokenizer = LlamaTokenizerFast.from_pretrained(\"huggyllama/llama-7b\")\n-        processor_kwargs = self.prepare_processor_dict()\n+        processor_kwargs = cls.prepare_processor_dict()\n         processor = LlavaProcessor(image_processor, tokenizer, **processor_kwargs)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n \n     def get_image_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).image_processor\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n-    def prepare_processor_dict(self):\n+    @staticmethod\n+    def prepare_processor_dict():\n         return {\n             \"chat_template\": \"{% for message in messages %}{% if message['role'] != 'system' %}{{ message['role'].upper() + ': '}}{% endif %}{# Render all images first #}{% for content in message['content'] | selectattr('type', 'equalto', 'image') %}{{ '<image>\\n' }}{% endfor %}{# Render all text next #}{% if message['role'] != 'assistant' %}{% for content in message['content'] | selectattr('type', 'equalto', 'text') %}{{ content['text'] + ' '}}{% endfor %}{% else %}{% for content in message['content'] | selectattr('type', 'equalto', 'text') %}{% generation %}{{ content['text'] + ' '}}{% endgeneration %}{% endfor %}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ 'ASSISTANT:' }}{% endif %}\",\n             \"patch_size\": 3,"
        },
        {
            "sha": "4a14f5ab771fce0f224ba391c04066e23503c7f8",
            "filename": "tests/models/llava_next/test_processor_llava_next.py",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fllava_next%2Ftest_processor_llava_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fllava_next%2Ftest_processor_llava_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fllava_next%2Ftest_processor_llava_next.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -34,22 +34,24 @@\n class LlavaNextProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = LlavaNextProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         image_processor = LlavaNextImageProcessor()\n         tokenizer = LlamaTokenizerFast.from_pretrained(\"huggyllama/llama-7b\")\n-        processor_kwargs = self.prepare_processor_dict()\n+        processor_kwargs = cls.prepare_processor_dict()\n         processor = LlavaNextProcessor(image_processor, tokenizer, **processor_kwargs)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return LlavaNextProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n \n     def get_image_processor(self, **kwargs):\n         return LlavaNextProcessor.from_pretrained(self.tmpdirname, **kwargs).image_processor\n \n-    def prepare_processor_dict(self):\n+    @staticmethod\n+    def prepare_processor_dict():\n         return {\n             \"chat_template\": \"{% for message in messages %}{% if message['role'] != 'system' %}{{ message['role'].upper() + ': '}}{% endif %}{# Render all images first #}{% for content in message['content'] | selectattr('type', 'equalto', 'image') %}{{ '<image>\\n' }}{% endfor %}{# Render all text next #}{% if message['role'] != 'assistant' %}{% for content in message['content'] | selectattr('type', 'equalto', 'text') %}{{ content['text'] + ' '}}{% endfor %}{% else %}{% for content in message['content'] | selectattr('type', 'equalto', 'text') %}{% generation %}{{ content['text'] + ' '}}{% endgeneration %}{% endfor %}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ 'ASSISTANT:' }}{% endif %}\",\n             \"patch_size\": 3,"
        },
        {
            "sha": "affa95cc04fc7df4f89678b010847af8b040fa4c",
            "filename": "tests/models/llava_next_video/test_processor_llava_next_video.py",
            "status": "modified",
            "additions": 10,
            "deletions": 7,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fllava_next_video%2Ftest_processor_llava_next_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fllava_next_video%2Ftest_processor_llava_next_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fllava_next_video%2Ftest_processor_llava_next_video.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -35,17 +35,18 @@\n class LlavaNextVideoProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = LlavaNextVideoProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n         image_processor = LlavaNextImageProcessor()\n         video_processor = LlavaNextVideoImageProcessor()\n         tokenizer = LlamaTokenizerFast.from_pretrained(\"llava-hf/LLaVA-NeXT-Video-7B-hf\")\n-        processor_kwargs = self.prepare_processor_dict()\n+        processor_kwargs = cls.prepare_processor_dict()\n \n         processor = LlavaNextVideoProcessor(\n             video_processor=video_processor, image_processor=image_processor, tokenizer=tokenizer, **processor_kwargs\n         )\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n@@ -56,7 +57,8 @@ def get_image_processor(self, **kwargs):\n     def get_video_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).video_processor\n \n-    def prepare_processor_dict(self):\n+    @classmethod\n+    def prepare_processor_dict(cls):\n         return {\n             \"chat_template\": \"{% for message in messages %}{{'<|im_start|>' + message['role'] + ' '}}{# Render all images first #}{% for content in message['content'] | selectattr('type', 'equalto', 'image') %}{{ '<image>' }}{% endfor %}{# Render all video then #}{% for content in message['content'] | selectattr('type', 'equalto', 'video') %}{{ '<video>' }}{% endfor %}{# Render all text next #}{% if message['role'] != 'assistant' %}{% for content in message['content'] | selectattr('type', 'equalto', 'text') %}{{ '\\n' + content['text'] }}{% endfor %}{% else %}{% for content in message['content'] | selectattr('type', 'equalto', 'text') %}{% generation %}{{ '\\n' + content['text'] }}{% endgeneration %}{% endfor %}{% endif %}{{'<|im_end|>'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\",\n             \"num_additional_image_tokens\": 6,\n@@ -85,8 +87,9 @@ def test_chat_template_is_saved(self):\n         processor_dict = self.prepare_processor_dict()\n         self.assertTrue(processor_loaded.chat_template == processor_dict.get(\"chat_template\", None))\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_chat_template(self):\n         processor = AutoProcessor.from_pretrained(\"llava-hf/LLaVA-NeXT-Video-7B-hf\")"
        },
        {
            "sha": "b545e5b396f71bff755844f9cc343233c86e7a6d",
            "filename": "tests/models/llava_onevision/test_processor_llava_onevision.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fllava_onevision%2Ftest_processor_llava_onevision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fllava_onevision%2Ftest_processor_llava_onevision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fllava_onevision%2Ftest_processor_llava_onevision.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -42,7 +42,6 @@ class LlavaOnevisionProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     @classmethod\n     def setUpClass(cls):\n         cls.tmpdirname = tempfile.mkdtemp()\n-        cls.addClassCleanup(lambda tempdir=cls.tmpdirname: shutil.rmtree(tempdir))\n         image_processor = LlavaOnevisionImageProcessor()\n         video_processor = LlavaOnevisionVideoProcessor()\n         tokenizer = Qwen2TokenizerFast.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n@@ -62,6 +61,10 @@ def get_image_processor(self, **kwargs):\n     def get_video_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).video_processor\n \n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n+\n     @staticmethod\n     def prepare_processor_dict():\n         return {"
        },
        {
            "sha": "0d53e34d728e08bbcea7e710b9966d6fc9ed8fb0",
            "filename": "tests/models/mllama/test_processor_mllama.py",
            "status": "modified",
            "additions": 17,
            "deletions": 15,
            "changes": 32,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fmllama%2Ftest_processor_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fmllama%2Ftest_processor_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmllama%2Ftest_processor_mllama.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -36,21 +36,23 @@\n class MllamaProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = MllamaProcessor\n \n-    def setUp(self):\n-        self.checkpoint = \"hf-internal-testing/mllama-11b\"\n-        processor = MllamaProcessor.from_pretrained(self.checkpoint)\n-        self.image1 = Image.new(\"RGB\", (224, 220))\n-        self.image2 = Image.new(\"RGB\", (512, 128))\n-        self.image_token = processor.image_token\n-        self.image_token_id = processor.image_token_id\n-        self.pad_token_id = processor.tokenizer.pad_token_id\n-        self.bos_token = processor.bos_token\n-        self.bos_token_id = processor.tokenizer.bos_token_id\n-        self.tmpdirname = tempfile.mkdtemp()\n-        processor.save_pretrained(self.tmpdirname)\n-\n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.checkpoint = \"hf-internal-testing/mllama-11b\"\n+        processor = MllamaProcessor.from_pretrained(cls.checkpoint)\n+        cls.image1 = Image.new(\"RGB\", (224, 220))\n+        cls.image2 = Image.new(\"RGB\", (512, 128))\n+        cls.image_token = processor.image_token\n+        cls.image_token_id = processor.image_token_id\n+        cls.pad_token_id = processor.tokenizer.pad_token_id\n+        cls.bos_token = processor.bos_token\n+        cls.bos_token_id = processor.tokenizer.bos_token_id\n+        cls.tmpdirname = tempfile.mkdtemp()\n+        processor.save_pretrained(cls.tmpdirname)\n+\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def prepare_processor_dict(self):\n         return {\"chat_template\": \"{% for message in messages %}{% if loop.index0 == 0 %}{{ bos_token }}{% endif %}{{ '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n' }}{% if message['content'] is string %}{{ message['content'] }}{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' %}{{ '<|image|>' }}{% elif content['type'] == 'text' %}{{ content['text'] }}{% endif %}{% endfor %}{% endif %}{{ '<|eot_id|>' }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\"}  # fmt: skip"
        },
        {
            "sha": "f36b6c7ec56c183fde926ccb4441c3184cff6fff",
            "filename": "tests/models/myt5/test_tokenization_myt5.py",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fmyt5%2Ftest_tokenization_myt5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fmyt5%2Ftest_tokenization_myt5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmyt5%2Ftest_tokenization_myt5.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -38,8 +38,9 @@ def str_to_hex(line: str, sep: str = \" \") -> str:\n \n \n class TestByteRewriter(unittest.TestCase):\n-    def setUp(self) -> None:\n-        self.tokenizer = MyT5Tokenizer.from_pretrained(\"Tomlim/myt5-base\")\n+    @classmethod\n+    def setUpClass(cls) -> None:\n+        cls.tokenizer = MyT5Tokenizer.from_pretrained(\"Tomlim/myt5-base\")\n \n     def test_simple_decompose(self):\n         decompose_rewriter = self.tokenizer.decompose_rewriter"
        },
        {
            "sha": "500e83c56b6238bdd8c95ada1983824e7428a710",
            "filename": "tests/models/omdet_turbo/test_processor_omdet_turbo.py",
            "status": "modified",
            "additions": 19,
            "deletions": 16,
            "changes": 35,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fomdet_turbo%2Ftest_processor_omdet_turbo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fomdet_turbo%2Ftest_processor_omdet_turbo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fomdet_turbo%2Ftest_processor_omdet_turbo.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -44,15 +44,16 @@ class OmDetTurboProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = OmDetTurboProcessor\n     text_input_name = \"classes_input_ids\"\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n         image_processor = DetrImageProcessor()\n         tokenizer = CLIPTokenizerFast.from_pretrained(\"openai/clip-vit-base-patch32\")\n \n         processor = OmDetTurboProcessor(image_processor, tokenizer)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-        self.input_keys = [\n+        cls.input_keys = [\n             \"tasks_input_ids\",\n             \"tasks_attention_mask\",\n             \"classes_input_ids\",\n@@ -62,18 +63,19 @@ def setUp(self):\n             \"pixel_mask\",\n         ]\n \n-        self.batch_size = 5\n-        self.num_queries = 5\n-        self.embed_dim = 3\n+        cls.batch_size = 5\n+        cls.num_queries = 5\n+        cls.embed_dim = 3\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n \n     def get_image_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).image_processor\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def get_fake_omdet_turbo_output(self):\n         classes = self.get_fake_omdet_turbo_classes()\n@@ -112,15 +114,16 @@ def test_post_process_grounded_object_detection(self):\n         torch.testing.assert_close(post_processed[0][\"boxes\"][0], expected_box_slice, rtol=1e-4, atol=1e-4)\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = OmDetTurboProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n-        processor.save_pretrained(self.tmpdirname)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = OmDetTurboProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n+            processor.save_pretrained(tmpdir)\n \n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n+            tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n \n-        processor = OmDetTurboProcessor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+            processor = OmDetTurboProcessor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, CLIPTokenizerFast)"
        },
        {
            "sha": "91043775069fe9ca52100f51852572f9c31ed11a",
            "filename": "tests/models/owlv2/test_processor_owlv2.py",
            "status": "modified",
            "additions": 9,
            "deletions": 7,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fowlv2%2Ftest_processor_owlv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fowlv2%2Ftest_processor_owlv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fowlv2%2Ftest_processor_owlv2.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -14,13 +14,15 @@\n class Owlv2ProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = Owlv2Processor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n-        processor = self.processor_class.from_pretrained(\"google/owlv2-base-patch16-ensemble\")\n-        processor.save_pretrained(self.tmpdirname)\n-\n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n+        processor = cls.processor_class.from_pretrained(\"google/owlv2-base-patch16-ensemble\")\n+        processor.save_pretrained(cls.tmpdirname)\n+\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_processor_query_images_positional(self):\n         processor_components = self.prepare_components()"
        },
        {
            "sha": "bae80aa7f30f96ef2ee20a717073ccc0519cf5c7",
            "filename": "tests/models/paligemma/test_processor_paligemma.py",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fpaligemma%2Ftest_processor_paligemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fpaligemma%2Ftest_processor_paligemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpaligemma%2Ftest_processor_paligemma.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -33,16 +33,18 @@\n class PaliGemmaProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = PaliGemmaProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n         image_processor = SiglipImageProcessor.from_pretrained(\"google/siglip-so400m-patch14-384\")\n         image_processor.image_seq_length = 0\n         tokenizer = GemmaTokenizer(SAMPLE_VOCAB, keep_accents=True)\n         processor = PaliGemmaProcessor(image_processor=image_processor, tokenizer=tokenizer)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     @require_torch\n     @require_vision"
        },
        {
            "sha": "d58605d44453e0d704f46e56965556e93c4886f4",
            "filename": "tests/models/pix2struct/test_processor_pix2struct.py",
            "status": "modified",
            "additions": 15,
            "deletions": 12,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fpix2struct%2Ftest_processor_pix2struct.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fpix2struct%2Ftest_processor_pix2struct.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpix2struct%2Ftest_processor_pix2struct.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -40,35 +40,38 @@ class Pix2StructProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     text_input_name = \"decoder_input_ids\"\n     images_input_name = \"flattened_patches\"\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         image_processor = Pix2StructImageProcessor()\n         tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-small\")\n \n         processor = Pix2StructProcessor(image_processor, tokenizer)\n \n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n \n     def get_image_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).image_processor\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = Pix2StructProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n-        processor.save_pretrained(self.tmpdirname)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = Pix2StructProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n+            processor.save_pretrained(tmpdir)\n \n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n+            tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n \n-        processor = Pix2StructProcessor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+            processor = Pix2StructProcessor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, PreTrainedTokenizerFast)"
        },
        {
            "sha": "b8cdf63ff92cda9f6624195916c2518623ea71d5",
            "filename": "tests/models/pop2piano/test_processor_pop2piano.py",
            "status": "modified",
            "additions": 29,
            "deletions": 26,
            "changes": 55,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fpop2piano%2Ftest_processor_pop2piano.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fpop2piano%2Ftest_processor_pop2piano.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpop2piano%2Ftest_processor_pop2piano.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -62,46 +62,49 @@\n @require_essentia\n @require_pretty_midi\n class Pop2PianoProcessorTest(unittest.TestCase):\n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         feature_extractor = Pop2PianoFeatureExtractor.from_pretrained(\"sweetcocoa/pop2piano\")\n         tokenizer = Pop2PianoTokenizer.from_pretrained(\"sweetcocoa/pop2piano\")\n         processor = Pop2PianoProcessor(feature_extractor, tokenizer)\n \n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return Pop2PianoTokenizer.from_pretrained(self.tmpdirname, **kwargs)\n \n     def get_feature_extractor(self, **kwargs):\n         return Pop2PianoFeatureExtractor.from_pretrained(self.tmpdirname, **kwargs)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = Pop2PianoProcessor(\n-            tokenizer=self.get_tokenizer(),\n-            feature_extractor=self.get_feature_extractor(),\n-        )\n-        processor.save_pretrained(self.tmpdirname)\n-\n-        tokenizer_add_kwargs = self.get_tokenizer(\n-            unk_token=\"-1\",\n-            eos_token=\"1\",\n-            pad_token=\"0\",\n-            bos_token=\"2\",\n-        )\n-        feature_extractor_add_kwargs = self.get_feature_extractor()\n-\n-        processor = Pop2PianoProcessor.from_pretrained(\n-            self.tmpdirname,\n-            unk_token=\"-1\",\n-            eos_token=\"1\",\n-            pad_token=\"0\",\n-            bos_token=\"2\",\n-        )\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = Pop2PianoProcessor(\n+                tokenizer=self.get_tokenizer(),\n+                feature_extractor=self.get_feature_extractor(),\n+            )\n+            processor.save_pretrained(tmpdir)\n+\n+            tokenizer_add_kwargs = self.get_tokenizer(\n+                unk_token=\"-1\",\n+                eos_token=\"1\",\n+                pad_token=\"0\",\n+                bos_token=\"2\",\n+            )\n+            feature_extractor_add_kwargs = self.get_feature_extractor()\n+\n+            processor = Pop2PianoProcessor.from_pretrained(\n+                tmpdir,\n+                unk_token=\"-1\",\n+                eos_token=\"1\",\n+                pad_token=\"0\",\n+                bos_token=\"2\",\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, Pop2PianoTokenizer)"
        },
        {
            "sha": "a7060cfc98894ac587d84de476f9ddb2a0df8454",
            "filename": "tests/models/qwen2_5_vl/test_processor_qwen2_5_vl.py",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_processor_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_processor_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_processor_qwen2_5_vl.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -36,10 +36,11 @@\n class Qwen2_5_VLProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = Qwen2_5_VLProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n         processor = Qwen2_5_VLProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\", patch_size=4)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n@@ -50,8 +51,9 @@ def get_image_processor(self, **kwargs):\n     def prepare_processor_dict(self):\n         return {\"chat_template\": \"{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n{% endif %}<|im_start|>{{ message['role'] }}\\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\\n{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\"}  # fmt: skip\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_default(self):\n         tokenizer = self.get_tokenizer()"
        },
        {
            "sha": "ebd41520c3a06be0f887d124926fbba0bb52f581",
            "filename": "tests/models/qwen2_audio/test_processor_qwen2_audio.py",
            "status": "modified",
            "additions": 15,
            "deletions": 11,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fqwen2_audio%2Ftest_processor_qwen2_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fqwen2_audio%2Ftest_processor_qwen2_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_audio%2Ftest_processor_qwen2_audio.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -32,24 +32,27 @@\n class Qwen2AudioProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = Qwen2AudioProcessor\n \n-    def setUp(self):\n-        self.checkpoint = \"Qwen/Qwen2-Audio-7B-Instruct\"\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.checkpoint = \"Qwen/Qwen2-Audio-7B-Instruct\"\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n-        processor_kwargs = self.prepare_processor_dict()\n-        processor = Qwen2AudioProcessor.from_pretrained(self.checkpoint, **processor_kwargs)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor_kwargs = cls.prepare_processor_dict()\n+        processor = Qwen2AudioProcessor.from_pretrained(cls.checkpoint, **processor_kwargs)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n \n     def get_audio_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).audio_processor\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n-    def prepare_processor_dict(self):\n+    @staticmethod\n+    def prepare_processor_dict():\n         return {\n             \"chat_template\": \"{% set audio_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n{% endif %}<|im_start|>{{ message['role'] }}\\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\\n{% else %}{% for content in message['content'] %}{% if 'audio' in content or 'audio_url' in content or message['type'] == 'audio' %}{% set audio_count.value = audio_count.value + 1 %}Audio {{ audio_count.value }}: <|audio_bos|><|AUDIO|><|audio_eos|>\\n{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\",\n         }\n@@ -80,8 +83,9 @@ def test_save_load_pretrained_default(self):\n \n         processor = Qwen2AudioProcessor(tokenizer=tokenizer, feature_extractor=feature_extractor)\n \n-        processor.save_pretrained(self.tmpdirname)\n-        processor = Qwen2AudioProcessor.from_pretrained(self.tmpdirname)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor.save_pretrained(tmpdir)\n+            processor = Qwen2AudioProcessor.from_pretrained(tmpdir)\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer.get_vocab())\n         self.assertEqual(processor.feature_extractor.to_json_string(), feature_extractor.to_json_string())"
        },
        {
            "sha": "b1a2e99c0a476d57533415be72a88c40ff06e1ff",
            "filename": "tests/models/qwen2_vl/test_processor_qwen2_vl.py",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fqwen2_vl%2Ftest_processor_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fqwen2_vl%2Ftest_processor_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_vl%2Ftest_processor_qwen2_vl.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -36,10 +36,11 @@\n class Qwen2VLProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = Qwen2VLProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n         processor = Qwen2VLProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\", patch_size=4)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_tokenizer(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).tokenizer\n@@ -50,8 +51,9 @@ def get_image_processor(self, **kwargs):\n     def prepare_processor_dict(self):\n         return {\"chat_template\": \"{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n{% endif %}<|im_start|>{{ message['role'] }}\\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\\n{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\\n{% endif %}\"}  # fmt: skip\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_default(self):\n         tokenizer = self.get_tokenizer()"
        },
        {
            "sha": "2275c7dc4b03eaf003fb342becc1062aa377c038",
            "filename": "tests/models/sam/test_processor_sam.py",
            "status": "modified",
            "additions": 12,
            "deletions": 9,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fsam%2Ftest_processor_sam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fsam%2Ftest_processor_sam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsam%2Ftest_processor_sam.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -49,17 +49,19 @@\n class SamProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = SamProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n         image_processor = SamImageProcessor()\n         processor = SamProcessor(image_processor)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n     def get_image_processor(self, **kwargs):\n         return AutoProcessor.from_pretrained(self.tmpdirname, **kwargs).image_processor\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def prepare_mask_inputs(self):\n         \"\"\"This function prepares a list of PIL images, or a list of numpy arrays if one specifies numpify=True,\n@@ -85,12 +87,13 @@ def test_tokenizer_defaults_preserved_by_kwargs(self):\n         self.skipTest(\"SamProcessor does not have a tokenizer\")\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = SamProcessor(image_processor=self.get_image_processor())\n-        processor.save_pretrained(self.tmpdirname)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = SamProcessor(image_processor=self.get_image_processor())\n+            processor.save_pretrained(tmpdir)\n \n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n+            image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n \n-        processor = SamProcessor.from_pretrained(self.tmpdirname, do_normalize=False, padding_value=1.0)\n+            processor = SamProcessor.from_pretrained(tmpdir, do_normalize=False, padding_value=1.0)\n \n         self.assertEqual(processor.image_processor.to_json_string(), image_processor_add_kwargs.to_json_string())\n         self.assertIsInstance(processor.image_processor, SamImageProcessor)"
        },
        {
            "sha": "5574fdfe32c32aab005daf637d73e8d2b608e20d",
            "filename": "tests/models/shieldgemma2/test_processing_shieldgemma2.py",
            "status": "modified",
            "additions": 10,
            "deletions": 7,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fshieldgemma2%2Ftest_processing_shieldgemma2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fshieldgemma2%2Ftest_processing_shieldgemma2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fshieldgemma2%2Ftest_processing_shieldgemma2.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -72,8 +72,9 @@\n class ShieldGemma2ProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = ShieldGemma2Processor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n         image_processor = Gemma3ImageProcessor.from_pretrained(\"google/siglip-so400m-patch14-384\")\n \n         extra_special_tokens = {\n@@ -83,14 +84,16 @@ def setUp(self):\n         }\n         tokenizer = GemmaTokenizer(SAMPLE_VOCAB, keep_accents=True, extra_special_tokens=extra_special_tokens)\n \n-        processor_kwargs = self.prepare_processor_dict()\n+        processor_kwargs = cls.prepare_processor_dict()\n         processor = ShieldGemma2Processor(image_processor=image_processor, tokenizer=tokenizer, **processor_kwargs)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n-    def prepare_processor_dict(self):\n+    @classmethod\n+    def prepare_processor_dict(cls):\n         return {\n             \"chat_template\": _CHAT_TEMPLATE,\n             \"policy_definitions\": _SHIELDGEMMA2_POLICIES,"
        },
        {
            "sha": "e06b74dca7224286da74ccb5e9432d8d588f838e",
            "filename": "tests/models/smolvlm/test_processor_smolvlm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fsmolvlm%2Ftest_processor_smolvlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fsmolvlm%2Ftest_processor_smolvlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsmolvlm%2Ftest_processor_smolvlm.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -111,7 +111,7 @@ def get_split_image_expected_tokens(self, processor, image_rows, image_cols):\n \n     @classmethod\n     def tearDownClass(cls):\n-        shutil.rmtree(cls.tmpdirname)\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_process_interleaved_images_prompts_no_image_splitting(self):\n         processor_components = self.prepare_components()"
        },
        {
            "sha": "4f2c714295b4cd25bc54a032b87fc0531825ff7b",
            "filename": "tests/models/speech_to_text/test_processor_speech_to_text.py",
            "status": "modified",
            "additions": 23,
            "deletions": 18,
            "changes": 41,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fspeech_to_text%2Ftest_processor_speech_to_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fspeech_to_text%2Ftest_processor_speech_to_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fspeech_to_text%2Ftest_processor_speech_to_text.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -33,18 +33,19 @@\n @require_torchaudio\n @require_sentencepiece\n class Speech2TextProcessorTest(unittest.TestCase):\n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         vocab = [\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"This\", \"is\", \"a\", \"t\", \"est\"]\n         vocab_tokens = dict(zip(vocab, range(len(vocab))))\n-        save_dir = Path(self.tmpdirname)\n+        save_dir = Path(cls.tmpdirname)\n         save_json(vocab_tokens, save_dir / VOCAB_FILES_NAMES[\"vocab_file\"])\n         if not (save_dir / VOCAB_FILES_NAMES[\"spm_file\"]).exists():\n             copyfile(SAMPLE_SP, save_dir / VOCAB_FILES_NAMES[\"spm_file\"])\n \n-        tokenizer = Speech2TextTokenizer.from_pretrained(self.tmpdirname)\n-        tokenizer.save_pretrained(self.tmpdirname)\n+        tokenizer = Speech2TextTokenizer.from_pretrained(cls.tmpdirname)\n+        tokenizer.save_pretrained(cls.tmpdirname)\n \n         feature_extractor_map = {\n             \"feature_size\": 24,\n@@ -62,8 +63,9 @@ def get_tokenizer(self, **kwargs):\n     def get_feature_extractor(self, **kwargs):\n         return Speech2TextFeatureExtractor.from_pretrained(self.tmpdirname, **kwargs)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_default(self):\n         tokenizer = self.get_tokenizer()\n@@ -81,17 +83,20 @@ def test_save_load_pretrained_default(self):\n         self.assertIsInstance(processor.feature_extractor, Speech2TextFeatureExtractor)\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = Speech2TextProcessor(\n-            tokenizer=self.get_tokenizer(), feature_extractor=self.get_feature_extractor()\n-        )\n-        processor.save_pretrained(self.tmpdirname)\n-\n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        feature_extractor_add_kwargs = self.get_feature_extractor(do_normalize=False, padding_value=1.0)\n-\n-        processor = Speech2TextProcessor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = Speech2TextProcessor(\n+                tokenizer=self.get_tokenizer(), feature_extractor=self.get_feature_extractor()\n+            )\n+            processor.save_pretrained(tmpdir)\n+\n+            tokenizer_add_kwargs = Speech2TextTokenizer.from_pretrained(tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            feature_extractor_add_kwargs = Speech2TextFeatureExtractor.from_pretrained(\n+                tmpdir, do_normalize=False, padding_value=1.0\n+            )\n+\n+            processor = Speech2TextProcessor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, Speech2TextTokenizer)"
        },
        {
            "sha": "f1e1529b23996fa1feb1682e702324da5ec9c39c",
            "filename": "tests/models/speecht5/test_processor_speecht5.py",
            "status": "modified",
            "additions": 23,
            "deletions": 16,
            "changes": 39,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fspeecht5%2Ftest_processor_speecht5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fspeecht5%2Ftest_processor_speecht5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fspeecht5%2Ftest_processor_speecht5.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -36,11 +36,12 @@\n \n @require_torch\n class SpeechT5ProcessorTest(unittest.TestCase):\n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         tokenizer = SpeechT5Tokenizer(SAMPLE_VOCAB)\n-        tokenizer.save_pretrained(self.tmpdirname)\n+        tokenizer.save_pretrained(cls.tmpdirname)\n \n         feature_extractor_map = {\n             \"feature_size\": 1,\n@@ -58,8 +59,8 @@ def setUp(self):\n             \"return_attention_mask\": True,\n         }\n \n-        self.feature_extraction_file = os.path.join(self.tmpdirname, FEATURE_EXTRACTOR_NAME)\n-        with open(self.feature_extraction_file, \"w\", encoding=\"utf-8\") as fp:\n+        cls.feature_extraction_file = os.path.join(cls.tmpdirname, FEATURE_EXTRACTOR_NAME)\n+        with open(cls.feature_extraction_file, \"w\", encoding=\"utf-8\") as fp:\n             fp.write(json.dumps(feature_extractor_map) + \"\\n\")\n \n     def get_tokenizer(self, **kwargs):\n@@ -68,8 +69,9 @@ def get_tokenizer(self, **kwargs):\n     def get_feature_extractor(self, **kwargs):\n         return SpeechT5FeatureExtractor.from_pretrained(self.tmpdirname, **kwargs)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_default(self):\n         tokenizer = self.get_tokenizer()\n@@ -87,15 +89,20 @@ def test_save_load_pretrained_default(self):\n         self.assertIsInstance(processor.feature_extractor, SpeechT5FeatureExtractor)\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = SpeechT5Processor(tokenizer=self.get_tokenizer(), feature_extractor=self.get_feature_extractor())\n-        processor.save_pretrained(self.tmpdirname)\n-\n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        feature_extractor_add_kwargs = self.get_feature_extractor(do_normalize=False, padding_value=1.0)\n-\n-        processor = SpeechT5Processor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = SpeechT5Processor(\n+                tokenizer=self.get_tokenizer(), feature_extractor=self.get_feature_extractor()\n+            )\n+            processor.save_pretrained(tmpdir)\n+\n+            tokenizer_add_kwargs = SpeechT5Tokenizer.from_pretrained(tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            feature_extractor_add_kwargs = SpeechT5FeatureExtractor.from_pretrained(\n+                tmpdir, do_normalize=False, padding_value=1.0\n+            )\n+\n+            processor = SpeechT5Processor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, SpeechT5Tokenizer)"
        },
        {
            "sha": "e2d64aeb0ea07541e888da3fd57b241b2e87e5cd",
            "filename": "tests/models/trocr/test_processor_trocr.py",
            "status": "modified",
            "additions": 24,
            "deletions": 20,
            "changes": 44,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Ftrocr%2Ftest_processor_trocr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Ftrocr%2Ftest_processor_trocr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ftrocr%2Ftest_processor_trocr.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -27,21 +27,23 @@ class TrOCRProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     text_input_name = \"labels\"\n     processor_class = TrOCRProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         vocab_tokens = [\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\", \"want\", \"##want\", \"##ed\", \"wa\", \"un\", \"runn\", \"##ing\", \",\", \"low\", \"lowest\"]  # fmt: skip\n-        self.vocab_file = os.path.join(self.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n-        with open(self.vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n+        cls.vocab_file = os.path.join(cls.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n+        with open(cls.vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n             vocab_writer.write(\"\".join([x + \"\\n\" for x in vocab_tokens]))\n \n         image_processor = ViTImageProcessor.from_pretrained(\"hf-internal-testing/tiny-random-vit\")\n         tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n         processor = TrOCRProcessor(image_processor=image_processor, tokenizer=tokenizer)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def get_tokenizer(self, **kwargs):\n         return XLMRobertaTokenizerFast.from_pretrained(self.tmpdirname, **kwargs)\n@@ -50,27 +52,29 @@ def get_image_processor(self, **kwargs):\n         return ViTImageProcessor.from_pretrained(self.tmpdirname, **kwargs)\n \n     def test_save_load_pretrained_default(self):\n-        image_processor = self.get_image_processor()\n-        tokenizer = self.get_tokenizer()\n-        processor = TrOCRProcessor(image_processor=image_processor, tokenizer=tokenizer)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            image_processor = self.get_image_processor()\n+            tokenizer = self.get_tokenizer()\n+            processor = TrOCRProcessor(image_processor=image_processor, tokenizer=tokenizer)\n \n-        processor.save_pretrained(self.tmpdirname)\n-        processor = TrOCRProcessor.from_pretrained(self.tmpdirname)\n+            processor.save_pretrained(tmpdir)\n+            processor = TrOCRProcessor.from_pretrained(tmpdir)\n \n         self.assertIsInstance(processor.tokenizer, XLMRobertaTokenizerFast)\n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer.get_vocab())\n         self.assertIsInstance(processor.image_processor, ViTImageProcessor)\n         self.assertEqual(processor.image_processor.to_json_string(), image_processor.to_json_string())\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = TrOCRProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n-        processor.save_pretrained(self.tmpdirname)\n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n-\n-        processor = TrOCRProcessor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = TrOCRProcessor(tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor())\n+            processor.save_pretrained(tmpdir)\n+            tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n+\n+            processor = TrOCRProcessor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertIsInstance(processor.tokenizer, XLMRobertaTokenizerFast)\n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())"
        },
        {
            "sha": "ea08feea41e1b8b3d5c37a137f3235b063a1fdcf",
            "filename": "tests/models/udop/test_processor_udop.py",
            "status": "modified",
            "additions": 42,
            "deletions": 35,
            "changes": 77,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fudop%2Ftest_processor_udop.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fudop%2Ftest_processor_udop.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fudop%2Ftest_processor_udop.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -55,47 +55,53 @@ class UdopProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = UdopProcessor\n     maxDiff = None\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n         image_processor = LayoutLMv3ImageProcessor(\n             do_resize=True,\n             size=224,\n             apply_ocr=True,\n         )\n         tokenizer = UdopTokenizer.from_pretrained(\"microsoft/udop-large\")\n         processor = UdopProcessor(image_processor=image_processor, tokenizer=tokenizer)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-        self.tokenizer_pretrained_name = \"microsoft/udop-large\"\n+        cls.tokenizer_pretrained_name = \"microsoft/udop-large\"\n \n-        image_processor = self.get_image_processor()\n-        tokenizer = self.get_tokenizers()[0]\n+        image_processor = cls.get_image_processor()\n+        tokenizer = cls.get_tokenizers()[0]\n         processor = UdopProcessor(image_processor=image_processor, tokenizer=tokenizer)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-    def get_tokenizer(self, **kwargs) -> PreTrainedTokenizer:\n-        return self.tokenizer_class.from_pretrained(self.tokenizer_pretrained_name, **kwargs)\n+    @classmethod\n+    def get_tokenizer(cls, **kwargs) -> PreTrainedTokenizer:\n+        return cls.tokenizer_class.from_pretrained(cls.tokenizer_pretrained_name, **kwargs)\n \n-    def get_image_processor(self, **kwargs):\n-        return LayoutLMv3ImageProcessor.from_pretrained(self.tmpdirname, **kwargs)\n+    @classmethod\n+    def get_image_processor(cls, **kwargs):\n+        return LayoutLMv3ImageProcessor.from_pretrained(cls.tmpdirname, **kwargs)\n \n-    def get_rust_tokenizer(self, **kwargs) -> PreTrainedTokenizerFast:\n-        return self.rust_tokenizer_class.from_pretrained(self.tokenizer_pretrained_name, **kwargs)\n+    @classmethod\n+    def get_rust_tokenizer(cls, **kwargs) -> PreTrainedTokenizerFast:\n+        return cls.rust_tokenizer_class.from_pretrained(cls.tokenizer_pretrained_name, **kwargs)\n \n-    def get_tokenizers(self, **kwargs) -> list[PreTrainedTokenizerBase]:\n-        return [self.get_tokenizer(**kwargs), self.get_rust_tokenizer(**kwargs)]\n+    @classmethod\n+    def get_tokenizers(cls, **kwargs) -> list[PreTrainedTokenizerBase]:\n+        return [cls.get_tokenizer(**kwargs), cls.get_rust_tokenizer(**kwargs)]\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_default(self):\n         image_processor = self.get_image_processor()\n         tokenizers = self.get_tokenizers()\n         for tokenizer in tokenizers:\n             processor = UdopProcessor(image_processor=image_processor, tokenizer=tokenizer)\n-\n-            processor.save_pretrained(self.tmpdirname)\n-            processor = UdopProcessor.from_pretrained(self.tmpdirname)\n+            with tempfile.TemporaryDirectory() as tmpdir:\n+                processor.save_pretrained(tmpdir)\n+                processor = UdopProcessor.from_pretrained(tmpdir)\n \n             self.assertEqual(processor.tokenizer.get_vocab(), tokenizer.get_vocab())\n             self.assertIsInstance(processor.tokenizer, (UdopTokenizer, UdopTokenizerFast))\n@@ -104,21 +110,22 @@ def test_save_load_pretrained_default(self):\n             self.assertIsInstance(processor.image_processor, LayoutLMv3ImageProcessor)\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = UdopProcessor(image_processor=self.get_image_processor(), tokenizer=self.get_tokenizer())\n-        processor.save_pretrained(self.tmpdirname)\n-\n-        # slow tokenizer\n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_resize=False, size=30)\n-\n-        processor = UdopProcessor.from_pretrained(\n-            self.tmpdirname,\n-            use_fast=False,\n-            bos_token=\"(BOS)\",\n-            eos_token=\"(EOS)\",\n-            do_resize=False,\n-            size=30,\n-        )\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = UdopProcessor(image_processor=self.get_image_processor(), tokenizer=self.get_tokenizer())\n+            processor.save_pretrained(tmpdir)\n+\n+            # slow tokenizer\n+            tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = self.get_image_processor(do_resize=False, size=30)\n+\n+            processor = UdopProcessor.from_pretrained(\n+                tmpdir,\n+                use_fast=False,\n+                bos_token=\"(BOS)\",\n+                eos_token=\"(EOS)\",\n+                do_resize=False,\n+                size=30,\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, UdopTokenizer)"
        },
        {
            "sha": "fdae4bf8e1b03a8f8c997ea70cae2c3d1019789c",
            "filename": "tests/models/vision_text_dual_encoder/test_processor_vision_text_dual_encoder.py",
            "status": "modified",
            "additions": 35,
            "deletions": 30,
            "changes": 65,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fvision_text_dual_encoder%2Ftest_processor_vision_text_dual_encoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fvision_text_dual_encoder%2Ftest_processor_vision_text_dual_encoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvision_text_dual_encoder%2Ftest_processor_vision_text_dual_encoder.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -35,12 +35,13 @@\n class VisionTextDualEncoderProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = VisionTextDualEncoderProcessor\n \n-    def setUp(self):\n-        self.tmpdirname = tempfile.mkdtemp()\n+    @classmethod\n+    def setUpClass(cls):\n+        cls.tmpdirname = tempfile.mkdtemp()\n \n         vocab_tokens = [\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\", \"want\", \"##want\", \"##ed\", \"wa\", \"un\", \"runn\", \"##ing\", \",\", \"low\", \"lowest\"]  # fmt: skip\n-        self.vocab_file = os.path.join(self.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n-        with open(self.vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n+        cls.vocab_file = os.path.join(cls.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n+        with open(cls.vocab_file, \"w\", encoding=\"utf-8\") as vocab_writer:\n             vocab_writer.write(\"\".join([x + \"\\n\" for x in vocab_tokens]))\n \n         image_processor_map = {\n@@ -50,34 +51,37 @@ def setUp(self):\n             \"image_mean\": [0.5, 0.5, 0.5],\n             \"image_std\": [0.5, 0.5, 0.5],\n         }\n-        self.image_processor_file = os.path.join(self.tmpdirname, IMAGE_PROCESSOR_NAME)\n-        with open(self.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n+        cls.image_processor_file = os.path.join(cls.tmpdirname, IMAGE_PROCESSOR_NAME)\n+        with open(cls.image_processor_file, \"w\", encoding=\"utf-8\") as fp:\n             json.dump(image_processor_map, fp)\n \n-        tokenizer = self.get_tokenizer()\n-        image_processor = self.get_image_processor()\n+        tokenizer = cls.get_tokenizer()\n+        image_processor = cls.get_image_processor()\n         processor = VisionTextDualEncoderProcessor(tokenizer=tokenizer, image_processor=image_processor)\n-        processor.save_pretrained(self.tmpdirname)\n+        processor.save_pretrained(cls.tmpdirname)\n \n-    def get_tokenizer(self, **kwargs):\n-        return BertTokenizer.from_pretrained(self.tmpdirname, **kwargs)\n+    @classmethod\n+    def get_tokenizer(cls, **kwargs):\n+        return BertTokenizer.from_pretrained(cls.tmpdirname, **kwargs)\n \n-    def get_image_processor(self, **kwargs):\n+    @classmethod\n+    def get_image_processor(cls, **kwargs):\n         if is_torchvision_available():\n-            return ViTImageProcessorFast.from_pretrained(self.tmpdirname, **kwargs)\n-        return ViTImageProcessor.from_pretrained(self.tmpdirname, **kwargs)\n+            return ViTImageProcessorFast.from_pretrained(cls.tmpdirname, **kwargs)\n+        return ViTImageProcessor.from_pretrained(cls.tmpdirname, **kwargs)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_default(self):\n         tokenizer = self.get_tokenizer()\n         image_processor = self.get_image_processor()\n \n         processor = VisionTextDualEncoderProcessor(tokenizer=tokenizer, image_processor=image_processor)\n-\n-        processor.save_pretrained(self.tmpdirname)\n-        processor = VisionTextDualEncoderProcessor.from_pretrained(self.tmpdirname)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor.save_pretrained(tmpdir)\n+            processor = VisionTextDualEncoderProcessor.from_pretrained(tmpdir)\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer.get_vocab())\n         self.assertIsInstance(processor.tokenizer, (BertTokenizer, BertTokenizerFast))\n@@ -86,17 +90,18 @@ def test_save_load_pretrained_default(self):\n         self.assertIsInstance(processor.image_processor, (ViTImageProcessor, ViTImageProcessorFast))\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = VisionTextDualEncoderProcessor(\n-            tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor()\n-        )\n-        processor.save_pretrained(self.tmpdirname)\n-\n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n-\n-        processor = VisionTextDualEncoderProcessor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = VisionTextDualEncoderProcessor(\n+                tokenizer=self.get_tokenizer(), image_processor=self.get_image_processor()\n+            )\n+            processor.save_pretrained(tmpdir)\n+\n+            tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n+            image_processor_add_kwargs = self.get_image_processor(do_normalize=False, padding_value=1.0)\n+\n+            processor = VisionTextDualEncoderProcessor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, (BertTokenizer, BertTokenizerFast))"
        },
        {
            "sha": "400142168103bad40d8f37ce037bb96c234291f3",
            "filename": "tests/models/wav2vec2/test_processor_wav2vec2.py",
            "status": "modified",
            "additions": 36,
            "deletions": 25,
            "changes": 61,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fwav2vec2%2Ftest_processor_wav2vec2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fwav2vec2%2Ftest_processor_wav2vec2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwav2vec2%2Ftest_processor_wav2vec2.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -31,11 +31,12 @@ class Wav2Vec2ProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     audio_input_name = \"input_values\"\n     text_input_name = \"labels\"\n \n-    def setUp(self):\n+    @classmethod\n+    def setUpClass(cls):\n         vocab = \"<pad> <s> </s> <unk> | E T A O N I H S R D L U M W C F G Y P B V K ' X J Q Z\".split(\" \")\n         vocab_tokens = dict(zip(vocab, range(len(vocab))))\n \n-        self.add_kwargs_tokens_map = {\n+        cls.add_kwargs_tokens_map = {\n             \"pad_token\": \"<pad>\",\n             \"unk_token\": \"<unk>\",\n             \"bos_token\": \"<s>\",\n@@ -49,37 +50,40 @@ def setUp(self):\n             \"do_normalize\": True,\n         }\n \n-        self.tmpdirname = tempfile.mkdtemp()\n-        self.vocab_file = os.path.join(self.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n-        self.feature_extraction_file = os.path.join(self.tmpdirname, FEATURE_EXTRACTOR_NAME)\n-        with open(self.vocab_file, \"w\", encoding=\"utf-8\") as fp:\n+        cls.tmpdirname = tempfile.mkdtemp()\n+        cls.vocab_file = os.path.join(cls.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n+        cls.feature_extraction_file = os.path.join(cls.tmpdirname, FEATURE_EXTRACTOR_NAME)\n+        with open(cls.vocab_file, \"w\", encoding=\"utf-8\") as fp:\n             fp.write(json.dumps(vocab_tokens) + \"\\n\")\n \n-        with open(self.feature_extraction_file, \"w\", encoding=\"utf-8\") as fp:\n+        with open(cls.feature_extraction_file, \"w\", encoding=\"utf-8\") as fp:\n             fp.write(json.dumps(feature_extractor_map) + \"\\n\")\n \n-        tokenizer = self.get_tokenizer()\n-        tokenizer.save_pretrained(self.tmpdirname)\n+        tokenizer = cls.get_tokenizer()\n+        tokenizer.save_pretrained(cls.tmpdirname)\n \n-    def get_tokenizer(self, **kwargs_init):\n-        kwargs = self.add_kwargs_tokens_map.copy()\n+    @classmethod\n+    def get_tokenizer(cls, **kwargs_init):\n+        kwargs = cls.add_kwargs_tokens_map.copy()\n         kwargs.update(kwargs_init)\n-        return Wav2Vec2CTCTokenizer.from_pretrained(self.tmpdirname, **kwargs)\n+        return Wav2Vec2CTCTokenizer.from_pretrained(cls.tmpdirname, **kwargs)\n \n     def get_feature_extractor(self, **kwargs):\n         return Wav2Vec2FeatureExtractor.from_pretrained(self.tmpdirname, **kwargs)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_default(self):\n         tokenizer = self.get_tokenizer()\n         feature_extractor = self.get_feature_extractor()\n \n         processor = Wav2Vec2Processor(tokenizer=tokenizer, feature_extractor=feature_extractor)\n \n-        processor.save_pretrained(self.tmpdirname)\n-        processor = Wav2Vec2Processor.from_pretrained(self.tmpdirname)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor.save_pretrained(tmpdir)\n+            processor = Wav2Vec2Processor.from_pretrained(tmpdir)\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer.get_vocab())\n         self.assertIsInstance(processor.tokenizer, Wav2Vec2CTCTokenizer)\n@@ -88,15 +92,22 @@ def test_save_load_pretrained_default(self):\n         self.assertIsInstance(processor.feature_extractor, Wav2Vec2FeatureExtractor)\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = Wav2Vec2Processor(tokenizer=self.get_tokenizer(), feature_extractor=self.get_feature_extractor())\n-        processor.save_pretrained(self.tmpdirname)\n-\n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        feature_extractor_add_kwargs = self.get_feature_extractor(do_normalize=False, padding_value=1.0)\n-\n-        processor = Wav2Vec2Processor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = Wav2Vec2Processor(\n+                tokenizer=self.get_tokenizer(), feature_extractor=self.get_feature_extractor()\n+            )\n+            processor.save_pretrained(tmpdir)\n+\n+            tokenizer_add_kwargs = Wav2Vec2CTCTokenizer.from_pretrained(\n+                tmpdir, **(self.add_kwargs_tokens_map | {\"bos_token\": \"(BOS)\", \"eos_token\": \"(EOS)\"})\n+            )\n+            feature_extractor_add_kwargs = Wav2Vec2FeatureExtractor.from_pretrained(\n+                tmpdir, do_normalize=False, padding_value=1.0\n+            )\n+\n+            processor = Wav2Vec2Processor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, Wav2Vec2CTCTokenizer)"
        },
        {
            "sha": "c269e15db32f5cf3fc780782c3c0d2aafa75784e",
            "filename": "tests/models/wav2vec2_bert/test_processor_wav2vec2_bert.py",
            "status": "modified",
            "additions": 36,
            "deletions": 27,
            "changes": 63,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fwav2vec2_bert%2Ftest_processor_wav2vec2_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Fmodels%2Fwav2vec2_bert%2Ftest_processor_wav2vec2_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwav2vec2_bert%2Ftest_processor_wav2vec2_bert.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -32,11 +32,12 @@ class Wav2Vec2BertProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     processor_class = Wav2Vec2BertProcessor\n     text_input_name = \"labels\"\n \n-    def setUp(self):\n+    @classmethod\n+    def setUpClass(cls):\n         vocab = \"<pad> <s> </s> <unk> | E T A O N I H S R D L U M W C F G Y P B V K ' X J Q Z\".split(\" \")\n         vocab_tokens = dict(zip(vocab, range(len(vocab))))\n \n-        self.add_kwargs_tokens_map = {\n+        cls.add_kwargs_tokens_map = {\n             \"pad_token\": \"<pad>\",\n             \"unk_token\": \"<unk>\",\n             \"bos_token\": \"<s>\",\n@@ -50,37 +51,40 @@ def setUp(self):\n             \"do_normalize\": True,\n         }\n \n-        self.tmpdirname = tempfile.mkdtemp()\n-        self.vocab_file = os.path.join(self.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n-        self.feature_extraction_file = os.path.join(self.tmpdirname, FEATURE_EXTRACTOR_NAME)\n-        with open(self.vocab_file, \"w\", encoding=\"utf-8\") as fp:\n+        cls.tmpdirname = tempfile.mkdtemp()\n+        cls.vocab_file = os.path.join(cls.tmpdirname, VOCAB_FILES_NAMES[\"vocab_file\"])\n+        cls.feature_extraction_file = os.path.join(cls.tmpdirname, FEATURE_EXTRACTOR_NAME)\n+        with open(cls.vocab_file, \"w\", encoding=\"utf-8\") as fp:\n             fp.write(json.dumps(vocab_tokens) + \"\\n\")\n \n-        with open(self.feature_extraction_file, \"w\", encoding=\"utf-8\") as fp:\n+        with open(cls.feature_extraction_file, \"w\", encoding=\"utf-8\") as fp:\n             fp.write(json.dumps(feature_extractor_map) + \"\\n\")\n \n-        tokenizer = self.get_tokenizer()\n-        tokenizer.save_pretrained(self.tmpdirname)\n+        tokenizer = cls.get_tokenizer()\n+        tokenizer.save_pretrained(cls.tmpdirname)\n \n-    def get_tokenizer(self, **kwargs_init):\n-        kwargs = self.add_kwargs_tokens_map.copy()\n+    @classmethod\n+    def get_tokenizer(cls, **kwargs_init):\n+        kwargs = cls.add_kwargs_tokens_map.copy()\n         kwargs.update(kwargs_init)\n-        return Wav2Vec2CTCTokenizer.from_pretrained(self.tmpdirname, **kwargs)\n+        return Wav2Vec2CTCTokenizer.from_pretrained(cls.tmpdirname, **kwargs)\n \n     def get_feature_extractor(self, **kwargs):\n         return SeamlessM4TFeatureExtractor.from_pretrained(self.tmpdirname, **kwargs)\n \n-    def tearDown(self):\n-        shutil.rmtree(self.tmpdirname)\n+    @classmethod\n+    def tearDownClass(cls):\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def test_save_load_pretrained_default(self):\n         tokenizer = self.get_tokenizer()\n         feature_extractor = self.get_feature_extractor()\n \n         processor = Wav2Vec2BertProcessor(tokenizer=tokenizer, feature_extractor=feature_extractor)\n \n-        processor.save_pretrained(self.tmpdirname)\n-        processor = Wav2Vec2BertProcessor.from_pretrained(self.tmpdirname)\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor.save_pretrained(tmpdir)\n+            processor = Wav2Vec2BertProcessor.from_pretrained(tmpdir)\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer.get_vocab())\n         self.assertIsInstance(processor.tokenizer, Wav2Vec2CTCTokenizer)\n@@ -89,17 +93,22 @@ def test_save_load_pretrained_default(self):\n         self.assertIsInstance(processor.feature_extractor, SeamlessM4TFeatureExtractor)\n \n     def test_save_load_pretrained_additional_features(self):\n-        processor = Wav2Vec2BertProcessor(\n-            tokenizer=self.get_tokenizer(), feature_extractor=self.get_feature_extractor()\n-        )\n-        processor.save_pretrained(self.tmpdirname)\n-\n-        tokenizer_add_kwargs = self.get_tokenizer(bos_token=\"(BOS)\", eos_token=\"(EOS)\")\n-        feature_extractor_add_kwargs = self.get_feature_extractor(do_normalize=False, padding_value=1.0)\n-\n-        processor = Wav2Vec2BertProcessor.from_pretrained(\n-            self.tmpdirname, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n-        )\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            processor = Wav2Vec2BertProcessor(\n+                tokenizer=self.get_tokenizer(), feature_extractor=self.get_feature_extractor()\n+            )\n+            processor.save_pretrained(tmpdir)\n+\n+            tokenizer_add_kwargs = Wav2Vec2CTCTokenizer.from_pretrained(\n+                tmpdir, **(self.add_kwargs_tokens_map | {\"bos_token\": \"(BOS)\", \"eos_token\": \"(EOS)\"})\n+            )\n+            feature_extractor_add_kwargs = SeamlessM4TFeatureExtractor.from_pretrained(\n+                tmpdir, do_normalize=False, padding_value=1.0\n+            )\n+\n+            processor = Wav2Vec2BertProcessor.from_pretrained(\n+                tmpdir, bos_token=\"(BOS)\", eos_token=\"(EOS)\", do_normalize=False, padding_value=1.0\n+            )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n         self.assertIsInstance(processor.tokenizer, Wav2Vec2CTCTokenizer)"
        },
        {
            "sha": "5e35d46aca845bd2618116c7fd4dac685280a0be",
            "filename": "tests/test_tokenization_common.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Ftest_tokenization_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4d0de5f73a0715ac9a63de5fa461af48d3abbb10/tests%2Ftest_tokenization_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_tokenization_common.py?ref=4d0de5f73a0715ac9a63de5fa461af48d3abbb10",
            "patch": "@@ -259,7 +259,7 @@ def setUpClass(cls) -> None:\n \n     @classmethod\n     def tearDownClass(cls):\n-        shutil.rmtree(cls.tmpdirname)\n+        shutil.rmtree(cls.tmpdirname, ignore_errors=True)\n \n     def get_input_output_texts(self, tokenizer):\n         input_txt = self.get_clean_sequence(tokenizer)[0]"
        }
    ],
    "stats": {
        "total": 1364,
        "additions": 765,
        "deletions": 599
    }
}