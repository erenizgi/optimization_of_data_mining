{
    "author": "zucchini-nlp",
    "message": "[idefics3] fix for vLLM (#39470)\n\n* fix idefics3 for vllm tests\n\n* fix copies",
    "sha": "e7e6efcbbdaaddae9ac732240659dff8fcdce397",
    "files": [
        {
            "sha": "65ad87dae43b866f36e3ba677fe4ed3025119bf0",
            "filename": "src/transformers/models/idefics3/image_processing_idefics3.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7e6efcbbdaaddae9ac732240659dff8fcdce397/src%2Ftransformers%2Fmodels%2Fidefics3%2Fimage_processing_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7e6efcbbdaaddae9ac732240659dff8fcdce397/src%2Ftransformers%2Fmodels%2Fidefics3%2Fimage_processing_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics3%2Fimage_processing_idefics3.py?ref=e7e6efcbbdaaddae9ac732240659dff8fcdce397",
            "patch": "@@ -870,6 +870,7 @@ def get_number_of_image_patches(self, height: int, width: int, images_kwargs=Non\n         max_image_size = images_kwargs.get(\"max_image_size\", None) or self.max_image_size\n         size = images_kwargs.get(\"size\", None) or self.size\n \n+        num_patches = num_rows = num_cols = 1\n         if do_image_splitting:\n             height, width = _resize_output_size_rescale_to_max_len(height, width, max_len=size[\"longest_edge\"])\n             height, width = _resize_output_size_scale_below_upper_bound(height, width, max_len=4096)\n@@ -891,7 +892,7 @@ def get_number_of_image_patches(self, height: int, width: int, images_kwargs=Non\n                 num_cols = math.ceil(resized_width / max_width)\n                 num_patches = num_rows * num_cols + 1\n \n-        return num_patches\n+        return num_patches, num_rows, num_cols\n \n \n __all__ = [\"Idefics3ImageProcessor\"]"
        },
        {
            "sha": "8fdef6e378e5bfad6f418dfb42ae5572b9322e37",
            "filename": "src/transformers/models/idefics3/image_processing_idefics3_fast.py",
            "status": "modified",
            "additions": 42,
            "deletions": 0,
            "changes": 42,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7e6efcbbdaaddae9ac732240659dff8fcdce397/src%2Ftransformers%2Fmodels%2Fidefics3%2Fimage_processing_idefics3_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7e6efcbbdaaddae9ac732240659dff8fcdce397/src%2Ftransformers%2Fmodels%2Fidefics3%2Fimage_processing_idefics3_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics3%2Fimage_processing_idefics3_fast.py?ref=e7e6efcbbdaaddae9ac732240659dff8fcdce397",
            "patch": "@@ -500,5 +500,47 @@ def to_dict(self):\n         encoder_dict.pop(\"return_row_col_info\", None)\n         return encoder_dict\n \n+    def get_number_of_image_patches(self, height: int, width: int, images_kwargs=None):\n+        \"\"\"\n+        A utility that returns number of image patches for a given image size.\n+\n+        Args:\n+            height (`int`):\n+                Height of the input image.\n+            width (`int`):\n+                Width of the input image.\n+            images_kwargs (`dict`, *optional*)\n+                Any kwargs to override defaults of the image processor.\n+        Returns:\n+            `int`: Number of patches per image.\n+        \"\"\"\n+        do_image_splitting = images_kwargs.get(\"do_image_splitting\", None) or self.do_image_splitting\n+        max_image_size = images_kwargs.get(\"max_image_size\", None) or self.max_image_size\n+        size = images_kwargs.get(\"size\", None) or self.size\n+\n+        num_patches = num_rows = num_cols = 1\n+        if do_image_splitting:\n+            height, width = _resize_output_size_rescale_to_max_len(height, width, max_len=size[\"longest_edge\"])\n+            height, width = _resize_output_size_scale_below_upper_bound(height, width, max_len=MAX_IMAGE_SIZE)\n+            aspect_ratio = width / height\n+\n+            if width >= height:\n+                resized_width = math.ceil(width / max_image_size[\"longest_edge\"]) * max_image_size[\"longest_edge\"]\n+                resized_height = int(width / aspect_ratio)\n+                resized_height = math.ceil(height / max_image_size[\"longest_edge\"]) * max_image_size[\"longest_edge\"]\n+            elif height > width:\n+                resized_height = math.ceil(height / max_image_size[\"longest_edge\"]) * max_image_size[\"longest_edge\"]\n+                resized_width = int(height * aspect_ratio)\n+                resized_width = math.ceil(width / max_image_size[\"longest_edge\"]) * max_image_size[\"longest_edge\"]\n+\n+            max_height = max_width = max_image_size[\"longest_edge\"]\n+            if resized_height > max_height or resized_width > max_width:\n+                # Calculate the number of splits\n+                num_rows = math.ceil(resized_height / max_height)\n+                num_cols = math.ceil(resized_width / max_width)\n+                num_patches = num_rows * num_cols + 1\n+\n+        return num_patches, num_rows, num_cols\n+\n \n __all__ = [\"Idefics3ImageProcessorFast\"]"
        },
        {
            "sha": "5f590faeeb9ad64f3662dafcb923cbed2641050a",
            "filename": "src/transformers/models/idefics3/processing_idefics3.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7e6efcbbdaaddae9ac732240659dff8fcdce397/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7e6efcbbdaaddae9ac732240659dff8fcdce397/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py?ref=e7e6efcbbdaaddae9ac732240659dff8fcdce397",
            "patch": "@@ -16,7 +16,6 @@\n Processor class for Idefics3.\n \"\"\"\n \n-import math\n import re\n from itertools import accumulate\n from typing import TYPE_CHECKING, Optional, Union\n@@ -390,19 +389,20 @@ def _get_num_multimodal_tokens(self, image_sizes=None, **kwargs):\n             images_kwargs = Idefics3ProcessorKwargs._defaults.get(\"images_kwargs\", {})\n             images_kwargs.update(kwargs)\n \n-            num_image_patches = [\n+            num_image_row_cols = [\n                 self.image_processor.get_number_of_image_patches(*image_size, images_kwargs)\n                 for image_size in image_sizes\n             ]\n \n             base_image_length = self.image_seq_len + 3\n             col_length = self.image_seq_len + 2\n             num_image_tokens = []\n+            num_image_patches = []\n \n-            for num_patches in num_image_patches:\n-                num_cols = num_rows = int(math.sqrt(num_patches - 1))\n+            for num_patches, num_rows, num_cols in num_image_row_cols:\n                 row_length = col_length * num_cols + 1\n                 num_image_tokens.append(base_image_length + (row_length * num_rows))\n+                num_image_patches.append(num_patches)\n \n             vision_data.update({\"num_image_tokens\": num_image_tokens, \"num_image_patches\": num_image_patches})\n "
        },
        {
            "sha": "431a6f32bb2a8158c8ed1a4a4249e2c3ac90053c",
            "filename": "src/transformers/models/smolvlm/image_processing_smolvlm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7e6efcbbdaaddae9ac732240659dff8fcdce397/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fimage_processing_smolvlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7e6efcbbdaaddae9ac732240659dff8fcdce397/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fimage_processing_smolvlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fimage_processing_smolvlm.py?ref=e7e6efcbbdaaddae9ac732240659dff8fcdce397",
            "patch": "@@ -867,6 +867,7 @@ def get_number_of_image_patches(self, height: int, width: int, images_kwargs=Non\n         max_image_size = images_kwargs.get(\"max_image_size\", None) or self.max_image_size\n         size = images_kwargs.get(\"size\", None) or self.size\n \n+        num_patches = num_rows = num_cols = 1\n         if do_image_splitting:\n             height, width = _resize_output_size_rescale_to_max_len(height, width, max_len=size[\"longest_edge\"])\n             height, width = _resize_output_size_scale_below_upper_bound(height, width, max_len=4096)\n@@ -888,7 +889,7 @@ def get_number_of_image_patches(self, height: int, width: int, images_kwargs=Non\n                 num_cols = math.ceil(resized_width / max_width)\n                 num_patches = num_rows * num_cols + 1\n \n-        return num_patches\n+        return num_patches, num_rows, num_cols\n \n \n __all__ = [\"SmolVLMImageProcessor\"]"
        },
        {
            "sha": "1cfca313068765fdb688c41ec90cba0e627b4452",
            "filename": "src/transformers/models/smolvlm/image_processing_smolvlm_fast.py",
            "status": "modified",
            "additions": 42,
            "deletions": 0,
            "changes": 42,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7e6efcbbdaaddae9ac732240659dff8fcdce397/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fimage_processing_smolvlm_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7e6efcbbdaaddae9ac732240659dff8fcdce397/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fimage_processing_smolvlm_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fimage_processing_smolvlm_fast.py?ref=e7e6efcbbdaaddae9ac732240659dff8fcdce397",
            "patch": "@@ -490,5 +490,47 @@ def to_dict(self):\n         encoder_dict.pop(\"return_row_col_info\", None)\n         return encoder_dict\n \n+    def get_number_of_image_patches(self, height: int, width: int, images_kwargs=None):\n+        \"\"\"\n+        A utility that returns number of image patches for a given image size.\n+\n+        Args:\n+            height (`int`):\n+                Height of the input image.\n+            width (`int`):\n+                Width of the input image.\n+            images_kwargs (`dict`, *optional*)\n+                Any kwargs to override defaults of the image processor.\n+        Returns:\n+            `int`: Number of patches per image.\n+        \"\"\"\n+        do_image_splitting = images_kwargs.get(\"do_image_splitting\", None) or self.do_image_splitting\n+        max_image_size = images_kwargs.get(\"max_image_size\", None) or self.max_image_size\n+        size = images_kwargs.get(\"size\", None) or self.size\n+\n+        num_patches = num_rows = num_cols = 1\n+        if do_image_splitting:\n+            height, width = _resize_output_size_rescale_to_max_len(height, width, max_len=size[\"longest_edge\"])\n+            height, width = _resize_output_size_scale_below_upper_bound(height, width, max_len=MAX_IMAGE_SIZE)\n+            aspect_ratio = width / height\n+\n+            if width >= height:\n+                resized_width = math.ceil(width / max_image_size[\"longest_edge\"]) * max_image_size[\"longest_edge\"]\n+                resized_height = int(width / aspect_ratio)\n+                resized_height = math.ceil(height / max_image_size[\"longest_edge\"]) * max_image_size[\"longest_edge\"]\n+            elif height > width:\n+                resized_height = math.ceil(height / max_image_size[\"longest_edge\"]) * max_image_size[\"longest_edge\"]\n+                resized_width = int(height * aspect_ratio)\n+                resized_width = math.ceil(width / max_image_size[\"longest_edge\"]) * max_image_size[\"longest_edge\"]\n+\n+            max_height = max_width = max_image_size[\"longest_edge\"]\n+            if resized_height > max_height or resized_width > max_width:\n+                # Calculate the number of splits\n+                num_rows = math.ceil(resized_height / max_height)\n+                num_cols = math.ceil(resized_width / max_width)\n+                num_patches = num_rows * num_cols + 1\n+\n+        return num_patches, num_rows, num_cols\n+\n \n __all__ = [\"SmolVLMImageProcessorFast\"]"
        }
    ],
    "stats": {
        "total": 98,
        "additions": 92,
        "deletions": 6
    }
}