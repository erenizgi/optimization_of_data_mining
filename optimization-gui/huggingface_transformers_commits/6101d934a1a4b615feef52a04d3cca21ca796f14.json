{
    "author": "newfull5",
    "message": "ğŸŒ [i18n-KO] Translated `conversations.md` to Korean (#32468)\n\n* docs: ko: conversations.md\r\n\r\n* feat: hand-crafted translate docs\r\n\r\n* fix: modify typo after Grammar Check\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nê°ì‚¬í•©ë‹ˆë‹¤\r\n\r\nCo-authored-by: SeungAhSon <gongsoonyee@gmail.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: SeungAhSon <gongsoonyee@gmail.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: SeungAhSon <gongsoonyee@gmail.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: SeungAhSon <gongsoonyee@gmail.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: SeungAhSon <gongsoonyee@gmail.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: SeungAhSon <gongsoonyee@gmail.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: SeungAhSon <gongsoonyee@gmail.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: SeungAhSon <gongsoonyee@gmail.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: SeungAhSon <gongsoonyee@gmail.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: SeungAhSon <gongsoonyee@gmail.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: SeungAhSon <gongsoonyee@gmail.com>\r\n\r\n* fix: accept suggestions about anchor and spacing\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: Jihun Lim <31366038+heuristicwave@users.noreply.github.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: Jihun Lim <31366038+heuristicwave@users.noreply.github.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: Jihun Lim <31366038+heuristicwave@users.noreply.github.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: Jihun Lim <31366038+heuristicwave@users.noreply.github.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: Jihun Lim <31366038+heuristicwave@users.noreply.github.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: Jihun Lim <31366038+heuristicwave@users.noreply.github.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: Sungmin Oh <fabxoe.kor@gmail.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: Sungmin Oh <fabxoe.kor@gmail.com>\r\n\r\n* Update docs/source/ko/conversations.md\r\n\r\nCo-authored-by: Sungmin Oh <fabxoe.kor@gmail.com>\r\n\r\n* fix: anchor 'what happened inside piepeline?' be removed question mark\r\n\r\n* fix: translate the comments in the code block\r\n\r\n---------\r\n\r\nCo-authored-by: SeungAhSon <gongsoonyee@gmail.com>\r\nCo-authored-by: Jihun Lim <31366038+heuristicwave@users.noreply.github.com>\r\nCo-authored-by: Sungmin Oh <fabxoe.kor@gmail.com>",
    "sha": "6101d934a1a4b615feef52a04d3cca21ca796f14",
    "files": [
        {
            "sha": "b128c13c2dc187ac2a491a37f21308293915fc71",
            "filename": "docs/source/ko/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/6101d934a1a4b615feef52a04d3cca21ca796f14/docs%2Fsource%2Fko%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/6101d934a1a4b615feef52a04d3cca21ca796f14/docs%2Fsource%2Fko%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2F_toctree.yml?ref=6101d934a1a4b615feef52a04d3cca21ca796f14",
            "patch": "@@ -27,8 +27,8 @@\n     title: ì—ì´ì „íŠ¸\n   - local: llm_tutorial\n     title: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë¡œ ìƒì„±í•˜ê¸°\n-  - local: in_translation\n-    title: (ë²ˆì—­ì¤‘)Chatting with Transformers\n+  - local: conversations\n+    title: Transformersë¡œ ì±„íŒ…í•˜ê¸°\n   title: íŠœí† ë¦¬ì–¼\n - sections:\n   - isExpanded: false"
        },
        {
            "sha": "920cb1387860865e6f01ff47b79c50a2e9c4bea3",
            "filename": "docs/source/ko/conversations.md",
            "status": "added",
            "additions": 306,
            "deletions": 0,
            "changes": 306,
            "blob_url": "https://github.com/huggingface/transformers/blob/6101d934a1a4b615feef52a04d3cca21ca796f14/docs%2Fsource%2Fko%2Fconversations.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/6101d934a1a4b615feef52a04d3cca21ca796f14/docs%2Fsource%2Fko%2Fconversations.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fconversations.md?ref=6101d934a1a4b615feef52a04d3cca21ca796f14",
            "patch": "@@ -0,0 +1,306 @@\n+<!--Copyright 2024 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n+\n+âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+\n+# Transformersë¡œ ì±„íŒ…í•˜ê¸°[[chatting-with-transformers]]\n+\n+ì´ ê¸€ì„ ë³´ê³  ìˆë‹¤ë©´ **ì±„íŒ… ëª¨ë¸**ì— ëŒ€í•´ ì–´ëŠ ì •ë„ ì•Œê³  ê³„ì‹¤ ê²ƒì…ë‹ˆë‹¤.\n+ì±„íŒ… ëª¨ë¸ì´ë€ ë©”ì„¸ì§€ë¥¼ ì£¼ê³ ë°›ì„ ìˆ˜ ìˆëŠ” ëŒ€í™”í˜• ì¸ê³µì§€ëŠ¥ì…ë‹ˆë‹¤. \n+ëŒ€í‘œì ìœ¼ë¡œ ChatGPTê°€ ìˆê³ , ì´ì™€ ë¹„ìŠ·í•˜ê±°ë‚˜ ë” ë›°ì–´ë‚œ ì˜¤í”ˆì†ŒìŠ¤ ì±„íŒ… ëª¨ë¸ì´ ë§ì´ ì¡´ì¬í•©ë‹ˆë‹¤.  \n+ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ ë¬´ë£Œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìœ¼ë©°, ë¡œì»¬ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n+í¬ê³  ë¬´ê±°ìš´ ëª¨ë¸ì€ ê³ ì„±ëŠ¥ í•˜ë“œì›¨ì–´ì™€ ë©”ëª¨ë¦¬ê°€ í•„ìš”í•˜ì§€ë§Œ, \n+ì €ì‚¬ì–‘ GPU í˜¹ì€ ì¼ë°˜ ë°ìŠ¤í¬íƒ‘ì´ë‚˜ ë…¸íŠ¸ë¶ CPUì—ì„œë„ ì˜ ì‘ë™í•˜ëŠ” ì†Œí˜• ëª¨ë¸ë“¤ë„ ìˆìŠµë‹ˆë‹¤.\n+\n+ì´ ê°€ì´ë“œëŠ” ì±„íŒ… ëª¨ë¸ì„ ì²˜ìŒ ì‚¬ìš©í•˜ëŠ” ë¶„ë“¤ì—ê²Œ ìœ ìš©í•  ê²ƒì…ë‹ˆë‹¤.\n+ìš°ë¦¬ëŠ” ê°„í¸í•œ ê³ ìˆ˜ì¤€(High-Level) \"pipeline\"ì„ í†µí•´ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œë¥¼ ì§„í–‰í•  ê²ƒì…ë‹ˆë‹¤.\n+ê°€ì´ë“œì—ëŠ” ì±„íŒ… ëª¨ë¸ì„ ë°”ë¡œ ì‹œì‘í•  ë•Œ í•„ìš”í•œ ëª¨ë“  ì •ë³´ê°€ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.\n+ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ ì´í›„ì—ëŠ” ì±„íŒ… ëª¨ë¸ì´ ì •í™•íˆ ë¬´ì—‡ì¸ì§€, ì ì ˆí•œ ëª¨ë¸ì„ ì„ íƒí•˜ëŠ” ë°©ë²•ê³¼, \n+ì±„íŒ… ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê° ë‹¨ê³„ì˜ ì €ìˆ˜ì¤€(Low-Level) ë¶„ì„ ë“± ë” ìì„¸í•œ ì •ë³´ë¥¼ ë‹¤ë£° ê²ƒì…ë‹ˆë‹¤. \n+ë˜í•œ ì±„íŒ… ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ìµœì í™”í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ íŒë„ ì œê³µí•  ê²ƒì…ë‹ˆë‹¤.\n+\n+\n+## ë¹ ë¥¸ ì‹œì‘[[quickstart]]\n+\n+ìì„¸íˆ ë³¼ ì—¬ìœ ê°€ ì—†ëŠ” ë¶„ë“¤ì„ ìœ„í•´ ê°„ë‹¨íˆ ìš”ì•½í•´ ë³´ê² ìŠµë‹ˆë‹¤: \n+ì±„íŒ… ëª¨ë¸ì€ ëŒ€í™” ë©”ì„¸ì§€ë¥¼ ê³„ì†í•´ì„œ ìƒì„±í•´ ë‚˜ê°‘ë‹ˆë‹¤.\n+ì¦‰, ì§¤ë§‰í•œ ì±„íŒ… ë©”ì„¸ì§€ë¥¼ ëª¨ë¸ì—ê²Œ ì „ë‹¬í•˜ë©´, ëª¨ë¸ì€ ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µì„ ì¶”ê°€í•˜ë©° ëŒ€í™”ë¥¼ ì´ì–´ ë‚˜ê°‘ë‹ˆë‹¤.\n+ì´ì œ ì‹¤ì œë¡œ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. \n+ë¨¼ì €, ì±„íŒ…ì„ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤:\n+\n+\n+```python\n+chat = [\n+    {\"role\": \"system\", \"content\": \"You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986.\"},\n+    {\"role\": \"user\", \"content\": \"Hey, can you tell me any fun things to do in New York?\"}\n+]\n+```\n+\n+ì£¼ëª©í•˜ì„¸ìš”, ëŒ€í™”ë¥¼ ì²˜ìŒ ì‹œì‘í•  ë•Œ ìœ ì € ë©”ì„¸ì§€ ì´ì™¸ì˜ë„, ë³„ë„ì˜ **ì‹œìŠ¤í…œ** ë©”ì„¸ì§€ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+ëª¨ë“  ì±„íŒ… ëª¨ë¸ì´ ì‹œìŠ¤í…œ ë©”ì„¸ì§€ë¥¼ ì§€ì›í•˜ëŠ” ê²ƒì€ ì•„ë‹ˆì§€ë§Œ,\n+ì§€ì›í•˜ëŠ” ê²½ìš°ì—ëŠ” ì‹œìŠ¤í…œ ë©”ì„¸ì§€ëŠ” ëŒ€í™”ì—ì„œ ëª¨ë¸ì´ ì–´ë–»ê²Œ í–‰ë™í•´ì•¼ í•˜ëŠ”ì§€ë¥¼ ì§€ì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+ì˜ˆë¥¼ ë“¤ì–´, ìœ ì¾Œí•˜ê±°ë‚˜ ì§„ì§€í•˜ê³ ì í•  ë•Œ, ì§§ì€ ë‹µë³€ì´ë‚˜ ê¸´ ë‹µë³€ì„ ì›í•  ë•Œ ë“±ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+ì‹œìŠ¤í…œ ë©”ì„¸ì§€ë¥¼ ìƒëµí•˜ê³ \n+\"You are a helpful and intelligent AI assistant who responds to user queries.\"\n+ì™€ ê°™ì€ ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n+\n+ì±„íŒ…ì„ ì‹œì‘í–ˆë‹¤ë©´ ëŒ€í™”ë¥¼ ì´ì–´ ë‚˜ê°€ëŠ” ê°€ì¥ ë¹ ë¥¸ ë°©ë²•ì€ [`TextGenerationPipeline`]ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. \n+í•œë²ˆ `LLaMA-3`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ ì‹œì—°í•´ ë³´ê² ìŠµë‹ˆë‹¤. \n+ìš°ì„  `LLaMA-3`ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤. [ê¶Œí•œ ì‹ ì²­](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)ì„ í•˜ê³  Hugging Face ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í•œ í›„ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n+ë˜í•œ ìš°ë¦¬ëŠ” `device_map=\"auto\"`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•˜ë‹¤ë©´ ë¡œë“œë  ê²ƒì…ë‹ˆë‹¤. \n+ê·¸ë¦¬ê³  ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ dtypeì„ `torch.bfloat16`ìœ¼ë¡œ ì„¤ì •í•  ê²ƒì…ë‹ˆë‹¤.\n+\n+```python\n+import torch\n+from transformers import pipeline\n+\n+pipe = pipeline(\"text-generation\", \"meta-llama/Meta-Llama-3-8B-Instruct\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n+response = pipe(chat, max_new_tokens=512)\n+print(response[0]['generated_text'][-1]['content'])\n+```\n+\n+ì´í›„ ì‹¤í–‰ì„ í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ì¶œë ¥ë©ë‹ˆë‹¤:\n+\n+```text\n+(sigh) Oh boy, you're asking me for advice? You're gonna need a map, pal! Alright, \n+alright, I'll give you the lowdown. But don't say I didn't warn you, I'm a robot, not a tour guide!\n+\n+So, you wanna know what's fun to do in the Big Apple? Well, let me tell you, there's a million \n+things to do, but I'll give you the highlights. First off, you gotta see the sights: the Statue of \n+Liberty, Central Park, Times Square... you know, the usual tourist traps. But if you're lookin' for \n+something a little more... unusual, I'd recommend checkin' out the Museum of Modern Art. It's got \n+some wild stuff, like that Warhol guy's soup cans and all that jazz.\n+\n+And if you're feelin' adventurous, take a walk across the Brooklyn Bridge. Just watch out for \n+those pesky pigeons, they're like little feathered thieves! (laughs) Get it? Thieves? Ah, never mind.\n+\n+Now, if you're lookin' for some serious fun, hit up the comedy clubs in Greenwich Village. You might \n+even catch a glimpse of some up-and-coming comedians... or a bunch of wannabes tryin' to make it big. (winks)\n+\n+And finally, if you're feelin' like a real New Yorker, grab a slice of pizza from one of the many amazing\n+pizzerias around the city. Just don't try to order a \"robot-sized\" slice, trust me, it won't end well. (laughs)\n+\n+So, there you have it, pal! That's my expert advice on what to do in New York. Now, if you'll\n+excuse me, I've got some oil changes to attend to. (winks)\n+```\n+\n+ì±„íŒ…ì„ ê³„ì†í•˜ë ¤ë©´, ìì‹ ì˜ ë‹µì¥ì„ ì¶”ê°€í•˜ë©´ ë©ë‹ˆë‹¤. \n+íŒŒì´í”„ë¼ì¸ì—ì„œ ë°˜í™˜ëœ `response` ê°ì²´ì—ëŠ” í˜„ì¬ê¹Œì§€ ëª¨ë“  ì±„íŒ…ì„ í¬í•¨í•˜ê³  ìˆìœ¼ë¯€ë¡œ \n+ë©”ì„¸ì§€ë¥¼ ì¶”ê°€í•˜ê³  ë‹¤ì‹œ ì „ë‹¬í•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.\n+\n+```python\n+chat = response[0]['generated_text']\n+chat.append(\n+    {\"role\": \"user\", \"content\": \"Wait, what's so wild about soup cans?\"}\n+)\n+response = pipe(chat, max_new_tokens=512)\n+print(response[0]['generated_text'][-1]['content'])\n+```\n+\n+ì´í›„ ì‹¤í–‰ì„ í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ì¶œë ¥ë©ë‹ˆë‹¤:\n+\n+```text\n+(laughs) Oh, you're killin' me, pal! You don't get it, do you? Warhol's soup cans are like, art, man! \n+It's like, he took something totally mundane, like a can of soup, and turned it into a masterpiece. It's \n+like, \"Hey, look at me, I'm a can of soup, but I'm also a work of art!\" \n+(sarcastically) Oh, yeah, real original, Andy.\n+\n+But, you know, back in the '60s, it was like, a big deal. People were all about challenging the\n+status quo, and Warhol was like, the king of that. He took the ordinary and made it extraordinary.\n+And, let me tell you, it was like, a real game-changer. I mean, who would've thought that a can of soup could be art? (laughs)\n+\n+But, hey, you're not alone, pal. I mean, I'm a robot, and even I don't get it. (winks)\n+But, hey, that's what makes art, art, right? (laughs)\n+```\n+\n+ì´ íŠœí† ë¦¬ì–¼ì˜ í›„ë°˜ë¶€ì—ì„œëŠ” ì„±ëŠ¥ê³¼ ë©”ëª¨ë¦¬ ê´€ë¦¬, \n+ê·¸ë¦¬ê³  ì‚¬ìš©ìì˜ í•„ìš”ì— ë§ëŠ” ì±„íŒ… ëª¨ë¸ ì„ íƒê³¼ ê°™ì€ êµ¬ì²´ì ì¸ ì£¼ì œë“¤ì„ ë‹¤ë£° ê²ƒì…ë‹ˆë‹¤.\n+\n+## ì±„íŒ… ëª¨ë¸ ê³ ë¥´ê¸°[[choosing-a-chat-model]]\n+\n+[Hugging Face Hub](https://huggingface.co/models?pipeline_tag=text-generation&sort=trending)ëŠ” ì±„íŒ… ëª¨ë¸ì„ ë‹¤ì–‘í•˜ê²Œ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤.\n+ì²˜ìŒ ì‚¬ìš©í•˜ëŠ” ì‚¬ëŒì—ê²ŒëŠ” ëª¨ë¸ì„ ì„ íƒí•˜ê¸°ê°€ ì–´ë ¤ìš¸ì§€ ëª¨ë¦…ë‹ˆë‹¤.\n+í•˜ì§€ë§Œ ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”! ë‘ ê°€ì§€ë§Œ ëª…ì‹¬í•˜ë©´ ë©ë‹ˆë‹¤:\n+\n+- ëª¨ë¸ì˜ í¬ê¸°ëŠ” ì‹¤í–‰ ì†ë„ì™€ ë©”ëª¨ë¦¬ì— ì˜¬ë¼ì˜¬ ìˆ˜ ìˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ê²°ì •.\n+- ëª¨ë¸ì´ ìƒì„±í•œ ì¶œë ¥ì˜ í’ˆì§ˆ.\n+\n+ì¼ë°˜ì ìœ¼ë¡œ ì´ëŸ¬í•œ ìš”ì†Œë“¤ì€ ìƒê´€ê´€ê³„ê°€ ìˆìŠµë‹ˆë‹¤. ë” í° ëª¨ë¸ì¼ìˆ˜ë¡ ë” ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²½í–¥ì´ ìˆì§€ë§Œ, ë™ì¼í•œ í¬ê¸°ì˜ ëª¨ë¸ì´ë¼ë„ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n+\n+### ëª¨ë¸ì˜ ëª…ì¹­ê³¼ í¬ê¸°[[size-and-model-naming]]\n+\n+ëª¨ë¸ì˜ í¬ê¸°ëŠ” ëª¨ë¸ ì´ë¦„ì— ìˆëŠ” ìˆ«ìë¡œ ì‰½ê²Œ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n+ì˜ˆë¥¼ ë“¤ì–´, \"8B\" ë˜ëŠ” \"70B\"ì™€ ê°™ì€ ìˆ«ìëŠ” ëª¨ë¸ì˜ **íŒŒë¼ë¯¸í„°** ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. \n+ì–‘ìí™”ëœ ê²½ìš°ê°€ ì•„ë‹ˆë¼ë©´, íŒŒë¼ë¯¸í„° í•˜ë‚˜ë‹¹ ì•½ 2ë°”ì´íŠ¸ì˜ ë©”ëª¨ë¦¬ê°€ í•„ìš”í•˜ë‹¤ê³  ì˜ˆìƒ ê°€ëŠ¥í•©ë‹ˆë‹¤. \n+ë”°ë¼ì„œ 80ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ \"8B\" ëª¨ë¸ì€ 16GBì˜ ë©”ëª¨ë¦¬ë¥¼ ì°¨ì§€í•˜ë©°, ì¶”ê°€ì ì¸ ì˜¤ë²„í—¤ë“œë¥¼ ìœ„í•œ ì•½ê°„ì˜ ì—¬ìœ ê°€ í•„ìš”í•©ë‹ˆë‹¤. \n+ì´ëŠ” 3090ì´ë‚˜ 4090ì™€ ê°™ì€ 24GBì˜ ë©”ëª¨ë¦¬ë¥¼ ê°–ì¶˜ í•˜ì´ì—”ë“œ GPUì— ì í•©í•©ë‹ˆë‹¤.\n+\n+ì¼ë¶€ ì±„íŒ… ëª¨ë¸ì€ \"Mixture of Experts\" ëª¨ë¸ì…ë‹ˆë‹¤. \n+ì´ëŸ¬í•œ ëª¨ë¸ì€ í¬ê¸°ë¥¼ \"8x7B\" ë˜ëŠ” \"141B-A35B\"ì™€ ê°™ì´ ë‹¤ë¥´ê²Œ í‘œì‹œí•˜ê³¤ í•©ë‹ˆë‹¤. \n+ìˆ«ìê°€ ë‹¤ì†Œ ëª¨í˜¸í•˜ë‹¤ ëŠê»´ì§ˆ ìˆ˜ ìˆì§€ë§Œ, ì²« ë²ˆì§¸ ê²½ìš°ì—ëŠ” ì•½ 56ì–µ(8x7) ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ ìˆê³ , \n+ë‘ ë²ˆì§¸ ê²½ìš°ì—ëŠ” ì•½ 141ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ ìˆë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+ì–‘ìí™”ëŠ” íŒŒë¼ë¯¸í„°ë‹¹ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ 8ë¹„íŠ¸, 4ë¹„íŠ¸, ë˜ëŠ” ê·¸ ì´í•˜ë¡œ ì¤„ì´ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. \n+ì´ ì£¼ì œì— ëŒ€í•´ì„œëŠ” ì•„ë˜ì˜ [ë©”ëª¨ë¦¬ ê³ ë ¤ì‚¬í•­](#memory-considerations) ì±•í„°ì—ì„œ ë” ìì„¸íˆ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤.\n+\n+### ê·¸ë ‡ë‹¤ë©´ ì–´ë–¤ ì±„íŒ… ëª¨ë¸ì´ ê°€ì¥ ì¢‹ì„ê¹Œìš”?[[but-which-chat-model-is-best]]\n+ëª¨ë¸ì˜ í¬ê¸° ì™¸ì—ë„ ê³ ë ¤í•  ì ì´ ë§ìŠµë‹ˆë‹¤. \n+ì´ë¥¼ í•œëˆˆì— ì‚´í´ë³´ë ¤ë©´ **ë¦¬ë”ë³´ë“œ**ë¥¼ ì°¸ê³ í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. \n+ê°€ì¥ ì¸ê¸° ìˆëŠ” ë¦¬ë”ë³´ë“œ ë‘ ê°€ì§€ëŠ” [OpenLLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)ì™€ [LMSys Chatbot Arena Leaderboard](https://chat.lmsys.org/?leaderboard)ì…ë‹ˆë‹¤. \n+LMSys ë¦¬ë”ë³´ë“œì—ëŠ” ë…ì  ëª¨ë¸ë„ í¬í•¨ë˜ì–´ ìˆìœ¼ë‹ˆ,\n+`license` ì—´ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì„ íƒí•œ í›„\n+[Hugging Face Hub](https://huggingface.co/models?pipeline_tag=text-generation&sort=trending)ì—ì„œ ê²€ìƒ‰í•´ ë³´ì„¸ìš”.\n+\n+### ì „ë¬¸ ë¶„ì•¼[[specialist-domains]]\n+ì¼ë¶€ ëª¨ë¸ì€ ì˜ë£Œ ë˜ëŠ” ë²•ë¥  í…ìŠ¤íŠ¸ì™€ ê°™ì€ íŠ¹ì • ë„ë©”ì¸ì´ë‚˜ ë¹„ì˜ì–´ê¶Œ ì–¸ì–´ì— íŠ¹í™”ë˜ì–´ ìˆê¸°ë„ í•©ë‹ˆë‹¤. \n+ì´ëŸ¬í•œ ë„ë©”ì¸ì—ì„œ ì‘ì—…í•  ê²½ìš° íŠ¹í™”ëœ ëª¨ë¸ì´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n+í•˜ì§€ë§Œ í•­ìƒ ê·¸ëŸ´ ê²ƒì´ë¼ ë‹¨ì •í•˜ê¸°ëŠ” í˜ë“­ë‹ˆë‹¤. \n+íŠ¹íˆ ëª¨ë¸ì˜ í¬ê¸°ê°€ ì‘ê±°ë‚˜ ì˜¤ë˜ëœ ëª¨ë¸ì¸ ê²½ìš°, \n+ìµœì‹  ë²”ìš© ëª¨ë¸ì´ ë” ë›°ì–´ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n+ë‹¤í–‰íˆë„ [domain-specific leaderboards](https://huggingface.co/blog/leaderboard-medicalllm)ê°€ ì ì°¨ ë“±ì¥í•˜ê³  ìˆì–´, íŠ¹ì • ë„ë©”ì¸ì— ìµœê³ ì˜ ëª¨ë¸ì„ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤. \n+\n+\n+## íŒŒì´í”„ë¼ì¸ ë‚´ë¶€ëŠ” ì–´ë–»ê²Œ ë˜ì–´ìˆëŠ”ê°€?[[what-happens-inside-the-pipeline]]\n+ìœ„ì˜ ë¹ ë¥¸ ì‹œì‘ì—ì„œëŠ” ê³ ìˆ˜ì¤€(High-Level) íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.\n+ì´ëŠ” ê°„í¸í•œ ë°©ë²•ì´ì§€ë§Œ, ìœ ì—°ì„±ì€ ë–¨ì–´ì§‘ë‹ˆë‹¤.\n+ì´ì œ ë” ì €ìˆ˜ì¤€(Low-Level) ì ‘ê·¼ ë°©ì‹ì„ í†µí•´ ëŒ€í™”ì— í¬í•¨ëœ ê° ë‹¨ê³„ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. \n+ì½”ë“œ ìƒ˜í”Œë¡œ ì‹œì‘í•œ í›„ ì´ë¥¼ ë¶„ì„í•´ ë³´ê² ìŠµë‹ˆë‹¤:\n+\n+```python\n+from transformers import AutoModelForCausalLM, AutoTokenizer\n+import torch\n+\n+# ì…ë ¥ê°’ì„ ì‚¬ì „ì— ì¤€ë¹„í•´ ë†“ìŠµë‹ˆë‹¤\n+chat = [\n+    {\"role\": \"system\", \"content\": \"You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986.\"},\n+    {\"role\": \"user\", \"content\": \"Hey, can you tell me any fun things to do in New York?\"}\n+]\n+\n+# 1: ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤\n+model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\", device_map=\"auto\", torch_dtype=torch.bfloat16)\n+tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n+\n+# 2: ì±„íŒ… í…œí”Œë¦¿ì— ì ìš©í•©ë‹ˆë‹¤\n+formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n+print(\"Formatted chat:\\n\", formatted_chat)\n+\n+# 3: ì±„íŒ…ì„ í† í°í™”í•©ë‹ˆë‹¤ (ë°”ë¡œ ì´ì „ ê³¼ì •ì—ì„œ tokenized=Trueë¡œ ì„¤ì •í•˜ë©´ í•œêº¼ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤)\n+inputs = tokenizer(formatted_chat, return_tensors=\"pt\", add_special_tokens=False)\n+# í† í°í™”ëœ ì…ë ¥ê°’ì„ ëª¨ë¸ì´ ì˜¬ë¼ì™€ ìˆëŠ” ê¸°ê¸°(CPU/GPU)ë¡œ ì˜®ê¹ë‹ˆë‹¤.\n+inputs = {key: tensor.to(model.device) for key, tensor in inputs.items()}\n+print(\"Tokenized inputs:\\n\", inputs)\n+\n+# 4: ëª¨ë¸ë¡œë¶€í„° ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤\n+outputs = model.generate(**inputs, max_new_tokens=512, temperature=0.1)\n+print(\"Generated tokens:\\n\", outputs)\n+\n+# 5: ëª¨ë¸ì´ ì¶œë ¥í•œ í† í°ì„ ë‹¤ì‹œ ë¬¸ìì—´ë¡œ ë””ì½”ë”©í•©ë‹ˆë‹¤\n+decoded_output = tokenizer.decode(outputs[0][inputs['input_ids'].size(1):], skip_special_tokens=True)\n+print(\"Decoded output:\\n\", decoded_output)\n+```\n+ì—¬ê¸°ì—ëŠ” ê° ë¶€ë¶„ì´ ìì²´ ë¬¸ì„œê°€ ë  ìˆ˜ ìˆì„ ë§Œí¼ ë§ì€ ë‚´ìš©ì´ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤! \n+ë„ˆë¬´ ìì„¸íˆ ì„¤ëª…í•˜ê¸°ë³´ë‹¤ëŠ” ë„“ì€ ê°œë…ì„ ë‹¤ë£¨ê³ , ì„¸ë¶€ ì‚¬í•­ì€ ë§í¬ëœ ë¬¸ì„œì—ì„œ ë‹¤ë£¨ê² ìŠµë‹ˆë‹¤. \n+ì£¼ìš” ë‹¨ê³„ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n+\n+1. [ëª¨ë¸](https://huggingface.co/learn/nlp-course/en/chapter2/3)ê³¼ [í† í¬ë‚˜ì´ì €](https://huggingface.co/learn/nlp-course/en/chapter2/4?fw=pt)ë¥¼ Hugging Face Hubì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.\n+2. ëŒ€í™”ëŠ” í† í¬ë‚˜ì´ì €ì˜ [ì±„íŒ… í…œí”Œë¦¿](https://huggingface.co/docs/transformers/main/en/chat_templating)ì„ ì‚¬ìš©í•˜ì—¬ ì–‘ì‹ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n+3. êµ¬ì„±ëœ ì±„íŒ…ì€ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ [í† í°í™”](https://huggingface.co/learn/nlp-course/en/chapter2/4)ë©ë‹ˆë‹¤.\n+4. ëª¨ë¸ì—ì„œ ì‘ë‹µì„ [ìƒì„±](https://huggingface.co/docs/transformers/en/llm_tutorial)í•©ë‹ˆë‹¤.\n+5. ëª¨ë¸ì´ ì¶œë ¥í•œ í† í°ì„ ë‹¤ì‹œ ë¬¸ìì—´ë¡œ ë””ì½”ë”©í•©ë‹ˆë‹¤.\n+\n+## ì„±ëŠ¥, ë©”ëª¨ë¦¬ì™€ í•˜ë“œì›¨ì–´[[performance-memory-and-hardware]]\n+ì´ì œ ëŒ€ë¶€ë¶„ì˜ ë¨¸ì‹  ëŸ¬ë‹ ì‘ì—…ì´ GPUì—ì„œ ì‹¤í–‰ëœë‹¤ëŠ” ê²ƒì„ ì•„ì‹¤ ê²ë‹ˆë‹¤. \n+ë‹¤ì†Œ ëŠë¦¬ê¸°ëŠ” í•´ë„ CPUì—ì„œ ì±„íŒ… ëª¨ë¸ì´ë‚˜ ì–¸ì–´ ëª¨ë¸ë¡œë¶€í„° í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•©ë‹ˆë‹¤. \n+í•˜ì§€ë§Œ ëª¨ë¸ì„ GPU ë©”ëª¨ë¦¬ì— ì˜¬ë ¤ë†“ì„ ìˆ˜ë§Œ ìˆë‹¤ë©´, GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ìœ¼ë¡œ ë” ì„ í˜¸ë˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\n+\n+### ë©”ëª¨ë¦¬ ê³ ë ¤ì‚¬í•­[[memory-considerations]]\n+\n+ê¸°ë³¸ì ìœ¼ë¡œ, [`TextGenerationPipeline`]ì´ë‚˜ [`AutoModelForCausalLM`]ê³¼ ê°™ì€ \n+Hugging Face í´ë˜ìŠ¤ëŠ” ëª¨ë¸ì„ `float32` ì •ë°€ë„(Precision)ë¡œ ë¡œë“œí•©ë‹ˆë‹¤. \n+ì´ëŠ” íŒŒë¼ë¯¸í„°ë‹¹ 4ë°”ì´íŠ¸(32ë¹„íŠ¸)ë¥¼ í•„ìš”ë¡œ í•˜ë¯€ë¡œ, \n+80ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ \"8B\" ëª¨ë¸ì€ ì•½ 32GBì˜ ë©”ëª¨ë¦¬ë¥¼ í•„ìš”ë¡œ í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. \n+í•˜ì§€ë§Œ ì´ëŠ” ë‚­ë¹„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤! \n+ëŒ€ë¶€ë¶„ì˜ ìµœì‹  ì–¸ì–´ ëª¨ë¸ì€ íŒŒë¼ë¯¸í„°ë‹¹ 2ë°”ì´íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” \"bfloat16\" ì •ë°€ë„(Precision)ë¡œ í•™ìŠµë©ë‹ˆë‹¤. \n+í•˜ë“œì›¨ì–´ê°€ ì´ë¥¼ ì§€ì›í•˜ëŠ” ê²½ìš°(Nvidia 30xx/Axxx ì´ìƒ), \n+`torch_dtype` íŒŒë¼ë¯¸í„°ë¡œ ìœ„ì™€ ê°™ì´ `bfloat16` ì •ë°€ë„(Precision)ë¡œ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+ë˜í•œ, 16ë¹„íŠ¸ë³´ë‹¤ ë” ë‚®ì€ ì •ë°€ë„(Precision)ë¡œ ëª¨ë¸ì„ ì••ì¶•í•˜ëŠ” \n+\"ì–‘ìí™”(quantization)\" ë°©ë²•ì„ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. \n+ì´ ë°©ë²•ì€ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì†ì‹¤ ì••ì¶•í•˜ì—¬ ê° íŒŒë¼ë¯¸í„°ë¥¼ 8ë¹„íŠ¸, \n+4ë¹„íŠ¸ ë˜ëŠ” ê·¸ ì´í•˜ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n+íŠ¹íˆ 4ë¹„íŠ¸ì—ì„œ ëª¨ë¸ì˜ ì¶œë ¥ì´ ë¶€ì •ì ì¸ ì˜í–¥ì„ ë°›ì„ ìˆ˜ ìˆì§€ë§Œ, \n+ë” í¬ê³  ê°•ë ¥í•œ ì±„íŒ… ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ê¸° ìœ„í•´ ì´ ê°™ì€ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ê°ìˆ˜í•  ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤. \n+ì´ì œ `bitsandbytes`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ ì‹¤ì œë¡œ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤:\n+\n+```python\n+from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n+\n+quantization_config = BitsAndBytesConfig(load_in_8bit=True)  # You can also try load_in_4bit\n+model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\", device_map=\"auto\", quantization_config=quantization_config)\n+```\n+\n+ìœ„ì˜ ì‘ì—…ì€ `pipeline` APIì—ë„ ì ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤:\n+\n+```python\n+from transformers import pipeline, BitsAndBytesConfig\n+\n+quantization_config = BitsAndBytesConfig(load_in_8bit=True)  # You can also try load_in_4bit\n+pipe = pipeline(\"text-generation\", \"meta-llama/Meta-Llama-3-8B-Instruct\", device_map=\"auto\", model_kwargs={\"quantization_config\": quantization_config})\n+```\n+\n+`bitsandbytes` ì™¸ì—ë„ ëª¨ë¸ì„ ì–‘ìí™”í•˜ëŠ” ë‹¤ì–‘í•œ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. \n+ìì„¸í•œ ë‚´ìš©ì€ [Quantization guide](./quantization)ë¥¼ ì°¸ì¡°í•´ ì£¼ì„¸ìš”.\n+\n+\n+### ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­[[performance-considerations]]\n+\n+<Tip>\n+\n+ì–¸ì–´ ëª¨ë¸ ì„±ëŠ¥ê³¼ ìµœì í™”ì— ëŒ€í•œ ë³´ë‹¤ ìì„¸í•œ ê°€ì´ë“œëŠ” [LLM Inference Optimization](./llm_optims)ì„ ì°¸ê³ í•˜ì„¸ìš”.\n+\n+</Tip>\n+\n+\n+ì¼ë°˜ì ìœ¼ë¡œ ë” í° ì±„íŒ… ëª¨ë¸ì€ ë©”ëª¨ë¦¬ë¥¼ ë” ë§ì´ ìš”êµ¬í•˜ê³ , \n+ì†ë„ë„ ëŠë ¤ì§€ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ ë§í•˜ìë©´, \n+ì±„íŒ… ëª¨ë¸ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ë•ŒëŠ” ì»´í“¨íŒ… íŒŒì›Œë³´ë‹¤ **ë©”ëª¨ë¦¬ ëŒ€ì—­í­**ì´ ë³‘ëª© í˜„ìƒì„ ì¼ìœ¼í‚¤ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. \n+ì´ëŠ” ëª¨ë¸ì´ í† í°ì„ í•˜ë‚˜ì”© ìƒì„±í•  ë•Œë§ˆë‹¤ íŒŒë¼ë¯¸í„°ë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ì½ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. \n+ë”°ë¼ì„œ ì±„íŒ… ëª¨ë¸ì—ì„œ ì´ˆë‹¹ ìƒì„±í•  ìˆ˜ ìˆëŠ” í† í° ìˆ˜ëŠ” ëª¨ë¸ì´ ìœ„ì¹˜í•œ ë©”ëª¨ë¦¬ì˜ ëŒ€ì—­í­ì„ ëª¨ë¸ì˜ í¬ê¸°ë¡œ ë‚˜ëˆˆ ê°’ì— ë¹„ë¡€í•©ë‹ˆë‹¤.\n+\n+ìœ„ì˜ ì˜ˆì œì—ì„œëŠ” ëª¨ë¸ì´ bfloat16 ì •ë°€ë„(Precision)ë¡œ ë¡œë“œë  ë•Œ ìš©ëŸ‰ì´ ì•½ 16GBì˜€ìŠµë‹ˆë‹¤. \n+ì´ ê²½ìš°, ëª¨ë¸ì´ ìƒì„±í•˜ëŠ” ê° í† í°ë§ˆë‹¤ 16GBë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ì½ì–´ì•¼ í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. \n+ì´ ë©”ëª¨ë¦¬ ëŒ€ì—­í­ì€ ì†Œë¹„ììš© CPUì—ì„œëŠ” 20-100GB/sec, \n+ì†Œë¹„ììš© GPUë‚˜ Intel Xeon, AMD Threadripper/Epyc, \n+ì• í”Œ ì‹¤ë¦¬ì½˜ê³¼ ê°™ì€ íŠ¹ìˆ˜ CPUì—ì„œëŠ” 200-900GB/sec, \n+ë°ì´í„° ì„¼í„° GPUì¸ Nvidia A100ì´ë‚˜ H100ì—ì„œëŠ” ìµœëŒ€ 2-3TB/secì— ì´ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n+ì´ëŸ¬í•œ ì •ë³´ëŠ” ê°ì í•˜ë“œì›¨ì–´ì—ì„œ ìƒì„± ì†ë„ë¥¼ ì˜ˆìƒí•˜ëŠ” ë° ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤.\n+\n+ë”°ë¼ì„œ í…ìŠ¤íŠ¸ ìƒì„± ì†ë„ë¥¼ ê°œì„ í•˜ë ¤ë©´ ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ ëª¨ë¸ì˜ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜(ì£¼ë¡œ ì–‘ìí™”ë¥¼ ì‚¬ìš©), \n+ë©”ëª¨ë¦¬ ëŒ€ì—­í­ì´ ë” ë†’ì€ í•˜ë“œì›¨ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. \n+ì´ ëŒ€ì—­í­ ë³‘ëª© í˜„ìƒì„ í”¼í•  ìˆ˜ ìˆëŠ” ê³ ê¸‰ ê¸°ìˆ ë„ ì—¬ëŸ¬ ê°€ì§€ ìˆìŠµë‹ˆë‹¤. \n+ê°€ì¥ ì¼ë°˜ì ì¸ ë°©ë²•ì€ [ë³´ì¡° ìƒì„±](https://huggingface.co/blog/assisted-generation), \"ì¶”ì¸¡ ìƒ˜í”Œë§\"ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. \n+ì´ ê¸°ìˆ ì€ ì¢…ì¢… ë” ì‘ì€ \"ì´ˆì•ˆ ëª¨ë¸\"ì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ê°œì˜ ë¯¸ë˜ í† í°ì„ í•œ ë²ˆì— ì¶”ì¸¡í•œ í›„, \n+ì±„íŒ… ëª¨ë¸ë¡œ ìƒì„± ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n+ë§Œì•½ ì±„íŒ… ëª¨ë¸ì´ ì¶”ì¸¡ì„ í™•ì¸í•˜ë©´, í•œ ë²ˆì˜ ìˆœì „íŒŒì—ì„œ ì—¬ëŸ¬ ê°œì˜ í† í°ì„ ìƒì„±í•  ìˆ˜ ìˆì–´ \n+ë³‘ëª© í˜„ìƒì´ í¬ê²Œ ì¤„ì–´ë“¤ê³  ìƒì„± ì†ë„ê°€ ë¹¨ë¼ì§‘ë‹ˆë‹¤.\n+\n+ë§ˆì§€ë§‰ìœ¼ë¡œ, \"Mixture of Experts\" (MoE) ëª¨ë¸ì— ëŒ€í•´ì„œë„ ì§šê³  ë„˜ì–´ê°€ ë³´ë„ë¡ í•©ë‹ˆë‹¤. \n+Mixtral, Qwen-MoE, DBRXì™€ ê°™ì€ ì¸ê¸° ìˆëŠ” ì±„íŒ… ëª¨ë¸ì´ ë°”ë¡œ MoE ëª¨ë¸ì…ë‹ˆë‹¤. \n+ì´ ëª¨ë¸ë“¤ì€ í† í°ì„ ìƒì„±í•  ë•Œ ëª¨ë“  íŒŒë¼ë¯¸í„°ê°€ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. \n+ì´ë¡œ ì¸í•´ MoE ëª¨ë¸ì€ ì „ì²´ í¬ê¸°ê°€ ìƒë‹¹íˆ í´ ìˆ˜ ìˆì§€ë§Œ, \n+ì°¨ì§€í•˜ëŠ” ë©”ëª¨ë¦¬ ëŒ€ì—­í­ì€ ë‚®ì€ í¸ì…ë‹ˆë‹¤. \n+ë”°ë¼ì„œ ë™ì¼í•œ í¬ê¸°ì˜ ì¼ë°˜ \"ì¡°ë°€í•œ(Dense)\" ëª¨ë¸ë³´ë‹¤ ëª‡ ë°° ë¹ ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n+í•˜ì§€ë§Œ ë³´ì¡° ìƒì„±ê³¼ ê°™ì€ ê¸°ìˆ ì€ MoE ëª¨ë¸ì—ì„œ ë¹„íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n+ìƒˆë¡œìš´ ì¶”ì¸¡ëœ í† í°ì´ ì¶”ê°€ë˜ë©´ì„œ ë” ë§ì€ íŒŒë¼ë¯¸í„°ê°€ í™œì„±í™”ë˜ê¸° ë•Œë¬¸ì—, \n+MoE ì•„í‚¤í…ì²˜ê°€ ì œê³µí•˜ëŠ” ì†ë„ ì´ì ì´ ìƒì‡„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\\ No newline at end of file"
        }
    ],
    "stats": {
        "total": 310,
        "additions": 308,
        "deletions": 2
    }
}