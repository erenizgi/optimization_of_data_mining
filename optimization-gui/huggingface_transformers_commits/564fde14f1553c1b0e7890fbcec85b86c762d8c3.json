{
    "author": "rangehow",
    "message": "FIX(trainer): ensure final checkpoint is saved when resuming training (#40347)\n\n* fix(trainer): ensure final checkpoint is saved when resuming training\n\n* add test\n\n* make style && slight fix of test\n\n* make style again\n\n* move test code to test_trainer\n\n* remove outdated test file\n\n* Apply style fixes\n\n---------\n\nCo-authored-by: rangehow <rangehow@foxmail.com>\nCo-authored-by: github-actions[bot] <github-actions[bot]@users.noreply.github.com>\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>",
    "sha": "564fde14f1553c1b0e7890fbcec85b86c762d8c3",
    "files": [
        {
            "sha": "97de1d6d539757ec27d5f543a8ccb627086dfae6",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 12,
            "deletions": 24,
            "changes": 36,
            "blob_url": "https://github.com/huggingface/transformers/blob/564fde14f1553c1b0e7890fbcec85b86c762d8c3/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/564fde14f1553c1b0e7890fbcec85b86c762d8c3/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=564fde14f1553c1b0e7890fbcec85b86c762d8c3",
            "patch": "@@ -2533,7 +2533,6 @@ def _inner_training_loop(\n         start_time = time.time()\n         epochs_trained = 0\n         steps_trained_in_current_epoch = 0\n-        steps_trained_progress_bar = None\n \n         # Check if continuing training from a checkpoint\n         if resume_from_checkpoint is not None and os.path.isfile(\n@@ -2594,18 +2593,18 @@ def _inner_training_loop(\n             )\n             self.control = self.callback_handler.on_epoch_begin(args, self.state, self.control)\n \n-            if epoch == epochs_trained and resume_from_checkpoint is not None and steps_trained_in_current_epoch == 0:\n-                self._load_rng_state(resume_from_checkpoint)\n-\n+            step = -1\n             rng_to_sync = False\n-            steps_skipped = 0\n-            if steps_trained_in_current_epoch > 0:\n-                epoch_dataloader = skip_first_batches(epoch_dataloader, steps_trained_in_current_epoch)\n-                steps_skipped = steps_trained_in_current_epoch\n-                steps_trained_in_current_epoch = 0\n-                rng_to_sync = True\n \n-            step = -1\n+            # Handle resumption from checkpoint\n+            if epoch == epochs_trained and resume_from_checkpoint is not None:\n+                if steps_trained_in_current_epoch > 0 and not args.ignore_data_skip:\n+                    epoch_dataloader = skip_first_batches(epoch_dataloader, steps_trained_in_current_epoch)\n+                    step = steps_trained_in_current_epoch - 1\n+                    rng_to_sync = True\n+                elif steps_trained_in_current_epoch == 0:\n+                    self._load_rng_state(resume_from_checkpoint)\n+\n             epoch_iterator = iter(epoch_dataloader)\n             # We chunkify the epoch iterator into gradient accumulation steps `n` batches\n             remainder = steps_in_epoch % args.gradient_accumulation_steps\n@@ -2658,22 +2657,11 @@ def _inner_training_loop(\n \n                             input_tokens = torch.tensor(input_tokens, device=self.args.device, dtype=torch.int64)\n                             self.state.num_input_tokens_seen += self.accelerator.gather(input_tokens).sum().item()\n+\n                     if rng_to_sync:\n                         self._load_rng_state(resume_from_checkpoint)\n                         rng_to_sync = False\n \n-                    # Skip past any already trained steps if resuming training\n-                    if steps_trained_in_current_epoch > 0:\n-                        steps_trained_in_current_epoch -= 1\n-                        if steps_trained_progress_bar is not None:\n-                            steps_trained_progress_bar.update(1)\n-                        if steps_trained_in_current_epoch == 0:\n-                            self._load_rng_state(resume_from_checkpoint)\n-                        continue\n-                    elif steps_trained_progress_bar is not None:\n-                        steps_trained_progress_bar.close()\n-                        steps_trained_progress_bar = None\n-\n                     if step % args.gradient_accumulation_steps == 0:\n                         self.control = self.callback_handler.on_step_begin(args, self.state, self.control)\n \n@@ -2765,7 +2753,7 @@ def _inner_training_loop(\n \n                         model.zero_grad()\n                         self.state.global_step += 1\n-                        self.state.epoch = epoch + (step + 1 + steps_skipped) / steps_in_epoch\n+                        self.state.epoch = epoch + (step + 1) / steps_in_epoch\n                         self.control = self.callback_handler.on_step_end(args, self.state, self.control)\n                         self._maybe_log_save_evaluate(\n                             tr_loss,"
        },
        {
            "sha": "47e1004df9b65e989d27541a6a13b1561b244581",
            "filename": "tests/trainer/test_trainer.py",
            "status": "modified",
            "additions": 109,
            "deletions": 0,
            "changes": 109,
            "blob_url": "https://github.com/huggingface/transformers/blob/564fde14f1553c1b0e7890fbcec85b86c762d8c3/tests%2Ftrainer%2Ftest_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/564fde14f1553c1b0e7890fbcec85b86c762d8c3/tests%2Ftrainer%2Ftest_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_trainer.py?ref=564fde14f1553c1b0e7890fbcec85b86c762d8c3",
            "patch": "@@ -5158,6 +5158,115 @@ def test_trainer_works_without_model_config(self):\n             )\n             trainer.train()\n \n+    @require_safetensors\n+    def test_resume_from_interrupted_training(self):\n+        \"\"\"\n+        Tests resuming training from a checkpoint after a simulated interruption.\n+        \"\"\"\n+\n+        # --- Helper classes and functions defined locally for this test ---\n+        class DummyModel(nn.Module):\n+            def __init__(self, input_dim=10, num_labels=2):\n+                super().__init__()\n+                self.linear = nn.Linear(input_dim, num_labels)\n+\n+            def forward(self, input_ids=None, attention_mask=None, labels=None):\n+                logits = self.linear(input_ids.float())\n+                loss = None\n+                if labels is not None:\n+                    loss_fn = nn.CrossEntropyLoss()\n+                    loss = loss_fn(logits, labels)\n+                return {\"loss\": loss, \"logits\": logits}\n+\n+        class DummyDictDataset(torch.utils.data.Dataset):\n+            def __init__(self, input_ids, attention_mask, labels):\n+                self.input_ids = input_ids\n+                self.attention_mask = attention_mask\n+                self.labels = labels\n+\n+            def __len__(self):\n+                return len(self.input_ids)\n+\n+            def __getitem__(self, idx):\n+                return {\n+                    \"input_ids\": self.input_ids[idx],\n+                    \"attention_mask\": self.attention_mask[idx],\n+                    \"labels\": self.labels[idx],\n+                }\n+\n+        def create_dummy_dataset():\n+            \"\"\"Creates a dummy dataset for this specific test.\"\"\"\n+            num_samples = 13\n+            input_dim = 10\n+            dummy_input_ids = torch.rand(num_samples, input_dim)\n+            dummy_attention_mask = torch.ones(num_samples, input_dim)\n+            dummy_labels = torch.randint(0, 2, (num_samples,))\n+            return DummyDictDataset(dummy_input_ids, dummy_attention_mask, dummy_labels)\n+\n+        # 1. Set up a dummy model and dataset\n+        model = DummyModel(input_dim=10, num_labels=2)\n+        dummy_dataset = create_dummy_dataset()\n+\n+        # 2. First training phase (simulating an interruption)\n+        output_dir_initial = self.get_auto_remove_tmp_dir()\n+        training_args_initial = TrainingArguments(\n+            output_dir=output_dir_initial,\n+            num_train_epochs=1,\n+            per_device_train_batch_size=2,\n+            gradient_accumulation_steps=3,\n+            save_strategy=\"steps\",\n+            save_steps=1,  # Save at every step\n+            report_to=[],  # Disable wandb/tensorboard and other loggers\n+            max_steps=2,  # Stop after step 2 to simulate interruption\n+        )\n+\n+        trainer_initial = Trainer(\n+            model=model,\n+            args=training_args_initial,\n+            train_dataset=dummy_dataset,\n+        )\n+        trainer_initial.train()\n+\n+        # 3. Verify that a checkpoint was created before the \"interruption\"\n+        checkpoint_path = os.path.join(output_dir_initial, \"checkpoint-2\")\n+        self.assertTrue(os.path.exists(checkpoint_path), f\"Checkpoint not found at {checkpoint_path}\")\n+\n+        # 4. Second training phase (resuming from the checkpoint)\n+        output_dir_resumed = self.get_auto_remove_tmp_dir()\n+        # Note: total steps for one epoch is ceil(13 / (2*3)) = 3.\n+        # We stopped at step 2, so the resumed training should run for 1 more step.\n+        training_args_resumed = TrainingArguments(\n+            output_dir=output_dir_resumed,\n+            num_train_epochs=1,\n+            per_device_train_batch_size=2,\n+            gradient_accumulation_steps=3,\n+            save_strategy=\"steps\",\n+            save_steps=1,\n+            report_to=[],\n+        )\n+\n+        trainer_resumed = Trainer(\n+            model=model,\n+            args=training_args_resumed,\n+            train_dataset=dummy_dataset,\n+        )\n+        # Resume from the interrupted checkpoint and finish the remaining training\n+        trainer_resumed.train(resume_from_checkpoint=checkpoint_path)\n+\n+        # 5. Assertions: Check if the training completed and the final model was saved\n+        # The training should have completed step 3.\n+        # Total steps per epoch = ceil(13 samples / (2 batch_size * 3 grad_accum)) = 3\n+        self.assertEqual(trainer_resumed.state.global_step, 3)\n+\n+        # Check that a checkpoint for the final step exists.\n+        final_checkpoint_path = os.path.join(output_dir_resumed, \"checkpoint-3\")\n+        self.assertTrue(os.path.exists(final_checkpoint_path))\n+\n+        # Check if the model weights file exists in the final checkpoint directory.\n+        # Trainer saves non-PreTrainedModel models as `model.safetensors` by default if safetensors is available.\n+        final_model_path = os.path.join(final_checkpoint_path, SAFE_WEIGHTS_NAME)\n+        self.assertTrue(os.path.exists(final_model_path), \"Final model checkpoint was not saved!\")\n+\n \n @require_torch\n @is_staging_test"
        }
    ],
    "stats": {
        "total": 145,
        "additions": 121,
        "deletions": 24
    }
}