{
    "author": "yao-matrix",
    "message": "enable 5 cases on XPU (#37507)\n\n* make speecht5 test_batch_generation pass on XPU\n\nSigned-off-by: YAO Matrix <matrix.yao@intel.com>\n\n* enable 4 GlmIntegrationTest cases on XPU\n\nSigned-off-by: YAO Matrix <matrix.yao@intel.com>\n\n* fix style\n\nSigned-off-by: YAO Matrix <matrix.yao@intel.com>\n\n* Update src/transformers/testing_utils.py\n\nCo-authored-by: Yih-Dar <2521628+ydshieh@users.noreply.github.com>\n\n---------\n\nSigned-off-by: YAO Matrix <matrix.yao@intel.com>\nCo-authored-by: Yih-Dar <2521628+ydshieh@users.noreply.github.com>",
    "sha": "5ab7a7c640c7305e435d14443a4c16b0d673b74c",
    "files": [
        {
            "sha": "380194a023ec8ee36e946a79a67256a9baefadd4",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/5ab7a7c640c7305e435d14443a4c16b0d673b74c/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5ab7a7c640c7305e435d14443a4c16b0d673b74c/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=5ab7a7c640c7305e435d14443a4c16b0d673b74c",
            "patch": "@@ -1026,6 +1026,19 @@ def require_torch_large_gpu(test_case, memory: float = 20):\n     )(test_case)\n \n \n+def require_torch_large_accelerator(test_case, memory: float = 20):\n+    \"\"\"Decorator marking a test that requires an accelerator with more than `memory` GiB of memory.\"\"\"\n+    if torch_device != \"cuda\" and torch_device != \"xpu\":\n+        return unittest.skip(reason=f\"test requires a GPU or XPU with more than {memory} GiB of memory\")(test_case)\n+\n+    torch_accelerator_module = getattr(torch, torch_device)\n+\n+    return unittest.skipUnless(\n+        torch_accelerator_module.get_device_properties(0).total_memory / 1024**3 > memory,\n+        f\"test requires a GPU or XPU with more than {memory} GiB of memory\",\n+    )(test_case)\n+\n+\n def require_torch_gpu_if_bnb_not_multi_backend_enabled(test_case):\n     \"\"\"\n     Decorator marking a test that requires a GPU if bitsandbytes multi-backend feature is not enabled."
        },
        {
            "sha": "f4dc0ab81bcbf833afb961de73c3b6622a04ddff",
            "filename": "tests/models/glm/test_modeling_glm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/5ab7a7c640c7305e435d14443a4c16b0d673b74c/tests%2Fmodels%2Fglm%2Ftest_modeling_glm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5ab7a7c640c7305e435d14443a4c16b0d673b74c/tests%2Fmodels%2Fglm%2Ftest_modeling_glm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fglm%2Ftest_modeling_glm.py?ref=5ab7a7c640c7305e435d14443a4c16b0d673b74c",
            "patch": "@@ -22,7 +22,7 @@\n     is_flaky,\n     require_flash_attn,\n     require_torch,\n-    require_torch_large_gpu,\n+    require_torch_large_accelerator,\n     require_torch_sdpa,\n     slow,\n     torch_device,\n@@ -309,7 +309,7 @@ def test_custom_4d_attention_mask(self):\n \n \n @slow\n-@require_torch_large_gpu\n+@require_torch_large_accelerator\n class GlmIntegrationTest(unittest.TestCase):\n     input_text = [\"Hello I am doing\", \"Hi today\"]\n     model_id = \"THUDM/glm-4-9b\""
        },
        {
            "sha": "34c5972cd44fb2119f980eae043384fc7eec382f",
            "filename": "tests/models/speecht5/test_modeling_speecht5.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/5ab7a7c640c7305e435d14443a4c16b0d673b74c/tests%2Fmodels%2Fspeecht5%2Ftest_modeling_speecht5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5ab7a7c640c7305e435d14443a4c16b0d673b74c/tests%2Fmodels%2Fspeecht5%2Ftest_modeling_speecht5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fspeecht5%2Ftest_modeling_speecht5.py?ref=5ab7a7c640c7305e435d14443a4c16b0d673b74c",
            "patch": "@@ -1223,6 +1223,7 @@ def test_one_to_many_generation(self):\n                 \"Mismatch in waveform between standalone and integrated vocoder for single instance generation.\",\n             )\n \n+    @require_deterministic_for_xpu\n     def test_batch_generation(self):\n         model = self.default_model\n         processor = self.default_processor"
        }
    ],
    "stats": {
        "total": 18,
        "additions": 16,
        "deletions": 2
    }
}