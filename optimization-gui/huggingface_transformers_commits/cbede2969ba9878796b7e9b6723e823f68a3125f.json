{
    "author": "jitesh-gupta",
    "message": "Add self-hosted runner scale set workflow for mi325 CI (#39651)",
    "sha": "cbede2969ba9878796b7e9b6723e823f68a3125f",
    "files": [
        {
            "sha": "bc0dfe0e5785ad86c55e9780798c078d1709e327",
            "filename": ".github/workflows/self-scheduled-amd-mi325-caller.yml",
            "status": "added",
            "additions": 63,
            "deletions": 0,
            "changes": 63,
            "blob_url": "https://github.com/huggingface/transformers/blob/cbede2969ba9878796b7e9b6723e823f68a3125f/.github%2Fworkflows%2Fself-scheduled-amd-mi325-caller.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/cbede2969ba9878796b7e9b6723e823f68a3125f/.github%2Fworkflows%2Fself-scheduled-amd-mi325-caller.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-scheduled-amd-mi325-caller.yml?ref=cbede2969ba9878796b7e9b6723e823f68a3125f",
            "patch": "@@ -0,0 +1,63 @@\n+name: Self-hosted runner scale set (AMD mi325 scheduled CI caller)\n+\n+# Note: For every job in this workflow, the name of the runner scale set is finalized in the runner yaml i.e. huggingface/hf-workflows/.github/workflows/transformers_amd_ci_scheduled_arc_scale_set.yaml\n+# For example, 1gpu scale set: amd-mi325-ci-1gpu\n+#              2gpu scale set: amd-mi325-ci-2gpu\n+\n+on:\n+  workflow_run:\n+    workflows: [\"Self-hosted runner (AMD scheduled CI caller)\"]\n+    branches: [\"main\"]\n+    types: [completed]\n+  push:\n+    branches:\n+      - run_amd_scheduled_ci_caller*\n+\n+jobs:\n+  model-ci:\n+    name: Model CI\n+    uses: huggingface/hf-workflows/.github/workflows/transformers_amd_ci_scheduled_arc_scale_set.yaml@main\n+    with:\n+      job: run_models_gpu\n+      slack_report_channel: \"#amd-hf-ci\"\n+      runner_scale_set: amd-mi325-ci\n+      docker: huggingface/transformers-pytorch-amd-gpu\n+      ci_event: Scheduled CI (AMD) - mi325\n+      report_repo_id: optimum-amd/transformers_daily_ci\n+    secrets: inherit\n+\n+  torch-pipeline:\n+    name: Torch pipeline CI\n+    uses: huggingface/hf-workflows/.github/workflows/transformers_amd_ci_scheduled_arc_scale_set.yaml@main\n+    with:\n+      job: run_pipelines_torch_gpu\n+      slack_report_channel: \"#amd-hf-ci\"\n+      runner_scale_set: amd-mi325-ci\n+      docker: huggingface/transformers-pytorch-amd-gpu\n+      ci_event: Scheduled CI (AMD) - mi325\n+      report_repo_id: optimum-amd/transformers_daily_ci\n+    secrets: inherit\n+\n+  example-ci:\n+    name: Example CI\n+    uses: huggingface/hf-workflows/.github/workflows/transformers_amd_ci_scheduled_arc_scale_set.yaml@main\n+    with:\n+      job: run_examples_gpu\n+      slack_report_channel: \"#amd-hf-ci\"\n+      runner_scale_set: amd-mi325-ci\n+      docker: huggingface/transformers-pytorch-amd-gpu\n+      ci_event: Scheduled CI (AMD) - mi325\n+      report_repo_id: optimum-amd/transformers_daily_ci\n+    secrets: inherit\n+\n+  deepspeed-ci:\n+    name: DeepSpeed CI\n+    uses: huggingface/hf-workflows/.github/workflows/transformers_amd_ci_scheduled_arc_scale_set.yaml@main\n+    with:\n+      job: run_torch_cuda_extensions_gpu\n+      slack_report_channel: \"#amd-hf-ci\"\n+      runner_scale_set: amd-mi325-ci\n+      docker: huggingface/transformers-pytorch-deepspeed-amd-gpu\n+      ci_event: Scheduled CI (AMD) - mi325\n+      report_repo_id: optimum-amd/transformers_daily_ci\n+    secrets: inherit"
        }
    ],
    "stats": {
        "total": 63,
        "additions": 63,
        "deletions": 0
    }
}