{
    "author": "ShadyPi",
    "message": "Fix: Correct tensor shape comment in Mamba modeling (#37801)\n\n* Fix: Correct tensor shape comment in Mamba modeling\n\n* Update src/transformers/models/mamba/modeling_mamba.py\n\n* Update src/transformers/models/mamba/modeling_mamba.py\n\n---------\n\nCo-authored-by: ShadyPi <11342288+shadypi@user.noreply.gitee.com>\nCo-authored-by: Matt <Rocketknight1@users.noreply.github.com>",
    "sha": "97e57b2545bfc302cc75f7b4f720a7f77992b69e",
    "files": [
        {
            "sha": "7fe46b11646cd0bf82e0df82a0bb7981798f55f7",
            "filename": "src/transformers/models/mamba/modeling_mamba.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/97e57b2545bfc302cc75f7b4f720a7f77992b69e/src%2Ftransformers%2Fmodels%2Fmamba%2Fmodeling_mamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/97e57b2545bfc302cc75f7b4f720a7f77992b69e/src%2Ftransformers%2Fmodels%2Fmamba%2Fmodeling_mamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmamba%2Fmodeling_mamba.py?ref=97e57b2545bfc302cc75f7b4f720a7f77992b69e",
            "patch": "@@ -301,10 +301,10 @@ def slow_forward(self, input_states, cache_params: Optional[MambaCache]=None, ca\n         else:\n             scan_outputs = []\n             for i in range(seq_len):\n-                ssm_state = discrete_A[:, :, i, :] * ssm_state + deltaB_u[:, :, i, :]      # [batch, intermediade_size, ssm_state]\n-                scan_output = torch.matmul(ssm_state.to(dtype), C[:, i, :].unsqueeze(-1))  # [batch, intermediade_size, 1]\n+                ssm_state = discrete_A[:, :, i, :] * ssm_state + deltaB_u[:, :, i, :]      # [batch, intermediate_size, ssm_state]\n+                scan_output = torch.matmul(ssm_state.to(dtype), C[:, i, :].unsqueeze(-1))  # [batch, intermediate_size, 1]\n                 scan_outputs.append(scan_output[:, :, 0])\n-            scan_output = torch.stack(scan_outputs, dim=-1)                                # [batch, seq_len, intermediade_size]\n+            scan_output = torch.stack(scan_outputs, dim=-1)                                # [batch, intermediate_size, seq_len]\n             scan_output = scan_output + (hidden_states * self.D[None, :, None])\n             scan_output = (scan_output * self.act(gate))\n "
        }
    ],
    "stats": {
        "total": 6,
        "additions": 3,
        "deletions": 3
    }
}