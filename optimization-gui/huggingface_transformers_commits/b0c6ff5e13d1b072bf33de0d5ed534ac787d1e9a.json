{
    "author": "we1559",
    "message": "fix issue that some example with no trainer use accelerator.end_trainâ€¦ (#37435)\n\n* fix issue that some example with no trainer use accelerator.end_training in a wrong way\n\n* reformat code\n\n---------\n\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>",
    "sha": "b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a",
    "files": [
        {
            "sha": "45259b1b0a6e59df6e0cd19b2945b6b3111988e4",
            "filename": "examples/pytorch/image-classification/run_image_classification_no_trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification_no_trainer.py?ref=b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a",
            "patch": "@@ -617,9 +617,6 @@ def collate_fn(examples):\n                 output_dir = os.path.join(args.output_dir, output_dir)\n             accelerator.save_state(output_dir)\n \n-    if args.with_tracking:\n-        accelerator.end_training()\n-\n     if args.output_dir is not None:\n         accelerator.wait_for_everyone()\n         unwrapped_model = accelerator.unwrap_model(model)\n@@ -640,6 +637,9 @@ def collate_fn(examples):\n             with open(os.path.join(args.output_dir, \"all_results.json\"), \"w\") as f:\n                 json.dump(all_results, f)\n \n+    accelerator.wait_for_everyone()\n+    accelerator.end_training()\n+\n \n if __name__ == \"__main__\":\n     main()"
        },
        {
            "sha": "13a545d4cbd15606585ce7d0c0348288885fcc89",
            "filename": "examples/pytorch/image-pretraining/run_mim_no_trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim_no_trainer.py?ref=b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a",
            "patch": "@@ -778,9 +778,6 @@ def preprocess_images(examples):\n                 output_dir = os.path.join(args.output_dir, output_dir)\n             accelerator.save_state(output_dir)\n \n-    if args.with_tracking:\n-        accelerator.end_training()\n-\n     if args.output_dir is not None:\n         accelerator.wait_for_everyone()\n         unwrapped_model = accelerator.unwrap_model(model)\n@@ -798,6 +795,9 @@ def preprocess_images(examples):\n                     token=args.hub_token,\n                 )\n \n+    accelerator.wait_for_everyone()\n+    accelerator.end_training()\n+\n \n if __name__ == \"__main__\":\n     main()"
        },
        {
            "sha": "fb33681168cd69bae9e83b8a63490440528b3c1b",
            "filename": "examples/pytorch/instance-segmentation/run_instance_segmentation_no_trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation_no_trainer.py?ref=b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a",
            "patch": "@@ -714,9 +714,6 @@ def main():\n \n     logger.info(f\"Test metrics: {metrics}\")\n \n-    if args.with_tracking:\n-        accelerator.end_training()\n-\n     if args.output_dir is not None:\n         accelerator.wait_for_everyone()\n         unwrapped_model = accelerator.unwrap_model(model)\n@@ -739,6 +736,9 @@ def main():\n                     ignore_patterns=[\"epoch_*\"],\n                 )\n \n+    accelerator.wait_for_everyone()\n+    accelerator.end_training()\n+\n \n if __name__ == \"__main__\":\n     main()"
        },
        {
            "sha": "2a5a0d5d72d92f36d274e91fa50454055f8ed2dd",
            "filename": "examples/pytorch/language-modeling/run_clm_no_trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm_no_trainer.py?ref=b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a",
            "patch": "@@ -697,9 +697,6 @@ def group_texts(examples):\n                 output_dir = os.path.join(args.output_dir, output_dir)\n             accelerator.save_state(output_dir)\n \n-    if args.with_tracking:\n-        accelerator.end_training()\n-\n     if args.output_dir is not None:\n         accelerator.wait_for_everyone()\n         unwrapped_model = accelerator.unwrap_model(model)\n@@ -719,6 +716,9 @@ def group_texts(examples):\n             with open(os.path.join(args.output_dir, \"all_results.json\"), \"w\") as f:\n                 json.dump({\"perplexity\": perplexity}, f)\n \n+    accelerator.wait_for_everyone()\n+    accelerator.end_training()\n+\n \n if __name__ == \"__main__\":\n     main()"
        },
        {
            "sha": "a53cd5740a979bbb5e0fc90f769a7ccf56af7d39",
            "filename": "examples/pytorch/language-modeling/run_fim_no_trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py?ref=b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a",
            "patch": "@@ -891,9 +891,6 @@ def apply_fim(examples):\n                 output_dir = os.path.join(args.output_dir, output_dir)\n             accelerator.save_state(output_dir)\n \n-    if args.with_tracking:\n-        accelerator.end_training()\n-\n     if args.output_dir is not None:\n         accelerator.wait_for_everyone()\n         unwrapped_model = accelerator.unwrap_model(model)\n@@ -908,6 +905,9 @@ def apply_fim(examples):\n             with open(os.path.join(args.output_dir, \"all_results.json\"), \"w\") as f:\n                 json.dump({\"perplexity\": perplexity}, f)\n \n+    accelerator.wait_for_everyone()\n+    accelerator.end_training()\n+\n \n if __name__ == \"__main__\":\n     main()"
        },
        {
            "sha": "d8285bdc0d20524d4ce6761bafb42db64bc18b53",
            "filename": "examples/pytorch/language-modeling/run_mlm_no_trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm_no_trainer.py?ref=b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a",
            "patch": "@@ -735,9 +735,6 @@ def group_texts(examples):\n                 output_dir = os.path.join(args.output_dir, output_dir)\n             accelerator.save_state(output_dir)\n \n-    if args.with_tracking:\n-        accelerator.end_training()\n-\n     if args.output_dir is not None:\n         accelerator.wait_for_everyone()\n         unwrapped_model = accelerator.unwrap_model(model)\n@@ -757,6 +754,9 @@ def group_texts(examples):\n             with open(os.path.join(args.output_dir, \"all_results.json\"), \"w\") as f:\n                 json.dump({\"perplexity\": perplexity}, f)\n \n+    accelerator.wait_for_everyone()\n+    accelerator.end_training()\n+\n \n if __name__ == \"__main__\":\n     main()"
        },
        {
            "sha": "851346c6d2156915a9134be45dc8cce1fa1ebdcf",
            "filename": "examples/pytorch/multiple-choice/run_swag_no_trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag_no_trainer.py?ref=b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a",
            "patch": "@@ -622,9 +622,6 @@ def preprocess_function(examples):\n                 output_dir = os.path.join(args.output_dir, output_dir)\n             accelerator.save_state(output_dir)\n \n-    if args.with_tracking:\n-        accelerator.end_training()\n-\n     if args.output_dir is not None:\n         accelerator.wait_for_everyone()\n         unwrapped_model = accelerator.unwrap_model(model)\n@@ -645,6 +642,9 @@ def preprocess_function(examples):\n             with open(os.path.join(args.output_dir, \"all_results.json\"), \"w\") as f:\n                 json.dump(all_results, f)\n \n+    accelerator.wait_for_everyone()\n+    accelerator.end_training()\n+\n \n if __name__ == \"__main__\":\n     main()"
        },
        {
            "sha": "5265ca0c40a236ce8964e6fe4ddc0a41d9c8c958",
            "filename": "examples/pytorch/object-detection/run_object_detection_no_trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection_no_trainer.py?ref=b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a",
            "patch": "@@ -759,9 +759,6 @@ def main():\n \n     logger.info(f\"Test metrics: {metrics}\")\n \n-    if args.with_tracking:\n-        accelerator.end_training()\n-\n     if args.output_dir is not None:\n         accelerator.wait_for_everyone()\n         unwrapped_model = accelerator.unwrap_model(model)\n@@ -784,6 +781,9 @@ def main():\n                     ignore_patterns=[\"epoch_*\"],\n                 )\n \n+    accelerator.wait_for_everyone()\n+    accelerator.end_training()\n+\n \n if __name__ == \"__main__\":\n     main()"
        },
        {
            "sha": "cd2a7a895b21bdec9954a41f666393f94ebe0176",
            "filename": "examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation_no_trainer.py?ref=b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a",
            "patch": "@@ -602,9 +602,6 @@ def preprocess_batch(example_batch, transforms: A.Compose):\n                 output_dir = os.path.join(args.output_dir, output_dir)\n             accelerator.save_state(output_dir)\n \n-    if args.with_tracking:\n-        accelerator.end_training()\n-\n     if args.output_dir is not None:\n         accelerator.wait_for_everyone()\n         unwrapped_model = accelerator.unwrap_model(model)\n@@ -628,6 +625,9 @@ def preprocess_batch(example_batch, transforms: A.Compose):\n             with open(os.path.join(args.output_dir, \"all_results.json\"), \"w\") as f:\n                 json.dump(all_results, f, indent=2)\n \n+    accelerator.wait_for_everyone()\n+    accelerator.end_training()\n+\n \n if __name__ == \"__main__\":\n     main()"
        },
        {
            "sha": "eab318867b3d5c2223e4219d8634159f18ae91d8",
            "filename": "examples/pytorch/text-classification/run_glue_no_trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Ftext-classification%2Frun_glue_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Ftext-classification%2Frun_glue_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftext-classification%2Frun_glue_no_trainer.py?ref=b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a",
            "patch": "@@ -634,9 +634,6 @@ def preprocess_function(examples):\n                 output_dir = os.path.join(args.output_dir, output_dir)\n             accelerator.save_state(output_dir)\n \n-    if args.with_tracking:\n-        accelerator.end_training()\n-\n     if args.output_dir is not None:\n         accelerator.wait_for_everyone()\n         unwrapped_model = accelerator.unwrap_model(model)\n@@ -679,6 +676,9 @@ def preprocess_function(examples):\n         with open(os.path.join(args.output_dir, \"all_results.json\"), \"w\") as f:\n             json.dump(all_results, f)\n \n+    accelerator.wait_for_everyone()\n+    accelerator.end_training()\n+\n \n if __name__ == \"__main__\":\n     main()"
        },
        {
            "sha": "cf42f0d01c257eb5320adce22499d0b38d39988f",
            "filename": "examples/pytorch/token-classification/run_ner_no_trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Ftoken-classification%2Frun_ner_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Ftoken-classification%2Frun_ner_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftoken-classification%2Frun_ner_no_trainer.py?ref=b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a",
            "patch": "@@ -794,9 +794,6 @@ def compute_metrics():\n                 output_dir = os.path.join(args.output_dir, output_dir)\n             accelerator.save_state(output_dir)\n \n-    if args.with_tracking:\n-        accelerator.end_training()\n-\n     if args.output_dir is not None:\n         accelerator.wait_for_everyone()\n         unwrapped_model = accelerator.unwrap_model(model)\n@@ -826,6 +823,9 @@ def compute_metrics():\n                         all_results[key] = int(value)\n                 json.dump(all_results, f)\n \n+    accelerator.wait_for_everyone()\n+    accelerator.end_training()\n+\n \n if __name__ == \"__main__\":\n     main()"
        },
        {
            "sha": "876bf3ebdb04078294500e72a8627055db6ff188",
            "filename": "examples/pytorch/translation/run_translation_no_trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Ftranslation%2Frun_translation_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a/examples%2Fpytorch%2Ftranslation%2Frun_translation_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftranslation%2Frun_translation_no_trainer.py?ref=b0c6ff5e13d1b072bf33de0d5ed534ac787d1e9a",
            "patch": "@@ -762,9 +762,6 @@ def postprocess_text(preds, labels):\n                 output_dir = os.path.join(args.output_dir, output_dir)\n             accelerator.save_state(output_dir)\n \n-    if args.with_tracking:\n-        accelerator.end_training()\n-\n     if args.output_dir is not None:\n         accelerator.wait_for_everyone()\n         unwrapped_model = accelerator.unwrap_model(model)\n@@ -784,6 +781,9 @@ def postprocess_text(preds, labels):\n         with open(os.path.join(args.output_dir, \"all_results.json\"), \"w\") as f:\n             json.dump({\"eval_bleu\": eval_metric[\"score\"]}, f)\n \n+    accelerator.wait_for_everyone()\n+    accelerator.end_training()\n+\n \n if __name__ == \"__main__\":\n     main()"
        }
    ],
    "stats": {
        "total": 72,
        "additions": 36,
        "deletions": 36
    }
}