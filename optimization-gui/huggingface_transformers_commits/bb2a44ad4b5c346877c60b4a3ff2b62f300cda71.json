{
    "author": "MekkCyber",
    "message": "Fix Quark quantization config (#37578)\n\nfix",
    "sha": "bb2a44ad4b5c346877c60b4a3ff2b62f300cda71",
    "files": [
        {
            "sha": "067b93c91a53fa6e6d58b728779108a3d2559ddb",
            "filename": "src/transformers/utils/quantization_config.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/bb2a44ad4b5c346877c60b4a3ff2b62f300cda71/src%2Ftransformers%2Futils%2Fquantization_config.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bb2a44ad4b5c346877c60b4a3ff2b62f300cda71/src%2Ftransformers%2Futils%2Fquantization_config.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fquantization_config.py?ref=bb2a44ad4b5c346877c60b4a3ff2b62f300cda71",
            "patch": "@@ -1821,7 +1821,10 @@ def __init__(\n             from quark.torch.export.config.config import JsonExporterConfig\n             from quark.torch.export.main_export.quant_config_parser import QuantConfigParser\n             from quark.torch.quantization.config.config import Config\n-\n+        else:\n+            raise ImportError(\n+                \"Quark is not installed. Please refer to https://quark.docs.amd.com/latest/install.html.\"\n+            )\n         # This might be e.g. `\"fp8\"` or `\"awq\"`.\n         self.custom_mode = kwargs[\"quant_method\"]\n         self.legacy = \"export\" not in kwargs"
        },
        {
            "sha": "4e2c964d56c55ec9a9a2c741c661e29dc4b5d093",
            "filename": "tests/quantization/quark_integration/test_quark.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/bb2a44ad4b5c346877c60b4a3ff2b62f300cda71/tests%2Fquantization%2Fquark_integration%2Ftest_quark.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bb2a44ad4b5c346877c60b4a3ff2b62f300cda71/tests%2Fquantization%2Fquark_integration%2Ftest_quark.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fquantization%2Fquark_integration%2Ftest_quark.py?ref=bb2a44ad4b5c346877c60b4a3ff2b62f300cda71",
            "patch": "@@ -33,6 +33,7 @@\n     from quark.torch.export.nn.modules.qparamslinear import QParamsLinear\n \n \n+@require_quark\n class QuarkConfigTest(unittest.TestCase):\n     def test_commmon_args(self):\n         config = AutoConfig.from_pretrained(\"amd/Llama-3.1-8B-Instruct-w-int8-a-int8-sym-test\")"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 5,
        "deletions": 1
    }
}