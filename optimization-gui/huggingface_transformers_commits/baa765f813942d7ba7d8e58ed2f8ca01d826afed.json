{
    "author": "aroun-coumar",
    "message": "Fixes for issue #33763 in idefics2 model (#33766)",
    "sha": "baa765f813942d7ba7d8e58ed2f8ca01d826afed",
    "files": [
        {
            "sha": "056811138155f3a7dec194d4c43a0d6c0bc43ddd",
            "filename": "src/transformers/models/idefics2/modeling_idefics2.py",
            "status": "modified",
            "additions": 12,
            "deletions": 11,
            "changes": 23,
            "blob_url": "https://github.com/huggingface/transformers/blob/baa765f813942d7ba7d8e58ed2f8ca01d826afed/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/baa765f813942d7ba7d8e58ed2f8ca01d826afed/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py?ref=baa765f813942d7ba7d8e58ed2f8ca01d826afed",
            "patch": "@@ -1348,17 +1348,18 @@ def forward(\n         past_seen_tokens = 0\n         # kept for BC (non `Cache` `past_key_values` inputs)\n         return_legacy_cache = False\n-        if use_cache and not isinstance(past_key_values, Cache):\n-            return_legacy_cache = True\n-            if past_key_values is None:\n-                past_key_values = DynamicCache()\n-            else:\n-                past_key_values = DynamicCache.from_legacy_cache(past_key_values)\n-                logger.warning_once(\n-                    \"We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and \"\n-                    \"will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class \"\n-                    \"(https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)\"\n-                )\n+        if use_cache:\n+            if not isinstance(past_key_values, Cache):\n+                return_legacy_cache = True\n+                if past_key_values is None:\n+                    past_key_values = DynamicCache()\n+                else:\n+                    past_key_values = DynamicCache.from_legacy_cache(past_key_values)\n+                    logger.warning_once(\n+                        \"We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and \"\n+                        \"will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class \"\n+                        \"(https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)\"\n+                    )\n             past_seen_tokens = past_key_values.get_seq_length()\n \n         if inputs_embeds is not None and input_ids is None and past_seen_tokens == 0:"
        }
    ],
    "stats": {
        "total": 23,
        "additions": 12,
        "deletions": 11
    }
}