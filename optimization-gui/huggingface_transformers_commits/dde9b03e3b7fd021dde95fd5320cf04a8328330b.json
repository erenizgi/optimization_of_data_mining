{
    "author": "astefanutti",
    "message": "Fix no_split_modules for Llama4 pretrained models (#37673)",
    "sha": "dde9b03e3b7fd021dde95fd5320cf04a8328330b",
    "files": [
        {
            "sha": "3718a43e24a92e9fd429120c0955d92bae5726f6",
            "filename": "src/transformers/models/llama4/modeling_llama4.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/dde9b03e3b7fd021dde95fd5320cf04a8328330b/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dde9b03e3b7fd021dde95fd5320cf04a8328330b/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py?ref=dde9b03e3b7fd021dde95fd5320cf04a8328330b",
            "patch": "@@ -474,7 +474,6 @@ class Llama4PreTrainedModel(PreTrainedModel):\n     _supports_quantized_cache = True\n     _supports_static_cache = True\n     _supports_attention_backend = True\n-    _no_split_modules = [\"Llama4TextDecoderLayer\", \"Llama4VisionEncoderLayer\"]\n \n     def _init_weights(self, module):\n         std = (\n@@ -927,6 +926,7 @@ def _prepare_4d_causal_attention_mask_with_cache_position(\n \n \n class Llama4ForCausalLM(Llama4PreTrainedModel, GenerationMixin):\n+    _no_split_modules = [\"Llama4TextDecoderLayer\"]\n     base_model_prefix = \"language_model\"\n     _tied_weights_keys = [\"lm_head.weight\"]\n     _tp_plan = {\"lm_head\": \"colwise_rep\"}\n@@ -1583,6 +1583,7 @@ def forward(\n \n \n class Llama4ForConditionalGeneration(Llama4PreTrainedModel, GenerationMixin):\n+    _no_split_modules = [\"Llama4TextDecoderLayer\", \"Llama4VisionEncoderLayer\"]\n     _tp_plan = {}\n     base_model_prefix = \"\"\n     config_class = Llama4Config"
        }
    ],
    "stats": {
        "total": 3,
        "additions": 2,
        "deletions": 1
    }
}