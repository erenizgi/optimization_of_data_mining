{
    "author": "seanswyi",
    "message": "New option called `\"best\"` for `args.save_strategy`. (#31817)\n\n* Add _determine_best_metric and new saving logic.\r\n\r\n1. Logic to determine the best logic was separated out from\r\n`_save_checkpoint`.\r\n2. In `_maybe_log_save_evaluate`, whether or not a new best metric was\r\nachieved is determined after each evaluation, and if the save strategy\r\nis \"best' then the TrainerControl is updated accordingly.\r\n\r\n* Added SaveStrategy.\r\n\r\nSame as IntervalStrategy, but with a new attribute called BEST.\r\n\r\n* IntervalStrategy -> SaveStrategy\r\n\r\n* IntervalStratgy -> SaveStrategy for save_strat.\r\n\r\n* Interval -> Save in docstring.\r\n\r\n* Updated docstring for save_strategy.\r\n\r\n* Added SaveStrategy and made according changes.\r\n\r\n`save_strategy` previously followed `IntervalStrategy` but now follows\r\n`SaveStrategy`.\r\n\r\nChanges were made accordingly to the code and the docstring.\r\n\r\n* Changes from `make fixup`.\r\n\r\n* Removed redundant metrics argument.\r\n\r\n* Added new test_save_best_checkpoint test.\r\n\r\n1. Checks for both cases where `metric_for_best_model` is explicitly\r\nprovided and when it's not provided.\r\n2. The first case should have two checkpoints saved, whereas the second\r\nshould have three saved.\r\n\r\n* Changed should_training_end saving logic.\r\n\r\nThe Trainer saves a checkpoints at the end of training by default as\r\nlong as `save_strategy != SaveStrategy.NO`. This condition was modified\r\nto include `SaveStrategy.BEST` because it would be counterintuitive that\r\nwe'd only want the best checkpoint to be saved but the last one is as\r\nwell.\r\n\r\n* `args.metric_for_best_model` default to loss.\r\n\r\n* Undo metric_for_best_model update.\r\n\r\n* Remove checking metric_for_best_model.\r\n\r\n* Added test cases for loss and no metric.\r\n\r\n* Added error for metric and changed default best_metric.\r\n\r\n* Removed unused import.\r\n\r\n* `new_best_metric` -> `is_new_best_metric`\r\n\r\nCo-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>\r\n\r\n* Applied `is_new_best_metric` to all.\r\n\r\nChanges were made for consistency and also to fix a potential bug.\r\n\r\n---------\r\n\r\nCo-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>\r\nCo-authored-by: Zach Mueller <muellerzr@gmail.com>",
    "sha": "c1753436dbb8bcbcee183cdd6eba9f08a90d602a",
    "files": [
        {
            "sha": "4315e54a42fc2e0474dc4e36e4eeaee2554f6509",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 55,
            "deletions": 29,
            "changes": 84,
            "blob_url": "https://github.com/huggingface/transformers/blob/c1753436dbb8bcbcee183cdd6eba9f08a90d602a/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c1753436dbb8bcbcee183cdd6eba9f08a90d602a/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=c1753436dbb8bcbcee183cdd6eba9f08a90d602a",
            "patch": "@@ -117,9 +117,9 @@\n     EvalPrediction,\n     HPSearchBackend,\n     HubStrategy,\n-    IntervalStrategy,\n     PredictionOutput,\n     RemoveColumnsCollator,\n+    SaveStrategy,\n     TrainerMemoryTracker,\n     TrainOutput,\n     check_target_module_exists,\n@@ -419,6 +419,12 @@ def __init__(\n             raise ValueError(\n                 f\"You have set `args.eval_strategy` to {args.eval_strategy} but you didn't pass an `eval_dataset` to `Trainer`. Either set `args.eval_strategy` to `no` or pass an `eval_dataset`. \"\n             )\n+        if args.save_strategy == SaveStrategy.BEST or args.load_best_model_at_end:\n+            if args.metric_for_best_model is None:\n+                raise ValueError(\n+                    \"`args.metric_for_best_model` must be provided when using 'best' save_strategy or if `args.load_best_model_at_end` is set to `True`.\"\n+                )\n+\n         self.args = args\n         self.compute_loss_func = compute_loss_func\n         # Seed must be set before instantiating the model when using model\n@@ -2998,9 +3004,13 @@ def _maybe_log_save_evaluate(self, tr_loss, grad_norm, model, trial, epoch, igno\n         metrics = None\n         if self.control.should_evaluate:\n             metrics = self._evaluate(trial, ignore_keys_for_eval)\n+            is_new_best_metric = self._determine_best_metric(metrics=metrics, trial=trial)\n+\n+            if self.args.save_strategy == SaveStrategy.BEST:\n+                self.control.should_save = is_new_best_metric\n \n         if self.control.should_save:\n-            self._save_checkpoint(model, trial, metrics=metrics)\n+            self._save_checkpoint(model, trial)\n             self.control = self.callback_handler.on_save(self.args, self.state, self.control)\n \n     def _load_rng_state(self, checkpoint):\n@@ -3077,7 +3087,48 @@ def _load_rng_state(self, checkpoint):\n                         \"\\nThis won't yield the same results as if the training had not been interrupted.\"\n                     )\n \n-    def _save_checkpoint(self, model, trial, metrics=None):\n+    def _determine_best_metric(self, metrics, trial):\n+        \"\"\"\n+        Determine if the model should be saved based on the evaluation metrics.\n+        If args.metric_for_best_model is not set, the loss is used.\n+\n+        Returns:\n+            bool: True if a new best metric was found, else False\n+        \"\"\"\n+        is_new_best_metric = False\n+\n+        if self.args.metric_for_best_model is not None:\n+            metric_to_check = self.args.metric_for_best_model\n+\n+            if not metric_to_check.startswith(\"eval_\"):\n+                metric_to_check = f\"eval_{metric_to_check}\"\n+\n+            try:\n+                metric_value = metrics[metric_to_check]\n+            except KeyError as exc:\n+                raise KeyError(\n+                    f\"The `metric_for_best_model` training argument is set to '{metric_to_check}', which is not found in the evaluation metrics. \"\n+                    f\"The available evaluation metrics are: {list(metrics.keys())}. Consider changing the `metric_for_best_model` via the TrainingArguments.\"\n+                ) from exc\n+\n+            operator = np.greater if self.args.greater_is_better else np.less\n+\n+            if self.state.best_metric is None:\n+                self.state.best_metric = float(\"-inf\") if self.args.greater_is_better else float(\"inf\")\n+\n+            if operator(metric_value, self.state.best_metric):\n+                run_dir = self._get_output_dir(trial=trial)\n+                checkpoint_folder = f\"{PREFIX_CHECKPOINT_DIR}-{self.state.global_step}\"\n+                output_dir = os.path.join(run_dir, checkpoint_folder)\n+\n+                self.state.best_metric = metric_value\n+                self.state.best_model_checkpoint = output_dir\n+\n+                is_new_best_metric = True\n+\n+        return is_new_best_metric\n+\n+    def _save_checkpoint(self, model, trial):\n         # In all cases, including ddp/dp/deepspeed, self.model is always a reference to the model we\n         # want to save except FullyShardedDDP.\n         # assert unwrap_model(model) is self.model, \"internal model should be a reference to self.model\"\n@@ -3098,31 +3149,6 @@ def _save_checkpoint(self, model, trial, metrics=None):\n             # Save RNG state\n             self._save_rng_state(output_dir)\n \n-        # Determine the new best metric / best model checkpoint\n-        if metrics is not None and self.args.metric_for_best_model is not None:\n-            metric_to_check = self.args.metric_for_best_model\n-            if not metric_to_check.startswith(\"eval_\"):\n-                metric_to_check = f\"eval_{metric_to_check}\"\n-            try:\n-                metric_value = metrics[metric_to_check]\n-            except KeyError as exc:\n-                raise KeyError(\n-                    f\"The `metric_for_best_model` training argument is set to '{metric_to_check}', \"\n-                    f\"which is not found in the evaluation metrics. \"\n-                    f\"The available evaluation metrics are: {list(metrics.keys())}. \"\n-                    f\"Please ensure that the `compute_metrics` function returns a dictionary that includes '{metric_to_check}' or \"\n-                    f\"consider changing the `metric_for_best_model` via the TrainingArguments.\"\n-                ) from exc\n-\n-            operator = np.greater if self.args.greater_is_better else np.less\n-            if (\n-                self.state.best_metric is None\n-                or self.state.best_model_checkpoint is None\n-                or operator(metric_value, self.state.best_metric)\n-            ):\n-                self.state.best_metric = metric_value\n-                self.state.best_model_checkpoint = output_dir\n-\n         # Save the Trainer state\n         if self.args.should_save:\n             # Update `ExportableState` callbacks and `TrainerControl` state to where we are currently\n@@ -4543,7 +4569,7 @@ def _push_from_checkpoint(self, checkpoint_folder):\n         # Same for the training arguments\n         torch.save(self.args, os.path.join(output_dir, TRAINING_ARGS_NAME))\n \n-        if self.args.save_strategy == IntervalStrategy.STEPS:\n+        if self.args.save_strategy == SaveStrategy.STEPS:\n             commit_message = f\"Training in progress, step {self.state.global_step}\"\n         else:\n             commit_message = f\"Training in progress, epoch {int(self.state.epoch)}\""
        },
        {
            "sha": "ce9f2a26732c2e0859c99abe5a0c9e7cc1a47525",
            "filename": "src/transformers/trainer_callback.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/c1753436dbb8bcbcee183cdd6eba9f08a90d602a/src%2Ftransformers%2Ftrainer_callback.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c1753436dbb8bcbcee183cdd6eba9f08a90d602a/src%2Ftransformers%2Ftrainer_callback.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer_callback.py?ref=c1753436dbb8bcbcee183cdd6eba9f08a90d602a",
            "patch": "@@ -24,7 +24,7 @@\n import numpy as np\n from tqdm.auto import tqdm\n \n-from .trainer_utils import IntervalStrategy, has_length\n+from .trainer_utils import IntervalStrategy, SaveStrategy, has_length\n from .training_args import TrainingArguments\n from .utils import logging\n \n@@ -555,7 +555,7 @@ def on_step_end(self, args: TrainingArguments, state: TrainerState, control: Tra\n \n         # Save\n         if (\n-            args.save_strategy == IntervalStrategy.STEPS\n+            args.save_strategy == SaveStrategy.STEPS\n             and state.save_steps > 0\n             and state.global_step % state.save_steps == 0\n         ):\n@@ -565,7 +565,7 @@ def on_step_end(self, args: TrainingArguments, state: TrainerState, control: Tra\n         if state.global_step >= state.max_steps:\n             control.should_training_stop = True\n             # Save the model at the end if we have a save strategy\n-            if args.save_strategy != IntervalStrategy.NO:\n+            if args.save_strategy not in [SaveStrategy.NO, SaveStrategy.BEST]:\n                 control.should_save = True\n \n         return control\n@@ -580,7 +580,7 @@ def on_epoch_end(self, args: TrainingArguments, state: TrainerState, control: Tr\n             control.should_evaluate = True\n \n         # Save\n-        if args.save_strategy == IntervalStrategy.EPOCH:\n+        if args.save_strategy == SaveStrategy.EPOCH:\n             control.should_save = True\n \n         return control"
        },
        {
            "sha": "42088cd730628db229bd8accbcac74864f435f72",
            "filename": "src/transformers/trainer_utils.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/c1753436dbb8bcbcee183cdd6eba9f08a90d602a/src%2Ftransformers%2Ftrainer_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c1753436dbb8bcbcee183cdd6eba9f08a90d602a/src%2Ftransformers%2Ftrainer_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer_utils.py?ref=c1753436dbb8bcbcee183cdd6eba9f08a90d602a",
            "patch": "@@ -227,6 +227,13 @@ class IntervalStrategy(ExplicitEnum):\n     EPOCH = \"epoch\"\n \n \n+class SaveStrategy(ExplicitEnum):\n+    NO = \"no\"\n+    STEPS = \"steps\"\n+    EPOCH = \"epoch\"\n+    BEST = \"best\"\n+\n+\n class EvaluationStrategy(ExplicitEnum):\n     NO = \"no\"\n     STEPS = \"steps\""
        },
        {
            "sha": "c98e8bc41b924d974539b431df3193be24237a75",
            "filename": "src/transformers/training_args.py",
            "status": "modified",
            "additions": 8,
            "deletions": 6,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/c1753436dbb8bcbcee183cdd6eba9f08a90d602a/src%2Ftransformers%2Ftraining_args.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c1753436dbb8bcbcee183cdd6eba9f08a90d602a/src%2Ftransformers%2Ftraining_args.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftraining_args.py?ref=c1753436dbb8bcbcee183cdd6eba9f08a90d602a",
            "patch": "@@ -33,6 +33,7 @@\n     FSDPOption,\n     HubStrategy,\n     IntervalStrategy,\n+    SaveStrategy,\n     SchedulerType,\n )\n from .utils import (\n@@ -349,12 +350,13 @@ class TrainingArguments:\n \n             </Tip>\n \n-        save_strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `\"steps\"`):\n+        save_strategy (`str` or [`~trainer_utils.SaveStrategy`], *optional*, defaults to `\"steps\"`):\n             The checkpoint save strategy to adopt during training. Possible values are:\n \n                 - `\"no\"`: No save is done during training.\n                 - `\"epoch\"`: Save is done at the end of each epoch.\n                 - `\"steps\"`: Save is done every `save_steps`.\n+                - `\"best\"`: Save is done whenever a new `best_metric` is achieved.\n \n                 If `\"epoch\"` or `\"steps\"` is chosen, saving will also be performed at the\n                 very end of training, always.\n@@ -962,7 +964,7 @@ class TrainingArguments:\n         },\n     )\n     logging_nan_inf_filter: bool = field(default=True, metadata={\"help\": \"Filter nan and inf losses for logging.\"})\n-    save_strategy: Union[IntervalStrategy, str] = field(\n+    save_strategy: Union[SaveStrategy, str] = field(\n         default=\"steps\",\n         metadata={\"help\": \"The checkpoint save strategy to use.\"},\n     )\n@@ -1580,7 +1582,7 @@ def __post_init__(self):\n \n         self.eval_strategy = IntervalStrategy(self.eval_strategy)\n         self.logging_strategy = IntervalStrategy(self.logging_strategy)\n-        self.save_strategy = IntervalStrategy(self.save_strategy)\n+        self.save_strategy = SaveStrategy(self.save_strategy)\n         self.hub_strategy = HubStrategy(self.hub_strategy)\n \n         self.lr_scheduler_type = SchedulerType(self.lr_scheduler_type)\n@@ -1616,7 +1618,7 @@ def __post_init__(self):\n             if self.eval_steps != int(self.eval_steps):\n                 raise ValueError(f\"--eval_steps must be an integer if bigger than 1: {self.eval_steps}\")\n             self.eval_steps = int(self.eval_steps)\n-        if self.save_strategy == IntervalStrategy.STEPS and self.save_steps > 1:\n+        if self.save_strategy == SaveStrategy.STEPS and self.save_steps > 1:\n             if self.save_steps != int(self.save_steps):\n                 raise ValueError(f\"--save_steps must be an integer if bigger than 1: {self.save_steps}\")\n             self.save_steps = int(self.save_steps)\n@@ -2750,8 +2752,8 @@ def set_save(\n         100\n         ```\n         \"\"\"\n-        self.save_strategy = IntervalStrategy(strategy)\n-        if self.save_strategy == IntervalStrategy.STEPS and steps == 0:\n+        self.save_strategy = SaveStrategy(strategy)\n+        if self.save_strategy == SaveStrategy.STEPS and steps == 0:\n             raise ValueError(\"Setting `strategy` as 'steps' requires a positive value for `steps`.\")\n         self.save_steps = steps\n         self.save_total_limit = total_limit"
        },
        {
            "sha": "3716a78879d50170149f2fe4fdf4f5e1740b4cec",
            "filename": "src/transformers/training_args_tf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/c1753436dbb8bcbcee183cdd6eba9f08a90d602a/src%2Ftransformers%2Ftraining_args_tf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c1753436dbb8bcbcee183cdd6eba9f08a90d602a/src%2Ftransformers%2Ftraining_args_tf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftraining_args_tf.py?ref=c1753436dbb8bcbcee183cdd6eba9f08a90d602a",
            "patch": "@@ -114,7 +114,7 @@ class TFTrainingArguments(TrainingArguments):\n             Whether to log and evaluate the first `global_step` or not.\n         logging_steps (`int`, *optional*, defaults to 500):\n             Number of update steps between two logs if `logging_strategy=\"steps\"`.\n-        save_strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `\"steps\"`):\n+        save_strategy (`str` or [`~trainer_utils.SaveStrategy`], *optional*, defaults to `\"steps\"`):\n             The checkpoint save strategy to adopt during training. Possible values are:\n \n                 - `\"no\"`: No save is done during training."
        },
        {
            "sha": "b6fe807fa4961a0f4d63ccf3735918e5042be10b",
            "filename": "tests/trainer/test_trainer.py",
            "status": "modified",
            "additions": 83,
            "deletions": 0,
            "changes": 83,
            "blob_url": "https://github.com/huggingface/transformers/blob/c1753436dbb8bcbcee183cdd6eba9f08a90d602a/tests%2Ftrainer%2Ftest_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c1753436dbb8bcbcee183cdd6eba9f08a90d602a/tests%2Ftrainer%2Ftest_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_trainer.py?ref=c1753436dbb8bcbcee183cdd6eba9f08a90d602a",
            "patch": "@@ -4041,6 +4041,89 @@ def test_trainer_saves_processor(self):\n             reloaded_tokenizer(test_sentence, padding=\"max_length\").input_ids,\n         )\n \n+    def test_save_best_checkpoint(self):\n+        freq = int(64 / self.batch_size)\n+        total = int(self.n_epochs * 64 / self.batch_size)\n+\n+        # Case 1: args.metric_for_best_model == \"accuracy\".\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            trainer = get_regression_trainer(\n+                a=1.5,\n+                b=2.5,\n+                output_dir=tmpdir,\n+                learning_rate=0.1,\n+                eval_strategy=\"epoch\",\n+                save_strategy=\"best\",\n+                metric_for_best_model=\"accuracy\",\n+                compute_metrics=AlmostAccuracy(),\n+            )\n+            self.assertTrue(trainer.args.metric_for_best_model == \"accuracy\")\n+\n+            with patch.object(\n+                trainer,\n+                \"_evaluate\",\n+                side_effect=[\n+                    {\"eval_loss\": 0.03, \"eval_accuracy\": 0.60, \"epoch\": 1.0},\n+                    {\"eval_loss\": 0.02, \"eval_accuracy\": 0.65, \"epoch\": 2.0},\n+                    {\"eval_loss\": 0.01, \"eval_accuracy\": 0.64, \"epoch\": 3.0},\n+                ],\n+            ):\n+                trainer.train()\n+\n+                self.assertEqual(len(os.listdir(tmpdir)), 2)\n+                self.check_saved_checkpoints(\n+                    output_dir=tmpdir,\n+                    freq=freq,\n+                    total=total,\n+                )\n+\n+        # Case 2: args.metric_for_best_model == \"loss\".\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            trainer = get_regression_trainer(\n+                a=1.5,\n+                b=2.5,\n+                output_dir=tmpdir,\n+                learning_rate=0.1,\n+                eval_strategy=\"epoch\",\n+                save_strategy=\"best\",\n+                metric_for_best_model=\"loss\",\n+                compute_metrics=AlmostAccuracy(),\n+            )\n+            self.assertTrue(trainer.args.metric_for_best_model == \"loss\")\n+\n+            with patch.object(\n+                trainer,\n+                \"_evaluate\",\n+                side_effect=[\n+                    {\"eval_loss\": 0.03, \"eval_accuracy\": 0.60, \"epoch\": 1.0},\n+                    {\"eval_loss\": 0.02, \"eval_accuracy\": 0.65, \"epoch\": 2.0},\n+                    {\"eval_loss\": 0.03, \"eval_accuracy\": 0.66, \"epoch\": 3.0},\n+                ],\n+            ):\n+                trainer.train()\n+\n+                self.assertEqual(len(os.listdir(tmpdir)), 2)\n+                self.check_saved_checkpoints(\n+                    output_dir=tmpdir,\n+                    freq=freq,\n+                    total=total,\n+                )\n+\n+        # Case 3: Metric name not provided; throw error.\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            with self.assertRaises(ValueError) as context:\n+                trainer = get_regression_trainer(\n+                    a=1.5,\n+                    b=2.5,\n+                    output_dir=tmpdir,\n+                    learning_rate=0.1,\n+                    eval_strategy=\"epoch\",\n+                    save_strategy=\"best\",\n+                    compute_metrics=AlmostAccuracy(),\n+                )\n+\n+            self.assertIn(\"`args.metric_for_best_model` must be provided\", str(context.exception))\n+\n \n @require_torch\n @is_staging_test"
        }
    ],
    "stats": {
        "total": 198,
        "additions": 158,
        "deletions": 40
    }
}