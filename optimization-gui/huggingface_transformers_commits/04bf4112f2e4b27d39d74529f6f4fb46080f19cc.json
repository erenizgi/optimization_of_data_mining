{
    "author": "sbucaille",
    "message": "ðŸš¨ [lightglue] fix: matches order changed because of early stopped indices (#40859)\n\n* fix: bug that made early stop change order of matches\n\n* fix: applied code suggestion\n\nCo-authored-by: Pavel Iakubovskii <qubvel@gmail.com>\n\n* fix: applied code suggestion to modular\n\n* fix: integration tests\n\n---------\n\nCo-authored-by: Pavel Iakubovskii <qubvel@gmail.com>",
    "sha": "04bf4112f2e4b27d39d74529f6f4fb46080f19cc",
    "files": [
        {
            "sha": "8e9faa3e4e0439750057ff2e1cab19dff16c9867",
            "filename": "src/transformers/models/lightglue/modeling_lightglue.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/04bf4112f2e4b27d39d74529f6f4fb46080f19cc/src%2Ftransformers%2Fmodels%2Flightglue%2Fmodeling_lightglue.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/04bf4112f2e4b27d39d74529f6f4fb46080f19cc/src%2Ftransformers%2Fmodels%2Flightglue%2Fmodeling_lightglue.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flightglue%2Fmodeling_lightglue.py?ref=04bf4112f2e4b27d39d74529f6f4fb46080f19cc",
            "patch": "@@ -628,6 +628,10 @@ def _concat_early_stopped_outputs(\n         matching_scores,\n     ):\n         early_stops_indices = torch.stack(early_stops_indices)\n+        # Rearrange tensors to have the same order as the input batch\n+        ids = torch.arange(early_stops_indices.shape[0])\n+        order_indices = early_stops_indices[ids]\n+        early_stops_indices = early_stops_indices[order_indices]\n         matches, final_pruned_keypoints_indices = (\n             pad_sequence(tensor, batch_first=True, padding_value=-1)\n             for tensor in [matches, final_pruned_keypoints_indices]"
        },
        {
            "sha": "29441344c9cdfbdc9c74afa7bec493c19166844c",
            "filename": "src/transformers/models/lightglue/modular_lightglue.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/04bf4112f2e4b27d39d74529f6f4fb46080f19cc/src%2Ftransformers%2Fmodels%2Flightglue%2Fmodular_lightglue.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/04bf4112f2e4b27d39d74529f6f4fb46080f19cc/src%2Ftransformers%2Fmodels%2Flightglue%2Fmodular_lightglue.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flightglue%2Fmodular_lightglue.py?ref=04bf4112f2e4b27d39d74529f6f4fb46080f19cc",
            "patch": "@@ -786,6 +786,10 @@ def _concat_early_stopped_outputs(\n         matching_scores,\n     ):\n         early_stops_indices = torch.stack(early_stops_indices)\n+        # Rearrange tensors to have the same order as the input batch\n+        ids = torch.arange(early_stops_indices.shape[0])\n+        order_indices = early_stops_indices[ids]\n+        early_stops_indices = early_stops_indices[order_indices]\n         matches, final_pruned_keypoints_indices = (\n             pad_sequence(tensor, batch_first=True, padding_value=-1)\n             for tensor in [matches, final_pruned_keypoints_indices]"
        },
        {
            "sha": "9342b9a58fb8bfa6619393a3fb535c002786c0bb",
            "filename": "tests/models/lightglue/test_modeling_lightglue.py",
            "status": "modified",
            "additions": 38,
            "deletions": 14,
            "changes": 52,
            "blob_url": "https://github.com/huggingface/transformers/blob/04bf4112f2e4b27d39d74529f6f4fb46080f19cc/tests%2Fmodels%2Flightglue%2Ftest_modeling_lightglue.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/04bf4112f2e4b27d39d74529f6f4fb46080f19cc/tests%2Fmodels%2Flightglue%2Ftest_modeling_lightglue.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flightglue%2Ftest_modeling_lightglue.py?ref=04bf4112f2e4b27d39d74529f6f4fb46080f19cc",
            "patch": "@@ -331,31 +331,31 @@ def test_inference(self):\n         predicted_matches_values1 = outputs.matches[1, 0, 10:30]\n         predicted_matching_scores_values1 = outputs.matching_scores[1, 0, 10:30]\n \n-        expected_number_of_matches0 = 140\n+        expected_number_of_matches0 = 866\n         expected_matches_values0 = torch.tensor(\n-            [14, -1, -1, 15, 17, 13, -1, -1, -1, -1, -1, -1, 5, -1, -1, 19, -1, 10, -1, 11],\n-            dtype=torch.int64,\n-            device=torch_device,\n-        )\n-        expected_matching_scores_values0 = torch.tensor(\n-            [0.3796, 0, 0, 0.3772, 0.4439, 0.2411, 0, 0, 0.0032, 0, 0, 0, 0.2997, 0, 0, 0.6762, 0, 0.8826, 0, 0.5583],\n-            device=torch_device,\n-        )\n-\n-        expected_number_of_matches1 = 866\n-        expected_matches_values1 = torch.tensor(\n             [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n             dtype=torch.int64,\n             device=torch_device,\n         )\n-        expected_matching_scores_values1 = torch.tensor(\n+        expected_matching_scores_values0 = torch.tensor(\n             [\n                 0.6188,0.7817,0.5686,0.9353,0.9801,0.9193,0.8632,0.9111,0.9821,0.5496,\n                 0.9906,0.8682,0.9679,0.9914,0.9318,0.1910,0.9669,0.3240,0.9971,0.9923,\n             ],\n             device=torch_device\n         )  # fmt:skip\n \n+        expected_number_of_matches1 = 140\n+        expected_matches_values1 = torch.tensor(\n+            [14, -1, -1, 15, 17, 13, -1, -1, -1, -1, -1, -1, 5, -1, -1, 19, -1, 10, -1, 11],\n+            dtype=torch.int64,\n+            device=torch_device,\n+        )\n+        expected_matching_scores_values1 = torch.tensor(\n+            [0.3796, 0, 0, 0.3772, 0.4439, 0.2411, 0, 0, 0.0032, 0, 0, 0, 0.2997, 0, 0, 0.6762, 0, 0.8826, 0, 0.5583],\n+            device=torch_device,\n+        )\n+\n         # expected_early_stopping_layer = 2\n         # predicted_early_stopping_layer = torch.max(outputs.prune[1]).item()\n         # self.assertEqual(predicted_early_stopping_layer, expected_early_stopping_layer)\n@@ -375,7 +375,6 @@ def test_inference(self):\n         Such CUDA inconsistencies can be found\n         [here](https://github.com/huggingface/transformers/pull/33200/files#r1785980300)\n         \"\"\"\n-\n         self.assertTrue(abs(predicted_number_of_matches0 - expected_number_of_matches0) < 4)\n         self.assertTrue(abs(predicted_number_of_matches1 - expected_number_of_matches1) < 4)\n         self.assertTrue(\n@@ -590,3 +589,28 @@ def test_inference_without_early_stop_and_keypoint_pruning(self):\n         )\n         self.assertTrue(torch.sum(predicted_matches_values0 != expected_matches_values0) < 4)\n         self.assertTrue(torch.sum(predicted_matches_values1 != expected_matches_values1) < 4)\n+\n+    @slow\n+    def test_inference_order_with_early_stop(self):\n+        model = LightGlueForKeypointMatching.from_pretrained(\n+            \"ETH-CVG/lightglue_superpoint\", attn_implementation=\"eager\"\n+        ).to(torch_device)\n+        preprocessor = self.default_image_processor\n+        images = prepare_imgs()\n+        # [[image2, image0], [image1, image1]] -> [[image2, image0], [image2, image0], [image1, image1]]\n+        images = [images[0]] + images  # adding a 3rd pair to test batching with early stopping\n+        inputs = preprocessor(images=images, return_tensors=\"pt\").to(torch_device)\n+        with torch.no_grad():\n+            outputs = model(**inputs, output_hidden_states=True, output_attentions=True)\n+\n+        predicted_number_of_matches_pair0 = torch.sum(outputs.matches[0][0] != -1).item()\n+        predicted_number_of_matches_pair1 = torch.sum(outputs.matches[1][0] != -1).item()\n+        predicted_number_of_matches_pair2 = torch.sum(outputs.matches[2][0] != -1).item()\n+\n+        # pair 0 and 1 are the same, so should have the same number of matches\n+        # pair 2 is [image1, image1] so should have more matches than first two pairs\n+        # This ensures that early stopping does not affect the order of the outputs\n+        # See : https://huggingface.co/ETH-CVG/lightglue_superpoint/discussions/6\n+        # The bug made the pairs switch order when early stopping was activated\n+        self.assertTrue(predicted_number_of_matches_pair0 == predicted_number_of_matches_pair1)\n+        self.assertTrue(predicted_number_of_matches_pair0 < predicted_number_of_matches_pair2)"
        }
    ],
    "stats": {
        "total": 60,
        "additions": 46,
        "deletions": 14
    }
}