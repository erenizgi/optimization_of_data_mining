{
    "author": "ydshieh",
    "message": "Skip `TvpImageProcessingTest::test_slow_fast_equivalence` (#40593)\n\nfix\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "8e0b2c8baf880c007514eb0712201d604433d614",
    "files": [
        {
            "sha": "28581290e9d1de001017a8d49beb91bdae4a8e43",
            "filename": "tests/models/tvp/test_image_processing_tvp.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/8e0b2c8baf880c007514eb0712201d604433d614/tests%2Fmodels%2Ftvp%2Ftest_image_processing_tvp.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8e0b2c8baf880c007514eb0712201d604433d614/tests%2Fmodels%2Ftvp%2Ftest_image_processing_tvp.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ftvp%2Ftest_image_processing_tvp.py?ref=8e0b2c8baf880c007514eb0712201d604433d614",
            "patch": "@@ -19,7 +19,7 @@\n import numpy as np\n \n from transformers.image_transforms import PaddingMode\n-from transformers.testing_utils import is_flaky, require_torch, require_vision\n+from transformers.testing_utils import require_torch, require_vision\n from transformers.utils import is_torch_available, is_torchvision_available, is_vision_available\n \n from ...test_image_processing_common import ImageProcessingTestMixin, prepare_video_inputs\n@@ -349,16 +349,16 @@ def test_call_pytorch(self):\n \n     @require_vision\n     @require_torch\n-    @is_flaky(\n-        description=\"FIXME: @yoni probably because of an extra 'time' dimension and since image processors don't handle it well?\"\n+    @unittest.skip(\n+        reason=\"FIXME: @yoni probably because of an extra 'time' dimension and since image processors don't handle it well?\"\n     )\n     def test_slow_fast_equivalence(self):\n         super().test_slow_fast_equivalence()\n \n     @require_vision\n     @require_torch\n-    @is_flaky(\n-        description=\"FIXME: @yoni probably because of an extra 'time' dimension and since image processors don't handle it well?\"\n+    @unittest.skip(\n+        reason=\"FIXME: @yoni probably because of an extra 'time' dimension and since image processors don't handle it well?\"\n     )\n     def test_slow_fast_equivalence_batched(self):\n         if not self.test_slow_image_processor or not self.test_fast_image_processor:"
        }
    ],
    "stats": {
        "total": 10,
        "additions": 5,
        "deletions": 5
    }
}