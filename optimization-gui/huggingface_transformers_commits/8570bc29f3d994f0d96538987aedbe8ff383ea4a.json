{
    "author": "Isotr0py",
    "message": "Fix missing fast tokenizer/image_processor in whisper/qwen2.5-omni processor (#39244)\n\n* fix missing fast tokenizer in whisper processor\n\nSigned-off-by: Isotr0py <2037008807@qq.com>\n\n* fix processor test\n\nSigned-off-by: Isotr0py <2037008807@qq.com>\n\n* fix qwen2.5 omni processor\n\nSigned-off-by: Isotr0py <2037008807@qq.com>\n\n---------\n\nSigned-off-by: Isotr0py <2037008807@qq.com>",
    "sha": "8570bc29f3d994f0d96538987aedbe8ff383ea4a",
    "files": [
        {
            "sha": "7bf11c4f66515dfdd3fc0f798b232ecbc03953b7",
            "filename": "src/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/8570bc29f3d994f0d96538987aedbe8ff383ea4a/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8570bc29f3d994f0d96538987aedbe8ff383ea4a/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py?ref=8570bc29f3d994f0d96538987aedbe8ff383ea4a",
            "patch": "@@ -93,8 +93,8 @@ class Qwen2_5OmniProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"video_processor\", \"feature_extractor\", \"tokenizer\"]\n-    image_processor_class = \"Qwen2VLImageProcessor\"\n-    video_processor_class = \"Qwen2VLVideoProcessor\"\n+    image_processor_class = \"AutoImageProcessor\"\n+    video_processor_class = \"AutoVideoProcessor\"\n     feature_extractor_class = \"WhisperFeatureExtractor\"\n     tokenizer_class = (\"Qwen2Tokenizer\", \"Qwen2TokenizerFast\")\n "
        },
        {
            "sha": "6708da67747c3755fcab7b8b76c10687339409b2",
            "filename": "src/transformers/models/whisper/processing_whisper.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8570bc29f3d994f0d96538987aedbe8ff383ea4a/src%2Ftransformers%2Fmodels%2Fwhisper%2Fprocessing_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8570bc29f3d994f0d96538987aedbe8ff383ea4a/src%2Ftransformers%2Fmodels%2Fwhisper%2Fprocessing_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Fprocessing_whisper.py?ref=8570bc29f3d994f0d96538987aedbe8ff383ea4a",
            "patch": "@@ -35,7 +35,7 @@ class WhisperProcessor(ProcessorMixin):\n     \"\"\"\n \n     feature_extractor_class = \"WhisperFeatureExtractor\"\n-    tokenizer_class = \"WhisperTokenizer\"\n+    tokenizer_class = (\"WhisperTokenizer\", \"WhisperTokenizerFast\")\n \n     def __init__(self, feature_extractor, tokenizer):\n         super().__init__(feature_extractor, tokenizer)"
        },
        {
            "sha": "86451b5412bb249c90b18741eb09bd525302c276",
            "filename": "tests/models/whisper/test_processor_whisper.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/8570bc29f3d994f0d96538987aedbe8ff383ea4a/tests%2Fmodels%2Fwhisper%2Ftest_processor_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8570bc29f3d994f0d96538987aedbe8ff383ea4a/tests%2Fmodels%2Fwhisper%2Ftest_processor_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwhisper%2Ftest_processor_whisper.py?ref=8570bc29f3d994f0d96538987aedbe8ff383ea4a",
            "patch": "@@ -19,7 +19,7 @@\n import numpy as np\n import pytest\n \n-from transformers import WhisperTokenizer, is_speech_available\n+from transformers import WhisperTokenizer, WhisperTokenizerFast, is_speech_available\n from transformers.testing_utils import require_sentencepiece, require_torch, require_torchaudio\n \n from .test_feature_extraction_whisper import floats_list\n@@ -60,7 +60,7 @@ def test_save_load_pretrained_default(self):\n         processor = WhisperProcessor.from_pretrained(self.tmpdirname)\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer.get_vocab())\n-        self.assertIsInstance(processor.tokenizer, WhisperTokenizer)\n+        self.assertIsInstance(processor.tokenizer, WhisperTokenizerFast)\n \n         self.assertEqual(processor.feature_extractor.to_json_string(), feature_extractor.to_json_string())\n         self.assertIsInstance(processor.feature_extractor, WhisperFeatureExtractor)\n@@ -77,7 +77,7 @@ def test_save_load_pretrained_additional_features(self):\n         )\n \n         self.assertEqual(processor.tokenizer.get_vocab(), tokenizer_add_kwargs.get_vocab())\n-        self.assertIsInstance(processor.tokenizer, WhisperTokenizer)\n+        self.assertIsInstance(processor.tokenizer, WhisperTokenizerFast)\n \n         self.assertEqual(processor.feature_extractor.to_json_string(), feature_extractor_add_kwargs.to_json_string())\n         self.assertIsInstance(processor.feature_extractor, WhisperFeatureExtractor)"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 6,
        "deletions": 6
    }
}