{
    "author": "SunMarc",
    "message": "Fix tests due to breaking change in accelerate (#39451)\n\n* update values\n\n* fix",
    "sha": "565dd0bad74a46d85c41e2d870f803d9e7a1a94e",
    "files": [
        {
            "sha": "dd0e3af4ab499b6793ec848022e3af8349aa5d79",
            "filename": "tests/trainer/test_trainer.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/565dd0bad74a46d85c41e2d870f803d9e7a1a94e/tests%2Ftrainer%2Ftest_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/565dd0bad74a46d85c41e2d870f803d9e7a1a94e/tests%2Ftrainer%2Ftest_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_trainer.py?ref=565dd0bad74a46d85c41e2d870f803d9e7a1a94e",
            "patch": "@@ -3394,7 +3394,7 @@ def test_auto_batch_size_with_deepspeed(self):\n         )\n         trainer = Trainer(model, args, train_dataset=train_dataset, callbacks=[MockCudaOOMCallback()])\n         trainer.train()\n-        self.assertEqual(trainer._train_batch_size, 8)\n+        self.assertEqual(trainer._train_batch_size, 14)\n \n     def test_auto_batch_size_with_resume_from_checkpoint(self):\n         train_dataset = RegressionDataset(length=128)\n@@ -3414,16 +3414,16 @@ def test_auto_batch_size_with_resume_from_checkpoint(self):\n         )\n         trainer = Trainer(model, args, train_dataset=train_dataset, callbacks=[MockCudaOOMCallback()])\n         trainer.train()\n-        # After `auto_find_batch_size` is ran we should now be at 8\n-        self.assertEqual(trainer._train_batch_size, 8)\n+        # After `auto_find_batch_size` is ran we should now be at 16*0.9=14\n+        self.assertEqual(trainer._train_batch_size, 14)\n \n         # We can then make a new Trainer\n         trainer = Trainer(model, args, train_dataset=train_dataset)\n         # Check we are at 16 to start\n         self.assertEqual(trainer._train_batch_size, 16 * max(trainer.args.n_gpu, 1))\n         trainer.train(resume_from_checkpoint=True)\n-        # We should be back to 8 again, picking up based upon the last ran Trainer\n-        self.assertEqual(trainer._train_batch_size, 8)\n+        # We should be back to 14 again, picking up based upon the last ran Trainer\n+        self.assertEqual(trainer._train_batch_size, 14)\n \n     # regression for this issue: https://github.com/huggingface/transformers/issues/12970\n     def test_training_with_resume_from_checkpoint_false(self):"
        },
        {
            "sha": "f24031b5d4ce876428e3c50980ecdc97c4e40335",
            "filename": "tests/trainer/test_trainer_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/565dd0bad74a46d85c41e2d870f803d9e7a1a94e/tests%2Ftrainer%2Ftest_trainer_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/565dd0bad74a46d85c41e2d870f803d9e7a1a94e/tests%2Ftrainer%2Ftest_trainer_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_trainer_utils.py?ref=565dd0bad74a46d85c41e2d870f803d9e7a1a94e",
            "patch": "@@ -464,7 +464,7 @@ def mock_training_loop_function(batch_size):\n                 raise RuntimeError(\"CUDA out of memory.\")\n \n         mock_training_loop_function()\n-        self.assertEqual(batch_sizes, [64, 32, 16])\n+        self.assertEqual(batch_sizes, [64, 57, 51, 45, 40, 36, 32, 28, 25, 22, 19, 17, 15])\n \n     @require_accelerate\n     def test_executable_batch_size_no_search(self):"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 6,
        "deletions": 6
    }
}