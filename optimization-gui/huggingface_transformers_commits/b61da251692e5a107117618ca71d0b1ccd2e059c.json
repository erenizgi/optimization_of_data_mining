{
    "author": "zucchini-nlp",
    "message": "Remove duplicated processor class from config (#42806)\n\n* remove duplicated processor class from config\n\n* adjust the test cases\n\n* check public and private attr, both were used in the past",
    "sha": "b61da251692e5a107117618ca71d0b1ccd2e059c",
    "files": [
        {
            "sha": "c6fcb70e64f1ac39a450f2297191c4a8fbff7a51",
            "filename": "examples/pytorch/speech-recognition/run_speech_recognition_seq2seq.py",
            "status": "modified",
            "additions": 14,
            "deletions": 29,
            "changes": 43,
            "blob_url": "https://github.com/huggingface/transformers/blob/b61da251692e5a107117618ca71d0b1ccd2e059c/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_seq2seq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b61da251692e5a107117618ca71d0b1ccd2e059c/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_seq2seq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_seq2seq.py?ref=b61da251692e5a107117618ca71d0b1ccd2e059c",
            "patch": "@@ -45,10 +45,8 @@\n import transformers\n from transformers import (\n     AutoConfig,\n-    AutoFeatureExtractor,\n     AutoModelForSpeechSeq2Seq,\n     AutoProcessor,\n-    AutoTokenizer,\n     HfArgumentParser,\n     Seq2SeqTrainer,\n     Seq2SeqTrainingArguments,\n@@ -396,17 +394,9 @@ def main():\n     if getattr(config, \"model_type\", None) == \"whisper\":\n         config.update({\"apply_spec_augment\": model_args.apply_spec_augment})\n \n-    feature_extractor = AutoFeatureExtractor.from_pretrained(\n-        (model_args.feature_extractor_name if model_args.feature_extractor_name else model_args.model_name_or_path),\n-        cache_dir=model_args.cache_dir,\n-        revision=model_args.model_revision,\n-        token=model_args.token,\n-        trust_remote_code=model_args.trust_remote_code,\n-    )\n-    tokenizer = AutoTokenizer.from_pretrained(\n-        (model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path),\n+    processor = AutoProcessor.from_pretrained(\n+        model_args.model_name_or_path,\n         cache_dir=model_args.cache_dir,\n-        use_fast=model_args.use_fast_tokenizer,\n         revision=model_args.model_revision,\n         token=model_args.token,\n         trust_remote_code=model_args.trust_remote_code,\n@@ -432,7 +422,7 @@ def main():\n \n     if hasattr(model.generation_config, \"is_multilingual\") and model.generation_config.is_multilingual:\n         # We only need to set the language and task ids in a multilingual setting\n-        tokenizer.set_prefix_tokens(language=data_args.language, task=data_args.task)\n+        processor.tokenizer.set_prefix_tokens(language=data_args.language, task=data_args.task)\n         model.generation_config.language = data_args.language\n         model.generation_config.task = data_args.task\n     elif data_args.language is not None:\n@@ -461,20 +451,20 @@ def main():\n \n     # 6. Resample speech dataset if necessary\n     dataset_sampling_rate = next(iter(raw_datasets.values())).features[data_args.audio_column_name].sampling_rate\n-    if dataset_sampling_rate != feature_extractor.sampling_rate:\n+    if dataset_sampling_rate != processor.feature_extractor.sampling_rate:\n         raw_datasets = raw_datasets.cast_column(\n             data_args.audio_column_name,\n-            datasets.features.Audio(sampling_rate=feature_extractor.sampling_rate),\n+            datasets.features.Audio(sampling_rate=processor.feature_extractor.sampling_rate),\n         )\n \n     # 7. Preprocessing the datasets.\n     # We need to read the audio files as arrays and tokenize the targets.\n-    max_input_length = data_args.max_duration_in_seconds * feature_extractor.sampling_rate\n-    min_input_length = data_args.min_duration_in_seconds * feature_extractor.sampling_rate\n+    max_input_length = data_args.max_duration_in_seconds * processor.feature_extractor.sampling_rate\n+    min_input_length = data_args.min_duration_in_seconds * processor.feature_extractor.sampling_rate\n     audio_column_name = data_args.audio_column_name\n     num_workers = data_args.preprocessing_num_workers\n     text_column_name = data_args.text_column_name\n-    model_input_name = feature_extractor.model_input_names[0]\n+    model_input_name = processor.feature_extractor.model_input_names[0]\n     do_lower_case = data_args.do_lower_case\n     # if SpecAugment is used for whisper models, return attention_mask to guide the mask along time axis\n     forward_attention_mask = (\n@@ -492,7 +482,7 @@ def main():\n     def prepare_dataset(batch):\n         # process audio\n         sample = batch[audio_column_name]\n-        inputs = feature_extractor(\n+        inputs = processor.feature_extractor(\n             sample[\"array\"],\n             sampling_rate=sample[\"sampling_rate\"],\n             return_attention_mask=forward_attention_mask,\n@@ -505,7 +495,7 @@ def prepare_dataset(batch):\n \n         # process targets\n         input_str = batch[text_column_name].lower() if do_lower_case else batch[text_column_name]\n-        batch[\"labels\"] = tokenizer(input_str).input_ids\n+        batch[\"labels\"] = processor.tokenizer(input_str).input_ids\n         return batch\n \n     with training_args.main_process_first(desc=\"dataset map pre-processing\"):\n@@ -543,11 +533,11 @@ def is_audio_in_length_range(length):\n     def compute_metrics(pred):\n         pred_ids = pred.predictions\n \n-        pred.label_ids[pred.label_ids == -100] = tokenizer.pad_token_id\n+        pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n \n-        pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n+        pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n         # we do not want to group tokens when computing the metrics\n-        label_str = tokenizer.batch_decode(pred.label_ids, skip_special_tokens=True)\n+        label_str = processor.tokenizer.batch_decode(pred.label_ids, skip_special_tokens=True)\n \n         wer = metric.compute(predictions=pred_str, references=label_str)\n \n@@ -558,13 +548,8 @@ def compute_metrics(pred):\n     with training_args.main_process_first():\n         # only the main process saves them\n         if is_main_process(training_args.local_process_index):\n-            # save feature extractor, tokenizer and config\n-            feature_extractor.save_pretrained(training_args.output_dir)\n-            tokenizer.save_pretrained(training_args.output_dir)\n             config.save_pretrained(training_args.output_dir)\n \n-    processor = AutoProcessor.from_pretrained(training_args.output_dir)\n-\n     # 10. Define data collator\n     data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n         processor=processor,\n@@ -578,7 +563,7 @@ def compute_metrics(pred):\n         args=training_args,\n         train_dataset=vectorized_datasets[\"train\"] if training_args.do_train else None,\n         eval_dataset=vectorized_datasets[\"eval\"] if training_args.do_eval else None,\n-        processing_class=feature_extractor,\n+        processing_class=processor.feature_extractor,\n         data_collator=data_collator,\n         compute_metrics=(compute_metrics if training_args.predict_with_generate else None),\n     )"
        },
        {
            "sha": "3c635087a461fc9337be6f32b776487223036ea6",
            "filename": "src/transformers/feature_extraction_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 12,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/b61da251692e5a107117618ca71d0b1ccd2e059c/src%2Ftransformers%2Ffeature_extraction_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b61da251692e5a107117618ca71d0b1ccd2e059c/src%2Ftransformers%2Ffeature_extraction_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ffeature_extraction_utils.py?ref=b61da251692e5a107117618ca71d0b1ccd2e059c",
            "patch": "@@ -256,8 +256,8 @@ class FeatureExtractionMixin(PushToHubMixin):\n \n     def __init__(self, **kwargs):\n         \"\"\"Set elements of `kwargs` as attributes.\"\"\"\n-        # Pop \"processor_class\" as it should be saved as private attribute\n-        self._processor_class = kwargs.pop(\"processor_class\", None)\n+        # Pop \"processor_class\", it should not be saved in feature extractor config\n+        kwargs.pop(\"processor_class\", None)\n         # Additional attributes without default values\n         for key, value in kwargs.items():\n             try:\n@@ -266,10 +266,6 @@ def __init__(self, **kwargs):\n                 logger.error(f\"Can't set {key} with value {value} for {self}\")\n                 raise err\n \n-    def _set_processor_class(self, processor_class: str):\n-        \"\"\"Sets processor class as an attribute.\"\"\"\n-        self._processor_class = processor_class\n-\n     @classmethod\n     def from_pretrained(\n         cls: type[SpecificFeatureExtractorType],\n@@ -613,12 +609,6 @@ def to_json_string(self) -> str:\n             if isinstance(value, np.ndarray):\n                 dictionary[key] = value.tolist()\n \n-        # make sure private name \"_processor_class\" is correctly\n-        # saved as \"processor_class\"\n-        _processor_class = dictionary.pop(\"_processor_class\", None)\n-        if _processor_class is not None:\n-            dictionary[\"processor_class\"] = _processor_class\n-\n         return json.dumps(dictionary, indent=2, sort_keys=True) + \"\\n\"\n \n     def to_json_file(self, json_file_path: Union[str, os.PathLike]):"
        },
        {
            "sha": "da8faa6e261010aa4206674df9e10fc1595a7198",
            "filename": "src/transformers/image_processing_base.py",
            "status": "modified",
            "additions": 2,
            "deletions": 12,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/b61da251692e5a107117618ca71d0b1ccd2e059c/src%2Ftransformers%2Fimage_processing_base.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b61da251692e5a107117618ca71d0b1ccd2e059c/src%2Ftransformers%2Fimage_processing_base.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fimage_processing_base.py?ref=b61da251692e5a107117618ca71d0b1ccd2e059c",
            "patch": "@@ -71,8 +71,8 @@ def __init__(self, **kwargs):\n         # This key was saved while we still used `XXXFeatureExtractor` for image processing. Now we use\n         # `XXXImageProcessor`, this attribute and its value are misleading.\n         kwargs.pop(\"feature_extractor_type\", None)\n-        # Pop \"processor_class\" as it should be saved as private attribute\n-        self._processor_class = kwargs.pop(\"processor_class\", None)\n+        # Pop \"processor_class\", should not be saved with image processing config anymore\n+        kwargs.pop(\"processor_class\", None)\n         # Additional attributes without default values\n         for key, value in kwargs.items():\n             try:\n@@ -81,10 +81,6 @@ def __init__(self, **kwargs):\n                 logger.error(f\"Can't set {key} with value {value} for {self}\")\n                 raise err\n \n-    def _set_processor_class(self, processor_class: str):\n-        \"\"\"Sets processor class as an attribute.\"\"\"\n-        self._processor_class = processor_class\n-\n     @classmethod\n     def from_pretrained(\n         cls: type[ImageProcessorType],\n@@ -428,12 +424,6 @@ def to_json_string(self) -> str:\n             if isinstance(value, np.ndarray):\n                 dictionary[key] = value.tolist()\n \n-        # make sure private name \"_processor_class\" is correctly\n-        # saved as \"processor_class\"\n-        _processor_class = dictionary.pop(\"_processor_class\", None)\n-        if _processor_class is not None:\n-            dictionary[\"processor_class\"] = _processor_class\n-\n         return json.dumps(dictionary, indent=2, sort_keys=True) + \"\\n\"\n \n     def to_json_file(self, json_file_path: Union[str, os.PathLike]):"
        },
        {
            "sha": "d70fa981cbb1047fb62bc223882c4321ffff1de0",
            "filename": "src/transformers/processing_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 14,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/b61da251692e5a107117618ca71d0b1ccd2e059c/src%2Ftransformers%2Fprocessing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b61da251692e5a107117618ca71d0b1ccd2e059c/src%2Ftransformers%2Fprocessing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fprocessing_utils.py?ref=b61da251692e5a107117618ca71d0b1ccd2e059c",
            "patch": "@@ -702,17 +702,6 @@ def to_dict(self) -> dict[str, Any]:\n         if \"chat_template\" in output:\n             del output[\"chat_template\"]\n \n-        def save_public_processor_class(dictionary):\n-            # make sure private name \"_processor_class\" is correctly\n-            # saved as \"processor_class\"\n-            _processor_class = dictionary.pop(\"_processor_class\", None)\n-            if _processor_class is not None:\n-                dictionary[\"processor_class\"] = _processor_class\n-            for value in dictionary.values():\n-                if isinstance(value, dict):\n-                    save_public_processor_class(value)\n-            return dictionary\n-\n         def cast_array_to_list(dictionary):\n             \"\"\"\n             Numpy arrays are not serialiazable but can be in pre-processing dicts.\n@@ -743,7 +732,6 @@ def cast_array_to_list(dictionary):\n             )\n         }\n         output = cast_array_to_list(output)\n-        output = save_public_processor_class(output)\n         output[\"processor_class\"] = self.__class__.__name__\n \n         return output\n@@ -816,15 +804,15 @@ def save_pretrained(self, save_directory, push_to_hub: bool = False, **kwargs):\n \n         for attribute_name in self.get_attributes():\n             attribute = getattr(self, attribute_name)\n-            if hasattr(attribute, \"_set_processor_class\"):\n-                attribute._set_processor_class(self.__class__.__name__)\n \n             # Save the tokenizer in its own vocab file. The other attributes are saved as part of `processor_config.json`\n             if attribute_name == \"tokenizer\":\n+                attribute._set_processor_class(self.__class__.__name__)\n                 attribute.save_pretrained(save_directory)\n             # if a model has multiple tokenizers, save the additional tokenizers in their own folders.\n             # Note that the additional tokenizers must have \"tokenizer\" in their attribute name.\n             elif \"tokenizer\" in attribute_name:\n+                attribute._set_processor_class(self.__class__.__name__)\n                 attribute.save_pretrained(os.path.join(save_directory, attribute_name))\n             elif attribute._auto_class is not None:\n                 custom_object_save(attribute, save_directory, config=attribute)"
        },
        {
            "sha": "e62693efdd83b9c6c188e89519853c4b477413ee",
            "filename": "src/transformers/video_processing_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 7,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/b61da251692e5a107117618ca71d0b1ccd2e059c/src%2Ftransformers%2Fvideo_processing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b61da251692e5a107117618ca71d0b1ccd2e059c/src%2Ftransformers%2Fvideo_processing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fvideo_processing_utils.py?ref=b61da251692e5a107117618ca71d0b1ccd2e059c",
            "patch": "@@ -175,7 +175,7 @@ class BaseVideoProcessor(BaseImageProcessorFast):\n     def __init__(self, **kwargs: Unpack[VideosKwargs]) -> None:\n         super().__init__()\n \n-        self._processor_class = kwargs.pop(\"processor_class\", None)\n+        kwargs.pop(\"processor_class\", None)\n \n         # Additional attributes without default values\n         for key, value in kwargs.items():\n@@ -799,12 +799,6 @@ def to_json_string(self) -> str:\n             if isinstance(value, np.ndarray):\n                 dictionary[key] = value.tolist()\n \n-        # make sure private name \"_processor_class\" is correctly\n-        # saved as \"processor_class\"\n-        _processor_class = dictionary.pop(\"_processor_class\", None)\n-        if _processor_class is not None:\n-            dictionary[\"processor_class\"] = _processor_class\n-\n         return json.dumps(dictionary, indent=2, sort_keys=True) + \"\\n\"\n \n     def to_json_file(self, json_file_path: Union[str, os.PathLike]):"
        },
        {
            "sha": "cf506c7323f0c7a5684cba3f00376eaa74dd5c7b",
            "filename": "tests/test_processing_common.py",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/b61da251692e5a107117618ca71d0b1ccd2e059c/tests%2Ftest_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b61da251692e5a107117618ca71d0b1ccd2e059c/tests%2Ftest_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_processing_common.py?ref=b61da251692e5a107117618ca71d0b1ccd2e059c",
            "patch": "@@ -428,6 +428,14 @@ def test_processor_from_and_save_pretrained(self):\n \n                     # tokenizer repr contains model-path from where we loaded\n                     if \"tokenizer\" not in attribute:\n+                        # We don't store/load `_processor_class` for subprocessors.\n+                        # The `_processor_class` is saved once per config, at general level\n+                        self.assertFalse(hasattr(attribute_second, \"_processor_class\"))\n+                        self.assertFalse(hasattr(attribute_first, \"_processor_class\"))\n+\n+                        self.assertFalse(hasattr(attribute_second, \"processor_class\"))\n+                        self.assertFalse(hasattr(attribute_first, \"processor_class\"))\n+\n                         self.assertEqual(repr(attribute_first), repr(attribute_second))\n \n     def test_processor_from_and_save_pretrained_as_nested_dict(self):"
        },
        {
            "sha": "96efad6df57cef31bf02df6ec2ca228bf6763d5c",
            "filename": "tests/trainer/test_trainer.py",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/b61da251692e5a107117618ca71d0b1ccd2e059c/tests%2Ftrainer%2Ftest_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b61da251692e5a107117618ca71d0b1ccd2e059c/tests%2Ftrainer%2Ftest_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_trainer.py?ref=b61da251692e5a107117618ca71d0b1ccd2e059c",
            "patch": "@@ -4592,9 +4592,6 @@ def test_trainer_saves_processor(self):\n \n         image_processor_dict = image_processor.to_dict()\n         reloaded_image_processor_dict = reloaded_image_processor.to_dict()\n-        # When the processor is saved in the trainer, the _processor_class gets set in the reload_image_processor dict\n-        image_processor_dict.pop(\"_processor_class\")\n-        reloaded_image_processor_dict.pop(\"_processor_class\")\n         self.assertDictEqual(image_processor_dict, reloaded_image_processor_dict)\n \n         # For tokenizers, there isn't a direct to_dict method and the properties stored in the configs e.g."
        }
    ],
    "stats": {
        "total": 106,
        "additions": 29,
        "deletions": 77
    }
}