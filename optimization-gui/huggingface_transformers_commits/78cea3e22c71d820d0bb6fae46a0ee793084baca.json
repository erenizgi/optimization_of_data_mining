{
    "author": "kmehant",
    "message": "fix: (llama4) fix no_split_modules to be picked up for fsdpv1 and v2 sharding (#37462)\n\nfix: fix no_split_modules to be picked up for fsdpv1 and v2 sharding\n\nSigned-off-by: Mehant Kammakomati <mehant.kammakomati2@ibm.com>",
    "sha": "78cea3e22c71d820d0bb6fae46a0ee793084baca",
    "files": [
        {
            "sha": "1fed0c9ca27d54586cf67f325b0339852978248b",
            "filename": "src/transformers/models/llama4/modeling_llama4.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/78cea3e22c71d820d0bb6fae46a0ee793084baca/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/78cea3e22c71d820d0bb6fae46a0ee793084baca/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py?ref=78cea3e22c71d820d0bb6fae46a0ee793084baca",
            "patch": "@@ -476,6 +476,7 @@ class Llama4PreTrainedModel(PreTrainedModel):\n     _supports_quantized_cache = True\n     _supports_static_cache = True\n     _supports_attention_backend = True\n+    _no_split_modules = [\"Llama4TextDecoderLayer\", \"Llama4VisionEncoderLayer\"]\n \n     def _init_weights(self, module):\n         std = ("
        }
    ],
    "stats": {
        "total": 1,
        "additions": 1,
        "deletions": 0
    }
}