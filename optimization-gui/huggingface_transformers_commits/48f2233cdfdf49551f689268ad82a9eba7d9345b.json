{
    "author": "ridima11",
    "message": "Improve grammar and clarity in perf_hardware.md (#39428)",
    "sha": "48f2233cdfdf49551f689268ad82a9eba7d9345b",
    "files": [
        {
            "sha": "03560c87d32bfddbbb09363c73df2fe9234b5aab",
            "filename": "docs/source/en/perf_hardware.md",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/48f2233cdfdf49551f689268ad82a9eba7d9345b/docs%2Fsource%2Fen%2Fperf_hardware.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/48f2233cdfdf49551f689268ad82a9eba7d9345b/docs%2Fsource%2Fen%2Fperf_hardware.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fperf_hardware.md?ref=48f2233cdfdf49551f689268ad82a9eba7d9345b",
            "patch": "@@ -15,7 +15,7 @@ rendered properly in your Markdown viewer.\n \n # Build your own machine\n \n-One of the most important consideration when building a machine for deep learning is the GPU choice. GPUs are the standard workhorse for deep learning owing to their tensor cores for performing very efficient matrix multiplication and high memory bandwidth. To train large models, you either need a more powerful GPU, multiple GPUs, or take advantage of techniques that offload some of the load to the CPU or NVMe.\n+One of the most important considerations when building a machine for deep learning is the GPU choice. GPUs are the standard workhorse for deep learning owing to their tensor cores for performing very efficient matrix multiplication and high memory bandwidth. To train large models, you either need a more powerful GPU, multiple GPUs, or take advantage of techniques that offload some of the load to the CPU or NVMe.\n \n This guide provides some practical tips for setting up a GPU for deep learning. For a more detailed discussion and comparison of GPUs, take a look at the [Which GPU(s) to Get for Deep Learning](https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/) blog post.\n \n@@ -25,11 +25,11 @@ High-end consumer GPUs may have two or three PCIe 8-pin power sockets, and you s\n \n Each PCIe 8-pin power cable should be connected to a 12V rail on the power supply unit (PSU) and can deliver up to 150W. Other GPUs may use a PCIe 12-pin connector which can deliver up to 500-600W. Lower-end GPUs may only use a PCIe 6-pin connector which supplies up to 75W.\n \n-It is important the PSU has stable voltage otherwise it may not be able to supply the GPU with enough power to function properly during peak usage.\n+It is important that the PSU maintains stable voltage; otherwise, it may fail to supply the GPU with enough power during peak usage.\n \n ## Cooling\n \n-An overheated GPU throttles its performance and can even shutdown if it's too hot to prevent damage. Keeping the GPU temperature low, anywhere between 158 - 167F, is essential for delivering full performance and maintaining its lifespan. Once temperatures reach 183 - 194F, the GPU may begin to throttle performance.\n+An overheated GPU throttles its performance and can even shutdown if it's too hot to prevent damage. Keeping the GPU temperature low, anywhere between 158–167°F, is essential for delivering full performance and maintaining its lifespan. Once temperatures reach 183 - 194°F, the GPU may begin to throttle performance.\n \n ## Multi-GPU connectivity\n "
        }
    ],
    "stats": {
        "total": 6,
        "additions": 3,
        "deletions": 3
    }
}