{
    "author": "cyyever",
    "message": "Fix invalid typing (#40612)\n\nSigned-off-by: cyy <cyyever@outlook.com>",
    "sha": "37103d6f22cd25c9eba7297ae79ed8c47a852e54",
    "files": [
        {
            "sha": "dece5233d956064e81dc1edf6dee4f71167b62e1",
            "filename": "src/transformers/modeling_flax_pytorch_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodeling_flax_pytorch_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodeling_flax_pytorch_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_flax_pytorch_utils.py?ref=37103d6f22cd25c9eba7297ae79ed8c47a852e54",
            "patch": "@@ -86,7 +86,7 @@ def rename_key_and_reshape_tensor(\n     pt_tensor: np.ndarray,\n     random_flax_state_dict: dict[str, jnp.ndarray],\n     model_prefix: str,\n-) -> (tuple[str], np.ndarray):\n+) -> tuple[tuple[str], np.ndarray]:\n     \"\"\"Rename PT weight names to corresponding Flax weight names and reshape tensor if necessary\"\"\"\n \n     def is_key_or_prefix_key_in_dict(key: tuple[str]) -> bool:"
        },
        {
            "sha": "fd240b97848033ab77e984f85d91aa63e190df0c",
            "filename": "src/transformers/models/cohere/tokenization_cohere_fast.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Fcohere%2Ftokenization_cohere_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Fcohere%2Ftokenization_cohere_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere%2Ftokenization_cohere_fast.py?ref=37103d6f22cd25c9eba7297ae79ed8c47a852e54",
            "patch": "@@ -227,7 +227,7 @@ def add_bos_token(self, value):\n \n     def apply_tool_use_template(\n         self,\n-        conversation: Union[list[dict[str, str]]],\n+        conversation: list[dict[str, str]],\n         tools: list[dict],\n         **kwargs,\n     ) -> Union[str, list[int]]:\n@@ -244,7 +244,7 @@ def apply_tool_use_template(\n         You can override the default template using the `tool_use_template` kwarg but the quality of your results may decrease.\n \n         Args:\n-            conversation (Union[list[dict[str, str]]]): A list of dicts\n+            conversation (list[dict[str, str]]): A list of dicts\n                 with \"role\" and \"content\" keys, representing the chat history so far.\n             tools (list[Dict]): a list of tools to render into the prompt for the model to choose from.\n                 See an example at the bottom of the docstring.\n@@ -382,7 +382,7 @@ def directly_answer() -> list[Dict]:\n \n     def apply_grounded_generation_template(\n         self,\n-        conversation: Union[list[dict[str, str]]],\n+        conversation: list[dict[str, str]],\n         documents: list[dict],\n         citation_mode: Literal[\"fast\", \"accurate\"] = \"accurate\",\n         **kwargs,\n@@ -400,7 +400,7 @@ def apply_grounded_generation_template(\n         You can override the default template using the `grounded_generation_template` kwarg but the quality of your results may decrease.\n \n         Args:\n-            conversation (Union[list[dict[str, str]]]): A list of dicts\n+            conversation (list[dict[str, str]]): A list of dicts\n                 with \"role\" and \"content\" keys, representing the chat history so far.\n             documents (list[dict[str, str]): A list of dicts, representing documents or tool outputs to ground your\n                 generation on. A document is a semistructured dict, with a string to string mapping. Common fields are"
        },
        {
            "sha": "34f5bce7a5c4f6bc12d8fdf670a0bc381f7f6850",
            "filename": "src/transformers/models/deformable_detr/modeling_deformable_detr.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fmodeling_deformable_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fmodeling_deformable_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fmodeling_deformable_detr.py?ref=37103d6f22cd25c9eba7297ae79ed8c47a852e54",
            "patch": "@@ -18,7 +18,7 @@\n import math\n import warnings\n from dataclasses import dataclass\n-from typing import Optional, Union\n+from typing import Any, Optional, Union\n \n import torch\n import torch.nn.functional as F\n@@ -230,8 +230,8 @@ class DeformableDetrObjectDetectionOutput(ModelOutput):\n     encoder_last_hidden_state: Optional[torch.FloatTensor] = None\n     encoder_hidden_states: Optional[tuple[torch.FloatTensor]] = None\n     encoder_attentions: Optional[tuple[torch.FloatTensor]] = None\n-    enc_outputs_class: Optional = None\n-    enc_outputs_coord_logits: Optional = None\n+    enc_outputs_class: Any = None\n+    enc_outputs_coord_logits: Optional[torch.FloatTensor] = None\n \n \n def _get_clones(module, N):"
        },
        {
            "sha": "a5066958b6c6a96c4cab9cad9260e0282d56c407",
            "filename": "src/transformers/models/deprecated/deta/modeling_deta.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fdeta%2Fmodeling_deta.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fdeta%2Fmodeling_deta.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fdeta%2Fmodeling_deta.py?ref=37103d6f22cd25c9eba7297ae79ed8c47a852e54",
            "patch": "@@ -326,8 +326,8 @@ class DetaObjectDetectionOutput(ModelOutput):\n     encoder_last_hidden_state: Optional[torch.FloatTensor] = None\n     encoder_hidden_states: Optional[tuple[torch.FloatTensor]] = None\n     encoder_attentions: Optional[tuple[torch.FloatTensor]] = None\n-    enc_outputs_class: Optional = None\n-    enc_outputs_coord_logits: Optional = None\n+    enc_outputs_class = None\n+    enc_outputs_coord_logits: Optional[torch.FloatTensor] = None\n     output_proposals: Optional[torch.FloatTensor] = None\n \n "
        },
        {
            "sha": "79407bfbf0d73cfac40297ccfa472f5e451f352d",
            "filename": "src/transformers/models/emu3/configuration_emu3.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Femu3%2Fconfiguration_emu3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Femu3%2Fconfiguration_emu3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Femu3%2Fconfiguration_emu3.py?ref=37103d6f22cd25c9eba7297ae79ed8c47a852e54",
            "patch": "@@ -14,7 +14,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-from typing import Optional, Union\n+from typing import Any, Optional, Union\n \n from ...configuration_utils import PretrainedConfig\n from ...modeling_rope_utils import rope_config_validation\n@@ -241,7 +241,7 @@ def __init__(\n         eos_token_id: int = 151850,\n         tie_word_embeddings: bool = False,\n         rope_theta: float = 1000000.0,\n-        rope_scaling: Optional = None,\n+        rope_scaling: Optional[dict[str, Any]] = None,\n         mlp_bias=False,\n         attention_bias=False,\n         attention_dropout: float = 0.1,"
        },
        {
            "sha": "d60738a29778c7d49d647a4647e989d36ec51c35",
            "filename": "src/transformers/models/mobilenet_v1/modeling_mobilenet_v1.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Fmobilenet_v1%2Fmodeling_mobilenet_v1.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Fmobilenet_v1%2Fmodeling_mobilenet_v1.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilenet_v1%2Fmodeling_mobilenet_v1.py?ref=37103d6f22cd25c9eba7297ae79ed8c47a852e54",
            "patch": "@@ -172,7 +172,7 @@ def __init__(\n         groups: Optional[int] = 1,\n         bias: bool = False,\n         use_normalization: Optional[bool] = True,\n-        use_activation: Optional[bool or str] = True,\n+        use_activation: Optional[Union[bool, str]] = True,\n     ) -> None:\n         super().__init__()\n         self.config = config"
        },
        {
            "sha": "d1290db16b18b1fc0637c9a8fc480715bc94ffc8",
            "filename": "src/transformers/models/musicgen/processing_musicgen.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Fmusicgen%2Fprocessing_musicgen.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Fmusicgen%2Fprocessing_musicgen.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmusicgen%2Fprocessing_musicgen.py?ref=37103d6f22cd25c9eba7297ae79ed8c47a852e54",
            "patch": "@@ -16,7 +16,7 @@\n Text/audio processor class for MusicGen\n \"\"\"\n \n-from typing import Optional\n+from typing import Any\n \n import numpy as np\n \n@@ -106,7 +106,7 @@ def batch_decode(self, *args, **kwargs):\n         else:\n             return self.tokenizer.batch_decode(*args, **kwargs)\n \n-    def _decode_audio(self, audio_values, padding_mask: Optional = None) -> list[np.ndarray]:\n+    def _decode_audio(self, audio_values, padding_mask: Any = None) -> list[np.ndarray]:\n         \"\"\"\n         This method strips any padding from the audio values to return a list of numpy audio arrays.\n         \"\"\""
        },
        {
            "sha": "470a5010646c60a25aa593d265dde102e574cdd6",
            "filename": "src/transformers/models/musicgen_melody/processing_musicgen_melody.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Fmusicgen_melody%2Fprocessing_musicgen_melody.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Fmusicgen_melody%2Fprocessing_musicgen_melody.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmusicgen_melody%2Fprocessing_musicgen_melody.py?ref=37103d6f22cd25c9eba7297ae79ed8c47a852e54",
            "patch": "@@ -16,7 +16,7 @@\n Text/audio processor class for MusicGen Melody\n \"\"\"\n \n-from typing import Optional\n+from typing import Any\n \n import numpy as np\n \n@@ -115,7 +115,7 @@ def batch_decode(self, *args, **kwargs):\n             return self.tokenizer.batch_decode(*args, **kwargs)\n \n     # Copied from transformers.models.musicgen.processing_musicgen.MusicgenProcessor._decode_audio with padding_mask->attention_mask\n-    def _decode_audio(self, audio_values, attention_mask: Optional = None) -> list[np.ndarray]:\n+    def _decode_audio(self, audio_values, attention_mask: Any = None) -> list[np.ndarray]:\n         \"\"\"\n         This method strips any padding from the audio values to return a list of numpy audio arrays.\n         \"\"\""
        },
        {
            "sha": "f636586ac8bafc03725ff8e345e4fe686e8f3de7",
            "filename": "src/transformers/models/whisper/modeling_whisper.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Fwhisper%2Fmodeling_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37103d6f22cd25c9eba7297ae79ed8c47a852e54/src%2Ftransformers%2Fmodels%2Fwhisper%2Fmodeling_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Fmodeling_whisper.py?ref=37103d6f22cd25c9eba7297ae79ed8c47a852e54",
            "patch": "@@ -1056,7 +1056,7 @@ def forward(\n         decoder_head_mask: Optional[torch.Tensor] = None,\n         cross_attn_head_mask: Optional[torch.Tensor] = None,\n         encoder_outputs: Optional[tuple[tuple[torch.FloatTensor]]] = None,\n-        past_key_values: Optional[Union[Cache]] = None,\n+        past_key_values: Optional[Cache] = None,\n         decoder_inputs_embeds: Optional[tuple[torch.FloatTensor]] = None,\n         decoder_position_ids: Optional[tuple[torch.LongTensor]] = None,\n         use_cache: Optional[bool] = None,\n@@ -1219,7 +1219,7 @@ def forward(\n         decoder_head_mask: Optional[torch.Tensor] = None,\n         cross_attn_head_mask: Optional[torch.Tensor] = None,\n         encoder_outputs: Optional[tuple[tuple[torch.FloatTensor]]] = None,\n-        past_key_values: Optional[Union[Cache]] = None,\n+        past_key_values: Optional[Cache] = None,\n         decoder_inputs_embeds: Optional[tuple[torch.FloatTensor]] = None,\n         decoder_position_ids: Optional[tuple[torch.LongTensor]] = None,\n         labels: Optional[torch.LongTensor] = None,"
        }
    ],
    "stats": {
        "total": 38,
        "additions": 19,
        "deletions": 19
    }
}