{
    "author": "MekkCyber",
    "message": "Fix data_seed unused (#33731)\n\n* fixing data_seed unused\r\n\r\n* fix accelerate version needed\r\n\r\n* fix style\r\n\r\n* update the fix following accelerate fix",
    "sha": "a37a06a20b4a006963f15acf5f49afa5a0496f29",
    "files": [
        {
            "sha": "9c4ddd268a0808d7fbe924a1e267ad464f2e310c",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/a37a06a20b4a006963f15acf5f49afa5a0496f29/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a37a06a20b4a006963f15acf5f49afa5a0496f29/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=a37a06a20b4a006963f15acf5f49afa5a0496f29",
            "patch": "@@ -417,6 +417,7 @@ def __init__(\n         self.args = args\n         # Seed must be set before instantiating the model when using model\n         enable_full_determinism(self.args.seed) if self.args.full_determinism else set_seed(self.args.seed)\n+\n         self.hp_name = None\n         self.deepspeed = None\n         self.is_in_train = False\n@@ -4864,6 +4865,9 @@ def create_accelerator_and_postprocess(self):\n                 even_batches=accelerator_config.pop(\"even_batches\"),\n                 use_seedable_sampler=accelerator_config.pop(\"use_seedable_sampler\"),\n             )\n+            if is_accelerate_available(\"1.1.0\"):\n+                dataloader_config.data_seed = self.args.data_seed\n+\n         non_blocking = accelerator_config.pop(\"non_blocking\")\n         if not is_accelerate_available(\"0.30.0\"):\n             if non_blocking:"
        },
        {
            "sha": "a2d83b2915eba465d9e59efc746f69b5ed14d700",
            "filename": "src/transformers/training_args.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/a37a06a20b4a006963f15acf5f49afa5a0496f29/src%2Ftransformers%2Ftraining_args.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a37a06a20b4a006963f15acf5f49afa5a0496f29/src%2Ftransformers%2Ftraining_args.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftraining_args.py?ref=a37a06a20b4a006963f15acf5f49afa5a0496f29",
            "patch": "@@ -2078,6 +2078,13 @@ def __post_init__(self):\n                 \"This is not supported and we recommend you to update your version.\"\n             )\n \n+        if self.data_seed is not None:\n+            if not is_accelerate_available(\"1.1.0\"):\n+                raise NotImplementedError(\n+                    \"data_seed requires Accelerate version `accelerate` >= 1.1.0. \"\n+                    \"This is not supported and we recommend you to update your version.\"\n+                )\n+\n         if self.include_inputs_for_metrics:\n             logger.warning(\n                 \"Using `include_inputs_for_metrics` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Please use `include_for_metrics` list argument instead.\""
        }
    ],
    "stats": {
        "total": 11,
        "additions": 11,
        "deletions": 0
    }
}