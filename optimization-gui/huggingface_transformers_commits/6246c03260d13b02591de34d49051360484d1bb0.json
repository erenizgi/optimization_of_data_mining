{
    "author": "faaany",
    "message": "[docs] fix outdated example code in `trainer.md` (#36066)\n\nfix bugs",
    "sha": "6246c03260d13b02591de34d49051360484d1bb0",
    "files": [
        {
            "sha": "67bb2ae4f594930fcebda919365ab023e70817d9",
            "filename": "docs/source/en/trainer.md",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/6246c03260d13b02591de34d49051360484d1bb0/docs%2Fsource%2Fen%2Ftrainer.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/6246c03260d13b02591de34d49051360484d1bb0/docs%2Fsource%2Fen%2Ftrainer.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftrainer.md?ref=6246c03260d13b02591de34d49051360484d1bb0",
            "patch": "@@ -130,7 +130,7 @@ from torch import nn\n from transformers import Trainer\n \n class CustomTrainer(Trainer):\n-    def compute_loss(self, model, inputs, return_outputs=False):\n+    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n         labels = inputs.pop(\"labels\")\n         # forward pass\n         outputs = model(**inputs)\n@@ -156,9 +156,7 @@ class EarlyStoppingCallback(TrainerCallback):\n \n     def on_step_end(self, args, state, control, **kwargs):\n         if state.global_step >= self.num_steps:\n-            return {\"should_training_stop\": True}\n-        else:\n-            return {}\n+            control.should_training_stop = True\n ```\n \n Then pass it to the [`Trainer`]'s `callback` parameter.\n@@ -737,7 +735,7 @@ accelerate launch --num_processes=2 \\\n     --fsdp_transformer_layer_cls_to_wrap=\"BertLayer\" \\\n     --fsdp_sharding_strategy=1 \\\n     --fsdp_state_dict_type=FULL_STATE_DICT \\\n-    ./examples/pytorch/text-classification/run_glue.py\n+    ./examples/pytorch/text-classification/run_glue.py \\\n     --model_name_or_path google-bert/bert-base-cased \\\n     --task_name $TASK_NAME \\\n     --do_train \\"
        }
    ],
    "stats": {
        "total": 8,
        "additions": 3,
        "deletions": 5
    }
}