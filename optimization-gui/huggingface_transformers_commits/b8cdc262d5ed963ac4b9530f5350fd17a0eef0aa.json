{
    "author": "faaany",
    "message": "[docs] use device-agnostic instead of `cuda` (#35047)\n\n* fix on xpu\r\n\r\n* [run_all]\r\n\r\n* add the missing import for Image lib\r\n\r\n* add more devices in comment\r\n\r\n* bug fix\r\n\r\n* replace cuda",
    "sha": "b8cdc262d5ed963ac4b9530f5350fd17a0eef0aa",
    "files": [
        {
            "sha": "2155a403b2b77f79cb06a3fb314b2ccd8fb0a73b",
            "filename": "docs/source/en/perf_torch_compile.md",
            "status": "modified",
            "additions": 13,
            "deletions": 7,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/b8cdc262d5ed963ac4b9530f5350fd17a0eef0aa/docs%2Fsource%2Fen%2Fperf_torch_compile.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/b8cdc262d5ed963ac4b9530f5350fd17a0eef0aa/docs%2Fsource%2Fen%2Fperf_torch_compile.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fperf_torch_compile.md?ref=b8cdc262d5ed963ac4b9530f5350fd17a0eef0aa",
            "patch": "@@ -27,7 +27,7 @@ To compile any computer vision model of your choice, call `torch.compile()` on t\n ```diff\n from transformers import AutoModelForImageClassification\n \n-model = AutoModelForImageClassification.from_pretrained(MODEL_ID).to(\"cuda\")\n+model = AutoModelForImageClassification.from_pretrained(MODEL_ID).to(DEVICE)\n + model = torch.compile(model)\n ```\n \n@@ -47,15 +47,17 @@ from PIL import Image\n import requests\n import numpy as np\n from transformers import AutoImageProcessor, AutoModelForImageClassification\n+from accelerate.test_utils.testing import get_backend\n \n+device, _, _ = get_backend() # automatically detects the underlying device type (CUDA, CPU, XPU, MPS, etc.)\n url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n image = Image.open(requests.get(url, stream=True).raw)\n \n processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n-model = AutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-224\").to(\"cuda\")\n+model = AutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-224\").to(device)\n model = torch.compile(model)\n \n-processed_input = processor(image, return_tensors='pt').to(device=\"cuda\")\n+processed_input = processor(image, return_tensors='pt').to(device)\n \n with torch.no_grad():\n     _ = model(**processed_input)\n@@ -66,13 +68,15 @@ with torch.no_grad():\n \n ```python \n from transformers import AutoImageProcessor, AutoModelForObjectDetection\n+from accelerate.test_utils.testing import get_backend\n \n+device, _, _ = get_backend() # automatically detects the underlying device type (CUDA, CPU, XPU, MPS, etc.)\n processor = AutoImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n-model = AutoModelForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\").to(\"cuda\")\n+model = AutoModelForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\").to(device)\n model = torch.compile(model)\n \n texts = [\"a photo of a cat\", \"a photo of a dog\"]\n-inputs = processor(text=texts, images=image, return_tensors=\"pt\").to(\"cuda\")\n+inputs = processor(text=texts, images=image, return_tensors=\"pt\").to(device)\n \n with torch.no_grad():\n     _ = model(**inputs)\n@@ -82,11 +86,13 @@ with torch.no_grad():\n \n ```python \n from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n+from accelerate.test_utils.testing import get_backend\n \n+device, _, _ = get_backend() # automatically detects the underlying device type (CUDA, CPU, XPU, MPS, etc.)\n processor = SegformerImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n-model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\").to(\"cuda\")\n+model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\").to(device)\n model = torch.compile(model)\n-seg_inputs = processor(images=image, return_tensors=\"pt\").to(\"cuda\")\n+seg_inputs = processor(images=image, return_tensors=\"pt\").to(device)\n \n with torch.no_grad():\n     _ = model(**seg_inputs)"
        }
    ],
    "stats": {
        "total": 20,
        "additions": 13,
        "deletions": 7
    }
}