{
    "author": "HyunZ118",
    "message": "ğŸŒ [i18n-KO] Translated gemma3n.md to Korean (#40873)\n\n* fix: manual edits\n\n* Apply suggestions from code review\r\n\r\nApply suggestions from code review and make additional revisions\n\nCo-authored-by: HyunSang Jang <tasker.dev103@gmail.com>\n\n* Apply suggestions from code review\r\n\r\nApply suggestions from code review â€” updated inline links for related text\n\n* Apply suggestions from code review\r\n\r\nApply suggestions from code review - final\n\n* Update docs/source/ko/_toctree.yml\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\n\n---------\n\nCo-authored-by: HyunSang Jang <tasker.dev103@gmail.com>\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
    "sha": "ac815417784320cb17ed7d6b077dd19cb6854fa1",
    "files": [
        {
            "sha": "5a5a7e1c484ae7301ad5928dc822fb903cc95e94",
            "filename": "docs/source/ko/_toctree.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ac815417784320cb17ed7d6b077dd19cb6854fa1/docs%2Fsource%2Fko%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/ac815417784320cb17ed7d6b077dd19cb6854fa1/docs%2Fsource%2Fko%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2F_toctree.yml?ref=ac815417784320cb17ed7d6b077dd19cb6854fa1",
            "patch": "@@ -1057,7 +1057,7 @@\n         title: FLAVA\n       - local: model_doc/gemma3\n         title: Gemma3\n-      - local: in_translation\n+      - local: model_doc/gemma3n\n         title: Gemma3n\n       - local: in_translation\n         title: GIT"
        },
        {
            "sha": "cce51a56192079d528c475eddf16288a39bfe281",
            "filename": "docs/source/ko/model_doc/gemma3n.md",
            "status": "added",
            "additions": 189,
            "deletions": 0,
            "changes": 189,
            "blob_url": "https://github.com/huggingface/transformers/blob/ac815417784320cb17ed7d6b077dd19cb6854fa1/docs%2Fsource%2Fko%2Fmodel_doc%2Fgemma3n.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/ac815417784320cb17ed7d6b077dd19cb6854fa1/docs%2Fsource%2Fko%2Fmodel_doc%2Fgemma3n.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fgemma3n.md?ref=ac815417784320cb17ed7d6b077dd19cb6854fa1",
            "patch": "@@ -0,0 +1,189 @@\n+\n+<!--Copyright 2025 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n+\n+âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+*ì´ ëª¨ë¸ì€ 2025ë…„ 5ì›” 20ì¼ì— ì¶œì‹œë˜ì—ˆìœ¼ë©°, 2025ë…„ 6ì›” 26ì¼ì— Hugging Face Transformersì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.*\n+\n+<div style=\"float: right;\">\n+    <div class=\"flex flex-wrap space-x-1\">\n+        <img alt=\"PyTorch\" src=\"https://img.shields.io/badge/PyTorch-DE3412?style=flat&logo=pytorch&logoColor=white\">\n+        <img alt=\"SDPA\" src=\"https://img.shields.io/badge/SDPA-DE3412?style=flat&logo=pytorch&logoColor=white\">\n+    </div>\n+</div>\n+\n+# Gemma3n[[gemma3n]]\n+\n+## ê°œìš”[[overview]]\n+\n+[Gemma3n](https://developers.googleblog.com/en/introducing-gemma-3n/)ì€ ì‚¬ì „ í›ˆë ¨ëœ ë²„ì „ê³¼ ëª…ë ¹ì–´ ê¸°ë°˜ ë¯¸ì„¸ì¡°ì • ë²„ì „ì´ ì œê³µë˜ëŠ” ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì´ë©°, ëª¨ë¸ í¬ê¸°ëŠ” E4Bì™€ E2B ë‘ ê°€ì§€ë¡œ ì¶œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. ì–¸ì–´ ëª¨ë¸ ì•„í‚¤í…ì²˜ëŠ” ì´ì „ Gemma ë²„ì „ê³¼ ë§ì€ ë¶€ë¶„ì„ ê³µìœ í•˜ì§€ë§Œ ì´ë²ˆ ë²„ì „ì—ëŠ” ì—¬ëŸ¬ ê°€ì§€ ìƒˆë¡œìš´ ê¸°ë²•ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ [êµì°¨ ì—…ë°ì´íŠ¸(AltUp)](https://proceedings.neurips.cc/paper_files/paper/2023/hash/f2059277ac6ce66e7e5543001afa8bb5-Abstract-Conference.html), [í•™ìŠµëœ ì¦ê°• ì”ì—¬ ë ˆì´ì–´(LAuReL)](https://huggingface.co/papers/2411.07501), [MatFormer](https://huggingface.co/papers/2310.07707), ë ˆì´ì–´ë³„ ì„ë² ë”©, [í†µê³„ì  Top-kë¥¼ ì´ìš©í•œ í™œì„±í™” í¬ì†Œì„±(SPARk-Transformer)](https://huggingface.co/papers/2506.06644), KV ìºì‹œ ê³µìœ  ë“±ì´ ìˆìŠµë‹ˆë‹¤. Gemma 3nì€ [Gemma 3](./gemma3)ì™€ ìœ ì‚¬í•œ ì–´í…ì…˜ íŒ¨í„´ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê¸€ë¡œë²Œ ì…€í”„ ì–´í…ì…˜ ë ˆì´ì–´ 1ê°œë§ˆë‹¤ ë¡œì»¬ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì…€í”„ ì–´í…ì…˜ ë ˆì´ì–´ 4ê°œë¥¼ êµì°¨ë¡œ ë°°ì¹˜í•˜ë©°, ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ëŠ” 32k í† í°ê¹Œì§€ ì§€ì›í•©ë‹ˆë‹¤. ë¹„ì „ ëª¨ë‹¬ë¦¬í‹°ì—ì„œëŠ” MobileNet v5ë¥¼ ë¹„ì „ ì¸ì½”ë”ë¡œ ë„ì…í•˜ì—¬ ê¸°ë³¸ í•´ìƒë„ë¥¼ 768x768 í”½ì…€ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤. ë˜í•œ ì˜¤ë””ì˜¤ ëª¨ë‹¬ë¦¬í‹°ì—ì„œëŠ” [Universal Speech Model(USM)](https://huggingface.co/papers/2303.01037) ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡­ê²Œ í•™ìŠµëœ ì˜¤ë””ì˜¤ ì¸ì½”ë”ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.\n+\n+ëª…ë ¹ì–´ ê¸°ë°˜ ë¯¸ì„¸ì¡°ì • ë²„ì „ì€ ì§€ì‹ ì¦ë¥˜ì™€ ê°•í™” í•™ìŠµì„ í†µí•´ í›„ì²˜ë¦¬ í•™ìŠµ ë˜ì—ˆìŠµë‹ˆë‹¤.\n+\n+Gemma 3nì˜ ì›ë³¸ ì²´í¬í¬ì¸íŠ¸ëŠ” [Gemma 3n][gemma3n-collection] ì¶œì‹œ í˜ì´ì§€ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+> [!TIP]\n+> ì˜¤ë¥¸ìª½ ì‚¬ì´ë“œë°”ì— ìˆëŠ” Gemma 3n ëª¨ë¸ì„ í´ë¦­í•˜ë©´, Gemmaë¥¼ ë‹¤ì–‘í•œ ë¹„ì „, ì˜¤ë””ì˜¤, \n+> ì–¸ì–´ ì‘ì—…ì— ì ìš©í•˜ëŠ” ë” ë§ì€ ì˜ˆì‹œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+ì•„ë˜ ì˜ˆì‹œëŠ” [`Pipeline`] ë˜ëŠ” [`AutoModel`] í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n+\n+<hfoptions id=\"usage\">\n+<hfoption id=\"Pipeline\">\n+\n+```py\n+import torch\n+from transformers import pipeline\n+\n+pipeline = pipeline(\n+    task=\"image-text-to-text\",\n+    model=\"google/gemma-3n-e4b\",\n+    device=0,\n+    dtype=torch.bfloat16\n+)\n+pipeline(\n+    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\",\n+    text=\"ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ë³´ì´ë‚˜ìš”?\"\n+)\n+```\n+\n+</hfoption>\n+<hfoption id=\"AutoModel\">\n+\n+```py\n+import torch\n+from transformers import AutoProcessor, Gemma3nForConditionalGeneration\n+\n+model = Gemma3nForConditionalGeneration.from_pretrained(\n+    \"google/gemma-3n-e4b-it\",\n+    dtype=torch.bfloat16,\n+    device_map=\"auto\",\n+    attn_implementation=\"sdpa\"\n+)\n+processor = AutoProcessor.from_pretrained(\n+    \"google/gemma-3n-e4b-it\",\n+    padding_side=\"left\"\n+)\n+\n+messages = [\n+    {\n+        \"role\": \"system\",\n+        \"content\": [\n+            {\"type\": \"text\", \"text\": \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"}\n+        ]\n+    },\n+    {\n+        \"role\": \"user\", \"content\": [\n+            {\"type\": \"image\", \"url\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"},\n+            {\"type\": \"text\", \"text\": \"ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ë³´ì´ë‚˜ìš”?\"},\n+        ]\n+    },\n+]\n+inputs = processor.apply_chat_template(\n+    messages,\n+    tokenize=True,\n+    return_dict=True,\n+    return_tensors=\"pt\",\n+    add_generation_prompt=True,\n+).to(model.device)\n+\n+output = model.generate(**inputs, max_new_tokens=50, cache_implementation=\"static\")\n+print(processor.decode(output[0], skip_special_tokens=True))\n+```\n+\n+</hfoption>\n+<hfoption id=\"transformers CLI\">\n+\n+```bash\n+echo -e \"ì‹ë¬¼ì€ íŠ¹ì • ê³¼ì •ì„ í†µí•´ ì—ë„ˆì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\" | transformers run --task text-generation --model google/gemma-3n-e2b --device 0\n+```\n+\n+</hfoption>\n+</hfoptions>\n+\n+## ì°¸ê³ ì‚¬í•­[[notes]]\n+\n+-   [`Gemma3nForConditionalGeneration`] í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©´ ì´ë¯¸ì§€-ì˜¤ë””ì˜¤-í…ìŠ¤íŠ¸, ì´ë¯¸ì§€-í…ìŠ¤íŠ¸, ì´ë¯¸ì§€-ì˜¤ë””ì˜¤, ì˜¤ë””ì˜¤-í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ë‹¨ë…, ì˜¤ë””ì˜¤ ë‹¨ë… ì…ë ¥ì„ ëª¨ë‘ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+-   Gemma 3nì€ í•œ ë²ˆì˜ ì…ë ¥ì— ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ë‹¤ë§Œ í”„ë¡œì„¸ì„œì— ì „ë‹¬í•˜ê¸° ì „ì— ì´ë¯¸ì§€ë“¤ì´ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì˜¬ë°”ë¥´ê²Œ ë¬¶ì—¬ìˆëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ê° ë°°ì¹˜ëŠ” í•˜ë‚˜ ì´ìƒì˜ ì´ë¯¸ì§€ë¥¼ ë‹´ì€ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì…ë‹ˆë‹¤.\n+\n+    ```py\n+    url_cow = \"https://media.istockphoto.com/id/1192867753/photo/cow-in-berchida-beach-siniscola.jpg?s=612x612&w=0&k=20&c=v0hjjniwsMNfJSuKWZuIn8pssmD5h5bSN1peBd1CmH4=\"\n+    url_cat = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n+\n+    messages =[\n+        {\n+            \"role\": \"system\",\n+            \"content\": [\n+                {\"type\": \"text\", \"text\": \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"}\n+            ]\n+        },\n+        {\n+            \"role\": \"user\",\n+            \"content\": [\n+                {\"type\": \"image\", \"url\": url_cow},\n+                {\"type\": \"image\", \"url\": url_cat},\n+                {\"type\": \"text\", \"text\": \"ì–´ë–¤ ì´ë¯¸ì§€ê°€ ë” ê·€ì—½ìŠµë‹ˆê¹Œ?\"},\n+            ]\n+        },\n+    ]\n+    ```\n+-   í”„ë¡œì„¸ì„œì— ì „ë‹¬ë˜ëŠ” í…ìŠ¤íŠ¸ì—ëŠ” ì´ë¯¸ì§€ë¥¼ ì‚½ì…í•´ì•¼ í•˜ëŠ” ìœ„ì¹˜ì— `<image_soft_token>` í† í°ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n+-   Gemma 3nì€ ì…ë ¥ë‹¹ ìµœëŒ€ í•˜ë‚˜ì˜ íƒ€ê¹ƒ ì˜¤ë””ì˜¤ í´ë¦½ë§Œ í—ˆìš©í•©ë‹ˆë‹¤. ë‹¤ë§Œ í“¨ìƒ· í”„ë¡¬í”„íŠ¸ì—ì„œëŠ” ì—¬ëŸ¬ ê°œì˜ ì˜¤ë””ì˜¤ í´ë¦½ì„ í•¨ê»˜ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+-   í”„ë¡œì„¸ì„œì— ì „ë‹¬ë˜ëŠ” í…ìŠ¤íŠ¸ì—ëŠ” ì˜¤ë””ì˜¤ í´ë¦½ì„ ì‚½ì…í•´ì•¼ í•˜ëŠ” ìœ„ì¹˜ì— `<audio_soft_token>` í† í°ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n+-   í”„ë¡œì„¸ì„œì—ëŠ” ì±„íŒ… ë©”ì‹œì§€ë¥¼ ëª¨ë¸ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ ìì²´ ë©”ì„œë“œì¸ [`~ProcessorMixin.apply_chat_template`]ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n+\n+## Gemma3nAudioFeatureExtractor[[transformers.Gemma3nAudioFeatureExtractor]]\n+\n+[[autodoc]] Gemma3nAudioFeatureExtractor\n+\n+## Gemma3nProcessor[[transformers.Gemma3nProcessor]]\n+\n+[[autodoc]] Gemma3nProcessor\n+\n+## Gemma3nTextConfig[[transformers.Gemma3nTextConfig]]\n+\n+[[autodoc]] Gemma3nTextConfig\n+\n+## Gemma3nVisionConfig[[transformers.Gemma3nVisionConfig]]\n+\n+[[autodoc]] Gemma3nVisionConfig\n+\n+## Gemma3nAudioConfig[[transformers.Gemma3nAudioConfig]]\n+\n+[[autodoc]] Gemma3nAudioConfig\n+\n+## Gemma3nConfig[[transformers.Gemma3nConfig]]\n+\n+[[autodoc]] Gemma3nConfig\n+\n+## Gemma3nTextModel[[transformers.Gemma3nTextModel]]\n+\n+[[autodoc]] Gemma3nTextModel\n+    - forward\n+\n+## Gemma3nModel[[transformers.Gemma3nModel]]\n+\n+[[autodoc]] Gemma3nModel\n+    - forward\n+\n+## Gemma3nForCausalLM[[transformers.Gemma3nForCausalLM]]\n+\n+[[autodoc]] Gemma3nForCausalLM\n+    - forward\n+\n+## Gemma3nForConditionalGeneration[[transformers.Gemma3nForConditionalGeneration]]\n+\n+[[autodoc]] Gemma3nForConditionalGeneration\n+    - forward\n+"
        }
    ],
    "stats": {
        "total": 191,
        "additions": 190,
        "deletions": 1
    }
}