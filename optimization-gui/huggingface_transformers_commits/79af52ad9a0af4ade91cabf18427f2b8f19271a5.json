{
    "author": "ahnjj",
    "message": "ğŸŒ [i18n-KO] Translated `bertweet.md` to Korean (#33891)\n\n* docs: ko: bertweet.md\r\n\r\n* Update _toctree.yml\r\n\r\n* fix: manual edits\r\n\r\n* Update docs/source/ko/model_doc/bertweet.md\r\n\r\nCo-authored-by: HyeokJun SHIN <96534680+jun048098@users.noreply.github.com>\r\n\r\n---------\r\n\r\nCo-authored-by: HyeokJun SHIN <96534680+jun048098@users.noreply.github.com>",
    "sha": "79af52ad9a0af4ade91cabf18427f2b8f19271a5",
    "files": [
        {
            "sha": "2d802c542e5ff5c03d3f8e91944215050c29930b",
            "filename": "docs/source/ko/_toctree.yml",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/79af52ad9a0af4ade91cabf18427f2b8f19271a5/docs%2Fsource%2Fko%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/79af52ad9a0af4ade91cabf18427f2b8f19271a5/docs%2Fsource%2Fko%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2F_toctree.yml?ref=79af52ad9a0af4ade91cabf18427f2b8f19271a5",
            "patch": "@@ -328,8 +328,8 @@\n         title: (ë²ˆì—­ì¤‘) BertGeneration\n       - local: in_translation\n         title: (ë²ˆì—­ì¤‘) BertJapanese\n-      - local: in_translation\n-        title: (ë²ˆì—­ì¤‘) Bertweet\n+      - local: model_doc/bertweet\n+        title: Bertweet\n       - local: in_translation\n         title: (ë²ˆì—­ì¤‘) BigBird\n       - local: in_translation\n@@ -774,4 +774,4 @@\n     - local: internal/time_series_utils\n       title: ì‹œê³„ì—´ì„ ìœ„í•œ ìœ í‹¸ë¦¬í‹°\n     title: (ë²ˆì—­ì¤‘) Internal Helpers\n-  title: (ë²ˆì—­ì¤‘) API\n\\ No newline at end of file\n+  title: (ë²ˆì—­ì¤‘) API"
        },
        {
            "sha": "7a46087d0a8ebf85929aadbb74808ffe029537c9",
            "filename": "docs/source/ko/model_doc/bertweet.md",
            "status": "added",
            "additions": 67,
            "deletions": 0,
            "changes": 67,
            "blob_url": "https://github.com/huggingface/transformers/blob/79af52ad9a0af4ade91cabf18427f2b8f19271a5/docs%2Fsource%2Fko%2Fmodel_doc%2Fbertweet.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/79af52ad9a0af4ade91cabf18427f2b8f19271a5/docs%2Fsource%2Fko%2Fmodel_doc%2Fbertweet.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fbertweet.md?ref=79af52ad9a0af4ade91cabf18427f2b8f19271a5",
            "patch": "@@ -0,0 +1,67 @@\n+<!--Copyright 2020 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n+\n+âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+\n+# BERTweet [[bertweet]]\n+\n+## ê°œìš” [[overview]]\n+\n+BERTweet ëª¨ë¸ì€ Dat Quoc Nguyen, Thanh Vu, Anh Tuan Nguyenì— ì˜í•´ [BERTweet: A pre-trained language model for English Tweets](https://www.aclweb.org/anthology/2020.emnlp-demos.2.pdf) ì—ì„œ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤.\n+\n+í•´ë‹¹ ë…¼ë¬¸ì˜ ì´ˆë¡ :\n+\n+*ì˜ì–´ íŠ¸ìœ—ì„ ìœ„í•œ ìµœì´ˆì˜ ê³µê°œ ëŒ€ê·œëª¨ ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì¸ BERTweetì„ ì†Œê°œí•©ë‹ˆë‹¤. \n+BERTweetì€ BERT-base(Devlin et al., 2019)ì™€ ë™ì¼í•œ ì•„í‚¤í…ì²˜ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, RoBERTa ì‚¬ì „ í•™ìŠµ ì ˆì°¨(Liu et al., 2019)ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤. \n+ì‹¤í—˜ ê²°ê³¼, BERTweetì€ ê°•ë ¥í•œ ê¸°ì¤€ ëª¨ë¸ì¸ RoBERTa-base ë° XLM-R-base(Conneau et al., 2020)ì˜ ì„±ëŠ¥ì„ ëŠ¥ê°€í•˜ì—¬ ì„¸ ê°€ì§€ íŠ¸ìœ— NLP ì‘ì—…(í’ˆì‚¬ íƒœê¹…, ê°œì²´ëª… ì¸ì‹, í…ìŠ¤íŠ¸ ë¶„ë¥˜)ì—ì„œ ì´ì „ ìµœì‹  ëª¨ë¸ë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.*\n+\n+ì´ ëª¨ë¸ì€ [dqnguyen](https://huggingface.co/dqnguyen) ê»˜ì„œ ê¸°ì—¬í•˜ì…¨ìŠµë‹ˆë‹¤. ì›ë³¸ ì½”ë“œëŠ” [ì—¬ê¸°](https://github.com/VinAIResearch/BERTweet).ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+\n+## ì‚¬ìš© ì˜ˆì‹œ [[usage-example]]\n+\n+```python\n+>>> import torch\n+>>> from transformers import AutoModel, AutoTokenizer\n+\n+>>> bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n+\n+>>> # íŠ¸ëœìŠ¤í¬ë¨¸ ë²„ì „ 4.x ì´ìƒ :\n+>>> tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n+\n+>>> # íŠ¸ëœìŠ¤í¬ë¨¸ ë²„ì „ 3.x ì´ìƒ:\n+>>> # tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n+\n+>>> # ì…ë ¥ëœ íŠ¸ìœ—ì€ ì´ë¯¸ ì •ê·œí™”ë˜ì—ˆìŠµë‹ˆë‹¤!\n+>>> line = \"SC has first two presumptive cases of coronavirus , DHEC confirms HTTPURL via @USER :cry:\"\n+\n+>>> input_ids = torch.tensor([tokenizer.encode(line)])\n+\n+>>> with torch.no_grad():\n+...     features = bertweet(input_ids)  # Models outputs are now tuples\n+\n+>>> # With TensorFlow 2.0+:\n+>>> # from transformers import TFAutoModel\n+>>> # bertweet = TFAutoModel.from_pretrained(\"vinai/bertweet-base\")\n+```\n+\n+<Tip> \n+\n+ì´ êµ¬í˜„ì€ í† í°í™” ë°©ë²•ì„ ì œì™¸í•˜ê³ ëŠ” BERTì™€ ë™ì¼í•©ë‹ˆë‹¤. API ì°¸ì¡° ì •ë³´ëŠ” [BERT ë¬¸ì„œ](bert) ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.\n+\n+</Tip>\n+\n+## Bertweet í† í°í™”(BertweetTokenizer) [[transformers.BertweetTokenizer]]\n+\n+[[autodoc]] BertweetTokenizer"
        }
    ],
    "stats": {
        "total": 73,
        "additions": 70,
        "deletions": 3
    }
}