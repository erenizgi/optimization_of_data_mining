{
    "author": "zucchini-nlp",
    "message": "Fix flaky tests (#34069)\n\n* fix mllama only\r\n\r\n* allow image token index",
    "sha": "fd70464fa74c101ab3bc60e0c3db7d5e3b75fe90",
    "files": [
        {
            "sha": "e486e149e3e6601ba6a87bd11ac0f634948b0535",
            "filename": "src/transformers/models/mllama/modeling_mllama.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/fd70464fa74c101ab3bc60e0c3db7d5e3b75fe90/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fd70464fa74c101ab3bc60e0c3db7d5e3b75fe90/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py?ref=fd70464fa74c101ab3bc60e0c3db7d5e3b75fe90",
            "patch": "@@ -2214,7 +2214,7 @@ def prepare_inputs_for_generation(\n \n         # If we're in pre-fill or cacheless decoding step, then we need pixel_values and aspect ratios\n         # to compute image hidden states, otherwise they are cached within each cross attn layer\n-        if (input_ids == self.config.image_token_index).any():\n+        if cache_position[0] == 0:\n             model_inputs[\"pixel_values\"] = pixel_values\n             model_inputs[\"aspect_ratio_ids\"] = aspect_ratio_ids\n             model_inputs[\"aspect_ratio_mask\"] = aspect_ratio_mask"
        },
        {
            "sha": "83fe07fef2eda0a9cd36a487831142584e8fd4c9",
            "filename": "utils/check_config_attributes.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/fd70464fa74c101ab3bc60e0c3db7d5e3b75fe90/utils%2Fcheck_config_attributes.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fd70464fa74c101ab3bc60e0c3db7d5e3b75fe90/utils%2Fcheck_config_attributes.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_config_attributes.py?ref=fd70464fa74c101ab3bc60e0c3db7d5e3b75fe90",
            "patch": "@@ -243,6 +243,7 @@ def check_attribute_being_used(config_class, attributes, default_value, source_s\n         \"pad_index\",\n         \"unk_index\",\n         \"mask_index\",\n+        \"image_token_index\",  # for VLMs\n         \"image_size\",\n         \"use_cache\",\n         \"out_features\","
        }
    ],
    "stats": {
        "total": 3,
        "additions": 2,
        "deletions": 1
    }
}