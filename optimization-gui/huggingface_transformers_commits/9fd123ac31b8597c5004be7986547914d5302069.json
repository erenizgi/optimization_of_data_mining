{
    "author": "dvrogozh",
    "message": "ci: mark model_parallel tests as cuda specific (#35269)\n\n`parallelize()` API is deprecated in favor of accelerate's `device_map=\"auto\"`\r\nand therefore is not accepting new features. At the same time `parallelize()`\r\nimplementation is currently CUDA-specific. This commit marks respective\r\nci tests with `@require_torch_gpu`.\r\n\r\nFixes: #35252\r\n\r\nSigned-off-by: Dmitry Rogozhkin <dmitry.v.rogozhkin@intel.com>",
    "sha": "9fd123ac31b8597c5004be7986547914d5302069",
    "files": [
        {
            "sha": "9bf351473074ac8de4def2059926b16e2d79eb8c",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fd123ac31b8597c5004be7986547914d5302069/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fd123ac31b8597c5004be7986547914d5302069/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=9fd123ac31b8597c5004be7986547914d5302069",
            "patch": "@@ -3061,6 +3061,7 @@ def test_multi_gpu_data_parallel_forward(self):\n             with torch.no_grad():\n                 _ = model(**self._prepare_for_class(inputs_dict, model_class))\n \n+    @require_torch_gpu\n     @require_torch_multi_gpu\n     def test_model_parallelization(self):\n         if not self.test_model_parallel:\n@@ -3123,6 +3124,7 @@ def get_current_gpu_memory_use():\n             gc.collect()\n             torch.cuda.empty_cache()\n \n+    @require_torch_gpu\n     @require_torch_multi_gpu\n     def test_model_parallel_equal_results(self):\n         if not self.test_model_parallel:"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 2,
        "deletions": 0
    }
}