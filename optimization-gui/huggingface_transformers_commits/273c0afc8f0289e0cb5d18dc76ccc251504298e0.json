{
    "author": "leloykun",
    "message": "Fix regression on `Processor.save_pretrained` caused by #31691 (#32921)\n\nfix save_pretrained",
    "sha": "273c0afc8f0289e0cb5d18dc76ccc251504298e0",
    "files": [
        {
            "sha": "60085fd00705b059d324198efa972227dafd89df",
            "filename": "src/transformers/processing_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/273c0afc8f0289e0cb5d18dc76ccc251504298e0/src%2Ftransformers%2Fprocessing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/273c0afc8f0289e0cb5d18dc76ccc251504298e0/src%2Ftransformers%2Fprocessing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fprocessing_utils.py?ref=273c0afc8f0289e0cb5d18dc76ccc251504298e0",
            "patch": "@@ -522,7 +522,7 @@ def save_pretrained(self, save_directory, push_to_hub: bool = False, **kwargs):\n                 token=kwargs.get(\"token\"),\n             )\n \n-        if set(self.to_dict().keys()) == {\"processor_class\"}:\n+        if set(processor_dict.keys()) == {\"processor_class\"}:\n             return []\n         return [output_processor_file]\n "
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}