{
    "author": "YangKai0616",
    "message": "Enable glm46v UTs on XPU (#42274)\n\nEnabled XPU UTs",
    "sha": "5804c1fa474f2568e359e3fb5800cb7b13fb01e2",
    "files": [
        {
            "sha": "80522bf08e776c9d363038ffeb77b99ff05c3c21",
            "filename": "tests/models/glm46v/test_modeling_glm46v.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/5804c1fa474f2568e359e3fb5800cb7b13fb01e2/tests%2Fmodels%2Fglm46v%2Ftest_modeling_glm46v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5804c1fa474f2568e359e3fb5800cb7b13fb01e2/tests%2Fmodels%2Fglm46v%2Ftest_modeling_glm46v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fglm46v%2Ftest_modeling_glm46v.py?ref=5804c1fa474f2568e359e3fb5800cb7b13fb01e2",
            "patch": "@@ -29,7 +29,7 @@\n     require_deterministic_for_xpu,\n     require_flash_attn,\n     require_torch,\n-    require_torch_gpu,\n+    require_torch_accelerator,\n     slow,\n     torch_device,\n )\n@@ -512,7 +512,7 @@ def test_small_model_integration_test_batch_different_resolutions(self):\n \n     @slow\n     @require_flash_attn\n-    @require_torch_gpu\n+    @require_torch_accelerator\n     def test_small_model_integration_test_batch_flashatt2(self):\n         model = Glm46VForConditionalGeneration.from_pretrained(\n             \"THUDM/GLM-4.1V-9B-Thinking\",\n@@ -547,7 +547,7 @@ def test_small_model_integration_test_batch_flashatt2(self):\n \n     @slow\n     @require_flash_attn\n-    @require_torch_gpu\n+    @require_torch_accelerator\n     def test_small_model_integration_test_batch_wo_image_flashatt2(self):\n         model = Glm46VForConditionalGeneration.from_pretrained(\n             \"THUDM/GLM-4.1V-9B-Thinking\","
        }
    ],
    "stats": {
        "total": 6,
        "additions": 3,
        "deletions": 3
    }
}