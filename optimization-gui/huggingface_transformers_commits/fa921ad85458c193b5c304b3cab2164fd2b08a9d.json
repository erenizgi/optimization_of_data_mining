{
    "author": "davidjsonn",
    "message": "fix spelling errors  (#38608)\n\n* fix errors test_modeling_mllama.py\n\n* fix error test_modeling_video_llava.py\n\n* fix errors test_processing_common.py",
    "sha": "fa921ad85458c193b5c304b3cab2164fd2b08a9d",
    "files": [
        {
            "sha": "41ae39681698804619a28dc7f3739f132fe2bcf7",
            "filename": "tests/models/mllama/test_modeling_mllama.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/fa921ad85458c193b5c304b3cab2164fd2b08a9d/tests%2Fmodels%2Fmllama%2Ftest_modeling_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fa921ad85458c193b5c304b3cab2164fd2b08a9d/tests%2Fmodels%2Fmllama%2Ftest_modeling_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmllama%2Ftest_modeling_mllama.py?ref=fa921ad85458c193b5c304b3cab2164fd2b08a9d",
            "patch": "@@ -366,15 +366,15 @@ def test_contrastive_generate_low_memory(self, assistant_type):\n     def test_assisted_decoding_with_num_logits_to_keep(self):\n         pass\n \n-    @unittest.skip(reason=\"Mllama uses self.weights dirrectly causing device mismatch when offloading`\")\n+    @unittest.skip(reason=\"Mllama uses self.weights directly causing device mismatch when offloading`\")\n     def test_cpu_offload(self):\n         pass\n \n-    @unittest.skip(reason=\"Mllama uses self.weights dirrectly causing device mismatch when offloading`\")\n+    @unittest.skip(reason=\"Mllama uses self.weights directly causing device mismatch when offloading`\")\n     def test_disk_offload_bin(self):\n         pass\n \n-    @unittest.skip(reason=\"Mllama uses self.weights dirrectly causing device mismatch when offloading`\")\n+    @unittest.skip(reason=\"Mllama uses self.weights directly causing device mismatch when offloading`\")\n     def test_disk_offload_safetensors(self):\n         pass\n "
        },
        {
            "sha": "39196f2b1c2fc64265a0a496b20b33b12c2cbb05",
            "filename": "tests/models/video_llava/test_modeling_video_llava.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/fa921ad85458c193b5c304b3cab2164fd2b08a9d/tests%2Fmodels%2Fvideo_llava%2Ftest_modeling_video_llava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fa921ad85458c193b5c304b3cab2164fd2b08a9d/tests%2Fmodels%2Fvideo_llava%2Ftest_modeling_video_llava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvideo_llava%2Ftest_modeling_video_llava.py?ref=fa921ad85458c193b5c304b3cab2164fd2b08a9d",
            "patch": "@@ -399,7 +399,7 @@ def test_mismatching_num_image_tokens(self):\n         for model_class in self.all_model_classes:\n             model = model_class(config).to(torch_device)\n             curr_input_dict = copy.deepcopy(input_dict)\n-            _ = model(**curr_input_dict)  # successfull forward with no modifications\n+            _ = model(**curr_input_dict)  # successful forward with no modifications\n \n             # remove one image but leave the image token in text\n             curr_input_dict[\"pixel_values_images\"] = curr_input_dict[\"pixel_values_images\"][-1:, ...]"
        },
        {
            "sha": "ea3e40d98f4bde0d89e81427bb443e4d99135a47",
            "filename": "tests/test_processing_common.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/fa921ad85458c193b5c304b3cab2164fd2b08a9d/tests%2Ftest_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fa921ad85458c193b5c304b3cab2164fd2b08a9d/tests%2Ftest_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_processing_common.py?ref=fa921ad85458c193b5c304b3cab2164fd2b08a9d",
            "patch": "@@ -915,7 +915,7 @@ def test_apply_chat_template_audio(self, batch_size: int, return_tensors: str):\n         )\n \n     @require_av\n-    @parameterized.expand([(1, \"pt\"), (2, \"pt\")])  # video processor suports only torchvision\n+    @parameterized.expand([(1, \"pt\"), (2, \"pt\")])  # video processor supports only torchvision\n     def test_apply_chat_template_video(self, batch_size: int, return_tensors: str):\n         self._test_apply_chat_template(\n             \"video\", batch_size, return_tensors, \"videos_input_name\", \"video_processor\", MODALITY_INPUT_DATA[\"videos\"]"
        }
    ],
    "stats": {
        "total": 10,
        "additions": 5,
        "deletions": 5
    }
}