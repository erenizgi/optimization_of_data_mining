{
    "author": "ArthurZucker",
    "message": "[`Exaone4`] Fixes the attn implementation!  (#39906)\n\n* fix\n\n* fix config",
    "sha": "cc5de364543f1c516911bdcf31e828afb56b1278",
    "files": [
        {
            "sha": "e040efcb56d0064096a2c9067fb7a2ddc14b8102",
            "filename": "src/transformers/models/exaone4/configuration_exaone4.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc5de364543f1c516911bdcf31e828afb56b1278/src%2Ftransformers%2Fmodels%2Fexaone4%2Fconfiguration_exaone4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc5de364543f1c516911bdcf31e828afb56b1278/src%2Ftransformers%2Fmodels%2Fexaone4%2Fconfiguration_exaone4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fexaone4%2Fconfiguration_exaone4.py?ref=cc5de364543f1c516911bdcf31e828afb56b1278",
            "patch": "@@ -212,7 +212,7 @@ def __init__(\n                 for i in range(self.num_hidden_layers)\n             ]\n         if \"sliding_window\" in self.layer_types:\n-            self._attn_implementation = \"hybrid\"\n+            self.cache_implementation = \"hybrid\"\n         layer_type_validation(self.layer_types)\n \n         super().__init__("
        },
        {
            "sha": "41200030bb569e10fac771eaeaba01e374dc2227",
            "filename": "src/transformers/models/exaone4/modular_exaone4.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc5de364543f1c516911bdcf31e828afb56b1278/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodular_exaone4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc5de364543f1c516911bdcf31e828afb56b1278/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodular_exaone4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fexaone4%2Fmodular_exaone4.py?ref=cc5de364543f1c516911bdcf31e828afb56b1278",
            "patch": "@@ -246,7 +246,7 @@ def __init__(\n                 for i in range(self.num_hidden_layers)\n             ]\n         if \"sliding_window\" in self.layer_types:\n-            self._attn_implementation = \"hybrid\"\n+            self.cache_implementation = \"hybrid\"\n         layer_type_validation(self.layer_types)\n \n         super().__init__("
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}