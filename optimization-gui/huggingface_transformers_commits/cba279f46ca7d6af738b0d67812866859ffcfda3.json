{
    "author": "zucchini-nlp",
    "message": "[VLMs] add helpers for get/set embedding (#38144)\n\n* add helpers in VLMs\n\n* fix tied weight key test",
    "sha": "cba279f46ca7d6af738b0d67812866859ffcfda3",
    "files": [
        {
            "sha": "8f552cfc8157aaf94f6b4e9f7a43fee675681d4c",
            "filename": "src/transformers/models/aria/modeling_aria.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -1219,6 +1219,12 @@ def get_output_embeddings(self) -> nn.Module:\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def language_model(self):"
        },
        {
            "sha": "e074d4b1193fe0585783c7fa5fe5c646ac425247",
            "filename": "src/transformers/models/aya_vision/modeling_aya_vision.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodeling_aya_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodeling_aya_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodeling_aya_vision.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -389,6 +389,12 @@ def get_output_embeddings(self) -> nn.Module:\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def language_model(self):"
        },
        {
            "sha": "31f01db1b5af51310ca033daea8c1ced6b3327fa",
            "filename": "src/transformers/models/emu3/modeling_emu3.py",
            "status": "modified",
            "additions": 13,
            "deletions": 3,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -1438,9 +1438,6 @@ class Emu3Model(Emu3PreTrainedModel):\n     def __init__(self, config):\n         super().__init__(config)\n         self.text_model = Emu3TextModel._from_config(config.text_config)\n-        if self.text_model._tied_weights_keys is not None:\n-            self._tied_weights_keys = [f\"text_model.{k}\" for k in self.text_model._tied_weights_keys]\n-\n         self.vqmodel = Emu3VQVAE(config.vq_config)\n         self.vocabulary_mapping = Emu3ImageVocabularyMapping(config.vocabulary_map)\n \n@@ -1561,6 +1558,7 @@ def forward(\n \n class Emu3ForConditionalGeneration(Emu3PreTrainedModel, GenerationMixin):\n     base_model_prefix = \"\"\n+    _tied_weights_keys = [\"lm_head.weight\"]\n     _checkpoint_conversion_mapping = {\n         \"^text_model.model\": \"model.text_model\",\n         \"^vqmodel\": \"model.vqmodel\",\n@@ -1581,6 +1579,18 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.model.set_input_embeddings(value)\n \n+    def get_output_embeddings(self) -> nn.Module:\n+        return self.lm_head\n+\n+    def set_output_embeddings(self, new_embeddings):\n+        self.lm_head = new_embeddings\n+\n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def text_model(self):"
        },
        {
            "sha": "8c86f81d5235b7935825fa9ece0b2094cb4ad179",
            "filename": "src/transformers/models/emu3/modular_emu3.py",
            "status": "modified",
            "additions": 13,
            "deletions": 3,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Femu3%2Fmodular_emu3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Femu3%2Fmodular_emu3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Femu3%2Fmodular_emu3.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -925,9 +925,6 @@ class Emu3Model(Emu3PreTrainedModel):\n     def __init__(self, config):\n         super().__init__(config)\n         self.text_model = Emu3TextModel._from_config(config.text_config)\n-        if self.text_model._tied_weights_keys is not None:\n-            self._tied_weights_keys = [f\"text_model.{k}\" for k in self.text_model._tied_weights_keys]\n-\n         self.vqmodel = Emu3VQVAE(config.vq_config)\n         self.vocabulary_mapping = Emu3ImageVocabularyMapping(config.vocabulary_map)\n \n@@ -1048,6 +1045,7 @@ def forward(\n \n class Emu3ForConditionalGeneration(Emu3PreTrainedModel, GenerationMixin):\n     base_model_prefix = \"\"\n+    _tied_weights_keys = [\"lm_head.weight\"]\n     _checkpoint_conversion_mapping = {\n         \"^text_model.model\": \"model.text_model\",\n         \"^vqmodel\": \"model.vqmodel\",\n@@ -1068,6 +1066,18 @@ def get_input_embeddings(self):\n     def set_input_embeddings(self, value):\n         self.model.set_input_embeddings(value)\n \n+    def get_output_embeddings(self) -> nn.Module:\n+        return self.lm_head\n+\n+    def set_output_embeddings(self, new_embeddings):\n+        self.lm_head = new_embeddings\n+\n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def text_model(self):"
        },
        {
            "sha": "92fbeff330315773ef576ef39ddbc7665c6a3257",
            "filename": "src/transformers/models/gemma3/modeling_gemma3.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodeling_gemma3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodeling_gemma3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodeling_gemma3.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -1008,6 +1008,12 @@ def get_output_embeddings(self):\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def language_model(self):"
        },
        {
            "sha": "0d6b44214ba2df24e94bc5f6d0b7fe2357f56745",
            "filename": "src/transformers/models/got_ocr2/modeling_got_ocr2.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fmodeling_got_ocr2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fmodeling_got_ocr2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fmodeling_got_ocr2.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -755,6 +755,12 @@ def get_output_embeddings(self) -> nn.Module:\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def language_model(self):"
        },
        {
            "sha": "c73f84d9222c8f170d0f1cf59b1e43b8dfd19358",
            "filename": "src/transformers/models/internvl/modeling_internvl.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodeling_internvl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodeling_internvl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodeling_internvl.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -868,6 +868,12 @@ def get_output_embeddings(self) -> nn.Module:\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def language_model(self):"
        },
        {
            "sha": "1fcb00e6e58a63972e2844dd341174a69407ead3",
            "filename": "src/transformers/models/llava/modeling_llava.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fllava%2Fmodeling_llava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fllava%2Fmodeling_llava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava%2Fmodeling_llava.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -359,6 +359,12 @@ def get_output_embeddings(self) -> nn.Module:\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def language_model(self):"
        },
        {
            "sha": "fb56a9b1748a3d2b8e3b497d12f7e9f3ebc4e04c",
            "filename": "src/transformers/models/llava_next/modeling_llava_next.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fllava_next%2Fmodeling_llava_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fllava_next%2Fmodeling_llava_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_next%2Fmodeling_llava_next.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -567,6 +567,12 @@ def get_output_embeddings(self) -> nn.Module:\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def language_model(self):"
        },
        {
            "sha": "c38ce78bc99c807426ffb800e49f778c67e1dfe4",
            "filename": "src/transformers/models/llava_next_video/modeling_llava_next_video.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fmodeling_llava_next_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fmodeling_llava_next_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fmodeling_llava_next_video.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -698,6 +698,12 @@ def get_output_embeddings(self) -> nn.Module:\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def language_model(self):"
        },
        {
            "sha": "9d40b2cef4da606d94dd831e29899e23e0f7450e",
            "filename": "src/transformers/models/llava_onevision/modeling_llava_onevision.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodeling_llava_onevision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodeling_llava_onevision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodeling_llava_onevision.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -725,6 +725,12 @@ def get_output_embeddings(self) -> nn.Module:\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def language_model(self):"
        },
        {
            "sha": "4da2570090bc699ae693c4de945844f69b789f2c",
            "filename": "src/transformers/models/mistral3/modeling_mistral3.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fmistral3%2Fmodeling_mistral3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fmistral3%2Fmodeling_mistral3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmistral3%2Fmodeling_mistral3.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -401,6 +401,12 @@ def get_output_embeddings(self) -> nn.Module:\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def language_model(self):"
        },
        {
            "sha": "97dd32b72156cc1d44f724c6cbf457b9c6fc1cd4",
            "filename": "src/transformers/models/mllama/modeling_mllama.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -1795,6 +1795,12 @@ def get_output_embeddings(self):\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def language_model(self):"
        },
        {
            "sha": "4e508ef33311284b1413ca2ee4ecad72da0baf73",
            "filename": "src/transformers/models/paligemma/modeling_paligemma.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fmodeling_paligemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fmodeling_paligemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fmodeling_paligemma.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -416,6 +416,12 @@ def get_output_embeddings(self):\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def language_model(self):"
        },
        {
            "sha": "ed7a19ca66454654c301b62daecd7388e9f6e9d4",
            "filename": "src/transformers/models/video_llava/modeling_video_llava.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fmodeling_video_llava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fmodeling_video_llava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fmodeling_video_llava.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -443,6 +443,12 @@ def get_output_embeddings(self) -> nn.Module:\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def language_model(self):"
        },
        {
            "sha": "dbe93bb61602f2c0a26df7eb1a0a03dd658b1afa",
            "filename": "src/transformers/models/vipllava/modeling_vipllava.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fvipllava%2Fmodeling_vipllava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cba279f46ca7d6af738b0d67812866859ffcfda3/src%2Ftransformers%2Fmodels%2Fvipllava%2Fmodeling_vipllava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvipllava%2Fmodeling_vipllava.py?ref=cba279f46ca7d6af738b0d67812866859ffcfda3",
            "patch": "@@ -320,6 +320,12 @@ def get_output_embeddings(self) -> nn.Module:\n     def set_output_embeddings(self, new_embeddings):\n         self.lm_head = new_embeddings\n \n+    def set_decoder(self, decoder):\n+        self.model = decoder\n+\n+    def get_decoder(self):\n+        return self.model\n+\n     # Make modules available throught conditional class for BC\n     @property\n     def language_model(self):"
        }
    ],
    "stats": {
        "total": 116,
        "additions": 110,
        "deletions": 6
    }
}