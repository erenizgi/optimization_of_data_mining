{
    "author": "zucchini-nlp",
    "message": "[v5] Delete left traces of feature extractor (#41321)\n\ndelete the left traces",
    "sha": "50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
    "files": [
        {
            "sha": "f600e8ce27d8ce281084c7abee96886a6bd92447",
            "filename": "src/transformers/models/blip/processing_blip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fblip%2Fprocessing_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fblip%2Fprocessing_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fprocessing_blip.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -60,7 +60,6 @@ class BlipProcessor(ProcessorMixin):\n     def __init__(self, image_processor, tokenizer, **kwargs):\n         tokenizer.return_token_type_ids = False\n         super().__init__(image_processor, tokenizer)\n-        self.current_processor = self.image_processor\n \n     def __call__(\n         self,"
        },
        {
            "sha": "40729f4f450112281c5ace59f839335a661b2746",
            "filename": "src/transformers/models/blip_2/processing_blip_2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fblip_2%2Fprocessing_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fblip_2%2Fprocessing_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip_2%2Fprocessing_blip_2.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -66,7 +66,6 @@ class Blip2Processor(ProcessorMixin):\n \n     def __init__(self, image_processor, tokenizer, num_query_tokens=None, **kwargs):\n         tokenizer.return_token_type_ids = False\n-        self.current_processor = image_processor\n         if not hasattr(tokenizer, \"image_token\"):\n             self.image_token = AddedToken(\"<image>\", normalized=False, special=True)\n             tokenizer.add_tokens([self.image_token], special_tokens=True)"
        },
        {
            "sha": "0510b9b0f3c942ecf85f2e3c72726bb500814d78",
            "filename": "src/transformers/models/chinese_clip/processing_chinese_clip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 22,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fprocessing_chinese_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fprocessing_chinese_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fprocessing_chinese_clip.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -16,8 +16,6 @@\n Image/Text processor class for Chinese-CLIP\n \"\"\"\n \n-import warnings\n-\n from ...processing_utils import ProcessorMixin\n \n \n@@ -41,27 +39,7 @@ class ChineseCLIPProcessor(ProcessorMixin):\n     tokenizer_class = (\"BertTokenizer\", \"BertTokenizerFast\")\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n-        feature_extractor = None\n-        if \"feature_extractor\" in kwargs:\n-            warnings.warn(\n-                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n-                \" instead.\",\n-                FutureWarning,\n-            )\n-            feature_extractor = kwargs.pop(\"feature_extractor\")\n-\n-        image_processor = image_processor if image_processor is not None else feature_extractor\n-\n         super().__init__(image_processor, tokenizer)\n-        self.current_processor = self.image_processor\n-\n-    @property\n-    def feature_extractor_class(self):\n-        warnings.warn(\n-            \"`feature_extractor_class` is deprecated and will be removed in v5. Use `image_processor_class` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor_class\n \n \n __all__ = [\"ChineseCLIPProcessor\"]"
        },
        {
            "sha": "7b856f9981ee6f7d3522c299099836d2b30fac8f",
            "filename": "src/transformers/models/clip/processing_clip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 29,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fclip%2Fprocessing_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fclip%2Fprocessing_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclip%2Fprocessing_clip.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -16,8 +16,6 @@\n Image/Text processor class for CLIP\n \"\"\"\n \n-import warnings\n-\n from ...processing_utils import ProcessorMixin\n \n \n@@ -40,34 +38,7 @@ class CLIPProcessor(ProcessorMixin):\n     tokenizer_class = \"AutoTokenizer\"\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n-        feature_extractor = None\n-        if \"feature_extractor\" in kwargs:\n-            warnings.warn(\n-                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n-                \" instead.\",\n-                FutureWarning,\n-            )\n-            feature_extractor = kwargs.pop(\"feature_extractor\")\n-\n-        image_processor = image_processor if image_processor is not None else feature_extractor\n-\n         super().__init__(image_processor, tokenizer)\n \n-    @property\n-    def feature_extractor_class(self):\n-        warnings.warn(\n-            \"`feature_extractor_class` is deprecated and will be removed in v5. Use `image_processor_class` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor_class\n-\n-    @property\n-    def feature_extractor(self):\n-        warnings.warn(\n-            \"`feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor\n-\n \n __all__ = [\"CLIPProcessor\"]"
        },
        {
            "sha": "39e091106c71de6189fc3edc3dcff386acef20fc",
            "filename": "src/transformers/models/clipseg/processing_clipseg.py",
            "status": "modified",
            "additions": 0,
            "deletions": 29,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fclipseg%2Fprocessing_clipseg.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fclipseg%2Fprocessing_clipseg.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclipseg%2Fprocessing_clipseg.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -16,8 +16,6 @@\n Image/Text processor class for CLIPSeg\n \"\"\"\n \n-import warnings\n-\n from ...processing_utils import ProcessorMixin\n from ...tokenization_utils_base import BatchEncoding\n \n@@ -41,17 +39,6 @@ class CLIPSegProcessor(ProcessorMixin):\n     tokenizer_class = (\"CLIPTokenizer\", \"CLIPTokenizerFast\")\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n-        feature_extractor = None\n-        if \"feature_extractor\" in kwargs:\n-            warnings.warn(\n-                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n-                \" instead.\",\n-                FutureWarning,\n-            )\n-            feature_extractor = kwargs.pop(\"feature_extractor\")\n-\n-        image_processor = image_processor if image_processor is not None else feature_extractor\n-\n         super().__init__(image_processor, tokenizer)\n \n     def __call__(self, text=None, images=None, visual_prompt=None, return_tensors=None, **kwargs):\n@@ -124,21 +111,5 @@ def __call__(self, text=None, images=None, visual_prompt=None, return_tensors=No\n         else:\n             return BatchEncoding(data=dict(**image_features), tensor_type=return_tensors)\n \n-    @property\n-    def feature_extractor_class(self):\n-        warnings.warn(\n-            \"`feature_extractor_class` is deprecated and will be removed in v5. Use `image_processor_class` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor_class\n-\n-    @property\n-    def feature_extractor(self):\n-        warnings.warn(\n-            \"`feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor\n-\n \n __all__ = [\"CLIPSegProcessor\"]"
        },
        {
            "sha": "65ca58bcf781fb174090d45fdd64eff46b134a87",
            "filename": "src/transformers/models/donut/processing_donut.py",
            "status": "modified",
            "additions": 0,
            "deletions": 50,
            "changes": 50,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fdonut%2Fprocessing_donut.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fdonut%2Fprocessing_donut.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdonut%2Fprocessing_donut.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -17,8 +17,6 @@\n \"\"\"\n \n import re\n-import warnings\n-from contextlib import contextmanager\n from typing import Optional, Union\n \n from ...image_utils import ImageInput\n@@ -55,20 +53,7 @@ class DonutProcessor(ProcessorMixin):\n     tokenizer_class = \"AutoTokenizer\"\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n-        feature_extractor = None\n-        if \"feature_extractor\" in kwargs:\n-            warnings.warn(\n-                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n-                \" instead.\",\n-                FutureWarning,\n-            )\n-            feature_extractor = kwargs.pop(\"feature_extractor\")\n-\n-        image_processor = image_processor if image_processor is not None else feature_extractor\n-\n         super().__init__(image_processor, tokenizer)\n-        self.current_processor = self.image_processor\n-        self._in_target_context_manager = False\n \n     def __call__(\n         self,\n@@ -82,9 +67,6 @@ def __call__(\n         [`~DonutProcessor.as_target_processor`] this method forwards all its arguments to DonutTokenizer's\n         [`~DonutTokenizer.__call__`]. Please refer to the docstring of the above two methods for more information.\n         \"\"\"\n-        if self._in_target_context_manager:\n-            return self.current_processor(images, text, **kwargs)\n-\n         if images is None and text is None:\n             raise ValueError(\"You need to specify either an `images` or `text` input to process.\")\n \n@@ -116,22 +98,6 @@ def model_input_names(self):\n \n         return list(image_processor_input_names + [\"input_ids\", \"labels\"])\n \n-    @contextmanager\n-    def as_target_processor(self):\n-        \"\"\"\n-        Temporarily sets the tokenizer for processing the input. Useful for encoding the labels when fine-tuning TrOCR.\n-        \"\"\"\n-        warnings.warn(\n-            \"`as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your \"\n-            \"labels by using the argument `text` of the regular `__call__` method (either in the same call as \"\n-            \"your images inputs, or in a separate call.\"\n-        )\n-        self._in_target_context_manager = True\n-        self.current_processor = self.tokenizer\n-        yield\n-        self.current_processor = self.image_processor\n-        self._in_target_context_manager = False\n-\n     def token2json(self, tokens, is_inner_value=False, added_vocab=None):\n         \"\"\"\n         Convert a (generated) token sequence into an ordered JSON format.\n@@ -190,21 +156,5 @@ def token2json(self, tokens, is_inner_value=False, added_vocab=None):\n         else:\n             return [] if is_inner_value else {\"text_sequence\": tokens}\n \n-    @property\n-    def feature_extractor_class(self):\n-        warnings.warn(\n-            \"`feature_extractor_class` is deprecated and will be removed in v5. Use `image_processor_class` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor_class\n-\n-    @property\n-    def feature_extractor(self):\n-        warnings.warn(\n-            \"`feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor\n-\n \n __all__ = [\"DonutProcessor\"]"
        },
        {
            "sha": "272fb01d7b7a23e8882f5c3a68d70060f2465a2c",
            "filename": "src/transformers/models/flava/processing_flava.py",
            "status": "modified",
            "additions": 0,
            "deletions": 29,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fflava%2Fprocessing_flava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fflava%2Fprocessing_flava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflava%2Fprocessing_flava.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -16,8 +16,6 @@\n Image/Text processor class for FLAVA\n \"\"\"\n \n-import warnings\n-\n from ...processing_utils import ProcessorMixin\n \n \n@@ -38,34 +36,7 @@ class FlavaProcessor(ProcessorMixin):\n     tokenizer_class = (\"BertTokenizer\", \"BertTokenizerFast\")\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n-        feature_extractor = None\n-        if \"feature_extractor\" in kwargs:\n-            warnings.warn(\n-                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n-                \" instead.\",\n-                FutureWarning,\n-            )\n-            feature_extractor = kwargs.pop(\"feature_extractor\")\n-\n-        image_processor = image_processor if image_processor is not None else feature_extractor\n         super().__init__(image_processor, tokenizer)\n-        self.current_processor = self.image_processor\n-\n-    @property\n-    def feature_extractor_class(self):\n-        warnings.warn(\n-            \"`feature_extractor_class` is deprecated and will be removed in v5. Use `image_processor_class` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor_class\n-\n-    @property\n-    def feature_extractor(self):\n-        warnings.warn(\n-            \"`feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor\n \n \n __all__ = [\"FlavaProcessor\"]"
        },
        {
            "sha": "a715ce412313143919075aa27233ed089504d0fd",
            "filename": "src/transformers/models/fuyu/processing_fuyu.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Ffuyu%2Fprocessing_fuyu.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Ffuyu%2Fprocessing_fuyu.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffuyu%2Fprocessing_fuyu.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -531,7 +531,6 @@ def __call__(\n \n         if text is not None and images is None:\n             logger.warning(\"You are processing a text with no associated image. Make sure it is intended.\")\n-            self.current_processor = self.tokenizer\n             text_encoding = self.tokenizer(text, **output_kwargs[\"text_kwargs\"])\n             return text_encoding\n "
        },
        {
            "sha": "2eba7c68f58402a563b3bde3222332636081cd14",
            "filename": "src/transformers/models/git/processing_git.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fgit%2Fprocessing_git.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fgit%2Fprocessing_git.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgit%2Fprocessing_git.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -39,7 +39,6 @@ class GitProcessor(ProcessorMixin):\n \n     def __init__(self, image_processor, tokenizer):\n         super().__init__(image_processor, tokenizer)\n-        self.current_processor = self.image_processor\n \n \n __all__ = [\"GitProcessor\"]"
        },
        {
            "sha": "b0ad20df386bf93a1bb602f0d81a326ac5fb00ba",
            "filename": "src/transformers/models/idefics/processing_idefics.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fidefics%2Fprocessing_idefics.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fidefics%2Fprocessing_idefics.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics%2Fprocessing_idefics.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -159,7 +159,6 @@ class IdeficsProcessor(ProcessorMixin):\n \n     def __init__(self, image_processor, tokenizer=None, image_size=224, add_end_of_utterance_token=None, **kwargs):\n         super().__init__(image_processor, tokenizer)\n-        self.current_processor = self.image_processor\n         self.image_token_id = (\n             tokenizer.image_token_id\n             if hasattr(tokenizer, \"image_token\")"
        },
        {
            "sha": "0a6ea0d200301d3a3a98040155ef504704cca672",
            "filename": "src/transformers/models/layoutlmv2/processing_layoutlmv2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fprocessing_layoutlmv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fprocessing_layoutlmv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fprocessing_layoutlmv2.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -16,7 +16,6 @@\n Processor class for LayoutLMv2.\n \"\"\"\n \n-import warnings\n from typing import Optional, Union\n \n from ...processing_utils import ProcessorMixin\n@@ -49,17 +48,6 @@ class LayoutLMv2Processor(ProcessorMixin):\n     tokenizer_class = (\"LayoutLMv2Tokenizer\", \"LayoutLMv2TokenizerFast\")\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n-        feature_extractor = None\n-        if \"feature_extractor\" in kwargs:\n-            warnings.warn(\n-                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n-                \" instead.\",\n-                FutureWarning,\n-            )\n-            feature_extractor = kwargs.pop(\"feature_extractor\")\n-\n-        image_processor = image_processor if image_processor is not None else feature_extractor\n-\n         super().__init__(image_processor, tokenizer)\n \n     def __call__(\n@@ -166,21 +154,5 @@ def get_overflowing_images(self, images, overflow_to_sample_mapping):\n     def model_input_names(self):\n         return [\"input_ids\", \"bbox\", \"token_type_ids\", \"attention_mask\", \"image\"]\n \n-    @property\n-    def feature_extractor_class(self):\n-        warnings.warn(\n-            \"`feature_extractor_class` is deprecated and will be removed in v5. Use `image_processor_class` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor_class\n-\n-    @property\n-    def feature_extractor(self):\n-        warnings.warn(\n-            \"`feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor\n-\n \n __all__ = [\"LayoutLMv2Processor\"]"
        },
        {
            "sha": "f4a2906b59852cf5e9888e885e06b64111435d5c",
            "filename": "src/transformers/models/layoutlmv3/processing_layoutlmv3.py",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Flayoutlmv3%2Fprocessing_layoutlmv3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Flayoutlmv3%2Fprocessing_layoutlmv3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flayoutlmv3%2Fprocessing_layoutlmv3.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -16,7 +16,6 @@\n Processor class for LayoutLMv3.\n \"\"\"\n \n-import warnings\n from typing import Optional, Union\n \n from ...processing_utils import ProcessorMixin\n@@ -49,17 +48,6 @@ class LayoutLMv3Processor(ProcessorMixin):\n     tokenizer_class = (\"LayoutLMv3Tokenizer\", \"LayoutLMv3TokenizerFast\")\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n-        feature_extractor = None\n-        if \"feature_extractor\" in kwargs:\n-            warnings.warn(\n-                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n-                \" instead.\",\n-                FutureWarning,\n-            )\n-            feature_extractor = kwargs.pop(\"feature_extractor\")\n-\n-        image_processor = image_processor if image_processor is not None else feature_extractor\n-\n         super().__init__(image_processor, tokenizer)\n \n     def __call__(\n@@ -164,21 +152,5 @@ def get_overflowing_images(self, images, overflow_to_sample_mapping):\n     def model_input_names(self):\n         return [\"input_ids\", \"bbox\", \"attention_mask\", \"pixel_values\"]\n \n-    @property\n-    def feature_extractor_class(self):\n-        warnings.warn(\n-            \"`feature_extractor_class` is deprecated and will be removed in v5. Use `image_processor_class` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor_class\n-\n-    @property\n-    def feature_extractor(self):\n-        warnings.warn(\n-            \"`feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor\n-\n \n __all__ = [\"LayoutLMv3Processor\"]"
        },
        {
            "sha": "8e6ef52f6c0f8392cd9041c4fd974c86e6244d2b",
            "filename": "src/transformers/models/layoutxlm/processing_layoutxlm.py",
            "status": "modified",
            "additions": 0,
            "deletions": 27,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Flayoutxlm%2Fprocessing_layoutxlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Flayoutxlm%2Fprocessing_layoutxlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flayoutxlm%2Fprocessing_layoutxlm.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -16,7 +16,6 @@\n Processor class for LayoutXLM.\n \"\"\"\n \n-import warnings\n from typing import Optional, Union\n \n from ...processing_utils import ProcessorMixin\n@@ -49,16 +48,6 @@ class LayoutXLMProcessor(ProcessorMixin):\n     tokenizer_class = (\"LayoutXLMTokenizer\", \"LayoutXLMTokenizerFast\")\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n-        if \"feature_extractor\" in kwargs:\n-            warnings.warn(\n-                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n-                \" instead.\",\n-                FutureWarning,\n-            )\n-            feature_extractor = kwargs.pop(\"feature_extractor\")\n-\n-        image_processor = image_processor if image_processor is not None else feature_extractor\n-\n         super().__init__(image_processor, tokenizer)\n \n     def __call__(\n@@ -165,21 +154,5 @@ def get_overflowing_images(self, images, overflow_to_sample_mapping):\n     def model_input_names(self):\n         return [\"input_ids\", \"bbox\", \"attention_mask\", \"image\"]\n \n-    @property\n-    def feature_extractor_class(self):\n-        warnings.warn(\n-            \"`feature_extractor_class` is deprecated and will be removed in v5. Use `image_processor_class` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor_class\n-\n-    @property\n-    def feature_extractor(self):\n-        warnings.warn(\n-            \"`feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor\n-\n \n __all__ = [\"LayoutXLMProcessor\"]"
        },
        {
            "sha": "349e075c79969dc7e605fa91d7a40a6d79322449",
            "filename": "src/transformers/models/mgp_str/processing_mgp_str.py",
            "status": "modified",
            "additions": 0,
            "deletions": 13,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fmgp_str%2Fprocessing_mgp_str.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fmgp_str%2Fprocessing_mgp_str.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmgp_str%2Fprocessing_mgp_str.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -14,8 +14,6 @@\n # limitations under the License.\n \"\"\"Processor class for MGP-STR.\"\"\"\n \n-import warnings\n-\n from transformers import AutoTokenizer\n from transformers.utils import is_torch_available\n from transformers.utils.generic import ExplicitEnum\n@@ -57,17 +55,6 @@ class MgpstrProcessor(ProcessorMixin):\n     char_tokenizer_class = \"MgpstrTokenizer\"\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n-        feature_extractor = None\n-        if \"feature_extractor\" in kwargs:\n-            warnings.warn(\n-                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n-                \" instead.\",\n-                FutureWarning,\n-            )\n-            feature_extractor = kwargs.pop(\"feature_extractor\")\n-\n-        image_processor = image_processor if image_processor is not None else feature_extractor\n-\n         self.char_tokenizer = tokenizer\n         self.bpe_tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n         self.wp_tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
        },
        {
            "sha": "030013d34f98e91fb10b2aad969b7203e88612fa",
            "filename": "src/transformers/models/musicgen/processing_musicgen.py",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fmusicgen%2Fprocessing_musicgen.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fmusicgen%2Fprocessing_musicgen.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmusicgen%2Fprocessing_musicgen.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -44,8 +44,6 @@ class MusicgenProcessor(ProcessorMixin):\n \n     def __init__(self, feature_extractor, tokenizer):\n         super().__init__(feature_extractor, tokenizer)\n-        self.current_processor = self.feature_extractor\n-        self._in_target_context_manager = False\n \n     def get_decoder_prompt_ids(self, task=None, language=None, no_timestamps=True):\n         return self.tokenizer.get_decoder_prompt_ids(task=task, language=language, no_timestamps=no_timestamps)\n@@ -56,10 +54,6 @@ def __call__(self, *args, **kwargs):\n         argument to [`~T5Tokenizer.__call__`]. Please refer to the docstring of the above two methods for more\n         information.\n         \"\"\"\n-        # For backward compatibility\n-        if self._in_target_context_manager:\n-            return self.current_processor(*args, **kwargs)\n-\n         if len(args) > 0:\n             kwargs[\"audio\"] = args[0]\n         return super().__call__(*args, **kwargs)"
        },
        {
            "sha": "b0b6d665bd22f9e01e0f7fe0c6019d13695c2513",
            "filename": "src/transformers/models/nougat/processing_nougat.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fnougat%2Fprocessing_nougat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fnougat%2Fprocessing_nougat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fnougat%2Fprocessing_nougat.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -44,7 +44,6 @@ class NougatProcessor(ProcessorMixin):\n \n     def __init__(self, image_processor, tokenizer):\n         super().__init__(image_processor, tokenizer)\n-        self.current_processor = self.image_processor\n \n     def __call__(\n         self,"
        },
        {
            "sha": "e6715e9688b91cd658a28e633513335cadd3eef7",
            "filename": "src/transformers/models/owlvit/processing_owlvit.py",
            "status": "modified",
            "additions": 0,
            "deletions": 27,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fowlvit%2Fprocessing_owlvit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fowlvit%2Fprocessing_owlvit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fowlvit%2Fprocessing_owlvit.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -71,17 +71,6 @@ class OwlViTProcessor(ProcessorMixin):\n     tokenizer_class = (\"CLIPTokenizer\", \"CLIPTokenizerFast\")\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n-        feature_extractor = None\n-        if \"feature_extractor\" in kwargs:\n-            warnings.warn(\n-                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n-                \" instead.\",\n-                FutureWarning,\n-            )\n-            feature_extractor = kwargs.pop(\"feature_extractor\")\n-\n-        image_processor = image_processor if image_processor is not None else feature_extractor\n-\n         super().__init__(image_processor, tokenizer)\n \n     def __call__(\n@@ -283,21 +272,5 @@ def post_process_image_guided_detection(\n             outputs=outputs, threshold=threshold, nms_threshold=nms_threshold, target_sizes=target_sizes\n         )\n \n-    @property\n-    def feature_extractor_class(self):\n-        warnings.warn(\n-            \"`feature_extractor_class` is deprecated and will be removed in v5. Use `image_processor_class` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor_class\n-\n-    @property\n-    def feature_extractor(self):\n-        warnings.warn(\n-            \"`feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor\n-\n \n __all__ = [\"OwlViTProcessor\"]"
        },
        {
            "sha": "25667f09ad81a4992f935f7866f3e84b22b39598",
            "filename": "src/transformers/models/pix2struct/processing_pix2struct.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fpix2struct%2Fprocessing_pix2struct.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fpix2struct%2Fprocessing_pix2struct.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpix2struct%2Fprocessing_pix2struct.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -95,7 +95,6 @@ def __call__(\n             output_kwargs[\"text_kwargs\"][\"add_special_tokens\"] = (\n                 add_special_tokens if add_special_tokens is not None else True\n             )\n-            self.current_processor = self.tokenizer\n             text_encoding = self.tokenizer(text=text, **output_kwargs[\"text_kwargs\"])\n             return text_encoding\n "
        },
        {
            "sha": "3cfe31c6547a537544c65cb7fd7d65f5340bfb96",
            "filename": "src/transformers/models/speech_to_text/processing_speech_to_text.py",
            "status": "modified",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fspeech_to_text%2Fprocessing_speech_to_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fspeech_to_text%2Fprocessing_speech_to_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fspeech_to_text%2Fprocessing_speech_to_text.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -17,7 +17,6 @@\n \"\"\"\n \n import warnings\n-from contextlib import contextmanager\n \n from ...processing_utils import ProcessorMixin\n \n@@ -43,8 +42,6 @@ class Speech2TextProcessor(ProcessorMixin):\n \n     def __init__(self, feature_extractor, tokenizer):\n         super().__init__(feature_extractor, tokenizer)\n-        self.current_processor = self.feature_extractor\n-        self._in_target_context_manager = False\n \n     def __call__(self, *args, **kwargs):\n         \"\"\"\n@@ -54,10 +51,6 @@ def __call__(self, *args, **kwargs):\n         [`~Speech2TextTokenizer.__call__`]. Please refer to the docstring of the above two methods for more\n         information.\n         \"\"\"\n-        # For backward compatibility\n-        if self._in_target_context_manager:\n-            return self.current_processor(*args, **kwargs)\n-\n         if \"raw_speech\" in kwargs:\n             warnings.warn(\"Using `raw_speech` as a keyword argument is deprecated. Use `audio` instead.\")\n             audio = kwargs.pop(\"raw_speech\")\n@@ -85,22 +78,5 @@ def __call__(self, *args, **kwargs):\n             inputs[\"labels\"] = encodings[\"input_ids\"]\n             return inputs\n \n-    @contextmanager\n-    def as_target_processor(self):\n-        \"\"\"\n-        Temporarily sets the tokenizer for processing the input. Useful for encoding the labels when fine-tuning\n-        Speech2Text.\n-        \"\"\"\n-        warnings.warn(\n-            \"`as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your \"\n-            \"labels by using the argument `text` of the regular `__call__` method (either in the same call as \"\n-            \"your audio inputs, or in a separate call.\"\n-        )\n-        self._in_target_context_manager = True\n-        self.current_processor = self.tokenizer\n-        yield\n-        self.current_processor = self.feature_extractor\n-        self._in_target_context_manager = False\n-\n \n __all__ = [\"Speech2TextProcessor\"]"
        },
        {
            "sha": "037f708e4ee4566476babc5007635e261a35a1ca",
            "filename": "src/transformers/models/trocr/processing_trocr.py",
            "status": "modified",
            "additions": 0,
            "deletions": 51,
            "changes": 51,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Ftrocr%2Fprocessing_trocr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Ftrocr%2Fprocessing_trocr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftrocr%2Fprocessing_trocr.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -16,8 +16,6 @@\n Processor class for TrOCR.\n \"\"\"\n \n-import warnings\n-from contextlib import contextmanager\n from typing import Optional, Union\n \n from ...image_processing_utils import BatchFeature\n@@ -50,20 +48,7 @@ class TrOCRProcessor(ProcessorMixin):\n     tokenizer_class = \"AutoTokenizer\"\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n-        feature_extractor = None\n-        if \"feature_extractor\" in kwargs:\n-            warnings.warn(\n-                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n-                \" instead.\",\n-                FutureWarning,\n-            )\n-            feature_extractor = kwargs.pop(\"feature_extractor\")\n-\n-        image_processor = image_processor if image_processor is not None else feature_extractor\n-\n         super().__init__(image_processor, tokenizer)\n-        self.current_processor = self.image_processor\n-        self._in_target_context_manager = False\n \n     def __call__(\n         self,\n@@ -77,10 +62,6 @@ def __call__(\n         [`~TrOCRProcessor.as_target_processor`] this method forwards all its arguments to TrOCRTokenizer's\n         [`~TrOCRTokenizer.__call__`]. Please refer to the docstring of the above two methods for more information.\n         \"\"\"\n-        # For backward compatibility\n-        if self._in_target_context_manager:\n-            return self.current_processor(images, **kwargs)\n-\n         if images is None and text is None:\n             raise ValueError(\"You need to specify either an `images` or `text` input to process.\")\n \n@@ -108,37 +89,5 @@ def model_input_names(self):\n         image_processor_input_names = self.image_processor.model_input_names\n         return image_processor_input_names + [\"labels\"]\n \n-    @contextmanager\n-    def as_target_processor(self):\n-        \"\"\"\n-        Temporarily sets the tokenizer for processing the input. Useful for encoding the labels when fine-tuning TrOCR.\n-        \"\"\"\n-        warnings.warn(\n-            \"`as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your \"\n-            \"labels by using the argument `text` of the regular `__call__` method (either in the same call as \"\n-            \"your images inputs, or in a separate call.\"\n-        )\n-        self._in_target_context_manager = True\n-        self.current_processor = self.tokenizer\n-        yield\n-        self.current_processor = self.image_processor\n-        self._in_target_context_manager = False\n-\n-    @property\n-    def feature_extractor_class(self):\n-        warnings.warn(\n-            \"`feature_extractor_class` is deprecated and will be removed in v5. Use `image_processor_class` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor_class\n-\n-    @property\n-    def feature_extractor(self):\n-        warnings.warn(\n-            \"`feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor\n-\n \n __all__ = [\"TrOCRProcessor\"]"
        },
        {
            "sha": "ceda264a5345ed6adf711b195d97fec8e44bdb49",
            "filename": "src/transformers/models/vilt/processing_vilt.py",
            "status": "modified",
            "additions": 0,
            "deletions": 29,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fvilt%2Fprocessing_vilt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fvilt%2Fprocessing_vilt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvilt%2Fprocessing_vilt.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -16,8 +16,6 @@\n Processor class for ViLT.\n \"\"\"\n \n-import warnings\n-\n from ...processing_utils import ProcessingKwargs, ProcessorMixin\n \n \n@@ -56,34 +54,7 @@ class ViltProcessor(ProcessorMixin):\n     valid_processor_kwargs = ViltProcessorKwargs\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n-        feature_extractor = None\n-        if \"feature_extractor\" in kwargs:\n-            warnings.warn(\n-                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n-                \" instead.\",\n-                FutureWarning,\n-            )\n-            feature_extractor = kwargs.pop(\"feature_extractor\")\n-\n-        image_processor = image_processor if image_processor is not None else feature_extractor\n         super().__init__(image_processor, tokenizer)\n-        self.current_processor = self.image_processor\n-\n-    @property\n-    def feature_extractor_class(self):\n-        warnings.warn(\n-            \"`feature_extractor_class` is deprecated and will be removed in v5. Use `image_processor_class` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor_class\n-\n-    @property\n-    def feature_extractor(self):\n-        warnings.warn(\n-            \"`feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor\n \n \n __all__ = [\"ViltProcessor\"]"
        },
        {
            "sha": "b98f2ac3f3739712f027033dfefe045616de066b",
            "filename": "src/transformers/models/vision_text_dual_encoder/processing_vision_text_dual_encoder.py",
            "status": "modified",
            "additions": 0,
            "deletions": 29,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fvision_text_dual_encoder%2Fprocessing_vision_text_dual_encoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fvision_text_dual_encoder%2Fprocessing_vision_text_dual_encoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvision_text_dual_encoder%2Fprocessing_vision_text_dual_encoder.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -16,8 +16,6 @@\n Processor class for VisionTextDualEncoder\n \"\"\"\n \n-import warnings\n-\n from ...processing_utils import ProcessingKwargs, ProcessorMixin\n \n \n@@ -46,34 +44,7 @@ class VisionTextDualEncoderProcessor(ProcessorMixin):\n     tokenizer_class = \"AutoTokenizer\"\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n-        feature_extractor = None\n-        if \"feature_extractor\" in kwargs:\n-            warnings.warn(\n-                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n-                \" instead.\",\n-                FutureWarning,\n-            )\n-            feature_extractor = kwargs.pop(\"feature_extractor\")\n-\n-        image_processor = image_processor if image_processor is not None else feature_extractor\n         super().__init__(image_processor, tokenizer)\n-        self.current_processor = self.image_processor\n-\n-    @property\n-    def feature_extractor_class(self):\n-        warnings.warn(\n-            \"`feature_extractor_class` is deprecated and will be removed in v5. Use `image_processor_class` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor_class\n-\n-    @property\n-    def feature_extractor(self):\n-        warnings.warn(\n-            \"`feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor\n \n \n __all__ = [\"VisionTextDualEncoderProcessor\"]"
        },
        {
            "sha": "642151e24fedaf5d9bcddecc3e58db65ea50b0a7",
            "filename": "src/transformers/models/wav2vec2/processing_wav2vec2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 31,
            "changes": 31,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fprocessing_wav2vec2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fprocessing_wav2vec2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fprocessing_wav2vec2.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -17,7 +17,6 @@\n \"\"\"\n \n import warnings\n-from contextlib import contextmanager\n from typing import Optional, Union\n \n from ...processing_utils import ProcessingKwargs, ProcessorMixin, Unpack\n@@ -50,8 +49,6 @@ class Wav2Vec2Processor(ProcessorMixin):\n \n     def __init__(self, feature_extractor, tokenizer):\n         super().__init__(feature_extractor, tokenizer)\n-        self.current_processor = self.feature_extractor\n-        self._in_target_context_manager = False\n \n     @classmethod\n     def from_pretrained(cls, pretrained_model_name_or_path, **kwargs):\n@@ -104,13 +101,6 @@ def __call__(\n             tokenizer_init_kwargs=self.tokenizer.init_kwargs,\n             **kwargs,\n         )\n-        # For backward compatibility\n-        if self._in_target_context_manager:\n-            return self.current_processor(\n-                audio,\n-                **output_kwargs[\"audio_kwargs\"],\n-                **output_kwargs[\"text_kwargs\"],\n-            )\n \n         if audio is not None:\n             inputs = self.feature_extractor(audio, **output_kwargs[\"audio_kwargs\"])\n@@ -139,10 +129,6 @@ def pad(self, *args, **kwargs):\n         Returns:\n             This method returns the results of each `pad` method. If both are used, the output is a dictionary containing the results of both.\n         \"\"\"\n-        # For backward compatibility\n-        if self._in_target_context_manager:\n-            return self.current_processor.pad(*args, **kwargs)\n-\n         input_features = kwargs.pop(\"input_features\", None)\n         labels = kwargs.pop(\"labels\", None)\n         if len(args) > 0:\n@@ -168,22 +154,5 @@ def model_input_names(self):\n         feature_extractor_input_names = self.feature_extractor.model_input_names\n         return feature_extractor_input_names + [\"labels\"]\n \n-    @contextmanager\n-    def as_target_processor(self):\n-        \"\"\"\n-        Temporarily sets the tokenizer for processing the input. Useful for encoding the labels when fine-tuning\n-        Wav2Vec2.\n-        \"\"\"\n-        warnings.warn(\n-            \"`as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your \"\n-            \"labels by using the argument `text` of the regular `__call__` method (either in the same call as \"\n-            \"your audio inputs, or in a separate call.\"\n-        )\n-        self._in_target_context_manager = True\n-        self.current_processor = self.tokenizer\n-        yield\n-        self.current_processor = self.feature_extractor\n-        self._in_target_context_manager = False\n-\n \n __all__ = [\"Wav2Vec2Processor\"]"
        },
        {
            "sha": "f5605ea6c5b51e70894e581fc909a90f004adffd",
            "filename": "src/transformers/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 28,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fwav2vec2_with_lm%2Fprocessing_wav2vec2_with_lm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fwav2vec2_with_lm%2Fprocessing_wav2vec2_with_lm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwav2vec2_with_lm%2Fprocessing_wav2vec2_with_lm.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -19,7 +19,7 @@\n import os\n import warnings\n from collections.abc import Iterable\n-from contextlib import contextmanager, nullcontext\n+from contextlib import nullcontext\n from dataclasses import dataclass\n from multiprocessing import Pool, get_context, get_start_method\n from typing import TYPE_CHECKING, Optional, Union\n@@ -110,8 +110,6 @@ def __init__(\n             )\n \n         self.decoder = decoder\n-        self.current_processor = self.feature_extractor\n-        self._in_target_context_manager = False\n \n     def save_pretrained(self, save_directory):\n         super().save_pretrained(save_directory)\n@@ -227,10 +225,6 @@ def __call__(self, *args, **kwargs):\n         Wav2Vec2CTCTokenizer's [`~Wav2Vec2CTCTokenizer.__call__`]. Please refer to the docstring of the above two\n         methods for more information.\n         \"\"\"\n-        # For backward compatibility\n-        if self._in_target_context_manager:\n-            return self.current_processor(*args, **kwargs)\n-\n         if \"raw_speech\" in kwargs:\n             warnings.warn(\"Using `raw_speech` as a keyword argument is deprecated. Use `audio` instead.\")\n             audio = kwargs.pop(\"raw_speech\")\n@@ -266,10 +260,6 @@ def pad(self, *args, **kwargs):\n         Wav2Vec2CTCTokenizer's [`~Wav2Vec2CTCTokenizer.pad`]. Please refer to the docstring of the above two methods\n         for more information.\n         \"\"\"\n-        # For backward compatibility\n-        if self._in_target_context_manager:\n-            return self.current_processor.pad(*args, **kwargs)\n-\n         input_features = kwargs.pop(\"input_features\", None)\n         labels = kwargs.pop(\"labels\", None)\n         if len(args) > 0:\n@@ -638,22 +628,5 @@ def decode(\n                 word_offsets=word_offsets[:n_best] if word_offsets is not None else None,\n             )\n \n-    @contextmanager\n-    def as_target_processor(self):\n-        \"\"\"\n-        Temporarily sets the processor for processing the target. Useful for encoding the labels when fine-tuning\n-        Wav2Vec2.\n-        \"\"\"\n-        warnings.warn(\n-            \"`as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your \"\n-            \"labels by using the argument `text` of the regular `__call__` method (either in the same call as \"\n-            \"your audio inputs, or in a separate call.\"\n-        )\n-        self._in_target_context_manager = True\n-        self.current_processor = self.tokenizer\n-        yield\n-        self.current_processor = self.feature_extractor\n-        self._in_target_context_manager = False\n-\n \n __all__ = [\"Wav2Vec2ProcessorWithLM\"]"
        },
        {
            "sha": "ece78b2f10b171e9c20ca3603eff658e626ed987",
            "filename": "src/transformers/models/whisper/processing_whisper.py",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fwhisper%2Fprocessing_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fwhisper%2Fprocessing_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Fprocessing_whisper.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -39,8 +39,6 @@ class WhisperProcessor(ProcessorMixin):\n \n     def __init__(self, feature_extractor, tokenizer):\n         super().__init__(feature_extractor, tokenizer)\n-        self.current_processor = self.feature_extractor\n-        self._in_target_context_manager = False\n \n     def get_decoder_prompt_ids(self, task=None, language=None, no_timestamps=True):\n         return self.tokenizer.get_decoder_prompt_ids(task=task, language=language, no_timestamps=no_timestamps)\n@@ -51,10 +49,6 @@ def __call__(self, *args, **kwargs):\n         argument to [`~WhisperTokenizer.__call__`]. Please refer to the docstring of the above two methods for more\n         information.\n         \"\"\"\n-        # For backward compatibility\n-        if self._in_target_context_manager:\n-            return self.current_processor(*args, **kwargs)\n-\n         audio = kwargs.pop(\"audio\", None)\n         sampling_rate = kwargs.pop(\"sampling_rate\", None)\n         text = kwargs.pop(\"text\", None)"
        },
        {
            "sha": "2110a783bb37ded26b3c95afa03ae87cd7ebe8d8",
            "filename": "src/transformers/models/x_clip/processing_x_clip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 29,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fx_clip%2Fprocessing_x_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/50090c3fc82e1e0a06b4da366ea2fb6055d529e9/src%2Ftransformers%2Fmodels%2Fx_clip%2Fprocessing_x_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fx_clip%2Fprocessing_x_clip.py?ref=50090c3fc82e1e0a06b4da366ea2fb6055d529e9",
            "patch": "@@ -16,8 +16,6 @@\n Image/Text processor class for XCLIP\n \"\"\"\n \n-import warnings\n-\n from ...processing_utils import ProcessorMixin\n \n \n@@ -40,35 +38,8 @@ class XCLIPProcessor(ProcessorMixin):\n     tokenizer_class = (\"CLIPTokenizer\", \"CLIPTokenizerFast\")\n \n     def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n-        feature_extractor = None\n-        if \"feature_extractor\" in kwargs:\n-            warnings.warn(\n-                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n-                \" instead.\",\n-                FutureWarning,\n-            )\n-            feature_extractor = kwargs.pop(\"feature_extractor\")\n-\n-        image_processor = image_processor if image_processor is not None else feature_extractor\n         super().__init__(image_processor, tokenizer)\n         self.video_processor = self.image_processor\n-        self.current_processor = self.image_processor\n-\n-    @property\n-    def feature_extractor_class(self):\n-        warnings.warn(\n-            \"`feature_extractor_class` is deprecated and will be removed in v5. Use `image_processor_class` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor_class\n-\n-    @property\n-    def feature_extractor(self):\n-        warnings.warn(\n-            \"`feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\",\n-            FutureWarning,\n-        )\n-        return self.image_processor\n \n \n __all__ = [\"XCLIPProcessor\"]"
        }
    ],
    "stats": {
        "total": 523,
        "additions": 1,
        "deletions": 522
    }
}