{
    "author": "jp1924",
    "message": "Fix: img size mismatch caused by incorrect unpadding in LLaVA-Next (#34522)\n\nFix: unpadding img mismatch",
    "sha": "1b86772de5d8429ff5ffe5caf7855548d2f4f072",
    "files": [
        {
            "sha": "2d23c48225cd0084947f0cab2c7a827d13a440f1",
            "filename": "src/transformers/models/llava_next/modeling_llava_next.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/1b86772de5d8429ff5ffe5caf7855548d2f4f072/src%2Ftransformers%2Fmodels%2Fllava_next%2Fmodeling_llava_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1b86772de5d8429ff5ffe5caf7855548d2f4f072/src%2Ftransformers%2Fmodels%2Fllava_next%2Fmodeling_llava_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_next%2Fmodeling_llava_next.py?ref=1b86772de5d8429ff5ffe5caf7855548d2f4f072",
            "patch": "@@ -138,12 +138,12 @@ def unpad_image(tensor, original_size):\n \n     if original_aspect_ratio > current_aspect_ratio:\n         scale_factor = current_width / original_width\n-        new_height = int(original_height * scale_factor)\n+        new_height = int(round(original_height * scale_factor, 7))\n         padding = (current_height - new_height) // 2\n         unpadded_tensor = tensor[:, padding : current_height - padding, :]\n     else:\n         scale_factor = current_height / original_height\n-        new_width = int(original_width * scale_factor)\n+        new_width = int(round(original_width * scale_factor, 7))\n         padding = (current_width - new_width) // 2\n         unpadded_tensor = tensor[:, :, padding : current_width - padding]\n "
        },
        {
            "sha": "a2328c1d2d92cbfdb057cb31c770cb582e17c07c",
            "filename": "src/transformers/models/llava_next_video/modeling_llava_next_video.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/1b86772de5d8429ff5ffe5caf7855548d2f4f072/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fmodeling_llava_next_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1b86772de5d8429ff5ffe5caf7855548d2f4f072/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fmodeling_llava_next_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fmodeling_llava_next_video.py?ref=1b86772de5d8429ff5ffe5caf7855548d2f4f072",
            "patch": "@@ -143,12 +143,12 @@ def unpad_image(tensor, original_size):\n \n     if original_aspect_ratio > current_aspect_ratio:\n         scale_factor = current_width / original_width\n-        new_height = int(original_height * scale_factor)\n+        new_height = int(round(original_height * scale_factor, 7))\n         padding = (current_height - new_height) // 2\n         unpadded_tensor = tensor[:, padding : current_height - padding, :]\n     else:\n         scale_factor = current_height / original_height\n-        new_width = int(original_width * scale_factor)\n+        new_width = int(round(original_width * scale_factor, 7))\n         padding = (current_width - new_width) // 2\n         unpadded_tensor = tensor[:, :, padding : current_width - padding]\n "
        },
        {
            "sha": "626db4d96aae2e47731b7aae6ca226613600d582",
            "filename": "src/transformers/models/llava_onevision/modeling_llava_onevision.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/1b86772de5d8429ff5ffe5caf7855548d2f4f072/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodeling_llava_onevision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1b86772de5d8429ff5ffe5caf7855548d2f4f072/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodeling_llava_onevision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodeling_llava_onevision.py?ref=1b86772de5d8429ff5ffe5caf7855548d2f4f072",
            "patch": "@@ -139,12 +139,12 @@ def unpad_image(tensor, original_size):\n \n     if original_aspect_ratio > current_aspect_ratio:\n         scale_factor = current_width / original_width\n-        new_height = int(original_height * scale_factor)\n+        new_height = int(round(original_height * scale_factor, 7))\n         padding = (current_height - new_height) // 2\n         unpadded_tensor = tensor[:, padding : current_height - padding, :]\n     else:\n         scale_factor = current_height / original_height\n-        new_width = int(original_width * scale_factor)\n+        new_width = int(round(original_width * scale_factor, 7))\n         padding = (current_width - new_width) // 2\n         unpadded_tensor = tensor[:, :, padding : current_width - padding]\n "
        }
    ],
    "stats": {
        "total": 12,
        "additions": 6,
        "deletions": 6
    }
}