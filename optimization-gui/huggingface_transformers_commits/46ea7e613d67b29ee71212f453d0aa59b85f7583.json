{
    "author": "ydshieh",
    "message": "[testing] test `num_hidden_layers` being small in model tester (#40992)\n\nfix\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "46ea7e613d67b29ee71212f453d0aa59b85f7583",
    "files": [
        {
            "sha": "b4a2f345b895fc9c594f5d3666605df92fe00f2c",
            "filename": "tests/models/aya_vision/test_modeling_aya_vision.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Faya_vision%2Ftest_modeling_aya_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Faya_vision%2Ftest_modeling_aya_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faya_vision%2Ftest_modeling_aya_vision.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -71,7 +71,7 @@ def __init__(\n             \"vocab_size\": 99,\n             \"hidden_size\": 128,\n             \"intermediate_size\": 37,\n-            \"num_hidden_layers\": 4,\n+            \"num_hidden_layers\": 2,\n             \"num_attention_heads\": 4,\n             \"output_channels\": 64,\n             \"hidden_act\": \"silu\","
        },
        {
            "sha": "06f99fc1c6ace596f180253b986167b6d6fd9df9",
            "filename": "tests/models/bamba/test_modeling_bamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fbamba%2Ftest_modeling_bamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fbamba%2Ftest_modeling_bamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbamba%2Ftest_modeling_bamba.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -73,7 +73,7 @@ def __init__(\n         use_labels=True,\n         vocab_size=99,\n         hidden_size=32,\n-        num_hidden_layers=4,\n+        num_hidden_layers=2,\n         num_attention_heads=4,\n         num_key_value_heads=2,\n         intermediate_size=64,"
        },
        {
            "sha": "19bc0c45eb2e45c2f4aeccf6a715e3ecee219f80",
            "filename": "tests/models/bitnet/test_modeling_bitnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fbitnet%2Ftest_modeling_bitnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fbitnet%2Ftest_modeling_bitnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbitnet%2Ftest_modeling_bitnet.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -49,7 +49,7 @@ def __init__(\n         use_input_mask=True,\n         vocab_size=99,\n         hidden_size=64,\n-        num_hidden_layers=5,\n+        num_hidden_layers=2,\n         num_attention_heads=4,\n         num_key_value_heads=2,\n         intermediate_size=37,"
        },
        {
            "sha": "8f3f5957e02e28b96a185e251421490163576b60",
            "filename": "tests/models/bros/test_modeling_bros.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fbros%2Ftest_modeling_bros.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fbros%2Ftest_modeling_bros.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbros%2Ftest_modeling_bros.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -49,7 +49,7 @@ def __init__(\n         use_labels=True,\n         vocab_size=99,\n         hidden_size=64,\n-        num_hidden_layers=5,\n+        num_hidden_layers=2,\n         num_attention_heads=4,\n         intermediate_size=37,\n         hidden_act=\"gelu\","
        },
        {
            "sha": "436d1f9d4226e8d9f9d12259cb79c7c7fb573a35",
            "filename": "tests/models/cohere/test_modeling_cohere.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fcohere%2Ftest_modeling_cohere.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fcohere%2Ftest_modeling_cohere.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fcohere%2Ftest_modeling_cohere.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -54,7 +54,7 @@ def __init__(\n         use_labels=True,\n         vocab_size=99,\n         hidden_size=32,\n-        num_hidden_layers=4,\n+        num_hidden_layers=2,\n         num_attention_heads=4,\n         intermediate_size=37,\n         hidden_act=\"gelu\","
        },
        {
            "sha": "776b2b254f178831d683c2a0473caf6e5309b77a",
            "filename": "tests/models/cohere2_vision/test_modeling_cohere2_vision.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fcohere2_vision%2Ftest_modeling_cohere2_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fcohere2_vision%2Ftest_modeling_cohere2_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fcohere2_vision%2Ftest_modeling_cohere2_vision.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -65,7 +65,7 @@ def __init__(\n             \"vocab_size\": 99,\n             \"hidden_size\": 128,\n             \"intermediate_size\": 37,\n-            \"num_hidden_layers\": 4,\n+            \"num_hidden_layers\": 2,\n             \"num_attention_heads\": 4,\n             \"output_channels\": 64,\n             \"hidden_act\": \"silu\","
        },
        {
            "sha": "62bb9c999958b7a7dcc849379dc193f1962f4ec6",
            "filename": "tests/models/deepseek_v3/test_modeling_deepseek_v3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fdeepseek_v3%2Ftest_modeling_deepseek_v3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fdeepseek_v3%2Ftest_modeling_deepseek_v3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdeepseek_v3%2Ftest_modeling_deepseek_v3.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -65,7 +65,7 @@ def __init__(\n         hidden_size=32,\n         intermediate_size=37,\n         moe_intermediate_size=12,\n-        num_hidden_layers=5,\n+        num_hidden_layers=2,\n         num_attention_heads=4,\n         num_key_value_heads=4,\n         n_shared_experts=1,"
        },
        {
            "sha": "f0d4a7c1fa9eb42984241a9454796658b6b785ea",
            "filename": "tests/models/eomt/test_modeling_eomt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Feomt%2Ftest_modeling_eomt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Feomt%2Ftest_modeling_eomt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Feomt%2Ftest_modeling_eomt.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -47,7 +47,7 @@ def __init__(\n         num_labels=4,\n         hidden_size=8,\n         num_attention_heads=2,\n-        num_hidden_layers=4,\n+        num_hidden_layers=2,\n     ):\n         self.parent = parent\n         self.batch_size = batch_size"
        },
        {
            "sha": "14e160fe594f90a9ea76e67fc83b1aa9c5f643fa",
            "filename": "tests/models/falcon/test_modeling_falcon.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Ffalcon%2Ftest_modeling_falcon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Ffalcon%2Ftest_modeling_falcon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ffalcon%2Ftest_modeling_falcon.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -208,7 +208,7 @@ def test_falcon_alibi_sdpa_matches_eager(self):\n         config = FalconConfig(\n             vocab_size=1000,\n             hidden_size=64,\n-            num_hidden_layers=3,\n+            num_hidden_layers=2,\n             num_attention_heads=4,\n             new_decoder_architecture=True,\n             alibi=True,"
        },
        {
            "sha": "3e475ef708027ac5a8933a3aea0c5d62550837c3",
            "filename": "tests/models/falcon_h1/test_modeling_falcon_h1.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Ffalcon_h1%2Ftest_modeling_falcon_h1.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Ffalcon_h1%2Ftest_modeling_falcon_h1.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ffalcon_h1%2Ftest_modeling_falcon_h1.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -55,7 +55,7 @@ def __init__(\n         use_labels=True,\n         vocab_size=99,\n         hidden_size=32,\n-        num_hidden_layers=4,\n+        num_hidden_layers=2,\n         num_attention_heads=4,\n         num_key_value_heads=2,\n         intermediate_size=64,"
        },
        {
            "sha": "3ece8d3aabafdcaf928567039676b75501db94e1",
            "filename": "tests/models/got_ocr2/test_modeling_got_ocr2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fgot_ocr2%2Ftest_modeling_got_ocr2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fgot_ocr2%2Ftest_modeling_got_ocr2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgot_ocr2%2Ftest_modeling_got_ocr2.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -59,7 +59,7 @@ def __init__(\n             \"vocab_size\": 99,\n             \"hidden_size\": 128,\n             \"intermediate_size\": 37,\n-            \"num_hidden_layers\": 4,\n+            \"num_hidden_layers\": 2,\n             \"num_attention_heads\": 4,\n             \"num_key_value_heads\": 2,\n             \"output_channels\": 64,"
        },
        {
            "sha": "5539d6a0b075d3853e214b46cd16f301023af783",
            "filename": "tests/models/idefics/test_modeling_idefics.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fidefics%2Ftest_modeling_idefics.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fidefics%2Ftest_modeling_idefics.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fidefics%2Ftest_modeling_idefics.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -67,7 +67,7 @@ def __init__(\n         use_labels=True,\n         vocab_size=99,\n         hidden_size=32,\n-        num_hidden_layers=5,\n+        num_hidden_layers=2,\n         num_attention_heads=4,\n         intermediate_size=37,\n         hidden_act=\"gelu\",\n@@ -85,7 +85,7 @@ def __init__(\n         vision_patch_size=2,\n         vision_image_size=30,\n         vision_num_attention_heads=4,\n-        vision_num_hidden_layers=5,\n+        vision_num_hidden_layers=2,\n         vision_intermediate_size=37,\n         perceiver_qk_layer_norms_perceiver=False,\n         perceiver_resampler_depth=2,"
        },
        {
            "sha": "6603f3604e0bb1d119188ddb21a2adff510795e2",
            "filename": "tests/models/idefics2/test_modeling_idefics2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fidefics2%2Ftest_modeling_idefics2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fidefics2%2Ftest_modeling_idefics2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fidefics2%2Ftest_modeling_idefics2.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -86,7 +86,7 @@ def __init__(\n             \"vocab_size\": 100,\n             \"hidden_size\": 64,\n             \"intermediate_size\": 56,\n-            \"num_hidden_layers\": 3,\n+            \"num_hidden_layers\": 2,\n             \"num_attention_heads\": 2,\n             \"num_key_value_heads\": 2,\n             \"hidden_act\": \"silu\","
        },
        {
            "sha": "fe05eda8c0fbabbac6c158fea16f57d17b6dd71d",
            "filename": "tests/models/idefics3/test_modeling_idefics3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fidefics3%2Ftest_modeling_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fidefics3%2Ftest_modeling_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fidefics3%2Ftest_modeling_idefics3.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -74,7 +74,7 @@ def __init__(\n             \"vocab_size\": 100,\n             \"hidden_size\": 64,\n             \"intermediate_size\": 56,\n-            \"num_hidden_layers\": 3,\n+            \"num_hidden_layers\": 2,\n             \"num_attention_heads\": 2,\n             \"num_key_value_heads\": 2,\n             \"hidden_act\": \"silu\","
        },
        {
            "sha": "8704fccb6a1c6b6b384da8adcc3d5f9124be156d",
            "filename": "tests/models/internvl/test_modeling_internvl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -74,7 +74,7 @@ def __init__(\n             \"vocab_size\": 99,\n             \"hidden_size\": 128,\n             \"intermediate_size\": 37,\n-            \"num_hidden_layers\": 4,\n+            \"num_hidden_layers\": 2,\n             \"num_attention_heads\": 4,\n             \"num_key_value_heads\": 2,\n             \"output_channels\": 64,"
        },
        {
            "sha": "ecfda972339d46d1344bfada9412e8b826a1673b",
            "filename": "tests/models/longcat_flash/test_modeling_longcat_flash.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Flongcat_flash%2Ftest_modeling_longcat_flash.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Flongcat_flash%2Ftest_modeling_longcat_flash.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flongcat_flash%2Ftest_modeling_longcat_flash.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -60,7 +60,7 @@ def __init__(\n         hidden_size=144,\n         ffn_hidden_size=288,\n         expert_ffn_hidden_size=48,\n-        num_layers=2,\n+        num_layers=1,  # We have `self.num_hidden_layers = 2 * num_layers` in the body. See `LongcatFlashConfig`.\n         num_attention_heads=8,\n         num_key_value_heads=8,\n         kv_lora_rank=16,\n@@ -96,7 +96,7 @@ def __init__(\n         self.expert_ffn_hidden_size = expert_ffn_hidden_size\n         self.num_layers = num_layers\n         self.num_hidden_layers = 2 * num_layers  # for compatibility\n-        self.expected_num_hidden_layers = 3  # embedding + 2 layers\n+        self.expected_num_hidden_layers = 2  # embedding + 2 layers\n         self.num_attention_heads = num_attention_heads\n         self.num_key_value_heads = num_key_value_heads\n         self.kv_lora_rank = kv_lora_rank"
        },
        {
            "sha": "3d9a88d561ce54ae6bfcec912eacbd1919f8ae70",
            "filename": "tests/models/lxmert/test_modeling_lxmert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Flxmert%2Ftest_modeling_lxmert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Flxmert%2Ftest_modeling_lxmert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flxmert%2Ftest_modeling_lxmert.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -59,7 +59,7 @@ def __init__(\n         num_object_labels=16,\n         num_attr_labels=4,\n         num_visual_features=10,\n-        l_layers=2,\n+        l_layers=1,\n         x_layers=1,\n         r_layers=1,\n         visual_feat_dim=128,"
        },
        {
            "sha": "0d151602ffcebc32ee3ad7fa0cbdaeb095e139db",
            "filename": "tests/models/mllama/test_modeling_mllama.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fmllama%2Ftest_modeling_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fmllama%2Ftest_modeling_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmllama%2Ftest_modeling_mllama.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -145,7 +145,7 @@ def __init__(\n             \"model_type\": \"mllama\",\n             \"vocab_size\": 99,\n             \"hidden_size\": 32,\n-            \"num_hidden_layers\": 4,\n+            \"num_hidden_layers\": 2,\n             \"num_attention_heads\": 4,\n             \"num_key_value_heads\": 4,\n             \"intermediate_size\": 37,\n@@ -166,7 +166,7 @@ def __init__(\n             \"intermediate_layers_indices\": [0],\n             \"vision_output_dim\": 32,\n             \"projection_dim\": 32,\n-            \"num_hidden_layers\": 6,\n+            \"num_hidden_layers\": 2,\n             \"num_global_layers\": 2,\n             \"num_attention_heads\": 4,\n             \"intermediate_size\": 37,"
        },
        {
            "sha": "91e25f6093b2d65b6f32ca438cf250e87eb7523d",
            "filename": "tests/models/pop2piano/test_modeling_pop2piano.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fpop2piano%2Ftest_modeling_pop2piano.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fpop2piano%2Ftest_modeling_pop2piano.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpop2piano%2Ftest_modeling_pop2piano.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -57,7 +57,7 @@ def __init__(\n         use_attention_mask=True,\n         use_labels=True,\n         hidden_size=64,\n-        num_hidden_layers=5,\n+        num_hidden_layers=2,\n         num_attention_heads=4,\n         d_ff=37,\n         relative_attention_num_buckets=8,"
        },
        {
            "sha": "61fa18153902888c7537e73a6c9bf4bb9ae9ff80",
            "filename": "tests/models/qwen2_5_omni/test_modeling_qwen2_5_omni.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_modeling_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_modeling_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_modeling_qwen2_5_omni.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -99,7 +99,7 @@ def __init__(\n             \"vocab_size\": 99,\n             \"hidden_size\": 32,\n             \"intermediate_size\": 37,\n-            \"num_hidden_layers\": 4,\n+            \"num_hidden_layers\": 2,\n             \"num_attention_heads\": 4,\n             \"num_key_value_heads\": 2,\n             \"hidden_act\": \"silu\","
        },
        {
            "sha": "d90dff9f13ffc996637ac8ce3f2da66c745ce0db",
            "filename": "tests/models/qwen2_5_vl/test_modeling_qwen2_5_vl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -85,7 +85,7 @@ def __init__(\n         max_window_layers=3,\n         model_type=\"qwen2_5_vl\",\n         num_attention_heads=4,\n-        num_hidden_layers=4,\n+        num_hidden_layers=2,\n         num_key_value_heads=2,\n         rope_theta=10000,\n         tie_word_embeddings=True,"
        },
        {
            "sha": "37f315b5dc386d77ca62ce5da89fa98f28bd1cdb",
            "filename": "tests/models/qwen2_vl/test_modeling_qwen2_vl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fqwen2_vl%2Ftest_modeling_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fqwen2_vl%2Ftest_modeling_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_vl%2Ftest_modeling_qwen2_vl.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -79,7 +79,7 @@ def __init__(\n         max_window_layers=3,\n         model_type=\"qwen2_vl\",\n         num_attention_heads=4,\n-        num_hidden_layers=4,\n+        num_hidden_layers=2,\n         num_key_value_heads=2,\n         rope_theta=10000,\n         tie_word_embeddings=True,"
        },
        {
            "sha": "6074efecf4a98a2613c05332e944ddb409509f05",
            "filename": "tests/models/qwen3_vl/test_modeling_qwen3_vl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fqwen3_vl%2Ftest_modeling_qwen3_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fqwen3_vl%2Ftest_modeling_qwen3_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen3_vl%2Ftest_modeling_qwen3_vl.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -61,7 +61,7 @@ def __init__(\n             \"max_position_embeddings\": 512,\n             \"model_type\": \"qwen3_vl\",\n             \"num_attention_heads\": 4,\n-            \"num_hidden_layers\": 4,\n+            \"num_hidden_layers\": 2,\n             \"num_key_value_heads\": 2,\n             \"rope_theta\": 10000,\n             \"tie_word_embeddings\": True,"
        },
        {
            "sha": "411845fcbfa5e5add06a6167a09af9d6cde9c0ee",
            "filename": "tests/models/qwen3_vl_moe/test_modeling_qwen3_vl_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fqwen3_vl_moe%2Ftest_modeling_qwen3_vl_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fqwen3_vl_moe%2Ftest_modeling_qwen3_vl_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen3_vl_moe%2Ftest_modeling_qwen3_vl_moe.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -61,7 +61,7 @@ def __init__(\n             \"model_type\": \"qwen3_vl_moe\",\n             \"num_attention_heads\": 4,\n             \"num_key_value_heads\": 2,\n-            \"num_hidden_layers\": 4,\n+            \"num_hidden_layers\": 2,\n             \"moe_intermediate_size\": 16,\n             \"num_experts_per_tok\": 4,\n             \"num_experts\": 8,"
        },
        {
            "sha": "48df1559e991aee28ae5021433d2d67abdc44653",
            "filename": "tests/models/reformer/test_modeling_reformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Freformer%2Ftest_modeling_reformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Freformer%2Ftest_modeling_reformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Freformer%2Ftest_modeling_reformer.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -83,7 +83,7 @@ def __init__(\n         axial_pos_embds=True,\n         axial_pos_shape=[4, 8],\n         axial_pos_embds_dim=[16, 16],\n-        attn_layers=[\"local\", \"local\", \"local\", \"local\"],\n+        attn_layers=[\"local\", \"local\"],\n         pad_token_id=0,\n         eos_token_id=2,\n         scope=None,"
        },
        {
            "sha": "7856afd2c9eb2da14cc28e28405933a1bb2928a1",
            "filename": "tests/models/smolvlm/test_modeling_smolvlm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fsmolvlm%2Ftest_modeling_smolvlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fsmolvlm%2Ftest_modeling_smolvlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsmolvlm%2Ftest_modeling_smolvlm.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -77,7 +77,7 @@ def __init__(\n             \"vocab_size\": 100,\n             \"hidden_size\": 64,\n             \"intermediate_size\": 56,\n-            \"num_hidden_layers\": 3,\n+            \"num_hidden_layers\": 2,\n             \"num_attention_heads\": 2,\n             \"num_key_value_heads\": 2,\n             \"hidden_act\": \"silu\","
        },
        {
            "sha": "4e6aa707ee20d04c56d95492fafdcf635856a351",
            "filename": "tests/models/udop/test_modeling_udop.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fudop%2Ftest_modeling_udop.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fudop%2Ftest_modeling_udop.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fudop%2Ftest_modeling_udop.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -55,7 +55,7 @@ def __init__(\n         use_attention_mask=True,\n         use_labels=True,\n         hidden_size=32,\n-        num_hidden_layers=5,\n+        num_hidden_layers=2,\n         num_attention_heads=4,\n         d_ff=37,\n         relative_attention_num_buckets=32,\n@@ -425,7 +425,7 @@ def __init__(\n         is_training=False,\n         use_attention_mask=True,\n         hidden_size=32,\n-        num_hidden_layers=5,\n+        num_hidden_layers=2,\n         decoder_layers=2,\n         num_attention_heads=4,\n         d_ff=37,"
        },
        {
            "sha": "d5dddc74a3bc149944b3a870b24c8ace9d549f44",
            "filename": "tests/models/vitpose/test_modeling_vitpose.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fvitpose%2Ftest_modeling_vitpose.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fvitpose%2Ftest_modeling_vitpose.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvitpose%2Ftest_modeling_vitpose.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -51,7 +51,7 @@ def __init__(\n         is_training=True,\n         use_labels=True,\n         hidden_size=32,\n-        num_hidden_layers=5,\n+        num_hidden_layers=2,\n         num_attention_heads=4,\n         intermediate_size=37,\n         hidden_act=\"gelu\","
        },
        {
            "sha": "6f8ee5eb9ed495bd7973b87ad078064a599046db",
            "filename": "tests/models/vitpose_backbone/test_modeling_vitpose_backbone.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fvitpose_backbone%2Ftest_modeling_vitpose_backbone.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fvitpose_backbone%2Ftest_modeling_vitpose_backbone.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvitpose_backbone%2Ftest_modeling_vitpose_backbone.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -44,7 +44,7 @@ def __init__(\n         is_training=True,\n         use_labels=True,\n         hidden_size=32,\n-        num_hidden_layers=5,\n+        num_hidden_layers=2,\n         num_attention_heads=4,\n         intermediate_size=37,\n         hidden_act=\"gelu\","
        },
        {
            "sha": "c61cb72bc0a03a136db9b032ee32ee72a6e8d86f",
            "filename": "tests/models/vjepa2/test_modeling_vjepa2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fvjepa2%2Ftest_modeling_vjepa2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fvjepa2%2Ftest_modeling_vjepa2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvjepa2%2Ftest_modeling_vjepa2.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -61,7 +61,7 @@ def __init__(\n         patch_size=16,\n         num_channels=3,\n         hidden_size=32,\n-        num_hidden_layers=4,\n+        num_hidden_layers=2,\n         num_attention_heads=2,\n         num_frames=2,\n         mlp_ratio=1,"
        },
        {
            "sha": "9f1fb24d17c7d28a259020c4a319e2cf09b7a4f5",
            "filename": "tests/models/xlnet/test_modeling_xlnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fxlnet%2Ftest_modeling_xlnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Fmodels%2Fxlnet%2Ftest_modeling_xlnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fxlnet%2Ftest_modeling_xlnet.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -80,7 +80,7 @@ def __init__(\n         self.hidden_size = 32\n         self.num_attention_heads = 4\n         self.d_inner = 128\n-        self.num_hidden_layers = 5\n+        self.num_hidden_layers = 3\n         self.type_sequence_label_size = 2\n         self.bi_data = False\n         self.same_length = False"
        },
        {
            "sha": "1a12f9e4608e3ee450d050863a761f4c56cc5852",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 39,
            "deletions": 0,
            "changes": 39,
            "blob_url": "https://github.com/huggingface/transformers/blob/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/46ea7e613d67b29ee71212f453d0aa59b85f7583/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=46ea7e613d67b29ee71212f453d0aa59b85f7583",
            "patch": "@@ -674,6 +674,45 @@ def _prepare_for_class(self, inputs_dict, model_class, return_labels=False):\n \n         return inputs_dict\n \n+    def test_num_layers_is_small(self):\n+        # TODO (if possible): Avoid exceptional cases, especially for `OwlViT`.\n+        # ⛔ DO NOT edit this list (unless there is really nothing to tweak in the model tester class and approved by the reviewer) ⛔!\n+        exceptional_num_hidden_layers = {\n+            # TODO: There might be some way to fix\n+            \"FunnelModelTest\": 5,\n+            \"FunnelBaseModelTest\": 4,\n+            \"GroupViTVisionModelTest\": 12,\n+            \"OwlViTModelTest\": 12,\n+            \"OwlViTTextModelTest\": 12,\n+            \"OwlViTForObjectDetectionTest\": 12,\n+            \"Owlv2ModelTest\": 12,\n+            \"Owlv2TextModelTest\": 12,\n+            \"Owlv2ForObjectDetectionTest\": 12,\n+            \"SamHQModelTest\": 12,\n+            \"Swin2SRModelTest\": 3,\n+            \"XLNetModelTest\": 3,\n+            \"DPTModelTest\": 4,  # `test_modeling_dpt_hybrid.py`: not able to get it work after change `num_hidden_layers` and `neck_hidden_sizes`\n+            # Nothing we can't do\n+            \"Gemma3nTextModelTest\": 4,  # need to test KV shared layer for both types: `full_attention` and `sliding_attention`\n+            \"BeitModelTest\": 4,  # BeitForSemanticSegmentation requires config.out_indices to be a list of 4 integers\n+            \"ZambaModelTest\": 5,  # The minimum number to test beyond the initial [\"mamba\", \"mamba\", \"hybrid\"] in `ZambaConfig._layers_block_type`\n+        }\n+        target_num_hidden_layers = exceptional_num_hidden_layers.get(type(self).__name__, 2)\n+\n+        if hasattr(self.model_tester, \"num_hidden_layers\") and isinstance(self.model_tester.num_hidden_layers, int):\n+            assert self.model_tester.num_hidden_layers <= target_num_hidden_layers\n+\n+        if hasattr(self.model_tester, \"vision_config\") and \"num_hidden_layers\" in self.model_tester.vision_config:\n+            if isinstance(self.model_tester.vision_config, dict):\n+                assert self.model_tester.vision_config[\"num_hidden_layers\"] <= target_num_hidden_layers\n+            else:\n+                assert self.model_tester.vision_config.num_hidden_layers <= target_num_hidden_layers\n+        if hasattr(self.model_tester, \"text_config\") and \"num_hidden_layers\" in self.model_tester.text_config:\n+            if isinstance(self.model_tester.text_config, dict):\n+                assert self.model_tester.text_config[\"num_hidden_layers\"] <= target_num_hidden_layers\n+            else:\n+                assert self.model_tester.text_config.num_hidden_layers <= target_num_hidden_layers\n+\n     def test_save_load(self):\n         def check_save_load(out1, out2):\n             # make sure we don't have nans"
        }
    ],
    "stats": {
        "total": 109,
        "additions": 74,
        "deletions": 35
    }
}