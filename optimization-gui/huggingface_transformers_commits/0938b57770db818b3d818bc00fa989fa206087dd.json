{
    "author": "zucchini-nlp",
    "message": "Assisted decoding multi-gpu (#35116)\n\n* fix\r\n\r\n* move a few lines up",
    "sha": "0938b57770db818b3d818bc00fa989fa206087dd",
    "files": [
        {
            "sha": "fe634141eca09ba984782ee5de39cbd830b1f992",
            "filename": "src/transformers/generation/utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/0938b57770db818b3d818bc00fa989fa206087dd/src%2Ftransformers%2Fgeneration%2Futils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0938b57770db818b3d818bc00fa989fa206087dd/src%2Ftransformers%2Fgeneration%2Futils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Futils.py?ref=0938b57770db818b3d818bc00fa989fa206087dd",
            "patch": "@@ -4260,9 +4260,10 @@ def _assisted_decoding(\n         while self._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):\n             cur_len = input_ids.shape[-1]\n \n-            #  1. Fetch candidate sequences from a `CandidateGenerator`\n+            #  1. Fetch candidate sequences from a `CandidateGenerator` and move to the correct device\n             candidate_input_ids, candidate_logits = candidate_generator.get_candidates(input_ids)\n \n+            candidate_input_ids = candidate_input_ids.to(self.device)\n             if candidate_logits is not None:\n                 candidate_logits = candidate_logits.to(self.device)\n "
        }
    ],
    "stats": {
        "total": 3,
        "additions": 2,
        "deletions": 1
    }
}