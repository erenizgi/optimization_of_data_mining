{
    "author": "yao-matrix",
    "message": "fix some ut failures on XPU w/ torch 2.9 (#41941)\n\n* fix some ut failures on XPU w/ torch 2.9\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>\n\n* fix style\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>\n\n---------\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>",
    "sha": "e7e7eca06b4ae1284ea6b066d4326744445f8300",
    "files": [
        {
            "sha": "eaf7e391c8f0df4ed728d5f8fe04f4c5b6be4db4",
            "filename": "tests/models/grounding_dino/test_modeling_grounding_dino.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7e7eca06b4ae1284ea6b066d4326744445f8300/tests%2Fmodels%2Fgrounding_dino%2Ftest_modeling_grounding_dino.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7e7eca06b4ae1284ea6b066d4326744445f8300/tests%2Fmodels%2Fgrounding_dino%2Ftest_modeling_grounding_dino.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgrounding_dino%2Ftest_modeling_grounding_dino.py?ref=e7e7eca06b4ae1284ea6b066d4326744445f8300",
            "patch": "@@ -682,7 +682,7 @@ def test_inference_object_detection_head(self):\n \n         expectations = Expectations(\n             {\n-                (None, None): [[0.4526, 0.4082]],\n+                (None, None): [0.4526, 0.4082],\n                 (\"cuda\", 8): [0.4524, 0.4074],\n             }\n         )"
        },
        {
            "sha": "d4a31f5951e2813baaa2bb70f7c7ea57e6a64286",
            "filename": "tests/models/internvl/test_modeling_internvl.py",
            "status": "modified",
            "additions": 16,
            "deletions": 6,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7e7eca06b4ae1284ea6b066d4326744445f8300/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7e7eca06b4ae1284ea6b066d4326744445f8300/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py?ref=e7e7eca06b4ae1284ea6b066d4326744445f8300",
            "patch": "@@ -227,6 +227,7 @@ def setUp(self):\n     def tearDown(self):\n         cleanup(torch_device, gc_collect=True)\n \n+    @require_deterministic_for_xpu\n     def test_qwen2_small_model_integration_generate(self):\n         processor = AutoProcessor.from_pretrained(self.small_model_checkpoint)\n         model = InternVLForConditionalGeneration.from_pretrained(\n@@ -244,7 +245,16 @@ def test_qwen2_small_model_integration_generate(self):\n             decoded_output = processor.decode(\n                 generate_ids[0, inputs[\"input_ids\"].shape[1] :], skip_special_tokens=True\n             )\n-        expected_output = \"The image shows two cats lying on a pink surface, which appears to be a bed or couch.\"\n+\n+        # fmt: off\n+        expected_outputs = Expectations(\n+            {\n+                (None, None): \"The image shows two cats lying on a pink surface, which appears to be a bed or couch.\",\n+                (\"xpu\", 3): \"The image shows two cats lying on a pink blanket. The cat on the left is a tabby\",\n+            }\n+        )\n+        # fmt: on\n+        expected_output = expected_outputs.get_expectation()\n \n         self.assertEqual(decoded_output, expected_output)\n \n@@ -268,9 +278,9 @@ def test_qwen2_small_model_integration_forward(self):\n         actual_logits = output.logits[0, -1, :5].cpu()\n         expected_logits_all = Expectations(\n             {\n-                (\"xpu\", 3): torch.tensor([11.7500, 14.7500, 14.1250, 10.5625, 6.7812], dtype=torch.float16),\n-                (\"cuda\", 7): torch.tensor([11.9531, 14.7031, 14.2734, 10.6562,  6.9219], dtype=torch.float16),\n-                (\"cuda\", 8): torch.tensor([11.9609, 14.7188, 14.2734, 10.6484,  6.9141], dtype=torch.float16),\n+                (\"xpu\", 3): torch.tensor([11.9922, 14.7188, 14.3125, 10.6719, 6.9297], dtype=torch.float16),\n+                (\"cuda\", 7): torch.tensor([11.9531, 14.7031, 14.2734, 10.6562, 6.9219], dtype=torch.float16),\n+                (\"cuda\", 8): torch.tensor([11.9609, 14.7188, 14.2734, 10.6484, 6.9141], dtype=torch.float16),\n             }\n         )  # fmt: skip\n         expected_logits = expected_logits_all.get_expectation()\n@@ -298,7 +308,7 @@ def test_qwen2_small_model_integration_generate_text_only(self):\n \n         expected_outputs = Expectations(\n             {\n-                (\"xpu\", 3): \"Whispers of dawn,\\nSilent whispers of the night,\\nNew day's light.\",\n+                (\"xpu\", 3): \"Whispers of dawn,\\nSilent whispers of night,\\nPeace in the stillness.\",\n                 (\"cuda\", 7): 'Whispers of dawn,\\nSilent whispers of night,\\nPeace in the stillness.',\n                 (\"cuda\", 8): 'Whispers of dawn,\\nSilent whispers of night,\\nPeace in the stillness.',\n             }\n@@ -570,7 +580,7 @@ def test_qwen2_small_model_integration_interleaved_images_videos(self):\n         decoded_output = processor.decode(output[1], skip_special_tokens=True)\n         expected_outputs = Expectations(\n             {\n-                (\"xpu\", 3): \"user\\nFrame1: \\nFrame2: \\nFrame3: \\nFrame4: \\nFrame5: \\nFrame6: \\nFrame7: \\nFrame8: \\nWhat type of shot is the man performing?\\nassistant\\nThe man is performing a forehand shot.\",\n+                (\"xpu\", 3): \"user\\nFrame1: \\nFrame2: \\nFrame3: \\nFrame4: \\nFrame5: \\nFrame6: \\nFrame7: \\nFrame8: \\nWhat type of shot is the man performing?\\nassistant\\nA forehand shot\",\n                 (\"cuda\", 7): 'user\\nFrame1: \\nFrame2: \\nFrame3: \\nFrame4: \\nFrame5: \\nFrame6: \\nFrame7: \\nFrame8: \\nWhat type of shot is the man performing?\\nassistant\\nA forehand shot',\n             }\n         )  # fmt: skip"
        },
        {
            "sha": "0f2e5db4d8aac12c46015257c90b7b67022655b2",
            "filename": "tests/test_processing_common.py",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7e7eca06b4ae1284ea6b066d4326744445f8300/tests%2Ftest_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7e7eca06b4ae1284ea6b066d4326744445f8300/tests%2Ftest_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_processing_common.py?ref=e7e7eca06b4ae1284ea6b066d4326744445f8300",
            "patch": "@@ -37,8 +37,9 @@\n from transformers.utils import is_torch_available, is_vision_available\n \n \n-sys.path.append(\".\")\n-from utils.fetch_hub_objects_for_ci import url_to_local_path\n+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n+sys.path.append(os.path.join(parent_dir, \"utils\"))\n+from fetch_hub_objects_for_ci import url_to_local_path  # noqa: E402\n \n \n global_rng = random.Random()"
        }
    ],
    "stats": {
        "total": 29,
        "additions": 20,
        "deletions": 9
    }
}