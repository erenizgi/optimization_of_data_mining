{
    "author": "Cyrilvallez",
    "message": "Fix TimesFm doc issue (#37552)\n\n* fix doc\n\n* code block",
    "sha": "dc8227827d3e94a2db544415cfcf0f037812b582",
    "files": [
        {
            "sha": "e34f823500da1af5eb049fe593fd4f19cc44d6cc",
            "filename": "src/transformers/models/timesfm/modeling_timesfm.py",
            "status": "modified",
            "additions": 32,
            "deletions": 28,
            "changes": 60,
            "blob_url": "https://github.com/huggingface/transformers/blob/dc8227827d3e94a2db544415cfcf0f037812b582/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fmodeling_timesfm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dc8227827d3e94a2db544415cfcf0f037812b582/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fmodeling_timesfm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fmodeling_timesfm.py?ref=dc8227827d3e94a2db544415cfcf0f037812b582",
            "patch": "@@ -33,7 +33,6 @@\n from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n from ...processing_utils import Unpack\n from ...utils import (\n-    add_code_sample_docstrings,\n     add_start_docstrings,\n     add_start_docstrings_to_model_forward,\n     can_return_tuple,\n@@ -44,8 +43,6 @@\n \n \n logger = logging.get_logger(__name__)\n-\n-_CHECKPOINT_FOR_DOC = \"google/timesfm-2.0-500m-pytorch\"\n _CONFIG_FOR_DOC = \"TimesFmConfig\"\n \n \n@@ -734,11 +731,6 @@ def _quantile_loss(self, predictions: torch.Tensor, targets: torch.Tensor) -> to\n     @can_return_tuple\n     @add_start_docstrings_to_model_forward(TIMESFM_INPUTS_DOCSTRING)\n     @replace_return_docstrings(output_type=TimesFmOutputForPrediction, config_class=_CONFIG_FOR_DOC)\n-    @add_code_sample_docstrings(\n-        checkpoint=_CHECKPOINT_FOR_DOC,\n-        output_type=TimesFmOutputForPrediction,\n-        config_class=_CONFIG_FOR_DOC,\n-    )\n     def forward(\n         self,\n         past_values: Sequence[torch.Tensor],\n@@ -752,28 +744,40 @@ def forward(\n         output_hidden_states: Optional[bool] = None,\n     ) -> TimesFmOutputForPrediction:\n         r\"\"\"\n-        window_size (`int`, *optional*):\n-            Window size of trend + residual decomposition. If None then we do not do decomposition.\n-        future_values (`torch.Tensor`, *optional*):\n-            Optional future time series values to be used for loss computation.\n-        forecast_context_len (`int`, *optional*):\n-            Optional max context length.\n-        return_forecast_on_context (`bool`, *optional*):\n-            True to return the forecast on the context when available, i.e. after the first input patch.\n-        truncate_negative (`bool`, *optional*):\n-            Truncate to only non-negative values if any of the contexts have non-negative values,\n-            otherwise do nothing.\n-        output_attentions (`bool`, *optional*):\n-            Whether to output the attentions.\n-        output_hidden_states (`bool`, *optional*):\n-            Whether to output the hidden states.\n+            window_size (`int`, *optional*):\n+                Window size of trend + residual decomposition. If None then we do not do decomposition.\n+            future_values (`torch.Tensor`, *optional*):\n+                Optional future time series values to be used for loss computation.\n+            forecast_context_len (`int`, *optional*):\n+                Optional max context length.\n+            return_forecast_on_context (`bool`, *optional*):\n+                True to return the forecast on the context when available, i.e. after the first input patch.\n+            truncate_negative (`bool`, *optional*):\n+                Truncate to only non-negative values if any of the contexts have non-negative values,\n+                otherwise do nothing.\n+            output_attentions (`bool`, *optional*):\n+                Whether to output the attentions.\n+            output_hidden_states (`bool`, *optional*):\n+                Whether to output the hidden states.\n \n         Returns:\n-            A TimesFmOutputForPrediction object or a tuple containing:\n-                - the mean forecast of size (# past_values, # forecast horizon),\n-                - the full forecast (mean + quantiles) of size\n-                    (# past_values,  # forecast horizon, 1 + # quantiles).\n-                - loss: the mean squared error loss + quantile loss if `future_values` is provided.\n+\n+        Example:\n+\n+        ```python\n+        >>> from transformers import TimesFmModelForPrediction\n+\n+        >>> model = TimesFmModelForPrediction.from_pretrained(\"google/timesfm-2.0-500m-pytorch\")\n+\n+        >>> forecast_input = [torch.linspace(0, 20, 100).sin(), torch.linspace(0, 20, 200).sin(), torch.linspace(0, 20, 400).sin()]\n+        >>> frequency_input = torch.tensor([0, 1, 2], dtype=torch.long)\n+\n+        >>> # Generate\n+        >>> with torch.no_grad():\n+        >>>     outputs = model(past_values=forecast_input, freq=frequency_input, return_dict=True)\n+        >>>     point_forecast_conv = outputs.mean_predictions\n+        >>>     quantile_forecast_conv = outputs.full_predictions\n+        ```\n         \"\"\"\n         if forecast_context_len is None:\n             fcontext_len = self.context_len"
        },
        {
            "sha": "e285a4a19e2006373f84399c1805057876c6b5dc",
            "filename": "src/transformers/models/timesfm/modular_timesfm.py",
            "status": "modified",
            "additions": 32,
            "deletions": 26,
            "changes": 58,
            "blob_url": "https://github.com/huggingface/transformers/blob/dc8227827d3e94a2db544415cfcf0f037812b582/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fmodular_timesfm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dc8227827d3e94a2db544415cfcf0f037812b582/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fmodular_timesfm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fmodular_timesfm.py?ref=dc8227827d3e94a2db544415cfcf0f037812b582",
            "patch": "@@ -27,7 +27,6 @@\n from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n from ...processing_utils import Unpack\n from ...utils import (\n-    add_code_sample_docstrings,\n     add_start_docstrings,\n     add_start_docstrings_to_model_forward,\n     can_return_tuple,\n@@ -690,11 +689,6 @@ def _quantile_loss(self, predictions: torch.Tensor, targets: torch.Tensor) -> to\n     @can_return_tuple\n     @add_start_docstrings_to_model_forward(TIMESFM_INPUTS_DOCSTRING)\n     @replace_return_docstrings(output_type=TimesFmOutputForPrediction, config_class=_CONFIG_FOR_DOC)\n-    @add_code_sample_docstrings(\n-        checkpoint=_CHECKPOINT_FOR_DOC,\n-        output_type=TimesFmOutputForPrediction,\n-        config_class=_CONFIG_FOR_DOC,\n-    )\n     def forward(\n         self,\n         past_values: Sequence[torch.Tensor],\n@@ -708,28 +702,40 @@ def forward(\n         output_hidden_states: Optional[bool] = None,\n     ) -> TimesFmOutputForPrediction:\n         r\"\"\"\n-        window_size (`int`, *optional*):\n-            Window size of trend + residual decomposition. If None then we do not do decomposition.\n-        future_values (`torch.Tensor`, *optional*):\n-            Optional future time series values to be used for loss computation.\n-        forecast_context_len (`int`, *optional*):\n-            Optional max context length.\n-        return_forecast_on_context (`bool`, *optional*):\n-            True to return the forecast on the context when available, i.e. after the first input patch.\n-        truncate_negative (`bool`, *optional*):\n-            Truncate to only non-negative values if any of the contexts have non-negative values,\n-            otherwise do nothing.\n-        output_attentions (`bool`, *optional*):\n-            Whether to output the attentions.\n-        output_hidden_states (`bool`, *optional*):\n-            Whether to output the hidden states.\n+            window_size (`int`, *optional*):\n+                Window size of trend + residual decomposition. If None then we do not do decomposition.\n+            future_values (`torch.Tensor`, *optional*):\n+                Optional future time series values to be used for loss computation.\n+            forecast_context_len (`int`, *optional*):\n+                Optional max context length.\n+            return_forecast_on_context (`bool`, *optional*):\n+                True to return the forecast on the context when available, i.e. after the first input patch.\n+            truncate_negative (`bool`, *optional*):\n+                Truncate to only non-negative values if any of the contexts have non-negative values,\n+                otherwise do nothing.\n+            output_attentions (`bool`, *optional*):\n+                Whether to output the attentions.\n+            output_hidden_states (`bool`, *optional*):\n+                Whether to output the hidden states.\n \n         Returns:\n-            A TimesFmOutputForPrediction object or a tuple containing:\n-                - the mean forecast of size (# past_values, # forecast horizon),\n-                - the full forecast (mean + quantiles) of size\n-                    (# past_values,  # forecast horizon, 1 + # quantiles).\n-                - loss: the mean squared error loss + quantile loss if `future_values` is provided.\n+\n+        Example:\n+\n+        ```python\n+        >>> from transformers import TimesFmModelForPrediction\n+\n+        >>> model = TimesFmModelForPrediction.from_pretrained(\"google/timesfm-2.0-500m-pytorch\")\n+\n+        >>> forecast_input = [torch.linspace(0, 20, 100).sin(), torch.linspace(0, 20, 200).sin(), torch.linspace(0, 20, 400).sin()]\n+        >>> frequency_input = torch.tensor([0, 1, 2], dtype=torch.long)\n+\n+        >>> # Generate\n+        >>> with torch.no_grad():\n+        >>>     outputs = model(past_values=forecast_input, freq=frequency_input, return_dict=True)\n+        >>>     point_forecast_conv = outputs.mean_predictions\n+        >>>     quantile_forecast_conv = outputs.full_predictions\n+        ```\n         \"\"\"\n         if forecast_context_len is None:\n             fcontext_len = self.context_len"
        }
    ],
    "stats": {
        "total": 118,
        "additions": 64,
        "deletions": 54
    }
}