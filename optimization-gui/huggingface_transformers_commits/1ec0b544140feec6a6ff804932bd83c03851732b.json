{
    "author": "zucchini-nlp",
    "message": "Rope for Qwen2--5-vl (#41173)\n\nqwen2--5-vl",
    "sha": "1ec0b544140feec6a6ff804932bd83c03851732b",
    "files": [
        {
            "sha": "76fdae589618dfdbf4ce48b1dbc6a1272d8f6a10",
            "filename": "src/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py",
            "status": "modified",
            "additions": 2,
            "deletions": 14,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/1ec0b544140feec6a6ff804932bd83c03851732b/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1ec0b544140feec6a6ff804932bd83c03851732b/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py?ref=1ec0b544140feec6a6ff804932bd83c03851732b",
            "patch": "@@ -41,7 +41,7 @@\n from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update\n from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n from ...processing_utils import Unpack\n-from ...utils import TransformersKwargs, auto_docstring, can_return_tuple, is_torchdynamo_compiling, logging\n+from ...utils import TransformersKwargs, auto_docstring, can_return_tuple, logging\n from ...utils.deprecation import deprecate_kwarg\n from ..qwen2.modeling_qwen2 import Qwen2RMSNorm\n from .configuration_qwen2_5_vl import Qwen2_5_VLConfig, Qwen2_5_VLTextConfig, Qwen2_5_VLVisionConfig\n@@ -1270,19 +1270,7 @@ def forward(\n             inputs_embeds = inputs_embeds.masked_scatter(video_mask, video_embeds)\n \n         if position_ids is None:\n-            # Calculate RoPE index once per generation in the pre-fill stage only.\n-            # When compiling, we can't check tensor values thus we check only input length\n-            # It is safe to assume that `length!=1` means we're in pre-fill because compiled\n-            # models currently cannot do asssisted decoding\n-            prefill_compiled_stage = is_torchdynamo_compiling() and (\n-                (input_ids is not None and input_ids.shape[1] != 1)\n-                or (inputs_embeds is not None and inputs_embeds.shape[1] != 1)\n-            )\n-            prefill_noncompiled_stage = not is_torchdynamo_compiling() and (\n-                (cache_position is not None and cache_position[0] == 0)\n-                or (past_key_values is None or past_key_values.get_seq_length() == 0)\n-            )\n-            if (prefill_compiled_stage or prefill_noncompiled_stage) or self.rope_deltas is None:\n+            if self.rope_deltas is None or cache_position is None or cache_position[0] == 0:\n                 position_ids, rope_deltas = self.get_rope_index(\n                     input_ids,\n                     image_grid_thw,"
        },
        {
            "sha": "9434e7a787ef70cb3dcaa86f40bb0c3f64b538e7",
            "filename": "src/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py",
            "status": "modified",
            "additions": 2,
            "deletions": 14,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/1ec0b544140feec6a6ff804932bd83c03851732b/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1ec0b544140feec6a6ff804932bd83c03851732b/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py?ref=1ec0b544140feec6a6ff804932bd83c03851732b",
            "patch": "@@ -51,7 +51,7 @@\n from ...modeling_layers import GradientCheckpointingLayer\n from ...processing_utils import MultiModalData, ProcessingKwargs, Unpack\n from ...tokenization_utils_base import PreTokenizedInput, TextInput\n-from ...utils import is_torchdynamo_compiling, logging\n+from ...utils import logging\n from ...video_utils import VideoInput\n \n \n@@ -594,19 +594,7 @@ def forward(\n             inputs_embeds = inputs_embeds.masked_scatter(video_mask, video_embeds)\n \n         if position_ids is None:\n-            # Calculate RoPE index once per generation in the pre-fill stage only.\n-            # When compiling, we can't check tensor values thus we check only input length\n-            # It is safe to assume that `length!=1` means we're in pre-fill because compiled\n-            # models currently cannot do asssisted decoding\n-            prefill_compiled_stage = is_torchdynamo_compiling() and (\n-                (input_ids is not None and input_ids.shape[1] != 1)\n-                or (inputs_embeds is not None and inputs_embeds.shape[1] != 1)\n-            )\n-            prefill_noncompiled_stage = not is_torchdynamo_compiling() and (\n-                (cache_position is not None and cache_position[0] == 0)\n-                or (past_key_values is None or past_key_values.get_seq_length() == 0)\n-            )\n-            if (prefill_compiled_stage or prefill_noncompiled_stage) or self.rope_deltas is None:\n+            if self.rope_deltas is None or cache_position is None or cache_position[0] == 0:\n                 position_ids, rope_deltas = self.get_rope_index(\n                     input_ids,\n                     image_grid_thw,"
        }
    ],
    "stats": {
        "total": 32,
        "additions": 4,
        "deletions": 28
    }
}