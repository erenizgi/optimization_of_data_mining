{
    "author": "qgallouedec",
    "message": "Move the warning to the documentation for DataCollatorWithFlattening (#36707)\n\nRemove init warning",
    "sha": "b815fae359fc8d28d6fb1e913ee706674ce60ba4",
    "files": [
        {
            "sha": "77f2a503506959f29b46924dc507bbf5e663c52b",
            "filename": "src/transformers/data/data_collator.py",
            "status": "modified",
            "additions": 7,
            "deletions": 4,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/b815fae359fc8d28d6fb1e913ee706674ce60ba4/src%2Ftransformers%2Fdata%2Fdata_collator.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b815fae359fc8d28d6fb1e913ee706674ce60ba4/src%2Ftransformers%2Fdata%2Fdata_collator.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdata%2Fdata_collator.py?ref=b815fae359fc8d28d6fb1e913ee706674ce60ba4",
            "patch": "@@ -1793,16 +1793,19 @@ class DataCollatorWithFlattening(DefaultDataCollator):\n     - concatate the entire mini batch into single long sequence [1, total_tokens]\n     - uses `separator_id` to separate sequences within the concatenated `labels`, default value is -100\n     - no padding will be added, returns `input_ids`, `labels` and `position_ids`\n+\n+    <Tip warning={true}>\n+\n+    Using `DataCollatorWithFlattening` will flatten the entire mini batch into single long sequence.\n+    Make sure your attention computation is able to handle it!\n+\n+    </Tip>\n     \"\"\"\n \n     def __init__(self, *args, return_position_ids=True, separator_id=-100, **kwargs):\n         super().__init__(*args, **kwargs)\n         self.return_position_ids = return_position_ids\n         self.separator_id = separator_id\n-        warnings.warn(\n-            \"Using `DataCollatorWithFlattening` will flatten the entire mini batch into single long sequence.\"\n-            \"Make sure your attention computation is able to handle it!\"\n-        )\n \n     def __call__(self, features, return_tensors=None, separator_id=None):\n         if return_tensors is None:"
        }
    ],
    "stats": {
        "total": 11,
        "additions": 7,
        "deletions": 4
    }
}