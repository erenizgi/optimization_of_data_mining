{
    "author": "Deep-unlearning",
    "message": "update with more recent tts models (#42328)\n\n* update with more recent tts models\n\n* fix pipelin",
    "sha": "01c51596ec56407eabc7f8d1f021a8aeb679a330",
    "files": [
        {
            "sha": "b285352acefd6c43648daf8247d647b8736d74d7",
            "filename": "docs/source/en/tasks/text-to-speech.md",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/01c51596ec56407eabc7f8d1f021a8aeb679a330/docs%2Fsource%2Fen%2Ftasks%2Ftext-to-speech.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/01c51596ec56407eabc7f8d1f021a8aeb679a330/docs%2Fsource%2Fen%2Ftasks%2Ftext-to-speech.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftasks%2Ftext-to-speech.md?ref=01c51596ec56407eabc7f8d1f021a8aeb679a330",
            "patch": "@@ -19,18 +19,18 @@ rendered properly in your Markdown viewer.\n [[open-in-colab]]\n \n Text-to-speech (TTS) is the task of creating natural-sounding speech from text, where the speech can be generated in multiple\n-languages and for multiple speakers. Several text-to-speech models are currently available in ðŸ¤— Transformers, such as\n+languages and for multiple speakers. Several text-to-speech models are currently available in ðŸ¤— Transformers, such as [Dia](../model_doc/dia), [CSM](../model_doc/csm),\n [Bark](../model_doc/bark), [MMS](../model_doc/mms), [VITS](../model_doc/vits) and [SpeechT5](../model_doc/speecht5).\n \n-You can easily generate audio using the `\"text-to-audio\"` pipeline (or its alias - `\"text-to-speech\"`). Some models, like Bark,\n+You can easily generate audio using the `\"text-to-audio\"` pipeline (or its alias - `\"text-to-speech\"`). Some models, like Dia,\n can also be conditioned to generate non-verbal communications such as laughing, sighing and crying, or even add music.\n-Here's an example of how you would use the `\"text-to-speech\"` pipeline with Bark:\n+Here's an example of how you would use the `\"text-to-speech\"` pipeline with Dia:\n \n ```py\n >>> from transformers import pipeline\n \n->>> pipe = pipeline(\"text-to-speech\", model=\"suno/bark-small\")\n->>> text = \"[clears throat] This is a test ... and I just took a long pause.\"\n+>>> pipe = pipeline(\"text-to-speech\", model=\"nari-labs/Dia-1.6B-0626\")\n+>>> text = \"[S1] (clears throat) Hello! How are you? [S2] I'm good, thanks! How about you?\"\n >>> output = pipe(text)\n ```\n \n@@ -45,7 +45,7 @@ For more examples on what Bark and other pretrained TTS models can do, refer to\n [Audio course](https://huggingface.co/learn/audio-course/chapter6/pre-trained_models).\n \n If you are looking to fine-tune a TTS model, the only text-to-speech models currently available in ðŸ¤— Transformers\n-are [SpeechT5](model_doc/speecht5) and [FastSpeech2Conformer](model_doc/fastspeech2_conformer), though more will be added in the future. SpeechT5 is pre-trained on a combination of speech-to-text and text-to-speech data, allowing it to learn a unified space of hidden representations shared by both text and speech. This means that the same pre-trained model can be fine-tuned for different tasks. Furthermore, SpeechT5 supports multiple speakers through x-vector speaker embeddings.\n+are [SpeechT5](model_doc/speecht5), [FastSpeech2Conformer](model_doc/fastspeech2_conformer), [Dia](model_doc/dia) and [CSM](model_doc/csm) though more will be added in the future. SpeechT5 is pre-trained on a combination of speech-to-text and text-to-speech data, allowing it to learn a unified space of hidden representations shared by both text and speech. This means that the same pre-trained model can be fine-tuned for different tasks. Furthermore, SpeechT5 supports multiple speakers through x-vector speaker embeddings.\n \n The remainder of this guide illustrates how to:\n "
        }
    ],
    "stats": {
        "total": 12,
        "additions": 6,
        "deletions": 6
    }
}