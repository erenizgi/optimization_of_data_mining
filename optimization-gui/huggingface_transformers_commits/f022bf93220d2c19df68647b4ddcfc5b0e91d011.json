{
    "author": "Titus-von-Koeller",
    "message": "Remove trust_remote_code=True tests from bnb quantization tests (MPT now integrated) (#38206)\n\nbnb quant tests: remove obsolete trust_remote_code test\n\nThe MPT model is now natively integrated in Transformers and no longer requires trust_remote_code=True. This removes the failing test_get_keys_to_not_convert_trust_remote_code and related usage, which depended on remote code and caused CI issues due to missing dependencies (e.g., triton_pre_mlir).",
    "sha": "f022bf93220d2c19df68647b4ddcfc5b0e91d011",
    "files": [
        {
            "sha": "8c718d69f4181ce8724e5e91c69a0e8bf219265e",
            "filename": "tests/quantization/bnb/test_mixed_int8.py",
            "status": "modified",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/f022bf93220d2c19df68647b4ddcfc5b0e91d011/tests%2Fquantization%2Fbnb%2Ftest_mixed_int8.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f022bf93220d2c19df68647b4ddcfc5b0e91d011/tests%2Fquantization%2Fbnb%2Ftest_mixed_int8.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fquantization%2Fbnb%2Ftest_mixed_int8.py?ref=f022bf93220d2c19df68647b4ddcfc5b0e91d011",
            "patch": "@@ -139,24 +139,6 @@ def tearDown(self):\n         gc.collect()\n         torch.cuda.empty_cache()\n \n-    def test_get_keys_to_not_convert_trust_remote_code(self):\n-        r\"\"\"\n-        Test the `get_keys_to_not_convert` function with `trust_remote_code` models.\n-        \"\"\"\n-        from accelerate import init_empty_weights\n-\n-        from transformers.integrations.bitsandbytes import get_keys_to_not_convert\n-\n-        model_id = \"mosaicml/mpt-7b\"\n-        config = AutoConfig.from_pretrained(\n-            model_id, trust_remote_code=True, revision=\"ada218f9a93b5f1c6dce48a4cc9ff01fcba431e7\"\n-        )\n-        with init_empty_weights():\n-            model = AutoModelForCausalLM.from_config(\n-                config, trust_remote_code=True, code_revision=\"ada218f9a93b5f1c6dce48a4cc9ff01fcba431e7\"\n-            )\n-        self.assertEqual(get_keys_to_not_convert(model), [\"transformer.wte\"])\n-\n     def test_get_keys_to_not_convert(self):\n         r\"\"\"\n         Test the `get_keys_to_not_convert` function."
        }
    ],
    "stats": {
        "total": 18,
        "additions": 0,
        "deletions": 18
    }
}