{
    "author": "SunMarc",
    "message": "Remove old sagemaker api support  (#41161)\n\n* fix\n\n* fix",
    "sha": "e99dee6470ef276d814138b087cf0541d1fa63ae",
    "files": [
        {
            "sha": "b877217035db93db7c3c0449d6e4e3884d107760",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 21,
            "deletions": 80,
            "changes": 101,
            "blob_url": "https://github.com/huggingface/transformers/blob/e99dee6470ef276d814138b087cf0541d1fa63ae/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e99dee6470ef276d814138b087cf0541d1fa63ae/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=e99dee6470ef276d814138b087cf0541d1fa63ae",
            "patch": "@@ -208,13 +208,8 @@\n \n if is_sagemaker_mp_enabled():\n     import smdistributed.modelparallel.torch as smp\n-    from smdistributed.modelparallel import __version__ as SMP_VERSION\n-\n-    IS_SAGEMAKER_MP_POST_1_10 = version.parse(SMP_VERSION) >= version.parse(\"1.10\")\n \n     from .trainer_pt_utils import smp_forward_backward, smp_forward_only, smp_gather, smp_nested_concat\n-else:\n-    IS_SAGEMAKER_MP_POST_1_10 = False\n \n \n if is_safetensors_available():\n@@ -710,23 +705,13 @@ def __init__(\n             # BF16 + model parallelism in SageMaker: currently not supported, raise an error\n             if args.bf16:\n                 raise ValueError(\"SageMaker Model Parallelism does not support BF16 yet. Please use FP16 instead \")\n-\n-            if IS_SAGEMAKER_MP_POST_1_10:\n-                # When there's mismatch between SMP config and trainer argument, use SMP config as truth\n-                if args.fp16 != smp.state.cfg.fp16:\n-                    logger.warning(\n-                        f\"FP16 provided in SM_HP_MP_PARAMETERS is {smp.state.cfg.fp16}, \"\n-                        f\"but FP16 provided in trainer argument is {args.fp16}, \"\n-                        f\"setting to {smp.state.cfg.fp16}\"\n-                    )\n-                    args.fp16 = smp.state.cfg.fp16\n-            else:\n-                # smp < 1.10 does not support fp16 in trainer.\n-                if hasattr(smp.state.cfg, \"fp16\"):\n-                    logger.warning(\n-                        f\"FP16 provided in SM_HP_MP_PARAMETERS is {smp.state.cfg.fp16}, \"\n-                        \"but SageMaker Model Parallelism < 1.10 does not support FP16 in trainer.\"\n-                    )\n+            if args.fp16 != smp.state.cfg.fp16:\n+                logger.warning(\n+                    f\"FP16 provided in SM_HP_MP_PARAMETERS is {smp.state.cfg.fp16}, \"\n+                    f\"but FP16 provided in trainer argument is {args.fp16}, \"\n+                    f\"setting to {smp.state.cfg.fp16}\"\n+                )\n+                args.fp16 = smp.state.cfg.fp16\n         if args.fp16 and args.device == torch.device(\"cpu\") and not is_torch_greater_or_equal_than_2_3:\n             raise ValueError(\"Tried to use `fp16` but it is not supported on cpu. You need to have torch>=2.3\")\n \n@@ -1230,8 +1215,8 @@ def create_optimizer_and_scheduler(self, num_training_steps: int):\n         `create_scheduler`) in a subclass.\n         \"\"\"\n         self.create_optimizer()\n-        if IS_SAGEMAKER_MP_POST_1_10 and smp.state.cfg.fp16:\n-            # If smp >= 1.10 and fp16 is enabled, we unwrap the optimizer\n+        if is_sagemaker_mp_enabled() and smp.state.cfg.fp16:\n+            # If fp16 is enabled, we unwrap the optimizer\n             optimizer = self.optimizer.optimizer\n         else:\n             optimizer = self.optimizer\n@@ -2902,26 +2887,9 @@ def _load_from_checkpoint(self, resume_from_checkpoint, model=None):\n         if os.path.isfile(weights_file) or os.path.isfile(safe_weights_file) or is_fsdp_ckpt:\n             # If the model is on the GPU, it still works!\n             if is_sagemaker_mp_enabled():\n-                if os.path.isfile(os.path.join(resume_from_checkpoint, \"user_content.pt\")):\n-                    # If the 'user_content.pt' file exists, load with the new smp api.\n-                    # Checkpoint must have been saved with the new smp api.\n-                    smp.resume_from_checkpoint(\n-                        path=resume_from_checkpoint, tag=WEIGHTS_NAME, partial=False, load_optimizer=False\n-                    )\n-                else:\n-                    # If the 'user_content.pt' file does NOT exist, load with the old smp api.\n-                    # Checkpoint must have been saved with the old smp api.\n-                    if hasattr(self.args, \"fp16\") and self.args.fp16 is True:\n-                        logger.warning(\n-                            \"Enabling FP16 and loading from smp < 1.10 checkpoint together is not supported.\"\n-                        )\n-                    check_torch_load_is_safe()\n-                    state_dict = torch.load(weights_file, map_location=\"cpu\", weights_only=True)\n-                    # Required for smp to not auto-translate state_dict from hf to smp (is already smp).\n-                    state_dict[\"_smp_is_partial\"] = False\n-                    load_result = model.load_state_dict(state_dict, strict=True)\n-                    # release memory\n-                    del state_dict\n+                smp.resume_from_checkpoint(\n+                    path=resume_from_checkpoint, tag=WEIGHTS_NAME, partial=False, load_optimizer=False\n+                )\n             elif self.is_fsdp_enabled:\n                 load_fsdp_model(\n                     self.accelerator.state.fsdp_plugin,\n@@ -3015,26 +2983,12 @@ def _load_best_model(self):\n         ):\n             has_been_loaded = True\n             if is_sagemaker_mp_enabled():\n-                if os.path.isfile(os.path.join(self.state.best_model_checkpoint, \"user_content.pt\")):\n-                    # If the 'user_content.pt' file exists, load with the new smp api.\n-                    # Checkpoint must have been saved with the new smp api.\n-                    smp.resume_from_checkpoint(\n-                        path=self.state.best_model_checkpoint,\n-                        tag=WEIGHTS_NAME,\n-                        partial=False,\n-                        load_optimizer=False,\n-                    )\n-                else:\n-                    # If the 'user_content.pt' file does NOT exist, load with the old smp api.\n-                    # Checkpoint must have been saved with the old smp api.\n-                    if self.args.save_safetensors and os.path.isfile(best_safe_model_path):\n-                        state_dict = safetensors.torch.load_file(best_safe_model_path, device=\"cpu\")\n-                    else:\n-                        check_torch_load_is_safe()\n-                        state_dict = torch.load(best_model_path, map_location=\"cpu\", weights_only=True)\n-\n-                    state_dict[\"_smp_is_partial\"] = False\n-                    load_result = model.load_state_dict(state_dict, strict=True)\n+                smp.resume_from_checkpoint(\n+                    path=self.state.best_model_checkpoint,\n+                    tag=WEIGHTS_NAME,\n+                    partial=False,\n+                    load_optimizer=False,\n+                )\n             else:\n                 if _is_peft_model(model):\n                     # If train a model using PEFT & LoRA, assume that adapter have been saved properly.\n@@ -3511,20 +3465,9 @@ def _load_optimizer_and_scheduler(self, checkpoint):\n                 self.lr_scheduler.load_state_dict(lr_scheduler_state)\n             else:\n                 if is_sagemaker_mp_enabled():\n-                    if os.path.isfile(os.path.join(checkpoint, \"user_content.pt\")):\n-                        # Optimizer checkpoint was saved with smp >= 1.10\n-                        def opt_load_hook(mod, opt):\n-                            opt.load_state_dict(smp.load(os.path.join(checkpoint, OPTIMIZER_NAME), partial=True))\n \n-                    else:\n-                        # Optimizer checkpoint was saved with smp < 1.10\n-                        def opt_load_hook(mod, opt):\n-                            if IS_SAGEMAKER_MP_POST_1_10:\n-                                opt.load_state_dict(\n-                                    smp.load(os.path.join(checkpoint, OPTIMIZER_NAME), partial=True, back_compat=True)\n-                                )\n-                            else:\n-                                opt.load_state_dict(smp.load(os.path.join(checkpoint, OPTIMIZER_NAME), partial=True))\n+                    def opt_load_hook(mod, opt):\n+                        opt.load_state_dict(smp.load(os.path.join(checkpoint, OPTIMIZER_NAME), partial=True))\n \n                     self.model_wrapped.register_post_step_hook(opt_load_hook)\n                 else:\n@@ -4138,9 +4081,7 @@ def save_model(self, output_dir: Optional[str] = None, _internal_call: bool = Fa\n             state_dict = self.model_wrapped.state_dict()\n             if self.args.should_save:\n                 self._save(output_dir, state_dict=state_dict)\n-            if IS_SAGEMAKER_MP_POST_1_10:\n-                # 'user_content.pt' indicates model state_dict saved with smp >= 1.10\n-                Path(os.path.join(output_dir, \"user_content.pt\")).touch()\n+            Path(os.path.join(output_dir, \"user_content.pt\")).touch()\n         # We are in N-D parallelism if we have parallelism_config set, so we check accelerate if we're on a to_save rank\n         elif getattr(self.accelerator, \"parallelism_config\", None) is not None:\n             if self.accelerator.should_save_model:"
        }
    ],
    "stats": {
        "total": 101,
        "additions": 21,
        "deletions": 80
    }
}