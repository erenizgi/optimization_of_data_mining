{
    "author": "yonigozlan",
    "message": "Remove tied weight keys Sam2Video (#42840)\n\n* Fix tied weight keys sam2 video\n\n* fix edgetam_video\n\n* fix modular sam3_tracker_video",
    "sha": "171e079edc52bc91c6f485fed2d54a77b9798683",
    "files": [
        {
            "sha": "a0e4f9ac72005e2f99c4e7e6fe34601d2affe005",
            "filename": "src/transformers/models/edgetam_video/modeling_edgetam_video.py",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/171e079edc52bc91c6f485fed2d54a77b9798683/src%2Ftransformers%2Fmodels%2Fedgetam_video%2Fmodeling_edgetam_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/171e079edc52bc91c6f485fed2d54a77b9798683/src%2Ftransformers%2Fmodels%2Fedgetam_video%2Fmodeling_edgetam_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fedgetam_video%2Fmodeling_edgetam_video.py?ref=171e079edc52bc91c6f485fed2d54a77b9798683",
            "patch": "@@ -1976,11 +1976,6 @@ class EdgeTamVideoModel(EdgeTamVideoPreTrainedModel):\n     input_modalities = (\"video\", \"text\")\n     _can_record_outputs = {\"mask_decoder_attentions\": OutputRecorder(EdgeTamVideoTwoWayAttentionBlock, index=2)}\n     _keys_to_ignore_on_load_unexpected = []\n-    _tied_weights_keys = {\n-        \"prompt_encoder.shared_embedding.positional_embedding\": \"shared_image_embedding.positional_embedding\"\n-    }\n-    # need to be ignored, as it's a buffer and will not be correctly detected as tied weight\n-    _keys_to_ignore_on_load_missing = [\"prompt_encoder.shared_embedding.positional_embedding\"]\n \n     def __init__(self, config: EdgeTamVideoConfig):\n         super().__init__(config)"
        },
        {
            "sha": "f6c9295b400bcd9bfd188b45fe8897c6a9521e1d",
            "filename": "src/transformers/models/edgetam_video/modular_edgetam_video.py",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/171e079edc52bc91c6f485fed2d54a77b9798683/src%2Ftransformers%2Fmodels%2Fedgetam_video%2Fmodular_edgetam_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/171e079edc52bc91c6f485fed2d54a77b9798683/src%2Ftransformers%2Fmodels%2Fedgetam_video%2Fmodular_edgetam_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fedgetam_video%2Fmodular_edgetam_video.py?ref=171e079edc52bc91c6f485fed2d54a77b9798683",
            "patch": "@@ -1040,11 +1040,6 @@ class EdgeTamVideoSegmentationOutput(Sam2VideoSegmentationOutput):\n \n @auto_docstring\n class EdgeTamVideoModel(Sam2VideoModel):\n-    _tied_weights_keys = {\n-        \"prompt_encoder.shared_embedding.positional_embedding\": \"shared_image_embedding.positional_embedding\"\n-    }\n-    # need to be ignored, as it's a buffer and will not be correctly detected as tied weight\n-    _keys_to_ignore_on_load_missing = [\"prompt_encoder.shared_embedding.positional_embedding\"]\n     _keys_to_ignore_on_load_unexpected = []\n     _can_record_outputs = {\"mask_decoder_attentions\": OutputRecorder(EdgeTamVideoTwoWayAttentionBlock, index=2)}\n "
        },
        {
            "sha": "f9d85c217befa649bf662a8686230bdd6e799657",
            "filename": "src/transformers/models/sam2_video/modeling_sam2_video.py",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/171e079edc52bc91c6f485fed2d54a77b9798683/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodeling_sam2_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/171e079edc52bc91c6f485fed2d54a77b9798683/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodeling_sam2_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodeling_sam2_video.py?ref=171e079edc52bc91c6f485fed2d54a77b9798683",
            "patch": "@@ -1559,11 +1559,6 @@ class Sam2VideoModel(Sam2VideoPreTrainedModel):\n     input_modalities = (\"video\", \"text\")\n     _can_record_outputs = {\"mask_decoder_attentions\": OutputRecorder(Sam2VideoTwoWayAttentionBlock, index=2)}\n     _keys_to_ignore_on_load_unexpected = []\n-    _tied_weights_keys = {\n-        \"prompt_encoder.shared_embedding.positional_embedding\": \"shared_image_embedding.positional_embedding\"\n-    }\n-    # need to be ignored, as it's a buffer and will not be correctly detected as tied weight\n-    _keys_to_ignore_on_load_missing = [\"prompt_encoder.shared_embedding.positional_embedding\"]\n \n     def __init__(self, config: Sam2VideoConfig):\n         super().__init__(config)"
        },
        {
            "sha": "ea2e5d7cadb1fdaac43b8c1ba5688f3116bf7c0c",
            "filename": "src/transformers/models/sam2_video/modular_sam2_video.py",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/171e079edc52bc91c6f485fed2d54a77b9798683/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodular_sam2_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/171e079edc52bc91c6f485fed2d54a77b9798683/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodular_sam2_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodular_sam2_video.py?ref=171e079edc52bc91c6f485fed2d54a77b9798683",
            "patch": "@@ -1446,11 +1446,6 @@ def get_1d_sine_pe(pos_inds, dim, temperature=10000):\n @auto_docstring\n class Sam2VideoModel(Sam2Model):\n     input_modalities = (\"video\", \"text\")\n-    _tied_weights_keys = {\n-        \"prompt_encoder.shared_embedding.positional_embedding\": \"shared_image_embedding.positional_embedding\"\n-    }\n-    # need to be ignored, as it's a buffer and will not be correctly detected as tied weight\n-    _keys_to_ignore_on_load_missing = [\"prompt_encoder.shared_embedding.positional_embedding\"]\n     _keys_to_ignore_on_load_unexpected = []\n     _can_record_outputs = {\"mask_decoder_attentions\": OutputRecorder(Sam2VideoTwoWayAttentionBlock, index=2)}\n "
        },
        {
            "sha": "5bde67111e617ca75c4b18a9b633b5561c434e8b",
            "filename": "src/transformers/models/sam3_tracker_video/modeling_sam3_tracker_video.py",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/171e079edc52bc91c6f485fed2d54a77b9798683/src%2Ftransformers%2Fmodels%2Fsam3_tracker_video%2Fmodeling_sam3_tracker_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/171e079edc52bc91c6f485fed2d54a77b9798683/src%2Ftransformers%2Fmodels%2Fsam3_tracker_video%2Fmodeling_sam3_tracker_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam3_tracker_video%2Fmodeling_sam3_tracker_video.py?ref=171e079edc52bc91c6f485fed2d54a77b9798683",
            "patch": "@@ -1567,8 +1567,6 @@ class Sam3TrackerVideoModel(Sam3TrackerVideoPreTrainedModel):\n     input_modalities = (\"video\", \"text\")\n     _can_record_outputs = {\"mask_decoder_attentions\": OutputRecorder(Sam3TrackerVideoTwoWayAttentionBlock, index=2)}\n     _keys_to_ignore_on_load_unexpected = [r\"^detector_model.\"]\n-    _tied_weights_keys = {}\n-    _keys_to_ignore_on_load_missing = []\n     _checkpoint_conversion_mapping = {\n         r\"tracker_model.(.+)\": r\"\\1\",  # the regex allows to remove the prefix, and add it back in revert mode\n         \"detector_model.vision_encoder.backbone.\": \"vision_encoder.backbone.\","
        },
        {
            "sha": "31608f91c784c3a1b4703449cf4ffb1a6103eaae",
            "filename": "src/transformers/models/sam3_tracker_video/modular_sam3_tracker_video.py",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/171e079edc52bc91c6f485fed2d54a77b9798683/src%2Ftransformers%2Fmodels%2Fsam3_tracker_video%2Fmodular_sam3_tracker_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/171e079edc52bc91c6f485fed2d54a77b9798683/src%2Ftransformers%2Fmodels%2Fsam3_tracker_video%2Fmodular_sam3_tracker_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam3_tracker_video%2Fmodular_sam3_tracker_video.py?ref=171e079edc52bc91c6f485fed2d54a77b9798683",
            "patch": "@@ -486,8 +486,6 @@ class Sam3TrackerVideoModel(Sam2VideoModel):\n         \"tracker_neck.\": \"vision_encoder.neck.\",\n     }\n     _keys_to_ignore_on_load_unexpected = [r\"^detector_model.\"]\n-    _tied_weights_keys = {}\n-    _keys_to_ignore_on_load_missing = []\n \n     def __init__(self, config: Sam3TrackerVideoConfig, remove_vision_encoder: bool = False):\n         r\"\"\""
        }
    ],
    "stats": {
        "total": 24,
        "additions": 0,
        "deletions": 24
    }
}