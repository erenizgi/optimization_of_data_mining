{
    "author": "ArthurZucker",
    "message": "Remove `benchmark.py` after #34275",
    "sha": "a9bd1e6284429bab46bdf73620f90a0a22bcf75e",
    "files": [
        {
            "sha": "2c6d1967137185a38d47c6f424beb91a93d7cdb7",
            "filename": "benchmark.py",
            "status": "removed",
            "additions": 0,
            "deletions": 132,
            "changes": 132,
            "blob_url": "https://github.com/huggingface/transformers/blob/e0646f3dce229a2552c56746eac618baf8210efa/benchmark.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e0646f3dce229a2552c56746eac618baf8210efa/benchmark.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/benchmark.py?ref=e0646f3dce229a2552c56746eac618baf8210efa",
            "patch": "@@ -1,132 +0,0 @@\n-import os\n-import time\n-\n-import cv2\n-import av\n-import numpy as np \n-from numba import jit, cuda\n-from decord import VideoReader, cpu, gpu\n-\n-import torch\n-from torchvision import io\n-\n-\n-video_dir = \"/raid/raushan/temp_dir/\"\n-NUM_FRAMES = 32\n-\n-\n-# @jit(nopython=True, target_backend='cuda') # <-- If you have a cuda GPU\n-def process_video_cv2(video: cv2.VideoCapture, indices: np.array, length: int):\n-    index = 0\n-    frames = []\n-    while video.isOpened():\n-        success, frame = video.read()\n-        if index in indices:\n-            # Channel 0:B 1:G 2:R\n-            height, width, channel = frame.shape\n-            frames.append(frame[0:height, 0:width, 0:channel])\n-        if success:\n-            index += 1\n-        if index >= length:\n-            break\n-\n-    video.release()\n-    return frames\n-\n-\n-def read_video_opencv(video_path, num_frames=NUM_FRAMES):\n-    '''\n-    Decode the video with open-cv decoder.\n-\n-    Args:\n-        video_path (str): Path to the video file.\n-        num_frames (int): Number of frames to sample uniformly. Defaults to NUM_FRAMES\n-\n-    Returns:\n-        np.ndarray: np array of decoded frames of shape (num_frames, height, width, 3).\n-    '''\n-    video = cv2.VideoCapture(video_path)\n-    fps = int(video.get(cv2.CAP_PROP_FPS))\n-    total_num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n-    indices = np.arange(0, total_num_frames, total_num_frames / num_frames).astype(int)\n-    frames = process_video_cv2(video, indices, total_num_frames)\n-    return np.stack(frames)\n-\n-\n-\n-def read_video_decord(video_path, num_frames=NUM_FRAMES):\n-    '''\n-    Decode the video with Decord decoder.\n-\n-    Args:\n-        video_path (str): Path to the video file.\n-        num_frames (int): Number of frames to sample uniformly. Defaults to NUM_FRAMES\n-\n-    Returns:\n-        np.ndarray: np array of decoded frames of shape (num_frames, height, width, 3).\n-    '''\n-    vr = VideoReader(uri=video_path, ctx=cpu(0)) # you need to install from source to use gpu ctx\n-    indices = np.arange(0, len(vr), len(vr) / num_frames).astype(int)\n-    frames = vr.get_batch(indices).asnumpy()\n-    return frames\n-\n-\n-def read_video_pyav(video_path, num_frames=NUM_FRAMES):\n-    '''\n-    Decode the video with PyAV decoder.\n-\n-    Args:\n-        video_path (str): Path to the video file.\n-        num_frames (int): Number of frames to sample uniformly. Defaults to NUM_FRAMES\n-\n-    Returns:\n-        np.ndarray: np array of decoded frames of shape (num_frames, height, width, 3).\n-    '''\n-    container = av.open(video_path)\n-\n-    # sample uniformly \"num_frames\" frames from the video\n-    total_frames = container.streams.video[0].frames\n-    indices = np.arange(0, total_frames, total_frames / num_frames).astype(int)\n-\n-    frames = []\n-    container.seek(0)\n-    start_index = indices[0]\n-    end_index = indices[-1]\n-    for i, frame in enumerate(container.decode(video=0)):\n-        if i > end_index:\n-            break\n-        if i >= start_index and i in indices:\n-            frames.append(frame)\n-    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n-\n-\n-\n-def read_video_torchvision(video_path, num_frames=NUM_FRAMES):\n-    video, _, info = io.read_video(\n-        video_path,\n-        start_pts=0.0,\n-        end_pts=None,\n-        pts_unit=\"sec\",\n-        output_format=\"TCHW\",\n-    )\n-\n-    idx = torch.linspace(0, video.size(0) - 1, num_frames, dtype=torch.int64)\n-    return video[idx]\n-\n-\n-decoders = {\"decord\": read_video_decord, \"opencv\": read_video_opencv, \"av\": read_video_pyav, \"torchvision\": read_video_torchvision}\n-for name, fn in decoders.items():\n-    start = time.perf_counter()\n-    for video_file in os.listdir(video_dir):\n-        path = f\"{video_dir}/{video_file}\"\n-        output = fn(path)\n-\n-    end = time.perf_counter()\n-    print(f\"Time taken for {name}: {(end-start):.04f} sec\")\n-\n-\n-# Time taken for decord: 475.2979 sec\n-# Time taken for opencv: 614.6062 sec\n-# Time taken for av: 1067.0860 sec\n-# Time taken for torchvision: 1924.0433 sec\n-"
        }
    ],
    "stats": {
        "total": 132,
        "additions": 0,
        "deletions": 132
    }
}