{
    "author": "Rocketknight1",
    "message": "Return attention mask in ASR pipeline to avoid warnings (#33509)\n\nreturn attention mask in ASR pipeline",
    "sha": "8efc06ee1863bd6e34e8adb7b10901da87c66818",
    "files": [
        {
            "sha": "4301982f1e901c4cee5a99438fcedb323423b1fe",
            "filename": "src/transformers/pipelines/automatic_speech_recognition.py",
            "status": "modified",
            "additions": 6,
            "deletions": 2,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/8efc06ee1863bd6e34e8adb7b10901da87c66818/src%2Ftransformers%2Fpipelines%2Fautomatic_speech_recognition.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8efc06ee1863bd6e34e8adb7b10901da87c66818/src%2Ftransformers%2Fpipelines%2Fautomatic_speech_recognition.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fautomatic_speech_recognition.py?ref=8efc06ee1863bd6e34e8adb7b10901da87c66818",
            "patch": "@@ -440,6 +440,7 @@ def preprocess(self, inputs, chunk_length_s=0, stride_length_s=None):\n                     truncation=False,\n                     padding=\"longest\",\n                     return_tensors=\"pt\",\n+                    return_attention_mask=True,\n                 )\n             else:\n                 if self.type == \"seq2seq_whisper\" and stride is None:\n@@ -448,13 +449,16 @@ def preprocess(self, inputs, chunk_length_s=0, stride_length_s=None):\n                         sampling_rate=self.feature_extractor.sampling_rate,\n                         return_tensors=\"pt\",\n                         return_token_timestamps=True,\n+                        return_attention_mask=True,\n                     )\n                     extra[\"num_frames\"] = processed.pop(\"num_frames\")\n                 else:\n                     processed = self.feature_extractor(\n-                        inputs, sampling_rate=self.feature_extractor.sampling_rate, return_tensors=\"pt\"\n+                        inputs,\n+                        sampling_rate=self.feature_extractor.sampling_rate,\n+                        return_tensors=\"pt\",\n+                        return_attention_mask=True,\n                     )\n-\n             if self.torch_dtype is not None:\n                 processed = processed.to(dtype=self.torch_dtype)\n             if stride is not None:"
        }
    ],
    "stats": {
        "total": 8,
        "additions": 6,
        "deletions": 2
    }
}