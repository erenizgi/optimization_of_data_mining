{
    "author": "eaidova",
    "message": "provide trust_remote_code for search feat extractor in model config (#34036)",
    "sha": "211f1d93db2bc1a2f5bbbe48aa7f1ab99184973e",
    "files": [
        {
            "sha": "98d679ef09c75b4c7f6f1b89596fa9209b392faa",
            "filename": "src/transformers/models/auto/feature_extraction_auto.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/211f1d93db2bc1a2f5bbbe48aa7f1ab99184973e/src%2Ftransformers%2Fmodels%2Fauto%2Ffeature_extraction_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/211f1d93db2bc1a2f5bbbe48aa7f1ab99184973e/src%2Ftransformers%2Fmodels%2Fauto%2Ffeature_extraction_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Ffeature_extraction_auto.py?ref=211f1d93db2bc1a2f5bbbe48aa7f1ab99184973e",
            "patch": "@@ -351,7 +351,9 @@ def from_pretrained(cls, pretrained_model_name_or_path, **kwargs):\n         # If we don't find the feature extractor class in the feature extractor config, let's try the model config.\n         if feature_extractor_class is None and feature_extractor_auto_map is None:\n             if not isinstance(config, PretrainedConfig):\n-                config = AutoConfig.from_pretrained(pretrained_model_name_or_path, **kwargs)\n+                config = AutoConfig.from_pretrained(\n+                    pretrained_model_name_or_path, trust_remote_code=trust_remote_code, **kwargs\n+                )\n             # It could be in `config.feature_extractor_type``\n             feature_extractor_class = getattr(config, \"feature_extractor_type\", None)\n             if hasattr(config, \"auto_map\") and \"AutoFeatureExtractor\" in config.auto_map:"
        },
        {
            "sha": "ef40798484ef4170ba4b9b54384da60ba80321ff",
            "filename": "src/transformers/models/auto/image_processing_auto.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/211f1d93db2bc1a2f5bbbe48aa7f1ab99184973e/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/211f1d93db2bc1a2f5bbbe48aa7f1ab99184973e/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py?ref=211f1d93db2bc1a2f5bbbe48aa7f1ab99184973e",
            "patch": "@@ -431,7 +431,9 @@ def from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs):\n         # If we don't find the image processor class in the image processor config, let's try the model config.\n         if image_processor_class is None and image_processor_auto_map is None:\n             if not isinstance(config, PretrainedConfig):\n-                config = AutoConfig.from_pretrained(pretrained_model_name_or_path, **kwargs)\n+                config = AutoConfig.from_pretrained(\n+                    pretrained_model_name_or_path, trust_remote_code=trust_remote_code, **kwargs\n+                )\n             # It could be in `config.image_processor_type``\n             image_processor_class = getattr(config, \"image_processor_type\", None)\n             if hasattr(config, \"auto_map\") and \"AutoImageProcessor\" in config.auto_map:"
        }
    ],
    "stats": {
        "total": 8,
        "additions": 6,
        "deletions": 2
    }
}