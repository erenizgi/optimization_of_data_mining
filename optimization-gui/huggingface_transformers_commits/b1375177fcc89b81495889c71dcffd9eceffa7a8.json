{
    "author": "ydshieh",
    "message": "add job links to new model failure report (#37973)\n\n* update for job link\n\n* stye\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "b1375177fcc89b81495889c71dcffd9eceffa7a8",
    "files": [
        {
            "sha": "399c792c9de8754cb182ec4918eefb0096352100",
            "filename": "utils/notification_service.py",
            "status": "modified",
            "additions": 22,
            "deletions": 0,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/b1375177fcc89b81495889c71dcffd9eceffa7a8/utils%2Fnotification_service.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b1375177fcc89b81495889c71dcffd9eceffa7a8/utils%2Fnotification_service.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fnotification_service.py?ref=b1375177fcc89b81495889c71dcffd9eceffa7a8",
            "patch": "@@ -1260,6 +1260,28 @@ def pop_default(l: list[Any], i: int, default: Any) -> Any:\n                 token=os.environ.get(\"TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN\", None),\n             )\n \n+        # Let's create a file contain job --> job link\n+        model_job_links = {}\n+        sorted_dict = sorted(model_results.items(), key=lambda t: t[0])\n+        for job, job_result in sorted_dict:\n+            model_name = job\n+            if model_name.startswith(\"models_\"):\n+                model_name = model_name[len(\"models_\") :]\n+            model_job_links[model_name] = job_result[\"job_link\"]\n+\n+        with open(f\"ci_results_{job_name}/model_job_links.json\", \"w\", encoding=\"UTF-8\") as fp:\n+            json.dump(model_job_links, fp, indent=4, ensure_ascii=False)\n+\n+        # upload results to Hub dataset (only for the scheduled daily CI run on `main`)\n+        if is_scheduled_ci_run:\n+            api.upload_file(\n+                path_or_fileobj=f\"ci_results_{job_name}/model_job_links.json\",\n+                path_in_repo=f\"{datetime.datetime.today().strftime('%Y-%m-%d')}/ci_results_{job_name}/model_job_links.json\",\n+                repo_id=\"hf-internal-testing/transformers_daily_ci\",\n+                repo_type=\"dataset\",\n+                token=os.environ.get(\"TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN\", None),\n+            )\n+\n     # Must have the same keys as in `additional_results`.\n     # The values are used as the file names where to save the corresponding CI job results.\n     test_to_result_name = {"
        },
        {
            "sha": "bba03b4bd1fa03b465dac38934b99898d77d7810",
            "filename": "utils/process_bad_commit_report.py",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/b1375177fcc89b81495889c71dcffd9eceffa7a8/utils%2Fprocess_bad_commit_report.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b1375177fcc89b81495889c71dcffd9eceffa7a8/utils%2Fprocess_bad_commit_report.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fprocess_bad_commit_report.py?ref=b1375177fcc89b81495889c71dcffd9eceffa7a8",
            "patch": "@@ -27,6 +27,9 @@\n     with open(\"new_model_failures_with_bad_commit.json\") as fp:\n         data = json.load(fp)\n \n+    with open(\"ci_results_run_models_gpu/model_job_links.json\") as fp:\n+        model_job_links = json.load(fp)\n+\n     # TODO: extend\n     team_members = [\n         \"ydshieh\",\n@@ -62,7 +65,12 @@\n     for author, _data in new_data_full.items():\n         for model, model_result in _data.items():\n             for device, failed_tests in model_result.items():\n+                # prepare job_link and add it to each entry of new failed test information.\n+                # need to change from `single-gpu` to `single` and same for `multi-gpu` to match `job_link`.\n+                job_link = model_job_links[model][device.replace(\"-gpu\", \"\")]\n                 failed_tests = [x for x in failed_tests if x[\"author\"] == author or x[\"merged_by\"] == author]\n+                for x in failed_tests:\n+                    x.update({\"job_link\": job_link})\n                 model_result[device] = failed_tests\n             _data[model] = {k: v for k, v in model_result.items() if len(v) > 0}\n         new_data_full[author] = {k: v for k, v in _data.items() if len(v) > 0}"
        }
    ],
    "stats": {
        "total": 30,
        "additions": 30,
        "deletions": 0
    }
}