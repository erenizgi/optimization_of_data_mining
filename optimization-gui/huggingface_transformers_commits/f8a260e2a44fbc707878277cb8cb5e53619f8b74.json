{
    "author": "Rocketknight1",
    "message": "Sync QuestionAnsweringPipeline (#34039)\n\n* Sync QuestionAnsweringPipeline\r\n\r\n* typo fixes\r\n\r\n* Update deprecation warnings",
    "sha": "f8a260e2a44fbc707878277cb8cb5e53619f8b74",
    "files": [
        {
            "sha": "6039e5ad1ee9891adc8d13b97ac72712d5505b0a",
            "filename": "src/transformers/pipelines/question_answering.py",
            "status": "modified",
            "additions": 16,
            "deletions": 11,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/f8a260e2a44fbc707878277cb8cb5e53619f8b74/src%2Ftransformers%2Fpipelines%2Fquestion_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f8a260e2a44fbc707878277cb8cb5e53619f8b74/src%2Ftransformers%2Fpipelines%2Fquestion_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fquestion_answering.py?ref=f8a260e2a44fbc707878277cb8cb5e53619f8b74",
            "patch": "@@ -183,8 +183,16 @@ def __call__(self, *args, **kwargs):\n         # Generic compatibility with sklearn and Keras\n         # Batched data\n         elif \"X\" in kwargs:\n+            warnings.warn(\n+                \"Passing the `X` argument to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\",\n+                FutureWarning,\n+            )\n             inputs = kwargs[\"X\"]\n         elif \"data\" in kwargs:\n+            warnings.warn(\n+                \"Passing the `data` argument to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\",\n+                FutureWarning,\n+            )\n             inputs = kwargs[\"data\"]\n         elif \"question\" in kwargs and \"context\" in kwargs:\n             if isinstance(kwargs[\"question\"], list) and isinstance(kwargs[\"context\"], str):\n@@ -345,22 +353,14 @@ def __call__(self, *args, **kwargs):\n         Answer the question(s) given as inputs by using the context(s).\n \n         Args:\n-            args ([`SquadExample`] or a list of [`SquadExample`]):\n-                One or several [`SquadExample`] containing the question and context.\n-            X ([`SquadExample`] or a list of [`SquadExample`], *optional*):\n-                One or several [`SquadExample`] containing the question and context (will be treated the same way as if\n-                passed as the first positional argument).\n-            data ([`SquadExample`] or a list of [`SquadExample`], *optional*):\n-                One or several [`SquadExample`] containing the question and context (will be treated the same way as if\n-                passed as the first positional argument).\n             question (`str` or `List[str]`):\n                 One or several question(s) (must be used in conjunction with the `context` argument).\n             context (`str` or `List[str]`):\n                 One or several context(s) associated with the question(s) (must be used in conjunction with the\n                 `question` argument).\n-            topk (`int`, *optional*, defaults to 1):\n+            top_k (`int`, *optional*, defaults to 1):\n                 The number of answers to return (will be chosen by order of likelihood). Note that we return less than\n-                topk answers if there are not enough options available within the context.\n+                top_k answers if there are not enough options available within the context.\n             doc_stride (`int`, *optional*, defaults to 128):\n                 If the context is too long to fit with the question for the model, it will be split in several chunks\n                 with some overlap. This argument controls the size of that overlap.\n@@ -374,7 +374,7 @@ def __call__(self, *args, **kwargs):\n             handle_impossible_answer (`bool`, *optional*, defaults to `False`):\n                 Whether or not we accept impossible as an answer.\n             align_to_words (`bool`, *optional*, defaults to `True`):\n-                Attempts to align the answer to real words. Improves quality on space separated langages. Might hurt on\n+                Attempts to align the answer to real words. Improves quality on space separated languages. Might hurt on\n                 non-space-separated languages (like Japanese or Chinese)\n \n         Return:\n@@ -387,6 +387,11 @@ def __call__(self, *args, **kwargs):\n         \"\"\"\n \n         # Convert inputs to features\n+        if args:\n+            warnings.warn(\n+                \"Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\",\n+                FutureWarning,\n+            )\n \n         examples = self._args_parser(*args, **kwargs)\n         if isinstance(examples, (list, tuple)) and len(examples) == 1:"
        },
        {
            "sha": "d06f88d1f0884482aa070424382ee434e30a83d6",
            "filename": "tests/pipelines/test_pipelines_question_answering.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/f8a260e2a44fbc707878277cb8cb5e53619f8b74/tests%2Fpipelines%2Ftest_pipelines_question_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f8a260e2a44fbc707878277cb8cb5e53619f8b74/tests%2Fpipelines%2Ftest_pipelines_question_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_question_answering.py?ref=f8a260e2a44fbc707878277cb8cb5e53619f8b74",
            "patch": "@@ -14,6 +14,8 @@\n \n import unittest\n \n+from huggingface_hub import QuestionAnsweringOutputElement\n+\n from transformers import (\n     MODEL_FOR_QUESTION_ANSWERING_MAPPING,\n     TF_MODEL_FOR_QUESTION_ANSWERING_MAPPING,\n@@ -23,6 +25,7 @@\n from transformers.data.processors.squad import SquadExample\n from transformers.pipelines import QuestionAnsweringArgumentHandler, pipeline\n from transformers.testing_utils import (\n+    compare_pipeline_output_to_hub_spec,\n     is_pipeline_test,\n     nested_simplify,\n     require_tf,\n@@ -132,6 +135,8 @@ def run_pipeline_test(self, question_answerer, _):\n         self.assertEqual(\n             outputs, [{\"answer\": ANY(str), \"start\": ANY(int), \"end\": ANY(int), \"score\": ANY(float)} for i in range(20)]\n         )\n+        for single_output in outputs:\n+            compare_pipeline_output_to_hub_spec(single_output, QuestionAnsweringOutputElement)\n \n         # Very long context require multiple features\n         outputs = question_answerer("
        },
        {
            "sha": "cae285f5f157270e84b5af696176765d58c5fad8",
            "filename": "tests/test_pipeline_mixin.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/f8a260e2a44fbc707878277cb8cb5e53619f8b74/tests%2Ftest_pipeline_mixin.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f8a260e2a44fbc707878277cb8cb5e53619f8b74/tests%2Ftest_pipeline_mixin.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_pipeline_mixin.py?ref=f8a260e2a44fbc707878277cb8cb5e53619f8b74",
            "patch": "@@ -33,6 +33,7 @@\n     ImageSegmentationInput,\n     ImageToTextInput,\n     ObjectDetectionInput,\n+    QuestionAnsweringInput,\n     ZeroShotImageClassificationInput,\n )\n \n@@ -45,6 +46,7 @@\n     ImageSegmentationPipeline,\n     ImageToTextPipeline,\n     ObjectDetectionPipeline,\n+    QuestionAnsweringPipeline,\n     ZeroShotImageClassificationPipeline,\n )\n from transformers.testing_utils import (\n@@ -129,6 +131,7 @@\n     \"image-segmentation\": (ImageSegmentationPipeline, ImageSegmentationInput),\n     \"image-to-text\": (ImageToTextPipeline, ImageToTextInput),\n     \"object-detection\": (ObjectDetectionPipeline, ObjectDetectionInput),\n+    \"question-answering\": (QuestionAnsweringPipeline, QuestionAnsweringInput),\n     \"zero-shot-image-classification\": (ZeroShotImageClassificationPipeline, ZeroShotImageClassificationInput),\n }\n "
        }
    ],
    "stats": {
        "total": 35,
        "additions": 24,
        "deletions": 11
    }
}