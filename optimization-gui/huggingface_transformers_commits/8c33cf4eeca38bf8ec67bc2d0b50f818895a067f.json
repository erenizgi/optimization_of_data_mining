{
    "author": "yijun-lee",
    "message": "ğŸŒ [i18n-KO] Translated `gemma2.md` to Korean (#33937)\n\n* docs: ko: gemma2.md\r\n\r\n* feat: nmt draft\r\n\r\n* fix: manual edits\r\n\r\n* fix: resolve suggestions",
    "sha": "8c33cf4eeca38bf8ec67bc2d0b50f818895a067f",
    "files": [
        {
            "sha": "8ba65da887e21fcafc5eb1c7684acc5620c73811",
            "filename": "docs/source/ko/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8c33cf4eeca38bf8ec67bc2d0b50f818895a067f/docs%2Fsource%2Fko%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/8c33cf4eeca38bf8ec67bc2d0b50f818895a067f/docs%2Fsource%2Fko%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2F_toctree.yml?ref=8c33cf4eeca38bf8ec67bc2d0b50f818895a067f",
            "patch": "@@ -400,6 +400,8 @@\n         title: (ë²ˆì—­ì¤‘) Funnel Transformer\n       - local: model_doc/gemma\n         title: Gemma\n+      - local: model_doc/gemma2\n+        title: Gemma2\n       - local: model_doc/openai-gpt\n         title: GPT\n       - local: in_translation"
        },
        {
            "sha": "6bffec616c6e97d853a8e4d0b8f279bf1033d668",
            "filename": "docs/source/ko/model_doc/gemma2.md",
            "status": "added",
            "additions": 63,
            "deletions": 0,
            "changes": 63,
            "blob_url": "https://github.com/huggingface/transformers/blob/8c33cf4eeca38bf8ec67bc2d0b50f818895a067f/docs%2Fsource%2Fko%2Fmodel_doc%2Fgemma2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/8c33cf4eeca38bf8ec67bc2d0b50f818895a067f/docs%2Fsource%2Fko%2Fmodel_doc%2Fgemma2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fgemma2.md?ref=8c33cf4eeca38bf8ec67bc2d0b50f818895a067f",
            "patch": "@@ -0,0 +1,63 @@\n+\n+<!--Copyright 2024 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n+\n+âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+\n+# Gemma2 [[gemma2]]\n+\n+## ê°œìš” [[overview]]\n+\n+Gemma2 ëª¨ë¸ì€ Googleì˜ Gemma2 íŒ€ì´ ì‘ì„±í•œ [Gemma2: Open Models Based on Gemini Technology and Research](https://blog.google/technology/developers/google-gemma-2/)ì—ì„œ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤.\n+íŒŒë¼ë¯¸í„° í¬ê¸°ê°€ ê°ê° 90ì–µ(9B)ê³¼ 270ì–µ(27B)ì¸ ë‘ ê°€ì§€ Gemma2 ëª¨ë¸ì´ ì¶œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.\n+\n+ë¸”ë¡œê·¸ ê²Œì‹œë¬¼ì˜ ì´ˆë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n+\n+*ì´ì œ ìš°ë¦¬ëŠ” ì „ ì„¸ê³„ì˜ ì—°êµ¬ìì™€ ê°œë°œìë“¤ì—ê²Œ Gemma 2ë¥¼ ê³µì‹ì ìœ¼ë¡œ ì¶œì‹œí•©ë‹ˆë‹¤. 90ì–µ(9B)ê³¼ 270ì–µ(27B) íŒŒë¼ë¯¸í„° í¬ê¸°ë¡œ ì œê³µë˜ëŠ” Gemma 2ëŠ” 1ì„¸ëŒ€ë³´ë‹¤ ë” ë†’ì€ ì„±ëŠ¥ê³¼ ì¶”ë¡  íš¨ìœ¨ì„±ì„ ì œê³µí•˜ë©°, ìƒë‹¹í•œ ì•ˆì „ì„± í–¥ìƒì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì‚¬ì‹¤ 270ì–µ ê·œëª¨ì˜ ëª¨ë¸ì€ í¬ê¸°ê°€ ë‘ ë°° ì´ìƒì¸ ëª¨ë¸ê³¼ ë¹„êµí•´ë„ ê²½ìŸë ¥ ìˆëŠ” ëŒ€ì•ˆì„ ì œê³µí•˜ë©°, ì´ëŠ” ì‘ë…„ 12ì›”ê¹Œì§€ë§Œ í•´ë„ ë…ì  ëª¨ë¸ì—ì„œë§Œ ê°€ëŠ¥í–ˆë˜ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.*\n+\n+íŒ:\n+\n+- ì›ë³¸ ì²´í¬í¬ì¸íŠ¸ëŠ” ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ `src/transformers/models/Gemma2/convert_Gemma2_weights_to_hf.py`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+<Tip warning={true}>\n+\n+- Gemma2ëŠ” ë§¤ ë‘ ë²ˆì§¸ ë ˆì´ì–´ë§ˆë‹¤ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì–´í…ì…˜ì„ ì‚¬ìš©í•˜ë¯€ë¡œ [`~DynamicCache`] ë˜ëŠ” í…ì„œì˜ íŠœí”Œê³¼ ê°™ì€ ì¼ë°˜ì ì¸ kv ìºì‹±ì—ëŠ” ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Gemma2ì˜ forward í˜¸ì¶œì—ì„œ ìºì‹±ì„ í™œì„±í™”í•˜ë ¤ë©´ [`~HybridCache`] ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ê³  ì´ë¥¼ `past_key_values`ë¡œ forward í˜¸ì¶œì— ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ `past_key_values`ì— ì´ë¯¸ ì´ì „ì˜ í‚¤ì™€ ê°’ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ `cache_position`ë„ ì¤€ë¹„í•´ì•¼ í•©ë‹ˆë‹¤.\n+\n+</Tip>\n+\n+ì´ ëª¨ë¸ì€ [Arthur Zucker](https://huggingface.co/ArthurZ), [Pedro Cuenca](https://huggingface.co/pcuenq), [Tom Arsen]()ì´ ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤.\n+\n+## Gemma2Config [[transformers.Gemma2Config]]\n+\n+[[autodoc]] Gemma2Config\n+\n+## Gemma2Model [[transformers.Gemma2Model]]\n+\n+[[autodoc]] Gemma2Model\n+    - forward\n+\n+## Gemma2ForCausalLM [[transformers.Gemma2ForCausalLM]]\n+\n+[[autodoc]] Gemma2ForCausalLM\n+    - forward\n+\n+## Gemma2ForSequenceClassification [[transformers.Gemma2ForSequenceClassification]]\n+\n+[[autodoc]] Gemma2ForSequenceClassification\n+    - forward\n+\n+## Gemma2ForTokenClassification [[transformers.Gemma2ForTokenClassification]]\n+\n+[[autodoc]] Gemma2ForTokenClassification\n+    - forward\n\\ No newline at end of file"
        }
    ],
    "stats": {
        "total": 65,
        "additions": 65,
        "deletions": 0
    }
}