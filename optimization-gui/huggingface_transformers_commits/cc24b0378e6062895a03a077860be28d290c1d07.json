{
    "author": "qubvel",
    "message": "Better typing for model.config (#39132)\n\n* Apply to all models config annotation\n\n* Update modular to preserve order\n\n* Apply modular\n\n* fix define docstring\n\n* fix dinov2 consistency (docs<->modular)\n\n* fix InstructBlipVideoForConditionalGeneration docs<->modular consistency\n\n* fixup\n\n* remove duplicate code\n\n* Delete config_class attribute from the modeling code\n\n* Add config_class attribute in base model\n\n* Update init sub class\n\n* Deprecated models update\n\n* Update new models\n\n* Fix remote code BC issue\n\n* fixup\n\n* fixing more corner cases\n\n* fix new models\n\n* add test\n\n* modular docs update\n\n* fix comment a bit\n\n* fix for py3.9",
    "sha": "cc24b0378e6062895a03a077860be28d290c1d07",
    "files": [
        {
            "sha": "9ce2539851e53ba94771af0adef44c2f7aa00a68",
            "filename": "src/transformers/generation/watermarking.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fgeneration%2Fwatermarking.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fgeneration%2Fwatermarking.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Fwatermarking.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -375,7 +375,7 @@ class BayesianDetectorModel(PreTrainedModel):\n             configuration. Check out the [`~PreTrainedModel.from_pretrained`] method to load the model weights.\n     \"\"\"\n \n-    config_class = BayesianDetectorConfig\n+    config: BayesianDetectorConfig\n     base_model_prefix = \"model\"\n \n     def __init__(self, config):"
        },
        {
            "sha": "6fadc8adf1e5d0ff073d06269fe7a00e46203d8a",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 25,
            "deletions": 1,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -33,7 +33,7 @@\n from enum import Enum\n from functools import partial, wraps\n from threading import Thread\n-from typing import Any, Callable, Optional, TypeVar, Union\n+from typing import Any, Callable, Optional, TypeVar, Union, get_type_hints\n from zipfile import is_zipfile\n \n import torch\n@@ -2060,6 +2060,30 @@ def framework(self) -> str:\n         \"\"\"\n         return \"pt\"\n \n+    def __init_subclass__(cls, **kwargs):\n+        super().__init_subclass__(**kwargs)\n+        # For BC we keep the original `config_class` definition in case\n+        # there is a `config_class` attribute (e.g. remote code models),\n+        # otherwise we derive it from the annotated `config` attribute.\n+\n+        # defined in this particular subclass\n+        child_annotation = cls.__dict__.get(\"__annotations__\", {}).get(\"config\", None)\n+        child_attribute = cls.__dict__.get(\"config_class\", None)\n+\n+        # defined in the class (this subclass or any parent class)\n+        full_annotation = get_type_hints(cls).get(\"config\", None)\n+        full_attribute = cls.config_class\n+\n+        # priority (child class_config -> child annotation -> global class_config -> global annotation)\n+        if child_attribute is not None:\n+            cls.config_class = child_attribute\n+        elif child_annotation is not None:\n+            cls.config_class = child_annotation\n+        elif full_attribute is not None:\n+            cls.config_class = full_attribute\n+        elif full_annotation is not None:\n+            cls.config_class = full_annotation\n+\n     def __init__(self, config: PretrainedConfig, *inputs, **kwargs):\n         super().__init__()\n         if not isinstance(config, PretrainedConfig):"
        },
        {
            "sha": "7b124a64c99a18b83ecbf304e63816873d50d2f2",
            "filename": "src/transformers/models/aimv2/modeling_aimv2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Faimv2%2Fmodeling_aimv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Faimv2%2Fmodeling_aimv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faimv2%2Fmodeling_aimv2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -434,7 +434,7 @@ class Aimv2PreTrainedModel(PreTrainedModel):\n     models. The model is only intended for inference and doesn't support finetuning.\n     \"\"\"\n \n-    config_class = Aimv2Config\n+    config: Aimv2Config\n     base_model_prefix = \"aimv2\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\n@@ -474,8 +474,8 @@ def _init_weights(self, module):\n     \"\"\"\n )\n class Aimv2VisionModel(Aimv2PreTrainedModel):\n+    config: Aimv2VisionConfig\n     main_input_name = \"pixel_values\"\n-    config_class = Aimv2VisionConfig\n \n     def __init__(self, config: Aimv2VisionConfig):\n         super().__init__(config)\n@@ -640,7 +640,7 @@ def _get_vector_norm(tensor: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class Aimv2Model(Aimv2PreTrainedModel):\n-    config_class = Aimv2Config\n+    config: Aimv2Config\n     _no_split_modules = [\"Aimv2TextEmbeddings\", \"Aimv2EncoderLayer\", \"Aimv2VisionEmbeddings\"]\n \n     def __init__(self, config: Aimv2Config):"
        },
        {
            "sha": "7c83bf4e2dc2caecda98e976e4123179ea6f250c",
            "filename": "src/transformers/models/aimv2/modular_aimv2.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Faimv2%2Fmodular_aimv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Faimv2%2Fmodular_aimv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faimv2%2Fmodular_aimv2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -431,7 +431,7 @@ class Aimv2PreTrainedModel(PreTrainedModel):\n     models. The model is only intended for inference and doesn't support finetuning.\n     \"\"\"\n \n-    config_class = Aimv2Config\n+    config: Aimv2Config\n     base_model_prefix = \"aimv2\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\n@@ -471,8 +471,8 @@ def _init_weights(self, module):\n     \"\"\"\n )\n class Aimv2VisionModel(Aimv2PreTrainedModel):\n+    config: Aimv2VisionConfig\n     main_input_name = \"pixel_values\"\n-    config_class = Aimv2VisionConfig\n \n     def __init__(self, config: Aimv2VisionConfig):\n         super().__init__(config)"
        },
        {
            "sha": "a7de99ac1de83ca829107c0b534b07bc3be072a5",
            "filename": "src/transformers/models/albert/modeling_albert.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Falbert%2Fmodeling_albert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Falbert%2Fmodeling_albert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Falbert%2Fmodeling_albert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -555,7 +555,7 @@ def forward(\n \n @auto_docstring\n class AlbertPreTrainedModel(PreTrainedModel):\n-    config_class = AlbertConfig\n+    config: AlbertConfig\n     load_tf_weights = load_tf_weights_in_albert\n     base_model_prefix = \"albert\"\n     _supports_sdpa = True\n@@ -606,7 +606,7 @@ class AlbertForPreTrainingOutput(ModelOutput):\n \n @auto_docstring\n class AlbertModel(AlbertPreTrainedModel):\n-    config_class = AlbertConfig\n+    config: AlbertConfig\n     base_model_prefix = \"albert\"\n \n     def __init__(self, config: AlbertConfig, add_pooling_layer: bool = True):"
        },
        {
            "sha": "4bc5f442cb7abff32745c016bad042fdad1a3fc8",
            "filename": "src/transformers/models/align/modeling_align.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Falign%2Fmodeling_align.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Falign%2Fmodeling_align.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Falign%2Fmodeling_align.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -881,7 +881,7 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class AlignPreTrainedModel(PreTrainedModel):\n-    config_class = AlignConfig\n+    config: AlignConfig\n     base_model_prefix = \"align\"\n     supports_gradient_checkpointing = True\n \n@@ -910,7 +910,7 @@ def _init_weights(self, module):\n     \"\"\"\n )\n class AlignTextModel(AlignPreTrainedModel):\n-    config_class = AlignTextConfig\n+    config: AlignTextConfig\n     _no_split_modules = [\"AlignTextEmbeddings\"]\n \n     def __init__(self, config: AlignTextConfig, add_pooling_layer: bool = True):\n@@ -1038,7 +1038,7 @@ def forward(\n     \"\"\"\n )\n class AlignVisionModel(AlignPreTrainedModel):\n-    config_class = AlignVisionConfig\n+    config: AlignVisionConfig\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = False\n \n@@ -1119,7 +1119,7 @@ def forward(\n \n @auto_docstring\n class AlignModel(AlignPreTrainedModel):\n-    config_class = AlignConfig\n+    config: AlignConfig\n \n     def __init__(self, config: AlignConfig):\n         super().__init__(config)"
        },
        {
            "sha": "9f44323fe46579981f20132fc5b0ff7f7acad664",
            "filename": "src/transformers/models/altclip/modeling_altclip.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Faltclip%2Fmodeling_altclip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Faltclip%2Fmodeling_altclip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faltclip%2Fmodeling_altclip.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -837,7 +837,7 @@ def forward(self, pixel_values: torch.FloatTensor, interpolate_pos_encoding=Fals\n \n @auto_docstring\n class AltCLIPPreTrainedModel(PreTrainedModel):\n-    config_class = AltCLIPConfig\n+    config: AltCLIPConfig\n     base_model_prefix = \"altclip\"\n     supports_gradient_checkpointing = True\n     _no_split_module = []\n@@ -941,7 +941,7 @@ def forward(\n \n \n class AltCLIPVisionModel(AltCLIPPreTrainedModel):\n-    config_class = AltCLIPVisionConfig\n+    config: AltCLIPVisionConfig\n     main_input_name = \"pixel_values\"\n \n     def __init__(self, config: AltCLIPVisionConfig):\n@@ -1003,7 +1003,7 @@ def forward(\n     \"\"\"\n )\n class AltRobertaModel(AltCLIPPreTrainedModel):\n-    config_class = AltCLIPTextConfig\n+    config: AltCLIPTextConfig\n \n     # Copied from transformers.models.clap.modeling_clap.ClapTextModel.__init__ with ClapText->AltRoberta\n     def __init__(self, config, add_pooling_layer=True):\n@@ -1121,7 +1121,7 @@ def forward(\n \n \n class AltCLIPTextModel(AltCLIPPreTrainedModel):\n-    config_class = AltCLIPTextConfig\n+    config: AltCLIPTextConfig\n \n     def __init__(self, config):\n         super().__init__(config)\n@@ -1208,7 +1208,7 @@ def forward(\n \n \n class AltCLIPModel(AltCLIPPreTrainedModel):\n-    config_class = AltCLIPConfig\n+    config: AltCLIPConfig\n \n     def __init__(self, config: AltCLIPConfig):\n         super().__init__(config)"
        },
        {
            "sha": "99a763b1e056f6e47dd993e9dc219f6b039f9e86",
            "filename": "src/transformers/models/arcee/modeling_arcee.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Farcee%2Fmodeling_arcee.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Farcee%2Fmodeling_arcee.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Farcee%2Fmodeling_arcee.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -308,7 +308,7 @@ def forward(\n \n @auto_docstring\n class ArceePreTrainedModel(PreTrainedModel):\n-    config_class = ArceeConfig\n+    config: ArceeConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"ArceeDecoderLayer\"]"
        },
        {
            "sha": "24e741f8794a45197442f4fed4bbb3c515b409ef",
            "filename": "src/transformers/models/aria/modeling_aria.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -624,7 +624,7 @@ def forward(\n \n @auto_docstring\n class AriaTextPreTrainedModel(PreTrainedModel):\n-    config_class = AriaTextConfig\n+    config: AriaTextConfig\n     base_model_prefix = \"model\"\n     _no_split_modules = [\"AriaTextDecoderLayer\", \"AriaGroupedExpertsGemm\"]\n     supports_gradient_checkpointing = True\n@@ -656,7 +656,7 @@ def _init_weights(self, module):\n \n @auto_docstring\n class AriaPreTrainedModel(PreTrainedModel):\n-    config_class = AriaConfig\n+    config: AriaConfig\n     base_model_prefix = \"\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"AriaDecoderLayer\"]"
        },
        {
            "sha": "95e3bad057671455bf78d5e9c5be7574a1410a22",
            "filename": "src/transformers/models/aria/modular_aria.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Faria%2Fmodular_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Faria%2Fmodular_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faria%2Fmodular_aria.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1279,7 +1279,7 @@ def __init__(self, config: AriaTextConfig, layer_idx: int):\n \n @auto_docstring\n class AriaTextPreTrainedModel(PreTrainedModel):\n-    config_class = AriaTextConfig\n+    config: AriaTextConfig\n     base_model_prefix = \"model\"\n     _no_split_modules = [\"AriaTextDecoderLayer\", \"AriaGroupedExpertsGemm\"]\n     supports_gradient_checkpointing = True\n@@ -1310,7 +1310,7 @@ def _init_weights(self, module):\n \n \n class AriaPreTrainedModel(LlamaPreTrainedModel):\n-    config_class = AriaConfig\n+    config: AriaConfig\n     base_model_prefix = \"\"\n     _supports_static_cache = False  # MoE models don't work with torch.compile (dynamic slicing)\n     _supports_attention_backend = True"
        },
        {
            "sha": "d6ac5f15dbdfde0b4cd45b3969a610d664a4de65",
            "filename": "src/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -381,7 +381,7 @@ def forward(\n \n @auto_docstring\n class ASTPreTrainedModel(PreTrainedModel):\n-    config_class = ASTConfig\n+    config: ASTConfig\n     base_model_prefix = \"audio_spectrogram_transformer\"\n     main_input_name = \"input_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "cdf7a7db052f2043d3441eb4ae722efa993e0351",
            "filename": "src/transformers/models/autoformer/modeling_autoformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fautoformer%2Fmodeling_autoformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fautoformer%2Fmodeling_autoformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fautoformer%2Fmodeling_autoformer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -847,7 +847,7 @@ def forward(\n \n @auto_docstring\n class AutoformerPreTrainedModel(PreTrainedModel):\n-    config_class = AutoformerConfig\n+    config: AutoformerConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"past_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "5692819b3e6526c996ab9a958295e6ba57e2854c",
            "filename": "src/transformers/models/aya_vision/modeling_aya_vision.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodeling_aya_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodeling_aya_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faya_vision%2Fmodeling_aya_vision.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -89,7 +89,7 @@ def pixel_shuffle(self, image_features):  # B, S, D\n \n @auto_docstring\n class AyaVisionPreTrainedModel(PreTrainedModel):\n-    config_class = AyaVisionConfig\n+    config: AyaVisionConfig\n     base_model_prefix = \"\"\n     supports_gradient_checkpointing = True\n     _skip_keys_device_placement = \"past_key_values\""
        },
        {
            "sha": "a0cfecc4e3c4e4247beabeb98874f163424e7a89",
            "filename": "src/transformers/models/bamba/modeling_bamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodeling_bamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodeling_bamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodeling_bamba.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1034,7 +1034,7 @@ def forward(\n \n @auto_docstring\n class BambaPreTrainedModel(PreTrainedModel):\n-    config_class = BambaConfig\n+    config: BambaConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"BambaDecoderLayer\"]"
        },
        {
            "sha": "e1a6eed50d1e3b57ea9c4a6759da3c8db827b359",
            "filename": "src/transformers/models/bamba/modular_bamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodular_bamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodular_bamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodular_bamba.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -805,7 +805,7 @@ def forward(\n \n @auto_docstring\n class BambaPreTrainedModel(PreTrainedModel):\n-    config_class = BambaConfig\n+    config: BambaConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"BambaDecoderLayer\"]"
        },
        {
            "sha": "5dd03770ece09a82b0cf3ddb8705cecdee5b831e",
            "filename": "src/transformers/models/bark/modeling_bark.py",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbark%2Fmodeling_bark.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbark%2Fmodeling_bark.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbark%2Fmodeling_bark.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -328,7 +328,7 @@ def forward(\n \n @auto_docstring\n class BarkPreTrainedModel(PreTrainedModel):\n-    config_class = BarkConfig\n+    config: BarkConfig\n     supports_gradient_checkpointing = False\n     _supports_flash_attn = True\n \n@@ -374,7 +374,7 @@ def device(self) -> torch.device:\n \n # GPT2-like autoregressive model\n class BarkCausalModel(BarkPreTrainedModel, GenerationMixin):\n-    config_class = BarkSubModelConfig\n+    config: BarkSubModelConfig\n \n     def __init__(self, config):\n         super().__init__(config)\n@@ -627,7 +627,7 @@ def forward(\n )\n class BarkSemanticModel(BarkCausalModel):\n     base_model_prefix = \"semantic\"\n-    config_class = BarkSemanticConfig\n+    config: BarkSemanticConfig\n \n     def generate(\n         self,\n@@ -738,7 +738,7 @@ def generate(\n )\n class BarkCoarseModel(BarkCausalModel):\n     base_model_prefix = \"coarse_acoustics\"\n-    config_class = BarkCoarseConfig\n+    config: BarkCoarseConfig\n \n     def preprocess_histories(\n         self,\n@@ -959,7 +959,7 @@ def generate(\n )\n class BarkFineModel(BarkPreTrainedModel):\n     base_model_prefix = \"fine_acoustics\"\n-    config_class = BarkFineConfig\n+    config: BarkFineConfig\n     main_input_name = \"codebook_idx\"\n \n     def __init__(self, config):\n@@ -1393,7 +1393,7 @@ def generate(\n     \"\"\"\n )\n class BarkModel(BarkPreTrainedModel):\n-    config_class = BarkConfig\n+    config: BarkConfig\n \n     def __init__(self, config):\n         super().__init__(config)"
        },
        {
            "sha": "1e43e754bb44e59d261986334d0e51a6f6131a24",
            "filename": "src/transformers/models/bart/modeling_bart.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbart%2Fmodeling_bart.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbart%2Fmodeling_bart.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbart%2Fmodeling_bart.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -484,7 +484,7 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class BartPreTrainedModel(PreTrainedModel):\n-    config_class = BartConfig\n+    config: BartConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _keys_to_ignore_on_load_unexpected = [\"encoder.version\", \"decoder.version\"]"
        },
        {
            "sha": "9138e7b8406d1530d43e918b6e9a3a2de7600927",
            "filename": "src/transformers/models/beit/modeling_beit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbeit%2Fmodeling_beit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbeit%2Fmodeling_beit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbeit%2Fmodeling_beit.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -722,7 +722,7 @@ def forward(\n \n @auto_docstring\n class BeitPreTrainedModel(PreTrainedModel):\n-    config_class = BeitConfig\n+    config: BeitConfig\n     base_model_prefix = \"beit\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "c92f02a5f8a3709db373917330ec966e592b675d",
            "filename": "src/transformers/models/bert/modeling_bert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbert%2Fmodeling_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbert%2Fmodeling_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbert%2Fmodeling_bert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -805,7 +805,7 @@ def forward(self, sequence_output, pooled_output):\n \n @auto_docstring\n class BertPreTrainedModel(PreTrainedModel):\n-    config_class = BertConfig\n+    config: BertConfig\n     load_tf_weights = load_tf_weights_in_bert\n     base_model_prefix = \"bert\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "0a4d56c3f3b7af6efcdf6c48f64005ab55c77916",
            "filename": "src/transformers/models/bert_generation/modeling_bert_generation.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbert_generation%2Fmodeling_bert_generation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbert_generation%2Fmodeling_bert_generation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbert_generation%2Fmodeling_bert_generation.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -572,7 +572,7 @@ def forward(self, input_ids=None, position_ids=None, inputs_embeds=None, past_ke\n \n @auto_docstring\n class BertGenerationPreTrainedModel(PreTrainedModel):\n-    config_class = BertGenerationConfig\n+    config: BertGenerationConfig\n     base_model_prefix = \"bert\"\n     supports_gradient_checkpointing = True\n "
        },
        {
            "sha": "affbc3335eef037b917a23b05cbc0483eafa313d",
            "filename": "src/transformers/models/big_bird/modeling_big_bird.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fmodeling_big_bird.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fmodeling_big_bird.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fmodeling_big_bird.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1709,7 +1709,7 @@ def forward(self, sequence_output, pooled_output):\n \n @auto_docstring\n class BigBirdPreTrainedModel(PreTrainedModel):\n-    config_class = BigBirdConfig\n+    config: BigBirdConfig\n     load_tf_weights = load_tf_weights_in_big_bird\n     base_model_prefix = \"bert\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "2220efc887478717345aead35c3efcaa93c337a5",
            "filename": "src/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fmodeling_bigbird_pegasus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fmodeling_bigbird_pegasus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fmodeling_bigbird_pegasus.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1559,7 +1559,7 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class BigBirdPegasusPreTrainedModel(PreTrainedModel):\n-    config_class = BigBirdPegasusConfig\n+    config: BigBirdPegasusConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"BigBirdPegasusEncoderLayer\", \"BigBirdPegasusDecoderLayer\"]"
        },
        {
            "sha": "c1575b0c049668f5334f1f280b2a6f6f190f4cfb",
            "filename": "src/transformers/models/biogpt/modeling_biogpt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fmodeling_biogpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fmodeling_biogpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fmodeling_biogpt.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -340,7 +340,7 @@ def forward(\n \n @auto_docstring\n class BioGptPreTrainedModel(PreTrainedModel):\n-    config_class = BioGptConfig\n+    config: BioGptConfig\n     base_model_prefix = \"biogpt\"\n     supports_gradient_checkpointing = True\n     _supports_flash_attn = True"
        },
        {
            "sha": "44ccac314d20dd5e84c36532101c8793cde3c7a5",
            "filename": "src/transformers/models/biogpt/modular_biogpt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fmodular_biogpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fmodular_biogpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fmodular_biogpt.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -165,7 +165,7 @@ def forward(\n \n @auto_docstring\n class BioGptPreTrainedModel(PreTrainedModel):\n-    config_class = BioGptConfig\n+    config: BioGptConfig\n     base_model_prefix = \"biogpt\"\n     supports_gradient_checkpointing = True\n     _supports_flash_attn = True"
        },
        {
            "sha": "140a2e7b526c83dc8ba89e3a2080c760ef7adb73",
            "filename": "src/transformers/models/bit/modeling_bit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbit%2Fmodeling_bit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbit%2Fmodeling_bit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbit%2Fmodeling_bit.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -631,7 +631,7 @@ def forward(\n \n @auto_docstring\n class BitPreTrainedModel(PreTrainedModel):\n-    config_class = BitConfig\n+    config: BitConfig\n     base_model_prefix = \"bit\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [\"BitEmbeddings\"]"
        },
        {
            "sha": "66cf5d02f4ba671b08d31702c9abacbe54545a11",
            "filename": "src/transformers/models/bitnet/modeling_bitnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbitnet%2Fmodeling_bitnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbitnet%2Fmodeling_bitnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbitnet%2Fmodeling_bitnet.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -303,7 +303,7 @@ def forward(self, x, position_ids):\n \n @auto_docstring\n class BitNetPreTrainedModel(PreTrainedModel):\n-    config_class = BitNetConfig\n+    config: BitNetConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"BitNetDecoderLayer\"]"
        },
        {
            "sha": "c4bb3b6e192721f7b155a71ff49b7081beb11bf6",
            "filename": "src/transformers/models/blenderbot/modeling_blenderbot.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_blenderbot.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_blenderbot.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_blenderbot.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -452,7 +452,7 @@ def forward(\n \n @auto_docstring\n class BlenderbotPreTrainedModel(PreTrainedModel):\n-    config_class = BlenderbotConfig\n+    config: BlenderbotConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _supports_flash_attn = True"
        },
        {
            "sha": "74e5d0767acb9562f568d83db2dbe4b3edd587fb",
            "filename": "src/transformers/models/blenderbot_small/modeling_blenderbot_small.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fmodeling_blenderbot_small.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fmodeling_blenderbot_small.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fmodeling_blenderbot_small.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -445,7 +445,7 @@ def forward(\n \n @auto_docstring\n class BlenderbotSmallPreTrainedModel(PreTrainedModel):\n-    config_class = BlenderbotSmallConfig\n+    config: BlenderbotSmallConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _supports_flash_attn = True"
        },
        {
            "sha": "3644c71cc0536621d47355c46e537ee522acb73e",
            "filename": "src/transformers/models/blip/modeling_blip.py",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -434,7 +434,7 @@ def forward(\n \n @auto_docstring\n class BlipPreTrainedModel(PreTrainedModel):\n-    config_class = BlipConfig\n+    config: BlipConfig\n     base_model_prefix = \"blip\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"BlipEncoderLayer\", \"BlipTextEmbeddings\"]\n@@ -551,7 +551,7 @@ def forward(\n \n class BlipVisionModel(BlipPreTrainedModel):\n     main_input_name = \"pixel_values\"\n-    config_class = BlipVisionConfig\n+    config: BlipVisionConfig\n \n     def __init__(self, config: BlipVisionConfig):\n         super().__init__(config)\n@@ -617,7 +617,7 @@ def get_input_embeddings(self):\n     \"\"\"\n )\n class BlipModel(BlipPreTrainedModel):\n-    config_class = BlipConfig\n+    config: BlipConfig\n \n     def __init__(self, config: BlipConfig):\n         super().__init__(config)\n@@ -902,7 +902,7 @@ def forward(\n     \"\"\"\n )\n class BlipForConditionalGeneration(BlipPreTrainedModel, GenerationMixin):\n-    config_class = BlipConfig\n+    config: BlipConfig\n     _tied_weights_keys = [\"text_decoder.cls.predictions.decoder.bias\"]\n     main_input_name = \"pixel_values\"\n \n@@ -1080,7 +1080,7 @@ def generate(\n     \"\"\"\n )\n class BlipForQuestionAnswering(BlipPreTrainedModel, GenerationMixin):\n-    config_class = BlipConfig\n+    config: BlipConfig\n     _tied_weights_keys = [\"text_decoder.cls.predictions.decoder.bias\"]\n \n     def __init__(self, config: BlipConfig):\n@@ -1310,7 +1310,7 @@ def generate(\n     \"\"\"\n )\n class BlipForImageTextRetrieval(BlipPreTrainedModel):\n-    config_class = BlipConfig\n+    config: BlipConfig\n \n     def __init__(self, config: BlipConfig):\n         super().__init__(config)"
        },
        {
            "sha": "0c6e8777fd0571bc48af2ba8b8dd79d8c603b33e",
            "filename": "src/transformers/models/blip/modeling_blip_text.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip_text.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -575,7 +575,7 @@ class BlipTextPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = BlipTextConfig\n+    config: BlipTextConfig\n     base_model_prefix = \"bert\"\n     _no_split_modules = []\n "
        },
        {
            "sha": "4c7a52e6fbbc5fcdb6055a7c3879b7c291485784",
            "filename": "src/transformers/models/blip_2/modeling_blip_2.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -405,7 +405,7 @@ def forward(\n \n @auto_docstring\n class Blip2PreTrainedModel(PreTrainedModel):\n-    config_class = Blip2Config\n+    config: Blip2Config\n     base_model_prefix = \"blip\"\n     supports_gradient_checkpointing = True\n     _supports_attention_backend = True\n@@ -536,7 +536,7 @@ def forward(\n # Copied from transformers.models.blip.modeling_blip.BlipVisionModel with Blip->Blip2, BLIP->BLIP_2\n class Blip2VisionModel(Blip2PreTrainedModel):\n     main_input_name = \"pixel_values\"\n-    config_class = Blip2VisionConfig\n+    config: Blip2VisionConfig\n \n     def __init__(self, config: Blip2VisionConfig):\n         super().__init__(config)\n@@ -1234,7 +1234,7 @@ def forward(\n     \"\"\"\n )\n class Blip2Model(Blip2PreTrainedModel):\n-    config_class = Blip2Config\n+    config: Blip2Config\n     main_input_name = \"pixel_values\"\n     _keep_in_fp32_modules = [\"query_tokens\", \"qformer\"]\n     _supports_flash_attn = False  # because self.qformer does not support FA2\n@@ -1828,7 +1828,7 @@ def forward(\n     \"\"\"\n )\n class Blip2ForConditionalGeneration(Blip2PreTrainedModel, GenerationMixin):\n-    config_class = Blip2Config\n+    config: Blip2Config\n     main_input_name = \"pixel_values\"\n \n     _supports_static_cache = True"
        },
        {
            "sha": "7da3e9de9e84888a9a08272738266267631917a6",
            "filename": "src/transformers/models/bloom/modeling_bloom.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbloom%2Fmodeling_bloom.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbloom%2Fmodeling_bloom.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbloom%2Fmodeling_bloom.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -428,7 +428,7 @@ def forward(\n \n @auto_docstring\n class BloomPreTrainedModel(PreTrainedModel):\n-    config_class = BloomConfig\n+    config: BloomConfig\n     base_model_prefix = \"transformer\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"BloomBlock\"]"
        },
        {
            "sha": "42d85da5e50664698a17a2b4ea3bcad24e3b5663",
            "filename": "src/transformers/models/bridgetower/modeling_bridgetower.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fmodeling_bridgetower.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fmodeling_bridgetower.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fmodeling_bridgetower.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -943,7 +943,7 @@ def create_position_ids_from_input_ids(input_ids, padding_idx, past_key_values_l\n \n @auto_docstring\n class BridgeTowerPreTrainedModel(PreTrainedModel):\n-    config_class = BridgeTowerConfig\n+    config: BridgeTowerConfig\n     base_model_prefix = \"bridgetower\"\n     supports_gradient_checkpointing = False\n     _no_split_modules = [\"BridgeTowerSelfAttention\", \"BridgeTowerResidualAttention\"]\n@@ -977,7 +977,7 @@ def _init_weights(self, module):\n \n \n class BridgeTowerVisionModel(BridgeTowerPreTrainedModel):\n-    config_class = BridgeTowerVisionConfig\n+    config: BridgeTowerVisionConfig\n \n     def __init__(self, config):\n         super().__init__(config)\n@@ -1006,7 +1006,7 @@ def forward(self, image, image_mask=None, interpolate_pos_encoding=False):\n     \"\"\"\n )\n class BridgeTowerTextModel(BridgeTowerPreTrainedModel):\n-    config_class = BridgeTowerTextConfig\n+    config: BridgeTowerTextConfig\n \n     def __init__(self, config, add_pooling_layer=True):\n         r\"\"\""
        },
        {
            "sha": "97a2f7fcf2b676122de340d18df615a898648961",
            "filename": "src/transformers/models/bros/modeling_bros.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbros%2Fmodeling_bros.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fbros%2Fmodeling_bros.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbros%2Fmodeling_bros.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -583,7 +583,7 @@ def forward(self, query_layer: torch.Tensor, key_layer: torch.Tensor):\n \n @auto_docstring\n class BrosPreTrainedModel(PreTrainedModel):\n-    config_class = BrosConfig\n+    config: BrosConfig\n     base_model_prefix = \"bros\"\n \n     def _init_weights(self, module):"
        },
        {
            "sha": "c0271d2f273baf28d4a7e6f2e94d8f18f230cf1b",
            "filename": "src/transformers/models/camembert/modeling_camembert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -691,7 +691,7 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class CamembertPreTrainedModel(PreTrainedModel):\n-    config_class = CamembertConfig\n+    config: CamembertConfig\n     base_model_prefix = \"roberta\"\n     supports_gradient_checkpointing = True\n     _supports_sdpa = True"
        },
        {
            "sha": "1f83c15b4f96ef7af6824be2920f36a3bd62da02",
            "filename": "src/transformers/models/canine/modeling_canine.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcanine%2Fmodeling_canine.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcanine%2Fmodeling_canine.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcanine%2Fmodeling_canine.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -873,7 +873,7 @@ def forward(\n \n @auto_docstring\n class CaninePreTrainedModel(PreTrainedModel):\n-    config_class = CanineConfig\n+    config: CanineConfig\n     load_tf_weights = load_tf_weights_in_canine\n     base_model_prefix = \"canine\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "9516f8b496eeea31905b20155ade45caffb8bfa7",
            "filename": "src/transformers/models/chameleon/modeling_chameleon.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fchameleon%2Fmodeling_chameleon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fchameleon%2Fmodeling_chameleon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchameleon%2Fmodeling_chameleon.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -807,7 +807,7 @@ def convert_img2bpe(self, img_batch: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class ChameleonPreTrainedModel(PreTrainedModel):\n-    config_class = ChameleonConfig\n+    config: ChameleonConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"ChameleonDecoderLayer\", \"ChameleonSwinDecoderLayer\"]\n@@ -847,7 +847,7 @@ def _init_weights(self, module):\n     \"\"\"\n )\n class ChameleonVQVAE(ChameleonPreTrainedModel):\n-    config_class = ChameleonVQVAEConfig\n+    config: ChameleonVQVAEConfig\n     _no_split_modules = [\"ChameleonVQVAEVectorQuantizer\"]\n \n     def __init__(self, config: ChameleonVQVAEConfig):"
        },
        {
            "sha": "6fcc04a94040ec2504da0c07b7a325cee15dd839",
            "filename": "src/transformers/models/chinese_clip/modeling_chinese_clip.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fmodeling_chinese_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fmodeling_chinese_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fmodeling_chinese_clip.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -607,7 +607,7 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class ChineseCLIPPreTrainedModel(PreTrainedModel):\n-    config_class = ChineseCLIPConfig\n+    config: ChineseCLIPConfig\n     base_model_prefix = \"chinese_clip\"\n     supports_gradient_checkpointing = True\n \n@@ -856,7 +856,7 @@ class ChineseCLIPTextModel(ChineseCLIPPreTrainedModel):\n     `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.\n     \"\"\"\n \n-    config_class = ChineseCLIPTextConfig\n+    config: ChineseCLIPTextConfig\n     _no_split_modules = [\"ChineseCLIPTextEmbeddings\"]\n \n     def __init__(self, config, add_pooling_layer=True):\n@@ -972,7 +972,7 @@ def forward(\n     \"\"\"\n )\n class ChineseCLIPVisionModel(ChineseCLIPPreTrainedModel):\n-    config_class = ChineseCLIPVisionConfig\n+    config: ChineseCLIPVisionConfig\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [\"ChineseCLIPVisionEmbeddings\", \"ChineseCLIPVisionAttention\"]\n \n@@ -1027,7 +1027,7 @@ def forward(\n \n @auto_docstring\n class ChineseCLIPModel(ChineseCLIPPreTrainedModel):\n-    config_class = ChineseCLIPConfig\n+    config: ChineseCLIPConfig\n \n     def __init__(self, config: ChineseCLIPConfig):\n         super().__init__(config)"
        },
        {
            "sha": "870aab4e2c445df5b4d0170e2912705d41f3fe8d",
            "filename": "src/transformers/models/clap/modeling_clap.py",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fclap%2Fmodeling_clap.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fclap%2Fmodeling_clap.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclap%2Fmodeling_clap.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1400,7 +1400,7 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class ClapPreTrainedModel(PreTrainedModel):\n-    config_class = ClapConfig\n+    config: ClapConfig\n     base_model_prefix = \"clap\"\n     supports_gradient_checkpointing = False\n \n@@ -1428,7 +1428,7 @@ def _init_weights(self, module):\n \n \n class ClapAudioModel(ClapPreTrainedModel):\n-    config_class = ClapAudioConfig\n+    config: ClapAudioConfig\n     main_input_name = \"input_features\"\n \n     def __init__(self, config: ClapAudioConfig):\n@@ -1501,7 +1501,7 @@ def forward(\n     \"\"\"\n )\n class ClapTextModel(ClapPreTrainedModel):\n-    config_class = ClapTextConfig\n+    config: ClapTextConfig\n \n     def __init__(self, config, add_pooling_layer=True):\n         r\"\"\"\n@@ -1611,7 +1611,7 @@ def forward(\n \n @auto_docstring\n class ClapModel(ClapPreTrainedModel):\n-    config_class = ClapConfig\n+    config: ClapConfig\n \n     def __init__(self, config: ClapConfig):\n         super().__init__(config)\n@@ -1843,7 +1843,7 @@ def forward(\n \n @auto_docstring\n class ClapTextModelWithProjection(ClapPreTrainedModel):\n-    config_class = ClapTextConfig\n+    config: ClapTextConfig\n \n     def __init__(self, config: ClapTextConfig):\n         super().__init__(config)\n@@ -1908,7 +1908,7 @@ def forward(\n \n @auto_docstring\n class ClapAudioModelWithProjection(ClapPreTrainedModel):\n-    config_class = ClapAudioConfig\n+    config: ClapAudioConfig\n     main_input_name = \"input_features\"\n \n     def __init__(self, config: ClapAudioConfig):"
        },
        {
            "sha": "a187bdaa635e0a7e7a51d402e1ae41c01b2a927f",
            "filename": "src/transformers/models/clip/modeling_clip.py",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fclip%2Fmodeling_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fclip%2Fmodeling_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclip%2Fmodeling_clip.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -424,7 +424,7 @@ def forward(\n \n @auto_docstring\n class CLIPPreTrainedModel(PreTrainedModel):\n-    config_class = CLIPConfig\n+    config: CLIPConfig\n     base_model_prefix = \"clip\"\n     supports_gradient_checkpointing = True\n     _supports_sdpa = True\n@@ -670,7 +670,7 @@ def forward(\n     \"\"\"\n )\n class CLIPTextModel(CLIPPreTrainedModel):\n-    config_class = CLIPTextConfig\n+    config: CLIPTextConfig\n \n     _no_split_modules = [\"CLIPTextEmbeddings\", \"CLIPEncoderLayer\"]\n \n@@ -775,7 +775,7 @@ def forward(\n     \"\"\"\n )\n class CLIPVisionModel(CLIPPreTrainedModel):\n-    config_class = CLIPVisionConfig\n+    config: CLIPVisionConfig\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [\"CLIPEncoderLayer\"]\n \n@@ -828,7 +828,7 @@ def forward(\n \n @auto_docstring\n class CLIPModel(CLIPPreTrainedModel):\n-    config_class = CLIPConfig\n+    config: CLIPConfig\n     _no_split_modules = [\"CLIPTextEmbeddings\", \"CLIPEncoderLayer\", \"CLIPVisionEmbeddings\"]\n \n     def __init__(self, config: CLIPConfig):\n@@ -1050,7 +1050,7 @@ def forward(\n \n @auto_docstring\n class CLIPTextModelWithProjection(CLIPPreTrainedModel):\n-    config_class = CLIPTextConfig\n+    config: CLIPTextConfig\n \n     _no_split_modules = [\"CLIPTextEmbeddings\", \"CLIPEncoderLayer\"]\n \n@@ -1116,7 +1116,7 @@ def forward(\n \n @auto_docstring\n class CLIPVisionModelWithProjection(CLIPPreTrainedModel):\n-    config_class = CLIPVisionConfig\n+    config: CLIPVisionConfig\n     main_input_name = \"pixel_values\"\n \n     def __init__(self, config: CLIPVisionConfig):"
        },
        {
            "sha": "46c7b1fcf2306fd683b08acf595eec73c11ef309",
            "filename": "src/transformers/models/clipseg/modeling_clipseg.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fclipseg%2Fmodeling_clipseg.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fclipseg%2Fmodeling_clipseg.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclipseg%2Fmodeling_clipseg.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -428,7 +428,7 @@ def forward(\n \n @auto_docstring\n class CLIPSegPreTrainedModel(PreTrainedModel):\n-    config_class = CLIPSegConfig\n+    config: CLIPSegConfig\n     base_model_prefix = \"clip\"\n     supports_gradient_checkpointing = True\n \n@@ -653,7 +653,7 @@ def forward(\n \n \n class CLIPSegTextModel(CLIPSegPreTrainedModel):\n-    config_class = CLIPSegTextConfig\n+    config: CLIPSegTextConfig\n \n     _no_split_modules = [\"CLIPSegTextEmbeddings\", \"CLIPSegEncoderLayer\"]\n \n@@ -757,7 +757,7 @@ def forward(\n \n \n class CLIPSegVisionModel(CLIPSegPreTrainedModel):\n-    config_class = CLIPSegVisionConfig\n+    config: CLIPSegVisionConfig\n     main_input_name = \"pixel_values\"\n \n     def __init__(self, config: CLIPSegVisionConfig):\n@@ -809,7 +809,7 @@ def forward(\n \n @auto_docstring\n class CLIPSegModel(CLIPSegPreTrainedModel):\n-    config_class = CLIPSegConfig\n+    config: CLIPSegConfig\n \n     def __init__(self, config: CLIPSegConfig):\n         super().__init__(config)\n@@ -1200,7 +1200,7 @@ def forward(\n     \"\"\"\n )\n class CLIPSegForImageSegmentation(CLIPSegPreTrainedModel):\n-    config_class = CLIPSegConfig\n+    config: CLIPSegConfig\n \n     def __init__(self, config: CLIPSegConfig):\n         super().__init__(config)"
        },
        {
            "sha": "bf55aa402bc5014b158e2e0d9b52e2cab74bc5bc",
            "filename": "src/transformers/models/clvp/modeling_clvp.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fclvp%2Fmodeling_clvp.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fclvp%2Fmodeling_clvp.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclvp%2Fmodeling_clvp.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -783,7 +783,7 @@ def forward(\n \n @auto_docstring\n class ClvpPreTrainedModel(PreTrainedModel):\n-    config_class = ClvpConfig\n+    config: ClvpConfig\n     base_model_prefix = \"clvp\"\n     supports_gradient_checkpointing = True\n     _skip_keys_device_placement = \"past_key_values\"\n@@ -1434,7 +1434,7 @@ def forward(\n     \"\"\"\n )\n class ClvpModelForConditionalGeneration(ClvpPreTrainedModel, GenerationMixin):\n-    config_class = ClvpConfig\n+    config: ClvpConfig\n \n     def __init__(self, config: ClvpConfig):\n         super().__init__(config)"
        },
        {
            "sha": "29798287dd55c3181194c6fc0f38389e243f445b",
            "filename": "src/transformers/models/codegen/modeling_codegen.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcodegen%2Fmodeling_codegen.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcodegen%2Fmodeling_codegen.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcodegen%2Fmodeling_codegen.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -281,7 +281,7 @@ def forward(\n \n @auto_docstring\n class CodeGenPreTrainedModel(PreTrainedModel):\n-    config_class = CodeGenConfig\n+    config: CodeGenConfig\n     base_model_prefix = \"transformer\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"CodeGenBlock\"]"
        },
        {
            "sha": "0180161e13117806898e163ccbcc1522b81d9bc8",
            "filename": "src/transformers/models/cohere/modeling_cohere.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcohere%2Fmodeling_cohere.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcohere%2Fmodeling_cohere.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere%2Fmodeling_cohere.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -336,7 +336,7 @@ def forward(\n \n @auto_docstring\n class CoherePreTrainedModel(PreTrainedModel):\n-    config_class = CohereConfig\n+    config: CohereConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"CohereDecoderLayer\"]"
        },
        {
            "sha": "a05155169033b87af34b2c3e5fd51002bdbbd7b1",
            "filename": "src/transformers/models/cohere2/modeling_cohere2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodeling_cohere2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodeling_cohere2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodeling_cohere2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -313,7 +313,7 @@ def forward(\n \n @auto_docstring\n class Cohere2PreTrainedModel(PreTrainedModel):\n-    config_class = Cohere2Config\n+    config: Cohere2Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Cohere2DecoderLayer\"]"
        },
        {
            "sha": "369b2ecae3ca41249fb6b6bad59ef3d755f35b70",
            "filename": "src/transformers/models/cohere2/modular_cohere2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodular_cohere2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodular_cohere2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodular_cohere2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -377,7 +377,7 @@ def forward(\n \n \n class Cohere2PreTrainedModel(CoherePreTrainedModel):\n-    config_class = Cohere2Config\n+    config: Cohere2Config\n \n \n class Cohere2Model(Gemma2Model):"
        },
        {
            "sha": "63ce8975e8e0a39c08e21fac063cf7346a079439",
            "filename": "src/transformers/models/colpali/modeling_colpali.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcolpali%2Fmodeling_colpali.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcolpali%2Fmodeling_colpali.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcolpali%2Fmodeling_colpali.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -30,7 +30,7 @@\n \n @auto_docstring\n class ColPaliPreTrainedModel(PreTrainedModel):\n-    config_class = ColPaliConfig\n+    config: ColPaliConfig\n     base_model_prefix = \"model\"\n     _no_split_modules = []\n "
        },
        {
            "sha": "6cbdaab123b3cffcbfb8e5231afd4c734649f229",
            "filename": "src/transformers/models/colqwen2/modeling_colqwen2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcolqwen2%2Fmodeling_colqwen2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcolqwen2%2Fmodeling_colqwen2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcolqwen2%2Fmodeling_colqwen2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -38,7 +38,7 @@\n \n @auto_docstring\n class ColQwen2PreTrainedModel(PreTrainedModel):\n-    config_class = ColQwen2Config\n+    config: ColQwen2Config\n     base_model_prefix = \"model\"\n     _no_split_modules = []\n     _supports_flash_attn = True"
        },
        {
            "sha": "25eacb959aefb479447128187688e0592d574518",
            "filename": "src/transformers/models/conditional_detr/modeling_conditional_detr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fconditional_detr%2Fmodeling_conditional_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fconditional_detr%2Fmodeling_conditional_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fconditional_detr%2Fmodeling_conditional_detr.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -956,7 +956,7 @@ def forward(self, x):\n @auto_docstring\n # Copied from transformers.models.detr.modeling_detr.DetrPreTrainedModel with Detr->ConditionalDetr\n class ConditionalDetrPreTrainedModel(PreTrainedModel):\n-    config_class = ConditionalDetrConfig\n+    config: ConditionalDetrConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [r\"ConditionalDetrConvEncoder\", r\"ConditionalDetrEncoderLayer\", r\"ConditionalDetrDecoderLayer\"]"
        },
        {
            "sha": "130cf183849ecf34170bd68e5e3b8370ba8ce8d5",
            "filename": "src/transformers/models/convbert/modeling_convbert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fconvbert%2Fmodeling_convbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fconvbert%2Fmodeling_convbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fconvbert%2Fmodeling_convbert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -232,7 +232,7 @@ def forward(\n \n @auto_docstring\n class ConvBertPreTrainedModel(PreTrainedModel):\n-    config_class = ConvBertConfig\n+    config: ConvBertConfig\n     load_tf_weights = load_tf_weights_in_convbert\n     base_model_prefix = \"convbert\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "5921aabc0f65e14c742e25d4ed65a798e6446c63",
            "filename": "src/transformers/models/convnext/modeling_convnext.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fconvnext%2Fmodeling_convnext.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fconvnext%2Fmodeling_convnext.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fconvnext%2Fmodeling_convnext.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -253,7 +253,7 @@ def forward(\n \n @auto_docstring\n class ConvNextPreTrainedModel(PreTrainedModel):\n-    config_class = ConvNextConfig\n+    config: ConvNextConfig\n     base_model_prefix = \"convnext\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [\"ConvNextLayer\"]"
        },
        {
            "sha": "b9d57b87e9f3f90a45fe080e330d729a98723b9e",
            "filename": "src/transformers/models/convnextv2/modeling_convnextv2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fconvnextv2%2Fmodeling_convnextv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fconvnextv2%2Fmodeling_convnextv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fconvnextv2%2Fmodeling_convnextv2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -273,7 +273,7 @@ def forward(\n \n @auto_docstring\n class ConvNextV2PreTrainedModel(PreTrainedModel):\n-    config_class = ConvNextV2Config\n+    config: ConvNextV2Config\n     base_model_prefix = \"convnextv2\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [\"ConvNextV2Layer\"]"
        },
        {
            "sha": "e1b1c33276fc2b0969675fb5d73767e4eb7de6ee",
            "filename": "src/transformers/models/cpmant/modeling_cpmant.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcpmant%2Fmodeling_cpmant.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcpmant%2Fmodeling_cpmant.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcpmant%2Fmodeling_cpmant.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -523,7 +523,7 @@ def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> to\n \n @auto_docstring\n class CpmAntPreTrainedModel(PreTrainedModel):\n-    config_class = CpmAntConfig\n+    config: CpmAntConfig\n     base_model_prefix = \"cpmant\"\n \n     def _init_weights(self, module):"
        },
        {
            "sha": "91b3ff39875bd6b2572c4d5ec03a2c56d835d514",
            "filename": "src/transformers/models/csm/modeling_csm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodeling_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodeling_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodeling_csm.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -361,7 +361,7 @@ def forward(\n )\n @auto_docstring\n class CsmPreTrainedModel(PreTrainedModel):\n-    config_class = CsmConfig\n+    config: CsmConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"CsmDecoderLayer\"]\n@@ -398,7 +398,7 @@ def _init_weights(self, module):\n \n @auto_docstring\n class CsmDepthDecoderModel(CsmPreTrainedModel):\n-    config_class = CsmDepthDecoderConfig\n+    config: CsmDepthDecoderConfig\n \n     def __init__(self, config):\n         super().__init__(config)"
        },
        {
            "sha": "e1bc64fd6c3cf906a35c42ee5db8bb15c731f212",
            "filename": "src/transformers/models/csm/modular_csm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodular_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodular_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcsm%2Fmodular_csm.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -124,7 +124,7 @@ class CsmDecoderLayer(LlamaDecoderLayer):\n )\n @auto_docstring\n class CsmPreTrainedModel(PreTrainedModel):\n-    config_class = CsmConfig\n+    config: CsmConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"CsmDecoderLayer\"]\n@@ -161,7 +161,7 @@ def _init_weights(self, module):\n \n @auto_docstring\n class CsmDepthDecoderModel(LlamaModel, CsmPreTrainedModel):\n-    config_class = CsmDepthDecoderConfig\n+    config: CsmDepthDecoderConfig\n \n     def __init__(self, config):\n         super().__init__(config)"
        },
        {
            "sha": "675ef96592c59ab6975d507baeb86cf02e16fad0",
            "filename": "src/transformers/models/ctrl/modeling_ctrl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fctrl%2Fmodeling_ctrl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fctrl%2Fmodeling_ctrl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fctrl%2Fmodeling_ctrl.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -210,7 +210,7 @@ def forward(\n \n @auto_docstring\n class CTRLPreTrainedModel(PreTrainedModel):\n-    config_class = CTRLConfig\n+    config: CTRLConfig\n     base_model_prefix = \"transformer\"\n \n     def _init_weights(self, module):"
        },
        {
            "sha": "e838ffb3cd41bd27f606caeb116df83976063c64",
            "filename": "src/transformers/models/cvt/modeling_cvt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcvt%2Fmodeling_cvt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fcvt%2Fmodeling_cvt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcvt%2Fmodeling_cvt.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -509,7 +509,7 @@ def forward(self, pixel_values, output_hidden_states=False, return_dict=True):\n \n @auto_docstring\n class CvtPreTrainedModel(PreTrainedModel):\n-    config_class = CvtConfig\n+    config: CvtConfig\n     base_model_prefix = \"cvt\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [\"CvtLayer\"]"
        },
        {
            "sha": "76726a651270e783842cd369c16f01003b8631bb",
            "filename": "src/transformers/models/d_fine/modeling_d_fine.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fd_fine%2Fmodeling_d_fine.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fd_fine%2Fmodeling_d_fine.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fd_fine%2Fmodeling_d_fine.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -882,7 +882,7 @@ def _get_clones(partial_module, N):\n \n @auto_docstring\n class DFinePreTrainedModel(PreTrainedModel):\n-    config_class = DFineConfig\n+    config: DFineConfig\n     base_model_prefix = \"d_fine\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [r\"DFineHybridEncoder\", r\"DFineDecoderLayer\"]"
        },
        {
            "sha": "d9060213f564e9709846cad22140e27463768522",
            "filename": "src/transformers/models/dab_detr/modeling_dab_detr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdab_detr%2Fmodeling_dab_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdab_detr%2Fmodeling_dab_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdab_detr%2Fmodeling_dab_detr.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -809,7 +809,7 @@ def forward(self, input_tensor):\n # Modified from transformers.models.detr.modeling_detr.DetrPreTrainedModel with Detr->DabDetr\n @auto_docstring\n class DabDetrPreTrainedModel(PreTrainedModel):\n-    config_class = DabDetrConfig\n+    config: DabDetrConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [r\"DabDetrConvEncoder\", r\"DabDetrEncoderLayer\", r\"DabDetrDecoderLayer\"]"
        },
        {
            "sha": "03227e72cf8cdff48f19c9d66acddc3e869bdf37",
            "filename": "src/transformers/models/dac/modeling_dac.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdac%2Fmodeling_dac.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdac%2Fmodeling_dac.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdac%2Fmodeling_dac.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -472,7 +472,7 @@ def forward(self, hidden_state):\n \n @auto_docstring\n class DacPreTrainedModel(PreTrainedAudioTokenizerBase):\n-    config_class = DacConfig\n+    config: DacConfig\n     base_model_prefix = \"dac\"\n     main_input_name = \"input_values\"\n "
        },
        {
            "sha": "622e28b0085924485dd8405ad27c866a29eaa126",
            "filename": "src/transformers/models/data2vec/modeling_data2vec_audio.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_audio.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -500,7 +500,7 @@ def forward(self, hidden_states):\n \n @auto_docstring\n class Data2VecAudioPreTrainedModel(PreTrainedModel):\n-    config_class = Data2VecAudioConfig\n+    config: Data2VecAudioConfig\n     base_model_prefix = \"data2vec_audio\"\n     main_input_name = \"input_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "32afbfc32019c26de1158e847b13ad502d881835",
            "filename": "src/transformers/models/data2vec/modeling_data2vec_text.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_text.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -570,7 +570,7 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class Data2VecTextPreTrainedModel(PreTrainedModel):\n-    config_class = Data2VecTextConfig\n+    config: Data2VecTextConfig\n     base_model_prefix = \"data2vec_text\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Data2VecTextForTextEmbeddings\", \"Data2VecTextLayer\"]"
        },
        {
            "sha": "48c103cf648e7a50eca1c3407addf0f1ba2d52c2",
            "filename": "src/transformers/models/data2vec/modeling_data2vec_vision.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_vision.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -736,7 +736,7 @@ def forward(\n @auto_docstring\n # Copied from transformers.models.beit.modeling_beit.BeitPreTrainedModel with Beit->Data2VecVision,beit->data2vec_vision\n class Data2VecVisionPreTrainedModel(PreTrainedModel):\n-    config_class = Data2VecVisionConfig\n+    config: Data2VecVisionConfig\n     base_model_prefix = \"data2vec_vision\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "0be5019c016cdb2596aff65cd340dffc91b123f8",
            "filename": "src/transformers/models/data2vec/modular_data2vec_audio.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodular_data2vec_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodular_data2vec_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodular_data2vec_audio.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -135,7 +135,7 @@ class Data2VecAudioAdapter(Wav2Vec2Adapter):\n \n \n class Data2VecAudioPreTrainedModel(PreTrainedModel, Wav2Vec2PreTrainedModel):\n-    config_class = Data2VecAudioConfig\n+    config: Data2VecAudioConfig\n     base_model_prefix = \"data2vec_audio\"\n     main_input_name = \"input_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "86b4944f08f19a842558802ce733b21e5ef2be25",
            "filename": "src/transformers/models/dbrx/modeling_dbrx.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodeling_dbrx.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodeling_dbrx.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdbrx%2Fmodeling_dbrx.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -802,7 +802,7 @@ def forward(\n \n @auto_docstring\n class DbrxPreTrainedModel(PreTrainedModel):\n-    config_class = DbrxConfig\n+    config: DbrxConfig\n     base_model_prefix = \"transformer\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"DbrxBlock\"]"
        },
        {
            "sha": "0e298f52297ab314b461e74cb37b360fef08a774",
            "filename": "src/transformers/models/deberta/modeling_deberta.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeberta%2Fmodeling_deberta.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeberta%2Fmodeling_deberta.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeberta%2Fmodeling_deberta.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -610,7 +610,7 @@ def forward(\n \n @auto_docstring\n class DebertaPreTrainedModel(PreTrainedModel):\n-    config_class = DebertaConfig\n+    config: DebertaConfig\n     base_model_prefix = \"deberta\"\n     _keys_to_ignore_on_load_unexpected = [\"position_embeddings\"]\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "047d4b3acd25966ed17f3a6b130b74dd6a1bc214",
            "filename": "src/transformers/models/deberta_v2/modeling_deberta_v2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeberta_v2%2Fmodeling_deberta_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeberta_v2%2Fmodeling_deberta_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeberta_v2%2Fmodeling_deberta_v2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -690,7 +690,7 @@ def forward(\n \n @auto_docstring\n class DebertaV2PreTrainedModel(PreTrainedModel):\n-    config_class = DebertaV2Config\n+    config: DebertaV2Config\n     base_model_prefix = \"deberta\"\n     _keys_to_ignore_on_load_unexpected = [\"position_embeddings\"]\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "1b33296d7dde530f24b75b56d750aeac21373814",
            "filename": "src/transformers/models/decision_transformer/modeling_decision_transformer.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdecision_transformer%2Fmodeling_decision_transformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdecision_transformer%2Fmodeling_decision_transformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdecision_transformer%2Fmodeling_decision_transformer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -447,7 +447,7 @@ def forward(\n \n @auto_docstring\n class DecisionTransformerGPT2PreTrainedModel(PreTrainedModel):\n-    config_class = DecisionTransformerConfig\n+    config: DecisionTransformerConfig\n     load_tf_weights = load_tf_weights_in_gpt2\n     base_model_prefix = \"transformer\"\n     is_parallelizable = True\n@@ -740,7 +740,7 @@ class DecisionTransformerPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = DecisionTransformerConfig\n+    config: DecisionTransformerConfig\n     base_model_prefix = \"decision_transformer\"\n     main_input_name = \"states\"\n     supports_gradient_checkpointing = False"
        },
        {
            "sha": "3794a392fd8af9a145f312b02168bc7f820ead4c",
            "filename": "src/transformers/models/deepseek_v2/modeling_deepseek_v2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -450,7 +450,7 @@ def forward(\n \n @auto_docstring\n class DeepseekV2PreTrainedModel(PreTrainedModel):\n-    config_class = DeepseekV2Config\n+    config: DeepseekV2Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"DeepseekV2DecoderLayer\"]"
        },
        {
            "sha": "9f10d63044796cb4017f0c8038da57bd2947981c",
            "filename": "src/transformers/models/deepseek_v3/modeling_deepseek_v3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -489,7 +489,7 @@ def forward(\n \n @auto_docstring\n class DeepseekV3PreTrainedModel(PreTrainedModel):\n-    config_class = DeepseekV3Config\n+    config: DeepseekV3Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"DeepseekV3DecoderLayer\"]"
        },
        {
            "sha": "db74c715b56517e15b65f34c2c0df8191d24edf8",
            "filename": "src/transformers/models/deformable_detr/modeling_deformable_detr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fmodeling_deformable_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fmodeling_deformable_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fmodeling_deformable_detr.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -916,7 +916,7 @@ def forward(\n \n @auto_docstring\n class DeformableDetrPreTrainedModel(PreTrainedModel):\n-    config_class = DeformableDetrConfig\n+    config: DeformableDetrConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "7499b6d7aafecc5b2047e3ebb25ad79eac8b7c97",
            "filename": "src/transformers/models/deit/modeling_deit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -447,7 +447,7 @@ def forward(\n \n @auto_docstring\n class DeiTPreTrainedModel(PreTrainedModel):\n-    config_class = DeiTConfig\n+    config: DeiTConfig\n     base_model_prefix = \"deit\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "e109b8493899459cc7a97d5e9ad8a0256a429ba3",
            "filename": "src/transformers/models/deprecated/deta/modeling_deta.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fdeta%2Fmodeling_deta.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fdeta%2Fmodeling_deta.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fdeta%2Fmodeling_deta.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1022,7 +1022,7 @@ def forward(\n \n \n class DetaPreTrainedModel(PreTrainedModel):\n-    config_class = DetaConfig\n+    config: DetaConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [r\"DetaBackboneWithPositionalEncodings\", r\"DetaEncoderLayer\", r\"DetaDecoderLayer\"]"
        },
        {
            "sha": "7d75e45dbc85b5d69a31dfe434288f0e46175868",
            "filename": "src/transformers/models/deprecated/efficientformer/modeling_efficientformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fefficientformer%2Fmodeling_efficientformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fefficientformer%2Fmodeling_efficientformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fefficientformer%2Fmodeling_efficientformer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -500,7 +500,7 @@ class EfficientFormerPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = EfficientFormerConfig\n+    config: EfficientFormerConfig\n     base_model_prefix = \"efficientformer\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = False"
        },
        {
            "sha": "69e5e61d3c3b686e6754206ebf590aa50126ca73",
            "filename": "src/transformers/models/deprecated/ernie_m/modeling_ernie_m.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fernie_m%2Fmodeling_ernie_m.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fernie_m%2Fmodeling_ernie_m.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fernie_m%2Fmodeling_ernie_m.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -400,7 +400,7 @@ class ErnieMPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = ErnieMConfig\n+    config: ErnieMConfig\n     base_model_prefix = \"ernie_m\"\n \n     def _init_weights(self, module):"
        },
        {
            "sha": "10664a8fef7d606aeb47c67865c9a3bdbd2f4035",
            "filename": "src/transformers/models/deprecated/gptsan_japanese/modeling_gptsan_japanese.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fgptsan_japanese%2Fmodeling_gptsan_japanese.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fgptsan_japanese%2Fmodeling_gptsan_japanese.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fgptsan_japanese%2Fmodeling_gptsan_japanese.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -673,7 +673,7 @@ class GPTSanJapanesePreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = GPTSanJapaneseConfig\n+    config: GPTSanJapaneseConfig\n     base_model_prefix = \"gptsan_japanese\"\n     supports_gradient_checkpointing = False\n     _no_split_modules = [\"GPTSanJapaneseBlock\"]"
        },
        {
            "sha": "b3e8ea742c8dabd4bd13e34ea84fa60547fc0645",
            "filename": "src/transformers/models/deprecated/graphormer/modeling_graphormer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fgraphormer%2Fmodeling_graphormer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fgraphormer%2Fmodeling_graphormer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fgraphormer%2Fmodeling_graphormer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -704,7 +704,7 @@ class GraphormerPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = GraphormerConfig\n+    config: GraphormerConfig\n     base_model_prefix = \"graphormer\"\n     main_input_name_nodes = \"input_nodes\"\n     main_input_name_edges = \"input_edges\""
        },
        {
            "sha": "4dfd1c69243b543027bab8e5553036242b1ecdd0",
            "filename": "src/transformers/models/deprecated/jukebox/modeling_jukebox.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fjukebox%2Fmodeling_jukebox.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fjukebox%2Fmodeling_jukebox.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fjukebox%2Fmodeling_jukebox.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -598,7 +598,7 @@ def forward(self, input_audio):\n     JUKEBOX_START_DOCSTRING,\n )\n class JukeboxVQVAE(PreTrainedModel):\n-    config_class = JukeboxVQVAEConfig\n+    config: JukeboxVQVAEConfig\n     base_model_prefix = \"vqvae\"\n \n     def _init_weights(self, module):\n@@ -1788,7 +1788,7 @@ class JukeboxPrior(PreTrainedModel):\n             the vqvae module to avoid getting the parameters.\n     \"\"\"\n \n-    config_class = JukeboxPriorConfig\n+    config: JukeboxPriorConfig\n \n     def _init_weights(self, module):\n         init_scale = self.config.init_scale\n@@ -2264,7 +2264,7 @@ class JukeboxPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = JukeboxConfig\n+    config: JukeboxConfig\n     base_model_prefix = \"jukebox\"\n     supports_gradient_checkpointing = False\n "
        },
        {
            "sha": "adaf4c1a70bc74949e4e003b288eb886ba8e7d80",
            "filename": "src/transformers/models/deprecated/mctct/modeling_mctct.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fmctct%2Fmodeling_mctct.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fmctct%2Fmodeling_mctct.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fmctct%2Fmodeling_mctct.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -423,7 +423,7 @@ class MCTCTPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = MCTCTConfig\n+    config: MCTCTConfig\n     base_model_prefix = \"mctct\"\n     main_input_name = \"input_features\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "85f314aeeab50b4ac3904e11e3048856197d066e",
            "filename": "src/transformers/models/deprecated/mega/modeling_mega.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fmega%2Fmodeling_mega.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fmega%2Fmodeling_mega.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fmega%2Fmodeling_mega.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1329,7 +1329,7 @@ class MegaPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = MegaConfig\n+    config: MegaConfig\n     base_model_prefix = \"mega\"\n     supports_gradient_checkpointing = False\n     _no_split_modules = [\"MegaMovingAverageGatedAttention\"]"
        },
        {
            "sha": "0a951623bc7cfa0761f2a66c2c0cb65f34ff6324",
            "filename": "src/transformers/models/deprecated/nat/modeling_nat.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fnat%2Fmodeling_nat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fnat%2Fmodeling_nat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fnat%2Fmodeling_nat.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -615,7 +615,7 @@ class NatPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = NatConfig\n+    config: NatConfig\n     base_model_prefix = \"nat\"\n     main_input_name = \"pixel_values\"\n "
        },
        {
            "sha": "692d5dd092ff6980968dd338ab6516a4dbfe94a8",
            "filename": "src/transformers/models/deprecated/nezha/modeling_nezha.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fnezha%2Fmodeling_nezha.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fnezha%2Fmodeling_nezha.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fnezha%2Fmodeling_nezha.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -699,7 +699,7 @@ class NezhaPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = NezhaConfig\n+    config: NezhaConfig\n     load_tf_weights = load_tf_weights_in_nezha\n     base_model_prefix = \"nezha\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "66efbe1c2419fe0f762199fbae7fc0d08931c394",
            "filename": "src/transformers/models/deprecated/open_llama/modeling_open_llama.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fopen_llama%2Fmodeling_open_llama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fopen_llama%2Fmodeling_open_llama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fopen_llama%2Fmodeling_open_llama.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -431,7 +431,7 @@ def forward(\n     OPEN_LLAMA_START_DOCSTRING,\n )\n class OpenLlamaPreTrainedModel(PreTrainedModel):\n-    config_class = OpenLlamaConfig\n+    config: OpenLlamaConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"OpenLlamaDecoderLayer\"]"
        },
        {
            "sha": "7245f44c34e745165087b0cf1774563bcdc28a7a",
            "filename": "src/transformers/models/deprecated/qdqbert/modeling_qdqbert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fqdqbert%2Fmodeling_qdqbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fqdqbert%2Fmodeling_qdqbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fqdqbert%2Fmodeling_qdqbert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -708,7 +708,7 @@ class QDQBertPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = QDQBertConfig\n+    config: QDQBertConfig\n     load_tf_weights = load_tf_weights_in_qdqbert\n     base_model_prefix = \"bert\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "767bcf5a9c71678e04e169267b19026482d99edb",
            "filename": "src/transformers/models/deprecated/realm/modeling_realm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Frealm%2Fmodeling_realm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Frealm%2Fmodeling_realm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Frealm%2Fmodeling_realm.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -940,7 +940,7 @@ class RealmPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = RealmConfig\n+    config: RealmConfig\n     load_tf_weights = load_tf_weights_in_realm\n     base_model_prefix = \"realm\"\n "
        },
        {
            "sha": "06806e8e6d0bb01fa31c6849ccb23f3e29bf74aa",
            "filename": "src/transformers/models/deprecated/retribert/modeling_retribert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fretribert%2Fmodeling_retribert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fretribert%2Fmodeling_retribert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fretribert%2Fmodeling_retribert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -39,7 +39,7 @@ class RetriBertPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = RetriBertConfig\n+    config: RetriBertConfig\n     load_tf_weights = None\n     base_model_prefix = \"retribert\"\n "
        },
        {
            "sha": "1012c9537a6e27c605b17c5d59cea2dcb1594018",
            "filename": "src/transformers/models/deprecated/speech_to_text_2/modeling_speech_to_text_2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fspeech_to_text_2%2Fmodeling_speech_to_text_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fspeech_to_text_2%2Fmodeling_speech_to_text_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fspeech_to_text_2%2Fmodeling_speech_to_text_2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -385,7 +385,7 @@ def forward(\n \n \n class Speech2Text2PreTrainedModel(PreTrainedModel):\n-    config_class = Speech2Text2Config\n+    config: Speech2Text2Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n "
        },
        {
            "sha": "cf49223b8b5d2c2341e99da87148a09540e492f2",
            "filename": "src/transformers/models/deprecated/trajectory_transformer/modeling_trajectory_transformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftrajectory_transformer%2Fmodeling_trajectory_transformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftrajectory_transformer%2Fmodeling_trajectory_transformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftrajectory_transformer%2Fmodeling_trajectory_transformer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -153,7 +153,7 @@ class TrajectoryTransformerPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = TrajectoryTransformerConfig\n+    config: TrajectoryTransformerConfig\n     load_tf_weights = load_tf_weights_in_trajectory_transformer\n     base_model_prefix = \"trajectory_transformer\"\n     main_input_name = \"trajectories\""
        },
        {
            "sha": "9c469036f23251f5a29078c95799f6bc802a7c4f",
            "filename": "src/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftransfo_xl%2Fmodeling_transfo_xl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftransfo_xl%2Fmodeling_transfo_xl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftransfo_xl%2Fmodeling_transfo_xl.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -458,7 +458,7 @@ class TransfoXLPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = TransfoXLConfig\n+    config: TransfoXLConfig\n     load_tf_weights = load_tf_weights_in_transfo_xl\n     base_model_prefix = \"transformer\"\n "
        },
        {
            "sha": "5f34083ac2ff5401fb417e556ee5892b879861ac",
            "filename": "src/transformers/models/deprecated/tvlt/modeling_tvlt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftvlt%2Fmodeling_tvlt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftvlt%2Fmodeling_tvlt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Ftvlt%2Fmodeling_tvlt.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -572,7 +572,7 @@ class TvltPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = TvltConfig\n+    config: TvltConfig\n     base_model_prefix = \"tvlt\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "7bbae4edb1a259682222004997b96734ab8db2ef",
            "filename": "src/transformers/models/deprecated/van/modeling_van.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvan%2Fmodeling_van.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvan%2Fmodeling_van.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvan%2Fmodeling_van.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -361,7 +361,7 @@ class VanPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = VanConfig\n+    config: VanConfig\n     base_model_prefix = \"van\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "7d1c22301defaafe9f0428f616ed3fa482a9a072",
            "filename": "src/transformers/models/deprecated/vit_hybrid/modeling_vit_hybrid.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvit_hybrid%2Fmodeling_vit_hybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvit_hybrid%2Fmodeling_vit_hybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvit_hybrid%2Fmodeling_vit_hybrid.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -483,7 +483,7 @@ class ViTHybridPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = ViTHybridConfig\n+    config: ViTHybridConfig\n     base_model_prefix = \"vit\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "9912cca22fe9b70b4b38926e0b079b52a8a540d7",
            "filename": "src/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fxlm_prophetnet%2Fmodeling_xlm_prophetnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fxlm_prophetnet%2Fmodeling_xlm_prophetnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fxlm_prophetnet%2Fmodeling_xlm_prophetnet.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -540,7 +540,7 @@ class XLMProphetNetDecoderLMOutput(ModelOutput):\n \n \n class XLMProphetNetPreTrainedModel(PreTrainedModel):\n-    config_class = XLMProphetNetConfig\n+    config: XLMProphetNetConfig\n     base_model_prefix = \"prophetnet\"\n     supports_gradient_checkpointing = True\n "
        },
        {
            "sha": "6fb3b23cd37ca4e36e9bf792981c1828a499b8a4",
            "filename": "src/transformers/models/depth_anything/modeling_depth_anything.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdepth_anything%2Fmodeling_depth_anything.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdepth_anything%2Fmodeling_depth_anything.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdepth_anything%2Fmodeling_depth_anything.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -211,7 +211,7 @@ def forward(self, hidden_states, size=None):\n # avoiding sdpa and flash_attn_2 support, it's done in the backend\n @auto_docstring\n class DepthAnythingPreTrainedModel(PreTrainedModel):\n-    config_class = DepthAnythingConfig\n+    config: DepthAnythingConfig\n     base_model_prefix = \"depth_anything\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "f894a6d8ff4eed12122aecb3d4acd94964150219",
            "filename": "src/transformers/models/depth_pro/modeling_depth_pro.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdepth_pro%2Fmodeling_depth_pro.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdepth_pro%2Fmodeling_depth_pro.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdepth_pro%2Fmodeling_depth_pro.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -607,7 +607,7 @@ def forward(self, features: list[torch.Tensor]) -> list[torch.Tensor]:\n \n @auto_docstring\n class DepthProPreTrainedModel(PreTrainedModel):\n-    config_class = DepthProConfig\n+    config: DepthProConfig\n     base_model_prefix = \"depth_pro\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "d2a205fb21123cedb65bd8d7651ed4cac243b9b4",
            "filename": "src/transformers/models/detr/modeling_detr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdetr%2Fmodeling_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdetr%2Fmodeling_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdetr%2Fmodeling_detr.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -717,7 +717,7 @@ def forward(\n \n @auto_docstring\n class DetrPreTrainedModel(PreTrainedModel):\n-    config_class = DetrConfig\n+    config: DetrConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [r\"DetrConvEncoder\", r\"DetrEncoderLayer\", r\"DetrDecoderLayer\"]"
        },
        {
            "sha": "2bf05cf683cef2c5ff90ab59f5c67f3f1e640216",
            "filename": "src/transformers/models/dia/modeling_dia.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdia%2Fmodeling_dia.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdia%2Fmodeling_dia.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdia%2Fmodeling_dia.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -61,7 +61,7 @@\n \n @auto_docstring\n class DiaPreTrainedModel(PreTrainedModel):\n-    config_class = DiaConfig\n+    config: DiaConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _supports_flash_attn = True"
        },
        {
            "sha": "8c84d936c543e34744c3c4d0320b6b6e1b561c83",
            "filename": "src/transformers/models/dia/modular_dia.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdia%2Fmodular_dia.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdia%2Fmodular_dia.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdia%2Fmodular_dia.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -56,7 +56,7 @@\n \n @auto_docstring\n class DiaPreTrainedModel(PreTrainedModel):\n-    config_class = DiaConfig\n+    config: DiaConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _supports_flash_attn = True"
        },
        {
            "sha": "c97319622d37cc81c68ed6e3afbd76d9aba7dbe8",
            "filename": "src/transformers/models/diffllama/modeling_diffllama.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdiffllama%2Fmodeling_diffllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdiffllama%2Fmodeling_diffllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdiffllama%2Fmodeling_diffllama.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -525,7 +525,7 @@ def forward(\n \n @auto_docstring\n class DiffLlamaPreTrainedModel(PreTrainedModel):\n-    config_class = DiffLlamaConfig\n+    config: DiffLlamaConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"DiffLlamaDecoderLayer\"]"
        },
        {
            "sha": "916fc94a79589067c99bda9fe93178696cf8b436",
            "filename": "src/transformers/models/dinat/modeling_dinat.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdinat%2Fmodeling_dinat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdinat%2Fmodeling_dinat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinat%2Fmodeling_dinat.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -583,7 +583,7 @@ def forward(\n \n @auto_docstring\n class DinatPreTrainedModel(PreTrainedModel):\n-    config_class = DinatConfig\n+    config: DinatConfig\n     base_model_prefix = \"dinat\"\n     main_input_name = \"pixel_values\"\n "
        },
        {
            "sha": "5748cb91da4245079b5ce972ddc3be620caf5b6c",
            "filename": "src/transformers/models/dinov2/modeling_dinov2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -491,7 +491,7 @@ def forward(\n \n @auto_docstring\n class Dinov2PreTrainedModel(PreTrainedModel):\n-    config_class = Dinov2Config\n+    config: Dinov2Config\n     base_model_prefix = \"dinov2\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "69621a0c1ed030f2743ae358b723e6d61a507e7b",
            "filename": "src/transformers/models/dinov2_with_registers/modeling_dinov2_with_registers.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -509,7 +509,7 @@ def forward(\n \n @auto_docstring\n class Dinov2WithRegistersPreTrainedModel(PreTrainedModel):\n-    config_class = Dinov2WithRegistersConfig\n+    config: Dinov2WithRegistersConfig\n     base_model_prefix = \"dinov2_with_registers\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "c3b604d5666583c247d97c5a550ce9167733173d",
            "filename": "src/transformers/models/distilbert/modeling_distilbert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdistilbert%2Fmodeling_distilbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdistilbert%2Fmodeling_distilbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdistilbert%2Fmodeling_distilbert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -571,7 +571,7 @@ def forward(\n # INTERFACE FOR ENCODER AND TASK SPECIFIC MODEL #\n @auto_docstring\n class DistilBertPreTrainedModel(PreTrainedModel):\n-    config_class = DistilBertConfig\n+    config: DistilBertConfig\n     load_tf_weights = None\n     base_model_prefix = \"distilbert\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "63813fe3d10705a22b5fc8944282e3b635d03382",
            "filename": "src/transformers/models/doge/modeling_doge.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdoge%2Fmodeling_doge.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdoge%2Fmodeling_doge.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdoge%2Fmodeling_doge.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -486,7 +486,7 @@ def forward(\n \n @auto_docstring\n class DogePreTrainedModel(PreTrainedModel):\n-    config_class = DogeConfig\n+    config: DogeConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"DogeDecoderLayer\"]"
        },
        {
            "sha": "289844d0bff0f2501747bbdc037b1d51e4d9b07b",
            "filename": "src/transformers/models/donut/modeling_donut_swin.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdonut%2Fmodeling_donut_swin.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdonut%2Fmodeling_donut_swin.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdonut%2Fmodeling_donut_swin.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -826,7 +826,7 @@ def forward(\n @auto_docstring\n # Copied from transformers.models.swin.modeling_swin.SwinPreTrainedModel with Swin->DonutSwin,swin->donut\n class DonutSwinPreTrainedModel(PreTrainedModel):\n-    config_class = DonutSwinConfig\n+    config: DonutSwinConfig\n     base_model_prefix = \"donut\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "6a84d77a0575e826f2444ae305ccf164bcffe1b7",
            "filename": "src/transformers/models/dots1/modeling_dots1.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -409,7 +409,7 @@ def forward(\n \n @auto_docstring\n class Dots1PreTrainedModel(PreTrainedModel):\n-    config_class = Dots1Config\n+    config: Dots1Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Dots1DecoderLayer\"]"
        },
        {
            "sha": "f1ae00a02e07a0f3ee4c0ca064e7e9818568e605",
            "filename": "src/transformers/models/dpr/modeling_dpr.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdpr%2Fmodeling_dpr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdpr%2Fmodeling_dpr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdpr%2Fmodeling_dpr.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -246,7 +246,7 @@ class DPRPretrainedContextEncoder(DPRPreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = DPRConfig\n+    config: DPRConfig\n     load_tf_weights = None\n     base_model_prefix = \"ctx_encoder\"\n \n@@ -257,7 +257,7 @@ class DPRPretrainedQuestionEncoder(DPRPreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = DPRConfig\n+    config: DPRConfig\n     load_tf_weights = None\n     base_model_prefix = \"question_encoder\"\n \n@@ -268,7 +268,7 @@ class DPRPretrainedReader(DPRPreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = DPRConfig\n+    config: DPRConfig\n     load_tf_weights = None\n     base_model_prefix = \"span_predictor\"\n "
        },
        {
            "sha": "60692d9fa71d7c0cea64a4e8aad0ebeccb16af87",
            "filename": "src/transformers/models/dpt/modeling_dpt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -815,7 +815,7 @@ def forward(self, hidden_state, residual=None):\n \n @auto_docstring\n class DPTPreTrainedModel(PreTrainedModel):\n-    config_class = DPTConfig\n+    config: DPTConfig\n     base_model_prefix = \"dpt\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "814a2375acfd7481a35c7aa36bea6c777d56ef72",
            "filename": "src/transformers/models/efficientnet/modeling_efficientnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fmodeling_efficientnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fmodeling_efficientnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fmodeling_efficientnet.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -432,7 +432,7 @@ def forward(\n \n @auto_docstring\n class EfficientNetPreTrainedModel(PreTrainedModel):\n-    config_class = EfficientNetConfig\n+    config: EfficientNetConfig\n     base_model_prefix = \"efficientnet\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = []"
        },
        {
            "sha": "ef7e8051e6db048c41ab121c08ba803710e346c0",
            "filename": "src/transformers/models/electra/modeling_electra.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Felectra%2Fmodeling_electra.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Felectra%2Fmodeling_electra.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Felectra%2Fmodeling_electra.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -646,7 +646,7 @@ def forward(self, generator_hidden_states):\n \n @auto_docstring\n class ElectraPreTrainedModel(PreTrainedModel):\n-    config_class = ElectraConfig\n+    config: ElectraConfig\n     load_tf_weights = load_tf_weights_in_electra\n     base_model_prefix = \"electra\"\n     supports_gradient_checkpointing = True\n@@ -1284,7 +1284,7 @@ def forward(\n \n @auto_docstring\n class ElectraForQuestionAnswering(ElectraPreTrainedModel):\n-    config_class = ElectraConfig\n+    config: ElectraConfig\n     base_model_prefix = \"electra\"\n \n     def __init__(self, config):"
        },
        {
            "sha": "b66e24423474ffc3f8eabd982f25c810e5f9bc99",
            "filename": "src/transformers/models/emu3/modeling_emu3.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -922,7 +922,7 @@ def forward(self, hidden_states: torch.Tensor, quant_states: torch.Tensor):\n     \"\"\"\n )\n class Emu3VQVAE(PreTrainedModel):\n-    config_class = Emu3VQVAEConfig\n+    config: Emu3VQVAEConfig\n     base_model_prefix = \"emuvideovq\"\n     main_input_name = \"pixel_values\"\n     _supports_sdpa = True\n@@ -1088,7 +1088,7 @@ def convert_bpe2img(self, img_batch: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class Emu3PreTrainedModel(PreTrainedModel):\n-    config_class = Emu3Config\n+    config: Emu3Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\n@@ -1246,7 +1246,7 @@ class Emu3ForCausalLM(Emu3PreTrainedModel, GenerationMixin):\n     _tied_weights_keys = [\"lm_head.weight\"]\n     _tp_plan = {\"lm_head\": \"colwise_rep\"}\n     _pp_plan = {\"lm_head\": ([\"hidden_states\"], [\"logits\"])}\n-    config_class = Emu3TextConfig\n+    config: Emu3TextConfig\n \n     def __init__(self, config):\n         super().__init__(config)"
        },
        {
            "sha": "e32cfd2dfc61f13b4c5238c06d843c4bab06b18c",
            "filename": "src/transformers/models/emu3/modular_emu3.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Femu3%2Fmodular_emu3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Femu3%2Fmodular_emu3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Femu3%2Fmodular_emu3.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -674,7 +674,7 @@ def forward(self, hidden_states: torch.Tensor, quant_states: torch.Tensor):\n     \"\"\"\n )\n class Emu3VQVAE(PreTrainedModel):\n-    config_class = Emu3VQVAEConfig\n+    config: Emu3VQVAEConfig\n     base_model_prefix = \"emuvideovq\"\n     main_input_name = \"pixel_values\"\n     _supports_sdpa = True\n@@ -873,7 +873,7 @@ def __init__(self, config: Emu3Config):\n \n \n class Emu3ForCausalLM(LlamaForCausalLM, Emu3PreTrainedModel, GenerationMixin):\n-    config_class = Emu3TextConfig\n+    config: Emu3TextConfig\n \n     def __init__(self, config):\n         super().__init__(config)"
        },
        {
            "sha": "cbdfd038e746de1762c045f183d38f1827fdf420",
            "filename": "src/transformers/models/encodec/modeling_encodec.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fencodec%2Fmodeling_encodec.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fencodec%2Fmodeling_encodec.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fencodec%2Fmodeling_encodec.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -446,7 +446,7 @@ def decode(self, codes: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class EncodecPreTrainedModel(PreTrainedModel):\n-    config_class = EncodecConfig\n+    config: EncodecConfig\n     base_model_prefix = \"encodec\"\n     main_input_name = \"input_values\"\n "
        },
        {
            "sha": "44d8e6cd7e07fa2266126b6f7daa3087660ee846",
            "filename": "src/transformers/models/encoder_decoder/modeling_encoder_decoder.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fencoder_decoder%2Fmodeling_encoder_decoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fencoder_decoder%2Fmodeling_encoder_decoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fencoder_decoder%2Fmodeling_encoder_decoder.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -73,7 +73,7 @@ class EncoderDecoderModel(PreTrainedModel, GenerationMixin):\n     :meth*~transformers.AutoModelForCausalLM.from_pretrained* class method for the decoder.\n     \"\"\"\n \n-    config_class = EncoderDecoderConfig\n+    config: EncoderDecoderConfig\n     base_model_prefix = \"encoder_decoder\"\n     main_input_name = \"input_ids\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "c0f5461f50eea0b04be8b3fad044b89c33065412",
            "filename": "src/transformers/models/eomt/modeling_eomt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Feomt%2Fmodeling_eomt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Feomt%2Fmodeling_eomt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Feomt%2Fmodeling_eomt.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -995,7 +995,7 @@ class EomtPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = EomtConfig\n+    config: EomtConfig\n     base_model_prefix = \"eomt\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = False"
        },
        {
            "sha": "a98cf4f779173154121193db6a84f06459953033",
            "filename": "src/transformers/models/eomt/modular_eomt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Feomt%2Fmodular_eomt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Feomt%2Fmodular_eomt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Feomt%2Fmodular_eomt.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -367,7 +367,7 @@ class EomtPreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = EomtConfig\n+    config: EomtConfig\n     base_model_prefix = \"eomt\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = False"
        },
        {
            "sha": "d291db4e6b8c1fb5408c09d6fdc85f09ec927e91",
            "filename": "src/transformers/models/ernie/modeling_ernie.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fernie%2Fmodeling_ernie.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fernie%2Fmodeling_ernie.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie%2Fmodeling_ernie.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -630,7 +630,7 @@ def forward(self, sequence_output, pooled_output):\n \n @auto_docstring\n class ErniePreTrainedModel(PreTrainedModel):\n-    config_class = ErnieConfig\n+    config: ErnieConfig\n     base_model_prefix = \"ernie\"\n     supports_gradient_checkpointing = True\n "
        },
        {
            "sha": "d7fd324285a088b35532d21e681c608c983f88b9",
            "filename": "src/transformers/models/esm/modeling_esm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fesm%2Fmodeling_esm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fesm%2Fmodeling_esm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fesm%2Fmodeling_esm.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -738,7 +738,7 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class EsmPreTrainedModel(PreTrainedModel):\n-    config_class = EsmConfig\n+    config: EsmConfig\n     base_model_prefix = \"esm\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"EsmLayer\", \"EsmFoldTriangularSelfAttentionBlock\", \"EsmEmbeddings\"]"
        },
        {
            "sha": "392472d5372dc7aa3556a2bccc9164f410c908b1",
            "filename": "src/transformers/models/falcon/modeling_falcon.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffalcon%2Fmodeling_falcon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffalcon%2Fmodeling_falcon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffalcon%2Fmodeling_falcon.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -636,7 +636,7 @@ def forward(\n \n @auto_docstring\n class FalconPreTrainedModel(PreTrainedModel):\n-    config_class = FalconConfig\n+    config: FalconConfig\n     base_model_prefix = \"transformer\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"FalconDecoderLayer\"]"
        },
        {
            "sha": "3c6a8e500e57726b7f287a29b10853ccdd7b5097",
            "filename": "src/transformers/models/falcon_h1/modeling_falcon_h1.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffalcon_h1%2Fmodeling_falcon_h1.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffalcon_h1%2Fmodeling_falcon_h1.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffalcon_h1%2Fmodeling_falcon_h1.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1145,7 +1145,7 @@ def forward(\n \n @auto_docstring\n class FalconH1PreTrainedModel(PreTrainedModel):\n-    config_class = FalconH1Config\n+    config: FalconH1Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"FalconH1DecoderLayer\"]"
        },
        {
            "sha": "305fd7bfbbb192a67f2a7f47278a65a6b521e901",
            "filename": "src/transformers/models/falcon_h1/modular_falcon_h1.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffalcon_h1%2Fmodular_falcon_h1.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffalcon_h1%2Fmodular_falcon_h1.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffalcon_h1%2Fmodular_falcon_h1.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -923,7 +923,7 @@ def forward(\n \n @auto_docstring\n class FalconH1PreTrainedModel(PreTrainedModel):\n-    config_class = FalconH1Config\n+    config: FalconH1Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"FalconH1DecoderLayer\"]"
        },
        {
            "sha": "c32157ab11c4f34e2dc547d94a1f2fab049de2a9",
            "filename": "src/transformers/models/falcon_mamba/modeling_falcon_mamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffalcon_mamba%2Fmodeling_falcon_mamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffalcon_mamba%2Fmodeling_falcon_mamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffalcon_mamba%2Fmodeling_falcon_mamba.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -437,7 +437,7 @@ def forward(\n @auto_docstring\n # Copied from transformers.models.mamba.modeling_mamba.MambaPreTrainedModel with Mamba->FalconMamba\n class FalconMambaPreTrainedModel(PreTrainedModel):\n-    config_class = FalconMambaConfig\n+    config: FalconMambaConfig\n     base_model_prefix = \"backbone\"\n     _no_split_modules = [\"FalconMambaBlock\", \"FalconMambaMixer\"]\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "08039ef2d6ec5483294c9a069a2eb9508c390fb2",
            "filename": "src/transformers/models/fastspeech2_conformer/modeling_fastspeech2_conformer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fmodeling_fastspeech2_conformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fmodeling_fastspeech2_conformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fmodeling_fastspeech2_conformer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -959,7 +959,7 @@ def forward(\n \n @auto_docstring\n class FastSpeech2ConformerPreTrainedModel(PreTrainedModel):\n-    config_class = FastSpeech2ConformerConfig\n+    config: FastSpeech2ConformerConfig\n     base_model_prefix = \"fastspeech2_conformer\"\n \n     main_input_name = \"input_ids\"\n@@ -1331,7 +1331,7 @@ def forward(self, hidden_states):\n )\n # Copied from transformers.models.speecht5.modeling_speecht5.SpeechT5HifiGan with SpeechT5->FastSpeech2Conformer\n class FastSpeech2ConformerHifiGan(PreTrainedModel):\n-    config_class = FastSpeech2ConformerHifiGanConfig\n+    config: FastSpeech2ConformerHifiGanConfig\n     main_input_name = \"spectrogram\"\n \n     def __init__(self, config: FastSpeech2ConformerHifiGanConfig):\n@@ -1455,7 +1455,7 @@ def forward(self, spectrogram: torch.FloatTensor) -> torch.FloatTensor:\n     \"\"\"\n )\n class FastSpeech2ConformerWithHifiGan(PreTrainedModel):\n-    config_class = FastSpeech2ConformerWithHifiGanConfig\n+    config: FastSpeech2ConformerWithHifiGanConfig\n \n     def __init__(self, config: FastSpeech2ConformerWithHifiGanConfig):\n         super().__init__(config)"
        },
        {
            "sha": "3643119988baac046b31ff92f957520e58c8b2f8",
            "filename": "src/transformers/models/flaubert/modeling_flaubert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fflaubert%2Fmodeling_flaubert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fflaubert%2Fmodeling_flaubert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflaubert%2Fmodeling_flaubert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -678,7 +678,7 @@ def forward(\n @auto_docstring\n # Copied from transformers.models.xlm.modeling_xlm.XLMPreTrainedModel with XLM->Flaubert\n class FlaubertPreTrainedModel(PreTrainedModel):\n-    config_class = FlaubertConfig\n+    config: FlaubertConfig\n     load_tf_weights = None\n     base_model_prefix = \"transformer\"\n "
        },
        {
            "sha": "63eadf41c380237f50a2cb91c10803c0e5cc7701",
            "filename": "src/transformers/models/flava/modeling_flava.py",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fflava%2Fmodeling_flava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fflava%2Fmodeling_flava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflava%2Fmodeling_flava.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -694,7 +694,7 @@ def forward(self, hidden_states: torch.Tensor):\n \n @auto_docstring\n class FlavaPreTrainedModel(PreTrainedModel):\n-    config_class = FlavaConfig\n+    config: FlavaConfig\n     base_model_prefix = \"flava\"\n     supports_gradient_checkpointing = True\n \n@@ -729,7 +729,7 @@ def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> No\n \n @auto_docstring\n class FlavaImageModel(FlavaPreTrainedModel):\n-    config_class = FlavaImageConfig\n+    config: FlavaImageConfig\n     # This override allows us to load FlavaImageModel from FlavaModel/FlavaForPreTraining checkpoints.\n     base_model_prefix = \"flava.image_model\"\n     main_input_name = \"pixel_values\"\n@@ -826,7 +826,7 @@ def forward(\n \n @auto_docstring\n class FlavaTextModel(FlavaPreTrainedModel):\n-    config_class = FlavaTextConfig\n+    config: FlavaTextConfig\n     # This override allows us to load FlavaTextModel from FlavaModel/FlavaForPreTraining checkpoints.\n     base_model_prefix = \"flava.text_model\"\n \n@@ -939,7 +939,7 @@ def forward(\n \n @auto_docstring\n class FlavaMultimodalModel(FlavaPreTrainedModel):\n-    config_class = FlavaMultimodalConfig\n+    config: FlavaMultimodalConfig\n     # This override allows us to load FlavaMultimodalModel from FlavaModel/FlavaForPreTraining checkpoints.\n     base_model_prefix = \"flava.multimodal_model\"\n     main_input_name = \"hidden_states\"\n@@ -1035,7 +1035,7 @@ def forward(\n \n @auto_docstring\n class FlavaModel(FlavaPreTrainedModel):\n-    config_class = FlavaConfig\n+    config: FlavaConfig\n \n     def __init__(self, config: FlavaConfig):\n         super().__init__(config)\n@@ -1400,7 +1400,7 @@ def forward(self, x: torch.Tensor) -> torch.Tensor:\n )\n class FlavaImageCodebook(FlavaPreTrainedModel):\n     base_model_prefix = \"\"\n-    config_class = FlavaImageCodebookConfig\n+    config: FlavaImageCodebookConfig\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = False\n "
        },
        {
            "sha": "1cb0e764b2a11326ac7a2ab4529e98ebfcfdfd7b",
            "filename": "src/transformers/models/fnet/modeling_fnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffnet%2Fmodeling_fnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffnet%2Fmodeling_fnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffnet%2Fmodeling_fnet.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -386,7 +386,7 @@ def forward(self, sequence_output, pooled_output):\n \n @auto_docstring\n class FNetPreTrainedModel(PreTrainedModel):\n-    config_class = FNetConfig\n+    config: FNetConfig\n     base_model_prefix = \"fnet\"\n     supports_gradient_checkpointing = True\n "
        },
        {
            "sha": "93bdae6096d1968a68f3201d1d372160b04a9258",
            "filename": "src/transformers/models/focalnet/modeling_focalnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffocalnet%2Fmodeling_focalnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffocalnet%2Fmodeling_focalnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffocalnet%2Fmodeling_focalnet.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -582,7 +582,7 @@ def forward(\n \n @auto_docstring\n class FocalNetPreTrainedModel(PreTrainedModel):\n-    config_class = FocalNetConfig\n+    config: FocalNetConfig\n     base_model_prefix = \"focalnet\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "66fdca387a3064b58ffbfa0db50d46448eff407a",
            "filename": "src/transformers/models/fsmt/modeling_fsmt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffsmt%2Fmodeling_fsmt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffsmt%2Fmodeling_fsmt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffsmt%2Fmodeling_fsmt.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -217,7 +217,7 @@ def _prepare_fsmt_decoder_inputs(\n \n @auto_docstring\n class PretrainedFSMTModel(PreTrainedModel):\n-    config_class = FSMTConfig\n+    config: FSMTConfig\n     base_model_prefix = \"model\"\n \n     def _init_weights(self, module):"
        },
        {
            "sha": "4370344cccfb19c710ed05b01e72f6880b54afdd",
            "filename": "src/transformers/models/funnel/modeling_funnel.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffunnel%2Fmodeling_funnel.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffunnel%2Fmodeling_funnel.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffunnel%2Fmodeling_funnel.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -760,7 +760,7 @@ def forward(self, discriminator_hidden_states: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class FunnelPreTrainedModel(PreTrainedModel):\n-    config_class = FunnelConfig\n+    config: FunnelConfig\n     load_tf_weights = load_tf_weights_in_funnel\n     base_model_prefix = \"funnel\"\n "
        },
        {
            "sha": "b7a4cb9a05ac151616c6b7268714eaeb34ae0e53",
            "filename": "src/transformers/models/fuyu/modeling_fuyu.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffuyu%2Fmodeling_fuyu.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Ffuyu%2Fmodeling_fuyu.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffuyu%2Fmodeling_fuyu.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -34,7 +34,7 @@\n \n @auto_docstring\n class FuyuPreTrainedModel(PreTrainedModel):\n-    config_class = FuyuConfig\n+    config: FuyuConfig\n     base_model_prefix = \"fuyu\"\n     supports_gradient_checkpointing = True\n     _supports_attention_backend = True"
        },
        {
            "sha": "2aab29381ab8e5f7e7b520e05d663ea604b70a68",
            "filename": "src/transformers/models/gemma/modeling_gemma.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgemma%2Fmodeling_gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgemma%2Fmodeling_gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma%2Fmodeling_gemma.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -305,7 +305,7 @@ def forward(\n \n @auto_docstring\n class GemmaPreTrainedModel(PreTrainedModel):\n-    config_class = GemmaConfig\n+    config: GemmaConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"GemmaDecoderLayer\"]"
        },
        {
            "sha": "df45009a9277b5b42471b5dc6cf5b5076c222ff5",
            "filename": "src/transformers/models/gemma2/modeling_gemma2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -335,7 +335,7 @@ def forward(self, x, position_ids):\n \n @auto_docstring\n class Gemma2PreTrainedModel(PreTrainedModel):\n-    config_class = Gemma2Config\n+    config: Gemma2Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Gemma2DecoderLayer\"]"
        },
        {
            "sha": "2aa3f994271ae2e9a6e57a805192488a8b8e4c6c",
            "filename": "src/transformers/models/gemma3/modeling_gemma3.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodeling_gemma3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodeling_gemma3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodeling_gemma3.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -420,7 +420,7 @@ def forward(\n \n @auto_docstring\n class Gemma3PreTrainedModel(PreTrainedModel):\n-    config_class = Gemma3Config\n+    config: Gemma3Config\n     base_model_prefix = \"\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\n@@ -460,7 +460,7 @@ def _init_weights(self, module):\n \n @auto_docstring\n class Gemma3TextModel(Gemma3PreTrainedModel):\n-    config_class = Gemma3TextConfig\n+    config: Gemma3TextConfig\n \n     def __init__(self, config: Gemma3TextConfig):\n         super().__init__(config)\n@@ -609,7 +609,7 @@ class Gemma3ForCausalLM(Gemma3PreTrainedModel, GenerationMixin):\n     _tied_weights_keys = [\"lm_head.weight\"]\n     _tp_plan = {\"lm_head\": \"colwise_rep\"}\n     _pp_plan = {\"lm_head\": ([\"hidden_states\"], [\"logits\"])}\n-    config_class = Gemma3TextConfig\n+    config: Gemma3TextConfig\n     base_model_prefix = \"language_model\"\n \n     def __init__(self, config: Gemma3TextConfig):"
        },
        {
            "sha": "62f0934bb8c8dc01beada221caaf3658819a2bd3",
            "filename": "src/transformers/models/gemma3/modular_gemma3.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodular_gemma3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodular_gemma3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma3%2Fmodular_gemma3.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -546,7 +546,7 @@ def _init_weights(self, module):\n \n \n class Gemma3TextModel(Gemma2Model):\n-    config_class = Gemma3TextConfig\n+    config: Gemma3TextConfig\n \n     def __init__(self, config: Gemma3TextConfig):\n         super().__init__(config)\n@@ -672,7 +672,7 @@ def forward(\n \n \n class Gemma3ForCausalLM(Gemma2ForCausalLM):\n-    config_class = Gemma3TextConfig\n+    config: Gemma3TextConfig\n     base_model_prefix = \"language_model\"\n \n     def __init__(self, config: Gemma3TextConfig):"
        },
        {
            "sha": "8b9b516d92e9faa2e3e23b0b323b22aa4e81592f",
            "filename": "src/transformers/models/gemma3n/modeling_gemma3n.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgemma3n%2Fmodeling_gemma3n.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgemma3n%2Fmodeling_gemma3n.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma3n%2Fmodeling_gemma3n.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -914,7 +914,7 @@ def forward(self, audio_encodings: torch.Tensor, audio_mel_mask: torch.BoolTenso\n class Gemma3nAudioEncoder(PreTrainedModel):\n     \"\"\"An audio encoder based on the [Universal Speech Model](https://arxiv.org/abs/2303.01037) architecture.\"\"\"\n \n-    config_class = Gemma3nAudioConfig\n+    config: Gemma3nAudioConfig\n \n     main_input_name = \"audio_mel\"\n \n@@ -1481,7 +1481,7 @@ def forward(\n \n @auto_docstring\n class Gemma3nPreTrainedModel(PreTrainedModel):\n-    config_class = Gemma3nConfig\n+    config: Gemma3nConfig\n     base_model_prefix = \"\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Gemma3nTextDecoderLayer\"]\n@@ -1523,7 +1523,7 @@ def _init_weights(self, module):\n \n @auto_docstring(custom_intro=\"The base Gemma 3n language model without a language modeling head.\")\n class Gemma3nTextModel(Gemma3nPreTrainedModel):\n-    config_class = Gemma3nTextConfig\n+    config: Gemma3nTextConfig\n \n     def __init__(self, config: Gemma3nTextConfig):\n         super().__init__(config)\n@@ -1780,7 +1780,7 @@ class Gemma3nForCausalLM(Gemma3nPreTrainedModel, GenerationMixin):\n     _tied_weights_keys = [\"lm_head.weight\"]\n     _tp_plan = {\"lm_head\": \"colwise_rep\"}\n     _pp_plan = {\"lm_head\": ([\"hidden_states\"], [\"logits\"])}\n-    config_class = Gemma3nTextConfig\n+    config: Gemma3nTextConfig\n     base_model_prefix = \"model\"\n     _checkpoint_conversion_mapping = {\"model.language_model\": \"model\"}\n "
        },
        {
            "sha": "8e3bcfd1f1565d6e5c3f8bd57e0a20f455af7c9a",
            "filename": "src/transformers/models/gemma3n/modular_gemma3n.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgemma3n%2Fmodular_gemma3n.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgemma3n%2Fmodular_gemma3n.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma3n%2Fmodular_gemma3n.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1475,7 +1475,7 @@ def forward(self, audio_encodings: torch.Tensor, audio_mel_mask: torch.BoolTenso\n class Gemma3nAudioEncoder(PreTrainedModel):\n     \"\"\"An audio encoder based on the [Universal Speech Model](https://arxiv.org/abs/2303.01037) architecture.\"\"\"\n \n-    config_class = Gemma3nAudioConfig\n+    config: Gemma3nAudioConfig\n \n     main_input_name = \"audio_mel\"\n \n@@ -1912,7 +1912,7 @@ def forward(\n \n \n class Gemma3nPreTrainedModel(Gemma2PreTrainedModel):\n-    config_class = Gemma3nConfig\n+    config: Gemma3nConfig\n     base_model_prefix = \"\"\n     _no_split_modules = [\"Gemma3nTextDecoderLayer\"]\n \n@@ -1942,7 +1942,7 @@ def _init_weights(self, module):\n \n @auto_docstring(custom_intro=\"The base Gemma 3n language model without a language modeling head.\")\n class Gemma3nTextModel(Gemma3TextModel):\n-    config_class = Gemma3nTextConfig\n+    config: Gemma3nTextConfig\n \n     def __init__(self, config: Gemma3nTextConfig):\n         super().__init__(config)"
        },
        {
            "sha": "3312e80c7999b6478cf92c9b25f75bfae2d57a2c",
            "filename": "src/transformers/models/git/modeling_git.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgit%2Fmodeling_git.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgit%2Fmodeling_git.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgit%2Fmodeling_git.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -453,7 +453,7 @@ def forward(\n \n @auto_docstring\n class GitPreTrainedModel(PreTrainedModel):\n-    config_class = GitConfig\n+    config: GitConfig\n     base_model_prefix = \"git\"\n     supports_gradient_checkpointing = True\n \n@@ -879,7 +879,7 @@ def forward(\n     \"\"\"\n )\n class GitVisionModel(GitPreTrainedModel):\n-    config_class = GitVisionConfig\n+    config: GitVisionConfig\n     main_input_name = \"pixel_values\"\n \n     # Copied from transformers.models.clip.modeling_clip.CLIPVisionModel.__init__ with CLIP->Git"
        },
        {
            "sha": "d6cf8e137fe2e9d705b383a28c5b9e86a3e6c627",
            "filename": "src/transformers/models/glm/modeling_glm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fglm%2Fmodeling_glm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fglm%2Fmodeling_glm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm%2Fmodeling_glm.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -322,7 +322,7 @@ def forward(\n \n @auto_docstring\n class GlmPreTrainedModel(PreTrainedModel):\n-    config_class = GlmConfig\n+    config: GlmConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"GlmDecoderLayer\"]"
        },
        {
            "sha": "c3c9a0ab1f29b6baae7e2581e28f2001dd0f969d",
            "filename": "src/transformers/models/glm4/modeling_glm4.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fglm4%2Fmodeling_glm4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fglm4%2Fmodeling_glm4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4%2Fmodeling_glm4.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -326,7 +326,7 @@ def forward(self, x, position_ids):\n \n @auto_docstring\n class Glm4PreTrainedModel(PreTrainedModel):\n-    config_class = Glm4Config\n+    config: Glm4Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Glm4DecoderLayer\"]"
        },
        {
            "sha": "90cddf636f612e52fc1f8468272b4bc4bffce666",
            "filename": "src/transformers/models/glm4v/modeling_glm4v.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -399,7 +399,7 @@ def forward(\n \n @auto_docstring\n class Glm4vPreTrainedModel(PreTrainedModel):\n-    config_class = Glm4vConfig\n+    config: Glm4vConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Glm4vTextDecoderLayer\", \"Glm4vVisionBlock\"]\n@@ -428,7 +428,7 @@ def _init_weights(self, module):\n \n \n class Glm4vVisionModel(Glm4vPreTrainedModel):\n-    config_class = Glm4vVisionConfig\n+    config: Glm4vVisionConfig\n     _no_split_modules = [\"Glm4vVisionBlock\"]\n \n     def __init__(self, config) -> None:\n@@ -819,7 +819,7 @@ class Glm4vModelOutputWithPast(ModelOutput):\n \n @auto_docstring\n class Glm4vTextModel(Glm4vPreTrainedModel):\n-    config_class = Glm4vTextConfig\n+    config: Glm4vTextConfig\n \n     def __init__(self, config: Glm4vTextConfig):\n         super().__init__(config)\n@@ -950,7 +950,7 @@ def forward(\n class Glm4vModel(Glm4vPreTrainedModel):\n     base_model_prefix = \"\"\n     _checkpoint_conversion_mapping = {}\n-    config_class = Glm4vConfig\n+    config: Glm4vConfig\n     _no_split_modules = [\"Glm4vTextDecoderLayer\", \"Glm4vVisionBlock\"]\n \n     def __init__(self, config):"
        },
        {
            "sha": "5db53e8b30fbf01b59afd9959b3a055466a6a6e7",
            "filename": "src/transformers/models/glm4v/modular_glm4v.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -543,7 +543,7 @@ def _init_weights(self, module):\n \n \n class Glm4vVisionModel(Glm4vPreTrainedModel):\n-    config_class = Glm4vVisionConfig\n+    config: Glm4vVisionConfig\n     _no_split_modules = [\"Glm4vVisionBlock\"]\n \n     def __init__(self, config) -> None:"
        },
        {
            "sha": "50408caa3f12b596493cb4a9c63f60e76bd24fe1",
            "filename": "src/transformers/models/glm4v/processing_glm4v.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fglm4v%2Fprocessing_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fglm4v%2Fprocessing_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v%2Fprocessing_glm4v.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -39,13 +39,13 @@ class Glm4vImagesKwargs(ImagesKwargs):\n \n \n class Glm4vProcessorKwargs(ProcessingKwargs, total=False):\n+    images_kwargs: Glm4vImagesKwargs\n+    videos_kwargs: Glm4vVideosProcessorKwargs\n     _defaults = {\n         \"text_kwargs\": {\n             \"padding\": False,\n         },\n     }\n-    images_kwargs: Glm4vImagesKwargs\n-    videos_kwargs: Glm4vVideosProcessorKwargs\n \n \n class Glm4vProcessor(ProcessorMixin):"
        },
        {
            "sha": "65e7b9b2654dbbcc338ff7edee7c752ae2a18815",
            "filename": "src/transformers/models/glpn/modeling_glpn.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fglpn%2Fmodeling_glpn.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fglpn%2Fmodeling_glpn.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglpn%2Fmodeling_glpn.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -409,7 +409,7 @@ def forward(\n \n @auto_docstring\n class GLPNPreTrainedModel(PreTrainedModel):\n-    config_class = GLPNConfig\n+    config: GLPNConfig\n     base_model_prefix = \"glpn\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = []"
        },
        {
            "sha": "4ff79a53def7c77d765f1898022b68c012c69d2a",
            "filename": "src/transformers/models/got_ocr2/modeling_got_ocr2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fmodeling_got_ocr2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fmodeling_got_ocr2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fmodeling_got_ocr2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -276,7 +276,7 @@ def forward(self, hidden_states: torch.Tensor) -> tuple[torch.FloatTensor]:\n \n @auto_docstring\n class GotOcr2PreTrainedModel(PreTrainedModel):\n-    config_class = GotOcr2Config\n+    config: GotOcr2Config\n     base_model_prefix = \"\"\n     supports_gradient_checkpointing = True\n     _skip_keys_device_placement = \"past_key_values\""
        },
        {
            "sha": "7039169519b79255eef0b05fa18fd9a1bbb92114",
            "filename": "src/transformers/models/gpt2/modeling_gpt2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgpt2%2Fmodeling_gpt2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgpt2%2Fmodeling_gpt2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt2%2Fmodeling_gpt2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -552,7 +552,7 @@ def forward(\n \n @auto_docstring\n class GPT2PreTrainedModel(PreTrainedModel):\n-    config_class = GPT2Config\n+    config: GPT2Config\n     load_tf_weights = load_tf_weights_in_gpt2\n     base_model_prefix = \"transformer\"\n     is_parallelizable = True"
        },
        {
            "sha": "89c280f93a36639af4e618582aa22072c36eaaa2",
            "filename": "src/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgpt_bigcode%2Fmodeling_gpt_bigcode.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgpt_bigcode%2Fmodeling_gpt_bigcode.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_bigcode%2Fmodeling_gpt_bigcode.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -359,7 +359,7 @@ def forward(\n \n @auto_docstring\n class GPTBigCodePreTrainedModel(PreTrainedModel):\n-    config_class = GPTBigCodeConfig\n+    config: GPTBigCodeConfig\n     base_model_prefix = \"transformer\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"GPTBigCodeBlock\"]"
        },
        {
            "sha": "cce119303a2f4489ec09c530bde68bb082dd59e0",
            "filename": "src/transformers/models/gpt_neo/modeling_gpt_neo.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgpt_neo%2Fmodeling_gpt_neo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgpt_neo%2Fmodeling_gpt_neo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_neo%2Fmodeling_gpt_neo.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -470,7 +470,7 @@ def forward(\n \n @auto_docstring\n class GPTNeoPreTrainedModel(PreTrainedModel):\n-    config_class = GPTNeoConfig\n+    config: GPTNeoConfig\n     load_tf_weights = load_tf_weights_in_gpt_neo\n     base_model_prefix = \"transformer\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "b868d4353c0d317f5ad50f8e5175d2219237b5f9",
            "filename": "src/transformers/models/gpt_neox/modeling_gpt_neox.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgpt_neox%2Fmodeling_gpt_neox.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgpt_neox%2Fmodeling_gpt_neox.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_neox%2Fmodeling_gpt_neox.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -355,7 +355,7 @@ def forward(\n \n @auto_docstring\n class GPTNeoXPreTrainedModel(PreTrainedModel):\n-    config_class = GPTNeoXConfig\n+    config: GPTNeoXConfig\n     base_model_prefix = \"gpt_neox\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"GPTNeoXLayer\"]"
        },
        {
            "sha": "9e1859e794b8482e4921e100a06727bc079aa30e",
            "filename": "src/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgpt_neox_japanese%2Fmodeling_gpt_neox_japanese.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgpt_neox_japanese%2Fmodeling_gpt_neox_japanese.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_neox_japanese%2Fmodeling_gpt_neox_japanese.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -43,7 +43,7 @@\n \n @auto_docstring\n class GPTNeoXJapanesePreTrainedModel(PreTrainedModel):\n-    config_class = GPTNeoXJapaneseConfig\n+    config: GPTNeoXJapaneseConfig\n     base_model_prefix = \"gpt_neox_japanese\"\n     _no_split_modules = [\"GPTNeoXJapaneseLayer\"]\n     _skip_keys_device_placement = \"past_key_values\""
        },
        {
            "sha": "093dbf355db604327633d2cd9544949a38e5e077",
            "filename": "src/transformers/models/gptj/modeling_gptj.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgptj%2Fmodeling_gptj.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgptj%2Fmodeling_gptj.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgptj%2Fmodeling_gptj.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -465,7 +465,7 @@ def forward(\n \n @auto_docstring\n class GPTJPreTrainedModel(PreTrainedModel):\n-    config_class = GPTJConfig\n+    config: GPTJConfig\n     base_model_prefix = \"transformer\"\n     is_parallelizable = True\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "13804b9c260db5eece6d21411c3da4fb88503d90",
            "filename": "src/transformers/models/granite/modeling_granite.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgranite%2Fmodeling_granite.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgranite%2Fmodeling_granite.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranite%2Fmodeling_granite.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -300,7 +300,7 @@ def forward(\n \n @auto_docstring\n class GranitePreTrainedModel(PreTrainedModel):\n-    config_class = GraniteConfig\n+    config: GraniteConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"GraniteDecoderLayer\"]"
        },
        {
            "sha": "18e16d36059bb2c12d68e51818b83b8520b20f29",
            "filename": "src/transformers/models/granite_speech/modeling_granite_speech.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgranite_speech%2Fmodeling_granite_speech.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgranite_speech%2Fmodeling_granite_speech.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranite_speech%2Fmodeling_granite_speech.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -281,7 +281,7 @@ def forward(self, hidden_states: torch.Tensor):\n \n @auto_docstring\n class GraniteSpeechPreTrainedModel(PreTrainedModel):\n-    config_class = GraniteSpeechConfig\n+    config: GraniteSpeechConfig\n \n     _supports_flash_attn = True\n     _supports_sdpa = True"
        },
        {
            "sha": "caa9214183be140f843a2150d76477031e24897f",
            "filename": "src/transformers/models/granitemoe/modeling_granitemoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -584,7 +584,7 @@ def forward(\n \n @auto_docstring\n class GraniteMoePreTrainedModel(PreTrainedModel):\n-    config_class = GraniteMoeConfig\n+    config: GraniteMoeConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"GraniteMoeDecoderLayer\"]"
        },
        {
            "sha": "1ba85ba7305a03edc8a0a2dc7e5c35a2fbf42419",
            "filename": "src/transformers/models/granitemoehybrid/modeling_granitemoehybrid.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1157,7 +1157,7 @@ def forward(\n \n @auto_docstring\n class GraniteMoeHybridPreTrainedModel(PreTrainedModel):\n-    config_class = GraniteMoeHybridConfig\n+    config: GraniteMoeHybridConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"GraniteMoeHybridDecoderLayer\"]"
        },
        {
            "sha": "80c5cfd4309d30448570a93f28888ec6aa177710",
            "filename": "src/transformers/models/granitemoehybrid/modular_granitemoehybrid.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodular_granitemoehybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodular_granitemoehybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodular_granitemoehybrid.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -162,7 +162,7 @@ def forward(\n \n \n class GraniteMoeHybridPreTrainedModel(GraniteMoeSharedPreTrainedModel):\n-    config_class = GraniteMoeHybridConfig\n+    config: GraniteMoeHybridConfig\n     _no_split_modules = [\"GraniteMoeHybridDecoderLayer\"]\n     _is_stateful = True\n "
        },
        {
            "sha": "7bd81f2db30fe58192a8eea545899239b6e7ff16",
            "filename": "src/transformers/models/granitemoeshared/modeling_granitemoeshared.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodeling_granitemoeshared.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodeling_granitemoeshared.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodeling_granitemoeshared.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -502,7 +502,7 @@ def forward(\n \n @auto_docstring\n class GraniteMoeSharedPreTrainedModel(PreTrainedModel):\n-    config_class = GraniteMoeSharedConfig\n+    config: GraniteMoeSharedConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"GraniteMoeSharedDecoderLayer\"]"
        },
        {
            "sha": "29342cb6251d5a1ebd127b08914fba6dde01e719",
            "filename": "src/transformers/models/granitemoeshared/modular_granitemoeshared.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodular_granitemoeshared.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodular_granitemoeshared.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodular_granitemoeshared.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -147,7 +147,7 @@ def forward(\n \n \n class GraniteMoeSharedPreTrainedModel(GraniteMoePreTrainedModel):\n-    config_class = GraniteMoeSharedConfig\n+    config: GraniteMoeSharedConfig\n     _no_split_modules = [\"GraniteMoeSharedDecoderLayer\"]\n \n "
        },
        {
            "sha": "8432e510ed814b64dc630916db9a8ed91f765133",
            "filename": "src/transformers/models/grounding_dino/modeling_grounding_dino.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgrounding_dino%2Fmodeling_grounding_dino.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgrounding_dino%2Fmodeling_grounding_dino.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgrounding_dino%2Fmodeling_grounding_dino.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1373,7 +1373,7 @@ def forward(\n \n @auto_docstring\n class GroundingDinoPreTrainedModel(PreTrainedModel):\n-    config_class = GroundingDinoConfig\n+    config: GroundingDinoConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"pixel_values\"\n "
        },
        {
            "sha": "c9673a128fa8d5a01ea8612d0ebb7fdf7cb93927",
            "filename": "src/transformers/models/groupvit/modeling_groupvit.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgroupvit%2Fmodeling_groupvit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fgroupvit%2Fmodeling_groupvit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgroupvit%2Fmodeling_groupvit.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -744,7 +744,7 @@ def forward(\n \n @auto_docstring\n class GroupViTPreTrainedModel(PreTrainedModel):\n-    config_class = GroupViTConfig\n+    config: GroupViTConfig\n     base_model_prefix = \"groupvit\"\n     supports_gradient_checkpointing = True\n \n@@ -1021,7 +1021,7 @@ def forward(\n \n \n class GroupViTTextModel(GroupViTPreTrainedModel):\n-    config_class = GroupViTTextConfig\n+    config: GroupViTTextConfig\n \n     def __init__(self, config: GroupViTTextConfig):\n         super().__init__(config)\n@@ -1124,7 +1124,7 @@ def forward(\n \n \n class GroupViTVisionModel(GroupViTPreTrainedModel):\n-    config_class = GroupViTVisionConfig\n+    config: GroupViTVisionConfig\n     main_input_name = \"pixel_values\"\n \n     def __init__(self, config: GroupViTVisionConfig):\n@@ -1174,7 +1174,7 @@ def forward(\n \n @auto_docstring\n class GroupViTModel(GroupViTPreTrainedModel):\n-    config_class = GroupViTConfig\n+    config: GroupViTConfig\n \n     def __init__(self, config: GroupViTConfig):\n         super().__init__(config)"
        },
        {
            "sha": "f68f810ddab93e2d78689c119635061c379f80d1",
            "filename": "src/transformers/models/helium/modeling_helium.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fhelium%2Fmodeling_helium.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fhelium%2Fmodeling_helium.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhelium%2Fmodeling_helium.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -307,7 +307,7 @@ def forward(\n \n @auto_docstring\n class HeliumPreTrainedModel(PreTrainedModel):\n-    config_class = HeliumConfig\n+    config: HeliumConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"HeliumDecoderLayer\"]"
        },
        {
            "sha": "e9620ade4053bf5b2e62b80f309e8948fd5393e4",
            "filename": "src/transformers/models/hgnet_v2/modeling_hgnet_v2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fhgnet_v2%2Fmodeling_hgnet_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fhgnet_v2%2Fmodeling_hgnet_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhgnet_v2%2Fmodeling_hgnet_v2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -40,7 +40,7 @@\n \n @auto_docstring\n class HGNetV2PreTrainedModel(PreTrainedModel):\n-    config_class = HGNetV2Config\n+    config: HGNetV2Config\n     base_model_prefix = \"hgnetv2\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [\"HGNetV2BasicLayer\"]"
        },
        {
            "sha": "f5b8735f46a96e0ba3118dce049fdae2dfe31bce",
            "filename": "src/transformers/models/hgnet_v2/modular_hgnet_v2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fhgnet_v2%2Fmodular_hgnet_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fhgnet_v2%2Fmodular_hgnet_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhgnet_v2%2Fmodular_hgnet_v2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -165,7 +165,7 @@ def __init__(\n \n @auto_docstring\n class HGNetV2PreTrainedModel(PreTrainedModel):\n-    config_class = HGNetV2Config\n+    config: HGNetV2Config\n     base_model_prefix = \"hgnetv2\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [\"HGNetV2BasicLayer\"]"
        },
        {
            "sha": "2fcd827e89ce987a8cd8999da84311bef5a6cbe3",
            "filename": "src/transformers/models/hiera/modeling_hiera.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fhiera%2Fmodeling_hiera.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fhiera%2Fmodeling_hiera.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhiera%2Fmodeling_hiera.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -791,7 +791,7 @@ def unroll(\n \n @auto_docstring\n class HieraPreTrainedModel(PreTrainedModel):\n-    config_class = HieraConfig\n+    config: HieraConfig\n     base_model_prefix = \"hiera\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "63df33beebfae560fc2780492dfe4a809f99ea15",
            "filename": "src/transformers/models/hubert/modeling_hubert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fhubert%2Fmodeling_hubert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fhubert%2Fmodeling_hubert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhubert%2Fmodeling_hubert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -679,7 +679,7 @@ def _update_full_mask(\n \n @auto_docstring\n class HubertPreTrainedModel(PreTrainedModel):\n-    config_class = HubertConfig\n+    config: HubertConfig\n     base_model_prefix = \"hubert\"\n     main_input_name = \"input_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "facebcf445e6bdfd75c7880aefad84e136f4da88",
            "filename": "src/transformers/models/hubert/modular_hubert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fhubert%2Fmodular_hubert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fhubert%2Fmodular_hubert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhubert%2Fmodular_hubert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -125,7 +125,7 @@ class HubertEncoderStableLayerNorm(Wav2Vec2EncoderStableLayerNorm):\n \n @auto_docstring\n class HubertPreTrainedModel(PreTrainedModel):\n-    config_class = HubertConfig\n+    config: HubertConfig\n     base_model_prefix = \"hubert\"\n     main_input_name = \"input_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "6b960148ca9b8cfb416eb6bb82d12c1cb424f695",
            "filename": "src/transformers/models/ibert/modeling_ibert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fibert%2Fmodeling_ibert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fibert%2Fmodeling_ibert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fibert%2Fmodeling_ibert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -623,7 +623,7 @@ def forward(self, hidden_states):\n \n @auto_docstring\n class IBertPreTrainedModel(PreTrainedModel):\n-    config_class = IBertConfig\n+    config: IBertConfig\n     base_model_prefix = \"ibert\"\n \n     def _init_weights(self, module):"
        },
        {
            "sha": "9ac09ca6d053fd2e5ab0eb9564c80eb83f5a7881",
            "filename": "src/transformers/models/idefics/modeling_idefics.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fidefics%2Fmodeling_idefics.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fidefics%2Fmodeling_idefics.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics%2Fmodeling_idefics.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -873,7 +873,7 @@ def forward(\n \n @auto_docstring\n class IdeficsPreTrainedModel(PreTrainedModel):\n-    config_class = IdeficsConfig\n+    config: IdeficsConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"IdeficsDecoderLayer\", \"IdeficsGatedCrossAttentionLayer\"]"
        },
        {
            "sha": "60022d781a075f5ed818d53d7c0a758a6e9dcf0f",
            "filename": "src/transformers/models/idefics2/modeling_idefics2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -451,7 +451,7 @@ def forward(\n \n @auto_docstring\n class Idefics2PreTrainedModel(PreTrainedModel):\n-    config_class = Idefics2Config\n+    config: Idefics2Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Idefics2VisionAttention\", \"Idefics2MLP\", \"Idefics2PerceiverLayer\", \"Idefics2DecoderLayer\"]\n@@ -492,7 +492,7 @@ def _init_weights(self, module):\n     \"\"\"\n )\n class Idefics2VisionTransformer(Idefics2PreTrainedModel):\n-    config_class = Idefics2VisionConfig\n+    config: Idefics2VisionConfig\n     _supports_sdpa = True\n     _supports_flash_attn = True\n     _supports_flex_attn = True\n@@ -779,7 +779,7 @@ def forward(\n     \"\"\"\n )\n class Idefics2PerceiverResampler(Idefics2PreTrainedModel):\n-    config_class = Idefics2PerceiverConfig\n+    config: Idefics2PerceiverConfig\n     _supports_sdpa = True\n     _supports_flash_attention_2 = True\n     _supports_flex_attn = True"
        },
        {
            "sha": "bb0cd4f70f20a7d952916259423f76c0cb8b9acc",
            "filename": "src/transformers/models/idefics3/modeling_idefics3.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -468,7 +468,7 @@ def forward(self, image_hidden_states):\n \n @auto_docstring\n class Idefics3PreTrainedModel(PreTrainedModel):\n-    config_class = Idefics3Config\n+    config: Idefics3Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Idefics3VisionAttention\", \"Idefics3DecoderLayer\"]\n@@ -503,7 +503,7 @@ def _init_weights(self, module):\n     \"\"\"\n )\n class Idefics3VisionTransformer(Idefics3PreTrainedModel):\n-    config_class = Idefics3VisionConfig\n+    config: Idefics3VisionConfig\n     _supports_sdpa = True\n     _supports_flash_attn = True\n     _supports_flex_attn = True"
        },
        {
            "sha": "51d09184a1f9ff8841aa2c78e01b1973218bf80b",
            "filename": "src/transformers/models/ijepa/modeling_ijepa.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -145,7 +145,7 @@ def forward(\n \n @auto_docstring\n class IJepaPreTrainedModel(PreTrainedModel):\n-    config_class = IJepaConfig\n+    config: IJepaConfig\n     base_model_prefix = \"ijepa\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "4749c3f598e0ebc9f0b6465918b80a7f1be2db2f",
            "filename": "src/transformers/models/ijepa/modular_ijepa.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodular_ijepa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodular_ijepa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodular_ijepa.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -88,7 +88,7 @@ def forward(\n \n @auto_docstring\n class IJepaPreTrainedModel(PreTrainedModel):\n-    config_class = IJepaConfig\n+    config: IJepaConfig\n     base_model_prefix = \"ijepa\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "cbac5c2792f9138aff7cbab17c0219bf57fa368f",
            "filename": "src/transformers/models/imagegpt/modeling_imagegpt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fimagegpt%2Fmodeling_imagegpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fimagegpt%2Fmodeling_imagegpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fimagegpt%2Fmodeling_imagegpt.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -498,7 +498,7 @@ def forward(\n \n @auto_docstring\n class ImageGPTPreTrainedModel(PreTrainedModel):\n-    config_class = ImageGPTConfig\n+    config: ImageGPTConfig\n     load_tf_weights = load_tf_weights_in_imagegpt\n     base_model_prefix = \"transformer\"\n     main_input_name = \"input_ids\""
        },
        {
            "sha": "d914b2553180029a509eb7014202033ee08bca4c",
            "filename": "src/transformers/models/informer/modeling_informer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Finformer%2Fmodeling_informer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Finformer%2Fmodeling_informer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finformer%2Fmodeling_informer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -251,7 +251,7 @@ def forward(self, x):\n \n @auto_docstring\n class InformerPreTrainedModel(PreTrainedModel):\n-    config_class = InformerConfig\n+    config: InformerConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"past_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "4e306b1753406649cc7614717952840d120d93a4",
            "filename": "src/transformers/models/informer/modular_informer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Finformer%2Fmodular_informer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Finformer%2Fmodular_informer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finformer%2Fmodular_informer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -92,7 +92,7 @@ class InformerValueEmbedding(TimeSeriesValueEmbedding):\n \n @auto_docstring\n class InformerPreTrainedModel(PreTrainedModel):\n-    config_class = InformerConfig\n+    config: InformerConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"past_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "b88c003660b4dd4d5e6b4f2d42ca35710aae2c15",
            "filename": "src/transformers/models/instructblip/modeling_instructblip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Finstructblip%2Fmodeling_instructblip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Finstructblip%2Fmodeling_instructblip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finstructblip%2Fmodeling_instructblip.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -332,7 +332,7 @@ def forward(\n \n @auto_docstring\n class InstructBlipPreTrainedModel(PreTrainedModel):\n-    config_class = InstructBlipConfig\n+    config: InstructBlipConfig\n     base_model_prefix = \"blip\"\n     supports_gradient_checkpointing = True\n     _supports_attention_backend = True\n@@ -452,7 +452,7 @@ def forward(\n # Copied from transformers.models.blip.modeling_blip.BlipVisionModel with Blip->InstructBlip, BLIP->INSTRUCTBLIP\n class InstructBlipVisionModel(InstructBlipPreTrainedModel):\n     main_input_name = \"pixel_values\"\n-    config_class = InstructBlipVisionConfig\n+    config: InstructBlipVisionConfig\n \n     def __init__(self, config: InstructBlipVisionConfig):\n         super().__init__(config)\n@@ -1351,7 +1351,7 @@ def forward(\n     \"\"\"\n )\n class InstructBlipForConditionalGeneration(InstructBlipPreTrainedModel, GenerationMixin):\n-    config_class = InstructBlipConfig\n+    config: InstructBlipConfig\n     main_input_name = \"pixel_values\"\n \n     _supports_static_cache = True"
        },
        {
            "sha": "cec91982532454141964b3ced786e413dc93b419",
            "filename": "src/transformers/models/instructblipvideo/modeling_instructblipvideo.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodeling_instructblipvideo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodeling_instructblipvideo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fmodeling_instructblipvideo.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -819,7 +819,7 @@ def forward(\n \n @auto_docstring\n class InstructBlipVideoPreTrainedModel(PreTrainedModel):\n-    config_class = InstructBlipVideoConfig\n+    config: InstructBlipVideoConfig\n     base_model_prefix = \"blip\"\n     supports_gradient_checkpointing = True\n     _supports_attention_backend = True\n@@ -858,7 +858,7 @@ def _init_weights(self, module):\n \n class InstructBlipVideoVisionModel(InstructBlipVideoPreTrainedModel):\n     main_input_name = \"pixel_values\"\n-    config_class = InstructBlipVideoVisionConfig\n+    config: InstructBlipVideoVisionConfig\n \n     def __init__(self, config: InstructBlipVideoVisionConfig):\n         super().__init__(config)\n@@ -1357,7 +1357,7 @@ def forward(\n     \"\"\"\n )\n class InstructBlipVideoForConditionalGeneration(InstructBlipVideoPreTrainedModel, GenerationMixin):\n-    config_class = InstructBlipVideoConfig\n+    config: InstructBlipVideoConfig\n     main_input_name = \"pixel_values\"\n \n     _supports_static_cache = True"
        },
        {
            "sha": "983d16ef03bd43b8f82de2a1761bd3560daef578",
            "filename": "src/transformers/models/internvl/modeling_internvl.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodeling_internvl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodeling_internvl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodeling_internvl.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -173,7 +173,7 @@ def forward(\n \n @auto_docstring\n class InternVLVisionPreTrainedModel(PreTrainedModel):\n-    config_class = InternVLVisionConfig\n+    config: InternVLVisionConfig\n     base_model_prefix = \"internvl_vision\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True\n@@ -516,7 +516,7 @@ def forward(\n \n @auto_docstring\n class InternVLPreTrainedModel(PreTrainedModel):\n-    config_class = InternVLConfig\n+    config: InternVLConfig\n     base_model_prefix = \"\"\n     supports_gradient_checkpointing = True\n     _skip_keys_device_placement = \"past_key_values\""
        },
        {
            "sha": "45d8c3be3e7cbf1c41d2dc9d239078ead229520f",
            "filename": "src/transformers/models/internvl/modular_internvl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodular_internvl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodular_internvl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodular_internvl.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -135,7 +135,7 @@ def forward(\n \n @auto_docstring\n class InternVLVisionPreTrainedModel(PreTrainedModel):\n-    config_class = InternVLVisionConfig\n+    config: InternVLVisionConfig\n     base_model_prefix = \"internvl_vision\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "52c5d7828a85a8de378c785f4e158862705a8c03",
            "filename": "src/transformers/models/jamba/modeling_jamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1064,7 +1064,7 @@ def forward(\n \n @auto_docstring\n class JambaPreTrainedModel(PreTrainedModel):\n-    config_class = JambaConfig\n+    config: JambaConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"JambaAttentionDecoderLayer\", \"JambaMambaDecoderLayer\"]"
        },
        {
            "sha": "3cd578bc803468ef33d628a9c3446348d4e065d9",
            "filename": "src/transformers/models/janus/modeling_janus.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -55,7 +55,7 @@\n \n @auto_docstring\n class JanusPreTrainedModel(PreTrainedModel):\n-    config_class = JanusConfig\n+    config: JanusConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"LlamaDecoderLayer\", \"JanusVisionEncoderLayer\"]\n@@ -513,7 +513,7 @@ def forward(\n @auto_docstring\n class JanusVisionModel(JanusPreTrainedModel):\n     main_input_name = \"pixel_values\"\n-    config_class = JanusVisionConfig\n+    config: JanusVisionConfig\n \n     def __init__(self, config: JanusVisionConfig):\n         super().__init__(config)\n@@ -932,7 +932,7 @@ def forward(self, hidden_state: torch.FloatTensor) -> torch.FloatTensor:\n     \"\"\"\n )\n class JanusVQVAE(JanusPreTrainedModel):\n-    config_class = JanusVQVAEConfig\n+    config: JanusVQVAEConfig\n     _no_split_modules = [\n         \"JanusVQVAEAttnBlock\",\n         \"JanusVQVAEResnetBlock\","
        },
        {
            "sha": "313b4313291e0b3e4e4722a9e802d04c5b9d7b6b",
            "filename": "src/transformers/models/janus/modular_janus.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodular_janus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodular_janus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodular_janus.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -382,7 +382,7 @@ def __init__(\n \n @auto_docstring\n class JanusPreTrainedModel(PreTrainedModel):\n-    config_class = JanusConfig\n+    config: JanusConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"LlamaDecoderLayer\", \"JanusVisionEncoderLayer\"]"
        },
        {
            "sha": "224d35f97b793ef34737179d4a6849c4cec9955f",
            "filename": "src/transformers/models/jetmoe/modeling_jetmoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -821,7 +821,7 @@ def forward(\n \n @auto_docstring\n class JetMoePreTrainedModel(PreTrainedModel):\n-    config_class = JetMoeConfig\n+    config: JetMoeConfig\n     base_model_prefix = \"transformer\"\n     supports_gradient_checkpointing = False\n     _no_split_modules = [\"JetMoeBlock\"]"
        },
        {
            "sha": "2082d68f29371d64bcad86fb8c5bd868da87d0e8",
            "filename": "src/transformers/models/kosmos2/modeling_kosmos2.py",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fmodeling_kosmos2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fmodeling_kosmos2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fmodeling_kosmos2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1149,7 +1149,7 @@ def forward(\n \n @auto_docstring\n class Kosmos2PreTrainedModel(PreTrainedModel):\n-    config_class = Kosmos2Config\n+    config: Kosmos2Config\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Kosmos2VisionEncoderLayer\", \"Kosmos2TextBlock\"]\n     _supports_attention_backend = True\n@@ -1241,7 +1241,7 @@ def _init_weights(self, module):\n \n \n class Kosmos2VisionModel(Kosmos2PreTrainedModel):\n-    config_class = Kosmos2VisionConfig\n+    config: Kosmos2VisionConfig\n     main_input_name = \"pixel_values\"\n \n     # Copied from transformers.models.clip.modeling_clip.CLIPVisionModel.__init__ with CLIP_VISION->KOSMOS2_VISION,CLIP->Kosmos2,self.vision_model->self.model\n@@ -1274,7 +1274,7 @@ def forward(\n \n \n class Kosmos2TextModel(Kosmos2PreTrainedModel):\n-    config_class = Kosmos2TextConfig\n+    config: Kosmos2TextConfig\n \n     def __init__(self, config: Kosmos2TextConfig):\n         super().__init__(config)\n@@ -1353,7 +1353,7 @@ def forward(\n     \"\"\"\n )\n class Kosmos2TextForCausalLM(Kosmos2PreTrainedModel, GenerationMixin):\n-    config_class = Kosmos2TextConfig\n+    config: Kosmos2TextConfig\n     _tied_weights_keys = [\"lm_head.weight\"]\n \n     def __init__(self, config: Kosmos2TextConfig):\n@@ -1549,7 +1549,7 @@ def forward(self, features):\n     \"\"\"\n )\n class Kosmos2Model(Kosmos2PreTrainedModel):\n-    config_class = Kosmos2Config\n+    config: Kosmos2Config\n     main_input_name = \"pixel_values\"\n \n     def __init__(self, config: Kosmos2Config):\n@@ -1708,7 +1708,7 @@ def forward(\n     \"\"\"\n )\n class Kosmos2ForConditionalGeneration(Kosmos2PreTrainedModel, GenerationMixin):\n-    config_class = Kosmos2Config\n+    config: Kosmos2Config\n     main_input_name = \"pixel_values\"\n     _tied_weights_keys = [\"text_model.lm_head.weight\"]\n "
        },
        {
            "sha": "5892d7649022822198347c0014c6a09b4732b5e1",
            "filename": "src/transformers/models/kyutai_speech_to_text/modeling_kyutai_speech_to_text.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fkyutai_speech_to_text%2Fmodeling_kyutai_speech_to_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fkyutai_speech_to_text%2Fmodeling_kyutai_speech_to_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fkyutai_speech_to_text%2Fmodeling_kyutai_speech_to_text.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -113,7 +113,7 @@ def forward(self, x, layer_idx=None):\n \n @auto_docstring\n class KyutaiSpeechToTextPreTrainedModel(PreTrainedModel):\n-    config_class = KyutaiSpeechToTextConfig\n+    config: KyutaiSpeechToTextConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"KyutaiSpeechToTextDecoderLayer\", \"MimiTransformerLayer\"]"
        },
        {
            "sha": "22f8745f5bb41d559e55011b54d94fc0a3b53b1d",
            "filename": "src/transformers/models/layoutlm/modeling_layoutlm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flayoutlm%2Fmodeling_layoutlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flayoutlm%2Fmodeling_layoutlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flayoutlm%2Fmodeling_layoutlm.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -487,7 +487,7 @@ def forward(self, sequence_output: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class LayoutLMPreTrainedModel(PreTrainedModel):\n-    config_class = LayoutLMConfig\n+    config: LayoutLMConfig\n     base_model_prefix = \"layoutlm\"\n     supports_gradient_checkpointing = True\n "
        },
        {
            "sha": "11d8127ef6c2e15f54492659cb8b70f4360576b7",
            "filename": "src/transformers/models/layoutlmv2/modeling_layoutlmv2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fmodeling_layoutlmv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fmodeling_layoutlmv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fmodeling_layoutlmv2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -468,7 +468,7 @@ def forward(\n \n @auto_docstring\n class LayoutLMv2PreTrainedModel(PreTrainedModel):\n-    config_class = LayoutLMv2Config\n+    config: LayoutLMv2Config\n     base_model_prefix = \"layoutlmv2\"\n \n     def _init_weights(self, module):"
        },
        {
            "sha": "bd8b525bb4275f19a4e28578b61971475e8bc4be",
            "filename": "src/transformers/models/layoutlmv3/modeling_layoutlmv3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flayoutlmv3%2Fmodeling_layoutlmv3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flayoutlmv3%2Fmodeling_layoutlmv3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flayoutlmv3%2Fmodeling_layoutlmv3.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -200,7 +200,7 @@ def forward(\n \n @auto_docstring\n class LayoutLMv3PreTrainedModel(PreTrainedModel):\n-    config_class = LayoutLMv3Config\n+    config: LayoutLMv3Config\n     base_model_prefix = \"layoutlmv3\"\n \n     def _init_weights(self, module):"
        },
        {
            "sha": "ae0f361bd49bc5817a05bc5eafa49f5aefec9c84",
            "filename": "src/transformers/models/led/modeling_led.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fled%2Fmodeling_led.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fled%2Fmodeling_led.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fled%2Fmodeling_led.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1107,7 +1107,7 @@ def forward(self, hidden_states: torch.Tensor):\n \n @auto_docstring\n class LEDPreTrainedModel(PreTrainedModel):\n-    config_class = LEDConfig\n+    config: LEDConfig\n     base_model_prefix = \"led\"\n     supports_gradient_checkpointing = True\n "
        },
        {
            "sha": "fc275a1c4c40418641fc041416223f630fa8188c",
            "filename": "src/transformers/models/levit/modeling_levit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flevit%2Fmodeling_levit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flevit%2Fmodeling_levit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flevit%2Fmodeling_levit.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -468,7 +468,7 @@ def forward(self, hidden_state):\n \n @auto_docstring\n class LevitPreTrainedModel(PreTrainedModel):\n-    config_class = LevitConfig\n+    config: LevitConfig\n     base_model_prefix = \"levit\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [\"LevitResidualLayer\"]"
        },
        {
            "sha": "99b2730507704fe8c12cfb096b77a98cab899752",
            "filename": "src/transformers/models/lfm2/modeling_lfm2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flfm2%2Fmodeling_lfm2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flfm2%2Fmodeling_lfm2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flfm2%2Fmodeling_lfm2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -534,7 +534,7 @@ def forward(\n \n @auto_docstring\n class Lfm2PreTrainedModel(PreTrainedModel):\n-    config_class = Lfm2Config\n+    config: Lfm2Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Lfm2DecoderLayer\"]"
        },
        {
            "sha": "e635f13e33eadd6f8debe8025f0be0a5991cd8a2",
            "filename": "src/transformers/models/lightglue/modeling_lightglue.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flightglue%2Fmodeling_lightglue.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flightglue%2Fmodeling_lightglue.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flightglue%2Fmodeling_lightglue.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -419,7 +419,7 @@ class LightGluePreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = LightGlueConfig\n+    config: LightGlueConfig\n     base_model_prefix = \"lightglue\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = False"
        },
        {
            "sha": "78caf28f1530ea17f918841b7b0919c8ddbb7dad",
            "filename": "src/transformers/models/lightglue/modular_lightglue.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flightglue%2Fmodular_lightglue.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flightglue%2Fmodular_lightglue.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flightglue%2Fmodular_lightglue.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -504,7 +504,7 @@ class LightGluePreTrainedModel(PreTrainedModel):\n     models.\n     \"\"\"\n \n-    config_class = LightGlueConfig\n+    config: LightGlueConfig\n     base_model_prefix = \"lightglue\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = False"
        },
        {
            "sha": "c3bcbf31f0354b2e61a9153b805218b695354b09",
            "filename": "src/transformers/models/lilt/modeling_lilt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flilt%2Fmodeling_lilt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flilt%2Fmodeling_lilt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flilt%2Fmodeling_lilt.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -560,7 +560,7 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class LiltPreTrainedModel(PreTrainedModel):\n-    config_class = LiltConfig\n+    config: LiltConfig\n     base_model_prefix = \"lilt\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = []"
        },
        {
            "sha": "ee7c72aabbb0d0814e8f8dfc0a223d8d1928aa06",
            "filename": "src/transformers/models/llama/modeling_llama.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fllama%2Fmodeling_llama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fllama%2Fmodeling_llama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllama%2Fmodeling_llama.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -306,7 +306,7 @@ def forward(\n \n @auto_docstring\n class LlamaPreTrainedModel(PreTrainedModel):\n-    config_class = LlamaConfig\n+    config: LlamaConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"LlamaDecoderLayer\"]"
        },
        {
            "sha": "3be5760ae22c9f476d700b1b028ba54842d5d258",
            "filename": "src/transformers/models/llama4/modeling_llama4.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllama4%2Fmodeling_llama4.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -430,7 +430,7 @@ def forward(\n \n @auto_docstring\n class Llama4PreTrainedModel(PreTrainedModel):\n-    config_class = Llama4Config\n+    config: Llama4Config\n     supports_gradient_checkpointing = True\n     _skip_keys_device_placement = [\"past_key_values\"]\n     _supports_flash_attn = False\n@@ -471,7 +471,7 @@ def _init_weights(self, module):\n class Llama4TextModel(Llama4PreTrainedModel):\n     _no_split_modules = [\"Llama4TextDecoderLayer\"]\n     base_model_prefix = \"model\"\n-    config_class = Llama4TextConfig\n+    config: Llama4TextConfig\n \n     def __init__(self, config: Llama4TextConfig):\n         super().__init__(config)\n@@ -608,7 +608,7 @@ class Llama4ForCausalLM(Llama4PreTrainedModel, GenerationMixin):\n     base_model_prefix = \"language_model\"\n     _tied_weights_keys = [\"lm_head.weight\"]\n     _tp_plan = {\"lm_head\": \"colwise_rep\"}\n-    config_class = Llama4TextConfig\n+    config: Llama4TextConfig\n \n     def __init__(self, config: Llama4TextConfig):\n         super().__init__(config)\n@@ -1076,7 +1076,7 @@ def forward(self, hidden_states):\n class Llama4VisionModel(Llama4PreTrainedModel):\n     base_model_prefix = \"vision_model\"\n     _no_split_modules = [\"Llama4VisionEncoderLayer\"]\n-    config_class = Llama4VisionConfig\n+    config: Llama4VisionConfig\n \n     def __init__(self, config: Llama4VisionConfig):\n         super().__init__(config)\n@@ -1211,7 +1211,7 @@ class Llama4ForConditionalGeneration(Llama4PreTrainedModel, GenerationMixin):\n     _no_split_modules = [\"Llama4TextDecoderLayer\", \"Llama4VisionEncoderLayer\"]\n     _tp_plan = {}\n     base_model_prefix = \"\"\n-    config_class = Llama4Config\n+    config: Llama4Config\n \n     def __init__(self, config: Llama4Config):\n         super().__init__(config)"
        },
        {
            "sha": "58331bdff0752a71644bd8bff704580359eb795a",
            "filename": "src/transformers/models/llava/modeling_llava.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fllava%2Fmodeling_llava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fllava%2Fmodeling_llava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava%2Fmodeling_llava.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -113,7 +113,7 @@ def forward(self, image_features):\n \n @auto_docstring\n class LlavaPreTrainedModel(PreTrainedModel):\n-    config_class = LlavaConfig\n+    config: LlavaConfig\n     base_model_prefix = \"\"\n     supports_gradient_checkpointing = True\n     _skip_keys_device_placement = \"past_key_values\""
        },
        {
            "sha": "03fa7015d34f52b58534a0c4cd234359e99b9748",
            "filename": "src/transformers/models/llava_next/modeling_llava_next.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fllava_next%2Fmodeling_llava_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fllava_next%2Fmodeling_llava_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_next%2Fmodeling_llava_next.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -223,7 +223,7 @@ def forward(self, image_features):\n \n @auto_docstring\n class LlavaNextPreTrainedModel(PreTrainedModel):\n-    config_class = LlavaNextConfig\n+    config: LlavaNextConfig\n     base_model_prefix = \"\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"LlamaDecoderLayer\"]"
        },
        {
            "sha": "c28a9c1565be02bd59d51050d2f9593a90d32659",
            "filename": "src/transformers/models/llava_next_video/modeling_llava_next_video.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fmodeling_llava_next_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fmodeling_llava_next_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fmodeling_llava_next_video.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -164,7 +164,7 @@ def forward(self, image_features):\n \n @auto_docstring\n class LlavaNextVideoPreTrainedModel(PreTrainedModel):\n-    config_class = LlavaNextVideoConfig\n+    config: LlavaNextVideoConfig\n     base_model_prefix = \"\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"LlamaDecoderLayer\"]"
        },
        {
            "sha": "2d07527f48b75995396f1f7c09bf597ae5eba494",
            "filename": "src/transformers/models/llava_onevision/modeling_llava_onevision.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodeling_llava_onevision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodeling_llava_onevision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fmodeling_llava_onevision.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -277,7 +277,7 @@ def unpad_image(tensor, original_size):\n \n @auto_docstring\n class LlavaOnevisionPreTrainedModel(PreTrainedModel):\n-    config_class = LlavaOnevisionConfig\n+    config: LlavaOnevisionConfig\n     base_model_prefix = \"\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"LlamaDecoderLayer\"]"
        },
        {
            "sha": "e2240c3843664c4d3462e8c5683e8cfb69a3f3a2",
            "filename": "src/transformers/models/longformer/modeling_longformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flongformer%2Fmodeling_longformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flongformer%2Fmodeling_longformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flongformer%2Fmodeling_longformer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1350,7 +1350,7 @@ def _tie_weights(self):\n \n @auto_docstring\n class LongformerPreTrainedModel(PreTrainedModel):\n-    config_class = LongformerConfig\n+    config: LongformerConfig\n     base_model_prefix = \"longformer\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"LongformerSelfAttention\"]"
        },
        {
            "sha": "871e75a12934ccb4fe28da3bae80f837bc631566",
            "filename": "src/transformers/models/longt5/modeling_longt5.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flongt5%2Fmodeling_longt5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flongt5%2Fmodeling_longt5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flongt5%2Fmodeling_longt5.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1245,7 +1245,7 @@ def forward(\n \n @auto_docstring\n class LongT5PreTrainedModel(PreTrainedModel):\n-    config_class = LongT5Config\n+    config: LongT5Config\n     base_model_prefix = \"transformer\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"LongT5Block\"]"
        },
        {
            "sha": "ed1f2084c9e82f8e73e850e41f515664fc3bd0a8",
            "filename": "src/transformers/models/luke/modeling_luke.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fluke%2Fmodeling_luke.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fluke%2Fmodeling_luke.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fluke%2Fmodeling_luke.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -780,7 +780,7 @@ def forward(self, hidden_states):\n \n @auto_docstring\n class LukePreTrainedModel(PreTrainedModel):\n-    config_class = LukeConfig\n+    config: LukeConfig\n     base_model_prefix = \"luke\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"LukeAttention\", \"LukeEntityEmbeddings\"]"
        },
        {
            "sha": "00243ce123299cff8aea89fb8ed8587aa9bc59b4",
            "filename": "src/transformers/models/lxmert/modeling_lxmert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flxmert%2Fmodeling_lxmert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Flxmert%2Fmodeling_lxmert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flxmert%2Fmodeling_lxmert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -759,7 +759,7 @@ def forward(self, sequence_output, pooled_output):\n \n @auto_docstring\n class LxmertPreTrainedModel(PreTrainedModel):\n-    config_class = LxmertConfig\n+    config: LxmertConfig\n     load_tf_weights = load_tf_weights_in_lxmert\n     base_model_prefix = \"lxmert\"\n     _supports_param_buffer_assignment = False"
        },
        {
            "sha": "b45fb0e68b76e11405792f4359abb189b52823bf",
            "filename": "src/transformers/models/m2m_100/modeling_m2m_100.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fm2m_100%2Fmodeling_m2m_100.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fm2m_100%2Fmodeling_m2m_100.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fm2m_100%2Fmodeling_m2m_100.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -516,7 +516,7 @@ def forward(\n \n @auto_docstring\n class M2M100PreTrainedModel(PreTrainedModel):\n-    config_class = M2M100Config\n+    config: M2M100Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"M2M100EncoderLayer\", \"M2M100DecoderLayer\"]"
        },
        {
            "sha": "fd0e362e9f08c32beb5feb153880b5acb155829f",
            "filename": "src/transformers/models/mamba/modeling_mamba.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmamba%2Fmodeling_mamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmamba%2Fmodeling_mamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmamba%2Fmodeling_mamba.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -374,7 +374,7 @@ def forward(\n \n @auto_docstring\n class MambaPreTrainedModel(PreTrainedModel):\n-    config_class = MambaConfig\n+    config: MambaConfig\n     base_model_prefix = \"backbone\"\n     _no_split_modules = [\"MambaBlock\", \"MambaMixer\"]\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "2511c1809db1f9b29e91583942bfc06c7dfcb921",
            "filename": "src/transformers/models/mamba2/modeling_mamba2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmamba2%2Fmodeling_mamba2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmamba2%2Fmodeling_mamba2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmamba2%2Fmodeling_mamba2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -713,7 +713,7 @@ def forward(\n \n @auto_docstring\n class Mamba2PreTrainedModel(PreTrainedModel):\n-    config_class = Mamba2Config\n+    config: Mamba2Config\n     base_model_prefix = \"backbone\"\n     _no_split_modules = [\"Mamba2Block\"]\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "052bbe3c1a133aad9819a24d851d97db8ccbe97b",
            "filename": "src/transformers/models/marian/modeling_marian.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmarian%2Fmodeling_marian.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmarian%2Fmodeling_marian.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmarian%2Fmodeling_marian.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -460,7 +460,7 @@ def forward(\n \n @auto_docstring\n class MarianPreTrainedModel(PreTrainedModel):\n-    config_class = MarianConfig\n+    config: MarianConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _supports_flash_attn = True"
        },
        {
            "sha": "3bf6553859637b7b64f1c0a7771275b310b9484f",
            "filename": "src/transformers/models/markuplm/modeling_markuplm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmarkuplm%2Fmodeling_markuplm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmarkuplm%2Fmodeling_markuplm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmarkuplm%2Fmodeling_markuplm.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -579,7 +579,7 @@ def forward(\n \n @auto_docstring\n class MarkupLMPreTrainedModel(PreTrainedModel):\n-    config_class = MarkupLMConfig\n+    config: MarkupLMConfig\n     base_model_prefix = \"markuplm\"\n \n     # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights with Bert->MarkupLM"
        },
        {
            "sha": "7f730bdb99a1de69e923478e477276a863c7ebbe",
            "filename": "src/transformers/models/mask2former/modeling_mask2former.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmask2former%2Fmodeling_mask2former.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmask2former%2Fmodeling_mask2former.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmask2former%2Fmodeling_mask2former.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -2085,7 +2085,7 @@ def forward(\n \n @auto_docstring\n class Mask2FormerPreTrainedModel(PreTrainedModel):\n-    config_class = Mask2FormerConfig\n+    config: Mask2FormerConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"pixel_values\"\n "
        },
        {
            "sha": "3be1021a2c2988fb67b9ed4dd1cae07fe2434c31",
            "filename": "src/transformers/models/maskformer/modeling_maskformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fmodeling_maskformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fmodeling_maskformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fmodeling_maskformer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1419,7 +1419,7 @@ def forward(\n \n @auto_docstring\n class MaskFormerPreTrainedModel(PreTrainedModel):\n-    config_class = MaskFormerConfig\n+    config: MaskFormerConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"pixel_values\"\n "
        },
        {
            "sha": "22e91c0970bf24bacac6715dc0f60adc1971254d",
            "filename": "src/transformers/models/maskformer/modeling_maskformer_swin.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fmodeling_maskformer_swin.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fmodeling_maskformer_swin.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fmodeling_maskformer_swin.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -734,7 +734,7 @@ def forward(\n \n @auto_docstring\n class MaskFormerSwinPreTrainedModel(PreTrainedModel):\n-    config_class = MaskFormerSwinConfig\n+    config: MaskFormerSwinConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "63b6ec0cb15fe8d0c947b6e227f9bb62a8144cc6",
            "filename": "src/transformers/models/mbart/modeling_mbart.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmbart%2Fmodeling_mbart.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmbart%2Fmodeling_mbart.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmbart%2Fmodeling_mbart.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -485,7 +485,7 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class MBartPreTrainedModel(PreTrainedModel):\n-    config_class = MBartConfig\n+    config: MBartConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"MBartDecoderLayer\", \"MBartEncoderLayer\", \"MBartAttention\"]"
        },
        {
            "sha": "d55734c2671a8fc0be1ca6ac45049a3fff46e2df",
            "filename": "src/transformers/models/megatron_bert/modeling_megatron_bert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmegatron_bert%2Fmodeling_megatron_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmegatron_bert%2Fmodeling_megatron_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmegatron_bert%2Fmodeling_megatron_bert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -679,7 +679,7 @@ def forward(self, sequence_output, pooled_output):\n \n @auto_docstring\n class MegatronBertPreTrainedModel(PreTrainedModel):\n-    config_class = MegatronBertConfig\n+    config: MegatronBertConfig\n     load_tf_weights = load_tf_weights_in_megatron_bert\n     base_model_prefix = \"bert\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "27b9d0df9dd6994f926d29a66cb80c225f265f9e",
            "filename": "src/transformers/models/mgp_str/modeling_mgp_str.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmgp_str%2Fmodeling_mgp_str.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmgp_str%2Fmodeling_mgp_str.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmgp_str%2Fmodeling_mgp_str.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -286,7 +286,7 @@ def forward(self, hidden_states):\n \n @auto_docstring\n class MgpstrPreTrainedModel(PreTrainedModel):\n-    config_class = MgpstrConfig\n+    config: MgpstrConfig\n     base_model_prefix = \"mgp_str\"\n     _no_split_modules = []\n \n@@ -357,7 +357,7 @@ def forward(\n     \"\"\"\n )\n class MgpstrForSceneTextRecognition(MgpstrPreTrainedModel):\n-    config_class = MgpstrConfig\n+    config: MgpstrConfig\n     main_input_name = \"pixel_values\"\n \n     def __init__(self, config: MgpstrConfig) -> None:"
        },
        {
            "sha": "0be377794d0a9859f7eea49c37d86b9e7d51a178",
            "filename": "src/transformers/models/mimi/modeling_mimi.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmimi%2Fmodeling_mimi.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmimi%2Fmodeling_mimi.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmimi%2Fmodeling_mimi.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1367,7 +1367,7 @@ def decode(self, codes: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class MimiPreTrainedModel(PreTrainedModel):\n-    config_class = MimiConfig\n+    config: MimiConfig\n     base_model_prefix = \"mimi\"\n     main_input_name = \"input_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "40ef35a3a6fa8a9f250ba187feb2b61e622f043b",
            "filename": "src/transformers/models/minimax/modeling_minimax.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodeling_minimax.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodeling_minimax.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodeling_minimax.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -580,7 +580,7 @@ def forward(\n \n @auto_docstring\n class MiniMaxPreTrainedModel(PreTrainedModel):\n-    config_class = MiniMaxConfig\n+    config: MiniMaxConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"MiniMaxDecoderLayer\"]"
        },
        {
            "sha": "29727dc415907192ed42c728b4f4305fb851c45e",
            "filename": "src/transformers/models/mistral/modeling_mistral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodeling_mistral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodeling_mistral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodeling_mistral.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -251,7 +251,7 @@ def forward(\n \n @auto_docstring\n class MistralPreTrainedModel(PreTrainedModel):\n-    config_class = MistralConfig\n+    config: MistralConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"MistralDecoderLayer\"]"
        },
        {
            "sha": "769697ada0ca05696abd5033339adbb4171a81f5",
            "filename": "src/transformers/models/mistral3/modeling_mistral3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmistral3%2Fmodeling_mistral3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmistral3%2Fmodeling_mistral3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmistral3%2Fmodeling_mistral3.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -178,7 +178,7 @@ class Mistral3ModelOutputWithPast(BaseModelOutputWithPast):\n \n @auto_docstring\n class Mistral3PreTrainedModel(PreTrainedModel):\n-    config_class = Mistral3Config\n+    config: Mistral3Config\n     base_model_prefix = \"\"\n     supports_gradient_checkpointing = True\n     _skip_keys_device_placement = \"past_key_values\""
        },
        {
            "sha": "671bc0390a392326fdfc79328b9586dbe45b02f8",
            "filename": "src/transformers/models/mixtral/modeling_mixtral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -380,7 +380,7 @@ def forward(self, x, position_ids):\n \n @auto_docstring\n class MixtralPreTrainedModel(PreTrainedModel):\n-    config_class = MixtralConfig\n+    config: MixtralConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"MixtralDecoderLayer\"]"
        },
        {
            "sha": "28919dae1d732b757d33e67491896f11e6cd5ab2",
            "filename": "src/transformers/models/mlcd/modeling_mlcd.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmlcd%2Fmodeling_mlcd.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmlcd%2Fmodeling_mlcd.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmlcd%2Fmodeling_mlcd.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -505,7 +505,7 @@ def forward(\n \n @auto_docstring\n class MLCDPreTrainedModel(PreTrainedModel):\n-    config_class = MLCDVisionConfig\n+    config: MLCDVisionConfig\n     base_model_prefix = \"mlcd\"\n     supports_gradient_checkpointing = True\n     _supports_flash_attn = True\n@@ -549,7 +549,7 @@ def _init_weights(self, module):\n     \"\"\"\n )\n class MLCDVisionModel(MLCDPreTrainedModel):\n-    config_class = MLCDVisionConfig\n+    config: MLCDVisionConfig\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [\"MLCDEncoderLayer\"]\n "
        },
        {
            "sha": "fcc18ab2b1c8f123be84c502d534c6000882a683",
            "filename": "src/transformers/models/mlcd/modular_mlcd.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmlcd%2Fmodular_mlcd.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmlcd%2Fmodular_mlcd.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmlcd%2Fmodular_mlcd.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -439,7 +439,7 @@ def forward(\n \n @auto_docstring\n class MLCDPreTrainedModel(PreTrainedModel):\n-    config_class = MLCDVisionConfig\n+    config: MLCDVisionConfig\n     base_model_prefix = \"mlcd\"\n     supports_gradient_checkpointing = True\n     _supports_flash_attn = True"
        },
        {
            "sha": "b520b75001c0afeec0c082a27dde14ca33e236c6",
            "filename": "src/transformers/models/mllama/modeling_mllama.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmllama%2Fmodeling_mllama.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -841,7 +841,7 @@ def forward(self, x, position_ids):\n \n @auto_docstring\n class MllamaPreTrainedModel(PreTrainedModel):\n-    config_class = MllamaConfig\n+    config: MllamaConfig\n     base_model_prefix = \"\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\n@@ -1019,7 +1019,7 @@ def _prepare_4d_causal_attention_mask_with_cache_position(\n     \"\"\"\n )\n class MllamaVisionModel(MllamaPreTrainedModel):\n-    config_class = MllamaVisionConfig\n+    config: MllamaVisionConfig\n     base_model_prefix = \"vision_model\"\n \n     def __init__(self, config: MllamaVisionConfig):\n@@ -1250,7 +1250,7 @@ def forward(\n     \"\"\"\n )\n class MllamaTextModel(MllamaPreTrainedModel):\n-    config_class = MllamaTextConfig\n+    config: MllamaTextConfig\n     base_model_prefix = \"language_model.model\"\n \n     def __init__(self, config: MllamaTextConfig):\n@@ -1454,7 +1454,7 @@ def forward(\n     \"\"\"\n )\n class MllamaForCausalLM(MllamaPreTrainedModel, GenerationMixin):\n-    config_class = MllamaTextConfig\n+    config: MllamaTextConfig\n     _supports_static_cache = True  # only the LLM without cross attn can do compile\n     base_model_prefix = \"language_model\"\n     _tied_weights_keys = [\"lm_head.weight\"]"
        },
        {
            "sha": "99768685002a2560b492bb8d59e1549d119f475b",
            "filename": "src/transformers/models/mobilebert/modeling_mobilebert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmobilebert%2Fmodeling_mobilebert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmobilebert%2Fmodeling_mobilebert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilebert%2Fmodeling_mobilebert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -658,7 +658,7 @@ def forward(self, sequence_output: torch.Tensor, pooled_output: torch.Tensor) ->\n \n @auto_docstring\n class MobileBertPreTrainedModel(PreTrainedModel):\n-    config_class = MobileBertConfig\n+    config: MobileBertConfig\n     load_tf_weights = load_tf_weights_in_mobilebert\n     base_model_prefix = \"mobilebert\"\n "
        },
        {
            "sha": "47b9f43e8a85c24c1d6e7bd9e93a0d8fe19fe198",
            "filename": "src/transformers/models/mobilenet_v1/modeling_mobilenet_v1.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmobilenet_v1%2Fmodeling_mobilenet_v1.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmobilenet_v1%2Fmodeling_mobilenet_v1.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilenet_v1%2Fmodeling_mobilenet_v1.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -229,7 +229,7 @@ def forward(self, features: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class MobileNetV1PreTrainedModel(PreTrainedModel):\n-    config_class = MobileNetV1Config\n+    config: MobileNetV1Config\n     load_tf_weights = load_tf_weights_in_mobilenet_v1\n     base_model_prefix = \"mobilenet_v1\"\n     main_input_name = \"pixel_values\""
        },
        {
            "sha": "fa213ab9d98d89983733321728dd0442bf300fd7",
            "filename": "src/transformers/models/mobilenet_v2/modeling_mobilenet_v2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmobilenet_v2%2Fmodeling_mobilenet_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmobilenet_v2%2Fmodeling_mobilenet_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilenet_v2%2Fmodeling_mobilenet_v2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -422,7 +422,7 @@ def forward(self, features: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class MobileNetV2PreTrainedModel(PreTrainedModel):\n-    config_class = MobileNetV2Config\n+    config: MobileNetV2Config\n     load_tf_weights = load_tf_weights_in_mobilenet_v2\n     base_model_prefix = \"mobilenet_v2\"\n     main_input_name = \"pixel_values\""
        },
        {
            "sha": "ce6c67e1ad6567936598fe57e7dd49da7973d5db",
            "filename": "src/transformers/models/mobilevit/modeling_mobilevit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fmodeling_mobilevit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fmodeling_mobilevit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fmodeling_mobilevit.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -623,7 +623,7 @@ def forward(\n \n @auto_docstring\n class MobileViTPreTrainedModel(PreTrainedModel):\n-    config_class = MobileViTConfig\n+    config: MobileViTConfig\n     base_model_prefix = \"mobilevit\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "f37f37c60553723f828bb83e75c06b4af1e799f7",
            "filename": "src/transformers/models/mobilevitv2/modeling_mobilevitv2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmobilevitv2%2Fmodeling_mobilevitv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmobilevitv2%2Fmodeling_mobilevitv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilevitv2%2Fmodeling_mobilevitv2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -571,7 +571,7 @@ def forward(\n @auto_docstring\n # Copied from transformers.models.mobilevit.modeling_mobilevit.MobileViTPreTrainedModel with MobileViT->MobileViTV2,mobilevit->mobilevitv2\n class MobileViTV2PreTrainedModel(PreTrainedModel):\n-    config_class = MobileViTV2Config\n+    config: MobileViTV2Config\n     base_model_prefix = \"mobilevitv2\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "9b26635835229962fc71db372df502b565db6e8d",
            "filename": "src/transformers/models/modernbert/modeling_modernbert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodeling_modernbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodeling_modernbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodeling_modernbert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -556,7 +556,7 @@ def forward(\n \n @auto_docstring\n class ModernBertPreTrainedModel(PreTrainedModel):\n-    config_class = ModernBertConfig\n+    config: ModernBertConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"ModernBertEmbeddings\", \"ModernBertEncoderLayer\"]"
        },
        {
            "sha": "3e4041bd8bebc597d3c572aac777c95bc5d54981",
            "filename": "src/transformers/models/modernbert/modular_modernbert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodular_modernbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodular_modernbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodular_modernbert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -756,7 +756,7 @@ def forward(\n \n @auto_docstring\n class ModernBertPreTrainedModel(PreTrainedModel):\n-    config_class = ModernBertConfig\n+    config: ModernBertConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"ModernBertEmbeddings\", \"ModernBertEncoderLayer\"]"
        },
        {
            "sha": "56b53446fdc95cc5b37437993cbc3196136f5062",
            "filename": "src/transformers/models/modernbert_decoder/modeling_modernbert_decoder.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodeling_modernbert_decoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodeling_modernbert_decoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodeling_modernbert_decoder.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -217,7 +217,7 @@ def forward(\n \n @auto_docstring\n class ModernBertDecoderPreTrainedModel(ModernBertPreTrainedModel):\n-    config_class = ModernBertDecoderConfig\n+    config_class: ModernBertDecoderConfig\n     base_model_prefix = \"model\"\n     _skip_keys_device_placement = [\"past_key_values\"]\n     _no_split_modules = [\"ModernBertDecoderLayer\"]"
        },
        {
            "sha": "f82fb1573a921a879289231499c24c58b03fcafc",
            "filename": "src/transformers/models/modernbert_decoder/modular_modernbert_decoder.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodular_modernbert_decoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodular_modernbert_decoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmodernbert_decoder%2Fmodular_modernbert_decoder.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -394,7 +394,7 @@ def forward(\n \n @auto_docstring\n class ModernBertDecoderPreTrainedModel(ModernBertPreTrainedModel):\n-    config_class = ModernBertDecoderConfig\n+    config_class: ModernBertDecoderConfig\n     base_model_prefix = \"model\"\n     _skip_keys_device_placement = [\"past_key_values\"]\n     _no_split_modules = [\"ModernBertDecoderLayer\"]"
        },
        {
            "sha": "61ab1cbcc565553b376afac7b1aec9a95281a8fb",
            "filename": "src/transformers/models/moonshine/modeling_moonshine.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodeling_moonshine.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodeling_moonshine.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodeling_moonshine.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -454,7 +454,7 @@ def forward(\n \n @auto_docstring\n class MoonshinePreTrainedModel(PreTrainedModel):\n-    config_class = MoonshineConfig\n+    config: MoonshineConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"input_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "9706d99d7cd5047ba8c8ba7ba4302ee7cb7c39d4",
            "filename": "src/transformers/models/moonshine/modular_moonshine.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodular_moonshine.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodular_moonshine.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodular_moonshine.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -489,7 +489,7 @@ def forward(\n \n @auto_docstring\n class MoonshinePreTrainedModel(PreTrainedModel):\n-    config_class = MoonshineConfig\n+    config: MoonshineConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"input_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "94a3a1fa1fe329135620b6126698400c7158a084",
            "filename": "src/transformers/models/moshi/modeling_moshi.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmoshi%2Fmodeling_moshi.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmoshi%2Fmodeling_moshi.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmoshi%2Fmodeling_moshi.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -801,7 +801,7 @@ def forward(\n \n @auto_docstring\n class MoshiPreTrainedModel(PreTrainedModel):\n-    config_class = MoshiConfig\n+    config: MoshiConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"MoshiDecoderLayer\", \"MimiTransformerLayer\"]\n@@ -835,7 +835,7 @@ class MoshiDepthDecoder(MoshiPreTrainedModel, GenerationMixin):\n         config: MoshiConfig\n     \"\"\"\n \n-    config_class = MoshiDepthConfig\n+    config: MoshiDepthConfig\n \n     def __init__(self, config: MoshiDepthConfig):\n         super().__init__(config)\n@@ -1628,7 +1628,7 @@ def forward(\n )\n class MoshiForConditionalGeneration(MoshiPreTrainedModel, GenerationMixin):\n     _tied_weights_keys = [\"decoder.model.embed_tokens.weight\", \"decoder.lm_head.weight\"]\n-    config_class = MoshiConfig\n+    config: MoshiConfig\n     main_input_name = \"input_ids\"\n     supports_gradient_checkpointing = True\n     _supports_flash_attn = True"
        },
        {
            "sha": "b25e5491738b7b5e9270fdfa96f27f7e0f3ce712",
            "filename": "src/transformers/models/mpnet/modeling_mpnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmpnet%2Fmodeling_mpnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmpnet%2Fmodeling_mpnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmpnet%2Fmodeling_mpnet.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -43,7 +43,7 @@\n \n @auto_docstring\n class MPNetPreTrainedModel(PreTrainedModel):\n-    config_class = MPNetConfig\n+    config: MPNetConfig\n     base_model_prefix = \"mpnet\"\n \n     def _init_weights(self, module):"
        },
        {
            "sha": "706318cc7906f09ba7ba56c9cddbbadf5ebe248b",
            "filename": "src/transformers/models/mpt/modeling_mpt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmpt%2Fmodeling_mpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmpt%2Fmodeling_mpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmpt%2Fmodeling_mpt.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -219,7 +219,7 @@ def forward(\n \n @auto_docstring\n class MptPreTrainedModel(PreTrainedModel):\n-    config_class = MptConfig\n+    config: MptConfig\n     base_model_prefix = \"transformer\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"MptBlock\"]"
        },
        {
            "sha": "602cf53cc0c63b54ab437078c879f1b25ff5703b",
            "filename": "src/transformers/models/mra/modeling_mra.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmra%2Fmodeling_mra.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmra%2Fmodeling_mra.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmra%2Fmodeling_mra.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -817,7 +817,7 @@ def forward(self, sequence_output: torch.Tensor) -> torch.Tensor:\n @auto_docstring\n # Copied from transformers.models.yoso.modeling_yoso.YosoPreTrainedModel with Yoso->Mra,yoso->mra\n class MraPreTrainedModel(PreTrainedModel):\n-    config_class = MraConfig\n+    config: MraConfig\n     base_model_prefix = \"mra\"\n     supports_gradient_checkpointing = True\n "
        },
        {
            "sha": "f30bc3073eae798f3407d31ea05d91247ee85491",
            "filename": "src/transformers/models/mt5/modeling_mt5.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmt5%2Fmodeling_mt5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmt5%2Fmodeling_mt5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmt5%2Fmodeling_mt5.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -752,7 +752,7 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n @auto_docstring\n # Copied from transformers.models.t5.modeling_t5.T5PreTrainedModel with T5->MT5, t5->mt5\n class MT5PreTrainedModel(PreTrainedModel):\n-    config_class = MT5Config\n+    config: MT5Config\n     load_tf_weights = load_tf_weights_in_mt5\n     base_model_prefix = \"transformer\"\n     is_parallelizable = True\n@@ -1297,7 +1297,7 @@ class MT5Model(MT5PreTrainedModel):\n     ```\"\"\"\n \n     model_type = \"mt5\"\n-    config_class = MT5Config\n+    config: MT5Config\n     _keys_to_ignore_on_load_unexpected = [\"decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight\"]\n     _tied_weights_keys = [\"encoder.embed_tokens.weight\", \"decoder.embed_tokens.weight\"]\n \n@@ -1564,7 +1564,7 @@ class MT5ForConditionalGeneration(MT5PreTrainedModel, GenerationMixin):\n     ```\"\"\"\n \n     model_type = \"mt5\"\n-    config_class = MT5Config\n+    config: MT5Config\n     _keys_to_ignore_on_load_unexpected = [\"decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight\"]\n     _tied_weights_keys = [\"encoder.embed_tokens.weight\", \"decoder.embed_tokens.weight\", \"lm_head.weight\"]\n \n@@ -1874,7 +1874,7 @@ class MT5EncoderModel(MT5PreTrainedModel):\n     ```\"\"\"\n \n     model_type = \"mt5\"\n-    config_class = MT5Config\n+    config: MT5Config\n     _tied_weights_keys = [\"encoder.embed_tokens.weight\"]\n \n     # Copied from transformers.models.t5.modeling_t5.T5EncoderModel.__init__ with T5->MT5"
        },
        {
            "sha": "c2e8e430c7179cccc441a8448bb8cc31e0a526d0",
            "filename": "src/transformers/models/musicgen/modeling_musicgen.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmusicgen%2Fmodeling_musicgen.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmusicgen%2Fmodeling_musicgen.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmusicgen%2Fmodeling_musicgen.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -419,7 +419,7 @@ def forward(\n \n @auto_docstring\n class MusicgenPreTrainedModel(PreTrainedModel):\n-    config_class = MusicgenDecoderConfig\n+    config: MusicgenDecoderConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"MusicgenDecoderLayer\", \"MusicgenAttention\"]\n@@ -1340,7 +1340,7 @@ def generate(\n     \"\"\"\n )\n class MusicgenForConditionalGeneration(PreTrainedModel, GenerationMixin):\n-    config_class = MusicgenConfig\n+    config: MusicgenConfig\n     base_model_prefix = \"encoder_decoder\"\n     main_input_name = \"input_ids\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "fce8bea6b4ac2719ba22233182c64211b93a3036",
            "filename": "src/transformers/models/musicgen_melody/modeling_musicgen_melody.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmusicgen_melody%2Fmodeling_musicgen_melody.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmusicgen_melody%2Fmodeling_musicgen_melody.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmusicgen_melody%2Fmodeling_musicgen_melody.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -384,7 +384,7 @@ def forward(\n @auto_docstring\n # Copied from transformers.models.musicgen.modeling_musicgen.MusicgenPreTrainedModel with Musicgen->MusicgenMelody\n class MusicgenMelodyPreTrainedModel(PreTrainedModel):\n-    config_class = MusicgenMelodyDecoderConfig\n+    config: MusicgenMelodyDecoderConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"MusicgenMelodyDecoderLayer\", \"MusicgenMelodyAttention\"]\n@@ -1269,7 +1269,7 @@ def generate(\n \n @auto_docstring\n class MusicgenMelodyForConditionalGeneration(PreTrainedModel, GenerationMixin):\n-    config_class = MusicgenMelodyConfig\n+    config: MusicgenMelodyConfig\n     main_input_name = \"input_ids\"\n     supports_gradient_checkpointing = True\n     _supports_flash_attn = True"
        },
        {
            "sha": "fd8f19ecccb4ac3511752b8b80b0edf4d645a66e",
            "filename": "src/transformers/models/mvp/modeling_mvp.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmvp%2Fmodeling_mvp.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fmvp%2Fmodeling_mvp.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmvp%2Fmodeling_mvp.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -486,7 +486,7 @@ def forward(self, prompt_ids: torch.Tensor) -> tuple[torch.Tensor]:\n \n @auto_docstring\n class MvpPreTrainedModel(PreTrainedModel):\n-    config_class = MvpConfig\n+    config: MvpConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n "
        },
        {
            "sha": "8da4a3bde89de2cef7052f029c5ffed60a2b432d",
            "filename": "src/transformers/models/nemotron/modeling_nemotron.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fnemotron%2Fmodeling_nemotron.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fnemotron%2Fmodeling_nemotron.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fnemotron%2Fmodeling_nemotron.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -581,7 +581,7 @@ def forward(\n \n @auto_docstring\n class NemotronPreTrainedModel(PreTrainedModel):\n-    config_class = NemotronConfig\n+    config: NemotronConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"NemotronDecoderLayer\"]"
        },
        {
            "sha": "5537d8c1286d4f135a16973cbea2a26a93a15cb7",
            "filename": "src/transformers/models/nllb_moe/modeling_nllb_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fmodeling_nllb_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fmodeling_nllb_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fmodeling_nllb_moe.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -839,7 +839,7 @@ def forward(\n \n @auto_docstring\n class NllbMoePreTrainedModel(PreTrainedModel):\n-    config_class = NllbMoeConfig\n+    config: NllbMoeConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"NllbMoeEncoderLayer\", \"NllbMoeDecoderLayer\"]"
        },
        {
            "sha": "45e69b6b469389d0c57390c2fb0582cad4a07f53",
            "filename": "src/transformers/models/nystromformer/modeling_nystromformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fnystromformer%2Fmodeling_nystromformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fnystromformer%2Fmodeling_nystromformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fnystromformer%2Fmodeling_nystromformer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -443,7 +443,7 @@ def forward(self, sequence_output: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class NystromformerPreTrainedModel(PreTrainedModel):\n-    config_class = NystromformerConfig\n+    config: NystromformerConfig\n     base_model_prefix = \"nystromformer\"\n     supports_gradient_checkpointing = True\n "
        },
        {
            "sha": "ef66f62236f53bd02ea615d7a1ee3d538a6a5e10",
            "filename": "src/transformers/models/olmo/modeling_olmo.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Folmo%2Fmodeling_olmo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Folmo%2Fmodeling_olmo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmo%2Fmodeling_olmo.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -285,7 +285,7 @@ def forward(self, x, position_ids):\n \n @auto_docstring\n class OlmoPreTrainedModel(PreTrainedModel):\n-    config_class = OlmoConfig\n+    config: OlmoConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"OlmoDecoderLayer\"]"
        },
        {
            "sha": "fde7f95adfd0c68df8eebeef323e44343190e439",
            "filename": "src/transformers/models/olmo2/modeling_olmo2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Folmo2%2Fmodeling_olmo2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Folmo2%2Fmodeling_olmo2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmo2%2Fmodeling_olmo2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -290,7 +290,7 @@ def forward(self, x, position_ids):\n \n @auto_docstring\n class Olmo2PreTrainedModel(PreTrainedModel):\n-    config_class = Olmo2Config\n+    config: Olmo2Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Olmo2DecoderLayer\"]"
        },
        {
            "sha": "89ebcb2013edb7d0ab386784fcb0cfb152bb11fe",
            "filename": "src/transformers/models/olmoe/modeling_olmoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -698,7 +698,7 @@ def forward(\n \n @auto_docstring\n class OlmoePreTrainedModel(PreTrainedModel):\n-    config_class = OlmoeConfig\n+    config: OlmoeConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"OlmoeDecoderLayer\"]"
        },
        {
            "sha": "8256f070dff6032ff7077d739c367f91d3fcf51c",
            "filename": "src/transformers/models/omdet_turbo/modeling_omdet_turbo.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fomdet_turbo%2Fmodeling_omdet_turbo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fomdet_turbo%2Fmodeling_omdet_turbo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fomdet_turbo%2Fmodeling_omdet_turbo.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -982,7 +982,7 @@ def forward(\n \n @auto_docstring\n class OmDetTurboPreTrainedModel(PreTrainedModel):\n-    config_class = OmDetTurboConfig\n+    config: OmDetTurboConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"pixel_values\"\n "
        },
        {
            "sha": "53160467c729a0d2220febf000056d8b2bf9e37c",
            "filename": "src/transformers/models/oneformer/modeling_oneformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Foneformer%2Fmodeling_oneformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Foneformer%2Fmodeling_oneformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Foneformer%2Fmodeling_oneformer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -2757,7 +2757,7 @@ def forward(self, inputs: Tensor) -> Tensor:\n \n @auto_docstring\n class OneFormerPreTrainedModel(PreTrainedModel):\n-    config_class = OneFormerConfig\n+    config: OneFormerConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"pixel_values\"\n "
        },
        {
            "sha": "074af9ce119c742b2401729b12940b036447734a",
            "filename": "src/transformers/models/openai/modeling_openai.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fopenai%2Fmodeling_openai.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fopenai%2Fmodeling_openai.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fopenai%2Fmodeling_openai.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -358,7 +358,7 @@ def forward(\n \n @auto_docstring\n class OpenAIGPTPreTrainedModel(PreTrainedModel):\n-    config_class = OpenAIGPTConfig\n+    config: OpenAIGPTConfig\n     load_tf_weights = load_tf_weights_in_openai_gpt\n     base_model_prefix = \"transformer\"\n "
        },
        {
            "sha": "e275168017d5cc6879578ddaceedbbc659062d88",
            "filename": "src/transformers/models/opt/modeling_opt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fopt%2Fmodeling_opt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fopt%2Fmodeling_opt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fopt%2Fmodeling_opt.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -304,7 +304,7 @@ def forward(\n \n @auto_docstring\n class OPTPreTrainedModel(PreTrainedModel):\n-    config_class = OPTConfig\n+    config: OPTConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"OPTDecoderLayer\"]"
        },
        {
            "sha": "6294e58d69f3d7474b6bacacfbd1b526415c0527",
            "filename": "src/transformers/models/owlv2/modeling_owlv2.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fowlv2%2Fmodeling_owlv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fowlv2%2Fmodeling_owlv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fowlv2%2Fmodeling_owlv2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -555,7 +555,7 @@ def forward(\n @auto_docstring\n # Copied from transformers.models.owlvit.modeling_owlvit.OwlViTPreTrainedModel with OwlViT->Owlv2,owlvit->owlv2\n class Owlv2PreTrainedModel(PreTrainedModel):\n-    config_class = Owlv2Config\n+    config: Owlv2Config\n     base_model_prefix = \"owlv2\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Owlv2EncoderLayer\"]\n@@ -761,7 +761,7 @@ def forward(\n \n # Copied from transformers.models.owlvit.modeling_owlvit.OwlViTTextModel with google/owlvit-base-patch32->google/owlv2-base-patch16, OWLVIT->OWLV2,OwlViT->Owlv2\n class Owlv2TextModel(Owlv2PreTrainedModel):\n-    config_class = Owlv2TextConfig\n+    config: Owlv2TextConfig\n \n     def __init__(self, config: Owlv2TextConfig):\n         super().__init__(config)\n@@ -872,7 +872,7 @@ def forward(\n \n # Copied from transformers.models.owlvit.modeling_owlvit.OwlViTVisionModel with OWLVIT->OWLV2,OwlViT->Owlv2,google/owlvit-base-patch32->google/owlv2-base-patch16\n class Owlv2VisionModel(Owlv2PreTrainedModel):\n-    config_class = Owlv2VisionConfig\n+    config: Owlv2VisionConfig\n     main_input_name = \"pixel_values\"\n \n     def __init__(self, config: Owlv2VisionConfig):\n@@ -923,7 +923,7 @@ def forward(\n @auto_docstring\n # Copied from transformers.models.owlvit.modeling_owlvit.OwlViTModel with google/owlvit-base-patch32->google/owlv2-base-patch16-ensemble, OWLVIT->OWLV2,OwlViT->Owlv2,owlvit->owlv2,OWL-ViT->OWLv2\n class Owlv2Model(Owlv2PreTrainedModel):\n-    config_class = Owlv2Config\n+    config: Owlv2Config\n \n     def __init__(self, config: Owlv2Config):\n         super().__init__(config)\n@@ -1208,7 +1208,7 @@ def forward(\n \n \n class Owlv2ForObjectDetection(Owlv2PreTrainedModel):\n-    config_class = Owlv2Config\n+    config: Owlv2Config\n \n     def __init__(self, config: Owlv2Config):\n         super().__init__(config)"
        },
        {
            "sha": "da914d48b154b754b2cca173a9424b8baaac571e",
            "filename": "src/transformers/models/owlvit/modeling_owlvit.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fowlvit%2Fmodeling_owlvit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fowlvit%2Fmodeling_owlvit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fowlvit%2Fmodeling_owlvit.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -542,7 +542,7 @@ def forward(\n \n @auto_docstring\n class OwlViTPreTrainedModel(PreTrainedModel):\n-    config_class = OwlViTConfig\n+    config: OwlViTConfig\n     base_model_prefix = \"owlvit\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"OwlViTEncoderLayer\"]\n@@ -745,7 +745,7 @@ def forward(\n \n \n class OwlViTTextModel(OwlViTPreTrainedModel):\n-    config_class = OwlViTTextConfig\n+    config: OwlViTTextConfig\n \n     def __init__(self, config: OwlViTTextConfig):\n         super().__init__(config)\n@@ -854,7 +854,7 @@ def forward(\n \n \n class OwlViTVisionModel(OwlViTPreTrainedModel):\n-    config_class = OwlViTVisionConfig\n+    config: OwlViTVisionConfig\n     main_input_name = \"pixel_values\"\n \n     def __init__(self, config: OwlViTVisionConfig):\n@@ -904,7 +904,7 @@ def forward(\n \n @auto_docstring\n class OwlViTModel(OwlViTPreTrainedModel):\n-    config_class = OwlViTConfig\n+    config: OwlViTConfig\n \n     def __init__(self, config: OwlViTConfig):\n         super().__init__(config)\n@@ -1187,7 +1187,7 @@ def forward(\n \n \n class OwlViTForObjectDetection(OwlViTPreTrainedModel):\n-    config_class = OwlViTConfig\n+    config: OwlViTConfig\n \n     def __init__(self, config: OwlViTConfig):\n         super().__init__(config)"
        },
        {
            "sha": "f10ece1c191b223f6c88a5975d4e928509ba0a3f",
            "filename": "src/transformers/models/paligemma/modeling_paligemma.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fmodeling_paligemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fmodeling_paligemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fmodeling_paligemma.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -108,7 +108,7 @@ def forward(self, image_features):\n \n @auto_docstring\n class PaliGemmaPreTrainedModel(PreTrainedModel):\n-    config_class = PaliGemmaConfig\n+    config: PaliGemmaConfig\n     base_model_prefix = \"\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"PaliGemmaMultiModalProjector\"]"
        },
        {
            "sha": "981575f42ae81040b772901679f55ad603d8e528",
            "filename": "src/transformers/models/patchtsmixer/modeling_patchtsmixer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpatchtsmixer%2Fmodeling_patchtsmixer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpatchtsmixer%2Fmodeling_patchtsmixer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpatchtsmixer%2Fmodeling_patchtsmixer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -683,7 +683,7 @@ def forward(self, hidden_features):\n @auto_docstring\n class PatchTSMixerPreTrainedModel(PreTrainedModel):\n     # Weight initialization\n-    config_class = PatchTSMixerConfig\n+    config: PatchTSMixerConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"past_values\"\n     supports_gradient_checkpointing = False"
        },
        {
            "sha": "559cf7df61632d8f50a32aee69392c70919becc7",
            "filename": "src/transformers/models/patchtst/modeling_patchtst.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpatchtst%2Fmodeling_patchtst.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpatchtst%2Fmodeling_patchtst.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpatchtst%2Fmodeling_patchtst.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -553,7 +553,7 @@ def forward(self, hidden_state: torch.Tensor, output_attentions: Optional[bool]\n \n @auto_docstring\n class PatchTSTPreTrainedModel(PreTrainedModel):\n-    config_class = PatchTSTConfig\n+    config: PatchTSTConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"past_values\"\n     supports_gradient_checkpointing = False"
        },
        {
            "sha": "f3c5bc8a4fbcd6697fe0ac524930929aed8e1014",
            "filename": "src/transformers/models/pegasus/modeling_pegasus.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpegasus%2Fmodeling_pegasus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpegasus%2Fmodeling_pegasus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpegasus%2Fmodeling_pegasus.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -451,7 +451,7 @@ def forward(\n \n @auto_docstring\n class PegasusPreTrainedModel(PreTrainedModel):\n-    config_class = PegasusConfig\n+    config: PegasusConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _supports_flash_attn = True"
        },
        {
            "sha": "46d3730695be81a1123fb5e304dbb080621f78dd",
            "filename": "src/transformers/models/pegasus_x/modeling_pegasus_x.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpegasus_x%2Fmodeling_pegasus_x.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpegasus_x%2Fmodeling_pegasus_x.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpegasus_x%2Fmodeling_pegasus_x.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -749,7 +749,7 @@ def forward(\n \n @auto_docstring\n class PegasusXPreTrainedModel(PreTrainedModel):\n-    config_class = PegasusXConfig\n+    config: PegasusXConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [r\"PegasusXEncoderLayer\", r\"PegasusXDecoderLayer\"]"
        },
        {
            "sha": "bd3a2d9e8c1b6a11a873bc7dd4bae47b8131c560",
            "filename": "src/transformers/models/perceiver/modeling_perceiver.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fperceiver%2Fmodeling_perceiver.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fperceiver%2Fmodeling_perceiver.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fperceiver%2Fmodeling_perceiver.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -560,7 +560,7 @@ def forward(\n \n @auto_docstring\n class PerceiverPreTrainedModel(PreTrainedModel):\n-    config_class = PerceiverConfig\n+    config: PerceiverConfig\n     base_model_prefix = \"perceiver\"\n     main_input_name = \"inputs\"\n "
        },
        {
            "sha": "d646569ff0a13fa206420f0d9380714e99502469",
            "filename": "src/transformers/models/perception_lm/modeling_perception_lm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fmodeling_perception_lm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fmodeling_perception_lm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fmodeling_perception_lm.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -87,7 +87,7 @@ def forward(self, features):\n \n @auto_docstring\n class PerceptionLMPreTrainedModel(PreTrainedModel):\n-    config_class = PerceptionLMConfig\n+    config: PerceptionLMConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _skip_keys_device_placement = \"past_key_values\""
        },
        {
            "sha": "cb3313753ec7f032572c3e866505347560429217",
            "filename": "src/transformers/models/persimmon/modeling_persimmon.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpersimmon%2Fmodeling_persimmon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpersimmon%2Fmodeling_persimmon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpersimmon%2Fmodeling_persimmon.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -383,7 +383,7 @@ def forward(\n \n @auto_docstring\n class PersimmonPreTrainedModel(PreTrainedModel):\n-    config_class = PersimmonConfig\n+    config: PersimmonConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"PersimmonDecoderLayer\"]"
        },
        {
            "sha": "2ca954635b82432725f82be91f0e666f4d77bdd9",
            "filename": "src/transformers/models/phi/modeling_phi.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fphi%2Fmodeling_phi.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fphi%2Fmodeling_phi.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi%2Fmodeling_phi.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -290,7 +290,7 @@ def forward(self, x, position_ids):\n \n @auto_docstring\n class PhiPreTrainedModel(PreTrainedModel):\n-    config_class = PhiConfig\n+    config: PhiConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"PhiDecoderLayer\"]"
        },
        {
            "sha": "35efc8d3db2e29a3853c4b5c95611f981920dc98",
            "filename": "src/transformers/models/phi3/modeling_phi3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodeling_phi3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodeling_phi3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodeling_phi3.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -282,7 +282,7 @@ def forward(\n \n @auto_docstring\n class Phi3PreTrainedModel(PreTrainedModel):\n-    config_class = Phi3Config\n+    config: Phi3Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Phi3DecoderLayer\"]"
        },
        {
            "sha": "301bd5a8463013f07703d2d8f4eb1d49679683de",
            "filename": "src/transformers/models/phi4_multimodal/modeling_phi4_multimodal.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodeling_phi4_multimodal.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodeling_phi4_multimodal.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodeling_phi4_multimodal.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -365,7 +365,7 @@ def default_flax_embed_init(tensor):\n \n @auto_docstring\n class Phi4MultimodalVisionPreTrainedModel(PreTrainedModel):\n-    config_class = Phi4MultimodalVisionConfig\n+    config: Phi4MultimodalVisionConfig\n     base_model_prefix = \"phi4_vision\"\n     supports_gradient_checkpointing = True\n \n@@ -524,7 +524,7 @@ def forward(self, hidden_state, attention_mask):\n \n \n class Phi4MultimodalVisionModel(Phi4MultimodalVisionPreTrainedModel):\n-    config_class = Phi4MultimodalVisionConfig\n+    config: Phi4MultimodalVisionConfig\n     main_input_name = \"pixel_values\"\n \n     def __init__(self, config: Phi4MultimodalVisionConfig):\n@@ -992,7 +992,7 @@ def forward(self, x):\n \n @auto_docstring\n class Phi4MultimodalAudioPreTrainedModel(PreTrainedModel):\n-    config_class = Phi4MultimodalAudioConfig\n+    config: Phi4MultimodalAudioConfig\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Phi4MultimodalAudioConformerEncoderLayer\"]\n     _supports_flash_attn = True\n@@ -1584,7 +1584,7 @@ def forward(self, x, position_ids):\n \n @auto_docstring\n class Phi4MultimodalPreTrainedModel(PreTrainedModel):\n-    config_class = Phi4MultimodalConfig\n+    config: Phi4MultimodalConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Phi4MultimodalDecoderLayer\"]"
        },
        {
            "sha": "fefe5d69abab10567ff74c9dd17f56e9c4b68d31",
            "filename": "src/transformers/models/phi4_multimodal/modular_phi4_multimodal.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodular_phi4_multimodal.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodular_phi4_multimodal.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fmodular_phi4_multimodal.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -535,7 +535,7 @@ def __init__(self, config: Phi4MultimodalVisionConfig):\n \n \n class Phi4MultimodalVisionPreTrainedModel(SiglipPreTrainedModel):\n-    config_class = Phi4MultimodalVisionConfig\n+    config: Phi4MultimodalVisionConfig\n     base_model_prefix = \"phi4_vision\"\n     supports_gradient_checkpointing = True\n \n@@ -649,7 +649,7 @@ def forward(self, hidden_state, attention_mask):\n \n \n class Phi4MultimodalVisionModel(Phi4MultimodalVisionPreTrainedModel):\n-    config_class = Phi4MultimodalVisionConfig\n+    config: Phi4MultimodalVisionConfig\n     main_input_name = \"pixel_values\"\n \n     def __init__(self, config: Phi4MultimodalVisionConfig):\n@@ -1117,7 +1117,7 @@ def forward(self, x):\n \n @auto_docstring\n class Phi4MultimodalAudioPreTrainedModel(PreTrainedModel):\n-    config_class = Phi4MultimodalAudioConfig\n+    config: Phi4MultimodalAudioConfig\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Phi4MultimodalAudioConformerEncoderLayer\"]\n     _supports_flash_attn = True"
        },
        {
            "sha": "4f8a9f2d28499d7931c9a76de2d969ecaa956ff2",
            "filename": "src/transformers/models/phimoe/modeling_phimoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fphimoe%2Fmodeling_phimoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fphimoe%2Fmodeling_phimoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphimoe%2Fmodeling_phimoe.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -882,7 +882,7 @@ def forward(\n \n @auto_docstring\n class PhimoePreTrainedModel(PreTrainedModel):\n-    config_class = PhimoeConfig\n+    config: PhimoeConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"PhimoeDecoderLayer\"]"
        },
        {
            "sha": "9eee774be2cf939bfcd3a775eca069814a7934b4",
            "filename": "src/transformers/models/pix2struct/modeling_pix2struct.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpix2struct%2Fmodeling_pix2struct.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpix2struct%2Fmodeling_pix2struct.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpix2struct%2Fmodeling_pix2struct.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -349,7 +349,7 @@ def forward(\n \n @auto_docstring\n class Pix2StructPreTrainedModel(PreTrainedModel):\n-    config_class = Pix2StructConfig\n+    config: Pix2StructConfig\n \n     _supports_static_cache = False\n \n@@ -474,7 +474,7 @@ def _shift_right(self, input_ids):\n \n @auto_docstring\n class Pix2StructVisionModel(Pix2StructPreTrainedModel):\n-    config_class = Pix2StructVisionConfig\n+    config: Pix2StructVisionConfig\n     main_input_name = \"flattened_patches\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Pix2StructVisionLayer\"]\n@@ -1013,7 +1013,7 @@ def forward(\n     \"\"\"\n )\n class Pix2StructTextModel(Pix2StructPreTrainedModel):\n-    config_class = Pix2StructTextConfig\n+    config: Pix2StructTextConfig\n     _no_split_modules = [\"Pix2StructTextBlock\"]\n     _tied_weights_keys = [\"lm_head.weight\"]\n     supports_gradient_checkpointing = True\n@@ -1396,7 +1396,7 @@ def _prepare_4d_causal_attention_mask_with_cache_position(\n     \"\"\"\n )\n class Pix2StructForConditionalGeneration(Pix2StructPreTrainedModel, GenerationMixin):\n-    config_class = Pix2StructConfig\n+    config: Pix2StructConfig\n     main_input_name = \"flattened_patches\"\n     _tied_weights_keys = [\"decoder.lm_head.weight\"]\n "
        },
        {
            "sha": "831e500c57256f07ae3e7101cad3c3943bccd1d5",
            "filename": "src/transformers/models/pixtral/modeling_pixtral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpixtral%2Fmodeling_pixtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpixtral%2Fmodeling_pixtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpixtral%2Fmodeling_pixtral.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -400,7 +400,7 @@ def forward(\n \n @auto_docstring\n class PixtralPreTrainedModel(PreTrainedModel):\n-    config_class = PixtralVisionConfig\n+    config: PixtralVisionConfig\n     base_model_prefix = \"model\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "52cb126e51b118e60d19173ec5b6725b772a8aa3",
            "filename": "src/transformers/models/plbart/modeling_plbart.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fplbart%2Fmodeling_plbart.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fplbart%2Fmodeling_plbart.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fplbart%2Fmodeling_plbart.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -73,7 +73,7 @@ def forward(self, input_ids: torch.Tensor):\n \n @auto_docstring\n class PLBartPreTrainedModel(PreTrainedModel):\n-    config_class = PLBartConfig\n+    config: PLBartConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"PLBartDecoderLayer\", \"PLBartEncoderLayer\"]"
        },
        {
            "sha": "3547b1da4064af24f216df4d586ffcd6cb274acf",
            "filename": "src/transformers/models/plbart/modular_plbart.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fplbart%2Fmodular_plbart.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fplbart%2Fmodular_plbart.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fplbart%2Fmodular_plbart.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -58,7 +58,7 @@ class PLBartScaledWordEmbedding(BartScaledWordEmbedding):\n \n @auto_docstring\n class PLBartPreTrainedModel(PreTrainedModel):\n-    config_class = PLBartConfig\n+    config: PLBartConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"PLBartDecoderLayer\", \"PLBartEncoderLayer\"]"
        },
        {
            "sha": "0c72944000a18f91d9f864ce35323964a9909df5",
            "filename": "src/transformers/models/poolformer/modeling_poolformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpoolformer%2Fmodeling_poolformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpoolformer%2Fmodeling_poolformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpoolformer%2Fmodeling_poolformer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -246,7 +246,7 @@ def forward(self, pixel_values, output_hidden_states=False, return_dict=True):\n \n @auto_docstring\n class PoolFormerPreTrainedModel(PreTrainedModel):\n-    config_class = PoolFormerConfig\n+    config: PoolFormerConfig\n     base_model_prefix = \"poolformer\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [\"PoolFormerLayer\"]"
        },
        {
            "sha": "aab17019ed54e09a467b76b50cb49be88525708b",
            "filename": "src/transformers/models/pop2piano/modeling_pop2piano.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpop2piano%2Fmodeling_pop2piano.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpop2piano%2Fmodeling_pop2piano.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpop2piano%2Fmodeling_pop2piano.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -572,7 +572,7 @@ def forward(\n \n @auto_docstring\n class Pop2PianoPreTrainedModel(PreTrainedModel):\n-    config_class = Pop2PianoConfig\n+    config: Pop2PianoConfig\n     base_model_prefix = \"transformer\"\n     is_parallelizable = False\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "f8e9092a10ad716dd3ef3818464cb4f2e81ddc2d",
            "filename": "src/transformers/models/prompt_depth_anything/modeling_prompt_depth_anything.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fprompt_depth_anything%2Fmodeling_prompt_depth_anything.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fprompt_depth_anything%2Fmodeling_prompt_depth_anything.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fprompt_depth_anything%2Fmodeling_prompt_depth_anything.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -240,7 +240,7 @@ def forward(self, hidden_states: list[torch.Tensor], patch_height: int, patch_wi\n \n @auto_docstring\n class PromptDepthAnythingPreTrainedModel(PreTrainedModel):\n-    config_class = PromptDepthAnythingConfig\n+    config: PromptDepthAnythingConfig\n     base_model_prefix = \"prompt_depth_anything\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "fcd3c9c91f2561656d5ca870335fe24853ddc917",
            "filename": "src/transformers/models/prompt_depth_anything/modular_prompt_depth_anything.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fprompt_depth_anything%2Fmodular_prompt_depth_anything.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fprompt_depth_anything%2Fmodular_prompt_depth_anything.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fprompt_depth_anything%2Fmodular_prompt_depth_anything.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -159,7 +159,7 @@ def forward(self, hidden_states: list[torch.Tensor], patch_height: int, patch_wi\n \n @auto_docstring\n class PromptDepthAnythingPreTrainedModel(PreTrainedModel):\n-    config_class = PromptDepthAnythingConfig\n+    config: PromptDepthAnythingConfig\n     base_model_prefix = \"prompt_depth_anything\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "467194eafd519eb3d360204c91525fddd4de45d8",
            "filename": "src/transformers/models/prophetnet/modeling_prophetnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fprophetnet%2Fmodeling_prophetnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fprophetnet%2Fmodeling_prophetnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fprophetnet%2Fmodeling_prophetnet.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -333,7 +333,7 @@ class ProphetNetDecoderLMOutput(ModelOutput):\n \n @auto_docstring\n class ProphetNetPreTrainedModel(PreTrainedModel):\n-    config_class = ProphetNetConfig\n+    config: ProphetNetConfig\n     base_model_prefix = \"prophetnet\"\n     supports_gradient_checkpointing = True\n "
        },
        {
            "sha": "9517b0252e2d3fc49c03f0c586398fe60bc03fe4",
            "filename": "src/transformers/models/pvt/modeling_pvt.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpvt%2Fmodeling_pvt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpvt%2Fmodeling_pvt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpvt%2Fmodeling_pvt.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -442,7 +442,7 @@ def forward(\n \n @auto_docstring\n class PvtPreTrainedModel(PreTrainedModel):\n-    config_class = PvtConfig\n+    config: PvtConfig\n     base_model_prefix = \"pvt\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = []"
        },
        {
            "sha": "0e077f41d8f2701c3b44f0a87ec9e24533707405",
            "filename": "src/transformers/models/pvt_v2/modeling_pvt_v2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpvt_v2%2Fmodeling_pvt_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fpvt_v2%2Fmodeling_pvt_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpvt_v2%2Fmodeling_pvt_v2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -388,7 +388,7 @@ def forward(\n \n @auto_docstring\n class PvtV2PreTrainedModel(PreTrainedModel):\n-    config_class = PvtV2Config\n+    config: PvtV2Config\n     base_model_prefix = \"pvt_v2\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "eddfef4ced0e948eadf8f73e3a61e2b0168f7763",
            "filename": "src/transformers/models/qwen2/modeling_qwen2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodeling_qwen2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodeling_qwen2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodeling_qwen2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -254,7 +254,7 @@ def forward(\n \n @auto_docstring\n class Qwen2PreTrainedModel(PreTrainedModel):\n-    config_class = Qwen2Config\n+    config: Qwen2Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Qwen2DecoderLayer\"]"
        },
        {
            "sha": "10eeadd766a4c4a0e4d16c2fa79248a9520f27d1",
            "filename": "src/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py",
            "status": "modified",
            "additions": 11,
            "deletions": 11,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fmodeling_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fmodeling_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fmodeling_qwen2_5_omni.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -80,7 +80,7 @@ def extra_repr(self):\n \n @auto_docstring\n class Qwen2_5OmniPreTrainedModel(PreTrainedModel):\n-    config_class = Qwen2_5OmniConfig\n+    config: Qwen2_5OmniConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Qwen2_5OmniDecoderLayer\", \"Qwen2_5OmniVisionBlock\"]\n@@ -742,7 +742,7 @@ def forward(self, seqlen: int):\n     \"\"\"\n )\n class Qwen2_5OmniAudioEncoder(Qwen2_5OmniPreTrainedModel):\n-    config_class = Qwen2_5OmniAudioEncoderConfig\n+    config: Qwen2_5OmniAudioEncoderConfig\n     main_input_name = \"input_features\"\n     _no_split_modules = [\"Qwen2_5OmniAudioEncoderLayer\"]\n     _supports_sdpa = True\n@@ -1106,7 +1106,7 @@ def forward(self, x: torch.Tensor) -> torch.Tensor:\n \n \n class Qwen2_5OmniVisionEncoder(Qwen2_5OmniPreTrainedModel):\n-    config_class = Qwen2_5OmniVisionEncoderConfig\n+    config: Qwen2_5OmniVisionEncoderConfig\n     _no_split_modules = [\"Qwen2_5OmniVisionBlock\"]\n \n     def __init__(self, config: Qwen2_5OmniVisionEncoderConfig, *inputs, **kwargs) -> None:\n@@ -1531,7 +1531,7 @@ def forward(\n \n @auto_docstring\n class Qwen2_5OmniThinkerTextModel(Qwen2_5OmniPreTrainedModel):\n-    config_class = Qwen2_5OmniTextConfig\n+    config: Qwen2_5OmniTextConfig\n     _no_split_modules = [\"Qwen2_5OmniDecoderLayer\"]\n \n     def __init__(self, config: Qwen2_5OmniTextConfig):\n@@ -1683,7 +1683,7 @@ def forward(\n     \"\"\"\n )\n class Qwen2_5OmniThinkerForConditionalGeneration(Qwen2_5OmniPreTrainedModelForConditionalGeneration, GenerationMixin):\n-    config_class = Qwen2_5OmniThinkerConfig\n+    config: Qwen2_5OmniThinkerConfig\n     base_model_prefix = \"thinker\"\n     _no_split_modules = [\"Qwen2_5OmniAudioEncoder\", \"Qwen2_5OmniVisionEncoder\"]\n \n@@ -2079,7 +2079,7 @@ class Qwen2_5OmniTalkerCausalLMOutputWithPast(ModelOutput):\n \n @auto_docstring\n class Qwen2_5OmniTalkerModel(Qwen2_5OmniPreTrainedModel):\n-    config_class = Qwen2_5OmniTalkerConfig\n+    config: Qwen2_5OmniTalkerConfig\n     _no_split_modules = [\"Qwen2_5OmniTalkerDecoderLayer\"]\n \n     def __init__(self, config: Qwen2_5OmniTalkerConfig):\n@@ -2225,7 +2225,7 @@ def forward(\n \n \n class Qwen2_5OmniTalkerForConditionalGeneration(Qwen2_5OmniPreTrainedModelForConditionalGeneration, GenerationMixin):\n-    config_class = Qwen2_5OmniTalkerConfig\n+    config: Qwen2_5OmniTalkerConfig\n     base_model_prefix = \"talker\"\n \n     def __init__(self, config: Qwen2_5OmniTalkerConfig):\n@@ -3329,7 +3329,7 @@ def forward(self, hidden_states):\n     \"\"\"\n )\n class Qwen2_5OmniToken2WavBigVGANModel(Qwen2_5OmniPreTrainedModel):\n-    config_class = Qwen2_5OmniBigVGANConfig\n+    config: Qwen2_5OmniBigVGANConfig\n \n     def __init__(self, config: Qwen2_5OmniBigVGANConfig):\n         super().__init__(config)\n@@ -3464,7 +3464,7 @@ def integrate(self, time_points):\n     \"\"\"\n )\n class Qwen2_5OmniToken2WavDiTModel(Qwen2_5OmniPreTrainedModel):\n-    config_class = Qwen2_5OmniDiTConfig\n+    config: Qwen2_5OmniDiTConfig\n     _no_split_modules = [\"DiTDecoderLayer\"]\n \n     def __init__(self, config: Qwen2_5OmniDiTConfig):\n@@ -3619,7 +3619,7 @@ def ode_function(time_step, hidden_states):\n     \"\"\"\n )\n class Qwen2_5OmniToken2WavModel(Qwen2_5OmniPreTrainedModel):\n-    config_class = Qwen2_5OmniToken2WavConfig\n+    config: Qwen2_5OmniToken2WavConfig\n     base_model_prefix = \"model\"\n     _no_split_modules = [\"Qwen2_5OmniToken2WavDiTModel\", \"Qwen2_5OmniToken2WavBigVGANModel\"]\n \n@@ -3687,7 +3687,7 @@ def forward(\n     \"\"\"\n )\n class Qwen2_5OmniForConditionalGeneration(Qwen2_5OmniPreTrainedModel, GenerationMixin):\n-    config_class = Qwen2_5OmniConfig\n+    config: Qwen2_5OmniConfig\n     _no_split_modules = [\n         \"Qwen2_5OmniTalkerForConditionalGeneration\",\n         \"Qwen2_5OmniToken2WavModel\","
        },
        {
            "sha": "34e61e0b263db0ac5fc847a57353a84a7487618d",
            "filename": "src/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py",
            "status": "modified",
            "additions": 11,
            "deletions": 11,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fmodular_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fmodular_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fmodular_qwen2_5_omni.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1131,7 +1131,7 @@ def get_text_config(self, decoder=False):\n \n \n class Qwen2_5OmniPreTrainedModel(Qwen2_5_VLPreTrainedModel):\n-    config_class = Qwen2_5OmniConfig\n+    config: Qwen2_5OmniConfig\n     _supports_static_cache = False\n \n     def _init_weights(self, module):\n@@ -1729,7 +1729,7 @@ def forward(self, seqlen: int):\n     \"\"\"\n )\n class Qwen2_5OmniAudioEncoder(Qwen2_5OmniPreTrainedModel):\n-    config_class = Qwen2_5OmniAudioEncoderConfig\n+    config: Qwen2_5OmniAudioEncoderConfig\n     main_input_name = \"input_features\"\n     _no_split_modules = [\"Qwen2_5OmniAudioEncoderLayer\"]\n     _supports_sdpa = True\n@@ -2015,7 +2015,7 @@ def forward(\n \n \n class Qwen2_5OmniVisionEncoder(Qwen2_5_VisionTransformerPretrainedModel):\n-    config_class = Qwen2_5OmniVisionEncoderConfig\n+    config: Qwen2_5OmniVisionEncoderConfig\n     _no_split_modules = [\"Qwen2_5OmniVisionBlock\"]\n \n     def __init__(self, config: Qwen2_5OmniVisionEncoderConfig, *inputs, **kwargs) -> None:\n@@ -2125,7 +2125,7 @@ class Qwen2MLP(Qwen2_5_VLMLP):\n \n \n class Qwen2_5OmniThinkerTextModel(Qwen2_5_VLTextModel):\n-    config_class = Qwen2_5OmniTextConfig\n+    config: Qwen2_5OmniTextConfig\n     _no_split_modules = [\"Qwen2_5OmniDecoderLayer\"]\n \n     def __init__(self, config: Qwen2_5OmniTextConfig):\n@@ -2138,7 +2138,7 @@ def __init__(self, config: Qwen2_5OmniTextConfig):\n     \"\"\"\n )\n class Qwen2_5OmniThinkerForConditionalGeneration(Qwen2_5OmniPreTrainedModelForConditionalGeneration, GenerationMixin):\n-    config_class = Qwen2_5OmniThinkerConfig\n+    config: Qwen2_5OmniThinkerConfig\n     base_model_prefix = \"thinker\"\n     _no_split_modules = [\"Qwen2_5OmniAudioEncoder\", \"Qwen2_5OmniVisionEncoder\"]\n \n@@ -2533,7 +2533,7 @@ class Qwen2_5OmniTalkerCausalLMOutputWithPast(ModelOutput):\n \n \n class Qwen2_5OmniTalkerModel(Qwen2_5_VLTextModel):\n-    config_class = Qwen2_5OmniTalkerConfig\n+    config: Qwen2_5OmniTalkerConfig\n     _no_split_modules = [\"Qwen2_5OmniTalkerDecoderLayer\"]\n \n     def __init__(self, config: Qwen2_5OmniTalkerConfig):\n@@ -2542,7 +2542,7 @@ def __init__(self, config: Qwen2_5OmniTalkerConfig):\n \n \n class Qwen2_5OmniTalkerForConditionalGeneration(Qwen2_5OmniPreTrainedModelForConditionalGeneration, GenerationMixin):\n-    config_class = Qwen2_5OmniTalkerConfig\n+    config: Qwen2_5OmniTalkerConfig\n     base_model_prefix = \"talker\"\n \n     def __init__(self, config: Qwen2_5OmniTalkerConfig):\n@@ -3646,7 +3646,7 @@ def forward(self, hidden_states):\n     \"\"\"\n )\n class Qwen2_5OmniToken2WavBigVGANModel(Qwen2_5OmniPreTrainedModel):\n-    config_class = Qwen2_5OmniBigVGANConfig\n+    config: Qwen2_5OmniBigVGANConfig\n \n     def __init__(self, config: Qwen2_5OmniBigVGANConfig):\n         super().__init__(config)\n@@ -3781,7 +3781,7 @@ def integrate(self, time_points):\n     \"\"\"\n )\n class Qwen2_5OmniToken2WavDiTModel(Qwen2_5OmniPreTrainedModel):\n-    config_class = Qwen2_5OmniDiTConfig\n+    config: Qwen2_5OmniDiTConfig\n     _no_split_modules = [\"DiTDecoderLayer\"]\n \n     def __init__(self, config: Qwen2_5OmniDiTConfig):\n@@ -3936,7 +3936,7 @@ def ode_function(time_step, hidden_states):\n     \"\"\"\n )\n class Qwen2_5OmniToken2WavModel(Qwen2_5OmniPreTrainedModel):\n-    config_class = Qwen2_5OmniToken2WavConfig\n+    config: Qwen2_5OmniToken2WavConfig\n     base_model_prefix = \"model\"\n     _no_split_modules = [\"Qwen2_5OmniToken2WavDiTModel\", \"Qwen2_5OmniToken2WavBigVGANModel\"]\n \n@@ -4004,7 +4004,7 @@ def forward(\n     \"\"\"\n )\n class Qwen2_5OmniForConditionalGeneration(Qwen2_5OmniPreTrainedModel, GenerationMixin):\n-    config_class = Qwen2_5OmniConfig\n+    config: Qwen2_5OmniConfig\n     _no_split_modules = [\n         \"Qwen2_5OmniTalkerForConditionalGeneration\",\n         \"Qwen2_5OmniToken2WavModel\","
        },
        {
            "sha": "7cf76017b718d1c94e230cb2d8c1f8694bd90c94",
            "filename": "src/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -318,7 +318,7 @@ def forward(\n \n @auto_docstring\n class Qwen2_5_VLPreTrainedModel(PreTrainedModel):\n-    config_class = Qwen2_5_VLConfig\n+    config: Qwen2_5_VLConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Qwen2_5_VLDecoderLayer\", \"Qwen2_5_VLVisionBlock\"]\n@@ -344,7 +344,7 @@ def _init_weights(self, module):\n \n \n class Qwen2_5_VisionTransformerPretrainedModel(Qwen2_5_VLPreTrainedModel):\n-    config_class = Qwen2_5_VLVisionConfig\n+    config: Qwen2_5_VLVisionConfig\n     _no_split_modules = [\"Qwen2_5_VLVisionBlock\"]\n \n     def __init__(self, config, *inputs, **kwargs) -> None:\n@@ -803,7 +803,7 @@ def forward(\n \n @auto_docstring\n class Qwen2_5_VLTextModel(Qwen2_5_VLPreTrainedModel):\n-    config_class = Qwen2_5_VLTextConfig\n+    config: Qwen2_5_VLTextConfig\n \n     def __init__(self, config: Qwen2_5_VLTextConfig):\n         super().__init__(config)\n@@ -952,7 +952,7 @@ def forward(\n class Qwen2_5_VLModel(Qwen2_5_VLPreTrainedModel):\n     base_model_prefix = \"\"\n     _checkpoint_conversion_mapping = {\"^model\": \"language_model\"}\n-    config_class = Qwen2_5_VLConfig\n+    config: Qwen2_5_VLConfig\n     _no_split_modules = [\"Qwen2_5_VLDecoderLayer\", \"Qwen2_5_VLVisionBlock\"]\n \n     def __init__(self, config):"
        },
        {
            "sha": "000d752165edb736c4cf6dafb3d401c28f5a6073",
            "filename": "src/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -189,7 +189,7 @@ def _init_weights(self, module):\n \n \n class Qwen2_5_VisionTransformerPretrainedModel(Qwen2_5_VLPreTrainedModel):\n-    config_class = Qwen2_5_VLVisionConfig\n+    config: Qwen2_5_VLVisionConfig\n     _no_split_modules = [\"Qwen2_5_VLVisionBlock\"]\n \n     def __init__(self, config, *inputs, **kwargs) -> None:\n@@ -354,7 +354,7 @@ class Qwen2_5_VLModelOutputWithPast(Qwen2VLModelOutputWithPast):\n \n \n class Qwen2_5_VLModel(Qwen2VLModel):\n-    config_class = Qwen2_5_VLConfig\n+    config: Qwen2_5_VLConfig\n     base_model_prefix = \"\"\n     _no_split_modules = [\"Qwen2_5_VLDecoderLayer\", \"Qwen2_5_VLVisionBlock\"]\n "
        },
        {
            "sha": "fb9d013eeff32788f9210bf1af07ed030347b3b8",
            "filename": "src/transformers/models/qwen2_audio/modeling_qwen2_audio.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2_audio%2Fmodeling_qwen2_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2_audio%2Fmodeling_qwen2_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_audio%2Fmodeling_qwen2_audio.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -257,7 +257,7 @@ def forward(\n \n @auto_docstring\n class Qwen2AudioPreTrainedModel(PreTrainedModel):\n-    config_class = Qwen2AudioConfig\n+    config: Qwen2AudioConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Qwen2AudioAttention\"]\n@@ -303,7 +303,7 @@ class Qwen2AudioEncoder(Qwen2AudioPreTrainedModel):\n     \"\"\"\n \n     # Ignore copy\n-    config_class = Qwen2AudioEncoderConfig\n+    config: Qwen2AudioEncoderConfig\n     main_input_name = \"input_features\"\n     _no_split_modules = [\"Qwen2AudioEncoderLayer\"]\n "
        },
        {
            "sha": "dc70ad547fd7d1cd4e9bae32f9e812b7faeec14d",
            "filename": "src/transformers/models/qwen2_moe/modeling_qwen2_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -739,7 +739,7 @@ def forward(\n \n @auto_docstring\n class Qwen2MoePreTrainedModel(PreTrainedModel):\n-    config_class = Qwen2MoeConfig\n+    config: Qwen2MoeConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Qwen2MoeDecoderLayer\"]"
        },
        {
            "sha": "6f88158558f9396acb0b4b1013d3a6efe9f97069",
            "filename": "src/transformers/models/qwen2_vl/modeling_qwen2_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -651,7 +651,7 @@ def forward(\n \n @auto_docstring\n class Qwen2VLPreTrainedModel(PreTrainedModel):\n-    config_class = Qwen2VLConfig\n+    config: Qwen2VLConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Qwen2VLDecoderLayer\", \"Qwen2VLVisionBlock\"]\n@@ -681,7 +681,7 @@ def _init_weights(self, module):\n \n @auto_docstring\n class Qwen2VisionTransformerPretrainedModel(Qwen2VLPreTrainedModel):\n-    config_class = Qwen2VLVisionConfig\n+    config: Qwen2VLVisionConfig\n     _no_split_modules = [\"Qwen2VLVisionBlock\"]\n \n     def __init__(self, config) -> None:\n@@ -778,7 +778,7 @@ def forward(\n \n @auto_docstring\n class Qwen2VLTextModel(Qwen2VLPreTrainedModel):\n-    config_class = Qwen2VLTextConfig\n+    config: Qwen2VLTextConfig\n \n     def __init__(self, config: Qwen2VLTextConfig):\n         super().__init__(config)"
        },
        {
            "sha": "4af78a109fa123a550521fe9ab16b2d23f98671c",
            "filename": "src/transformers/models/qwen3/modeling_qwen3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen3%2Fmodeling_qwen3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen3%2Fmodeling_qwen3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3%2Fmodeling_qwen3.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -280,7 +280,7 @@ def forward(\n \n @auto_docstring\n class Qwen3PreTrainedModel(PreTrainedModel):\n-    config_class = Qwen3Config\n+    config: Qwen3Config\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Qwen3DecoderLayer\"]"
        },
        {
            "sha": "581dd2faba1d3ce55e6a5eabd25f05975f35a6cf",
            "filename": "src/transformers/models/qwen3_moe/modeling_qwen3_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen3_moe%2Fmodeling_qwen3_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fqwen3_moe%2Fmodeling_qwen3_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_moe%2Fmodeling_qwen3_moe.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -403,7 +403,7 @@ def forward(self, x, position_ids):\n \n @auto_docstring\n class Qwen3MoePreTrainedModel(PreTrainedModel):\n-    config_class = Qwen3MoeConfig\n+    config: Qwen3MoeConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Qwen3MoeDecoderLayer\"]"
        },
        {
            "sha": "4cb08b1bc4c39dd3828b2611b22569e227e3bb10",
            "filename": "src/transformers/models/rag/modeling_rag.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Frag%2Fmodeling_rag.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Frag%2Fmodeling_rag.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frag%2Fmodeling_rag.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -232,7 +232,7 @@ class RetrievAugLMOutput(ModelOutput):\n )\n @auto_docstring\n class RagPreTrainedModel(PreTrainedModel):\n-    config_class = RagConfig\n+    config: RagConfig\n     base_model_prefix = \"rag\"\n     _supports_flash_attn = True\n     _supports_sdpa = True"
        },
        {
            "sha": "833b1689c28e0fb6814427f96cf3d94def374269",
            "filename": "src/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Frecurrent_gemma%2Fmodeling_recurrent_gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Frecurrent_gemma%2Fmodeling_recurrent_gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frecurrent_gemma%2Fmodeling_recurrent_gemma.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -504,7 +504,7 @@ def forward(\n \n @auto_docstring\n class RecurrentGemmaPreTrainedModel(PreTrainedModel):\n-    config_class = RecurrentGemmaConfig\n+    config: RecurrentGemmaConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"RecurrentGemmaDecoderLayer\"]"
        },
        {
            "sha": "97cb08deb98664cd6d2c8cad9b56c682adacbf76",
            "filename": "src/transformers/models/reformer/modeling_reformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Freformer%2Fmodeling_reformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Freformer%2Fmodeling_reformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Freformer%2Fmodeling_reformer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1900,7 +1900,7 @@ def _tie_weights(self) -> None:\n \n @auto_docstring\n class ReformerPreTrainedModel(PreTrainedModel):\n-    config_class = ReformerConfig\n+    config: ReformerConfig\n     base_model_prefix = \"reformer\"\n \n     @property"
        },
        {
            "sha": "c9cdda640b607b376d8a88496790b50a7c63a115",
            "filename": "src/transformers/models/regnet/modeling_regnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fregnet%2Fmodeling_regnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fregnet%2Fmodeling_regnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fregnet%2Fmodeling_regnet.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -260,7 +260,7 @@ def forward(\n \n @auto_docstring\n class RegNetPreTrainedModel(PreTrainedModel):\n-    config_class = RegNetConfig\n+    config: RegNetConfig\n     base_model_prefix = \"regnet\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [\"RegNetYLayer\"]"
        },
        {
            "sha": "c8a81319f3fef26957e5847a2c7af93b16e8c9f9",
            "filename": "src/transformers/models/rembert/modeling_rembert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Frembert%2Fmodeling_rembert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Frembert%2Fmodeling_rembert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frembert%2Fmodeling_rembert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -626,7 +626,7 @@ def forward(self, sequence_output: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class RemBertPreTrainedModel(PreTrainedModel):\n-    config_class = RemBertConfig\n+    config: RemBertConfig\n     load_tf_weights = load_tf_weights_in_rembert\n     base_model_prefix = \"rembert\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "266d148bcc48c8e539ff36920e6ab6eda45b10b5",
            "filename": "src/transformers/models/resnet/modeling_resnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fresnet%2Fmodeling_resnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Fresnet%2Fmodeling_resnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fresnet%2Fmodeling_resnet.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -246,7 +246,7 @@ def forward(\n \n @auto_docstring\n class ResNetPreTrainedModel(PreTrainedModel):\n-    config_class = ResNetConfig\n+    config: ResNetConfig\n     base_model_prefix = \"resnet\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [\"ResNetConvLayer\", \"ResNetShortCut\"]"
        },
        {
            "sha": "998685ccc15da2c62024f19eb62f3753da6dbfa2",
            "filename": "src/transformers/models/roberta/modeling_roberta.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Froberta%2Fmodeling_roberta.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Froberta%2Fmodeling_roberta.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froberta%2Fmodeling_roberta.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -690,7 +690,7 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class RobertaPreTrainedModel(PreTrainedModel):\n-    config_class = RobertaConfig\n+    config: RobertaConfig\n     base_model_prefix = \"roberta\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"RobertaEmbeddings\", \"RobertaSelfAttention\", \"RobertaSdpaSelfAttention\"]"
        },
        {
            "sha": "d778a42703321696770d1de050eae57210f4d7e6",
            "filename": "src/transformers/models/roberta_prelayernorm/modeling_roberta_prelayernorm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fmodeling_roberta_prelayernorm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fmodeling_roberta_prelayernorm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fmodeling_roberta_prelayernorm.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -562,7 +562,7 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class RobertaPreLayerNormPreTrainedModel(PreTrainedModel):\n-    config_class = RobertaPreLayerNormConfig\n+    config: RobertaPreLayerNormConfig\n     base_model_prefix = \"roberta_prelayernorm\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"RobertaPreLayerNormEmbeddings\", \"RobertaPreLayerNormSelfAttention\"]"
        },
        {
            "sha": "38111c817c7f23c3ed4f6183d673a09c161bb52f",
            "filename": "src/transformers/models/roc_bert/modeling_roc_bert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Froc_bert%2Fmodeling_roc_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Froc_bert%2Fmodeling_roc_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froc_bert%2Fmodeling_roc_bert.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -734,7 +734,7 @@ def forward(self, sequence_output: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class RoCBertPreTrainedModel(PreTrainedModel):\n-    config_class = RoCBertConfig\n+    config: RoCBertConfig\n     load_tf_weights = load_tf_weights_in_roc_bert\n     base_model_prefix = \"roc_bert\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "0fa8ac4e0c48f5c5e3d2ea6c28990fb2d8b53c84",
            "filename": "src/transformers/models/roformer/modeling_roformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Froformer%2Fmodeling_roformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Froformer%2Fmodeling_roformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froformer%2Fmodeling_roformer.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -749,7 +749,7 @@ def forward(self, sequence_output: torch.Tensor) -> torch.Tensor:\n \n @auto_docstring\n class RoFormerPreTrainedModel(PreTrainedModel):\n-    config_class = RoFormerConfig\n+    config: RoFormerConfig\n     load_tf_weights = load_tf_weights_in_roformer\n     base_model_prefix = \"roformer\"\n     supports_gradient_checkpointing = True"
        },
        {
            "sha": "6ec7edbb2b7d0b18263f9a95cf988b7c9b510443",
            "filename": "src/transformers/models/rt_detr/modeling_rt_detr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Frt_detr%2Fmodeling_rt_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Frt_detr%2Fmodeling_rt_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frt_detr%2Fmodeling_rt_detr.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1000,7 +1000,7 @@ def forward(\n \n @auto_docstring\n class RTDetrPreTrainedModel(PreTrainedModel):\n-    config_class = RTDetrConfig\n+    config: RTDetrConfig\n     base_model_prefix = \"rt_detr\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [r\"RTDetrHybridEncoder\", r\"RTDetrDecoderLayer\"]"
        },
        {
            "sha": "770a9b0326604de7628189d2557fe61f4144ef6f",
            "filename": "src/transformers/models/rt_detr/modeling_rt_detr_resnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Frt_detr%2Fmodeling_rt_detr_resnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Frt_detr%2Fmodeling_rt_detr_resnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frt_detr%2Fmodeling_rt_detr_resnet.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -297,7 +297,7 @@ def forward(\n @auto_docstring\n # Copied from transformers.models.resnet.modeling_resnet.ResNetPreTrainedModel with ResNet->RTDetrResNet\n class RTDetrResNetPreTrainedModel(PreTrainedModel):\n-    config_class = RTDetrResNetConfig\n+    config: RTDetrResNetConfig\n     base_model_prefix = \"resnet\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [\"RTDetrResNetConvLayer\", \"RTDetrResNetShortCut\"]"
        },
        {
            "sha": "3589b257612e798ddbe009eb7d771cbfb5eca229",
            "filename": "src/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Frt_detr_v2%2Fmodeling_rt_detr_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cc24b0378e6062895a03a077860be28d290c1d07/src%2Ftransformers%2Fmodels%2Frt_detr_v2%2Fmodeling_rt_detr_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frt_detr_v2%2Fmodeling_rt_detr_v2.py?ref=cc24b0378e6062895a03a077860be28d290c1d07",
            "patch": "@@ -1214,7 +1214,7 @@ def _get_clones(partial_module, N):\n \n @auto_docstring\n class RTDetrV2PreTrainedModel(PreTrainedModel):\n-    config_class = RTDetrV2Config\n+    config: RTDetrV2Config\n     base_model_prefix = \"rt_detr_v2\"\n     main_input_name = \"pixel_values\"\n     _no_split_modules = [r\"RTDetrV2HybridEncoder\", r\"RTDetrV2DecoderLayer\"]"
        }
    ],
    "stats": {
        "total": 1215,
        "additions": 630,
        "deletions": 585
    }
}