{
    "author": "yao-matrix",
    "message": "enable `test_offloaded_cache_implementation` on XPU (#37514)\n\nSigned-off-by: YAO Matrix <matrix.yao@intel.com>\nCo-authored-by: Yih-Dar <2521628+ydshieh@users.noreply.github.com>",
    "sha": "a335dc4d6d3cd88c12ca9dd869d8c6621e969ccb",
    "files": [
        {
            "sha": "c738ca46457c79a55f55f4de462d8eda434b611b",
            "filename": "tests/generation/test_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/a335dc4d6d3cd88c12ca9dd869d8c6621e969ccb/tests%2Fgeneration%2Ftest_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a335dc4d6d3cd88c12ca9dd869d8c6621e969ccb/tests%2Fgeneration%2Ftest_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fgeneration%2Ftest_utils.py?ref=a335dc4d6d3cd88c12ca9dd869d8c6621e969ccb",
            "patch": "@@ -1947,7 +1947,7 @@ def test_generate_continue_from_inputs_embeds(self):\n                     )\n \n     @parameterized.expand([(\"offloaded\",)])  # (\"offloaded_static\",) TODO: @raushan fixme in some models (eg T5)\n-    @require_torch_gpu\n+    @require_torch_accelerator\n     @pytest.mark.generate\n     def test_offloaded_cache_implementation(self, cache_implementation):\n         \"\"\"Tests we can generate by indicating `cache_implementation` for each possible cache class\"\"\""
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}