{
    "author": "yao-matrix",
    "message": "add XPU info print in print_env (#38282)\n\nSigned-off-by: Matrix Yao <matrix.yao@intel.com>",
    "sha": "b26157d64cf12dbd3ec34172c4202e1ab562fca6",
    "files": [
        {
            "sha": "04ea99947e0c55ae0c0ec36b395269d98b1c365b",
            "filename": "utils/print_env.py",
            "status": "modified",
            "additions": 16,
            "deletions": 5,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/b26157d64cf12dbd3ec34172c4202e1ab562fca6/utils%2Fprint_env.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b26157d64cf12dbd3ec34172c4202e1ab562fca6/utils%2Fprint_env.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fprint_env.py?ref=b26157d64cf12dbd3ec34172c4202e1ab562fca6",
            "patch": "@@ -21,6 +21,7 @@\n import sys\n \n import transformers\n+from transformers import is_torch_xpu_available\n \n \n os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n@@ -32,11 +33,21 @@\n     import torch\n \n     print(\"Torch version:\", torch.__version__)\n-    print(\"Cuda available:\", torch.cuda.is_available())\n-    print(\"Cuda version:\", torch.version.cuda)\n-    print(\"CuDNN version:\", torch.backends.cudnn.version())\n-    print(\"Number of GPUs available:\", torch.cuda.device_count())\n-    print(\"NCCL version:\", torch.cuda.nccl.version())\n+    accelerator = \"NA\"\n+    if torch.cuda.is_available():\n+        accelerator = \"CUDA\"\n+    elif is_torch_xpu_available():\n+        accelerator = \"XPU\"\n+    print(\"Torch accelerator:\", accelerator)\n+\n+    if accelerator == \"CUDA\":\n+        print(\"Cuda version:\", torch.version.cuda)\n+        print(\"CuDNN version:\", torch.backends.cudnn.version())\n+        print(\"Number of GPUs available:\", torch.cuda.device_count())\n+        print(\"NCCL version:\", torch.cuda.nccl.version())\n+    elif accelerator == \"XPU\":\n+        print(\"SYCL version:\", torch.version.xpu)\n+        print(\"Number of XPUs available:\", torch.xpu.device_count())\n except ImportError:\n     print(\"Torch version:\", None)\n "
        }
    ],
    "stats": {
        "total": 21,
        "additions": 16,
        "deletions": 5
    }
}