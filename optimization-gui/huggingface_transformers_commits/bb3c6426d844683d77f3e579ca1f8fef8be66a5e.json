{
    "author": "SunMarc",
    "message": "Make `train_dataset` attribute in `_get_train_sampler` optional  (#38226)\n\nmake it optional",
    "sha": "bb3c6426d844683d77f3e579ca1f8fef8be66a5e",
    "files": [
        {
            "sha": "c2a44b6ff08124eadfe50d0a8e13617b9f2d6d11",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/bb3c6426d844683d77f3e579ca1f8fef8be66a5e/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bb3c6426d844683d77f3e579ca1f8fef8be66a5e/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=bb3c6426d844683d77f3e579ca1f8fef8be66a5e",
            "patch": "@@ -972,7 +972,9 @@ def _get_collator_with_removed_columns(\n         )\n         return remove_columns_collator\n \n-    def _get_train_sampler(self, train_dataset) -> Optional[torch.utils.data.Sampler]:\n+    def _get_train_sampler(self, train_dataset: Optional[Dataset] = None) -> Optional[torch.utils.data.Sampler]:\n+        if train_dataset is None:\n+            train_dataset = self.train_dataset\n         if train_dataset is None or not has_length(train_dataset):\n             return None\n "
        }
    ],
    "stats": {
        "total": 4,
        "additions": 3,
        "deletions": 1
    }
}