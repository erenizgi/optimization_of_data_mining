{
    "author": "tibor-reiss",
    "message": "uniformize kwargs for SAM (#34578)\n\n* Make kwargs uniform for SAM\n\n* Remove unused attribute\n\n* Make point_pad_value part of image_kwargs\n\n* Update annotations\n\n* Code review - use existing methods\n\n* Use ProcessorTesterMixin\n\n* Do not add ProcessorTesterMixin everywhere",
    "sha": "e10be82b71a05aeae45eedab5c83cea6ca303d9e",
    "files": [
        {
            "sha": "7ea1d573544e4d1bcb3ebf940da7a1773dc23ca0",
            "filename": "src/transformers/models/sam/processing_sam.py",
            "status": "modified",
            "additions": 60,
            "deletions": 20,
            "changes": 80,
            "blob_url": "https://github.com/huggingface/transformers/blob/e10be82b71a05aeae45eedab5c83cea6ca303d9e/src%2Ftransformers%2Fmodels%2Fsam%2Fprocessing_sam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e10be82b71a05aeae45eedab5c83cea6ca303d9e/src%2Ftransformers%2Fmodels%2Fsam%2Fprocessing_sam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam%2Fprocessing_sam.py?ref=e10be82b71a05aeae45eedab5c83cea6ca303d9e",
            "patch": "@@ -17,13 +17,14 @@\n \"\"\"\n \n from copy import deepcopy\n-from typing import Optional, Union\n+from typing import List, Optional, Union\n \n import numpy as np\n \n-from ...processing_utils import ProcessorMixin\n-from ...tokenization_utils_base import BatchEncoding\n-from ...utils import TensorType, is_tf_available, is_torch_available\n+from ...image_utils import ImageInput, VideoInput\n+from ...processing_utils import ImagesKwargs, ProcessingKwargs, ProcessorMixin\n+from ...tokenization_utils_base import AudioInput, BatchEncoding, PreTokenizedInput, TextInput\n+from ...utils import is_tf_available, is_torch_available\n \n \n if is_torch_available():\n@@ -33,6 +34,23 @@\n     import tensorflow as tf\n \n \n+class SamImagesKwargs(ImagesKwargs):\n+    segmentation_maps: Optional[ImageInput]\n+    input_points: Optional[List[List[float]]]\n+    input_labels: Optional[List[List[int]]]\n+    input_boxes: Optional[List[List[List[float]]]]\n+    point_pad_value: Optional[int]\n+\n+\n+class SamProcessorKwargs(ProcessingKwargs, total=False):\n+    images_kwargs: SamImagesKwargs\n+    _defaults = {\n+        \"images_kwargs\": {\n+            \"point_pad_value\": -10,\n+        }\n+    }\n+\n+\n class SamProcessor(ProcessorMixin):\n     r\"\"\"\n     Constructs a SAM processor which wraps a SAM image processor and an 2D points & Bounding boxes processor into a\n@@ -48,32 +66,50 @@ class SamProcessor(ProcessorMixin):\n \n     attributes = [\"image_processor\"]\n     image_processor_class = \"SamImageProcessor\"\n+    # For backward compatibility. See transformers.processing_utils.ProcessorMixin.prepare_and_validate_optional_call_args for more details.\n+    optional_call_args = [\n+        \"segmentation_maps\",\n+        \"input_points\",\n+        \"input_labels\",\n+        \"input_boxes\",\n+    ]\n \n     def __init__(self, image_processor):\n         super().__init__(image_processor)\n-        self.current_processor = self.image_processor\n-        self.point_pad_value = -10\n         self.target_size = self.image_processor.size[\"longest_edge\"]\n \n     def __call__(\n         self,\n-        images=None,\n-        segmentation_maps=None,\n-        input_points=None,\n-        input_labels=None,\n-        input_boxes=None,\n-        return_tensors: Optional[Union[str, TensorType]] = None,\n+        images: Optional[ImageInput] = None,\n+        # The following is to capture `segmentation_maps`, `input_points`, `input_labels` and `input_boxes`\n+        # arguments that may be passed as a positional argument.\n+        # See transformers.processing_utils.ProcessorMixin.prepare_and_validate_optional_call_args for more details,\n+        # or this conversation for more context:\n+        # https://github.com/huggingface/transformers/pull/32544#discussion_r1720208116\n+        # This behavior is only needed for backward compatibility and will be removed in future versions.\n+        *args,  # to be deprecated\n+        text: Optional[Union[TextInput, PreTokenizedInput, List[TextInput], List[PreTokenizedInput]]] = None,\n+        audio: Optional[AudioInput] = None,\n+        video: Optional[VideoInput] = None,\n         **kwargs,\n     ) -> BatchEncoding:\n         \"\"\"\n         This method uses [`SamImageProcessor.__call__`] method to prepare image(s) for the model. It also prepares 2D\n         points and bounding boxes for the model if they are provided.\n         \"\"\"\n+        output_kwargs = self._merge_kwargs(\n+            SamProcessorKwargs,\n+            tokenizer_init_kwargs={},\n+            **kwargs,\n+            **self.prepare_and_validate_optional_call_args(*args),\n+        )\n+        input_points = output_kwargs[\"images_kwargs\"].pop(\"input_points\", None)\n+        input_labels = output_kwargs[\"images_kwargs\"].pop(\"input_labels\", None)\n+        input_boxes = output_kwargs[\"images_kwargs\"].pop(\"input_boxes\", None)\n+\n         encoding_image_processor = self.image_processor(\n             images,\n-            segmentation_maps=segmentation_maps,\n-            return_tensors=return_tensors,\n-            **kwargs,\n+            **output_kwargs[\"images_kwargs\"],\n         )\n \n         # pop arguments that are not used in the foward but used nevertheless\n@@ -94,7 +130,8 @@ def __call__(\n             input_points=input_points,\n             input_labels=input_labels,\n             input_boxes=input_boxes,\n-            return_tensors=return_tensors,\n+            return_tensors=output_kwargs[\"common_kwargs\"].get(\"return_tensors\"),\n+            point_pad_value=output_kwargs[\"images_kwargs\"].get(\"point_pad_value\"),\n         )\n \n         return encoding_image_processor\n@@ -107,6 +144,7 @@ def _normalize_and_convert(\n         input_labels=None,\n         input_boxes=None,\n         return_tensors=\"pt\",\n+        point_pad_value=-10,\n     ):\n         if input_points is not None:\n             if len(original_sizes) != len(input_points):\n@@ -121,7 +159,9 @@ def _normalize_and_convert(\n             # check that all arrays have the same shape\n             if not all(point.shape == input_points[0].shape for point in input_points):\n                 if input_labels is not None:\n-                    input_points, input_labels = self._pad_points_and_labels(input_points, input_labels)\n+                    input_points, input_labels = self._pad_points_and_labels(\n+                        input_points, input_labels, point_pad_value\n+                    )\n \n             input_points = np.array(input_points)\n \n@@ -174,7 +214,7 @@ def _normalize_and_convert(\n \n         return encoding_image_processor\n \n-    def _pad_points_and_labels(self, input_points, input_labels):\n+    def _pad_points_and_labels(self, input_points, input_labels, point_pad_value):\n         r\"\"\"\n         The method pads the 2D points and labels to the maximum number of points in the batch.\n         \"\"\"\n@@ -183,9 +223,9 @@ def _pad_points_and_labels(self, input_points, input_labels):\n         for i, point in enumerate(input_points):\n             if point.shape[0] != expected_nb_points:\n                 point = np.concatenate(\n-                    [point, np.zeros((expected_nb_points - point.shape[0], 2)) + self.point_pad_value], axis=0\n+                    [point, np.zeros((expected_nb_points - point.shape[0], 2)) + point_pad_value], axis=0\n                 )\n-                input_labels[i] = np.append(input_labels[i], [self.point_pad_value])\n+                input_labels[i] = np.append(input_labels[i], [point_pad_value])\n             processed_input_points.append(point)\n         input_points = processed_input_points\n         return input_points, input_labels"
        },
        {
            "sha": "654f892062625abb25b38024df6c98b7a20e0306",
            "filename": "tests/models/sam/test_processor_sam.py",
            "status": "modified",
            "additions": 21,
            "deletions": 9,
            "changes": 30,
            "blob_url": "https://github.com/huggingface/transformers/blob/e10be82b71a05aeae45eedab5c83cea6ca303d9e/tests%2Fmodels%2Fsam%2Ftest_processor_sam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e10be82b71a05aeae45eedab5c83cea6ca303d9e/tests%2Fmodels%2Fsam%2Ftest_processor_sam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsam%2Ftest_processor_sam.py?ref=e10be82b71a05aeae45eedab5c83cea6ca303d9e",
            "patch": "@@ -26,7 +26,7 @@\n )\n from transformers.utils import is_tf_available, is_torch_available, is_vision_available\n \n-from ...test_processing_common import prepare_image_inputs\n+from ...test_processing_common import ProcessorTesterMixin, prepare_image_inputs\n \n \n if is_vision_available():\n@@ -43,7 +43,9 @@\n \n @require_vision\n @require_torchvision\n-class SamProcessorTest(unittest.TestCase):\n+class SamProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n+    processor_class = SamProcessor\n+\n     def setUp(self):\n         self.tmpdirname = tempfile.mkdtemp()\n         image_processor = SamImageProcessor()\n@@ -56,11 +58,6 @@ def get_image_processor(self, **kwargs):\n     def tearDown(self):\n         shutil.rmtree(self.tmpdirname)\n \n-    # Processor tester class can't use ProcessorTesterMixin atm because the processor is atypical e.g. only contains an image processor\n-    def prepare_image_inputs(self):\n-        \"\"\"This function prepares a list of PIL images.\"\"\"\n-        return prepare_image_inputs()\n-\n     def prepare_mask_inputs(self):\n         \"\"\"This function prepares a list of PIL images, or a list of numpy arrays if one specifies numpify=True,\n         or a list of PyTorch tensors if one specifies torchify=True.\n@@ -69,6 +66,21 @@ def prepare_mask_inputs(self):\n         mask_inputs = [Image.fromarray(x) for x in mask_inputs]\n         return mask_inputs\n \n+    def test_chat_template_save_loading(self):\n+        self.skipTest(\"SamProcessor does not have a tokenizer\")\n+\n+    def test_image_processor_defaults_preserved_by_image_kwargs(self):\n+        self.skipTest(\"SamProcessor does not have a tokenizer\")\n+\n+    def test_kwargs_overrides_default_image_processor_kwargs(self):\n+        self.skipTest(\"SamProcessor does not have a tokenizer\")\n+\n+    def test_kwargs_overrides_default_tokenizer_kwargs(self):\n+        self.skipTest(\"SamProcessor does not have a tokenizer\")\n+\n+    def test_tokenizer_defaults_preserved_by_kwargs(self):\n+        self.skipTest(\"SamProcessor does not have a tokenizer\")\n+\n     def test_save_load_pretrained_additional_features(self):\n         processor = SamProcessor(image_processor=self.get_image_processor())\n         processor.save_pretrained(self.tmpdirname)\n@@ -165,7 +177,7 @@ def get_image_processor(self, **kwargs):\n     def tearDown(self):\n         shutil.rmtree(self.tmpdirname)\n \n-    # Processor tester class can't use ProcessorTesterMixin as processor is atypical e.g. only contains an image processor and it assumes torch\n+    # This is to avoid repeating the skipping of the common tests\n     def prepare_image_inputs(self):\n         \"\"\"This function prepares a list of PIL images.\"\"\"\n         return prepare_image_inputs()\n@@ -248,7 +260,7 @@ def get_image_processor(self, **kwargs):\n     def tearDown(self):\n         shutil.rmtree(self.tmpdirname)\n \n-    # Processor tester class can't use ProcessorTesterMixin atm because the processor is atypical e.g. only contains an image processor\n+    # This is to avoid repeating the skipping of the common tests\n     def prepare_image_inputs(self):\n         \"\"\"This function prepares a list of PIL images.\"\"\"\n         return prepare_image_inputs()"
        }
    ],
    "stats": {
        "total": 110,
        "additions": 81,
        "deletions": 29
    }
}