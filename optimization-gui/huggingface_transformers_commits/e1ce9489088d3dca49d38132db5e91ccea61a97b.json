{
    "author": "gante",
    "message": "[CLI] add import guards (#36376)\n\n* add import guards\n\n* nit",
    "sha": "e1ce9489088d3dca49d38132db5e91ccea61a97b",
    "files": [
        {
            "sha": "f87720a9cae7bc066490e203bd729192f8d30430",
            "filename": "src/transformers/commands/chat.py",
            "status": "modified",
            "additions": 17,
            "deletions": 6,
            "changes": 23,
            "blob_url": "https://github.com/huggingface/transformers/blob/e1ce9489088d3dca49d38132db5e91ccea61a97b/src%2Ftransformers%2Fcommands%2Fchat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e1ce9489088d3dca49d38132db5e91ccea61a97b/src%2Ftransformers%2Fcommands%2Fchat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fchat.py?ref=e1ce9489088d3dca49d38132db5e91ccea61a97b",
            "patch": "@@ -24,20 +24,26 @@\n from threading import Thread\n from typing import Optional\n \n-import torch\n import yaml\n-from rich.console import Console\n-from rich.live import Live\n-from rich.markdown import Markdown\n \n-from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TextIteratorStreamer\n+from transformers.utils import is_rich_available, is_torch_available\n \n from . import BaseTransformersCLICommand\n \n \n if platform.system() != \"Windows\":\n     import pwd\n \n+if is_rich_available():\n+    from rich.console import Console\n+    from rich.live import Live\n+    from rich.markdown import Markdown\n+\n+if is_torch_available():\n+    import torch\n+\n+    from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TextIteratorStreamer\n+\n \n HELP_STRING = \"\"\"\\\n \n@@ -153,7 +159,7 @@ def parse_settings(user_input, current_args, interface):\n         return current_args, True\n \n \n-def get_quantization_config(model_args) -> Optional[BitsAndBytesConfig]:\n+def get_quantization_config(model_args) -> Optional[\"BitsAndBytesConfig\"]:\n     if model_args.load_in_4bit:\n         quantization_config = BitsAndBytesConfig(\n             load_in_4bit=True,\n@@ -433,6 +439,11 @@ def __init__(self, args):\n         self.args = args\n \n     def run(self):\n+        if not is_rich_available():\n+            raise ImportError(\"You need to install rich to use the chat interface. (`pip install rich`)\")\n+        if not is_torch_available():\n+            raise ImportError(\"You need to install torch to use the chat interface. (`pip install torch`)\")\n+\n         args = self.args\n         if args.examples_path is None:\n             examples = DEFAULT_EXAMPLES"
        },
        {
            "sha": "85ed61339f3e2b4e54ce8079de045634303ca529",
            "filename": "src/transformers/utils/__init__.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/e1ce9489088d3dca49d38132db5e91ccea61a97b/src%2Ftransformers%2Futils%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e1ce9489088d3dca49d38132db5e91ccea61a97b/src%2Ftransformers%2Futils%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2F__init__.py?ref=e1ce9489088d3dca49d38132db5e91ccea61a97b",
            "patch": "@@ -181,6 +181,7 @@\n     is_pytesseract_available,\n     is_pytest_available,\n     is_pytorch_quantization_available,\n+    is_rich_available,\n     is_rjieba_available,\n     is_sacremoses_available,\n     is_safetensors_available,"
        },
        {
            "sha": "c9007d909c7d94563cb14ee0eddc856ec08989ee",
            "filename": "src/transformers/utils/import_utils.py",
            "status": "modified",
            "additions": 11,
            "deletions": 1,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/e1ce9489088d3dca49d38132db5e91ccea61a97b/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e1ce9489088d3dca49d38132db5e91ccea61a97b/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fimport_utils.py?ref=e1ce9489088d3dca49d38132db5e91ccea61a97b",
            "patch": "@@ -149,7 +149,6 @@ def _is_package_available(pkg_name: str, return_version: bool = False) -> Union[\n _gptqmodel_available = _is_package_available(\"gptqmodel\")\n # `importlib.metadata.version` doesn't work with `awq`\n _auto_awq_available = importlib.util.find_spec(\"awq\") is not None\n-_quanto_available = _is_package_available(\"quanto\")\n _is_optimum_quanto_available = False\n try:\n     importlib.metadata.version(\"optimum_quanto\")\n@@ -203,6 +202,7 @@ def _is_package_available(pkg_name: str, return_version: bool = False) -> Union[\n _liger_kernel_available = _is_package_available(\"liger_kernel\")\n _triton_available = _is_package_available(\"triton\")\n _spqr_available = _is_package_available(\"spqr_quant\")\n+_rich_available = _is_package_available(\"rich\")\n \n _torch_version = \"N/A\"\n _torch_available = False\n@@ -1300,6 +1300,10 @@ def is_triton_available():\n     return _triton_available\n \n \n+def is_rich_available():\n+    return _rich_available\n+\n+\n # docstyle-ignore\n AV_IMPORT_ERROR = \"\"\"\n {0} requires the PyAv library but it was not found in your environment. You can install it with:\n@@ -1659,6 +1663,11 @@ def is_triton_available():\n jinja2`. Please note that you may need to restart your runtime after installation.\n \"\"\"\n \n+RICH_IMPORT_ERROR = \"\"\"\n+{0} requires the rich library but it was not found in your environment. You can install it with pip: `pip install\n+rich`. Please note that you may need to restart your runtime after installation.\n+\"\"\"\n+\n BACKENDS_MAPPING = OrderedDict(\n     [\n         (\"av\", (is_av_available, AV_IMPORT_ERROR)),\n@@ -1705,6 +1714,7 @@ def is_triton_available():\n         (\"peft\", (is_peft_available, PEFT_IMPORT_ERROR)),\n         (\"jinja\", (is_jinja_available, JINJA_IMPORT_ERROR)),\n         (\"yt_dlp\", (is_yt_dlp_available, YT_DLP_IMPORT_ERROR)),\n+        (\"rich\", (is_rich_available, RICH_IMPORT_ERROR)),\n     ]\n )\n "
        }
    ],
    "stats": {
        "total": 36,
        "additions": 29,
        "deletions": 7
    }
}