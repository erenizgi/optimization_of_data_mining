{
    "author": "Cyrilvallez",
    "message": "Update Phi4 converter (#37594)\n\n* fix converter\n\n* Update phi4_multimodal.md",
    "sha": "4acf692acebf4b9f25613d5ee410259bad761594",
    "files": [
        {
            "sha": "22b55792f60ad73c8d93a5ac19615a021d05a997",
            "filename": "docs/source/en/model_doc/phi4_multimodal.md",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/4acf692acebf4b9f25613d5ee410259bad761594/docs%2Fsource%2Fen%2Fmodel_doc%2Fphi4_multimodal.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/4acf692acebf4b9f25613d5ee410259bad761594/docs%2Fsource%2Fen%2Fmodel_doc%2Fphi4_multimodal.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fphi4_multimodal.md?ref=4acf692acebf4b9f25613d5ee410259bad761594",
            "patch": "@@ -64,7 +64,7 @@ inputs = processor.apply_chat_template(\n     tokenize=True,\n     return_dict=True,\n     return_tensors=\"pt\",\n-).to(device, torch.float16)\n+).to(device)\n \n # Generate response\n generate_ids = model.generate(\n@@ -98,8 +98,7 @@ inputs = processor.apply_chat_template(\n     tokenize=True,\n     return_dict=True,\n     return_tensors=\"pt\",\n-    sample_rate=sample_rate,\n-).to(device, torch.float16)\n+).to(device)\n \n generate_ids = model.generate(\n     **inputs,"
        },
        {
            "sha": "b1a4ac90ac7c3057ec592fee004b3d9de5e6f0d5",
            "filename": "src/transformers/models/phi4_multimodal/convert_phi4_multimodal_weights_to_hf.py",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/4acf692acebf4b9f25613d5ee410259bad761594/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fconvert_phi4_multimodal_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4acf692acebf4b9f25613d5ee410259bad761594/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fconvert_phi4_multimodal_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fconvert_phi4_multimodal_weights_to_hf.py?ref=4acf692acebf4b9f25613d5ee410259bad761594",
            "patch": "@@ -170,12 +170,25 @@ def convert_and_save_processor(input_dir: str, output_dir: str):\n     \"\"\"Convert the processor.\"\"\"\n     original_processor = AutoProcessor.from_pretrained(input_dir, trust_remote_code=True)\n     original_processor.tokenizer.extra_special_tokens = {\"image_token\": \"<|image|>\", \"audio_token\": \"<|audio|>\"}\n+    # We need to add those temporarily to instantiate the processor\n+    original_processor.tokenizer.image_token = \"<|image|>\"\n+    original_processor.tokenizer.audio_token = \"<|audio|>\"\n+    original_processor.tokenizer.image_token_id = 200010\n+    original_processor.tokenizer.audio_token_id = 200011\n+\n     converted_processor = Phi4MultimodalProcessor(\n         tokenizer=original_processor.tokenizer,\n         image_processor=Phi4MultimodalImageProcessorFast(),\n         audio_processor=Phi4MultimodalFeatureExtractor(),\n         chat_template=CHAT_TEMPLATE,\n     )\n+    # We remove them before saving to avoid polluting somehow\n+    del converted_processor.tokenizer.image_token\n+    del converted_processor.tokenizer.image_token_id\n+    del converted_processor.tokenizer.audio_token\n+    del converted_processor.tokenizer.audio_token_id\n+\n+    # Save the processor\n     converted_processor.save_pretrained(output_dir)\n \n     # we need to rename a few tokens but tokenizers doesn't allow doing that programatically"
        }
    ],
    "stats": {
        "total": 18,
        "additions": 15,
        "deletions": 3
    }
}