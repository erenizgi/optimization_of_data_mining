{
    "author": "xenova",
    "message": "Fix in-place modification of user-input in SAM2 embed boxes (#42173)\n\n* Do not modify boxes tensor in-place",
    "sha": "ffb35fe14283d61cd5434a32d04d07993e66477a",
    "files": [
        {
            "sha": "4562f55b9aba0e7f48d6dde4ecaa51397e911a46",
            "filename": "src/transformers/models/edgetam/modeling_edgetam.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ffb35fe14283d61cd5434a32d04d07993e66477a/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodeling_edgetam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ffb35fe14283d61cd5434a32d04d07993e66477a/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodeling_edgetam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fedgetam%2Fmodeling_edgetam.py?ref=ffb35fe14283d61cd5434a32d04d07993e66477a",
            "patch": "@@ -600,7 +600,7 @@ def _embed_points(self, points: torch.Tensor, labels: torch.Tensor, pad: bool) -\n \n     def _embed_boxes(self, boxes: torch.Tensor) -> torch.Tensor:\n         \"\"\"Embeds box prompts.\"\"\"\n-        boxes += 0.5  # Shift to center of pixel\n+        boxes = boxes + 0.5  # Shift to center of pixel\n         coords = boxes.view(*boxes.shape[:2], 2, 2)\n         # add padding point for consistency with the original implementation\n         coords = torch.nn.functional.pad(coords, (0, 0, 0, 1), mode=\"constant\", value=0)"
        },
        {
            "sha": "a6c383a30055da86620ccd0be24a0d4a5b0c2ec1",
            "filename": "src/transformers/models/edgetam_video/modeling_edgetam_video.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ffb35fe14283d61cd5434a32d04d07993e66477a/src%2Ftransformers%2Fmodels%2Fedgetam_video%2Fmodeling_edgetam_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ffb35fe14283d61cd5434a32d04d07993e66477a/src%2Ftransformers%2Fmodels%2Fedgetam_video%2Fmodeling_edgetam_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fedgetam_video%2Fmodeling_edgetam_video.py?ref=ffb35fe14283d61cd5434a32d04d07993e66477a",
            "patch": "@@ -1644,7 +1644,7 @@ def _embed_points(self, points: torch.Tensor, labels: torch.Tensor, pad: bool) -\n \n     def _embed_boxes(self, boxes: torch.Tensor) -> torch.Tensor:\n         \"\"\"Embeds box prompts.\"\"\"\n-        boxes += 0.5  # Shift to center of pixel\n+        boxes = boxes + 0.5  # Shift to center of pixel\n         coords = boxes.view(*boxes.shape[:2], 2, 2)\n         # add padding point for consistency with the original implementation\n         coords = torch.nn.functional.pad(coords, (0, 0, 0, 1), mode=\"constant\", value=0)"
        },
        {
            "sha": "90710eee63922364dc23d610c62f7180fecf4663",
            "filename": "src/transformers/models/sam2/modeling_sam2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ffb35fe14283d61cd5434a32d04d07993e66477a/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodeling_sam2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ffb35fe14283d61cd5434a32d04d07993e66477a/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodeling_sam2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodeling_sam2.py?ref=ffb35fe14283d61cd5434a32d04d07993e66477a",
            "patch": "@@ -792,7 +792,7 @@ def _embed_points(self, points: torch.Tensor, labels: torch.Tensor, pad: bool) -\n \n     def _embed_boxes(self, boxes: torch.Tensor) -> torch.Tensor:\n         \"\"\"Embeds box prompts.\"\"\"\n-        boxes += 0.5  # Shift to center of pixel\n+        boxes = boxes + 0.5  # Shift to center of pixel\n         coords = boxes.view(*boxes.shape[:2], 2, 2)\n         # add padding point for consistency with the original implementation\n         coords = torch.nn.functional.pad(coords, (0, 0, 0, 1), mode=\"constant\", value=0)"
        },
        {
            "sha": "87c556efbc0f3bad06e1570aba816bbf6bda078c",
            "filename": "src/transformers/models/sam2/modular_sam2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ffb35fe14283d61cd5434a32d04d07993e66477a/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ffb35fe14283d61cd5434a32d04d07993e66477a/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py?ref=ffb35fe14283d61cd5434a32d04d07993e66477a",
            "patch": "@@ -890,7 +890,7 @@ def _embed_points(self, points: torch.Tensor, labels: torch.Tensor, pad: bool) -\n \n     def _embed_boxes(self, boxes: torch.Tensor) -> torch.Tensor:\n         \"\"\"Embeds box prompts.\"\"\"\n-        boxes += 0.5  # Shift to center of pixel\n+        boxes = boxes + 0.5  # Shift to center of pixel\n         coords = boxes.view(*boxes.shape[:2], 2, 2)\n         # add padding point for consistency with the original implementation\n         coords = torch.nn.functional.pad(coords, (0, 0, 0, 1), mode=\"constant\", value=0)"
        },
        {
            "sha": "3d3566fbcd1ce1b032fd0f5c5ee75de5efbe4c6f",
            "filename": "src/transformers/models/sam2_video/modeling_sam2_video.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ffb35fe14283d61cd5434a32d04d07993e66477a/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodeling_sam2_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ffb35fe14283d61cd5434a32d04d07993e66477a/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodeling_sam2_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodeling_sam2_video.py?ref=ffb35fe14283d61cd5434a32d04d07993e66477a",
            "patch": "@@ -1227,7 +1227,7 @@ def _embed_points(self, points: torch.Tensor, labels: torch.Tensor, pad: bool) -\n \n     def _embed_boxes(self, boxes: torch.Tensor) -> torch.Tensor:\n         \"\"\"Embeds box prompts.\"\"\"\n-        boxes += 0.5  # Shift to center of pixel\n+        boxes = boxes + 0.5  # Shift to center of pixel\n         coords = boxes.view(*boxes.shape[:2], 2, 2)\n         # add padding point for consistency with the original implementation\n         coords = torch.nn.functional.pad(coords, (0, 0, 0, 1), mode=\"constant\", value=0)"
        }
    ],
    "stats": {
        "total": 10,
        "additions": 5,
        "deletions": 5
    }
}