{
    "author": "cyyever",
    "message": "Fix outdated torch version check (#40925)\n\nUpdate torch minimum version check to 2.2\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>",
    "sha": "6eff44bb8db3c90614b45cc960e70c21bd5246c8",
    "files": [
        {
            "sha": "76cbaad0eb17f944ee13519c3bda24e7899740e7",
            "filename": "src/transformers/utils/import_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/6eff44bb8db3c90614b45cc960e70c21bd5246c8/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6eff44bb8db3c90614b45cc960e70c21bd5246c8/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fimport_utils.py?ref=6eff44bb8db3c90614b45cc960e70c21bd5246c8",
            "patch": "@@ -236,9 +236,9 @@ def _is_package_available(pkg_name: str, return_version: bool = False) -> Union[\n \n _torch_available, _torch_version = _is_package_available(\"torch\", return_version=True)\n if _torch_available:\n-    _torch_available = version.parse(_torch_version) >= version.parse(\"2.1.0\")\n+    _torch_available = version.parse(_torch_version) >= version.parse(\"2.2.0\")\n     if not _torch_available:\n-        logger.warning(f\"Disabling PyTorch because PyTorch >= 2.1 is required but found {_torch_version}\")\n+        logger.warning(f\"Disabling PyTorch because PyTorch >= 2.2 is required but found {_torch_version}\")\n \n \n _essentia_available = importlib.util.find_spec(\"essentia\") is not None"
        },
        {
            "sha": "cb2e31867194867936173fe3b2b8f2eaab2da964",
            "filename": "tests/models/qwen2_5_vl/test_modeling_qwen2_5_vl.py",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/6eff44bb8db3c90614b45cc960e70c21bd5246c8/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6eff44bb8db3c90614b45cc960e70c21bd5246c8/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py?ref=6eff44bb8db3c90614b45cc960e70c21bd5246c8",
            "patch": "@@ -55,8 +55,6 @@\n if is_torch_available():\n     import torch\n \n-else:\n-    is_torch_greater_or_equal_than_2_0 = False\n \n if is_vision_available():\n     from PIL import Image"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 2,
        "deletions": 4
    }
}