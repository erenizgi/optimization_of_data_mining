{
    "author": "pcuenca",
    "message": "Fix Llama 3 TikToken conversion (#33538)\n\n* Fix Llama 3 TikToken conversion\r\n\r\n* No need to add tokens again",
    "sha": "0c718f16d1e8b73ac637529f6328fd8cb378ce7e",
    "files": [
        {
            "sha": "99aa198bf62c940d63bd1d4b69d25646c71c748d",
            "filename": "src/transformers/models/llama/convert_llama_weights_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/0c718f16d1e8b73ac637529f6328fd8cb378ce7e/src%2Ftransformers%2Fmodels%2Fllama%2Fconvert_llama_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0c718f16d1e8b73ac637529f6328fd8cb378ce7e/src%2Ftransformers%2Fmodels%2Fllama%2Fconvert_llama_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllama%2Fconvert_llama_weights_to_hf.py?ref=0c718f16d1e8b73ac637529f6328fd8cb378ce7e",
            "patch": "@@ -332,7 +332,7 @@ def permute(w, n_heads, dim1=dim, dim2=dim):\n \n class Llama3Converter(TikTokenConverter):\n     def __init__(self, vocab_file, special_tokens=None, instruct=False, model_max_length=None, **kwargs):\n-        super().__init__(vocab_file, **kwargs)\n+        super().__init__(vocab_file, additional_special_tokens=special_tokens, **kwargs)\n         tokenizer = self.converted()\n         chat_template = (\n             \"{% set loop_messages = messages %}\"\n@@ -345,7 +345,6 @@ def __init__(self, vocab_file, special_tokens=None, instruct=False, model_max_le\n             \"{% endfor %}\"\n             \"{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\"\n         )\n-        tokenizer.add_special_tokens(special_tokens)\n \n         self.tokenizer = PreTrainedTokenizerFast(\n             tokenizer_object=tokenizer,"
        }
    ],
    "stats": {
        "total": 3,
        "additions": 1,
        "deletions": 2
    }
}