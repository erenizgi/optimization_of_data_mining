{
    "author": "ydshieh",
    "message": "Simplify running tests in a subprocess (#34213)\n\n* check\r\n\r\n* check\r\n\r\n* check\r\n\r\n* check\r\n\r\n* add docstring\r\n\r\n---------\r\n\r\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "439334c8fb4edf11314dc94c72dda868f87a0808",
    "files": [
        {
            "sha": "0eef286732d81c36c5e2e9193a6042b11563ac4f",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 40,
            "deletions": 0,
            "changes": 40,
            "blob_url": "https://github.com/huggingface/transformers/blob/439334c8fb4edf11314dc94c72dda868f87a0808/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/439334c8fb4edf11314dc94c72dda868f87a0808/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=439334c8fb4edf11314dc94c72dda868f87a0808",
            "patch": "@@ -2366,6 +2366,46 @@ def run_test_in_subprocess(test_case, target_func, inputs=None, timeout=None):\n         test_case.fail(f'{results[\"error\"]}')\n \n \n+def run_test_using_subprocess(func):\n+    \"\"\"\n+    To decorate a test to run in a subprocess using the `subprocess` module. This could avoid potential GPU memory\n+    issues (GPU OOM or a test that causes many subsequential failing with `CUDA error: device-side assert triggered`).\n+    \"\"\"\n+    import pytest\n+\n+    @functools.wraps(func)\n+    def wrapper(*args, **kwargs):\n+        if os.getenv(\"_INSIDE_SUB_PROCESS\", None) == \"1\":\n+            func(*args, **kwargs)\n+        else:\n+            test = \" \".join(os.environ.get(\"PYTEST_CURRENT_TEST\").split(\" \")[:-1])\n+            try:\n+                import copy\n+\n+                env = copy.deepcopy(os.environ)\n+                env[\"_INSIDE_SUB_PROCESS\"] = \"1\"\n+\n+                # If not subclass of `unitTest.TestCase` and `pytestconfig` is used: try to grab and use the arguments\n+                if \"pytestconfig\" in kwargs:\n+                    command = list(kwargs[\"pytestconfig\"].invocation_params.args)\n+                    for idx, x in enumerate(command):\n+                        if x in kwargs[\"pytestconfig\"].args:\n+                            test = test.split(\"::\")[1:]\n+                            command[idx] = \"::\".join([f\"{func.__globals__['__file__']}\"] + test)\n+                    command = [f\"{sys.executable}\", \"-m\", \"pytest\"] + command\n+                    command = [x for x in command if x not in [\"--no-summary\"]]\n+                # Otherwise, simply run the test with no option at all\n+                else:\n+                    command = [f\"{sys.executable}\", \"-m\", \"pytest\", f\"{test}\"]\n+\n+                subprocess.run(command, env=env, check=True, capture_output=True)\n+            except subprocess.CalledProcessError as e:\n+                exception_message = e.stdout.decode()\n+                raise pytest.fail(exception_message, pytrace=False)\n+\n+    return wrapper\n+\n+\n \"\"\"\n The following contains utils to run the documentation tests without having to overwrite any files.\n "
        },
        {
            "sha": "cdbe815431f319f235a13b463e192032bd7c281d",
            "filename": "tests/models/imagegpt/test_modeling_imagegpt.py",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/439334c8fb4edf11314dc94c72dda868f87a0808/tests%2Fmodels%2Fimagegpt%2Ftest_modeling_imagegpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/439334c8fb4edf11314dc94c72dda868f87a0808/tests%2Fmodels%2Fimagegpt%2Ftest_modeling_imagegpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fimagegpt%2Ftest_modeling_imagegpt.py?ref=439334c8fb4edf11314dc94c72dda868f87a0808",
            "patch": "@@ -18,7 +18,7 @@\n import unittest\n \n from transformers import ImageGPTConfig\n-from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n+from transformers.testing_utils import require_torch, require_vision, run_test_using_subprocess, slow, torch_device\n from transformers.utils import cached_property, is_torch_available, is_vision_available\n \n from ...generation.test_utils import GenerationTesterMixin\n@@ -257,11 +257,9 @@ def _check_scores(self, batch_size, scores, length, config):\n         self.assertEqual(len(scores), length)\n         self.assertListEqual([iter_scores.shape for iter_scores in scores], [expected_shape] * len(scores))\n \n-    @unittest.skip(\n-        reason=\"After #33632, this test still passes, but many subsequential tests fail with `device-side assert triggered`\"\n-    )\n+    @run_test_using_subprocess\n     def test_beam_search_generate_dict_outputs_use_cache(self):\n-        pass\n+        super().test_beam_search_generate_dict_outputs_use_cache()\n \n     def setUp(self):\n         self.model_tester = ImageGPTModelTester(self)"
        },
        {
            "sha": "fd4c49f4a6966dcd239a44ac7d958af087536e68",
            "filename": "tests/models/video_llava/test_modeling_video_llava.py",
            "status": "modified",
            "additions": 9,
            "deletions": 4,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/439334c8fb4edf11314dc94c72dda868f87a0808/tests%2Fmodels%2Fvideo_llava%2Ftest_modeling_video_llava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/439334c8fb4edf11314dc94c72dda868f87a0808/tests%2Fmodels%2Fvideo_llava%2Ftest_modeling_video_llava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvideo_llava%2Ftest_modeling_video_llava.py?ref=439334c8fb4edf11314dc94c72dda868f87a0808",
            "patch": "@@ -28,7 +28,14 @@\n     is_torch_available,\n     is_vision_available,\n )\n-from transformers.testing_utils import require_bitsandbytes, require_torch, require_torch_gpu, slow, torch_device\n+from transformers.testing_utils import (\n+    require_bitsandbytes,\n+    require_torch,\n+    require_torch_gpu,\n+    run_test_using_subprocess,\n+    slow,\n+    torch_device,\n+)\n \n from ...generation.test_utils import GenerationTesterMixin\n from ...test_configuration_common import ConfigTester\n@@ -248,9 +255,7 @@ def test_flash_attn_2_fp32_ln(self):\n     def test_flash_attention_2_padding_matches_padding_free_with_position_ids(self):\n         pass\n \n-    @unittest.skip(\n-        reason=\"After #33533, this still passes, but many subsequential tests fail with `device-side assert triggered`\"\n-    )\n+    @run_test_using_subprocess\n     def test_mixed_input(self):\n         config, inputs = self.model_tester.prepare_config_and_inputs_for_common()\n         for model_class in self.all_model_classes:"
        }
    ],
    "stats": {
        "total": 61,
        "additions": 52,
        "deletions": 9
    }
}