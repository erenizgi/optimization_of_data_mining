{
    "author": "nithinraok",
    "message": "add support for saving encoder only so any parakeet model can be loaded for inference (#41969)\n\n* add support for saving encoder only so any decoder model can be loaded\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* use convolution_bias\n\n* convert modular\n\n* convolution_bias in convertion script\n\n---------\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\nCo-authored-by: Eustache Le Bihan <eulebihan@gmail.com>\nCo-authored-by: eustlb <94853470+eustlb@users.noreply.github.com>",
    "sha": "b9f90dc388fd415a2ba2a6a31a372f451d4a4eed",
    "files": [
        {
            "sha": "aecfd9f18b2cc9e84010323ac6dd31f83cf1a661",
            "filename": "src/transformers/models/fastspeech2_conformer/configuration_fastspeech2_conformer.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/b9f90dc388fd415a2ba2a6a31a372f451d4a4eed/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fconfiguration_fastspeech2_conformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b9f90dc388fd415a2ba2a6a31a372f451d4a4eed/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fconfiguration_fastspeech2_conformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fconfiguration_fastspeech2_conformer.py?ref=b9f90dc388fd415a2ba2a6a31a372f451d4a4eed",
            "patch": "@@ -147,6 +147,8 @@ class FastSpeech2ConformerConfig(PreTrainedConfig):\n             Speaker embedding dimension. If set to > 0, assume that speaker_embedding will be provided as the input.\n         is_encoder_decoder (`bool`, *optional*, defaults to `True`):\n             Specifies whether the model is an encoder-decoder.\n+        convolution_bias (`bool`, *optional*, defaults to `True`):\n+            Specifies whether to use bias in convolutions of the conformer's convolution module.\n \n     Example:\n \n@@ -224,6 +226,7 @@ def __init__(\n         num_languages=None,\n         speaker_embed_dim=None,\n         is_encoder_decoder=True,\n+        convolution_bias=True,\n         **kwargs,\n     ):\n         if positionwise_conv_kernel_size % 2 == 0:\n@@ -318,6 +321,7 @@ def __init__(\n         self.speaker_embed_dim = speaker_embed_dim\n         self.duration_predictor_dropout_rate = duration_predictor_dropout_rate\n         self.is_encoder_decoder = is_encoder_decoder\n+        self.convolution_bias = convolution_bias\n \n         super().__init__(\n             is_encoder_decoder=is_encoder_decoder,"
        },
        {
            "sha": "fa1544a0171cf33485b80d8faaa2c77c94622acc",
            "filename": "src/transformers/models/fastspeech2_conformer/modeling_fastspeech2_conformer.py",
            "status": "modified",
            "additions": 13,
            "deletions": 3,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/b9f90dc388fd415a2ba2a6a31a372f451d4a4eed/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fmodeling_fastspeech2_conformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b9f90dc388fd415a2ba2a6a31a372f451d4a4eed/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fmodeling_fastspeech2_conformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fmodeling_fastspeech2_conformer.py?ref=b9f90dc388fd415a2ba2a6a31a372f451d4a4eed",
            "patch": "@@ -490,12 +490,22 @@ def __init__(self, config: FastSpeech2ConformerConfig, module_config=None):\n             kernel_size = module_config[\"kernel_size\"]\n             self.activation = ACT2FN[module_config.get(\"activation\", \"silu\")]\n         self.padding = (kernel_size - 1) // 2\n-        self.pointwise_conv1 = nn.Conv1d(channels, 2 * channels, kernel_size=1, stride=1, padding=0, bias=True)\n+        self.pointwise_conv1 = nn.Conv1d(\n+            channels, 2 * channels, kernel_size=1, stride=1, padding=0, bias=config.convolution_bias\n+        )\n         self.depthwise_conv = nn.Conv1d(\n-            channels, channels, kernel_size, stride=1, padding=self.padding, groups=channels, bias=True\n+            channels,\n+            channels,\n+            kernel_size,\n+            stride=1,\n+            padding=self.padding,\n+            groups=channels,\n+            bias=config.convolution_bias,\n         )\n         self.norm = nn.BatchNorm1d(channels)\n-        self.pointwise_conv2 = nn.Conv1d(channels, channels, kernel_size=1, stride=1, padding=0, bias=True)\n+        self.pointwise_conv2 = nn.Conv1d(\n+            channels, channels, kernel_size=1, stride=1, padding=0, bias=config.convolution_bias\n+        )\n \n     def forward(self, hidden_states, attention_mask=None):\n         \"\"\""
        },
        {
            "sha": "057259b0489944bcb45a6a83f44de430660779e0",
            "filename": "src/transformers/models/parakeet/configuration_parakeet.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/b9f90dc388fd415a2ba2a6a31a372f451d4a4eed/src%2Ftransformers%2Fmodels%2Fparakeet%2Fconfiguration_parakeet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b9f90dc388fd415a2ba2a6a31a372f451d4a4eed/src%2Ftransformers%2Fmodels%2Fparakeet%2Fconfiguration_parakeet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fparakeet%2Fconfiguration_parakeet.py?ref=b9f90dc388fd415a2ba2a6a31a372f451d4a4eed",
            "patch": "@@ -44,6 +44,8 @@ class ParakeetEncoderConfig(PreTrainedConfig):\n             The non-linear activation function (function or string) in the encoder and pooler.\n         attention_bias (`bool`, *optional*, defaults to `True`):\n             Whether to use bias in the attention layers.\n+        convolution_bias (`bool`, *optional*, defaults to `True`):\n+            Whether to use bias in convolutions of the conformer's convolution module.\n         conv_kernel_size (`int`, *optional*, defaults to 9):\n             The kernel size of the convolution layers in the Conformer block.\n         subsampling_factor (`int`, *optional*, defaults to 8):\n@@ -102,6 +104,7 @@ def __init__(\n         intermediate_size=4096,\n         hidden_act=\"silu\",\n         attention_bias=True,\n+        convolution_bias=True,\n         conv_kernel_size=9,\n         subsampling_factor=8,\n         subsampling_conv_channels=256,\n@@ -128,6 +131,7 @@ def __init__(\n         self.intermediate_size = intermediate_size\n         self.hidden_act = hidden_act\n         self.attention_bias = attention_bias\n+        self.convolution_bias = convolution_bias\n \n         if (conv_kernel_size - 1) % 2 != 0:\n             raise ValueError(f\"conv_kernel_size must be odd, got {conv_kernel_size}\")"
        },
        {
            "sha": "e5cbe7f785db9fd61ff48edcf7206a9f9478ab12",
            "filename": "src/transformers/models/parakeet/convert_nemo_to_hf.py",
            "status": "modified",
            "additions": 92,
            "deletions": 26,
            "changes": 118,
            "blob_url": "https://github.com/huggingface/transformers/blob/b9f90dc388fd415a2ba2a6a31a372f451d4a4eed/src%2Ftransformers%2Fmodels%2Fparakeet%2Fconvert_nemo_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b9f90dc388fd415a2ba2a6a31a372f451d4a4eed/src%2Ftransformers%2Fmodels%2Fparakeet%2Fconvert_nemo_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fparakeet%2Fconvert_nemo_to_hf.py?ref=b9f90dc388fd415a2ba2a6a31a372f451d4a4eed",
            "patch": "@@ -25,6 +25,8 @@\n \n from transformers import (\n     ParakeetCTCConfig,\n+    ParakeetEncoder,\n+    ParakeetEncoderConfig,\n     ParakeetFeatureExtractor,\n     ParakeetForCTC,\n     ParakeetProcessor,\n@@ -203,7 +205,8 @@ def write_processor(nemo_config: dict, model_files, output_dir, push_to_repo_id=\n         processor.push_to_hub(push_to_repo_id)\n \n \n-def write_model(nemo_config, model_files, model_type, output_dir, push_to_repo_id=None):\n+def convert_encoder_config(nemo_config):\n+    \"\"\"Convert NeMo encoder config to HF encoder config.\"\"\"\n     encoder_keys_to_ignore = [\n         \"att_context_size\",\n         \"causal_downsampling\",\n@@ -220,8 +223,11 @@ def write_model(nemo_config, model_files, model_type, output_dir, push_to_repo_i\n         \"stochastic_depth_mode\",\n         \"conv_context_size\",\n         \"dropout_pre_encoder\",\n+        \"reduction\",\n+        \"reduction_factor\",\n+        \"reduction_position\",\n     ]\n-    enocder_config_keys_mapping = {\n+    encoder_config_keys_mapping = {\n         \"d_model\": \"hidden_size\",\n         \"n_heads\": \"num_attention_heads\",\n         \"n_layers\": \"num_hidden_layers\",\n@@ -234,17 +240,26 @@ def write_model(nemo_config, model_files, model_type, output_dir, push_to_repo_i\n         \"dropout_emb\": \"dropout_positions\",\n         \"dropout_att\": \"attention_dropout\",\n         \"xscaling\": \"scale_input\",\n+        \"use_bias\": \"attention_bias\",\n     }\n     converted_encoder_config = {}\n \n     for key, value in nemo_config[\"encoder\"].items():\n         if key in encoder_keys_to_ignore:\n             continue\n-        if key in enocder_config_keys_mapping:\n-            converted_encoder_config[enocder_config_keys_mapping[key]] = value\n+        if key in encoder_config_keys_mapping:\n+            converted_encoder_config[encoder_config_keys_mapping[key]] = value\n+            # NeMo uses 'use_bias' for both attention and convolution bias, but HF separates them\n+            if key == \"use_bias\":\n+                converted_encoder_config[\"convolution_bias\"] = value\n         else:\n-            raise ValueError(f\"Key {key} not found in enocder_config_keys_mapping\")\n+            raise ValueError(f\"Key {key} not found in encoder_config_keys_mapping\")\n+\n+    return ParakeetEncoderConfig(**converted_encoder_config)\n+\n \n+def load_and_convert_state_dict(model_files):\n+    \"\"\"Load NeMo state dict and convert keys to HF format.\"\"\"\n     state_dict = torch.load(model_files[\"model_weights\"], map_location=\"cpu\", weights_only=True)\n     converted_state_dict = {}\n     for key, value in state_dict.items():\n@@ -255,31 +270,80 @@ def write_model(nemo_config, model_files, model_type, output_dir, push_to_repo_i\n         converted_key = convert_key(key, NEMO_TO_HF_WEIGHT_MAPPING)\n         converted_state_dict[converted_key] = value\n \n-    if model_type == \"ctc\":\n-        model_config = ParakeetCTCConfig(\n-            encoder_config=converted_encoder_config,\n-        )\n-        print(\"Loading the checkpoint in a Parakeet CTC model.\")\n-        with torch.device(\"meta\"):\n-            model = ParakeetForCTC(model_config)\n-        model.load_state_dict(converted_state_dict, strict=True, assign=True)\n-        print(\"Checkpoint loaded successfully.\")\n-        del model.config._name_or_path\n+    return converted_state_dict\n+\n+\n+def write_ctc_model(encoder_config, converted_state_dict, output_dir, push_to_repo_id=None):\n+    \"\"\"Write CTC model using encoder config and converted state dict.\"\"\"\n+    model_config = ParakeetCTCConfig.from_encoder_config(encoder_config)\n+\n+    print(\"Loading the checkpoint in a Parakeet CTC model.\")\n+    with torch.device(\"meta\"):\n+        model = ParakeetForCTC(model_config)\n+    model.load_state_dict(converted_state_dict, strict=True, assign=True)\n+    print(\"Checkpoint loaded successfully.\")\n+    del model.config._name_or_path\n+\n+    print(\"Saving the model.\")\n+    model.save_pretrained(output_dir)\n+\n+    if push_to_repo_id:\n+        model.push_to_hub(push_to_repo_id)\n \n-        print(\"Saving the model.\")\n-        model.save_pretrained(output_dir)\n+    del model\n \n-        if push_to_repo_id:\n-            model.push_to_hub(push_to_repo_id)\n+    # Safety check: reload the converted model\n+    gc.collect()\n+    print(\"Reloading the model to check if it's saved correctly.\")\n+    ParakeetForCTC.from_pretrained(output_dir, dtype=torch.bfloat16, device_map=\"auto\")\n+    print(\"Model reloaded successfully.\")\n \n-        del converted_state_dict, model\n \n-        # Safety check: reload the converted model\n-        gc.collect()\n-        print(\"Reloading the model to check if it's saved correctly.\")\n-        ParakeetForCTC.from_pretrained(output_dir, dtype=torch.bfloat16, device_map=\"auto\")\n-        print(\"Model reloaded successfully.\")\n+def write_encoder_model(encoder_config, converted_state_dict, output_dir, push_to_repo_id=None):\n+    \"\"\"Write encoder model using encoder config and converted state dict.\"\"\"\n+    # Filter to only encoder weights (exclude CTC head if present)\n+    encoder_state_dict = {\n+        k.replace(\"encoder.\", \"\", 1) if k.startswith(\"encoder.\") else k: v\n+        for k, v in converted_state_dict.items()\n+        if k.startswith(\"encoder.\")\n+    }\n+\n+    print(\"Loading the checkpoint in a Parakeet Encoder model (for TDT).\")\n+    with torch.device(\"meta\"):\n+        model = ParakeetEncoder(encoder_config)\n+\n+    model.load_state_dict(encoder_state_dict, strict=True, assign=True)\n+    print(\"Checkpoint loaded successfully.\")\n+    del model.config._name_or_path\n+\n+    print(\"Saving the model.\")\n+    model.save_pretrained(output_dir)\n+\n+    if push_to_repo_id:\n+        model.push_to_hub(push_to_repo_id)\n+    del model\n+\n+    # Safety check: reload the converted model\n+    gc.collect()\n+    print(\"Reloading the model to check if it's saved correctly.\")\n+    ParakeetEncoder.from_pretrained(output_dir, dtype=torch.bfloat16, device_map=\"auto\")\n+    print(\"Model reloaded successfully.\")\n+\n \n+def write_model(nemo_config, model_files, model_type, output_dir, push_to_repo_id=None):\n+    \"\"\"Main model conversion function.\"\"\"\n+    # Step 1: Convert encoder config (shared across all model types)\n+    encoder_config = convert_encoder_config(nemo_config)\n+    print(f\"Converted encoder config: {encoder_config}\")\n+\n+    # Step 2: Load and convert state dict (shared across all model types)\n+    converted_state_dict = load_and_convert_state_dict(model_files)\n+\n+    # Step 3: Write model based on type\n+    if model_type == \"encoder\":\n+        write_encoder_model(encoder_config, converted_state_dict, output_dir, push_to_repo_id)\n+    elif model_type == \"ctc\":\n+        write_ctc_model(encoder_config, converted_state_dict, output_dir, push_to_repo_id)\n     else:\n         raise ValueError(f\"Model type {model_type} not supported.\")\n \n@@ -303,7 +367,9 @@ def main(\n if __name__ == \"__main__\":\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"--hf_repo_id\", required=True, help=\"Model repo on huggingface.co\")\n-    parser.add_argument(\"--model_type\", required=True, choices=[\"ctc\"], help=\"Model type (`ctc`, `tdt`)\")\n+    parser.add_argument(\n+        \"--model_type\", required=True, choices=[\"encoder\", \"ctc\"], help=\"Model type (`encoder`, `ctc`)\"\n+    )\n     parser.add_argument(\"--output_dir\", required=True, help=\"Output directory for HuggingFace model\")\n     parser.add_argument(\"--push_to_repo_id\", help=\"Repository ID to push the model to on the Hub\")\n     args = parser.parse_args()"
        },
        {
            "sha": "34697507ffc76d5005dbc1e9d855409008489868",
            "filename": "src/transformers/models/parakeet/modeling_parakeet.py",
            "status": "modified",
            "additions": 13,
            "deletions": 3,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/b9f90dc388fd415a2ba2a6a31a372f451d4a4eed/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodeling_parakeet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b9f90dc388fd415a2ba2a6a31a372f451d4a4eed/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodeling_parakeet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fparakeet%2Fmodeling_parakeet.py?ref=b9f90dc388fd415a2ba2a6a31a372f451d4a4eed",
            "patch": "@@ -130,12 +130,22 @@ def __init__(self, config: ParakeetEncoderConfig, module_config=None):\n             kernel_size = module_config[\"kernel_size\"]\n             self.activation = ACT2FN[module_config.get(\"activation\", \"silu\")]\n         self.padding = (kernel_size - 1) // 2\n-        self.pointwise_conv1 = nn.Conv1d(channels, 2 * channels, kernel_size=1, stride=1, padding=0, bias=True)\n+        self.pointwise_conv1 = nn.Conv1d(\n+            channels, 2 * channels, kernel_size=1, stride=1, padding=0, bias=config.convolution_bias\n+        )\n         self.depthwise_conv = nn.Conv1d(\n-            channels, channels, kernel_size, stride=1, padding=self.padding, groups=channels, bias=True\n+            channels,\n+            channels,\n+            kernel_size,\n+            stride=1,\n+            padding=self.padding,\n+            groups=channels,\n+            bias=config.convolution_bias,\n         )\n         self.norm = nn.BatchNorm1d(channels)\n-        self.pointwise_conv2 = nn.Conv1d(channels, channels, kernel_size=1, stride=1, padding=0, bias=True)\n+        self.pointwise_conv2 = nn.Conv1d(\n+            channels, channels, kernel_size=1, stride=1, padding=0, bias=config.convolution_bias\n+        )\n \n     def forward(self, hidden_states, attention_mask=None):\n         \"\"\""
        }
    ],
    "stats": {
        "total": 158,
        "additions": 126,
        "deletions": 32
    }
}