{
    "author": "shuminghu",
    "message": "Fix PerceptionLM image preprocessing for non-tiled image input. (#40006)\n\n* Fix PerceptionLM image preprocessing for non-tiled image input.\n\n* Add test for single tile vanilla image processing.\n\n* ruff format\n\n* recover missing test skip\n\n* Simplify test.\n\n* minor test name fix",
    "sha": "3ff2e984d2c3703501aafb8ede90fd47e6ff69a7",
    "files": [
        {
            "sha": "7fe3293ea28f9373d0b95d15e1cae6c2c501a44e",
            "filename": "src/transformers/models/perception_lm/image_processing_perception_lm_fast.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/3ff2e984d2c3703501aafb8ede90fd47e6ff69a7/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fimage_processing_perception_lm_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3ff2e984d2c3703501aafb8ede90fd47e6ff69a7/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fimage_processing_perception_lm_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fimage_processing_perception_lm_fast.py?ref=3ff2e984d2c3703501aafb8ede90fd47e6ff69a7",
            "patch": "@@ -310,7 +310,7 @@ def _preprocess(\n             )\n             processed_images_grouped[shape] = stacked_images\n         processed_images = reorder_images(processed_images_grouped, grouped_images_index)\n-\n+        processed_images = [p[None] if p.ndim == 3 else p for p in processed_images]  # add tiles dimension if needed\n         processed_images = torch.stack(processed_images, dim=0) if return_tensors else processed_images\n         return BatchFeature(data={\"pixel_values\": processed_images}, tensor_type=return_tensors)\n "
        },
        {
            "sha": "a0d2c19fbf0e043a761ddb63468ed6f5772f88da",
            "filename": "tests/models/perception_lm/test_processing_perception_lm.py",
            "status": "modified",
            "additions": 30,
            "deletions": 0,
            "changes": 30,
            "blob_url": "https://github.com/huggingface/transformers/blob/3ff2e984d2c3703501aafb8ede90fd47e6ff69a7/tests%2Fmodels%2Fperception_lm%2Ftest_processing_perception_lm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3ff2e984d2c3703501aafb8ede90fd47e6ff69a7/tests%2Fmodels%2Fperception_lm%2Ftest_processing_perception_lm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fperception_lm%2Ftest_processing_perception_lm.py?ref=3ff2e984d2c3703501aafb8ede90fd47e6ff69a7",
            "patch": "@@ -115,6 +115,36 @@ def test_image_token_filling(self):\n         )\n         image_tokens = (inputs[\"input_ids\"] == image_token_index).sum().item()\n         self.assertEqual(expected_image_tokens, image_tokens)\n+        self.assertEqual(inputs[\"pixel_values\"].ndim, 5)\n+\n+    def test_vanilla_image_with_no_tiles_token_filling(self):\n+        processor = self.processor_class.from_pretrained(self.tmpdirname)\n+        processor.image_processor.vision_input_type = \"vanilla\"\n+        # Important to check with non square image\n+        image = torch.randn((1, 3, 450, 500))\n+        #  1 tile\n+        #  448/patch_size/pooling_ratio = 16 => 16*16 tokens per tile\n+        expected_image_tokens = 16 * 16 * 1\n+        image_token_index = processor.image_token_id\n+\n+        messages = [\n+            {\n+                \"role\": \"user\",\n+                \"content\": [\n+                    {\"type\": \"image\"},\n+                    {\"type\": \"text\", \"text\": \"What is shown in this image?\"},\n+                ],\n+            },\n+        ]\n+        inputs = processor(\n+            text=[processor.apply_chat_template(messages)],\n+            images=[image],\n+            return_tensors=\"pt\",\n+        )\n+        image_tokens = (inputs[\"input_ids\"] == image_token_index).sum().item()\n+        self.assertEqual(expected_image_tokens, image_tokens)\n+        self.assertEqual(inputs[\"pixel_values\"].ndim, 5)\n+        self.assertEqual(inputs[\"pixel_values\"].shape[1], 1)  # 1 tile\n \n \n CHAT_TEMPLATE = ("
        }
    ],
    "stats": {
        "total": 32,
        "additions": 31,
        "deletions": 1
    }
}