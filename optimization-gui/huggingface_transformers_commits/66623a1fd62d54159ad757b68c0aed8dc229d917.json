{
    "author": "jiqing-feng",
    "message": "Fix speccht5_tts pipeline (#42830)\n\n* Fix speccht5_tts pipeline\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\n\n* Update src/transformers/pipelines/text_to_audio.py\n\nCo-authored-by: Anton Vlasjuk <73884904+vasqu@users.noreply.github.com>\n\n---------\n\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\nCo-authored-by: Anton Vlasjuk <73884904+vasqu@users.noreply.github.com>",
    "sha": "66623a1fd62d54159ad757b68c0aed8dc229d917",
    "files": [
        {
            "sha": "b656e16d198f300d193035f7071971a7df5d5f2d",
            "filename": "src/transformers/pipelines/text_to_audio.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/66623a1fd62d54159ad757b68c0aed8dc229d917/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/66623a1fd62d54159ad757b68c0aed8dc229d917/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py?ref=66623a1fd62d54159ad757b68c0aed8dc229d917",
            "patch": "@@ -117,8 +117,8 @@ def __init__(self, *args, vocoder=None, sampling_rate=None, **kwargs):\n                 else vocoder\n             )\n \n-        if self.model.config.model_type in [\"musicgen\"]:\n-            # MusicGen expect to use the tokenizer\n+        if self.model.config.model_type in [\"musicgen\", \"speecht5\"]:\n+            # MusicGen and SpeechT5 expect to use their tokenizer instead\n             self.processor = None\n \n         self.sampling_rate = sampling_rate"
        },
        {
            "sha": "25a125ba84f8ddb26deb7fc4e4f9dd9fc4113d6a",
            "filename": "tests/pipelines/test_pipelines_text_to_audio.py",
            "status": "modified",
            "additions": 33,
            "deletions": 0,
            "changes": 33,
            "blob_url": "https://github.com/huggingface/transformers/blob/66623a1fd62d54159ad757b68c0aed8dc229d917/tests%2Fpipelines%2Ftest_pipelines_text_to_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/66623a1fd62d54159ad757b68c0aed8dc229d917/tests%2Fpipelines%2Ftest_pipelines_text_to_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_text_to_audio.py?ref=66623a1fd62d54159ad757b68c0aed8dc229d917",
            "patch": "@@ -15,6 +15,7 @@\n import unittest\n \n import numpy as np\n+import torch\n \n from transformers import (\n     MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING,\n@@ -40,6 +41,38 @@ class TextToAudioPipelineTests(unittest.TestCase):\n     model_mapping = MODEL_FOR_TEXT_TO_WAVEFORM_MAPPING\n     # for now only test text_to_waveform and not text_to_spectrogram\n \n+    @require_torch\n+    def test_small_speecht5_pt(self):\n+        audio_generator = pipeline(task=\"text-to-audio\", model=\"microsoft/speecht5_tts\")\n+        num_channels = 1  # model generates mono audio\n+        forward_params = {\n+            \"do_sample\": True,\n+            \"semantic_max_new_tokens\": 5,\n+            \"speaker_embeddings\": torch.rand(1, 512) * 0.2 - 0.1,\n+        }\n+\n+        outputs = audio_generator(\"This is a test\", forward_params=forward_params)\n+        self.assertEqual({\"audio\": ANY(np.ndarray), \"sampling_rate\": 16000}, outputs)\n+        self.assertEqual(len(outputs[\"audio\"].shape), num_channels)\n+\n+        # test two examples side-by-side\n+        outputs = audio_generator([\"This is a test\", \"This is a second test\"], forward_params=forward_params)\n+        audio = [output[\"audio\"] for output in outputs]\n+        self.assertEqual([ANY(np.ndarray), ANY(np.ndarray)], audio)\n+\n+        # test batching, this time with parameterization in the forward pass\n+        audio_generator = pipeline(task=\"text-to-audio\", model=\"microsoft/speecht5_tts\")\n+        forward_params = {\n+            \"do_sample\": False,\n+            \"max_new_tokens\": 5,\n+            \"speaker_embeddings\": torch.rand(1, 512) * 0.2 - 0.1,\n+        }\n+        outputs = audio_generator(\n+            [\"This is a test\", \"This is a second test\"], forward_params=forward_params, batch_size=2\n+        )\n+        audio = [output[\"audio\"] for output in outputs]\n+        self.assertEqual([ANY(np.ndarray), ANY(np.ndarray)], audio)\n+\n     @require_torch\n     def test_small_musicgen_pt(self):\n         music_generator = pipeline("
        }
    ],
    "stats": {
        "total": 37,
        "additions": 35,
        "deletions": 2
    }
}