{
    "author": "qubvel",
    "message": "Fix custom kernel for DeformableDetr, RT-Detr, GroindingDINO, OmDet-Turbo in Pytorch 2.6.0 (#35979)\n\nUpdates type().is_cuda() -> .is_cuda(); .data<> -> .data_ptr<>",
    "sha": "9c02cb6233eddedd8ecf0d48957cb481103f93f3",
    "files": [
        {
            "sha": "c2b3a462a1a06338d4a04c33a6867fcad42248e6",
            "filename": "src/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu",
            "status": "modified",
            "additions": 28,
            "deletions": 28,
            "changes": 56,
            "blob_url": "https://github.com/huggingface/transformers/blob/9c02cb6233eddedd8ecf0d48957cb481103f93f3/src%2Ftransformers%2Fkernels%2Fdeformable_detr%2Fcuda%2Fms_deform_attn_cuda.cu",
            "raw_url": "https://github.com/huggingface/transformers/raw/9c02cb6233eddedd8ecf0d48957cb481103f93f3/src%2Ftransformers%2Fkernels%2Fdeformable_detr%2Fcuda%2Fms_deform_attn_cuda.cu",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fkernels%2Fdeformable_detr%2Fcuda%2Fms_deform_attn_cuda.cu?ref=9c02cb6233eddedd8ecf0d48957cb481103f93f3",
            "patch": "@@ -36,11 +36,11 @@ at::Tensor ms_deform_attn_cuda_forward(\n     AT_ASSERTM(sampling_loc.is_contiguous(), \"sampling_loc tensor has to be contiguous\");\n     AT_ASSERTM(attn_weight.is_contiguous(), \"attn_weight tensor has to be contiguous\");\n \n-    AT_ASSERTM(value.type().is_cuda(), \"value must be a CUDA tensor\");\n-    AT_ASSERTM(spatial_shapes.type().is_cuda(), \"spatial_shapes must be a CUDA tensor\");\n-    AT_ASSERTM(level_start_index.type().is_cuda(), \"level_start_index must be a CUDA tensor\");\n-    AT_ASSERTM(sampling_loc.type().is_cuda(), \"sampling_loc must be a CUDA tensor\");\n-    AT_ASSERTM(attn_weight.type().is_cuda(), \"attn_weight must be a CUDA tensor\");\n+    AT_ASSERTM(value.is_cuda(), \"value must be a CUDA tensor\");\n+    AT_ASSERTM(spatial_shapes.is_cuda(), \"spatial_shapes must be a CUDA tensor\");\n+    AT_ASSERTM(level_start_index.is_cuda(), \"level_start_index must be a CUDA tensor\");\n+    AT_ASSERTM(sampling_loc.is_cuda(), \"sampling_loc must be a CUDA tensor\");\n+    AT_ASSERTM(attn_weight.is_cuda(), \"attn_weight must be a CUDA tensor\");\n \n     const int batch = value.size(0);\n     const int spatial_size = value.size(1);\n@@ -66,15 +66,15 @@ at::Tensor ms_deform_attn_cuda_forward(\n     for (int n = 0; n < batch/im2col_step_; ++n)\n     {\n         auto columns = output_n.select(0, n);\n-        AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n+        AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, value.scalar_type(), \"ms_deform_attn_forward_cuda\", ([&] {\n             ms_deformable_im2col_cuda(at::cuda::getCurrentCUDAStream(),\n-                value.data<scalar_t>() + n * im2col_step_ * per_value_size,\n-                spatial_shapes.data<int64_t>(),\n-                level_start_index.data<int64_t>(),\n-                sampling_loc.data<scalar_t>() + n * im2col_step_ * per_sample_loc_size,\n-                attn_weight.data<scalar_t>() + n * im2col_step_ * per_attn_weight_size,\n+                value.data_ptr<scalar_t>() + n * im2col_step_ * per_value_size,\n+                spatial_shapes.data_ptr<int64_t>(),\n+                level_start_index.data_ptr<int64_t>(),\n+                sampling_loc.data_ptr<scalar_t>() + n * im2col_step_ * per_sample_loc_size,\n+                attn_weight.data_ptr<scalar_t>() + n * im2col_step_ * per_attn_weight_size,\n                 batch_n, spatial_size, num_heads, channels, num_levels, num_query, num_point,\n-                columns.data<scalar_t>());\n+                columns.data_ptr<scalar_t>());\n \n         }));\n     }\n@@ -103,12 +103,12 @@ std::vector<at::Tensor> ms_deform_attn_cuda_backward(\n     AT_ASSERTM(attn_weight.is_contiguous(), \"attn_weight tensor has to be contiguous\");\n     AT_ASSERTM(grad_output.is_contiguous(), \"grad_output tensor has to be contiguous\");\n \n-    AT_ASSERTM(value.type().is_cuda(), \"value must be a CUDA tensor\");\n-    AT_ASSERTM(spatial_shapes.type().is_cuda(), \"spatial_shapes must be a CUDA tensor\");\n-    AT_ASSERTM(level_start_index.type().is_cuda(), \"level_start_index must be a CUDA tensor\");\n-    AT_ASSERTM(sampling_loc.type().is_cuda(), \"sampling_loc must be a CUDA tensor\");\n-    AT_ASSERTM(attn_weight.type().is_cuda(), \"attn_weight must be a CUDA tensor\");\n-    AT_ASSERTM(grad_output.type().is_cuda(), \"grad_output must be a CUDA tensor\");\n+    AT_ASSERTM(value.is_cuda(), \"value must be a CUDA tensor\");\n+    AT_ASSERTM(spatial_shapes.is_cuda(), \"spatial_shapes must be a CUDA tensor\");\n+    AT_ASSERTM(level_start_index.is_cuda(), \"level_start_index must be a CUDA tensor\");\n+    AT_ASSERTM(sampling_loc.is_cuda(), \"sampling_loc must be a CUDA tensor\");\n+    AT_ASSERTM(attn_weight.is_cuda(), \"attn_weight must be a CUDA tensor\");\n+    AT_ASSERTM(grad_output.is_cuda(), \"grad_output must be a CUDA tensor\");\n \n     const int batch = value.size(0);\n     const int spatial_size = value.size(1);\n@@ -137,18 +137,18 @@ std::vector<at::Tensor> ms_deform_attn_cuda_backward(\n     for (int n = 0; n < batch/im2col_step_; ++n)\n     {\n         auto grad_output_g = grad_output_n.select(0, n);\n-        AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n+        AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, value.scalar_type(), \"ms_deform_attn_backward_cuda\", ([&] {\n             ms_deformable_col2im_cuda(at::cuda::getCurrentCUDAStream(),\n-                                    grad_output_g.data<scalar_t>(),\n-                                    value.data<scalar_t>() + n * im2col_step_ * per_value_size,\n-                                    spatial_shapes.data<int64_t>(),\n-                                    level_start_index.data<int64_t>(),\n-                                    sampling_loc.data<scalar_t>() + n * im2col_step_ * per_sample_loc_size,\n-                                    attn_weight.data<scalar_t>() + n * im2col_step_ * per_attn_weight_size,\n+                                    grad_output_g.data_ptr<scalar_t>(),\n+                                    value.data_ptr<scalar_t>() + n * im2col_step_ * per_value_size,\n+                                    spatial_shapes.data_ptr<int64_t>(),\n+                                    level_start_index.data_ptr<int64_t>(),\n+                                    sampling_loc.data_ptr<scalar_t>() + n * im2col_step_ * per_sample_loc_size,\n+                                    attn_weight.data_ptr<scalar_t>() + n * im2col_step_ * per_attn_weight_size,\n                                     batch_n, spatial_size, num_heads, channels, num_levels, num_query, num_point,\n-                                    grad_value.data<scalar_t>() +  n * im2col_step_ * per_value_size,\n-                                    grad_sampling_loc.data<scalar_t>() + n * im2col_step_ * per_sample_loc_size,\n-                                    grad_attn_weight.data<scalar_t>() + n * im2col_step_ * per_attn_weight_size);\n+                                    grad_value.data_ptr<scalar_t>() +  n * im2col_step_ * per_value_size,\n+                                    grad_sampling_loc.data_ptr<scalar_t>() + n * im2col_step_ * per_sample_loc_size,\n+                                    grad_attn_weight.data_ptr<scalar_t>() + n * im2col_step_ * per_attn_weight_size);\n \n         }));\n     }"
        },
        {
            "sha": "20ae6892e4b9881578a72aae27ddc4ec9f68ae1c",
            "filename": "src/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cuh",
            "status": "modified",
            "additions": 35,
            "deletions": 35,
            "changes": 70,
            "blob_url": "https://github.com/huggingface/transformers/blob/9c02cb6233eddedd8ecf0d48957cb481103f93f3/src%2Ftransformers%2Fkernels%2Fdeformable_detr%2Fcuda%2Fms_deform_attn_cuda.cuh",
            "raw_url": "https://github.com/huggingface/transformers/raw/9c02cb6233eddedd8ecf0d48957cb481103f93f3/src%2Ftransformers%2Fkernels%2Fdeformable_detr%2Fcuda%2Fms_deform_attn_cuda.cuh",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fkernels%2Fdeformable_detr%2Fcuda%2Fms_deform_attn_cuda.cuh?ref=9c02cb6233eddedd8ecf0d48957cb481103f93f3",
            "patch": "@@ -42,11 +42,11 @@ at::Tensor ms_deform_attn_cuda_forward(\n     AT_ASSERTM(sampling_loc.is_contiguous(), \"sampling_loc tensor has to be contiguous\");\n     AT_ASSERTM(attn_weight.is_contiguous(), \"attn_weight tensor has to be contiguous\");\n \n-    AT_ASSERTM(value.type().is_cuda(), \"value must be a CUDA tensor\");\n-    AT_ASSERTM(spatial_shapes.type().is_cuda(), \"spatial_shapes must be a CUDA tensor\");\n-    AT_ASSERTM(level_start_index.type().is_cuda(), \"level_start_index must be a CUDA tensor\");\n-    AT_ASSERTM(sampling_loc.type().is_cuda(), \"sampling_loc must be a CUDA tensor\");\n-    AT_ASSERTM(attn_weight.type().is_cuda(), \"attn_weight must be a CUDA tensor\");\n+    AT_ASSERTM(value.is_cuda(), \"value must be a CUDA tensor\");\n+    AT_ASSERTM(spatial_shapes.is_cuda(), \"spatial_shapes must be a CUDA tensor\");\n+    AT_ASSERTM(level_start_index.is_cuda(), \"level_start_index must be a CUDA tensor\");\n+    AT_ASSERTM(sampling_loc.is_cuda(), \"sampling_loc must be a CUDA tensor\");\n+    AT_ASSERTM(attn_weight.is_cuda(), \"attn_weight must be a CUDA tensor\");\n \n     const int batch = value.size(0);\n     const int spatial_size = value.size(1);\n@@ -72,15 +72,15 @@ at::Tensor ms_deform_attn_cuda_forward(\n     for (int n = 0; n < batch/im2col_step_; ++n)\n     {\n         auto columns = output_n.select(0, n);\n-        AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n+        AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, value.scalar_type(), \"ms_deform_attn_forward_cuda\", ([&] {\n             ms_deformable_im2col_cuda(at::cuda::getCurrentCUDAStream(),\n-                value.data<scalar_t>() + n * im2col_step_ * per_value_size,\n-                spatial_shapes.data<int64_t>(),\n-                level_start_index.data<int64_t>(),\n-                sampling_loc.data<scalar_t>() + n * im2col_step_ * per_sample_loc_size,\n-                attn_weight.data<scalar_t>() + n * im2col_step_ * per_attn_weight_size,\n+                value.data_ptr<scalar_t>() + n * im2col_step_ * per_value_size,\n+                spatial_shapes.data_ptr<int64_t>(),\n+                level_start_index.data_ptr<int64_t>(),\n+                sampling_loc.data_ptr<scalar_t>() + n * im2col_step_ * per_sample_loc_size,\n+                attn_weight.data_ptr<scalar_t>() + n * im2col_step_ * per_attn_weight_size,\n                 batch_n, spatial_size, num_heads, channels, num_levels, num_query, num_point,\n-                columns.data<scalar_t>());\n+                columns.data_ptr<scalar_t>());\n \n         }));\n     }\n@@ -108,12 +108,12 @@ std::vector<at::Tensor> ms_deform_attn_cuda_backward(\n     AT_ASSERTM(attn_weight.is_contiguous(), \"attn_weight tensor has to be contiguous\");\n     AT_ASSERTM(grad_output.is_contiguous(), \"grad_output tensor has to be contiguous\");\n \n-    AT_ASSERTM(value.type().is_cuda(), \"value must be a CUDA tensor\");\n-    AT_ASSERTM(spatial_shapes.type().is_cuda(), \"spatial_shapes must be a CUDA tensor\");\n-    AT_ASSERTM(level_start_index.type().is_cuda(), \"level_start_index must be a CUDA tensor\");\n-    AT_ASSERTM(sampling_loc.type().is_cuda(), \"sampling_loc must be a CUDA tensor\");\n-    AT_ASSERTM(attn_weight.type().is_cuda(), \"attn_weight must be a CUDA tensor\");\n-    AT_ASSERTM(grad_output.type().is_cuda(), \"grad_output must be a CUDA tensor\");\n+    AT_ASSERTM(value.is_cuda(), \"value must be a CUDA tensor\");\n+    AT_ASSERTM(spatial_shapes.is_cuda(), \"spatial_shapes must be a CUDA tensor\");\n+    AT_ASSERTM(level_start_index.is_cuda(), \"level_start_index must be a CUDA tensor\");\n+    AT_ASSERTM(sampling_loc.is_cuda(), \"sampling_loc must be a CUDA tensor\");\n+    AT_ASSERTM(attn_weight.is_cuda(), \"attn_weight must be a CUDA tensor\");\n+    AT_ASSERTM(grad_output.is_cuda(), \"grad_output must be a CUDA tensor\");\n \n     const int batch = value.size(0);\n     const int spatial_size = value.size(1);\n@@ -142,18 +142,18 @@ std::vector<at::Tensor> ms_deform_attn_cuda_backward(\n     for (int n = 0; n < batch/im2col_step_; ++n)\n     {\n         auto grad_output_g = grad_output_n.select(0, n);\n-        AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n+        AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, value.scalar_type(), \"ms_deform_attn_backward_cuda\", ([&] {\n             ms_deformable_col2im_cuda(at::cuda::getCurrentCUDAStream(),\n-                                    grad_output_g.data<scalar_t>(),\n-                                    value.data<scalar_t>() + n * im2col_step_ * per_value_size,\n-                                    spatial_shapes.data<int64_t>(),\n-                                    level_start_index.data<int64_t>(),\n-                                    sampling_loc.data<scalar_t>() + n * im2col_step_ * per_sample_loc_size,\n-                                    attn_weight.data<scalar_t>() + n * im2col_step_ * per_attn_weight_size,\n+                                    grad_output_g.data_ptr<scalar_t>(),\n+                                    value.data_ptr<scalar_t>() + n * im2col_step_ * per_value_size,\n+                                    spatial_shapes.data_ptr<int64_t>(),\n+                                    level_start_index.data_ptr<int64_t>(),\n+                                    sampling_loc.data_ptr<scalar_t>() + n * im2col_step_ * per_sample_loc_size,\n+                                    attn_weight.data_ptr<scalar_t>() + n * im2col_step_ * per_attn_weight_size,\n                                     batch_n, spatial_size, num_heads, channels, num_levels, num_query, num_point,\n-                                    grad_value.data<scalar_t>() +  n * im2col_step_ * per_value_size,\n-                                    grad_sampling_loc.data<scalar_t>() + n * im2col_step_ * per_sample_loc_size,\n-                                    grad_attn_weight.data<scalar_t>() + n * im2col_step_ * per_attn_weight_size);\n+                                    grad_value.data_ptr<scalar_t>() +  n * im2col_step_ * per_value_size,\n+                                    grad_sampling_loc.data_ptr<scalar_t>() + n * im2col_step_ * per_sample_loc_size,\n+                                    grad_attn_weight.data_ptr<scalar_t>() + n * im2col_step_ * per_attn_weight_size);\n \n         }));\n     }\n@@ -398,7 +398,7 @@ __global__ void ms_deformable_im2col_gpu_kernel(const int n,\n     const int sampling_index = _temp; \n     const int m_col = _temp % num_heads;\n     _temp /= num_heads;\n-    const int q_col = _temp % num_query;\n+    [[maybe_unused]] const int q_col = _temp % num_query;\n     _temp /= num_query;\n     const int b_col = _temp;\n \n@@ -468,7 +468,7 @@ __global__ void ms_deformable_col2im_gpu_kernel_shm_blocksize_aware_reduce_v1(co\n     const int sampling_index = _temp; \n     const int m_col = _temp % num_heads;\n     _temp /= num_heads;\n-    const int q_col = _temp % num_query;\n+    [[maybe_unused]] const int q_col = _temp % num_query;\n     _temp /= num_query;\n     const int b_col = _temp;\n \n@@ -573,7 +573,7 @@ __global__ void ms_deformable_col2im_gpu_kernel_shm_blocksize_aware_reduce_v2(co\n     const int sampling_index = _temp; \n     const int m_col = _temp % num_heads;\n     _temp /= num_heads;\n-    const int q_col = _temp % num_query;\n+    [[maybe_unused]] const int q_col = _temp % num_query;\n     _temp /= num_query;\n     const int b_col = _temp;\n \n@@ -681,7 +681,7 @@ __global__ void ms_deformable_col2im_gpu_kernel_shm_reduce_v1(const int n,\n     const int sampling_index = _temp; \n     const int m_col = _temp % num_heads;\n     _temp /= num_heads;\n-    const int q_col = _temp % num_query;\n+    [[maybe_unused]] const int q_col = _temp % num_query;\n     _temp /= num_query;\n     const int b_col = _temp;\n \n@@ -786,7 +786,7 @@ __global__ void ms_deformable_col2im_gpu_kernel_shm_reduce_v2(const int n,\n     const int sampling_index = _temp; \n     const int m_col = _temp % num_heads;\n     _temp /= num_heads;\n-    const int q_col = _temp % num_query;\n+    [[maybe_unused]] const int q_col = _temp % num_query;\n     _temp /= num_query;\n     const int b_col = _temp;\n \n@@ -899,7 +899,7 @@ __global__ void ms_deformable_col2im_gpu_kernel_shm_reduce_v2_multi_blocks(const\n     const int sampling_index = _temp; \n     const int m_col = _temp % num_heads;\n     _temp /= num_heads;\n-    const int q_col = _temp % num_query;\n+    [[maybe_unused]] const int q_col = _temp % num_query;\n     _temp /= num_query;\n     const int b_col = _temp;\n \n@@ -1009,7 +1009,7 @@ __global__ void ms_deformable_col2im_gpu_kernel_gm(const int n,\n     const int sampling_index = _temp; \n     const int m_col = _temp % num_heads;\n     _temp /= num_heads;\n-    const int q_col = _temp % num_query;\n+    [[maybe_unused]] const int q_col = _temp % num_query;\n     _temp /= num_query;\n     const int b_col = _temp;\n "
        },
        {
            "sha": "4fb544bf791ddae79238924df591b7a33f3cccdd",
            "filename": "src/transformers/kernels/deformable_detr/cuda/ms_deform_im2col_cuda.cuh",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/9c02cb6233eddedd8ecf0d48957cb481103f93f3/src%2Ftransformers%2Fkernels%2Fdeformable_detr%2Fcuda%2Fms_deform_im2col_cuda.cuh",
            "raw_url": "https://github.com/huggingface/transformers/raw/9c02cb6233eddedd8ecf0d48957cb481103f93f3/src%2Ftransformers%2Fkernels%2Fdeformable_detr%2Fcuda%2Fms_deform_im2col_cuda.cuh",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fkernels%2Fdeformable_detr%2Fcuda%2Fms_deform_im2col_cuda.cuh?ref=9c02cb6233eddedd8ecf0d48957cb481103f93f3",
            "patch": "@@ -258,7 +258,7 @@ __global__ void ms_deformable_im2col_gpu_kernel(const int n,\n     const int sampling_index = _temp; \n     const int m_col = _temp % num_heads;\n     _temp /= num_heads;\n-    const int q_col = _temp % num_query;\n+    [[maybe_unused]] const int q_col = _temp % num_query;\n     _temp /= num_query;\n     const int b_col = _temp;\n \n@@ -328,7 +328,7 @@ __global__ void ms_deformable_col2im_gpu_kernel_shm_blocksize_aware_reduce_v1(co\n     const int sampling_index = _temp; \n     const int m_col = _temp % num_heads;\n     _temp /= num_heads;\n-    const int q_col = _temp % num_query;\n+    [[maybe_unused]] const int q_col = _temp % num_query;\n     _temp /= num_query;\n     const int b_col = _temp;\n \n@@ -433,7 +433,7 @@ __global__ void ms_deformable_col2im_gpu_kernel_shm_blocksize_aware_reduce_v2(co\n     const int sampling_index = _temp; \n     const int m_col = _temp % num_heads;\n     _temp /= num_heads;\n-    const int q_col = _temp % num_query;\n+    [[maybe_unused]] const int q_col = _temp % num_query;\n     _temp /= num_query;\n     const int b_col = _temp;\n \n@@ -541,7 +541,7 @@ __global__ void ms_deformable_col2im_gpu_kernel_shm_reduce_v1(const int n,\n     const int sampling_index = _temp; \n     const int m_col = _temp % num_heads;\n     _temp /= num_heads;\n-    const int q_col = _temp % num_query;\n+    [[maybe_unused]] const int q_col = _temp % num_query;\n     _temp /= num_query;\n     const int b_col = _temp;\n \n@@ -646,7 +646,7 @@ __global__ void ms_deformable_col2im_gpu_kernel_shm_reduce_v2(const int n,\n     const int sampling_index = _temp; \n     const int m_col = _temp % num_heads;\n     _temp /= num_heads;\n-    const int q_col = _temp % num_query;\n+    [[maybe_unused]] const int q_col = _temp % num_query;\n     _temp /= num_query;\n     const int b_col = _temp;\n \n@@ -759,7 +759,7 @@ __global__ void ms_deformable_col2im_gpu_kernel_shm_reduce_v2_multi_blocks(const\n     const int sampling_index = _temp; \n     const int m_col = _temp % num_heads;\n     _temp /= num_heads;\n-    const int q_col = _temp % num_query;\n+    [[maybe_unused]] const int q_col = _temp % num_query;\n     _temp /= num_query;\n     const int b_col = _temp;\n \n@@ -869,7 +869,7 @@ __global__ void ms_deformable_col2im_gpu_kernel_gm(const int n,\n     const int sampling_index = _temp; \n     const int m_col = _temp % num_heads;\n     _temp /= num_heads;\n-    const int q_col = _temp % num_query;\n+    [[maybe_unused]] const int q_col = _temp % num_query;\n     _temp /= num_query;\n     const int b_col = _temp;\n "
        },
        {
            "sha": "e649e65e37ae58d789a4cfb396e715ff2e33477f",
            "filename": "src/transformers/kernels/deformable_detr/ms_deform_attn.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9c02cb6233eddedd8ecf0d48957cb481103f93f3/src%2Ftransformers%2Fkernels%2Fdeformable_detr%2Fms_deform_attn.h",
            "raw_url": "https://github.com/huggingface/transformers/raw/9c02cb6233eddedd8ecf0d48957cb481103f93f3/src%2Ftransformers%2Fkernels%2Fdeformable_detr%2Fms_deform_attn.h",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fkernels%2Fdeformable_detr%2Fms_deform_attn.h?ref=9c02cb6233eddedd8ecf0d48957cb481103f93f3",
            "patch": "@@ -26,7 +26,7 @@ ms_deform_attn_forward(\n     const at::Tensor &attn_weight,\n     const int im2col_step)\n {\n-    if (value.type().is_cuda())\n+    if (value.is_cuda())\n     {\n #ifdef WITH_CUDA\n         return ms_deform_attn_cuda_forward(\n@@ -48,7 +48,7 @@ ms_deform_attn_backward(\n     const at::Tensor &grad_output,\n     const int im2col_step)\n {\n-    if (value.type().is_cuda())\n+    if (value.is_cuda())\n     {\n #ifdef WITH_CUDA\n         return ms_deform_attn_cuda_backward("
        }
    ],
    "stats": {
        "total": 144,
        "additions": 72,
        "deletions": 72
    }
}