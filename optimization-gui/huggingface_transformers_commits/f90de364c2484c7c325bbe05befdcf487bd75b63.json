{
    "author": "LysandreJik",
    "message": "Rename huggingface_cli to hf (#39630)\n\n* Rename huggingface_cli to hf\n\n* hfh",
    "sha": "f90de364c2484c7c325bbe05befdcf487bd75b63",
    "files": [
        {
            "sha": "d46df9cb7298bde1e6f31bd68c75c997e1a0b638",
            "filename": "docs/source/ar/custom_models.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Far%2Fcustom_models.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Far%2Fcustom_models.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fcustom_models.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -280,7 +280,7 @@ resnet50d.model.load_state_dict(pretrained_model.state_dict())\n Ø§Ù„Ø¢Ù† Ù„Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ HubØŒ ØªØ£ÙƒØ¯ Ù…Ù† ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„. Ø¥Ù…Ø§ ØªØ´ØºÙŠÙ„ ÙÙŠ Ø§Ù„Ù…Ø­Ø·Ø© Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø·Ø±ÙÙŠØ© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ:\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n Ø£Ùˆ Ù…Ù† Ø¯ÙØªØ± Ù…Ù„Ø§Ø­Ø¸Ø§Øª:"
        },
        {
            "sha": "b4b1bb821b9bce1beb3b1fb4d507567106ad5a1f",
            "filename": "docs/source/ar/model_sharing.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Far%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Far%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fmodel_sharing.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -41,7 +41,7 @@ picture-in-picture\" allowfullscreen></iframe>\n Ù‚Ø¨Ù„ Ù…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ HubØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø¹ØªÙ…Ø§Ø¯ Ø­Ø³Ø§Ø¨ Hugging Face Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ.  Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… Ù…Ù†ØµØ© Ø§Ù„Ø£ÙˆØ§Ù…Ø±ØŒ ÙÙ‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø­ÙŠØ« ØªÙ… ØªØ«Ø¨ÙŠØª ğŸ¤— Transformers. Ø³ÙŠÙ‚ÙˆÙ… Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø± Ø¨ØªØ®Ø²ÙŠÙ† Ø±Ù…Ø² Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ ÙÙŠ Ù…Ø¬Ù„Ø¯ ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù€ Hugging Face (`~/.cache/` Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠ):\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… Ø¯ÙØªØ± Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ø«Ù„ Jupyter Ø£Ùˆ ColaboratoryØŒ ÙØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© [`huggingface_hub`](https://huggingface.co/docs/hub/adding-a-library). ØªØ³Ù…Ø­ Ù„Ùƒ Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø¨Ø§Ù„ØªÙØ§Ø¹Ù„ Ø¨Ø±Ù…Ø¬ÙŠÙ‹Ø§ Ù…Ø¹ Hub."
        },
        {
            "sha": "f7673408ca7d012d864a4134b7d5e49ca183174d",
            "filename": "docs/source/ar/run_scripts.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Far%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Far%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Frun_scripts.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -324,7 +324,7 @@ python examples/pytorch/summarization/run_summarization.py\n ÙŠÙ…ÙƒÙ† Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø±ÙØ¹ Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¥Ù„Ù‰ [Ù…Ø±ÙƒØ² Ø§Ù„Ù†Ù…Ø§Ø°Ø¬](https://huggingface.co/models). ØªØ£ÙƒØ¯ Ù…Ù† ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ Hugging Face Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡:\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n Ø«Ù… Ø£Ø¶Ù Ø§Ù„Ù…Ø¹Ù„Ù…Ø© `push_to_hub` Ø¥Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ . Ø³ØªÙ‚ÙˆÙ… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„Ù…Ø© Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªÙˆØ¯Ø¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³Ù… Ù…Ø³ØªØ®Ø¯Ù… Hugging Face ÙˆØ§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯ ÙÙŠ `output_dir`."
        },
        {
            "sha": "3b6e55eb4bf9a804717afd45274fe31f4d75740b",
            "filename": "docs/source/de/model_sharing.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fde%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fde%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fde%2Fmodel_sharing.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -56,7 +56,7 @@ Dateien lassen sich auch in einem Repository leicht bearbeiten, und Sie kÃ¶nnen\n Bevor Sie ein Modell fÃ¼r den Hub freigeben, benÃ¶tigen Sie Ihre Hugging Face-Anmeldedaten. Wenn Sie Zugang zu einem Terminal haben, fÃ¼hren Sie den folgenden Befehl in der virtuellen Umgebung aus, in der ğŸ¤— Transformers installiert ist. Dadurch werden Ihre Zugangsdaten in Ihrem Hugging Face-Cache-Ordner (standardmÃ¤ÃŸig `~/.cache/`) gespeichert:\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n Wenn Sie ein Notebook wie Jupyter oder Colaboratory verwenden, stellen Sie sicher, dass Sie die [`huggingface_hub`](https://huggingface.co/docs/hub/adding-a-library) Bibliothek installiert haben. Diese Bibliothek ermÃ¶glicht Ihnen die programmatische Interaktion mit dem Hub."
        },
        {
            "sha": "069a0c3fd3de4537cd1967343c4075ae22ded803",
            "filename": "docs/source/de/run_scripts.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fde%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fde%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fde%2Frun_scripts.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -324,7 +324,7 @@ python examples/pytorch/summarization/run_summarization.py\n Alle Skripte kÃ¶nnen Ihr endgÃ¼ltiges Modell in den [Model Hub](https://huggingface.co/models) hochladen. Stellen Sie sicher, dass Sie bei Hugging Face angemeldet sind, bevor Sie beginnen:\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n Dann fÃ¼gen Sie dem Skript das Argument `push_to_hub` hinzu. Mit diesem Argument wird ein Repository mit Ihrem Hugging Face-Benutzernamen und dem in `output_dir` angegebenen Ordnernamen erstellt."
        },
        {
            "sha": "68afc91531fb34be290404a620a648a9765e96b4",
            "filename": "docs/source/en/custom_models.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fen%2Fcustom_models.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fen%2Fcustom_models.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fcustom_models.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -271,7 +271,7 @@ The model is ready to be pushed to the Hub now. Log in to your Hugging Face acco\n <hfoption id=\"huggingface-CLI\">\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n </hfoption>"
        },
        {
            "sha": "1a31072dbd089ab702ea79cf2a38ec1ea74ad388",
            "filename": "docs/source/en/model_sharing.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fen%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fen%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_sharing.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -28,7 +28,7 @@ To share a model to the Hub, you need a Hugging Face [account](https://hf.co/joi\n <hfoption id=\"huggingface-CLI\">\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n </hfoption>"
        },
        {
            "sha": "67ef9922b0e9fa3baab16f5c2d29c91c797420bf",
            "filename": "docs/source/en/quicktour.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fen%2Fquicktour.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fen%2Fquicktour.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fquicktour.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -49,7 +49,7 @@ notebook_login()\n Make sure the [huggingface_hub[cli]](https://huggingface.co/docs/huggingface_hub/guides/cli#getting-started) package is installed and run the command below. Paste your User Access Token when prompted to log in.\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n </hfoption>"
        },
        {
            "sha": "13aa4804bc1a272bfeb1910f18d3312c9652bc97",
            "filename": "docs/source/en/tasks/semantic_segmentation.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fen%2Ftasks%2Fsemantic_segmentation.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fen%2Ftasks%2Fsemantic_segmentation.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftasks%2Fsemantic_segmentation.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -289,7 +289,7 @@ You could also create and use your own dataset if you prefer to train with the [\n           }\n      )\n \n-     # step 3: push to Hub (assumes you have ran the huggingface-cli login command in a terminal/notebook)\n+     # step 3: push to Hub (assumes you have ran the hf auth login command in a terminal/notebook)\n      dataset.push_to_hub(\"your-name/dataset-repo\")\n \n      # optionally, you can push to a private repo on the Hub"
        },
        {
            "sha": "fec50e4e7a18c3f3de6faf9c5f07cc8910b540e9",
            "filename": "docs/source/es/custom_models.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fes%2Fcustom_models.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fes%2Fcustom_models.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Fcustom_models.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -285,7 +285,7 @@ resnet50d.model.load_state_dict(pretrained_model.state_dict())\n Ahora, para enviar el modelo al Hub, asegÃºrate de haber iniciado sesiÃ³n. Ejecuta en tu terminal:\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n o desde un _notebook_:"
        },
        {
            "sha": "aef87578da31c3f69602d7f19ab4cb28c281e778",
            "filename": "docs/source/es/model_sharing.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fes%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fes%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Fmodel_sharing.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -56,7 +56,7 @@ Los archivos son editados fÃ¡cilmente dentro de un repositorio. Incluso puedes o\n Antes de compartir un modelo al Hub necesitarÃ¡s tus credenciales de Hugging Face. Si tienes acceso a una terminal ejecuta el siguiente comando en el entorno virtual donde ğŸ¤— Transformers estÃ© instalado. Esto guardarÃ¡ tu token de acceso dentro de tu carpeta cache de Hugging Face (~/.cache/ by default):\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n Si usas un notebook como Jupyter o Colaboratory, asegÃºrate de tener instalada la biblioteca [`huggingface_hub`](https://huggingface.co/docs/hub/adding-a-library). Esta biblioteca te permitirÃ¡ interactuar por cÃ³digo con el Hub."
        },
        {
            "sha": "cbabefa47b01bee1209f215e12f7985a0fcda0ad",
            "filename": "docs/source/es/run_scripts.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fes%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fes%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Frun_scripts.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -324,7 +324,7 @@ python examples/pytorch/summarization/run_summarization.py\n Todos los scripts pueden cargar tu modelo final en el [Model Hub](https://huggingface.co/models). AsegÃºrate de haber iniciado sesiÃ³n en Hugging Face antes de comenzar:\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n Luego agrega el argumento `push_to_hub` al script. Este argumento crearÃ¡ un repositorio con tu nombre de usuario Hugging Face y el nombre de la carpeta especificado en `output_dir`."
        },
        {
            "sha": "561f9f0470053e53049c2e12450fed07ac2b906b",
            "filename": "docs/source/fr/run_scripts_fr.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Ffr%2Frun_scripts_fr.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Ffr%2Frun_scripts_fr.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Ffr%2Frun_scripts_fr.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -327,7 +327,7 @@ python examples/pytorch/summarization/run_summarization.py\n Tous les scripts peuvent tÃ©lÃ©charger votre modÃ¨le final sur le Model Hub. Assurez-vous que vous Ãªtes connectÃ© Ã  Hugging Face avant de commencer :\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n Ensuite, ajoutez l'argument `push_to_hub` au script. Cet argument crÃ©era un dÃ©pÃ´t avec votre nom d'utilisateur Hugging Face et le nom du dossier spÃ©cifiÃ© dans `output_dir`."
        },
        {
            "sha": "5f3d4cade0073f07bae794d9a9c006baed4db47b",
            "filename": "docs/source/it/custom_models.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fit%2Fcustom_models.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fit%2Fcustom_models.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fit%2Fcustom_models.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -285,7 +285,7 @@ resnet50d.model.load_state_dict(pretrained_model.state_dict())\n Adesso, per inviare il modello all'Hub, assicurati di aver effettuato l'accesso. Lancia dal tuo terminale:\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n O da un notebook:"
        },
        {
            "sha": "c6efa717efb82401c89b6d0ae70a4ca873423632",
            "filename": "docs/source/it/model_sharing.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fit%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fit%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fit%2Fmodel_sharing.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -56,7 +56,7 @@ Anche i file possono essere modificati facilmente in un repository ed Ã¨ possibi\n Prima di condividere un modello nell'Hub, hai bisogno delle tue credenziali di Hugging Face. Se hai accesso ad un terminale, esegui il seguente comando nell'ambiente virtuale in cui Ã¨ installata la libreria ğŸ¤— Transformers. Questo memorizzerÃ  il tuo token di accesso nella cartella cache di Hugging Face (di default `~/.cache/`):\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n Se stai usando un notebook come Jupyter o Colaboratory, assicurati di avere la libreria [`huggingface_hub`](https://huggingface.co/docs/hub/adding-a-library) installata. Questa libreria ti permette di interagire in maniera programmatica con l'Hub."
        },
        {
            "sha": "71ccf0eed52bdb154822c980f0415dd46192d816",
            "filename": "docs/source/it/run_scripts.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fit%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fit%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fit%2Frun_scripts.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -324,7 +324,7 @@ python examples/pytorch/summarization/run_summarization.py\n Tutti gli script possono caricare il tuo modello finale al [Model Hub](https://huggingface.co/models). Prima di iniziare, assicurati di aver effettuato l'accesso su Hugging Face:\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n Poi, aggiungi l'argomento `push_to_hub` allo script. Questo argomento consentirÃ  di creare un repository con il tuo username Hugging Face e la cartella specificata in `output_dir`."
        },
        {
            "sha": "737f5fd36d0337288302f1e41dc3795665c671af",
            "filename": "docs/source/ja/custom_models.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fja%2Fcustom_models.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fja%2Fcustom_models.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fcustom_models.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -270,7 +270,7 @@ resnet50d.model.load_state_dict(pretrained_model.state_dict())\n ãƒ¢ãƒ‡ãƒ«ã‚’Hubã«é€ä¿¡ã™ã‚‹ã«ã¯ã€ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ï¼š\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n ã¾ãŸã¯ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‹ã‚‰ï¼š"
        },
        {
            "sha": "83df9d8f687e7e52fb3fb56ba576ac6e7e321882",
            "filename": "docs/source/ja/model_sharing.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fja%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fja%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_sharing.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -56,7 +56,7 @@ Model Hubã®çµ„ã¿è¾¼ã¿ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã¯gitãŠã‚ˆã³[git-lfs](https://gi\n ãƒ¢ãƒ‡ãƒ«ã‚’Hubã«å…±æœ‰ã™ã‚‹å‰ã«ã€Hugging Faceã®èªè¨¼æƒ…å ±ãŒå¿…è¦ã§ã™ã€‚ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©ãŒã‚ã‚‹å ´åˆã€ğŸ¤— TransformersãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ä»®æƒ³ç’°å¢ƒã§ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒHugging Faceã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã•ã‚Œã¾ã™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ `~/.cache/` ã«ä¿å­˜ã•ã‚Œã¾ã™ï¼‰ï¼š\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n Jupyterã‚„Colaboratoryã®ã‚ˆã†ãªãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã€[`huggingface_hub`](https://huggingface.co/docs/hub/adding-a-library)ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        },
        {
            "sha": "ca224d75a453b88603643d77558771a4d5d9558a",
            "filename": "docs/source/ja/run_scripts.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fja%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fja%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Frun_scripts.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -337,7 +337,7 @@ python examples/pytorch/summarization/run_summarization.py\n ã™ã¹ã¦ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€æœ€çµ‚çš„ãªãƒ¢ãƒ‡ãƒ«ã‚’ [Model Hub](https://huggingface.co/models) ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚é–‹å§‹ã™ã‚‹å‰ã« Hugging Face ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n æ¬¡ã«ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã« `push_to_hub` å¼•æ•°ã‚’è¿½åŠ ã—ã¾ã™ã€‚ã“ã®å¼•æ•°ã¯ã€Hugging Face ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ `output_dir` ã§æŒ‡å®šã—ãŸãƒ•ã‚©ãƒ«ãƒ€åã§ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆã—ã¾ã™ã€‚"
        },
        {
            "sha": "1e76608b1520e0678e082a84a5e227a603d05748",
            "filename": "docs/source/ko/custom_models.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fko%2Fcustom_models.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fko%2Fcustom_models.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fcustom_models.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -277,7 +277,7 @@ resnet50d.model.load_state_dict(pretrained_model.state_dict())\n í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•´ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n ì£¼í”¼í„° ë…¸íŠ¸ë¶ì˜ ê²½ìš°ì—ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:"
        },
        {
            "sha": "934838c5ffe185dfba9ca1c3fddc06fd959d1d6e",
            "filename": "docs/source/ko/model_sharing.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fko%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fko%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_sharing.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -56,7 +56,7 @@ picture-in-picture\" allowfullscreen></iframe>\n ëª¨ë¸ì„ í—ˆë¸Œì— ê³µìœ í•˜ê¸° ì „ì— Hugging Face ìê²© ì¦ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤. í„°ë¯¸ë„ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆëŠ” ê²½ìš°, ğŸ¤— Transformersê°€ ì„¤ì¹˜ëœ ê°€ìƒ í™˜ê²½ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë©´ Hugging Face ìºì‹œ í´ë”(ê¸°ë³¸ì ìœ¼ë¡œ `~/.cache/`)ì— ì•¡ì„¸ìŠ¤ í† í°ì„ ì €ì¥í•©ë‹ˆë‹¤:\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n Jupyter ë˜ëŠ” Colaboratoryì™€ ê°™ì€ ë…¸íŠ¸ë¶ì„ ì‚¬ìš© ì¤‘ì¸ ê²½ìš°, [`huggingface_hub`](https://huggingface.co/docs/hub/adding-a-library) ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ë©´ APIë¡œ í—ˆë¸Œì™€ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        },
        {
            "sha": "7cbf2288880cf02812d0ad0ea88604d14e972bf1",
            "filename": "docs/source/ko/run_scripts.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fko%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fko%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Frun_scripts.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -347,7 +347,7 @@ python examples/pytorch/summarization/run_summarization.py\n ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ëŠ” ìµœì¢… ëª¨ë¸ì„ [Model Hub](https://huggingface.co/models)ì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n ì‹œì‘í•˜ê¸° ì „ì— Hugging Faceì— ë¡œê·¸ì¸í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:\n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n ê·¸ëŸ° ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ì— `push_to_hub` ì¸ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."
        },
        {
            "sha": "1866cca182e28665e1b1ffe74f24fd0fe78dc4f0",
            "filename": "docs/source/pt/custom_models.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fpt%2Fcustom_models.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fpt%2Fcustom_models.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fpt%2Fcustom_models.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -284,7 +284,7 @@ resnet50d.model.load_state_dict(pretrained_model.state_dict())\n Agora para enviar o modelo para o Hub, certifique-se de estar logado. Ou execute no seu terminal:\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n ou a partir do notebook:"
        },
        {
            "sha": "8aad0f602896c9c8b038ca4a5f0493cc887ccc87",
            "filename": "docs/source/pt/run_scripts.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fpt%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fpt%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fpt%2Frun_scripts.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -327,7 +327,7 @@ python examples/pytorch/summarization/run_summarization.py\n Todos os scripts podem enviar seu modelo final para o [Model Hub](https://huggingface.co/models). Certifique-se de estar conectado ao Hugging Face antes de comeÃ§ar:\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n Em seguida, adicione o argumento `push_to_hub` ao script. Este argumento criarÃ¡ um repositÃ³rio com seu nome de usuÃ¡rio do Hugging Face e o nome da pasta especificado em `output_dir`."
        },
        {
            "sha": "d38aaf4511f26e43dec7729b806380dc6d21f728",
            "filename": "docs/source/zh/custom_models.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fzh%2Fcustom_models.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fzh%2Fcustom_models.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fcustom_models.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -246,7 +246,7 @@ resnet50d.model.load_state_dict(pretrained_model.state_dict())\n ç°åœ¨è¦å°†æ¨¡å‹æ¨é€åˆ°é›†çº¿å™¨ï¼Œè¯·ç¡®ä¿ä½ å·²ç™»å½•ã€‚ä½ çœ‹å¯ä»¥åœ¨ç»ˆç«¯ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n æˆ–è€…åœ¨ç¬”è®°æœ¬ä¸­è¿è¡Œä»¥ä¸‹ä»£ç ï¼š"
        },
        {
            "sha": "c0ce60252537dededd88ba149811d1813283d667",
            "filename": "docs/source/zh/model_sharing.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fzh%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fzh%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fmodel_sharing.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -56,7 +56,7 @@ Model Hubçš„å†…ç½®ç‰ˆæœ¬æ§åˆ¶åŸºäºgitå’Œ[git-lfs](https://git-lfs.github.com/)\n \n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨åƒJupyteræˆ–Colaboratoryè¿™æ ·çš„`notebook`ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…äº†[`huggingface_hub`](https://huggingface.co/docs/hub/adding-a-library)åº“ã€‚è¯¥åº“å…è®¸æ‚¨ä»¥ç¼–ç¨‹æ–¹å¼ä¸Hubè¿›è¡Œäº¤äº’ã€‚"
        },
        {
            "sha": "06ce4ce0d18a3e335ee59255fd1b220e62db8bc3",
            "filename": "docs/source/zh/run_scripts.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fzh%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/docs%2Fsource%2Fzh%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Frun_scripts.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -331,7 +331,7 @@ python examples/pytorch/summarization/run_summarization.py\n æ‰€æœ‰è„šæœ¬éƒ½å¯ä»¥å°†æ‚¨çš„æœ€ç»ˆæ¨¡å‹ä¸Šä¼ åˆ°[Model Hub](https://huggingface.co/models)ã€‚åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²ç™»å½•Hugging Faceï¼š\n \n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n ç„¶åï¼Œåœ¨è„šæœ¬ä¸­æ·»åŠ `push_to_hub`å‚æ•°ã€‚è¿™ä¸ªå‚æ•°ä¼šåˆ›å»ºä¸€ä¸ªå¸¦æœ‰æ‚¨Hugging Faceç”¨æˆ·åå’Œ`output_dir`ä¸­æŒ‡å®šçš„æ–‡ä»¶å¤¹åç§°çš„ä»“åº“ã€‚"
        },
        {
            "sha": "3b1aa9d494e42a9c7381aa977d0bbf251aa6e380",
            "filename": "examples/flax/README.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fflax%2FREADME.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -79,5 +79,5 @@ To specify a given repository name, use the `--hub_model_id` argument. You will\n \n A few notes on this integration:\n \n-- you will need to be logged in to the Hugging Face website locally for it to work, the easiest way to achieve this is to run `huggingface-cli login` and then type your username and password when prompted. You can also pass along your authentication token with the `--hub_token` argument.\n+- you will need to be logged in to the Hugging Face website locally for it to work, the easiest way to achieve this is to run `hf auth login` and then type your username and password when prompted. You can also pass along your authentication token with the `--hub_token` argument.\n - the `output_dir` you pick will either need to be a new folder or a local clone of the distant repository you are using."
        },
        {
            "sha": "cb7dad8d583fc9dbbc031c731d64bd17867dcb6f",
            "filename": "examples/flax/image-captioning/run_image_captioning_flax.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Fimage-captioning%2Frun_image_captioning_flax.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Fimage-captioning%2Frun_image_captioning_flax.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fflax%2Fimage-captioning%2Frun_image_captioning_flax.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -186,7 +186,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "f3e27be1cc94211025b50c6c5fb7045ed460057d",
            "filename": "examples/flax/language-modeling/run_bart_dlm_flax.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Flanguage-modeling%2Frun_bart_dlm_flax.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Flanguage-modeling%2Frun_bart_dlm_flax.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fflax%2Flanguage-modeling%2Frun_bart_dlm_flax.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -172,7 +172,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "8d2daaf517ed3e1c50ebb88e43ee8858e3491a2c",
            "filename": "examples/flax/language-modeling/run_clm_flax.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Flanguage-modeling%2Frun_clm_flax.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Flanguage-modeling%2Frun_clm_flax.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fflax%2Flanguage-modeling%2Frun_clm_flax.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -173,7 +173,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "df548de619f7f5e416d370289a84b1609a9fef24",
            "filename": "examples/flax/language-modeling/run_mlm_flax.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Flanguage-modeling%2Frun_mlm_flax.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Flanguage-modeling%2Frun_mlm_flax.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fflax%2Flanguage-modeling%2Frun_mlm_flax.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -179,7 +179,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "9a64b6d7164327a80b25692b2baec8a7968808cc",
            "filename": "examples/flax/language-modeling/run_t5_mlm_flax.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Flanguage-modeling%2Frun_t5_mlm_flax.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Flanguage-modeling%2Frun_t5_mlm_flax.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fflax%2Flanguage-modeling%2Frun_t5_mlm_flax.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -173,7 +173,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "a8ecf5b64ade4c21672dc977bf9afd494634d477",
            "filename": "examples/flax/question-answering/run_qa.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Fquestion-answering%2Frun_qa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Fquestion-answering%2Frun_qa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fflax%2Fquestion-answering%2Frun_qa.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -159,7 +159,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "6c9777cf322ae0733d138c3bace2c39725f0186e",
            "filename": "examples/flax/summarization/run_summarization_flax.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Fsummarization%2Frun_summarization_flax.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Fsummarization%2Frun_summarization_flax.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fflax%2Fsummarization%2Frun_summarization_flax.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -192,7 +192,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "63544e66581e7e4f0e8b9e788f1c006138fa0041",
            "filename": "examples/flax/text-classification/run_flax_glue.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Ftext-classification%2Frun_flax_glue.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Ftext-classification%2Frun_flax_glue.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fflax%2Ftext-classification%2Frun_flax_glue.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -107,7 +107,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "8257e963f50f75eb78a128cdff2eb43fee3d90aa",
            "filename": "examples/flax/token-classification/run_flax_ner.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Ftoken-classification%2Frun_flax_ner.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Ftoken-classification%2Frun_flax_ner.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fflax%2Ftoken-classification%2Frun_flax_ner.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -155,7 +155,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "4c6550e6b8033e0f76b9ed054340e0c96a108a6b",
            "filename": "examples/flax/vision/run_image_classification.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Fvision%2Frun_image_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fflax%2Fvision%2Frun_image_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fflax%2Fvision%2Frun_image_classification.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -163,7 +163,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "6ff3389c162c30674beee16dcd6ea7b7fea76c5d",
            "filename": "examples/pytorch/README.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2FREADME.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -90,7 +90,7 @@ To specify a given repository name, use the `--hub_model_id` argument. You will\n \n A few notes on this integration:\n \n-- you will need to be logged in to the Hugging Face website locally for it to work, the easiest way to achieve this is to run `huggingface-cli login` and then type your username and password when prompted. You can also pass along your authentication token with the `--hub_token` argument.\n+- you will need to be logged in to the Hugging Face website locally for it to work, the easiest way to achieve this is to run `hf auth login` and then type your username and password when prompted. You can also pass along your authentication token with the `--hub_token` argument.\n - the `output_dir` you pick will either need to be a new folder or a local clone of the distant repository you are using.\n \n ## Distributed training and mixed precision"
        },
        {
            "sha": "6f9069b331ab3e176bdbc1b8f67031f4bb4ce59f",
            "filename": "examples/pytorch/audio-classification/README.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Faudio-classification%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Faudio-classification%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Faudio-classification%2FREADME.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -115,10 +115,10 @@ On 4 V100 GPUs (16GB), this script should run in ~1 hour and yield accuracy of *\n $ apt install git-lfs\n ```\n \n-2. Log in with your HuggingFace account credentials using `huggingface-cli`\n+2. Log in with your HuggingFace account credentials using `hf`\n \n ```bash\n-$ huggingface-cli login\n+$ hf auth login\n # ...follow the prompts\n ```\n "
        },
        {
            "sha": "3ab87693bbc3a13218b93371f8df929ae38c2034",
            "filename": "examples/pytorch/audio-classification/run_audio_classification.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Faudio-classification%2Frun_audio_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Faudio-classification%2Frun_audio_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Faudio-classification%2Frun_audio_classification.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -167,7 +167,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "477c5622c1bc65be1e438792c59490ddcba03e0f",
            "filename": "examples/pytorch/contrastive-image-text/run_clip.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fcontrastive-image-text%2Frun_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fcontrastive-image-text%2Frun_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fcontrastive-image-text%2Frun_clip.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -100,7 +100,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "0ef36c75c72675e5e7ba84bb5a0a5f3d80924e52",
            "filename": "examples/pytorch/image-classification/README.md",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fimage-classification%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fimage-classification%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-classification%2FREADME.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -129,7 +129,7 @@ dataset = load_dataset(\"imagefolder\", data_files={\"train\": [\"path/to/file1\", \"pa\n Next, push it to the hub!\n \n ```python\n-# assuming you have ran the huggingface-cli login command in a terminal\n+# assuming you have ran the hf auth login command in a terminal\n dataset.push_to_hub(\"name_of_your_dataset\")\n \n # if you want to push to a private repo, simply pass private=True:\n@@ -152,10 +152,10 @@ $ git config --global user.email \"you@example.com\"\n $ git config --global user.name \"Your Name\"\n ```\n \n-2. Log in with your HuggingFace account credentials using `huggingface-cli`:\n+2. Log in with your HuggingFace account credentials using `hf`:\n \n ```bash\n-$ huggingface-cli login\n+$ hf auth login\n # ...follow the prompts\n ```\n "
        },
        {
            "sha": "51cdaf71f0c03ea5875140acaf2876ac9e4cfcd0",
            "filename": "examples/pytorch/image-classification/run_image_classification.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -168,7 +168,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "bca37f24135a2f07e321a6883f7a6d764e9ad8c4",
            "filename": "examples/pytorch/image-pretraining/README.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fimage-pretraining%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fimage-pretraining%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-pretraining%2FREADME.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -239,10 +239,10 @@ $ git config --global user.email \"you@example.com\"\n $ git config --global user.name \"Your Name\"\n ```\n \n-2. Log in with your HuggingFace account credentials using `huggingface-cli`\n+2. Log in with your HuggingFace account credentials using `hf`\n \n ```bash\n-$ huggingface-cli login\n+$ hf auth login\n # ...follow the prompts\n ```\n "
        },
        {
            "sha": "ea4fabf0651e935b89c632272d4b19f9371d73e3",
            "filename": "examples/pytorch/image-pretraining/run_mae.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fimage-pretraining%2Frun_mae.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fimage-pretraining%2Frun_mae.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-pretraining%2Frun_mae.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -156,7 +156,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "8ee44521863f306e209bd81a85efb48306fef846",
            "filename": "examples/pytorch/image-pretraining/run_mim.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -166,7 +166,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "fe560ba901f37e8daa90b0c6eba845dfd034fdc9",
            "filename": "examples/pytorch/image-pretraining/run_mim_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim_no_trainer.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -200,7 +200,7 @@ def parse_args():\n         default=None,\n         help=(\n             \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-            \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+            \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n         ),\n     )\n     parser.add_argument("
        },
        {
            "sha": "a0c1554f4da9ecb389d01029693e1c95a4966a6b",
            "filename": "examples/pytorch/instance-segmentation/run_instance_segmentation.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -97,7 +97,7 @@ class Arguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "3a87d07313990aa0c15bfb3b3b5c558abda177ec",
            "filename": "examples/pytorch/language-modeling/run_clm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -130,7 +130,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "cf31af2b9e28005a86d23a26f8a7725ce52a9c44",
            "filename": "examples/pytorch/language-modeling/run_fim.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -133,7 +133,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "7c56aa7cf229cdd2477a57cd59f8b927c33025c5",
            "filename": "examples/pytorch/language-modeling/run_mlm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -127,7 +127,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "175cf813070055ca586f763c54b6be2656618f9d",
            "filename": "examples/pytorch/language-modeling/run_plm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Flanguage-modeling%2Frun_plm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Flanguage-modeling%2Frun_plm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_plm.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -114,7 +114,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "90374bb7cccff137c9940500d8f001e6c829c426",
            "filename": "examples/pytorch/multiple-choice/run_swag.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -94,7 +94,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "0459f3f9e7d6999f5fac3cf6262939ec31d291a8",
            "filename": "examples/pytorch/object-detection/README.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fobject-detection%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fobject-detection%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fobject-detection%2FREADME.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -217,7 +217,7 @@ dataset = load_dataset(\"imagefolder\", data_dir=\"custom_dataset/\")\n # ...     })\n # ... })\n \n-# Push to hub (assumes you have ran the huggingface-cli login command in a terminal/notebook)\n+# Push to hub (assumes you have ran the hf auth login command in a terminal/notebook)\n dataset.push_to_hub(\"name of repo on the hub\")\n \n # optionally, you can push to a private repo on the hub"
        },
        {
            "sha": "412eb9414d0bdd51bc501d1b17e1907972aede99",
            "filename": "examples/pytorch/object-detection/run_object_detection.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -320,7 +320,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "74e5fb548737549109916f80b1c0f30a10ee484b",
            "filename": "examples/pytorch/question-answering/run_qa.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fquestion-answering%2Frun_qa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fquestion-answering%2Frun_qa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fquestion-answering%2Frun_qa.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -84,7 +84,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "74c76d6b1987e53bb1b674c5d7f335c9ae099443",
            "filename": "examples/pytorch/question-answering/run_qa_beam_search.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_beam_search.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_beam_search.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_beam_search.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -82,7 +82,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "98ad4585de594a0946ed739c74f8d5482851d370",
            "filename": "examples/pytorch/question-answering/run_seq2seq_qa.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fquestion-answering%2Frun_seq2seq_qa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fquestion-answering%2Frun_seq2seq_qa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fquestion-answering%2Frun_seq2seq_qa.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -84,7 +84,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "e54be51ee899ae595e634f439314c358d3bc3b3a",
            "filename": "examples/pytorch/semantic-segmentation/README.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fsemantic-segmentation%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fsemantic-segmentation%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fsemantic-segmentation%2FREADME.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -66,7 +66,7 @@ dataset = DatasetDict({\n   }\n )\n \n-# step 3: push to hub (assumes you have ran the huggingface-cli login command in a terminal/notebook)\n+# step 3: push to hub (assumes you have ran the hf auth login command in a terminal/notebook)\n dataset.push_to_hub(\"name of repo on the hub\")\n \n # optionally, you can push to a private repo on the hub\n@@ -98,7 +98,7 @@ The script leverages the [ğŸ¤— Trainer API](https://huggingface.co/docs/transfor\n Here we show how to fine-tune a [SegFormer](https://huggingface.co/nvidia/mit-b0) model on the [segments/sidewalk-semantic](https://huggingface.co/datasets/segments/sidewalk-semantic) dataset:\n \n In order to use `segments/sidewalk-semantic`: \n- - Log in to Hugging Face with `huggingface-cli login` (token can be accessed [here](https://huggingface.co/settings/tokens)).\n+ - Log in to Hugging Face with `hf auth login` (token can be accessed [here](https://huggingface.co/settings/tokens)).\n  - Accept terms of use for `sidewalk-semantic` on [dataset page](https://huggingface.co/datasets/segments/sidewalk-semantic).\n \n ```bash"
        },
        {
            "sha": "37729637ea10dc700b51b2a4cd3e52d621513bb1",
            "filename": "examples/pytorch/semantic-segmentation/run_semantic_segmentation.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -168,7 +168,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "2889919655f4f8f4da8c94a20004b50d15cb4fe1",
            "filename": "examples/pytorch/speech-recognition/README.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fspeech-recognition%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fspeech-recognition%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fspeech-recognition%2FREADME.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -278,7 +278,7 @@ accordingly be called `adapter.{<target_language}.safetensors`.\n \n Let's run an example script. Make sure to be logged in so that your model can be directly uploaded to the Hub.\n ```bash\n-huggingface-cli login\n+hf auth login\n ```\n \n Now, let's run an example and upload it to the Hub under `wav2vec2-common_voice-tr-mms-demo`.\n@@ -448,7 +448,7 @@ By pairing a pretrained speech model with a pretrained text model, the warm-star\n As an example, let's instantiate a *Wav2Vec2-2-Bart* model with the `SpeechEncoderDecoderModel` framework. First create an empty repo on `hf.co`:\n \n ```bash\n-huggingface-cli repo create wav2vec2-2-bart-base\n+hf repo create wav2vec2-2-bart-base\n git clone https://huggingface.co/<your-user-name>/wav2vec2-2-bart-base\n cd wav2vec2-2-bart-base\n ```"
        },
        {
            "sha": "cf297b71bd78b6c339a2368ce93ea219417ec4c3",
            "filename": "examples/pytorch/speech-recognition/run_speech_recognition_ctc.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -258,7 +258,7 @@ class DataTrainingArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "86f8dc8350c71f62b7f2d774a933f098ba35ba2d",
            "filename": "examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc_adapter.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc_adapter.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc_adapter.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -248,7 +248,7 @@ class DataTrainingArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "6f1c6d39c1c81c90a0ef55e1d8da05a826d7dbc8",
            "filename": "examples/pytorch/speech-recognition/run_speech_recognition_seq2seq.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_seq2seq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_seq2seq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_seq2seq.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -102,7 +102,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "6403a2fe9a54062c812826de16454718163efc28",
            "filename": "examples/pytorch/summarization/run_summarization.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fsummarization%2Frun_summarization.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Fsummarization%2Frun_summarization.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fsummarization%2Frun_summarization.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -119,7 +119,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "1b2695592e082787935774b281c9532568dc217c",
            "filename": "examples/pytorch/text-classification/run_classification.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Ftext-classification%2Frun_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Ftext-classification%2Frun_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftext-classification%2Frun_classification.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -250,7 +250,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "f3b5aba72f733a6a8dcf4974900644dec52cf155",
            "filename": "examples/pytorch/text-classification/run_glue.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Ftext-classification%2Frun_glue.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Ftext-classification%2Frun_glue.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftext-classification%2Frun_glue.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -208,7 +208,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "16d7a268c5caf705e2a2dfd6c0fd5fc5855f8f05",
            "filename": "examples/pytorch/text-classification/run_xnli.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Ftext-classification%2Frun_xnli.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Ftext-classification%2Frun_xnli.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftext-classification%2Frun_xnli.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -171,7 +171,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "3e6986050a4c5dbaf0ec27f82c239e75cbe688d7",
            "filename": "examples/pytorch/token-classification/run_ner.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Ftoken-classification%2Frun_ner.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Ftoken-classification%2Frun_ner.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftoken-classification%2Frun_ner.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -95,7 +95,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "2bc0adc55221ec02358e8edc549a25e4d2c855f6",
            "filename": "examples/pytorch/translation/run_translation.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Ftranslation%2Frun_translation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Fpytorch%2Ftranslation%2Frun_translation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftranslation%2Frun_translation.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -108,7 +108,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "ebaab0c136973963ee396d86feb87a60a33ae406",
            "filename": "examples/tensorflow/contrastive-image-text/run_clip.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Fcontrastive-image-text%2Frun_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Fcontrastive-image-text%2Frun_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Ftensorflow%2Fcontrastive-image-text%2Frun_clip.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -96,7 +96,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "e779a29c1b9799ac16a32732c0440a6e23a6f008",
            "filename": "examples/tensorflow/image-classification/README.md",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Fimage-classification%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Fimage-classification%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Ftensorflow%2Fimage-classification%2FREADME.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -122,7 +122,7 @@ dataset = load_dataset(\"imagefolder\", data_files={\"train\": [\"path/to/file1\", \"pa\n Next, push it to the hub!\n \n ```python\n-# assuming you have ran the huggingface-cli login command in a terminal\n+# assuming you have ran the hf auth login command in a terminal\n dataset.push_to_hub(\"name_of_your_dataset\")\n \n # if you want to push to a private repo, simply pass private=True:\n@@ -145,10 +145,10 @@ $ git config --global user.email \"you@example.com\"\n $ git config --global user.name \"Your Name\"\n ```\n \n-2. Log in with your HuggingFace account credentials using `huggingface-cli`:\n+2. Log in with your HuggingFace account credentials using `hf`:\n \n ```bash\n-$ huggingface-cli login\n+$ hf auth login\n # ...follow the prompts\n ```\n "
        },
        {
            "sha": "7b515bc04bd9582e8d03bad555b3f3c4d8d807e9",
            "filename": "examples/tensorflow/image-classification/run_image_classification.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Fimage-classification%2Frun_image_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Fimage-classification%2Frun_image_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Ftensorflow%2Fimage-classification%2Frun_image_classification.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -162,7 +162,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "094c95cd395a0bd83178cb2d365eaa7a696a8401",
            "filename": "examples/tensorflow/language-modeling-tpu/README.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Flanguage-modeling-tpu%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Flanguage-modeling-tpu%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Ftensorflow%2Flanguage-modeling-tpu%2FREADME.md?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -35,7 +35,7 @@ python train_unigram.py --batch_size 1000 --vocab_size 25000 --export_to_hub\n \n The script will automatically load the `train` split of the WikiText dataset and train a [Unigram tokenizer](https://huggingface.co/course/chapter6/7?fw=pt) on it.\n \n-> ğŸ’¡ **Note**: In order for `export_to_hub` to work, you must authenticate yourself with the `huggingface-cli`. Run `huggingface-cli login` and follow the on-screen instructions.\n+> ğŸ’¡ **Note**: In order for `export_to_hub` to work, you must authenticate yourself with the `hf`. Run `hf auth login` and follow the on-screen instructions.\n \n ## Preparing the dataset\n "
        },
        {
            "sha": "0d776229d251c17c838c29d96c5f4afc38a6b32b",
            "filename": "examples/tensorflow/language-modeling/run_clm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Flanguage-modeling%2Frun_clm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Flanguage-modeling%2Frun_clm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Ftensorflow%2Flanguage-modeling%2Frun_clm.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -116,7 +116,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "5dcbd35729ef5b5da85c415fe9824c2bfdd91bda",
            "filename": "examples/tensorflow/language-modeling/run_mlm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Flanguage-modeling%2Frun_mlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Flanguage-modeling%2Frun_mlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Ftensorflow%2Flanguage-modeling%2Frun_mlm.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -114,7 +114,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "ee396d5098147ed5774ea478cf9a325bbc1d5ca4",
            "filename": "examples/tensorflow/multiple-choice/run_swag.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Fmultiple-choice%2Frun_swag.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Fmultiple-choice%2Frun_swag.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Ftensorflow%2Fmultiple-choice%2Frun_swag.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -87,7 +87,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "41d63e800c5a6181ab4076e723e103cf0fbdd531",
            "filename": "examples/tensorflow/question-answering/run_qa.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Fquestion-answering%2Frun_qa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Fquestion-answering%2Frun_qa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Ftensorflow%2Fquestion-answering%2Frun_qa.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -95,7 +95,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "6be43eb71387f494bb03ec6e086a5503b523a493",
            "filename": "examples/tensorflow/summarization/run_summarization.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Fsummarization%2Frun_summarization.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Fsummarization%2Frun_summarization.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Ftensorflow%2Fsummarization%2Frun_summarization.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -103,7 +103,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "6664da523b959abc082febcdf2b1c1f7da7a0464",
            "filename": "examples/tensorflow/text-classification/run_glue.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Ftext-classification%2Frun_glue.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Ftext-classification%2Frun_glue.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Ftensorflow%2Ftext-classification%2Frun_glue.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -168,7 +168,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "7546c7bd327fb1f82eff244a07dae63f93c257ef",
            "filename": "examples/tensorflow/text-classification/run_text_classification.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Ftext-classification%2Frun_text_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Ftext-classification%2Frun_text_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Ftensorflow%2Ftext-classification%2Frun_text_classification.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -188,7 +188,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "0bada558fb937c2bf21faafe2e5379e45e69eab0",
            "filename": "examples/tensorflow/token-classification/run_ner.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Ftoken-classification%2Frun_ner.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Ftoken-classification%2Frun_ner.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Ftensorflow%2Ftoken-classification%2Frun_ner.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -79,7 +79,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "bbf69e0943a2e57a2755fd5067a8b2b4ed0f61ac",
            "filename": "examples/tensorflow/translation/run_translation.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Ftranslation%2Frun_translation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/examples%2Ftensorflow%2Ftranslation%2Frun_translation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Ftensorflow%2Ftranslation%2Frun_translation.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -97,7 +97,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "8082853a8a30e13d8696c0b3e33b7f6846ebd71a",
            "filename": "setup.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/setup.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/setup.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/setup.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -117,7 +117,7 @@\n     \"GitPython<3.1.19\",\n     \"hf-doc-builder>=0.3.0\",\n     \"hf_xet\",\n-    \"huggingface-hub>=0.30.0,<1.0\",\n+    \"huggingface-hub>=0.34.0,<1.0\",\n     \"importlib_metadata\",\n     \"ipadic>=1.0.0,<2.0\",\n     \"jax>=0.4.1,<=0.4.13\","
        },
        {
            "sha": "8abdb94c9641c165abf6e4e288bd6d9fc62e9a68",
            "filename": "src/transformers/configuration_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fconfiguration_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fconfiguration_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fconfiguration_utils.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -550,7 +550,7 @@ def from_pretrained(\n                 'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n             token (`str` or `bool`, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use\n-                the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                the token generated when running `hf auth login` (stored in `~/.huggingface`).\n             revision (`str`, *optional*, defaults to `\"main\"`):\n                 The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n                 git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any"
        },
        {
            "sha": "a5f7daf188b8fdcb140f6e97e6171b05ebe8b4ec",
            "filename": "src/transformers/dependency_versions_table.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fdependency_versions_table.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fdependency_versions_table.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdependency_versions_table.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -24,7 +24,7 @@\n     \"GitPython\": \"GitPython<3.1.19\",\n     \"hf-doc-builder\": \"hf-doc-builder>=0.3.0\",\n     \"hf_xet\": \"hf_xet\",\n-    \"huggingface-hub\": \"huggingface-hub>=0.30.0,<1.0\",\n+    \"huggingface-hub\": \"huggingface-hub>=0.34.0,<1.0\",\n     \"importlib_metadata\": \"importlib_metadata\",\n     \"ipadic\": \"ipadic>=1.0.0,<2.0\",\n     \"jax\": \"jax>=0.4.1,<=0.4.13\","
        },
        {
            "sha": "ff0cd22fabfb1c77a20ef0c05c9419b72067d811",
            "filename": "src/transformers/dynamic_module_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fdynamic_module_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fdynamic_module_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdynamic_module_utils.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -322,7 +322,7 @@ def get_cached_module_file(\n             'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n         token (`str` or *bool*, *optional*):\n             The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-            when running `huggingface-cli login` (stored in `~/.huggingface`).\n+            when running `hf auth login` (stored in `~/.huggingface`).\n         revision (`str`, *optional*, defaults to `\"main\"`):\n             The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n             git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\n@@ -513,7 +513,7 @@ def get_class_from_dynamic_module(\n             'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n         token (`str` or `bool`, *optional*):\n             The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-            when running `huggingface-cli login` (stored in `~/.huggingface`).\n+            when running `hf auth login` (stored in `~/.huggingface`).\n         revision (`str`, *optional*, defaults to `\"main\"`):\n             The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n             git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any"
        },
        {
            "sha": "d9d6ca0e215c07bedfd9b273ae7f9237dfd4a300",
            "filename": "src/transformers/feature_extraction_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Ffeature_extraction_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Ffeature_extraction_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ffeature_extraction_utils.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -311,7 +311,7 @@ def from_pretrained(\n                 'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n             token (`str` or `bool`, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use\n-                the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                the token generated when running `hf auth login` (stored in `~/.huggingface`).\n             revision (`str`, *optional*, defaults to `\"main\"`):\n                 The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n                 git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any"
        },
        {
            "sha": "84b892251d501502c9e333f9400361dbcb5a07a1",
            "filename": "src/transformers/generation/configuration_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fgeneration%2Fconfiguration_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fgeneration%2Fconfiguration_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Fconfiguration_utils.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -921,7 +921,7 @@ def from_pretrained(\n                 'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n             token (`str` or `bool`, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use\n-                the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                the token generated when running `hf auth login` (stored in `~/.huggingface`).\n             revision (`str`, *optional*, defaults to `\"main\"`):\n                 The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n                 git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any"
        },
        {
            "sha": "9b40b0da7bc3281f72b50451571dfabf266eb3b9",
            "filename": "src/transformers/image_processing_base.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fimage_processing_base.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fimage_processing_base.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fimage_processing_base.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -132,7 +132,7 @@ def from_pretrained(\n                 'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n             token (`str` or `bool`, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use\n-                the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                the token generated when running `hf auth login` (stored in `~/.huggingface`).\n             revision (`str`, *optional*, defaults to `\"main\"`):\n                 The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n                 git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any"
        },
        {
            "sha": "c944a2359e09fb4b5a5e451dda73375284a5d07a",
            "filename": "src/transformers/integrations/peft.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fintegrations%2Fpeft.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fintegrations%2Fpeft.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Fpeft.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -131,7 +131,7 @@ def load_adapter(\n \n             token (`str`, `optional`):\n                 Whether to use authentication token to load the remote folder. Useful to load private repositories\n-                that are on HuggingFace Hub. You might need to call `huggingface-cli login` and paste your tokens to\n+                that are on HuggingFace Hub. You might need to call `hf auth login` and paste your tokens to\n                 cache it.\n             device_map (`str` or `dict[str, Union[int, str, torch.device]]` or `int` or `torch.device`, *optional*):\n                 A map that specifies where each submodule should go. It doesn't need to be refined to each"
        },
        {
            "sha": "77c8fe428c945a5d672733fca7dbe106bfcbd6b0",
            "filename": "src/transformers/keras_callbacks.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fkeras_callbacks.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fkeras_callbacks.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fkeras_callbacks.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -306,7 +306,7 @@ class PushToHubCallback(keras.callbacks.Callback):\n             Will default to the name of `output_dir`.\n         hub_token (`str`, *optional*):\n             The token to use to push the model to the Hub. Will default to the token in the cache folder obtained with\n-            `huggingface-cli login`.\n+            `hf auth login`.\n         checkpoint (`bool`, *optional*, defaults to `False`):\n             Whether to save full training checkpoints (including epoch and optimizer state) to allow training to be\n             resumed. Only usable when `save_strategy` is `\"epoch\"`."
        },
        {
            "sha": "3f94a3c6cef51692fb642ce9f89a26cc284d6de4",
            "filename": "src/transformers/modeling_flax_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodeling_flax_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodeling_flax_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_flax_utils.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -588,7 +588,7 @@ def from_pretrained(\n                 Whether or not to only look at local files (i.e., do not try to download the model).\n             token (`str` or `bool`, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use\n-                the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                the token generated when running `hf auth login` (stored in `~/.huggingface`).\n             revision (`str`, *optional*, defaults to `\"main\"`):\n                 The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n                 git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\n@@ -1112,7 +1112,7 @@ def save_pretrained(\n \n             token (`str` or `bool`, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use\n-                the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                the token generated when running `hf auth login` (stored in `~/.huggingface`).\n             kwargs (`dict[str, Any]`, *optional*):\n                 Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.\n             safe_serialization (`bool`, *optional*, defaults to `False`):"
        },
        {
            "sha": "3e2564bc7a105767357e4e7a591af9c006551703",
            "filename": "src/transformers/modeling_tf_utils.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodeling_tf_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodeling_tf_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_tf_utils.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -2386,7 +2386,7 @@ def save_pretrained(\n                 Whether to save the model using `safetensors` or the traditional TensorFlow way (that uses `h5`).\n             token (`str` or `bool`, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use\n-                the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                the token generated when running `hf auth login` (stored in `~/.huggingface`).\n             kwargs (`dict[str, Any]`, *optional*):\n                 Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.\n         \"\"\"\n@@ -2600,7 +2600,7 @@ def from_pretrained(\n                 Whether or not to only look at local files (e.g., not try downloading the model).\n             token (`str` or `bool`, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use\n-                the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                the token generated when running `hf auth login` (stored in `~/.huggingface`).\n             revision (`str`, *optional*, defaults to `\"main\"`):\n                 The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n                 git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\n@@ -3145,7 +3145,7 @@ def push_to_hub(\n                 Whether to make the repo private. If `None` (default), the repo will be public unless the organization's default is private. This value is ignored if the repo already exists.\n             token (`bool` or `str`, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-                when running `huggingface-cli login` (stored in `~/.huggingface`). Will default to `True` if `repo_url`\n+                when running `hf auth login` (stored in `~/.huggingface`). Will default to `True` if `repo_url`\n                 is not specified.\n             max_shard_size (`int` or `str`, *optional*, defaults to `\"10GB\"`):\n                 Only applicable for models. The maximum size for a checkpoint before being sharded. Checkpoints shard"
        },
        {
            "sha": "5c4226ad2cae018186fe0178c0c392fc2b7c7735",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -3872,7 +3872,7 @@ def save_pretrained(\n                 If specified, weights are saved in the format pytorch_model.<variant>.bin.\n             token (`str` or `bool`, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use\n-                the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                the token generated when running `hf auth login` (stored in `~/.huggingface`).\n             save_peft_format (`bool`, *optional*, defaults to `True`):\n                 For backward compatibility with PEFT library, in case adapter weights are attached to the model, all\n                 keys of the state dict of adapters needs to be prepended with `base_model.model`. Advanced users can\n@@ -4520,7 +4520,7 @@ def from_pretrained(\n                 Whether or not to only look at local files (i.e., do not try to download the model).\n             token (`str` or `bool`, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use\n-                the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                the token generated when running `hf auth login` (stored in `~/.huggingface`).\n             revision (`str`, *optional*, defaults to `\"main\"`):\n                 The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n                 git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any"
        },
        {
            "sha": "0878c5ce30144c87eeb11491db336fef9933aa36",
            "filename": "src/transformers/models/auto/feature_extraction_auto.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodels%2Fauto%2Ffeature_extraction_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodels%2Fauto%2Ffeature_extraction_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Ffeature_extraction_auto.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -183,7 +183,7 @@ def get_feature_extractor_config(\n             'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n         token (`str` or *bool*, *optional*):\n             The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-            when running `huggingface-cli login` (stored in `~/.huggingface`).\n+            when running `hf auth login` (stored in `~/.huggingface`).\n         revision (`str`, *optional*, defaults to `\"main\"`):\n             The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n             git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\n@@ -300,7 +300,7 @@ def from_pretrained(cls, pretrained_model_name_or_path, **kwargs):\n                 'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n             token (`str` or *bool*, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-                when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                when running `hf auth login` (stored in `~/.huggingface`).\n             revision (`str`, *optional*, defaults to `\"main\"`):\n                 The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n                 git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any"
        },
        {
            "sha": "3d7be9f18b770d9fb128d232bcd676e0f43b7ed8",
            "filename": "src/transformers/models/auto/image_processing_auto.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -264,7 +264,7 @@ def get_image_processor_config(\n             'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n         token (`str` or *bool*, *optional*):\n             The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-            when running `huggingface-cli login` (stored in `~/.huggingface`).\n+            when running `hf auth login` (stored in `~/.huggingface`).\n         revision (`str`, *optional*, defaults to `\"main\"`):\n             The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n             git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\n@@ -389,7 +389,7 @@ def from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs):\n                 'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n             token (`str` or *bool*, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-                when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                when running `hf auth login` (stored in `~/.huggingface`).\n             revision (`str`, *optional*, defaults to `\"main\"`):\n                 The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n                 git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any"
        },
        {
            "sha": "69f65e23e151695048d8fb6d539c229c21155184",
            "filename": "src/transformers/models/auto/processing_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodels%2Fauto%2Fprocessing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodels%2Fauto%2Fprocessing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fprocessing_auto.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -216,7 +216,7 @@ def from_pretrained(cls, pretrained_model_name_or_path, **kwargs):\n                 'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n             token (`str` or *bool*, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-                when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                when running `hf auth login` (stored in `~/.huggingface`).\n             revision (`str`, *optional*, defaults to `\"main\"`):\n                 The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n                 git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any"
        },
        {
            "sha": "6c4e3e98c75716a96e7e4acf2e17b7e75f463e7b",
            "filename": "src/transformers/models/auto/tokenization_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -808,7 +808,7 @@ def get_tokenizer_config(\n             'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n         token (`str` or *bool*, *optional*):\n             The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-            when running `huggingface-cli login` (stored in `~/.huggingface`).\n+            when running `hf auth login` (stored in `~/.huggingface`).\n         revision (`str`, *optional*, defaults to `\"main\"`):\n             The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n             git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any"
        },
        {
            "sha": "77a8c458bd33238309c7248084e1042a2e72a1e4",
            "filename": "src/transformers/models/auto/video_processing_auto.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodels%2Fauto%2Fvideo_processing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodels%2Fauto%2Fvideo_processing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fvideo_processing_auto.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -134,7 +134,7 @@ def get_video_processor_config(\n             'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n         token (`str` or *bool*, *optional*):\n             The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-            when running `huggingface-cli login` (stored in `~/.huggingface`).\n+            when running `hf auth login` (stored in `~/.huggingface`).\n         revision (`str`, *optional*, defaults to `\"main\"`):\n             The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n             git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\n@@ -249,7 +249,7 @@ def from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs):\n                 'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n             token (`str` or *bool*, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-                when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                when running `hf auth login` (stored in `~/.huggingface`).\n             revision (`str`, *optional*, defaults to `\"main\"`):\n                 The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n                 git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any"
        },
        {
            "sha": "ab3f38d644bec3ed10f612706aa3c7a5c3b92308",
            "filename": "src/transformers/models/wav2vec2/modeling_wav2vec2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fmodeling_wav2vec2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fmodeling_wav2vec2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fmodeling_wav2vec2.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -1175,7 +1175,7 @@ def load_adapter(self, target_lang: str, force_load=True, **kwargs):\n                 Whether or not to only look at local files (i.e., do not try to download the model).\n             token (`str` or `bool`, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use\n-                the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                the token generated when running `hf auth login` (stored in `~/.huggingface`).\n             revision (`str`, *optional*, defaults to `\"main\"`):\n                 The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n                 git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any"
        },
        {
            "sha": "b84e1bf9d4eb8eb243ef72a9579127e910b83c52",
            "filename": "src/transformers/pipelines/__init__.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fpipelines%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fpipelines%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2F__init__.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -761,7 +761,7 @@ def pipeline(\n             Whether or not to use a Fast tokenizer if possible (a [`PreTrainedTokenizerFast`]).\n         use_auth_token (`str` or *bool*, *optional*):\n             The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-            when running `huggingface-cli login` (stored in `~/.huggingface`).\n+            when running `hf auth login` (stored in `~/.huggingface`).\n         device (`int` or `str` or `torch.device`):\n             Defines the device (*e.g.*, `\"cpu\"`, `\"cuda:1\"`, `\"mps\"`, or a GPU ordinal rank like `1`) on which this\n             pipeline will be allocated."
        },
        {
            "sha": "95bd64049bf9ce1801a5e06115fb3ea53ad82064",
            "filename": "src/transformers/tokenization_mistral_common.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Ftokenization_mistral_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Ftokenization_mistral_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_mistral_common.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -1726,7 +1726,7 @@ def from_pretrained(\n                 exist.\n             token (`str` or *bool*, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-                when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                when running `hf auth login` (stored in `~/.huggingface`).\n             local_files_only (`bool`, *optional*, defaults to `False`):\n                 Whether or not to only rely on local files and not to attempt to download any files.\n             revision (`str`, *optional*, defaults to `\"main\"`):"
        },
        {
            "sha": "a8d0336b4663621364a27c6c014d075ce46f9a61",
            "filename": "src/transformers/tokenization_utils_base.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Ftokenization_utils_base.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Ftokenization_utils_base.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_utils_base.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -1790,7 +1790,7 @@ def from_pretrained(\n                 'http://hostname': 'foo.bar:4012'}`. The proxies are used on each request.\n             token (`str` or *bool*, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-                when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                when running `hf auth login` (stored in `~/.huggingface`).\n             local_files_only (`bool`, *optional*, defaults to `False`):\n                 Whether or not to only rely on local files and not to attempt to download any files.\n             revision (`str`, *optional*, defaults to `\"main\"`):"
        },
        {
            "sha": "8314e271343b1ffc5fc6303eabbbdf1c17f4f98d",
            "filename": "src/transformers/training_args.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Ftraining_args.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Ftraining_args.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftraining_args.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -690,7 +690,7 @@ class TrainingArguments:\n \n         hub_token (`str`, *optional*):\n             The token to use to push the model to the Hub. Will default to the token in the cache folder obtained with\n-            `huggingface-cli login`.\n+            `hf auth login`.\n         hub_private_repo (`bool`, *optional*):\n             Whether to make the repo private. If `None` (default), the repo will be public unless the organization's default is private. This value is ignored if the repo already exists.\n         hub_always_push (`bool`, *optional*, defaults to `False`):\n@@ -2930,7 +2930,7 @@ def set_push_to_hub(\n \n             token (`str`, *optional*):\n                 The token to use to push the model to the Hub. Will default to the token in the cache folder obtained\n-                with `huggingface-cli login`.\n+                with `hf auth login`.\n             private_repo (`bool`, *optional*, defaults to `False`):\n                 Whether to make the repo private. If `None` (default), the repo will be public unless the organization's default is private. This value is ignored if the repo already exists.\n             always_push (`bool`, *optional*, defaults to `False`):"
        },
        {
            "sha": "c4921459a7913eec2ee4e8e08fc4d3fafd9fc20a",
            "filename": "src/transformers/utils/hub.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Futils%2Fhub.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Futils%2Fhub.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fhub.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -286,7 +286,7 @@ def cached_file(\n             'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n         token (`str` or *bool*, *optional*):\n             The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-            when running `huggingface-cli login` (stored in `~/.huggingface`).\n+            when running `hf auth login` (stored in `~/.huggingface`).\n         revision (`str`, *optional*, defaults to `\"main\"`):\n             The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n             git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\n@@ -363,7 +363,7 @@ def cached_files(\n             'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n         token (`str` or *bool*, *optional*):\n             The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-            when running `huggingface-cli login` (stored in `~/.huggingface`).\n+            when running `hf auth login` (stored in `~/.huggingface`).\n         revision (`str`, *optional*, defaults to `\"main\"`):\n             The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n             git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\n@@ -508,7 +508,7 @@ def cached_files(\n             raise OSError(\n                 f\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\n                 \"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\n-                \"having permission to this repo either by logging in with `huggingface-cli login` or by passing \"\n+                \"having permission to this repo either by logging in with `hf auth login` or by passing \"\n                 \"`token=<your_token>`\"\n             ) from e\n         elif isinstance(e, RevisionNotFoundError):\n@@ -699,7 +699,7 @@ def has_file(\n         raise OSError(\n             f\"{path_or_repo} is a gated repository. Make sure to request access at \"\n             f\"https://huggingface.co/{path_or_repo} and pass a token having permission to this repo either by \"\n-            \"logging in with `huggingface-cli login` or by passing `token=<your_token>`.\"\n+            \"logging in with `hf auth login` or by passing `token=<your_token>`.\"\n         ) from e\n     except RepositoryNotFoundError as e:\n         logger.error(e)\n@@ -873,7 +873,7 @@ def push_to_hub(\n                 Whether to make the repo private. If `None` (default), the repo will be public unless the organization's default is private. This value is ignored if the repo already exists.\n             token (`bool` or `str`, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-                when running `huggingface-cli login` (stored in `~/.huggingface`). Will default to `True` if `repo_url`\n+                when running `hf auth login` (stored in `~/.huggingface`). Will default to `True` if `repo_url`\n                 is not specified.\n             max_shard_size (`int` or `str`, *optional*, defaults to `\"5GB\"`):\n                 Only applicable for models. The maximum size for a checkpoint before being sharded. Checkpoints shard"
        },
        {
            "sha": "e3976acf168bee27583aa18510c1f0b28aeba00e",
            "filename": "src/transformers/utils/peft_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Futils%2Fpeft_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Futils%2Fpeft_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fpeft_utils.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -59,7 +59,7 @@ def find_adapter_config_file(\n             'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n         token (`str` or *bool*, *optional*):\n             The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n-            when running `huggingface-cli login` (stored in `~/.huggingface`).\n+            when running `hf auth login` (stored in `~/.huggingface`).\n         revision (`str`, *optional*, defaults to `\"main\"`):\n             The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n             git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any"
        },
        {
            "sha": "0db55024e6d2708eb1bf10de2c300936a9283cf7",
            "filename": "src/transformers/video_processing_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fvideo_processing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/src%2Ftransformers%2Fvideo_processing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fvideo_processing_utils.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -456,7 +456,7 @@ def from_pretrained(\n                 'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n             token (`str` or `bool`, *optional*):\n                 The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use\n-                the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).\n+                the token generated when running `hf auth login` (stored in `~/.huggingface`).\n             revision (`str`, *optional*, defaults to `\"main\"`):\n                 The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n                 git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any"
        },
        {
            "sha": "3cd69eb95630b6ab05161af9b75667400d49097d",
            "filename": "templates/adding_a_new_example_script/{{cookiecutter.directory_name}}/run_{{cookiecutter.example_shortcut}}.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/templates%2Fadding_a_new_example_script%2F%7B%7Bcookiecutter.directory_name%7D%7D%2Frun_%7B%7Bcookiecutter.example_shortcut%7D%7D.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/templates%2Fadding_a_new_example_script%2F%7B%7Bcookiecutter.directory_name%7D%7D%2Frun_%7B%7Bcookiecutter.example_shortcut%7D%7D.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/templates%2Fadding_a_new_example_script%2F%7B%7Bcookiecutter.directory_name%7D%7D%2Frun_%7B%7Bcookiecutter.example_shortcut%7D%7D.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -120,7 +120,7 @@ class ModelArguments:\n         metadata={\n             \"help\": (\n                 \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n-                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n+                \"generated when running `hf auth login` (stored in `~/.huggingface`).\"\n             )\n         },\n     )"
        },
        {
            "sha": "2b1a19b9ab257009d389717e1e22e628c93f1d5f",
            "filename": "tests/sagemaker/scripts/pytorch/run_glue_model_parallelism.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f90de364c2484c7c325bbe05befdcf487bd75b63/tests%2Fsagemaker%2Fscripts%2Fpytorch%2Frun_glue_model_parallelism.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f90de364c2484c7c325bbe05befdcf487bd75b63/tests%2Fsagemaker%2Fscripts%2Fpytorch%2Frun_glue_model_parallelism.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fsagemaker%2Fscripts%2Fpytorch%2Frun_glue_model_parallelism.py?ref=f90de364c2484c7c325bbe05befdcf487bd75b63",
            "patch": "@@ -180,7 +180,7 @@ class ModelArguments:\n         default=False,\n         metadata={\n             \"help\": (\n-                \"Will use the token generated when running `huggingface-cli login` (necessary to use this script \"\n+                \"Will use the token generated when running `hf auth login` (necessary to use this script \"\n                 \"with private models).\"\n             )\n         },"
        }
    ],
    "stats": {
        "total": 264,
        "additions": 132,
        "deletions": 132
    }
}