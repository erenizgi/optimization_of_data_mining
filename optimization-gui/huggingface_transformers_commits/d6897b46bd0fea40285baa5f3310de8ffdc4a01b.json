{
    "author": "sambhavnoobcoder",
    "message": "Add utility for Reload Transformers imports cache for development workflow #35508 (#35858)\n\n* Reload transformers fix form cache\n\n* add imports\n\n* add test fn for clearing import cache\n\n* ruff fix to core import logic\n\n* ruff fix to test file\n\n* fixup for imports\n\n* fixup for test\n\n* lru restore\n\n* test check\n\n* fix style changes\n\n* added documentation for usecase\n\n* fixing\n\n---------\n\nCo-authored-by: sambhavnoobcoder <indosambahv@gmail.com>",
    "sha": "d6897b46bd0fea40285baa5f3310de8ffdc4a01b",
    "files": [
        {
            "sha": "5e2aa8297bcfae71986009f179c4b874dfb64040",
            "filename": "docs/source/en/how_to_hack_models.md",
            "status": "modified",
            "additions": 31,
            "deletions": 1,
            "changes": 32,
            "blob_url": "https://github.com/huggingface/transformers/blob/d6897b46bd0fea40285baa5f3310de8ffdc4a01b/docs%2Fsource%2Fen%2Fhow_to_hack_models.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/d6897b46bd0fea40285baa5f3310de8ffdc4a01b/docs%2Fsource%2Fen%2Fhow_to_hack_models.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fhow_to_hack_models.md?ref=d6897b46bd0fea40285baa5f3310de8ffdc4a01b",
            "patch": "@@ -24,7 +24,37 @@ You'll learn how to:\n - Modify a model's architecture by changing its attention mechanism.\n - Apply techniques like Low-Rank Adaptation (LoRA) to specific model components.\n \n-We encourage you to contribute your own hacks and share them here with the community1\n+We encourage you to contribute your own hacks and share them here with the community!\n+\n+## Efficient Development Workflow\n+\n+When modifying model code, you'll often need to test your changes without restarting your Python session. The `clear_import_cache()` utility helps with this workflow, especially during model development and contribution when you need to frequently test and compare model outputs:\n+\n+```python\n+from transformers import AutoModel\n+model = AutoModel.from_pretrained(\"bert-base-uncased\")\n+\n+# Make modifications to the transformers code...\n+\n+# Clear the cache to reload the modified code\n+from transformers.utils.import_utils import clear_import_cache\n+clear_import_cache()\n+\n+# Reimport to get the changes\n+from transformers import AutoModel\n+model = AutoModel.from_pretrained(\"bert-base-uncased\")  # Will use updated code\n+```\n+\n+This is particularly useful when:\n+- Iteratively modifying model architectures\n+- Debugging model implementations \n+- Testing changes during model development\n+- Comparing outputs between original and modified versions\n+- Working on model contributions\n+\n+The `clear_import_cache()` function removes all cached Transformers modules and allows Python to reload the modified code. This enables rapid development cycles without constantly restarting your environment.\n+\n+This workflow is especially valuable when implementing new models, where you need to frequently compare outputs between the original implementation and your Transformers version (as described in the [Add New Model](https://huggingface.co/docs/transformers/add_new_model) guide).\n \n ## Example: Modifying the Attention Mechanism in the Segment Anything Model (SAM)\n "
        },
        {
            "sha": "41065a5d11cb8a6ac27f49960e1400588668e77a",
            "filename": "src/transformers/utils/import_utils.py",
            "status": "modified",
            "additions": 25,
            "deletions": 0,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/d6897b46bd0fea40285baa5f3310de8ffdc4a01b/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d6897b46bd0fea40285baa5f3310de8ffdc4a01b/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fimport_utils.py?ref=d6897b46bd0fea40285baa5f3310de8ffdc4a01b",
            "patch": "@@ -2271,3 +2271,28 @@ def define_import_structure(module_path: str) -> IMPORT_STRUCTURE_T:\n     \"\"\"\n     import_structure = create_import_structure_from_path(module_path)\n     return spread_import_structure(import_structure)\n+\n+\n+def clear_import_cache():\n+    \"\"\"\n+    Clear cached Transformers modules to allow reloading modified code.\n+\n+    This is useful when actively developing/modifying Transformers code.\n+    \"\"\"\n+    # Get all transformers modules\n+    transformers_modules = [mod_name for mod_name in sys.modules if mod_name.startswith(\"transformers.\")]\n+\n+    # Remove them from sys.modules\n+    for mod_name in transformers_modules:\n+        module = sys.modules[mod_name]\n+        # Clear _LazyModule caches if applicable\n+        if isinstance(module, _LazyModule):\n+            module._objects = {}  # Clear cached objects\n+        del sys.modules[mod_name]\n+\n+    # Force reload main transformers module\n+    if \"transformers\" in sys.modules:\n+        main_module = sys.modules[\"transformers\"]\n+        if isinstance(main_module, _LazyModule):\n+            main_module._objects = {}  # Clear cached objects\n+        importlib.reload(main_module)"
        },
        {
            "sha": "3d846174aca1db0ed56939d50b8f53615a9bbc8b",
            "filename": "tests/utils/test_import_utils.py",
            "status": "added",
            "additions": 23,
            "deletions": 0,
            "changes": 23,
            "blob_url": "https://github.com/huggingface/transformers/blob/d6897b46bd0fea40285baa5f3310de8ffdc4a01b/tests%2Futils%2Ftest_import_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d6897b46bd0fea40285baa5f3310de8ffdc4a01b/tests%2Futils%2Ftest_import_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_import_utils.py?ref=d6897b46bd0fea40285baa5f3310de8ffdc4a01b",
            "patch": "@@ -0,0 +1,23 @@\n+import sys\n+\n+from transformers.utils.import_utils import clear_import_cache\n+\n+\n+def test_clear_import_cache():\n+    # Import some transformers modules\n+\n+    # Get initial module count\n+    initial_modules = {name: mod for name, mod in sys.modules.items() if name.startswith(\"transformers.\")}\n+\n+    # Verify we have some modules loaded\n+    assert len(initial_modules) > 0\n+\n+    # Clear cache\n+    clear_import_cache()\n+\n+    # Check modules were removed\n+    remaining_modules = {name: mod for name, mod in sys.modules.items() if name.startswith(\"transformers.\")}\n+    assert len(remaining_modules) < len(initial_modules)\n+\n+    # Verify we can reimport\n+    assert \"transformers.models.auto.modeling_auto\" in sys.modules"
        }
    ],
    "stats": {
        "total": 80,
        "additions": 79,
        "deletions": 1
    }
}