{
    "author": "kaixuanliu",
    "message": "fix device dismatch issue for pe_audio_video model parallelism (#42917)\n\n* fix device dismatch issue for pe_audio_video model parallelism\n\nSigned-off-by: Liu, Kaixuan <kaixuan.liu@intel.com>\n\n* skip the model parallelism unit test\n\nSigned-off-by: Liu, Kaixuan <kaixuan.liu@intel.com>\n\n* update\n\nSigned-off-by: Liu, Kaixuan <kaixuan.liu@intel.com>\n\n* Set all padding_mask_videos to 1 to avoid NaN values in outputs\n\nSigned-off-by: Liu, Kaixuan <kaixuan.liu@intel.com>\n\n* fix bug\n\nSigned-off-by: Liu, Kaixuan <kaixuan.liu@intel.com>\n\n* keep at least 1 valid frame\n\nSigned-off-by: Liu, Kaixuan <kaixuan.liu@intel.com>\n\n* fix format issue\n\nSigned-off-by: Liu, Kaixuan <kaixuan.liu@intel.com>\n\n* use random.seed\n\nSigned-off-by: Liu, Kaixuan <kaixuan.liu@intel.com>\n\n* update code\n\nSigned-off-by: Liu, Kaixuan <kaixuan.liu@intel.com>\n\n---------\n\nSigned-off-by: Liu, Kaixuan <kaixuan.liu@intel.com>",
    "sha": "1b280f998a86a930db3ced9f7108316c671b2d8b",
    "files": [
        {
            "sha": "7603b71ec42259fdf7f5e87ceda4a01969ccde76",
            "filename": "src/transformers/models/timm_wrapper/modeling_timm_wrapper.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/1b280f998a86a930db3ced9f7108316c671b2d8b/src%2Ftransformers%2Fmodels%2Ftimm_wrapper%2Fmodeling_timm_wrapper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1b280f998a86a930db3ced9f7108316c671b2d8b/src%2Ftransformers%2Fmodels%2Ftimm_wrapper%2Fmodeling_timm_wrapper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftimm_wrapper%2Fmodeling_timm_wrapper.py?ref=1b280f998a86a930db3ced9f7108316c671b2d8b",
            "patch": "@@ -86,7 +86,8 @@ class TimmWrapperPreTrainedModel(PreTrainedModel):\n     main_input_name = \"pixel_values\"\n     input_modalities = (\"image\",)\n     config: TimmWrapperConfig\n-    _no_split_modules = []\n+    # add WA here as `timm` does not support model parallelism\n+    _no_split_modules = [\"TimmWrapperModel\"]\n     model_tags = [\"timm\"]\n \n     # used in Trainer to avoid passing `loss_kwargs` to model forward"
        },
        {
            "sha": "12dab67c842b99f94505b4252c0efb06bbf976af",
            "filename": "tests/models/pe_audio/test_modeling_pe_audio.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/1b280f998a86a930db3ced9f7108316c671b2d8b/tests%2Fmodels%2Fpe_audio%2Ftest_modeling_pe_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1b280f998a86a930db3ced9f7108316c671b2d8b/tests%2Fmodels%2Fpe_audio%2Ftest_modeling_pe_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpe_audio%2Ftest_modeling_pe_audio.py?ref=1b280f998a86a930db3ced9f7108316c671b2d8b",
            "patch": "@@ -101,7 +101,8 @@ def seq_length(self):\n \n     def prepare_config_and_inputs(self):\n         input_values = floats_tensor([self.batch_size, self.num_channels, self.audio_seq_length])\n-        valid_lengths = ids_tensor([self.batch_size], self.audio_seq_length)\n+        # Generate valid_lengths in range [1, self.audio_seq_length] to ensure at least one valid frame\n+        valid_lengths = ids_tensor([self.batch_size], self.audio_seq_length - 1) + 1\n         padding_mask = torch.arange(self.audio_seq_length, device=torch_device)[None, :] < valid_lengths[:, None]\n         padding_mask = padding_mask.int()\n         config = self.get_config()"
        },
        {
            "sha": "399f610dba14b73ca6f0a9ffce6e8862c43040d4",
            "filename": "tests/models/pe_audio_video/test_modeling_pe_audio_video.py",
            "status": "modified",
            "additions": 8,
            "deletions": 2,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/1b280f998a86a930db3ced9f7108316c671b2d8b/tests%2Fmodels%2Fpe_audio_video%2Ftest_modeling_pe_audio_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1b280f998a86a930db3ced9f7108316c671b2d8b/tests%2Fmodels%2Fpe_audio_video%2Ftest_modeling_pe_audio_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpe_audio_video%2Ftest_modeling_pe_audio_video.py?ref=1b280f998a86a930db3ced9f7108316c671b2d8b",
            "patch": "@@ -149,7 +149,8 @@ def seq_length(self):\n \n     def prepare_config_and_inputs(self):\n         input_values = floats_tensor([self.batch_size, self.num_audio_channels, self.audio_seq_length])\n-        valid_audio_lengths = ids_tensor([self.batch_size], self.audio_seq_length)\n+        # Generate valid_lengths in range [1, self.audio_seq_length] to ensure at least one valid frame\n+        valid_audio_lengths = ids_tensor([self.batch_size], self.audio_seq_length - 1) + 1\n         padding_mask = torch.arange(self.audio_seq_length, device=torch_device)[None, :] < valid_audio_lengths[:, None]\n         padding_mask = padding_mask.int()\n \n@@ -162,7 +163,8 @@ def prepare_config_and_inputs(self):\n                 self.config_kwargs[\"video_config\"][\"vision_config\"][\"model_args\"][\"img_size\"][1],\n             ]\n         )\n-        valid_video_lengths = ids_tensor([self.batch_size], self.num_frames)\n+        # Generate valid_lengths in range [1, self.num_frames] to ensure at least one valid frame\n+        valid_video_lengths = ids_tensor([self.batch_size], self.num_frames - 1) + 1\n         padding_mask_videos = (\n             torch.arange(self.num_frames, device=torch_device)[None, :] < valid_video_lengths[:, None]\n         )\n@@ -258,6 +260,10 @@ def test_feed_forward_chunking(self):\n     def test_save_load(self):\n         pass\n \n+    @unittest.skip(reason=\"TimmWrapperModel does not support model parallelism\")\n+    def test_model_parallelism(self):\n+        pass\n+\n     @unittest.skip(reason=\"@eustlb this is not really expected\")\n     def test_batching_equivalence(self):\n         pass"
        },
        {
            "sha": "7b3bc2a6e7b2144a5d993eabc570ef6e78a9b29a",
            "filename": "tests/models/pe_video/test_modeling_pe_video.py",
            "status": "modified",
            "additions": 7,
            "deletions": 4,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/1b280f998a86a930db3ced9f7108316c671b2d8b/tests%2Fmodels%2Fpe_video%2Ftest_modeling_pe_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1b280f998a86a930db3ced9f7108316c671b2d8b/tests%2Fmodels%2Fpe_video%2Ftest_modeling_pe_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpe_video%2Ftest_modeling_pe_video.py?ref=1b280f998a86a930db3ced9f7108316c671b2d8b",
            "patch": "@@ -103,10 +103,9 @@ def prepare_config_and_inputs(self):\n                 self.config_kwargs[\"vision_config\"][\"model_args\"][\"img_size\"][1],\n             ]\n         )\n-        valid_lengths = ids_tensor([self.batch_size], self.num_frames)\n-        padding_mask_videos = (\n-            torch.ones([self.batch_size, self.num_frames], device=torch_device) < valid_lengths[:, None]\n-        )\n+        # Generate valid_lengths in range [1, num_frames] to ensure at least one valid frame\n+        valid_lengths = ids_tensor([self.batch_size], self.num_frames - 1) + 1\n+        padding_mask_videos = torch.arange(self.num_frames, device=torch_device).unsqueeze(0) < valid_lengths[:, None]\n         padding_mask_videos = padding_mask_videos.int()\n         config = self.get_config()\n \n@@ -187,6 +186,10 @@ def test_feed_forward_chunking(self):\n     def test_save_load(self):\n         pass\n \n+    @unittest.skip(reason=\"TimmWrapperModel does not support model parallelism\")\n+    def test_model_parallelism(self):\n+        pass\n+\n     @unittest.skip(reason=\"@eustlb this is not really expected\")\n     def test_batching_equivalence(self):\n         pass"
        }
    ],
    "stats": {
        "total": 27,
        "additions": 19,
        "deletions": 8
    }
}