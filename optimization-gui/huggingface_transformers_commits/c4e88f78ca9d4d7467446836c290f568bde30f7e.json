{
    "author": "st81",
    "message": "Reduce warning noise caused by Tensor.new_tensor (#41748)",
    "sha": "c4e88f78ca9d4d7467446836c290f568bde30f7e",
    "files": [
        {
            "sha": "6944045ddd161fe90da26495636b6478fadf6c52",
            "filename": "src/transformers/models/encoder_decoder/modeling_encoder_decoder.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/c4e88f78ca9d4d7467446836c290f568bde30f7e/src%2Ftransformers%2Fmodels%2Fencoder_decoder%2Fmodeling_encoder_decoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c4e88f78ca9d4d7467446836c290f568bde30f7e/src%2Ftransformers%2Fmodels%2Fencoder_decoder%2Fmodeling_encoder_decoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fencoder_decoder%2Fmodeling_encoder_decoder.py?ref=c4e88f78ca9d4d7467446836c290f568bde30f7e",
            "patch": "@@ -450,7 +450,7 @@ def forward(\n                 labels, self.config.pad_token_id, self.config.decoder_start_token_id\n             )\n             if decoder_attention_mask is None:\n-                decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n+                decoder_attention_mask = (decoder_input_ids != self.config.pad_token_id).to(decoder_input_ids.dtype)\n \n         # Decode\n         decoder_outputs = self.decoder("
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}