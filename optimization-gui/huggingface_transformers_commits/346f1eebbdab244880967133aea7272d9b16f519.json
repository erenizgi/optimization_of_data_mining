{
    "author": "tonyksong",
    "message": "docs: fix typo (#37567)\n\nCo-authored-by: Anthony <anthony.song@capitalone.com>",
    "sha": "346f1eebbdab244880967133aea7272d9b16f519",
    "files": [
        {
            "sha": "3dd0845e671a7608cc034e72c696dc690c1ab311",
            "filename": "docs/source/en/perf_train_gpu_many.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/346f1eebbdab244880967133aea7272d9b16f519/docs%2Fsource%2Fen%2Fperf_train_gpu_many.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/346f1eebbdab244880967133aea7272d9b16f519/docs%2Fsource%2Fen%2Fperf_train_gpu_many.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fperf_train_gpu_many.md?ref=346f1eebbdab244880967133aea7272d9b16f519",
            "patch": "@@ -111,7 +111,7 @@ This approach optimizes parallel data processing by reducing idle GPU utilizatio\n \n Data, pipeline and model parallelism combine to form [3D parallelism](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/) to optimize memory and compute efficiency.\n \n-Memory effiiciency is achieved by splitting the model across GPUs and also dividing it into stages to create a pipeline. This allows GPUs to work in parallel on micro-batches of data, reducing the memory usage of the model, optimizer, and activations.\n+Memory efficiency is achieved by splitting the model across GPUs and also dividing it into stages to create a pipeline. This allows GPUs to work in parallel on micro-batches of data, reducing the memory usage of the model, optimizer, and activations.\n \n Compute efficiency is enabled by ZeRO data parallelism where each GPU only stores a slice of the model, optimizer, and activations. This allows higher communication bandwidth between data parallel nodes because communication can occur independently or in parallel with the other pipeline stages.\n "
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}