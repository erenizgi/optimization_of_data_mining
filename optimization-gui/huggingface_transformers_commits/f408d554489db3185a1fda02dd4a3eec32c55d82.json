{
    "author": "anferico",
    "message": "Fix bug when requesting input normalization with EnCodec (#34756)\n\n* EnCodec: unsqueeze padding mask\n\n* add test for normalization",
    "sha": "f408d554489db3185a1fda02dd4a3eec32c55d82",
    "files": [
        {
            "sha": "6fe658a7057fc3b10ed25f44e439952f5a27e90a",
            "filename": "src/transformers/models/encodec/modeling_encodec.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f408d554489db3185a1fda02dd4a3eec32c55d82/src%2Ftransformers%2Fmodels%2Fencodec%2Fmodeling_encodec.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f408d554489db3185a1fda02dd4a3eec32c55d82/src%2Ftransformers%2Fmodels%2Fencodec%2Fmodeling_encodec.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fencodec%2Fmodeling_encodec.py?ref=f408d554489db3185a1fda02dd4a3eec32c55d82",
            "patch": "@@ -576,7 +576,7 @@ def _encode_frame(\n         scale = None\n         if self.config.normalize:\n             # if the padding is non zero\n-            input_values = input_values * padding_mask\n+            input_values = input_values * padding_mask.unsqueeze(1)\n             mono = torch.sum(input_values, 1, keepdim=True) / input_values.shape[1]\n             scale = mono.pow(2).mean(dim=-1, keepdim=True).sqrt() + 1e-8\n             input_values = input_values / scale"
        },
        {
            "sha": "47931cbe45c0d9f94b7a47c561a28f0d96cc257f",
            "filename": "tests/models/encodec/test_modeling_encodec.py",
            "status": "modified",
            "additions": 19,
            "deletions": 4,
            "changes": 23,
            "blob_url": "https://github.com/huggingface/transformers/blob/f408d554489db3185a1fda02dd4a3eec32c55d82/tests%2Fmodels%2Fencodec%2Ftest_modeling_encodec.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f408d554489db3185a1fda02dd4a3eec32c55d82/tests%2Fmodels%2Fencodec%2Ftest_modeling_encodec.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fencodec%2Ftest_modeling_encodec.py?ref=f408d554489db3185a1fda02dd4a3eec32c55d82",
            "patch": "@@ -39,7 +39,7 @@\n if is_torch_available():\n     import torch\n \n-    from transformers import EncodecModel\n+    from transformers import EncodecFeatureExtractor, EncodecModel\n \n \n def prepare_inputs_dict(\n@@ -111,6 +111,19 @@ def prepare_config_and_inputs_for_model_class(self, model_class):\n \n         return config, inputs_dict\n \n+    def prepare_config_and_inputs_for_normalization(self):\n+        input_values = floats_tensor([self.batch_size, self.num_channels, self.intermediate_size], scale=1.0)\n+        config = self.get_config()\n+        config.normalize = True\n+\n+        processor = EncodecFeatureExtractor(feature_size=config.audio_channels, sampling_rate=config.sampling_rate)\n+        input_values = list(input_values.cpu().numpy())\n+        inputs_dict = processor(\n+            input_values, sampling_rate=config.sampling_rate, padding=True, return_tensors=\"pt\"\n+        ).to(torch_device)\n+\n+        return config, inputs_dict\n+\n     def get_config(self):\n         return EncodecConfig(\n             audio_channels=self.num_channels,\n@@ -125,9 +138,7 @@ def get_config(self):\n \n     def create_and_check_model_forward(self, config, inputs_dict):\n         model = EncodecModel(config=config).to(torch_device).eval()\n-\n-        input_values = inputs_dict[\"input_values\"]\n-        result = model(input_values)\n+        result = model(**inputs_dict)\n         self.parent.assertEqual(\n             result.audio_values.shape, (self.batch_size, self.num_channels, self.intermediate_size)\n         )\n@@ -435,6 +446,10 @@ def test_identity_shortcut(self):\n         config.use_conv_shortcut = False\n         self.model_tester.create_and_check_model_forward(config, inputs_dict)\n \n+    def test_model_forward_with_normalization(self):\n+        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_normalization()\n+        self.model_tester.create_and_check_model_forward(config, inputs_dict)\n+\n \n def normalize(arr):\n     norm = np.linalg.norm(arr)"
        }
    ],
    "stats": {
        "total": 25,
        "additions": 20,
        "deletions": 5
    }
}