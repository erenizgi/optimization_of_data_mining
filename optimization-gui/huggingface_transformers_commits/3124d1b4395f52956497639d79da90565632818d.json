{
    "author": "zucchini-nlp",
    "message": "[qwen-vl] fix beam search with videos (#39726)\n\n* fix\n\n* fix copies",
    "sha": "3124d1b4395f52956497639d79da90565632818d",
    "files": [
        {
            "sha": "1b3f673088133c61c9ddb6cae58688e36ebd775b",
            "filename": "src/transformers/models/glm4v/modeling_glm4v.py",
            "status": "modified",
            "additions": 3,
            "deletions": 8,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/3124d1b4395f52956497639d79da90565632818d/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3124d1b4395f52956497639d79da90565632818d/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py?ref=3124d1b4395f52956497639d79da90565632818d",
            "patch": "@@ -1614,14 +1614,9 @@ def _repeat_interleave_samples(x, lengths, repeat_times):\n                         dict_to_expand[key], lengths=lengths, repeat_times=expand_size\n                     )\n                 elif key == \"second_per_grid_ts\":\n-                    if not isinstance(dict_to_expand[key], list):\n-                        raise TypeError(\n-                            f\"Expected value for key '{key}' to be a list, but got {type(dict_to_expand[key])} instead.\"\n-                        )\n-                    tensor = torch.tensor(dict_to_expand[key])\n-                    lengths = list(video_nums)\n-                    tensor = _repeat_interleave_samples(tensor, lengths=lengths, repeat_times=expand_size)\n-                    dict_to_expand[key] = tensor.tolist()\n+                    dict_to_expand[key] = _repeat_interleave_samples(\n+                        dict_to_expand[key], lengths=list(video_nums), repeat_times=expand_size\n+                    )\n             return dict_to_expand\n \n         def _expand_dict_for_generation(dict_to_expand):"
        },
        {
            "sha": "84451b6b199eb34ebfab530d69ab373c57c39851",
            "filename": "src/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 8,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/3124d1b4395f52956497639d79da90565632818d/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3124d1b4395f52956497639d79da90565632818d/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py?ref=3124d1b4395f52956497639d79da90565632818d",
            "patch": "@@ -1713,14 +1713,9 @@ def _repeat_interleave_samples(x, lengths, repeat_times):\n                         dict_to_expand[key], lengths=lengths, repeat_times=expand_size\n                     )\n                 elif key == \"second_per_grid_ts\":\n-                    if not isinstance(dict_to_expand[key], list):\n-                        raise TypeError(\n-                            f\"Expected value for key '{key}' to be a list, but got {type(dict_to_expand[key])} instead.\"\n-                        )\n-                    tensor = torch.tensor(dict_to_expand[key])\n-                    lengths = list(video_nums)\n-                    tensor = _repeat_interleave_samples(tensor, lengths=lengths, repeat_times=expand_size)\n-                    dict_to_expand[key] = tensor.tolist()\n+                    dict_to_expand[key] = _repeat_interleave_samples(\n+                        dict_to_expand[key], lengths=list(video_nums), repeat_times=expand_size\n+                    )\n             return dict_to_expand\n \n         def _expand_dict_for_generation(dict_to_expand):"
        },
        {
            "sha": "ea4ddbbcadacaea416de3f16c5a6288414c7051a",
            "filename": "src/transformers/models/qwen2_vl/modeling_qwen2_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 8,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/3124d1b4395f52956497639d79da90565632818d/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3124d1b4395f52956497639d79da90565632818d/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py?ref=3124d1b4395f52956497639d79da90565632818d",
            "patch": "@@ -1599,14 +1599,9 @@ def _repeat_interleave_samples(x, lengths, repeat_times):\n                         dict_to_expand[key], lengths=lengths, repeat_times=expand_size\n                     )\n                 elif key == \"second_per_grid_ts\":\n-                    if not isinstance(dict_to_expand[key], list):\n-                        raise TypeError(\n-                            f\"Expected value for key '{key}' to be a list, but got {type(dict_to_expand[key])} instead.\"\n-                        )\n-                    tensor = torch.tensor(dict_to_expand[key])\n-                    lengths = list(video_nums)\n-                    tensor = _repeat_interleave_samples(tensor, lengths=lengths, repeat_times=expand_size)\n-                    dict_to_expand[key] = tensor.tolist()\n+                    dict_to_expand[key] = _repeat_interleave_samples(\n+                        dict_to_expand[key], lengths=list(video_nums), repeat_times=expand_size\n+                    )\n             return dict_to_expand\n \n         def _expand_dict_for_generation(dict_to_expand):"
        }
    ],
    "stats": {
        "total": 33,
        "additions": 9,
        "deletions": 24
    }
}