{
    "author": "qubvel",
    "message": "[typing] better return type hint for `AutoModelForCausalLM` and `AutoModelForImageTextToText` (#39881)\n\n* Better return type hint for  AutoModelForCausalLM and AutoModelForImageTextToText\n\n* fix imports\n\n* fix",
    "sha": "7dca2ff8cfd6102430acd3af3fdc3831b9779884",
    "files": [
        {
            "sha": "2fbdb36b390c9228af1c25d69b69fde1fbaf744d",
            "filename": "src/transformers/models/auto/modeling_auto.py",
            "status": "modified",
            "additions": 31,
            "deletions": 0,
            "changes": 31,
            "blob_url": "https://github.com/huggingface/transformers/blob/7dca2ff8cfd6102430acd3af3fdc3831b9779884/src%2Ftransformers%2Fmodels%2Fauto%2Fmodeling_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7dca2ff8cfd6102430acd3af3fdc3831b9779884/src%2Ftransformers%2Fmodels%2Fauto%2Fmodeling_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fmodeling_auto.py?ref=7dca2ff8cfd6102430acd3af3fdc3831b9779884",
            "patch": "@@ -14,8 +14,10 @@\n # limitations under the License.\n \"\"\"Auto Model class.\"\"\"\n \n+import os\n import warnings\n from collections import OrderedDict\n+from typing import TYPE_CHECKING, Union\n \n from ...utils import logging\n from .auto_factory import (\n@@ -27,6 +29,15 @@\n from .configuration_auto import CONFIG_MAPPING_NAMES\n \n \n+if TYPE_CHECKING:\n+    from ...generation import GenerationMixin\n+    from ...modeling_utils import PreTrainedModel\n+\n+    # class for better type annotations\n+    class _BaseModelWithGenerate(PreTrainedModel, GenerationMixin):\n+        pass\n+\n+\n logger = logging.get_logger(__name__)\n \n MODEL_MAPPING_NAMES = OrderedDict(\n@@ -1863,6 +1874,16 @@ class _AutoModelWithLMHead(_BaseAutoModelClass):\n class AutoModelForCausalLM(_BaseAutoModelClass):\n     _model_mapping = MODEL_FOR_CAUSAL_LM_MAPPING\n \n+    # override to give better return typehint\n+    @classmethod\n+    def from_pretrained(\n+        cls: type[\"AutoModelForCausalLM\"],\n+        pretrained_model_name_or_path: Union[str, os.PathLike[str]],\n+        *model_args,\n+        **kwargs,\n+    ) -> \"_BaseModelWithGenerate\":\n+        return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n+\n \n AutoModelForCausalLM = auto_class_update(AutoModelForCausalLM, head_doc=\"causal language modeling\")\n \n@@ -2057,6 +2078,16 @@ class _AutoModelForVision2Seq(_BaseAutoModelClass):\n class AutoModelForImageTextToText(_BaseAutoModelClass):\n     _model_mapping = MODEL_FOR_IMAGE_TEXT_TO_TEXT_MAPPING\n \n+    # override to give better return typehint\n+    @classmethod\n+    def from_pretrained(\n+        cls: type[\"AutoModelForImageTextToText\"],\n+        pretrained_model_name_or_path: Union[str, os.PathLike[str]],\n+        *model_args,\n+        **kwargs,\n+    ) -> \"_BaseModelWithGenerate\":\n+        return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n+\n \n AutoModelForImageTextToText = auto_class_update(AutoModelForImageTextToText, head_doc=\"image-text-to-text modeling\")\n "
        }
    ],
    "stats": {
        "total": 31,
        "additions": 31,
        "deletions": 0
    }
}