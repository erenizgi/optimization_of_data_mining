{
    "author": "npuichigo",
    "message": "Update no split modules in T5Gemma model (#40810)\n\n* Update no split modules in T5Gemma model\n\n* Update no_split_modules also for T5Gemma modular\n\n* Remove model_split_percents from test cases\n\n---------\n\nCo-authored-by: Anton Vlasjuk <73884904+vasqu@users.noreply.github.com>",
    "sha": "797859c9b8f81abd12102dfdee7ad5f974509cc0",
    "files": [
        {
            "sha": "ba023447c2bcd5a1280b0972e523493ad7746953",
            "filename": "src/transformers/models/t5gemma/modeling_t5gemma.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/797859c9b8f81abd12102dfdee7ad5f974509cc0/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodeling_t5gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/797859c9b8f81abd12102dfdee7ad5f974509cc0/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodeling_t5gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodeling_t5gemma.py?ref=797859c9b8f81abd12102dfdee7ad5f974509cc0",
            "patch": "@@ -585,7 +585,7 @@ class T5GemmaPreTrainedModel(PreTrainedModel):\n     config: T5GemmaConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n-    _no_split_modules = [\"T5GemmaBlock\"]\n+    _no_split_modules = [\"T5GemmaEncoderLayer\", \"T5GemmaDecoderLayer\"]\n     _skip_keys_device_placement = [\"past_key_values\"]\n     _supports_flash_attn = True\n     _supports_sdpa = True"
        },
        {
            "sha": "4ac42d99239cfcc72fdce3f37b3c3856f38de4cb",
            "filename": "src/transformers/models/t5gemma/modular_t5gemma.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/797859c9b8f81abd12102dfdee7ad5f974509cc0/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodular_t5gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/797859c9b8f81abd12102dfdee7ad5f974509cc0/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodular_t5gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ft5gemma%2Fmodular_t5gemma.py?ref=797859c9b8f81abd12102dfdee7ad5f974509cc0",
            "patch": "@@ -476,7 +476,7 @@ class T5GemmaPreTrainedModel(Gemma2PreTrainedModel):\n     config: T5GemmaConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n-    _no_split_modules = [\"T5GemmaBlock\"]\n+    _no_split_modules = [\"T5GemmaEncoderLayer\", \"T5GemmaDecoderLayer\"]\n \n     def _init_weights(self, module):\n         # TODO: support initialization for encoders and decoders separately(?)"
        },
        {
            "sha": "6a94ff93ea23be4bcc48666f746ef9fb44b5b047",
            "filename": "tests/models/t5gemma/test_modeling_t5gemma.py",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/797859c9b8f81abd12102dfdee7ad5f974509cc0/tests%2Fmodels%2Ft5gemma%2Ftest_modeling_t5gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/797859c9b8f81abd12102dfdee7ad5f974509cc0/tests%2Fmodels%2Ft5gemma%2Ftest_modeling_t5gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ft5gemma%2Ftest_modeling_t5gemma.py?ref=797859c9b8f81abd12102dfdee7ad5f974509cc0",
            "patch": "@@ -597,7 +597,6 @@ class T5GemmaModelTest(ModelTesterMixin, GenerationTesterMixin, PipelineTesterMi\n     test_pruning = False\n     _is_stateful = True\n     is_encoder_decoder = True\n-    model_split_percents = [0.5, 0.6]\n \n     # used in `test_torch_compile_for_training`\n     _torch_compile_train_cls = T5GemmaForConditionalGeneration if is_torch_available() else None\n@@ -1460,7 +1459,6 @@ class T5GemmaEncoderOnlyModelTest(ModelTesterMixin, unittest.TestCase):\n     test_headmasking = False\n     _is_stateful = True\n     is_encoder_decoder = False\n-    model_split_percents = [0.4, 0.5]\n \n     # won't fix\n     test_torchscript = False"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 2,
        "deletions": 4
    }
}