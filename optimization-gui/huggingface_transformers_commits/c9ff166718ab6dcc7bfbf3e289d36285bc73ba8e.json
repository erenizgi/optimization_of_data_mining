{
    "author": "remi-or",
    "message": "Various AMD expectations (#40510)\n\n* AMD expectations for qwen2\n\n* Added more detailled excpectation to smolvlm\n\n* Added AMD expectations to TableTransformer\n\n* Style",
    "sha": "c9ff166718ab6dcc7bfbf3e289d36285bc73ba8e",
    "files": [
        {
            "sha": "f85ec2dcdfa3f429a9519178af7efd5d408d7e4b",
            "filename": "tests/models/qwen2/test_modeling_qwen2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/c9ff166718ab6dcc7bfbf3e289d36285bc73ba8e/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c9ff166718ab6dcc7bfbf3e289d36285bc73ba8e/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py?ref=c9ff166718ab6dcc7bfbf3e289d36285bc73ba8e",
            "patch": "@@ -256,6 +256,9 @@ def test_export_static_cache(self):\n             (\"cuda\", 8): [\n                 \"My favourite condiment is 100% natural, organic, gluten free, vegan, and vegetarian. I love to use\"\n             ],\n+            (\"rocm\", (9, 4)): [\n+                \"My favourite condiment is 100% natural, organic and vegan. I love to use it in my cooking, but\"\n+            ],\n             (\"rocm\", (9, 5)): [\n                 \"My favourite condiment is 100% natural, organic, gluten free, vegan, and vegetarian. I love to use\"\n             ]"
        },
        {
            "sha": "e6e38eb10534610a28580d7d33019e3724a0e521",
            "filename": "tests/models/smolvlm/test_modeling_smolvlm.py",
            "status": "modified",
            "additions": 7,
            "deletions": 11,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/c9ff166718ab6dcc7bfbf3e289d36285bc73ba8e/tests%2Fmodels%2Fsmolvlm%2Ftest_modeling_smolvlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c9ff166718ab6dcc7bfbf3e289d36285bc73ba8e/tests%2Fmodels%2Fsmolvlm%2Ftest_modeling_smolvlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsmolvlm%2Ftest_modeling_smolvlm.py?ref=c9ff166718ab6dcc7bfbf3e289d36285bc73ba8e",
            "patch": "@@ -583,19 +583,15 @@ def test_integration_test_video(self):\n         generated_ids = model.generate(**inputs, max_new_tokens=20)\n         generated_texts = self.processor.batch_decode(generated_ids, skip_special_tokens=True)\n \n-        expected_generated_strings = Expectations(\n+        expected_generated_text = Expectations(\n             {\n-                (None, None): 'User: You are provided the following series of nine frames from a 0:00:09 [H:MM:SS] video.\\n\\nFrame from 00:00:\\nFrame from 00:01:\\nFrame from 00:02:\\nFrame from 00:03:\\nFrame from 00:04:\\nFrame from 00:05:\\nFrame from 00:06:\\nFrame from 00:08:\\nFrame from 00:09:\\n\\nDescribe this video in detail\\nAssistant: The video depicts a large language model architecture, specifically a language model with a \"quick brown\" feature',  # fmt: skip\n-                (\"cuda\", (8, 0)): 'User: You are provided the following series of nine frames from a 0:00:09 [H:MM:SS] video.\\n\\nFrame from 00:00:\\nFrame from 00:01:\\nFrame from 00:02:\\nFrame from 00:03:\\nFrame from 00:04:\\nFrame from 00:05:\\nFrame from 00:06:\\nFrame from 00:08:\\nFrame from 00:09:\\n\\nDescribe this video in detail\\nAssistant: The video showcases a large language model architecture, specifically a \"Quick Brown\" model, which is designed',  # fmt: skip\n-                (\"cuda\", (8, 6)): 'User: You are provided the following series of nine frames from a 0:00:09 [H:MM:SS] video.\\n\\nFrame from 00:00:\\nFrame from 00:01:\\nFrame from 00:02:\\nFrame from 00:03:\\nFrame from 00:04:\\nFrame from 00:05:\\nFrame from 00:06:\\nFrame from 00:08:\\nFrame from 00:09:\\n\\nDescribe this video in detail\\nAssistant: The video showcases a large language model, specifically a neural network model, which is designed to learn and',  # fmt: skip\n-                (\"rocm\", None): 'User: You are provided the following series of nine frames from a 0:00:09 [H:MM:SS] video.\\n\\nFrame from 00:00:\\nFrame from 00:01:\\nFrame from 00:02:\\nFrame from 00:03:\\nFrame from 00:04:\\nFrame from 00:05:\\nFrame from 00:06:\\nFrame from 00:08:\\nFrame from 00:09:\\n\\nDescribe this video in detail\\nAssistant: The video showcases a large language model architecture, specifically a \"Quick Brown\" model, which is designed',  # fmt: skip\n+                (None, None): 'User: You are provided the following series of nine frames from a 0:00:09 [H:MM:SS] video.\\n\\nFrame from 00:00:\\nFrame from 00:01:\\nFrame from 00:02:\\nFrame from 00:03:\\nFrame from 00:04:\\nFrame from 00:05:\\nFrame from 00:06:\\nFrame from 00:08:\\nFrame from 00:09:\\n\\nDescribe this video in detail\\nAssistant: The video depicts a large language model architecture, specifically a language model with a \"quick brown\" feature',\n+                (\"cuda\", (8, 0)): 'User: You are provided the following series of nine frames from a 0:00:09 [H:MM:SS] video.\\n\\nFrame from 00:00:\\nFrame from 00:01:\\nFrame from 00:02:\\nFrame from 00:03:\\nFrame from 00:04:\\nFrame from 00:05:\\nFrame from 00:06:\\nFrame from 00:08:\\nFrame from 00:09:\\n\\nDescribe this video in detail\\nAssistant: The video showcases a large language model architecture, specifically a \"Quick Brown\" model, which is designed',\n+                (\"cuda\", (8, 6)): 'User: You are provided the following series of nine frames from a 0:00:09 [H:MM:SS] video.\\n\\nFrame from 00:00:\\nFrame from 00:01:\\nFrame from 00:02:\\nFrame from 00:03:\\nFrame from 00:04:\\nFrame from 00:05:\\nFrame from 00:06:\\nFrame from 00:08:\\nFrame from 00:09:\\n\\nDescribe this video in detail\\nAssistant: The video showcases a large language model, specifically a neural network model, which is designed to learn and',\n+                (\"rocm\", (9, 4)): 'User: You are provided the following series of nine frames from a 0:00:09 [H:MM:SS] video.\\n\\nFrame from 00:00:\\nFrame from 00:01:\\nFrame from 00:02:\\nFrame from 00:03:\\nFrame from 00:04:\\nFrame from 00:05:\\nFrame from 00:06:\\nFrame from 00:08:\\nFrame from 00:09:\\n\\nDescribe this video in detail\\nAssistant: The video depicts a large language model architecture, specifically a language model with a \"quick brown\" feature',\n+                (\"rocm\", None): 'User: You are provided the following series of nine frames from a 0:00:09 [H:MM:SS] video.\\n\\nFrame from 00:00:\\nFrame from 00:01:\\nFrame from 00:02:\\nFrame from 00:03:\\nFrame from 00:04:\\nFrame from 00:05:\\nFrame from 00:06:\\nFrame from 00:08:\\nFrame from 00:09:\\n\\nDescribe this video in detail\\nAssistant: The video showcases a large language model architecture, specifically a \"Quick Brown\" model, which is designed',\n             }\n-        )  # fmt: skip\n-\n-        expected_generated_text = expected_generated_strings.get_expectation()\n-\n-        print(f\"Generated text: {generated_texts[0]}\")\n-\n+        ).get_expectation()  # fmt: skip\n         self.assertEqual(generated_texts[0], expected_generated_text)\n \n     @slow"
        },
        {
            "sha": "7d4eb4be4bb8f3d9c60c5824d9874bd087a665b3",
            "filename": "tests/models/table_transformer/test_modeling_table_transformer.py",
            "status": "modified",
            "additions": 13,
            "deletions": 8,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/c9ff166718ab6dcc7bfbf3e289d36285bc73ba8e/tests%2Fmodels%2Ftable_transformer%2Ftest_modeling_table_transformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c9ff166718ab6dcc7bfbf3e289d36285bc73ba8e/tests%2Fmodels%2Ftable_transformer%2Ftest_modeling_table_transformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ftable_transformer%2Ftest_modeling_table_transformer.py?ref=c9ff166718ab6dcc7bfbf3e289d36285bc73ba8e",
            "patch": "@@ -20,7 +20,7 @@\n from huggingface_hub import hf_hub_download\n \n from transformers import ResNetConfig, TableTransformerConfig, is_torch_available, is_vision_available\n-from transformers.testing_utils import require_timm, require_torch, require_vision, slow, torch_device\n+from transformers.testing_utils import Expectations, require_timm, require_torch, require_vision, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor\n@@ -591,13 +591,18 @@ def test_table_detection(self):\n         expected_shape = (1, 15, 3)\n         self.assertEqual(outputs.logits.shape, expected_shape)\n \n-        expected_logits = torch.tensor(\n-            [[-6.7329, -16.9590, 6.7447], [-8.0038, -22.3071, 6.9288], [-7.2445, -20.9855, 7.3465]],\n-            device=torch_device,\n-        )\n+        expected_logits_data = Expectations({\n+            (\"cuda\", None): [[-6.7329, -16.9590, 6.7447], [-8.0038, -22.3071, 6.9288], [-7.2445, -20.9855, 7.3465]],\n+            (\"rocm\", (9, 4)): [[-6.7668, -16.9917, 6.7738], [-8.0046, -22.2668, 6.9491], [-7.2834, -21.0321, 7.3785]],\n+        }).get_expectation()  # fmt: skip\n+\n+        expected_logits = torch.tensor(expected_logits_data, device=torch_device)\n         torch.testing.assert_close(outputs.logits[0, :3, :3], expected_logits, rtol=1e-4, atol=1e-4)\n \n-        expected_boxes = torch.tensor(\n-            [[0.4868, 0.1764, 0.6729], [0.6674, 0.4621, 0.3864], [0.4720, 0.1757, 0.6362]], device=torch_device\n-        )\n+        expected_boxes_data = Expectations({\n+            (\"cuda\", None): [[0.4868, 0.1764, 0.6729], [0.6674, 0.4621, 0.3864], [0.4720, 0.1757, 0.6362]],\n+            (\"rocm\", (9, 4)): [[0.4868, 0.1766, 0.6732], [0.6686, 0.4526, 0.3859], [0.4717, 0.1760, 0.6362]],\n+        }).get_expectation()  # fmt: skip\n+\n+        expected_boxes = torch.tensor(expected_boxes_data, device=torch_device)\n         torch.testing.assert_close(outputs.pred_boxes[0, :3, :3], expected_boxes, rtol=1e-3, atol=1e-3)"
        }
    ],
    "stats": {
        "total": 42,
        "additions": 23,
        "deletions": 19
    }
}