{
    "author": "zucchini-nlp",
    "message": "Fix typo in LFM-VL (#41742)\n\noops, remove untrelated commits",
    "sha": "ce4ffeeb6c39a9e7e2e62e23606d0b83b9a49b96",
    "files": [
        {
            "sha": "8872b3b1eebf7b970277a42e9a05598de38df2b0",
            "filename": "src/transformers/generation/utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce4ffeeb6c39a9e7e2e62e23606d0b83b9a49b96/src%2Ftransformers%2Fgeneration%2Futils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce4ffeeb6c39a9e7e2e62e23606d0b83b9a49b96/src%2Ftransformers%2Fgeneration%2Futils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Futils.py?ref=ce4ffeeb6c39a9e7e2e62e23606d0b83b9a49b96",
            "patch": "@@ -1941,7 +1941,7 @@ def _supports_default_dynamic_cache(cls) -> bool:\n                 \"minimax\",\n                 \"xlnet\",\n                 \"lfm2\",\n-                \"lfm2-vl\",\n+                \"lfm2_vl\",\n             ]\n         )\n "
        },
        {
            "sha": "8b9aa335c86198fd66c269c2013f49ab52fa7b02",
            "filename": "src/transformers/models/lfm2_vl/configuration_lfm2_vl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce4ffeeb6c39a9e7e2e62e23606d0b83b9a49b96/src%2Ftransformers%2Fmodels%2Flfm2_vl%2Fconfiguration_lfm2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce4ffeeb6c39a9e7e2e62e23606d0b83b9a49b96/src%2Ftransformers%2Fmodels%2Flfm2_vl%2Fconfiguration_lfm2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flfm2_vl%2Fconfiguration_lfm2_vl.py?ref=ce4ffeeb6c39a9e7e2e62e23606d0b83b9a49b96",
            "patch": "@@ -50,7 +50,7 @@ class Lfm2VlConfig(PreTrainedConfig):\n             The downsample_factor factor of the vision backbone.\n     \"\"\"\n \n-    model_type = \"lfm2-vl\"\n+    model_type = \"lfm2_vl\"\n     sub_configs = {\"text_config\": AutoConfig, \"vision_config\": AutoConfig}\n \n     def __init__("
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}