{
    "author": "peteryschneider",
    "message": "fix: ImageTextToTextPipeline handles user-defined generation_config (#39374)\n\nfix: ImageTextToTextPipeline handles user-defined generation_config passed to the pipeline\n\nCo-authored-by: Raushan Turganbay <raushan@huggingface.co>",
    "sha": "7fd60047c8fac34d15cfd9044737dce536afe576",
    "files": [
        {
            "sha": "c18378cd0df05e351a859323e715ec998d75ddb9",
            "filename": "src/transformers/pipelines/image_text_to_text.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/7fd60047c8fac34d15cfd9044737dce536afe576/src%2Ftransformers%2Fpipelines%2Fimage_text_to_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7fd60047c8fac34d15cfd9044737dce536afe576/src%2Ftransformers%2Fpipelines%2Fimage_text_to_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fimage_text_to_text.py?ref=7fd60047c8fac34d15cfd9044737dce536afe576",
            "patch": "@@ -422,6 +422,11 @@ def _forward(self, model_inputs, generate_kwargs=None):\n         input_ids = (\n             model_inputs[\"input_ids\"] if \"input_ids\" in model_inputs else model_inputs[\"decoder_input_ids\"]\n         )  # for decoder-only models\n+\n+        # User-defined `generation_config` passed to the pipeline call take precedence\n+        if \"generation_config\" not in generate_kwargs:\n+            generate_kwargs[\"generation_config\"] = self.generation_config\n+\n         generated_sequence = self.model.generate(**model_inputs, **generate_kwargs)\n \n         return {\"generated_sequence\": generated_sequence, \"prompt_text\": prompt_text, \"input_ids\": input_ids}"
        }
    ],
    "stats": {
        "total": 5,
        "additions": 5,
        "deletions": 0
    }
}