{
    "author": "ydshieh",
    "message": "Avoid check expected exception when it is on CUDA (#34408)\n\n* update\r\n\r\n* update\r\n\r\n---------\r\n\r\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "f73f5e62e2383c1cb6975fca70082d6dc51ec6f2",
    "files": [
        {
            "sha": "613b9dca8e1a71fd84836278706ab43fd4e1b360",
            "filename": "tests/pipelines/test_pipelines_summarization.py",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/f73f5e62e2383c1cb6975fca70082d6dc51ec6f2/tests%2Fpipelines%2Ftest_pipelines_summarization.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f73f5e62e2383c1cb6975fca70082d6dc51ec6f2/tests%2Fpipelines%2Ftest_pipelines_summarization.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_summarization.py?ref=f73f5e62e2383c1cb6975fca70082d6dc51ec6f2",
            "patch": "@@ -85,8 +85,9 @@ def run_pipeline_test(self, summarizer, _):\n                 and len(summarizer.model.trainable_weights) > 0\n                 and \"GPU\" in summarizer.model.trainable_weights[0].device\n             ):\n-                with self.assertRaises(Exception):\n-                    outputs = summarizer(\"This \" * 1000)\n+                if str(summarizer.device) == \"cpu\":\n+                    with self.assertRaises(Exception):\n+                        outputs = summarizer(\"This \" * 1000)\n         outputs = summarizer(\"This \" * 1000, truncation=TruncationStrategy.ONLY_FIRST)\n \n     @require_torch"
        },
        {
            "sha": "51f3cae5e31235d2ad5f6e353d2cb448f3743a2d",
            "filename": "tests/pipelines/test_pipelines_text_generation.py",
            "status": "modified",
            "additions": 10,
            "deletions": 8,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/f73f5e62e2383c1cb6975fca70082d6dc51ec6f2/tests%2Fpipelines%2Ftest_pipelines_text_generation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f73f5e62e2383c1cb6975fca70082d6dc51ec6f2/tests%2Fpipelines%2Ftest_pipelines_text_generation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_text_generation.py?ref=f73f5e62e2383c1cb6975fca70082d6dc51ec6f2",
            "patch": "@@ -493,17 +493,19 @@ def run_pipeline_test(self, text_generator, _):\n             and text_generator.model.__class__.__name__ not in EXTRA_MODELS_CAN_HANDLE_LONG_INPUTS\n         ):\n             # Handling of large generations\n-            with self.assertRaises((RuntimeError, IndexError, ValueError, AssertionError)):\n-                text_generator(\"This is a test\" * 500, max_new_tokens=20)\n+            if str(text_generator.device) == \"cpu\":\n+                with self.assertRaises((RuntimeError, IndexError, ValueError, AssertionError)):\n+                    text_generator(\"This is a test\" * 500, max_new_tokens=20)\n \n             outputs = text_generator(\"This is a test\" * 500, handle_long_generation=\"hole\", max_new_tokens=20)\n             # Hole strategy cannot work\n-            with self.assertRaises(ValueError):\n-                text_generator(\n-                    \"This is a test\" * 500,\n-                    handle_long_generation=\"hole\",\n-                    max_new_tokens=tokenizer.model_max_length + 10,\n-                )\n+            if str(text_generator.device) == \"cpu\":\n+                with self.assertRaises(ValueError):\n+                    text_generator(\n+                        \"This is a test\" * 500,\n+                        handle_long_generation=\"hole\",\n+                        max_new_tokens=tokenizer.model_max_length + 10,\n+                    )\n \n     @require_torch\n     @require_accelerate"
        }
    ],
    "stats": {
        "total": 23,
        "additions": 13,
        "deletions": 10
    }
}