{
    "author": "regisss",
    "message": "Enable modular files from other libraries (#41372)\n\nCo-authored-by: Cyril Vallez <cyril.vallez@gmail.com>",
    "sha": "d7c9fbdb64842c541eebeaf0b11d1883ccf10be4",
    "files": [
        {
            "sha": "b815932cf2e8b128f6c1af3904d14d7e4e1d8500",
            "filename": "utils/modular_integrations.py",
            "status": "added",
            "additions": 185,
            "deletions": 0,
            "changes": 185,
            "blob_url": "https://github.com/huggingface/transformers/blob/d7c9fbdb64842c541eebeaf0b11d1883ccf10be4/utils%2Fmodular_integrations.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d7c9fbdb64842c541eebeaf0b11d1883ccf10be4/utils%2Fmodular_integrations.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fmodular_integrations.py?ref=d7c9fbdb64842c541eebeaf0b11d1883ccf10be4",
            "patch": "@@ -0,0 +1,185 @@\n+import os\n+from typing import Optional\n+\n+import libcst as cst\n+\n+\n+# Files from external libraries that should not be tracked\n+# E.g. for habana, we don't want to track the dependencies from `modeling_all_models.py` as it is not part of the transformers library\n+EXCLUDED_EXTERNAL_FILES = {\n+    \"habana\": [{\"name\": \"modeling_all_models\", \"type\": \"modeling\"}],\n+}\n+\n+\n+def convert_relative_import_to_absolute(\n+    import_node: cst.ImportFrom,\n+    file_path: str,\n+    package_name: Optional[str] = \"transformers\",\n+) -> cst.ImportFrom:\n+    \"\"\"\n+    Convert a relative libcst.ImportFrom node into an absolute one,\n+    using the file path and package name.\n+\n+    Args:\n+        import_node: A relative import node (e.g. `from ..utils import helper`)\n+        file_path: Path to the file containing the import (can be absolute or relative)\n+        package_name: The top-level package name (e.g. 'myproject')\n+\n+    Returns:\n+        A new ImportFrom node with the absolute import path\n+    \"\"\"\n+    if not (import_node.relative and len(import_node.relative) > 0):\n+        return import_node  # Already absolute\n+\n+    file_path = os.path.abspath(file_path)\n+    rel_level = len(import_node.relative)\n+\n+    # Strip file extension and split into parts\n+    file_path_no_ext = file_path[:-3] if file_path.endswith(\".py\") else file_path\n+    file_parts = file_path_no_ext.split(os.path.sep)\n+\n+    # Ensure the file path includes the package name\n+    if package_name not in file_parts:\n+        raise ValueError(f\"Package name '{package_name}' not found in file path '{file_path}'\")\n+\n+    # Slice file_parts starting from the package name\n+    pkg_index = file_parts.index(package_name)\n+    module_parts = file_parts[pkg_index + 1 :]  # e.g. ['module', 'submodule', 'foo']\n+    if len(module_parts) < rel_level:\n+        raise ValueError(f\"Relative import level ({rel_level}) goes beyond package root.\")\n+\n+    base_parts = module_parts[:-rel_level]\n+\n+    # Flatten the module being imported (if any)\n+    def flatten_module(module: Optional[cst.BaseExpression]) -> list[str]:\n+        if not module:\n+            return []\n+        if isinstance(module, cst.Name):\n+            return [module.value]\n+        elif isinstance(module, cst.Attribute):\n+            parts = []\n+            while isinstance(module, cst.Attribute):\n+                parts.insert(0, module.attr.value)\n+                module = module.value\n+            if isinstance(module, cst.Name):\n+                parts.insert(0, module.value)\n+            return parts\n+        return []\n+\n+    import_parts = flatten_module(import_node.module)\n+\n+    # Combine to get the full absolute import path\n+    full_parts = [package_name] + base_parts + import_parts\n+\n+    # Handle special case where the import comes from a namespace package (e.g. optimum with `optimum.habana`, `optimum.intel` instead of `src.optimum`)\n+    if package_name != \"transformers\" and file_parts[pkg_index - 1] != \"src\":\n+        full_parts = [file_parts[pkg_index - 1]] + full_parts\n+\n+    # Build the dotted module path\n+    dotted_module: Optional[cst.BaseExpression] = None\n+    for part in full_parts:\n+        name = cst.Name(part)\n+        dotted_module = name if dotted_module is None else cst.Attribute(value=dotted_module, attr=name)\n+\n+    # Return a new ImportFrom node with absolute import\n+    return import_node.with_changes(module=dotted_module, relative=[])\n+\n+\n+def convert_to_relative_import(import_node: cst.ImportFrom, file_path: str, package_name: str) -> cst.ImportFrom:\n+    \"\"\"\n+    Convert an absolute import to a relative one if it belongs to `package_name`.\n+\n+    Parameters:\n+    - node: The ImportFrom node to possibly transform.\n+    - file_path: Absolute path to the file containing the import (e.g., '/path/to/mypackage/foo/bar.py').\n+    - package_name: The top-level package name (e.g., 'mypackage').\n+\n+    Returns:\n+    - A possibly modified ImportFrom node.\n+    \"\"\"\n+    if import_node.relative:\n+        return import_node  # Already relative import\n+\n+    # Extract module name string from ImportFrom\n+    def get_module_name(module):\n+        if isinstance(module, cst.Name):\n+            return module.value, [module.value]\n+        elif isinstance(module, cst.Attribute):\n+            parts = []\n+            while isinstance(module, cst.Attribute):\n+                parts.append(module.attr.value)\n+                module = module.value\n+            if isinstance(module, cst.Name):\n+                parts.append(module.value)\n+            parts.reverse()\n+            return \".\".join(parts), parts\n+        return \"\", None\n+\n+    module_name, submodule_list = get_module_name(import_node.module)\n+\n+    # Check if it's from the target package\n+    if (\n+        not (module_name.startswith(package_name + \".\") or module_name.startswith(\"optimum.\" + package_name + \".\"))\n+        and module_name != package_name\n+    ):\n+        return import_node  # Not from target package\n+\n+    # Locate the package root inside the file path\n+    norm_file_path = os.path.normpath(file_path)\n+    parts = norm_file_path.split(os.sep)\n+\n+    try:\n+        pkg_index = parts.index(package_name)\n+    except ValueError:\n+        # Package name not found in path â€” assume we can't resolve relative depth\n+        return import_node\n+\n+    # Depth is how many directories after the package name before the current file\n+    depth = len(parts) - pkg_index - 1  # exclude the .py file itself\n+    for i, submodule in enumerate(parts[pkg_index + 1 :]):\n+        if submodule == submodule_list[2 + i]:\n+            depth -= 1\n+        else:\n+            break\n+\n+    # Create the correct number of dots\n+    relative = [cst.Dot()] * depth if depth > 0 else [cst.Dot()]\n+\n+    # Strip package prefix from import module path\n+    if module_name.startswith(\"optimum.\" + package_name + \".\"):\n+        stripped_name = module_name[len(\"optimum.\" + package_name) :].lstrip(\".\")\n+    else:\n+        stripped_name = module_name[len(package_name) :].lstrip(\".\")\n+\n+    # Build new module node\n+    if stripped_name == \"\":\n+        new_module = None\n+    else:\n+        name_parts = stripped_name.split(\".\")[i:]\n+        new_module = cst.Name(name_parts[0])\n+        for part in name_parts[1:]:\n+            new_module = cst.Attribute(value=new_module, attr=cst.Name(part))\n+\n+    return import_node.with_changes(module=new_module, relative=relative)\n+\n+\n+class AbsoluteImportTransformer(cst.CSTTransformer):\n+    def __init__(self, relative_path: str, source_library: str):\n+        super().__init__()\n+        self.relative_path = relative_path\n+        self.source_library = source_library\n+\n+    def leave_ImportFrom(self, original_node: cst.ImportFrom, updated_node: cst.ImportFrom) -> cst.ImportFrom:\n+        return convert_relative_import_to_absolute(\n+            import_node=updated_node, file_path=self.relative_path, package_name=self.source_library\n+        )\n+\n+\n+class RelativeImportTransformer(cst.CSTTransformer):\n+    def __init__(self, relative_path: str, source_library: str):\n+        super().__init__()\n+        self.relative_path = relative_path\n+        self.source_library = source_library\n+\n+    def leave_ImportFrom(self, original_node: cst.ImportFrom, updated_node: cst.ImportFrom) -> cst.ImportFrom:\n+        return convert_to_relative_import(updated_node, self.relative_path, self.source_library)"
        },
        {
            "sha": "44bb32ce362de06b74545baf65013b9ad15e1d19",
            "filename": "utils/modular_model_converter.py",
            "status": "modified",
            "additions": 87,
            "deletions": 14,
            "changes": 101,
            "blob_url": "https://github.com/huggingface/transformers/blob/d7c9fbdb64842c541eebeaf0b11d1883ccf10be4/utils%2Fmodular_model_converter.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d7c9fbdb64842c541eebeaf0b11d1883ccf10be4/utils%2Fmodular_model_converter.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fmodular_model_converter.py?ref=d7c9fbdb64842c541eebeaf0b11d1883ccf10be4",
            "patch": "@@ -21,13 +21,20 @@\n import subprocess\n from abc import ABC, abstractmethod\n from collections import Counter, defaultdict, deque\n+from functools import partial\n from typing import Optional, Union\n \n import libcst as cst\n from create_dependency_mapping import find_priority_list\n from libcst import ClassDef, CSTVisitor\n from libcst import matchers as m\n from libcst.metadata import MetadataWrapper, ParentNodeProvider, PositionProvider, ScopeProvider\n+from modular_integrations import (\n+    EXCLUDED_EXTERNAL_FILES,\n+    AbsoluteImportTransformer,\n+    RelativeImportTransformer,\n+    convert_relative_import_to_absolute,\n+)\n \n from transformers import logging\n from transformers.models.auto.configuration_auto import CONFIG_MAPPING_NAMES\n@@ -1204,7 +1211,7 @@ class ModularFileMapper(ModuleMapper):\n     Calling the method `create_modules()` after visit will create all modules based on this modular file.\n     \"\"\"\n \n-    def __init__(self, python_module, new_name):\n+    def __init__(self, python_module, new_name, package_name):\n         super().__init__(python_module)\n         # fmt: off\n         self.model_name = new_name  # name of the model being defined. Should be in the format of `llama` or `layout_xlm` or `phi3`\n@@ -1213,6 +1220,8 @@ def __init__(self, python_module, new_name):\n         self.model_specific_modules: dict[str, cst.Module] = {}  # e.g. {\"transformers.models.llama.modeling_llama\": cst.Module}\n \n         self.all_all_to_add = {}\n+\n+        self.excluded_external_files = {} if package_name == \"transformers\" else EXCLUDED_EXTERNAL_FILES[package_name]\n         # fmt: on\n \n     def visit_ImportFrom(self, node: cst.ImportFrom) -> None:\n@@ -1225,6 +1234,9 @@ def visit_ImportFrom(self, node: cst.ImportFrom) -> None:\n             return\n         if m.matches(node.module, m.Attribute()):\n             for imported_ in node.names:\n+                # If we match here, it's an import from 3rd party lib that we need to skip\n+                if any(external_file[\"name\"] in import_statement for external_file in self.excluded_external_files):\n+                    continue\n                 _import = re.search(\n                     rf\"(?:transformers\\.models\\.)|(?:\\.\\.\\.models\\.)|(?:\\.\\.)\\w+\\.({self.match_patterns}).*\",\n                     import_statement,\n@@ -1274,7 +1286,9 @@ def visit_SimpleStatementLine(self, node):\n             elif m.matches(node, m.SimpleStatementLine(body=[m.ImportFrom()])):\n                 import_module = self.python_module.code_for_node(node.body[0].module)\n                 import_statement = \".\" * len(node.body[0].relative) + import_module\n-                if not (\n+                if any(\n+                    external_file[\"name\"] in import_statement for external_file in self.excluded_external_files\n+                ) or not (\n                     re.search(rf\"(?:transformers\\.models\\.)|(?:\\.\\.)\\w+\\.({self.match_patterns}).*\", import_statement)\n                     and not any(import_to_skip in import_statement for import_to_skip in IMPORTS_TO_SKIP_IN_MODULAR)\n                 ):\n@@ -1339,6 +1353,14 @@ def leave_Module(self, node):\n         self.imported_objects_per_file = defaultdict(set)\n         for file, mapper in self.visited_modules.items():\n             file_type = re.search(rf\"^transformers\\.models\\.\\w+\\.({self.match_patterns})\", file).group(1)\n+\n+            # If there are excluded external files, override the file type if there is a match\n+            if self.excluded_external_files:\n+                for excluded_file in self.excluded_external_files:\n+                    if file.split(\".\")[-1] == excluded_file[\"name\"]:\n+                        file_type = excluded_file[\"type\"]\n+                        break\n+\n             self.imported_objects_per_file[file_type].update(mapper.objects_imported_from_modeling)\n \n     def merge_model_specific_imports(self, visited_modules):\n@@ -1362,7 +1384,7 @@ def merge_model_specific_imports(self, visited_modules):\n                             self.functions[dep] = visited_module.global_nodes[dep]\n \n                 # Add/overwrite the imported functions to other visited modules as well, in case it is absent/different\n-                # in he modeling source file of the inherited class. See `examples/modular-tranformers/modular_switch_function.py`\n+                # in the modeling source file of the inherited class. See `examples/modular-tranformers/modular_switch_function.py`\n                 # and `examples/modular-tranformers/modular_add_function.py` for examples\n                 recursive_dependencies = visited_module.object_recursive_dependency_mapping.get(object_name, set())\n                 node_recursive_dependencies_mapping = {\n@@ -1635,7 +1657,11 @@ class node based on the inherited classes if needed. Also returns any new import\n     return nodes_to_add, file_type, new_imports\n \n \n-def create_modules(modular_mapper: ModularFileMapper) -> dict[str, cst.Module]:\n+def create_modules(\n+    modular_mapper: ModularFileMapper,\n+    file_path: Optional[str] = None,\n+    package_name: Optional[str] = \"transformers\",\n+) -> dict[str, cst.Module]:\n     \"\"\"Create all the new modules based on visiting the modular file. It replaces all classes as necessary.\"\"\"\n     files = defaultdict(dict)\n     current_file_indices = defaultdict(lambda: 0)\n@@ -1644,6 +1670,19 @@ def create_modules(modular_mapper: ModularFileMapper) -> dict[str, cst.Module]:\n     for class_name, node in modular_mapper.classes.items():\n         nodes_to_add, file_type, new_imports = get_class_node_and_dependencies(modular_mapper, class_name, node, files)\n \n+        if package_name != \"transformers\":\n+            # New imports involve new files like configuration_xxx.py, etc\n+            # Those are imported with relative imports by default in the modeling file\n+            # Since relative imports are Transformers imports at this point in the code, convert them to absolute imports from the source library (e.g. optimum-habana)\n+            for key, new_import in new_imports.items():\n+                new_imports[key] = new_import.with_changes(\n+                    body=[\n+                        convert_relative_import_to_absolute(\n+                            import_node=new_import.body[0], file_path=file_path, package_name=package_name\n+                        )\n+                    ]\n+                )\n+\n         # Add the new potential new imports that we may need to the `modular_mapper` variable\n         modular_mapper.imported_objects_per_file[file_type].update(new_imports.keys())\n         modular_mapper.imports.extend(list(new_imports.values()))\n@@ -1682,6 +1721,15 @@ def create_modules(modular_mapper: ModularFileMapper) -> dict[str, cst.Module]:\n     for file, body in files.items():\n         new_body = [k[1][\"node\"] for k in sorted(body.items(), key=lambda x: x[1][\"insert_idx\"])]\n         needed_imports = get_needed_imports(body, all_imports)\n+\n+        if package_name != \"transformers\":\n+            # Convert all transformers relative imports to absolute ones\n+            for imp in needed_imports:\n+                if m.matches(imp, m.SimpleStatementLine(body=[m.ImportFrom()])):\n+                    imp.body[0] = convert_relative_import_to_absolute(\n+                        import_node=imp.body[0], file_path=file_path, package_name=\"transformers\"\n+                    )\n+\n         full_module = needed_imports + new_body\n         new_module = cst.Module(body=full_module, header=modular_mapper.python_module.header)\n         files[file] = new_module\n@@ -1699,7 +1747,7 @@ def run_ruff(code, check=False):\n     return stdout.decode()\n \n \n-def convert_modular_file(modular_file: str) -> dict[str, str]:\n+def convert_modular_file(modular_file: str, source_library: Optional[str] = \"transformers\") -> dict[str, str]:\n     \"\"\"Convert a `modular_file` into all the different model-specific files it depicts.\"\"\"\n     pattern = re.search(r\"modular_(.*)(?=\\.py$)\", modular_file)\n     output = {}\n@@ -1709,15 +1757,34 @@ def convert_modular_file(modular_file: str) -> dict[str, str]:\n         with open(modular_file, \"r\", encoding=\"utf-8\") as file:\n             code = file.read()\n         module = cst.parse_module(code)\n+\n+        # Get relative path starting from src/transformers/\n+        if source_library != \"transformers\":\n+            relative_path = os.path.abspath(modular_file).replace(\"\\\\\", \"/\")\n+        else:\n+            relative_path = re.search(\n+                r\"(src/transformers/.*|examples/.*)\", os.path.abspath(modular_file).replace(\"\\\\\", \"/\")\n+            )\n+            if relative_path is None:\n+                raise ValueError(\n+                    f\"Cannot find the relative path of {modular_file} inside this `transformers` repository. If this modular file is located in another repository and you would like to generate the modeling file there, use the `--external` flag.\"\n+                )\n+            relative_path = relative_path.group(1)\n+\n+        # Convert all source library relative imports to absolute ones\n+        if source_library != \"transformers\":\n+            module = module.visit(AbsoluteImportTransformer(relative_path, source_library))\n+\n         wrapper = MetadataWrapper(module)\n-        cst_transformers = ModularFileMapper(module, model_name)\n+        cst_transformers = ModularFileMapper(module, model_name, source_library)\n         wrapper.visit(cst_transformers)\n-        for file, module in create_modules(cst_transformers).items():\n+        for file, module in create_modules(\n+            cst_transformers, file_path=relative_path, package_name=source_library\n+        ).items():\n             if module != {}:\n-                # Get relative path starting from src/transformers/\n-                relative_path = re.search(\n-                    r\"(src/transformers/.*|examples/.*)\", os.path.abspath(modular_file).replace(\"\\\\\", \"/\")\n-                ).group(1)\n+                if source_library != \"transformers\":\n+                    # Convert back all absolute imports from the source library to relative ones\n+                    module = module.visit(RelativeImportTransformer(relative_path, source_library))\n \n                 header = AUTO_GENERATED_MESSAGE.format(\n                     relative_path=relative_path, short_name=os.path.basename(relative_path)\n@@ -1751,10 +1818,10 @@ def count_loc(file_path: str) -> int:\n     return len([line for line in comment_less_code.split(\"\\n\") if line.strip()])\n \n \n-def run_converter(modular_file: str):\n+def run_converter(modular_file: str, source_library: Optional[str] = \"transformers\"):\n     \"\"\"Convert a modular file, and save resulting files.\"\"\"\n     print(f\"Converting {modular_file} to a single model single file format\")\n-    converted_files = convert_modular_file(modular_file)\n+    converted_files = convert_modular_file(modular_file, source_library=source_library)\n     save_modeling_files(modular_file, converted_files)\n \n     model_directory = os.path.dirname(modular_file)\n@@ -1801,6 +1868,12 @@ def run_converter(modular_file: str):\n         type=int,\n         help=\"The number of workers to use. Default is -1, which means the number of CPU cores.\",\n     )\n+    parser.add_argument(\n+        \"--source-library\",\n+        type=str,\n+        default=\"transformers\",\n+        help=\"The top-level package name (default: 'transformers')\",\n+    )\n     args = parser.parse_args()\n     # Both arg represent the same data, but as positional and optional\n     files_to_parse = args.files if len(args.files) > 0 else args.files_to_parse\n@@ -1835,4 +1908,4 @@ def run_converter(modular_file: str):\n         # Process files with diff\n         workers = min(num_workers, len(dependency_level_files))\n         with mp.Pool(workers) as pool:\n-            pool.map(run_converter, dependency_level_files)\n+            pool.map(partial(run_converter, source_library=args.source_library), dependency_level_files)"
        }
    ],
    "stats": {
        "total": 286,
        "additions": 272,
        "deletions": 14
    }
}