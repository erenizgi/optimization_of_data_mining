{
    "author": "dmdaksh",
    "message": "Add Fast Image Processor for MobileNetV1  (#37111)\n\n* fast image processor template for MobileNetV1 via transformers-cli\n\n* Add fast image processors and unify tests for slow/fast image processor classes\n\n* added loop over image_processor_list for all tests and removed boilerplate comments.\n\n---------\n\nCo-authored-by: Yoni Gozlan <74535834+yonigozlan@users.noreply.github.com>",
    "sha": "b6d65e40b256d98d9621707762b94bc8ad83b7a7",
    "files": [
        {
            "sha": "3f3d04aa5f5bcae51dd1d283bf2a64f9bcd95e5e",
            "filename": "docs/source/en/model_doc/mobilenet_v1.md",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/b6d65e40b256d98d9621707762b94bc8ad83b7a7/docs%2Fsource%2Fen%2Fmodel_doc%2Fmobilenet_v1.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/b6d65e40b256d98d9621707762b94bc8ad83b7a7/docs%2Fsource%2Fen%2Fmodel_doc%2Fmobilenet_v1.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fmobilenet_v1.md?ref=b6d65e40b256d98d9621707762b94bc8ad83b7a7",
            "patch": "@@ -77,6 +77,11 @@ If you're interested in submitting a resource to be included here, please feel f\n [[autodoc]] MobileNetV1ImageProcessor\n     - preprocess\n \n+## MobileNetV1ImageProcessorFast\n+\n+[[autodoc]] MobileNetV1ImageProcessorFast\n+    - preprocess\n+\n ## MobileNetV1Model\n \n [[autodoc]] MobileNetV1Model"
        },
        {
            "sha": "79b13f1f4a262e44793b4a7891e27f3f8cff420f",
            "filename": "src/transformers/models/auto/image_processing_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/b6d65e40b256d98d9621707762b94bc8ad83b7a7/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b6d65e40b256d98d9621707762b94bc8ad83b7a7/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py?ref=b6d65e40b256d98d9621707762b94bc8ad83b7a7",
            "patch": "@@ -117,7 +117,7 @@\n             (\"mistral3\", (\"PixtralImageProcessor\", \"PixtralImageProcessorFast\")),\n             (\"mlcd\", (\"CLIPImageProcessor\", \"CLIPImageProcessorFast\")),\n             (\"mllama\", (\"MllamaImageProcessor\",)),\n-            (\"mobilenet_v1\", (\"MobileNetV1ImageProcessor\",)),\n+            (\"mobilenet_v1\", (\"MobileNetV1ImageProcessor\", \"MobileNetV1ImageProcessorFast\")),\n             (\"mobilenet_v2\", (\"MobileNetV2ImageProcessor\", \"MobileNetV2ImageProcessorFast\")),\n             (\"mobilevit\", (\"MobileViTImageProcessor\",)),\n             (\"mobilevitv2\", (\"MobileViTImageProcessor\",)),"
        },
        {
            "sha": "bce83216c35546fe01cf96c738cbe9c2f3582486",
            "filename": "src/transformers/models/mobilenet_v1/__init__.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/b6d65e40b256d98d9621707762b94bc8ad83b7a7/src%2Ftransformers%2Fmodels%2Fmobilenet_v1%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b6d65e40b256d98d9621707762b94bc8ad83b7a7/src%2Ftransformers%2Fmodels%2Fmobilenet_v1%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilenet_v1%2F__init__.py?ref=b6d65e40b256d98d9621707762b94bc8ad83b7a7",
            "patch": "@@ -21,6 +21,7 @@\n     from .configuration_mobilenet_v1 import *\n     from .feature_extraction_mobilenet_v1 import *\n     from .image_processing_mobilenet_v1 import *\n+    from .image_processing_mobilenet_v1_fast import *\n     from .modeling_mobilenet_v1 import *\n else:\n     import sys"
        },
        {
            "sha": "2da7a1be7942effe465860acae069c02a1c29163",
            "filename": "src/transformers/models/mobilenet_v1/image_processing_mobilenet_v1_fast.py",
            "status": "added",
            "additions": 47,
            "deletions": 0,
            "changes": 47,
            "blob_url": "https://github.com/huggingface/transformers/blob/b6d65e40b256d98d9621707762b94bc8ad83b7a7/src%2Ftransformers%2Fmodels%2Fmobilenet_v1%2Fimage_processing_mobilenet_v1_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b6d65e40b256d98d9621707762b94bc8ad83b7a7/src%2Ftransformers%2Fmodels%2Fmobilenet_v1%2Fimage_processing_mobilenet_v1_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilenet_v1%2Fimage_processing_mobilenet_v1_fast.py?ref=b6d65e40b256d98d9621707762b94bc8ad83b7a7",
            "patch": "@@ -0,0 +1,47 @@\n+# coding=utf-8\n+# Copyright 2025 The HuggingFace Inc. team. All rights reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\"\"\"Fast Image processor class for MobileNetV1.\"\"\"\n+\n+from ...image_processing_utils_fast import (\n+    BASE_IMAGE_PROCESSOR_FAST_DOCSTRING,\n+    BaseImageProcessorFast,\n+    DefaultFastImageProcessorKwargs,\n+    Unpack,\n+)\n+from ...image_utils import IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD, PILImageResampling\n+from ...utils import add_start_docstrings\n+\n+\n+@add_start_docstrings(\n+    \"Constructs a fast MobileNetV1 image processor.\",\n+    BASE_IMAGE_PROCESSOR_FAST_DOCSTRING,\n+)\n+class MobileNetV1ImageProcessorFast(BaseImageProcessorFast):\n+    resample = PILImageResampling.BILINEAR\n+    image_mean = IMAGENET_STANDARD_MEAN\n+    image_std = IMAGENET_STANDARD_STD\n+    size = {\"shortest_edge\": 256}\n+    default_to_square = False\n+    crop_size = {\"height\": 224, \"width\": 224}\n+    do_resize = True\n+    do_center_crop = True\n+    do_rescale = True\n+    do_normalize = True\n+\n+    def __init__(self, **kwargs: Unpack[DefaultFastImageProcessorKwargs]) -> None:\n+        super().__init__(**kwargs)\n+\n+\n+__all__ = [\"MobileNetV1ImageProcessorFast\"]"
        },
        {
            "sha": "93d2b5da40b3fffb1e5f9912383bd903241af292",
            "filename": "tests/models/mobilenet_v1/test_image_processing_mobilenet_v1.py",
            "status": "modified",
            "additions": 19,
            "deletions": 13,
            "changes": 32,
            "blob_url": "https://github.com/huggingface/transformers/blob/b6d65e40b256d98d9621707762b94bc8ad83b7a7/tests%2Fmodels%2Fmobilenet_v1%2Ftest_image_processing_mobilenet_v1.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b6d65e40b256d98d9621707762b94bc8ad83b7a7/tests%2Fmodels%2Fmobilenet_v1%2Ftest_image_processing_mobilenet_v1.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmobilenet_v1%2Ftest_image_processing_mobilenet_v1.py?ref=b6d65e40b256d98d9621707762b94bc8ad83b7a7",
            "patch": "@@ -16,14 +16,17 @@\n import unittest\n \n from transformers.testing_utils import require_torch, require_vision\n-from transformers.utils import is_vision_available\n+from transformers.utils import is_torchvision_available, is_vision_available\n \n from ...test_image_processing_common import ImageProcessingTestMixin, prepare_image_inputs\n \n \n if is_vision_available():\n     from transformers import MobileNetV1ImageProcessor\n \n+    if is_torchvision_available():\n+        from transformers import MobileNetV1ImageProcessorFast\n+\n \n class MobileNetV1ImageProcessingTester:\n     def __init__(\n@@ -79,6 +82,7 @@ def prepare_image_inputs(self, equal_resolution=False, numpify=False, torchify=F\n @require_vision\n class MobileNetV1ImageProcessingTest(ImageProcessingTestMixin, unittest.TestCase):\n     image_processing_class = MobileNetV1ImageProcessor if is_vision_available() else None\n+    fast_image_processing_class = MobileNetV1ImageProcessorFast if is_torchvision_available() else None\n \n     def setUp(self):\n         super().setUp()\n@@ -89,17 +93,19 @@ def image_processor_dict(self):\n         return self.image_processor_tester.prepare_image_processor_dict()\n \n     def test_image_processor_properties(self):\n-        image_processing = self.image_processing_class(**self.image_processor_dict)\n-        self.assertTrue(hasattr(image_processing, \"do_resize\"))\n-        self.assertTrue(hasattr(image_processing, \"size\"))\n-        self.assertTrue(hasattr(image_processing, \"do_center_crop\"))\n-        self.assertTrue(hasattr(image_processing, \"center_crop\"))\n+        for image_processing_class in self.image_processor_list:\n+            image_processing = image_processing_class(**self.image_processor_dict)\n+            self.assertTrue(hasattr(image_processing, \"do_resize\"))\n+            self.assertTrue(hasattr(image_processing, \"size\"))\n+            self.assertTrue(hasattr(image_processing, \"do_center_crop\"))\n+            self.assertTrue(hasattr(image_processing, \"center_crop\"))\n \n     def test_image_processor_from_dict_with_kwargs(self):\n-        image_processor = self.image_processing_class.from_dict(self.image_processor_dict)\n-        self.assertEqual(image_processor.size, {\"shortest_edge\": 20})\n-        self.assertEqual(image_processor.crop_size, {\"height\": 18, \"width\": 18})\n-\n-        image_processor = self.image_processing_class.from_dict(self.image_processor_dict, size=42, crop_size=84)\n-        self.assertEqual(image_processor.size, {\"shortest_edge\": 42})\n-        self.assertEqual(image_processor.crop_size, {\"height\": 84, \"width\": 84})\n+        for image_processing_class in self.image_processor_list:\n+            image_processor = image_processing_class.from_dict(self.image_processor_dict)\n+            self.assertEqual(image_processor.size, {\"shortest_edge\": 20})\n+            self.assertEqual(image_processor.crop_size, {\"height\": 18, \"width\": 18})\n+\n+            image_processor = image_processing_class.from_dict(self.image_processor_dict, size=42, crop_size=84)\n+            self.assertEqual(image_processor.size, {\"shortest_edge\": 42})\n+            self.assertEqual(image_processor.crop_size, {\"height\": 84, \"width\": 84})"
        }
    ],
    "stats": {
        "total": 87,
        "additions": 73,
        "deletions": 14
    }
}