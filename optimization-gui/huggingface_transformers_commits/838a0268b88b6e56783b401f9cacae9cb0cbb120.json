{
    "author": "ydshieh",
    "message": "fix flaky `test_generate_compile_model_forward` (#39276)\n\nfix\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "838a0268b88b6e56783b401f9cacae9cb0cbb120",
    "files": [
        {
            "sha": "e01b1ac50bc6637c91fe28bd745722480cf80f21",
            "filename": "tests/generation/test_utils.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/838a0268b88b6e56783b401f9cacae9cb0cbb120/tests%2Fgeneration%2Ftest_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/838a0268b88b6e56783b401f9cacae9cb0cbb120/tests%2Fgeneration%2Ftest_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fgeneration%2Ftest_utils.py?ref=838a0268b88b6e56783b401f9cacae9cb0cbb120",
            "patch": "@@ -2088,14 +2088,17 @@ def test_generate_compile_model_forward(self):\n \n         ⚠️ Runs two sequential generations to ensure the cache doesn't get stuck after the first compiled run! ⚠️\n         \"\"\"\n+        set_model_tester_for_less_flaky_test(self)\n         for model_class in self.all_generative_model_classes:\n             # 1. Test exclusion criteria\n             if not model_class._supports_static_cache:\n                 self.skipTest(\"This model doesn't support static cache (= no expectations of compilation support)\")\n \n             # 2. Prepares two sets of inputs\n             config, inputs_dict = self.prepare_config_and_inputs_for_generate(batch_size=4)\n+            set_config_for_less_flaky_test(config)\n             model = model_class(config).to(torch_device)\n+            set_model_for_less_flaky_test(model)\n             model.eval()  # otherwise `self.training` is `True` -- this flag is used at attn mask creation time\n \n             # Some composite models have a custom generate and will call an inner model's generate -> that inner model"
        }
    ],
    "stats": {
        "total": 3,
        "additions": 3,
        "deletions": 0
    }
}