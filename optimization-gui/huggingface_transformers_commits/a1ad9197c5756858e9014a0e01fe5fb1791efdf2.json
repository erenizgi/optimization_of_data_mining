{
    "author": "yonigozlan",
    "message": "Fix overriding Fast Image/Video Processors instance attributes affect other instances (#39363)\n\n* fix and add tests\n\n* nit",
    "sha": "a1ad9197c5756858e9014a0e01fe5fb1791efdf2",
    "files": [
        {
            "sha": "4f7865b2c99a6c189478ab59f9fe707a1c732bb2",
            "filename": "src/transformers/image_processing_utils_fast.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/a1ad9197c5756858e9014a0e01fe5fb1791efdf2/src%2Ftransformers%2Fimage_processing_utils_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a1ad9197c5756858e9014a0e01fe5fb1791efdf2/src%2Ftransformers%2Fimage_processing_utils_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fimage_processing_utils_fast.py?ref=a1ad9197c5756858e9014a0e01fe5fb1791efdf2",
            "patch": "@@ -13,6 +13,7 @@\n # limitations under the License.\n \n from collections.abc import Iterable\n+from copy import deepcopy\n from functools import lru_cache, partial\n from typing import Any, Optional, TypedDict, Union\n \n@@ -229,7 +230,7 @@ def __init__(\n             if kwarg is not None:\n                 setattr(self, key, kwarg)\n             else:\n-                setattr(self, key, getattr(self, key, None))\n+                setattr(self, key, deepcopy(getattr(self, key, None)))\n \n         # get valid kwargs names\n         self._valid_kwargs_names = list(self.valid_kwargs.__annotations__.keys())"
        },
        {
            "sha": "715912846cdb86017423672332819bfb46015b6f",
            "filename": "src/transformers/video_processing_utils.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/a1ad9197c5756858e9014a0e01fe5fb1791efdf2/src%2Ftransformers%2Fvideo_processing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a1ad9197c5756858e9014a0e01fe5fb1791efdf2/src%2Ftransformers%2Fvideo_processing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fvideo_processing_utils.py?ref=a1ad9197c5756858e9014a0e01fe5fb1791efdf2",
            "patch": "@@ -13,10 +13,10 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-import copy\n import json\n import os\n import warnings\n+from copy import deepcopy\n from typing import Any, Optional, Union\n \n import numpy as np\n@@ -202,7 +202,7 @@ def __init__(self, **kwargs: Unpack[VideosKwargs]) -> None:\n             if kwargs.get(key) is not None:\n                 setattr(self, key, kwargs[key])\n             else:\n-                setattr(self, key, getattr(self, key, None))\n+                setattr(self, key, deepcopy(getattr(self, key, None)))\n \n     def __call__(self, videos, **kwargs) -> BatchFeature:\n         return self.preprocess(videos, **kwargs)\n@@ -774,7 +774,7 @@ def to_dict(self) -> dict[str, Any]:\n         Returns:\n             `dict[str, Any]`: Dictionary of all the attributes that make up this video processor instance.\n         \"\"\"\n-        output = copy.deepcopy(self.__dict__)\n+        output = deepcopy(self.__dict__)\n         output.pop(\"model_valid_processing_keys\", None)\n         output.pop(\"_valid_kwargs_names\", None)\n         output[\"video_processor_type\"] = self.__class__.__name__"
        },
        {
            "sha": "8f159045e68c63e6208c98e1842c9364b15070d8",
            "filename": "tests/test_image_processing_common.py",
            "status": "modified",
            "additions": 38,
            "deletions": 1,
            "changes": 39,
            "blob_url": "https://github.com/huggingface/transformers/blob/a1ad9197c5756858e9014a0e01fe5fb1791efdf2/tests%2Ftest_image_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a1ad9197c5756858e9014a0e01fe5fb1791efdf2/tests%2Ftest_image_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_image_processing_common.py?ref=a1ad9197c5756858e9014a0e01fe5fb1791efdf2",
            "patch": "@@ -19,6 +19,7 @@\n import tempfile\n import time\n import warnings\n+from copy import deepcopy\n \n import numpy as np\n import requests\n@@ -559,6 +560,43 @@ def test_image_processor_preprocess_arguments(self):\n         if not is_tested:\n             self.skipTest(reason=\"No validation found for `preprocess` method\")\n \n+    def test_override_instance_attributes_does_not_affect_other_instances(self):\n+        if self.fast_image_processing_class is None:\n+            self.skipTest(\n+                \"Only testing fast image processor, as most slow processors break this test and are to be deprecated\"\n+            )\n+\n+        image_processing_class = self.fast_image_processing_class\n+        image_processor_1 = image_processing_class()\n+        image_processor_2 = image_processing_class()\n+        if not (hasattr(image_processor_1, \"size\") and isinstance(image_processor_1.size, dict)) or not (\n+            hasattr(image_processor_1, \"image_mean\") and isinstance(image_processor_1.image_mean, list)\n+        ):\n+            self.skipTest(\n+                reason=\"Skipping test as the image processor does not have dict size or list image_mean attributes\"\n+            )\n+\n+        original_size_2 = deepcopy(image_processor_2.size)\n+        for key in image_processor_1.size:\n+            image_processor_1.size[key] = -1\n+        modified_copied_size_1 = deepcopy(image_processor_1.size)\n+\n+        original_image_mean_2 = deepcopy(image_processor_2.image_mean)\n+        image_processor_1.image_mean[0] = -1\n+        modified_copied_image_mean_1 = deepcopy(image_processor_1.image_mean)\n+\n+        # check that the original attributes of the second instance are not affected\n+        self.assertEqual(image_processor_2.size, original_size_2)\n+        self.assertEqual(image_processor_2.image_mean, original_image_mean_2)\n+\n+        for key in image_processor_2.size:\n+            image_processor_2.size[key] = -2\n+        image_processor_2.image_mean[0] = -2\n+\n+        # check that the modified attributes of the first instance are not affected by the second instance\n+        self.assertEqual(image_processor_1.size, modified_copied_size_1)\n+        self.assertEqual(image_processor_1.image_mean, modified_copied_image_mean_1)\n+\n     @slow\n     @require_torch_accelerator\n     @require_vision\n@@ -575,7 +613,6 @@ def test_can_compile_fast_image_processor(self):\n \n         image_processor = torch.compile(image_processor, mode=\"reduce-overhead\")\n         output_compiled = image_processor(input_image, device=torch_device, return_tensors=\"pt\")\n-        print(output_eager.pixel_values.dtype, output_compiled.pixel_values.dtype)\n         self._assert_slow_fast_tensors_equivalence(\n             output_eager.pixel_values, output_compiled.pixel_values, atol=1e-4, rtol=1e-4, mean_atol=1e-5\n         )"
        },
        {
            "sha": "8507108163caa36304e43ff417671c7f332d2d4a",
            "filename": "tests/test_video_processing_common.py",
            "status": "modified",
            "additions": 38,
            "deletions": 0,
            "changes": 38,
            "blob_url": "https://github.com/huggingface/transformers/blob/a1ad9197c5756858e9014a0e01fe5fb1791efdf2/tests%2Ftest_video_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a1ad9197c5756858e9014a0e01fe5fb1791efdf2/tests%2Ftest_video_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_video_processing_common.py?ref=a1ad9197c5756858e9014a0e01fe5fb1791efdf2",
            "patch": "@@ -18,6 +18,7 @@\n import os\n import tempfile\n import warnings\n+from copy import deepcopy\n \n import numpy as np\n from packaging import version\n@@ -448,3 +449,40 @@ def test_video_processor_preprocess_arguments(self):\n \n         if not is_tested:\n             self.skipTest(reason=\"No validation found for `preprocess` method\")\n+\n+    def test_override_instance_attributes_does_not_affect_other_instances(self):\n+        if self.fast_video_processing_class is None:\n+            self.skipTest(\n+                \"Only testing fast video processor, as most slow processors break this test and are to be deprecated\"\n+            )\n+\n+        video_processing_class = self.fast_video_processing_class\n+        video_processor_1 = video_processing_class()\n+        video_processor_2 = video_processing_class()\n+        if not (hasattr(video_processor_1, \"size\") and isinstance(video_processor_1.size, dict)) or not (\n+            hasattr(video_processor_1, \"image_mean\") and isinstance(video_processor_1.image_mean, list)\n+        ):\n+            self.skipTest(\n+                reason=\"Skipping test as the image processor does not have dict size or list image_mean attributes\"\n+            )\n+\n+        original_size_2 = deepcopy(video_processor_2.size)\n+        for key in video_processor_1.size:\n+            video_processor_1.size[key] = -1\n+        modified_copied_size_1 = deepcopy(video_processor_1.size)\n+\n+        original_image_mean_2 = deepcopy(video_processor_2.image_mean)\n+        video_processor_1.image_mean[0] = -1\n+        modified_copied_image_mean_1 = deepcopy(video_processor_1.image_mean)\n+\n+        # check that the original attributes of the second instance are not affected\n+        self.assertEqual(video_processor_2.size, original_size_2)\n+        self.assertEqual(video_processor_2.image_mean, original_image_mean_2)\n+\n+        for key in video_processor_2.size:\n+            video_processor_2.size[key] = -2\n+        video_processor_2.image_mean[0] = -2\n+\n+        # check that the modified attributes of the first instance are not affected by the second instance\n+        self.assertEqual(video_processor_1.size, modified_copied_size_1)\n+        self.assertEqual(video_processor_1.image_mean, modified_copied_image_mean_1)"
        }
    ],
    "stats": {
        "total": 86,
        "additions": 81,
        "deletions": 5
    }
}