{
    "author": "cyyever",
    "message": "Use pyupgrade --py39-plus to improve code (#36843)",
    "sha": "ce091b1bda847bc3ba426cd5430a3d71e267cdae",
    "files": [
        {
            "sha": "f54e5375c10633dbfbbb68a09b348f090ad967f0",
            "filename": "src/transformers/audio_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 5,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Faudio_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Faudio_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Faudio_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2023 The HuggingFace Inc. team and the librosa & torchaudio authors.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -18,7 +17,7 @@\n \"\"\"\n \n import warnings\n-from typing import List, Optional, Tuple, Union\n+from typing import Optional, Union\n \n import numpy as np\n \n@@ -146,7 +145,7 @@ def chroma_filter_bank(\n     sampling_rate: int,\n     tuning: float = 0.0,\n     power: Optional[float] = 2.0,\n-    weighting_parameters: Optional[Tuple[float, float]] = (5.0, 2.0),\n+    weighting_parameters: Optional[tuple[float, float]] = (5.0, 2.0),\n     start_at_c_chroma: Optional[bool] = True,\n ):\n     \"\"\"\n@@ -592,7 +591,7 @@ def spectrogram(\n \n \n def spectrogram_batch(\n-    waveform_list: List[np.ndarray],\n+    waveform_list: list[np.ndarray],\n     window: np.ndarray,\n     frame_length: int,\n     hop_length: int,\n@@ -611,7 +610,7 @@ def spectrogram_batch(\n     db_range: Optional[float] = None,\n     remove_dc_offset: Optional[bool] = None,\n     dtype: np.dtype = np.float32,\n-) -> List[np.ndarray]:\n+) -> list[np.ndarray]:\n     \"\"\"\n     Calculates spectrograms for a list of waveforms using the Short-Time Fourier Transform, optimized for batch processing.\n     This function extends the capabilities of the `spectrogram` function to handle multiple waveforms efficiently by leveraging broadcasting."
        },
        {
            "sha": "4301716ebdee3ae23acd31ff95ce740161cffa2f",
            "filename": "src/transformers/convert_graph_to_onnx.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fconvert_graph_to_onnx.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fconvert_graph_to_onnx.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fconvert_graph_to_onnx.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -16,7 +16,7 @@\n from argparse import ArgumentParser\n from os import listdir, makedirs\n from pathlib import Path\n-from typing import Dict, List, Optional, Tuple\n+from typing import Optional\n \n from packaging.version import Version, parse\n \n@@ -159,7 +159,7 @@ def ensure_valid_input(model, tokens, input_names):\n     return ordered_input_names, tuple(model_args)\n \n \n-def infer_shapes(nlp: Pipeline, framework: str) -> Tuple[List[str], List[str], Dict, BatchEncoding]:\n+def infer_shapes(nlp: Pipeline, framework: str) -> tuple[list[str], list[str], dict, BatchEncoding]:\n     \"\"\"\n     Attempt to infer the static vs dynamic axes for each input and output tensors for a specific model\n "
        },
        {
            "sha": "46c7ba12a549402cecab9f1448961cf0bd78696c",
            "filename": "src/transformers/convert_pytorch_checkpoint_to_tf2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fconvert_pytorch_checkpoint_to_tf2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fconvert_pytorch_checkpoint_to_tf2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fconvert_pytorch_checkpoint_to_tf2.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2018 The HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");"
        },
        {
            "sha": "d687d32a35770bef0a0f2333ee4d1367062c9ca2",
            "filename": "src/transformers/convert_slow_tokenizer.py",
            "status": "modified",
            "additions": 4,
            "deletions": 6,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fconvert_slow_tokenizer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fconvert_slow_tokenizer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fconvert_slow_tokenizer.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2018 The HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -20,7 +19,6 @@\n \"\"\"\n \n import warnings\n-from typing import Dict, List, Tuple\n \n from packaging import version\n from tokenizers import AddedToken, Regex, Tokenizer, decoders, normalizers, pre_tokenizers, processors\n@@ -91,7 +89,7 @@ def __init__(self, model: str):\n         self.sp = SentencePieceProcessor()\n         self.sp.Load(model)\n \n-    def extract(self, vocab_scores=None) -> Tuple[Dict[str, int], List[Tuple]]:\n+    def extract(self, vocab_scores=None) -> tuple[dict[str, int], list[tuple]]:\n         \"\"\"\n         By default will return vocab and merges with respect to their order, by sending `vocab_scores` we're going to\n         order the merges with respect to the piece scores instead.\n@@ -105,7 +103,7 @@ def extract(self, vocab_scores=None) -> Tuple[Dict[str, int], List[Tuple]]:\n \n \n class GemmaSentencePieceExtractor(SentencePieceExtractor):\n-    def extract(self, vocab_scores=None) -> Tuple[Dict[str, int], List[Tuple]]:\n+    def extract(self, vocab_scores=None) -> tuple[dict[str, int], list[tuple]]:\n         \"\"\"\n         By default will return vocab and merges with respect to their order, by sending `vocab_scores` we're going to\n         order the merges with respect to the piece scores instead.\n@@ -328,7 +326,7 @@ def converted(self) -> Tokenizer:\n \n \n class GPT2Converter(Converter):\n-    def converted(self, vocab: Dict[str, int] = None, merges: List[Tuple[str, str]] = None) -> Tokenizer:\n+    def converted(self, vocab: dict[str, int] = None, merges: list[tuple[str, str]] = None) -> Tokenizer:\n         if not vocab:\n             vocab = self.original_tokenizer.encoder\n         if not merges:\n@@ -397,7 +395,7 @@ def converted(self) -> Tokenizer:\n \n \n class Qwen2Converter(Converter):\n-    def converted(self, vocab: Dict[str, int] = None, merges: List[Tuple[str, str]] = None) -> Tokenizer:\n+    def converted(self, vocab: dict[str, int] = None, merges: list[tuple[str, str]] = None) -> Tokenizer:\n         if not vocab:\n             vocab = self.original_tokenizer.encoder\n         if not merges:"
        },
        {
            "sha": "855ab6381ee1de5dd2d13a279381160625fd6b59",
            "filename": "src/transformers/convert_slow_tokenizers_checkpoints_to_fast.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fconvert_slow_tokenizers_checkpoints_to_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fconvert_slow_tokenizers_checkpoints_to_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fconvert_slow_tokenizers_checkpoints_to_fast.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2018 The HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");"
        },
        {
            "sha": "e2c825a45b605c271c3912bf5b4f3ff4b5c1a32c",
            "filename": "src/transformers/convert_tf_hub_seq_to_seq_bert_to_pytorch.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fconvert_tf_hub_seq_to_seq_bert_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fconvert_tf_hub_seq_to_seq_bert_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fconvert_tf_hub_seq_to_seq_bert_to_pytorch.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2020 The HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");"
        },
        {
            "sha": "c9a26bac9b3dcd9bb14d855f34494a38df3f7f71",
            "filename": "src/transformers/feature_extraction_sequence_utils.py",
            "status": "modified",
            "additions": 7,
            "deletions": 8,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ffeature_extraction_sequence_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ffeature_extraction_sequence_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ffeature_extraction_sequence_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2021 The HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -16,7 +15,7 @@\n Sequence feature extraction class for common feature extractors to preprocess sequences.\n \"\"\"\n \n-from typing import Dict, List, Optional, Union\n+from typing import Optional, Union\n \n import numpy as np\n \n@@ -54,10 +53,10 @@ def pad(\n         self,\n         processed_features: Union[\n             BatchFeature,\n-            List[BatchFeature],\n-            Dict[str, BatchFeature],\n-            Dict[str, List[BatchFeature]],\n-            List[Dict[str, BatchFeature]],\n+            list[BatchFeature],\n+            dict[str, BatchFeature],\n+            dict[str, list[BatchFeature]],\n+            list[dict[str, BatchFeature]],\n         ],\n         padding: Union[bool, str, PaddingStrategy] = True,\n         max_length: Optional[int] = None,\n@@ -226,7 +225,7 @@ def pad(\n \n     def _pad(\n         self,\n-        processed_features: Union[Dict[str, np.ndarray], BatchFeature],\n+        processed_features: Union[dict[str, np.ndarray], BatchFeature],\n         max_length: Optional[int] = None,\n         padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n         pad_to_multiple_of: Optional[int] = None,\n@@ -298,7 +297,7 @@ def _pad(\n \n     def _truncate(\n         self,\n-        processed_features: Union[Dict[str, np.ndarray], BatchFeature],\n+        processed_features: Union[dict[str, np.ndarray], BatchFeature],\n         max_length: Optional[int] = None,\n         pad_to_multiple_of: Optional[int] = None,\n         truncation: Optional[bool] = None,"
        },
        {
            "sha": "4d6a3b89e265dbcef6db3d0d6c849f7c4ff7d816",
            "filename": "src/transformers/hf_argparser.py",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fhf_argparser.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fhf_argparser.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fhf_argparser.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -18,11 +18,12 @@\n import sys\n import types\n from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser, ArgumentTypeError\n+from collections.abc import Iterable\n from copy import copy\n from enum import Enum\n from inspect import isclass\n from pathlib import Path\n-from typing import Any, Callable, Dict, Iterable, List, Literal, NewType, Optional, Tuple, Union, get_type_hints\n+from typing import Any, Callable, Literal, NewType, Optional, Union, get_type_hints\n \n import yaml\n \n@@ -62,7 +63,7 @@ def make_choice_type_function(choices: list) -> Callable[[str], Any]:\n \n def HfArg(\n     *,\n-    aliases: Union[str, List[str]] = None,\n+    aliases: Union[str, list[str]] = None,\n     help: str = None,\n     default: Any = dataclasses.MISSING,\n     default_factory: Callable[[], Any] = dataclasses.MISSING,\n@@ -254,7 +255,7 @@ def _add_dataclass_arguments(self, dtype: DataClassType):\n             parser = self\n \n         try:\n-            type_hints: Dict[str, type] = get_type_hints(dtype)\n+            type_hints: dict[str, type] = get_type_hints(dtype)\n         except NameError:\n             raise RuntimeError(\n                 f\"Type resolution failed for {dtype}. Try declaring the class in global scope or \"\n@@ -288,7 +289,7 @@ def parse_args_into_dataclasses(\n         look_for_args_file=True,\n         args_filename=None,\n         args_file_flag=None,\n-    ) -> Tuple[DataClass, ...]:\n+    ) -> tuple[DataClass, ...]:\n         \"\"\"\n         Parse command-line args into instances of the specified dataclass types.\n \n@@ -367,7 +368,7 @@ def parse_args_into_dataclasses(\n \n             return (*outputs,)\n \n-    def parse_dict(self, args: Dict[str, Any], allow_extra_keys: bool = False) -> Tuple[DataClass, ...]:\n+    def parse_dict(self, args: dict[str, Any], allow_extra_keys: bool = False) -> tuple[DataClass, ...]:\n         \"\"\"\n         Alternative helper method that does not use `argparse` at all, instead uses a dict and populating the dataclass\n         types.\n@@ -397,7 +398,7 @@ def parse_dict(self, args: Dict[str, Any], allow_extra_keys: bool = False) -> Tu\n \n     def parse_json_file(\n         self, json_file: Union[str, os.PathLike], allow_extra_keys: bool = False\n-    ) -> Tuple[DataClass, ...]:\n+    ) -> tuple[DataClass, ...]:\n         \"\"\"\n         Alternative helper method that does not use `argparse` at all, instead loading a json file and populating the\n         dataclass types.\n@@ -421,7 +422,7 @@ def parse_json_file(\n \n     def parse_yaml_file(\n         self, yaml_file: Union[str, os.PathLike], allow_extra_keys: bool = False\n-    ) -> Tuple[DataClass, ...]:\n+    ) -> tuple[DataClass, ...]:\n         \"\"\"\n         Alternative helper method that does not use `argparse` at all, instead loading a yaml file and populating the\n         dataclass types."
        },
        {
            "sha": "6169db9db56d7ed91997e28f8070616d0c3f9e0b",
            "filename": "src/transformers/hyperparameter_search.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fhyperparameter_search.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fhyperparameter_search.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fhyperparameter_search.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2023-present the HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");"
        },
        {
            "sha": "ec0f817728d327fe95b140f3f30f33bac7042ad9",
            "filename": "src/transformers/image_processing_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fimage_processing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fimage_processing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fimage_processing_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2022 The HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -14,7 +13,8 @@\n # limitations under the License.\n \n import math\n-from typing import Dict, Iterable, Optional, Union\n+from collections.abc import Iterable\n+from typing import Optional, Union\n \n import numpy as np\n \n@@ -116,7 +116,7 @@ def normalize(\n     def center_crop(\n         self,\n         image: np.ndarray,\n-        size: Dict[str, int],\n+        size: dict[str, int],\n         data_format: Optional[Union[str, ChannelDimension]] = None,\n         input_data_format: Optional[Union[str, ChannelDimension]] = None,\n         **kwargs,\n@@ -207,7 +207,7 @@ def convert_to_size_dict(\n \n \n def get_size_dict(\n-    size: Union[int, Iterable[int], Dict[str, int]] = None,\n+    size: Union[int, Iterable[int], dict[str, int]] = None,\n     max_size: Optional[int] = None,\n     height_width_order: bool = True,\n     default_to_square: bool = True,"
        },
        {
            "sha": "fa0f9952e005b41f68f310b52e3ccead4d3c9858",
            "filename": "src/transformers/image_processing_utils_fast.py",
            "status": "modified",
            "additions": 23,
            "deletions": 23,
            "changes": 46,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fimage_processing_utils_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fimage_processing_utils_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fimage_processing_utils_fast.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2024 The HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -13,8 +12,9 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n+from collections.abc import Iterable\n from functools import lru_cache, partial\n-from typing import Any, Dict, Iterable, List, Optional, Tuple, TypedDict, Union\n+from typing import Any, Optional, TypedDict, Union\n \n import numpy as np\n \n@@ -77,8 +77,8 @@ def validate_fast_preprocess_arguments(\n     do_rescale: Optional[bool] = None,\n     rescale_factor: Optional[float] = None,\n     do_normalize: Optional[bool] = None,\n-    image_mean: Optional[Union[float, List[float]]] = None,\n-    image_std: Optional[Union[float, List[float]]] = None,\n+    image_mean: Optional[Union[float, list[float]]] = None,\n+    image_std: Optional[Union[float, list[float]]] = None,\n     do_pad: Optional[bool] = None,\n     size_divisibility: Optional[int] = None,\n     do_center_crop: Optional[bool] = None,\n@@ -128,14 +128,14 @@ def safe_squeeze(tensor: \"torch.Tensor\", axis: Optional[int] = None) -> \"torch.T\n         return tensor\n \n \n-def max_across_indices(values: Iterable[Any]) -> List[Any]:\n+def max_across_indices(values: Iterable[Any]) -> list[Any]:\n     \"\"\"\n     Return the maximum value across all indices of an iterable of values.\n     \"\"\"\n     return [max(values_i) for values_i in zip(*values)]\n \n \n-def get_max_height_width(images: List[\"torch.Tensor\"]) -> Tuple[int]:\n+def get_max_height_width(images: list[\"torch.Tensor\"]) -> tuple[int]:\n     \"\"\"\n     Get the maximum height and width across all images in a batch.\n     \"\"\"\n@@ -147,7 +147,7 @@ def get_max_height_width(images: List[\"torch.Tensor\"]) -> Tuple[int]:\n \n def divide_to_patches(\n     image: Union[np.array, \"torch.Tensor\"], patch_size: int\n-) -> List[Union[np.array, \"torch.Tensor\"]]:\n+) -> list[Union[np.array, \"torch.Tensor\"]]:\n     \"\"\"\n     Divides an image into patches of a specified size.\n \n@@ -171,16 +171,16 @@ def divide_to_patches(\n \n class DefaultFastImageProcessorKwargs(TypedDict, total=False):\n     do_resize: Optional[bool]\n-    size: Optional[Dict[str, int]]\n+    size: Optional[dict[str, int]]\n     default_to_square: Optional[bool]\n     resample: Optional[Union[\"PILImageResampling\", \"F.InterpolationMode\"]]\n     do_center_crop: Optional[bool]\n-    crop_size: Optional[Dict[str, int]]\n+    crop_size: Optional[dict[str, int]]\n     do_rescale: Optional[bool]\n     rescale_factor: Optional[Union[int, float]]\n     do_normalize: Optional[bool]\n-    image_mean: Optional[Union[float, List[float]]]\n-    image_std: Optional[Union[float, List[float]]]\n+    image_mean: Optional[Union[float, list[float]]]\n+    image_std: Optional[Union[float, list[float]]]\n     do_convert_rgb: Optional[bool]\n     return_tensors: Optional[Union[str, TensorType]]\n     data_format: Optional[ChannelDimension]\n@@ -427,8 +427,8 @@ def normalize(\n     def _fuse_mean_std_and_rescale_factor(\n         self,\n         do_normalize: Optional[bool] = None,\n-        image_mean: Optional[Union[float, List[float]]] = None,\n-        image_std: Optional[Union[float, List[float]]] = None,\n+        image_mean: Optional[Union[float, list[float]]] = None,\n+        image_std: Optional[Union[float, list[float]]] = None,\n         do_rescale: Optional[bool] = None,\n         rescale_factor: Optional[float] = None,\n         device: Optional[\"torch.device\"] = None,\n@@ -446,8 +446,8 @@ def rescale_and_normalize(\n         do_rescale: bool,\n         rescale_factor: float,\n         do_normalize: bool,\n-        image_mean: Union[float, List[float]],\n-        image_std: Union[float, List[float]],\n+        image_mean: Union[float, list[float]],\n+        image_std: Union[float, list[float]],\n     ) -> \"torch.Tensor\":\n         \"\"\"\n         Rescale and normalize images.\n@@ -471,7 +471,7 @@ def rescale_and_normalize(\n     def center_crop(\n         self,\n         image: \"torch.Tensor\",\n-        size: Dict[str, int],\n+        size: dict[str, int],\n         **kwargs,\n     ) -> \"torch.Tensor\":\n         \"\"\"\n@@ -576,7 +576,7 @@ def _prepare_input_images(\n         do_convert_rgb: bool = None,\n         input_data_format: Optional[Union[str, ChannelDimension]] = None,\n         device: Optional[\"torch.device\"] = None,\n-    ) -> List[\"torch.Tensor\"]:\n+    ) -> list[\"torch.Tensor\"]:\n         \"\"\"\n         Prepare the input images for processing.\n         \"\"\"\n@@ -599,8 +599,8 @@ def _further_process_kwargs(\n         size: Optional[SizeDict] = None,\n         crop_size: Optional[SizeDict] = None,\n         default_to_square: Optional[bool] = None,\n-        image_mean: Optional[Union[float, List[float]]] = None,\n-        image_std: Optional[Union[float, List[float]]] = None,\n+        image_mean: Optional[Union[float, list[float]]] = None,\n+        image_std: Optional[Union[float, list[float]]] = None,\n         data_format: Optional[ChannelDimension] = None,\n         **kwargs,\n     ) -> dict:\n@@ -701,7 +701,7 @@ def preprocess(self, images: ImageInput, **kwargs: Unpack[DefaultFastImageProces\n \n     def _preprocess(\n         self,\n-        images: List[\"torch.Tensor\"],\n+        images: list[\"torch.Tensor\"],\n         do_resize: bool,\n         size: SizeDict,\n         interpolation: Optional[\"F.InterpolationMode\"],\n@@ -710,8 +710,8 @@ def _preprocess(\n         do_rescale: bool,\n         rescale_factor: float,\n         do_normalize: bool,\n-        image_mean: Optional[Union[float, List[float]]],\n-        image_std: Optional[Union[float, List[float]]],\n+        image_mean: Optional[Union[float, list[float]]],\n+        image_std: Optional[Union[float, list[float]]],\n         return_tensors: Optional[Union[str, TensorType]],\n         **kwargs,\n     ) -> BatchFeature:\n@@ -749,7 +749,7 @@ def to_dict(self):\n \n \n class SemanticSegmentationMixin:\n-    def post_process_semantic_segmentation(self, outputs, target_sizes: List[Tuple] = None):\n+    def post_process_semantic_segmentation(self, outputs, target_sizes: list[tuple] = None):\n         \"\"\"\n         Converts the output of [`MobileNetV2ForSemanticSegmentation`] into semantic segmentation maps. Only supports PyTorch.\n "
        },
        {
            "sha": "1ea163202d1fa273c968b7a782e843dce7aba49b",
            "filename": "src/transformers/image_transforms.py",
            "status": "modified",
            "additions": 13,
            "deletions": 14,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fimage_transforms.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fimage_transforms.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fimage_transforms.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2022 The HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -14,9 +13,9 @@\n # limitations under the License.\n \n import warnings\n-from collections.abc import Collection\n+from collections.abc import Collection, Iterable\n from math import ceil\n-from typing import Dict, Iterable, List, Optional, Tuple, Union\n+from typing import Optional, Union\n \n import numpy as np\n \n@@ -86,7 +85,7 @@ def to_channel_dimension_format(\n     elif target_channel_dim == ChannelDimension.LAST:\n         image = image.transpose((1, 2, 0))\n     else:\n-        raise ValueError(\"Unsupported channel dimension format: {}\".format(channel_dim))\n+        raise ValueError(f\"Unsupported channel dimension format: {channel_dim}\")\n \n     return image\n \n@@ -192,7 +191,7 @@ def to_pil_image(\n     elif is_jax_tensor(image):\n         image = np.array(image)\n     elif not isinstance(image, np.ndarray):\n-        raise ValueError(\"Input image type not supported: {}\".format(type(image)))\n+        raise ValueError(f\"Input image type not supported: {type(image)}\")\n \n     # If the channel has been moved to first dim, we put it back at the end.\n     image = to_channel_dimension_format(image, ChannelDimension.LAST, input_data_format)\n@@ -210,7 +209,7 @@ def to_pil_image(\n     return PIL.Image.fromarray(image, mode=image_mode)\n \n \n-def get_size_with_aspect_ratio(image_size, size, max_size=None) -> Tuple[int, int]:\n+def get_size_with_aspect_ratio(image_size, size, max_size=None) -> tuple[int, int]:\n     \"\"\"\n     Computes the output image size given the input image size and the desired output size.\n \n@@ -252,7 +251,7 @@ def get_size_with_aspect_ratio(image_size, size, max_size=None) -> Tuple[int, in\n # Logic adapted from torchvision resizing logic: https://github.com/pytorch/vision/blob/511924c1ced4ce0461197e5caa64ce5b9e558aab/torchvision/transforms/functional.py#L366\n def get_resize_output_image_size(\n     input_image: np.ndarray,\n-    size: Union[int, Tuple[int, int], List[int], Tuple[int]],\n+    size: Union[int, tuple[int, int], list[int], tuple[int]],\n     default_to_square: bool = True,\n     max_size: Optional[int] = None,\n     input_data_format: Optional[Union[str, ChannelDimension]] = None,\n@@ -319,7 +318,7 @@ def get_resize_output_image_size(\n \n def resize(\n     image: np.ndarray,\n-    size: Tuple[int, int],\n+    size: tuple[int, int],\n     resample: \"PILImageResampling\" = None,\n     reducing_gap: Optional[int] = None,\n     data_format: Optional[ChannelDimension] = None,\n@@ -451,7 +450,7 @@ def normalize(\n \n def center_crop(\n     image: np.ndarray,\n-    size: Tuple[int, int],\n+    size: tuple[int, int],\n     data_format: Optional[Union[str, ChannelDimension]] = None,\n     input_data_format: Optional[Union[str, ChannelDimension]] = None,\n     return_numpy: Optional[bool] = None,\n@@ -705,7 +704,7 @@ class PaddingMode(ExplicitEnum):\n \n def pad(\n     image: np.ndarray,\n-    padding: Union[int, Tuple[int, int], Iterable[Tuple[int, int]]],\n+    padding: Union[int, tuple[int, int], Iterable[tuple[int, int]]],\n     mode: PaddingMode = PaddingMode.CONSTANT,\n     constant_values: Union[float, Iterable[float]] = 0.0,\n     data_format: Optional[Union[str, ChannelDimension]] = None,\n@@ -855,8 +854,8 @@ def _cast_tensor_to_float(x):\n \n \n def group_images_by_shape(\n-    images: List[\"torch.Tensor\"],\n-) -> Tuple[Dict[Tuple[int, int], List[\"torch.Tensor\"]], Dict[int, Tuple[Tuple[int, int], int]]]:\n+    images: list[\"torch.Tensor\"],\n+) -> tuple[dict[tuple[int, int], list[\"torch.Tensor\"]], dict[int, tuple[tuple[int, int], int]]]:\n     \"\"\"\n     Groups images by shape.\n     Returns a dictionary with the shape as key and a list of images with that shape as value,\n@@ -876,8 +875,8 @@ def group_images_by_shape(\n \n \n def reorder_images(\n-    processed_images: Dict[Tuple[int, int], \"torch.Tensor\"], grouped_images_index: Dict[int, Tuple[int, int]]\n-) -> List[\"torch.Tensor\"]:\n+    processed_images: dict[tuple[int, int], \"torch.Tensor\"], grouped_images_index: dict[int, tuple[int, int]]\n+) -> list[\"torch.Tensor\"]:\n     \"\"\"\n     Reconstructs a list of images in the original order.\n     \"\"\""
        },
        {
            "sha": "8eb10d1f6178ee551b6188750a8b11872a9e42e8",
            "filename": "src/transformers/image_utils.py",
            "status": "modified",
            "additions": 31,
            "deletions": 31,
            "changes": 62,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fimage_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fimage_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fimage_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2021 The HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -15,10 +14,11 @@\n \n import base64\n import os\n+from collections.abc import Iterable\n from contextlib import redirect_stdout\n from dataclasses import dataclass\n from io import BytesIO\n-from typing import TYPE_CHECKING, Callable, Dict, Iterable, List, Optional, Tuple, Union\n+from typing import TYPE_CHECKING, Callable, Optional, Union\n \n import numpy as np\n import requests\n@@ -83,19 +83,19 @@\n \n \n ImageInput = Union[\n-    \"PIL.Image.Image\", np.ndarray, \"torch.Tensor\", List[\"PIL.Image.Image\"], List[np.ndarray], List[\"torch.Tensor\"]\n+    \"PIL.Image.Image\", np.ndarray, \"torch.Tensor\", list[\"PIL.Image.Image\"], list[np.ndarray], list[\"torch.Tensor\"]\n ]  # noqa\n \n \n VideoInput = Union[\n-    List[\"PIL.Image.Image\"],\n+    list[\"PIL.Image.Image\"],\n     \"np.ndarray\",\n     \"torch.Tensor\",\n-    List[\"np.ndarray\"],\n-    List[\"torch.Tensor\"],\n-    List[List[\"PIL.Image.Image\"]],\n-    List[List[\"np.ndarrray\"]],\n-    List[List[\"torch.Tensor\"]],\n+    list[\"np.ndarray\"],\n+    list[\"torch.Tensor\"],\n+    list[list[\"PIL.Image.Image\"]],\n+    list[list[\"np.ndarrray\"]],\n+    list[list[\"torch.Tensor\"]],\n ]  # noqa\n \n \n@@ -122,7 +122,7 @@ class VideoMetadata:\n     video_backend: str\n \n \n-AnnotationType = Dict[str, Union[int, str, List[Dict]]]\n+AnnotationType = dict[str, Union[int, str, list[dict]]]\n \n \n def is_pil_image(img):\n@@ -155,7 +155,7 @@ def is_valid_image(img):\n     return is_pil_image(img) or is_numpy_array(img) or is_torch_tensor(img) or is_tf_tensor(img) or is_jax_tensor(img)\n \n \n-def is_valid_list_of_images(images: List):\n+def is_valid_list_of_images(images: list):\n     return images and all(is_valid_image(image) for image in images)\n \n \n@@ -188,7 +188,7 @@ def is_scaled_image(image: np.ndarray) -> bool:\n     return np.min(image) >= 0 and np.max(image) <= 1\n \n \n-def make_list_of_images(images, expected_ndims: int = 3) -> List[ImageInput]:\n+def make_list_of_images(images, expected_ndims: int = 3) -> list[ImageInput]:\n     \"\"\"\n     Ensure that the output is a list of images. If the input is a single image, it is converted to a list of length 1.\n     If the input is a batch of images, it is converted to a list of images.\n@@ -228,7 +228,7 @@ def make_list_of_images(images, expected_ndims: int = 3) -> List[ImageInput]:\n \n \n def make_flat_list_of_images(\n-    images: Union[List[ImageInput], ImageInput],\n+    images: Union[list[ImageInput], ImageInput],\n ) -> ImageInput:\n     \"\"\"\n     Ensure that the output is a flat list of images. If the input is a single image, it is converted to a list of length 1.\n@@ -263,7 +263,7 @@ def make_flat_list_of_images(\n \n \n def make_nested_list_of_images(\n-    images: Union[List[ImageInput], ImageInput],\n+    images: Union[list[ImageInput], ImageInput],\n ) -> ImageInput:\n     \"\"\"\n     Ensure that the output is a nested list of images.\n@@ -339,7 +339,7 @@ def to_numpy_array(img) -> np.ndarray:\n \n \n def infer_channel_dimension_format(\n-    image: np.ndarray, num_channels: Optional[Union[int, Tuple[int, ...]]] = None\n+    image: np.ndarray, num_channels: Optional[Union[int, tuple[int, ...]]] = None\n ) -> ChannelDimension:\n     \"\"\"\n     Infers the channel dimension format of `image`.\n@@ -399,7 +399,7 @@ def get_channel_dimension_axis(\n     raise ValueError(f\"Unsupported data format: {input_data_format}\")\n \n \n-def get_image_size(image: np.ndarray, channel_dim: ChannelDimension = None) -> Tuple[int, int]:\n+def get_image_size(image: np.ndarray, channel_dim: ChannelDimension = None) -> tuple[int, int]:\n     \"\"\"\n     Returns the (height, width) dimensions of the image.\n \n@@ -424,10 +424,10 @@ def get_image_size(image: np.ndarray, channel_dim: ChannelDimension = None) -> T\n \n \n def get_image_size_for_max_height_width(\n-    image_size: Tuple[int, int],\n+    image_size: tuple[int, int],\n     max_height: int,\n     max_width: int,\n-) -> Tuple[int, int]:\n+) -> tuple[int, int]:\n     \"\"\"\n     Computes the output image size given the input image and the maximum allowed height and width. Keep aspect ratio.\n     Important, even if image_height < max_height and image_width < max_width, the image will be resized\n@@ -454,7 +454,7 @@ def get_image_size_for_max_height_width(\n     return new_height, new_width\n \n \n-def is_valid_annotation_coco_detection(annotation: Dict[str, Union[List, Tuple]]) -> bool:\n+def is_valid_annotation_coco_detection(annotation: dict[str, Union[list, tuple]]) -> bool:\n     if (\n         isinstance(annotation, dict)\n         and \"image_id\" in annotation\n@@ -469,7 +469,7 @@ def is_valid_annotation_coco_detection(annotation: Dict[str, Union[List, Tuple]]\n     return False\n \n \n-def is_valid_annotation_coco_panoptic(annotation: Dict[str, Union[List, Tuple]]) -> bool:\n+def is_valid_annotation_coco_panoptic(annotation: dict[str, Union[list, tuple]]) -> bool:\n     if (\n         isinstance(annotation, dict)\n         and \"image_id\" in annotation\n@@ -485,11 +485,11 @@ def is_valid_annotation_coco_panoptic(annotation: Dict[str, Union[List, Tuple]])\n     return False\n \n \n-def valid_coco_detection_annotations(annotations: Iterable[Dict[str, Union[List, Tuple]]]) -> bool:\n+def valid_coco_detection_annotations(annotations: Iterable[dict[str, Union[list, tuple]]]) -> bool:\n     return all(is_valid_annotation_coco_detection(ann) for ann in annotations)\n \n \n-def valid_coco_panoptic_annotations(annotations: Iterable[Dict[str, Union[List, Tuple]]]) -> bool:\n+def valid_coco_panoptic_annotations(annotations: Iterable[dict[str, Union[list, tuple]]]) -> bool:\n     return all(is_valid_annotation_coco_panoptic(ann) for ann in annotations)\n \n \n@@ -880,8 +880,8 @@ def sample_indices_fn_func(metadata, **fn_kwargs):\n \n \n def load_images(\n-    images: Union[List, Tuple, str, \"PIL.Image.Image\"], timeout: Optional[float] = None\n-) -> Union[\"PIL.Image.Image\", List[\"PIL.Image.Image\"], List[List[\"PIL.Image.Image\"]]]:\n+    images: Union[list, tuple, str, \"PIL.Image.Image\"], timeout: Optional[float] = None\n+) -> Union[\"PIL.Image.Image\", list[\"PIL.Image.Image\"], list[list[\"PIL.Image.Image\"]]]:\n     \"\"\"Loads images, handling different levels of nesting.\n \n     Args:\n@@ -904,14 +904,14 @@ def validate_preprocess_arguments(\n     do_rescale: Optional[bool] = None,\n     rescale_factor: Optional[float] = None,\n     do_normalize: Optional[bool] = None,\n-    image_mean: Optional[Union[float, List[float]]] = None,\n-    image_std: Optional[Union[float, List[float]]] = None,\n+    image_mean: Optional[Union[float, list[float]]] = None,\n+    image_std: Optional[Union[float, list[float]]] = None,\n     do_pad: Optional[bool] = None,\n     size_divisibility: Optional[int] = None,\n     do_center_crop: Optional[bool] = None,\n-    crop_size: Optional[Dict[str, int]] = None,\n+    crop_size: Optional[dict[str, int]] = None,\n     do_resize: Optional[bool] = None,\n-    size: Optional[Dict[str, int]] = None,\n+    size: Optional[dict[str, int]] = None,\n     resample: Optional[\"PILImageResampling\"] = None,\n ):\n     \"\"\"\n@@ -1295,8 +1295,8 @@ def rotate(self, image, angle, resample=None, expand=0, center=None, translate=N\n \n def validate_annotations(\n     annotation_format: AnnotationFormat,\n-    supported_annotation_formats: Tuple[AnnotationFormat, ...],\n-    annotations: List[Dict],\n+    supported_annotation_formats: tuple[AnnotationFormat, ...],\n+    annotations: list[dict],\n ) -> None:\n     if annotation_format not in supported_annotation_formats:\n         raise ValueError(f\"Unsupported annotation format: {format} must be one of {supported_annotation_formats}\")\n@@ -1318,7 +1318,7 @@ def validate_annotations(\n             )\n \n \n-def validate_kwargs(valid_processor_keys: List[str], captured_kwargs: List[str]):\n+def validate_kwargs(valid_processor_keys: list[str], captured_kwargs: list[str]):\n     unused_keys = set(captured_kwargs).difference(set(valid_processor_keys))\n     if unused_keys:\n         unused_key_str = \", \".join(unused_keys)"
        },
        {
            "sha": "57e72aea7e6cf22a0ff420267ccca1703a21cdf2",
            "filename": "src/transformers/keras_callbacks.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fkeras_callbacks.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fkeras_callbacks.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fkeras_callbacks.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -2,7 +2,7 @@\n import os\n from pathlib import Path\n from time import sleep\n-from typing import Callable, List, Optional, Union\n+from typing import Callable, Optional, Union\n \n import numpy as np\n import tensorflow as tf\n@@ -79,8 +79,8 @@ def __init__(\n         self,\n         metric_fn: Callable,\n         eval_dataset: Union[tf.data.Dataset, np.ndarray, tf.Tensor, tuple, dict],\n-        output_cols: Optional[List[str]] = None,\n-        label_cols: Optional[List[str]] = None,\n+        output_cols: Optional[list[str]] = None,\n+        label_cols: Optional[list[str]] = None,\n         batch_size: Optional[int] = None,\n         predict_with_generate: bool = False,\n         use_xla_generation: bool = False,"
        },
        {
            "sha": "dfdd976f0156139024c6f7788870a71e4a41754d",
            "filename": "src/transformers/modeling_attn_mask_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fmodeling_attn_mask_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fmodeling_attn_mask_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_attn_mask_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n from dataclasses import dataclass\n-from typing import List, Optional, Tuple, Union\n+from typing import Optional, Union\n \n import torch\n \n@@ -301,7 +301,7 @@ def _ignore_causal_mask_sdpa(\n \n def _prepare_4d_causal_attention_mask(\n     attention_mask: Optional[torch.Tensor],\n-    input_shape: Union[torch.Size, Tuple, List],\n+    input_shape: Union[torch.Size, tuple, list],\n     inputs_embeds: torch.Tensor,\n     past_key_values_length: int,\n     sliding_window: Optional[int] = None,\n@@ -354,7 +354,7 @@ def _prepare_4d_causal_attention_mask(\n # Adapted from _prepare_4d_causal_attention_mask\n def _prepare_4d_causal_attention_mask_for_sdpa(\n     attention_mask: Optional[torch.Tensor],\n-    input_shape: Union[torch.Size, Tuple, List],\n+    input_shape: Union[torch.Size, tuple, list],\n     inputs_embeds: torch.Tensor,\n     past_key_values_length: int,\n     sliding_window: Optional[int] = None,\n@@ -452,7 +452,7 @@ def _prepare_4d_attention_mask_for_sdpa(mask: torch.Tensor, dtype: torch.dtype,\n \n \n def _create_4d_causal_attention_mask(\n-    input_shape: Union[torch.Size, Tuple, List],\n+    input_shape: Union[torch.Size, tuple, list],\n     dtype: torch.dtype,\n     device: torch.device,\n     past_key_values_length: int = 0,"
        },
        {
            "sha": "4da8b451f1af28fdb2d4151d7446a21302110de1",
            "filename": "src/transformers/modeling_flash_attention_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fmodeling_flash_attention_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fmodeling_flash_attention_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_flash_attention_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2024 The Fairseq Authors and the HuggingFace Inc. team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -15,7 +14,7 @@\n \n import inspect\n import os\n-from typing import Optional, Tuple, TypedDict\n+from typing import Optional, TypedDict\n \n import torch\n import torch.nn.functional as F\n@@ -33,7 +32,7 @@\n     _flash_supports_window_size = \"window_size\" in list(inspect.signature(flash_attn_func).parameters)\n \n \n-def _get_unpad_data(attention_mask: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, int]:\n+def _get_unpad_data(attention_mask: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, int]:\n     \"\"\"\n     Retrieves indexing data required to repad unpadded (ragged) tensors.\n "
        },
        {
            "sha": "c2aa21e595b87e28990d72d07b150f10afa21b1e",
            "filename": "src/transformers/modeling_gguf_pytorch_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fmodeling_gguf_pytorch_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fmodeling_gguf_pytorch_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_gguf_pytorch_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2024 The ggml.ai team and The HuggingFace Inc. team. and pygguf author (github.com/99991)\n # https://github.com/99991/pygguf\n #\n@@ -15,7 +14,7 @@\n # limitations under the License.\n \n import re\n-from typing import Dict, NamedTuple, Optional\n+from typing import NamedTuple, Optional\n \n import numpy as np\n from tqdm.auto import tqdm\n@@ -115,7 +114,7 @@ def process(self, weights, name, **kwargs):\n         return GGUFTensor(weights, name, {})\n \n     def _split_moe_expert_tensor(\n-        self, weights: np.ndarray, parsed_parameters: Dict[str, Dict], name: str, tensor_key_mapping: dict\n+        self, weights: np.ndarray, parsed_parameters: dict[str, dict], name: str, tensor_key_mapping: dict\n     ):\n         # Original merge implementation\n         # https://github.com/ggerganov/llama.cpp/blob/master/convert_hf_to_gguf.py#L1994-L2022"
        },
        {
            "sha": "d419f7c186566413b4c779798e5523e75c1f545f",
            "filename": "src/transformers/modeling_rope_utils.py",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fmodeling_rope_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fmodeling_rope_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_rope_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -13,7 +13,7 @@\n # limitations under the License.\n \n import math\n-from typing import Optional, Tuple\n+from typing import Optional\n \n from .configuration_utils import PretrainedConfig\n from .utils import is_torch_available, logging\n@@ -31,7 +31,7 @@ def _compute_default_rope_parameters(\n     device: Optional[\"torch.device\"] = None,\n     seq_len: Optional[int] = None,\n     **rope_kwargs,\n-) -> Tuple[\"torch.Tensor\", float]:\n+) -> tuple[\"torch.Tensor\", float]:\n     \"\"\"\n     Computes the inverse frequencies according to the original RoPE implementation\n     Args:\n@@ -73,7 +73,7 @@ def _compute_linear_scaling_rope_parameters(\n     device: Optional[\"torch.device\"] = None,\n     seq_len: Optional[int] = None,\n     **rope_kwargs,\n-) -> Tuple[\"torch.Tensor\", float]:\n+) -> tuple[\"torch.Tensor\", float]:\n     \"\"\"\n     Computes the inverse frequencies with linear scaling. Credits to the Reddit user /u/kaiokendev\n     Args:\n@@ -114,7 +114,7 @@ def _compute_dynamic_ntk_parameters(\n     device: Optional[\"torch.device\"] = None,\n     seq_len: Optional[int] = None,\n     **rope_kwargs,\n-) -> Tuple[\"torch.Tensor\", float]:\n+) -> tuple[\"torch.Tensor\", float]:\n     \"\"\"\n     Computes the inverse frequencies with NTK scaling. Credits to the Reddit users /u/bloc97 and /u/emozilla\n     Args:\n@@ -162,7 +162,7 @@ def _compute_dynamic_ntk_parameters(\n \n def _compute_yarn_parameters(\n     config: PretrainedConfig, device: \"torch.device\", seq_len: Optional[int] = None, **rope_kwargs\n-) -> Tuple[\"torch.Tensor\", float]:\n+) -> tuple[\"torch.Tensor\", float]:\n     \"\"\"\n     Computes the inverse frequencies with NTK scaling. Please refer to the\n     [original paper](https://arxiv.org/abs/2309.00071)\n@@ -241,7 +241,7 @@ def linear_ramp_factor(min, max, dim):\n \n def _compute_longrope_parameters(\n     config: PretrainedConfig, device: \"torch.device\", seq_len: Optional[int] = None, **rope_kwargs\n-) -> Tuple[\"torch.Tensor\", float]:\n+) -> tuple[\"torch.Tensor\", float]:\n     \"\"\"\n     Computes the inverse frequencies with LongRoPE scaling. Please refer to the\n     [original implementation](https://github.com/microsoft/LongRoPE)\n@@ -304,7 +304,7 @@ def _compute_longrope_parameters(\n \n def _compute_llama3_parameters(\n     config: PretrainedConfig, device: \"torch.device\", seq_len: Optional[int] = None, **rope_kwargs\n-) -> Tuple[\"torch.Tensor\", float]:\n+) -> tuple[\"torch.Tensor\", float]:\n     \"\"\"\n     Computes the inverse frequencies for llama 3.1.\n "
        },
        {
            "sha": "416db528880d877ca6c83bfe1485685eadae73e7",
            "filename": "src/transformers/modeling_tf_pytorch_utils.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fmodeling_tf_pytorch_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fmodeling_tf_pytorch_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_tf_pytorch_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n # Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n #"
        },
        {
            "sha": "6d39bd52b8e19e2634b1ed848484bd7e2779b818",
            "filename": "src/transformers/optimization.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Foptimization.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Foptimization.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Foptimization.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");"
        },
        {
            "sha": "cce7fb154d359dac1cd8bb18c34183be4564361a",
            "filename": "src/transformers/optimization_tf.py",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Foptimization_tf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Foptimization_tf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Foptimization_tf.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -15,7 +15,7 @@\n \"\"\"Functions and classes related to optimization (weight updates).\"\"\"\n \n import re\n-from typing import Callable, List, Optional, Union\n+from typing import Callable, Optional, Union\n \n import tensorflow as tf\n \n@@ -105,7 +105,7 @@ def create_optimizer(\n     adam_global_clipnorm: Optional[float] = None,\n     weight_decay_rate: float = 0.0,\n     power: float = 1.0,\n-    include_in_weight_decay: Optional[List[str]] = None,\n+    include_in_weight_decay: Optional[list[str]] = None,\n ):\n     \"\"\"\n     Creates an optimizer with a learning rate schedule using a warmup phase followed by a linear decay.\n@@ -224,8 +224,8 @@ def __init__(\n         epsilon: float = 1e-7,\n         amsgrad: bool = False,\n         weight_decay_rate: float = 0.0,\n-        include_in_weight_decay: Optional[List[str]] = None,\n-        exclude_from_weight_decay: Optional[List[str]] = None,\n+        include_in_weight_decay: Optional[list[str]] = None,\n+        exclude_from_weight_decay: Optional[list[str]] = None,\n         name: str = \"AdamWeightDecay\",\n         **kwargs,\n     ):\n@@ -238,10 +238,10 @@ def __init__(\n     def from_config(cls, config):\n         \"\"\"Creates an optimizer from its config with WarmUp custom object.\"\"\"\n         custom_objects = {\"WarmUp\": WarmUp}\n-        return super(AdamWeightDecay, cls).from_config(config, custom_objects=custom_objects)\n+        return super().from_config(config, custom_objects=custom_objects)\n \n     def _prepare_local(self, var_device, var_dtype, apply_state):\n-        super(AdamWeightDecay, self)._prepare_local(var_device, var_dtype, apply_state)\n+        super()._prepare_local(var_device, var_dtype, apply_state)\n         apply_state[(var_device, var_dtype)][\"weight_decay_rate\"] = tf.constant(\n             self.weight_decay_rate, name=\"adam_weight_decay_rate\"\n         )\n@@ -257,7 +257,7 @@ def _decay_weights_op(self, var, learning_rate, apply_state):\n \n     def apply_gradients(self, grads_and_vars, name=None, **kwargs):\n         grads, tvars = list(zip(*grads_and_vars))\n-        return super(AdamWeightDecay, self).apply_gradients(zip(grads, tvars), name=name, **kwargs)\n+        return super().apply_gradients(zip(grads, tvars), name=name, **kwargs)\n \n     def _get_lr(self, var_device, var_dtype, apply_state):\n         \"\"\"Retrieves the learning rate with the given state.\"\"\"\n@@ -276,13 +276,13 @@ def _resource_apply_dense(self, grad, var, apply_state=None):\n         lr_t, kwargs = self._get_lr(var.device, var.dtype.base_dtype, apply_state)\n         decay = self._decay_weights_op(var, lr_t, apply_state)\n         with tf.control_dependencies([decay]):\n-            return super(AdamWeightDecay, self)._resource_apply_dense(grad, var, **kwargs)\n+            return super()._resource_apply_dense(grad, var, **kwargs)\n \n     def _resource_apply_sparse(self, grad, var, indices, apply_state=None):\n         lr_t, kwargs = self._get_lr(var.device, var.dtype.base_dtype, apply_state)\n         decay = self._decay_weights_op(var, lr_t, apply_state)\n         with tf.control_dependencies([decay]):\n-            return super(AdamWeightDecay, self)._resource_apply_sparse(grad, var, indices, **kwargs)\n+            return super()._resource_apply_sparse(grad, var, indices, **kwargs)\n \n     def get_config(self):\n         config = super().get_config()"
        },
        {
            "sha": "c899490824b95806be0e6da070fb00ad29528b8b",
            "filename": "src/transformers/pytorch_utils.py",
            "status": "modified",
            "additions": 6,
            "deletions": 10,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fpytorch_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Fpytorch_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpytorch_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -15,7 +15,7 @@\n \n import inspect\n from functools import lru_cache, wraps\n-from typing import Callable, List, Optional, Set, Tuple, Union\n+from typing import Callable\n \n import torch\n from packaging import version\n@@ -157,9 +157,7 @@ def prune_conv1d_layer(layer: Conv1D, index: torch.LongTensor, dim: int = 1) ->\n     return new_layer\n \n \n-def prune_layer(\n-    layer: Union[nn.Linear, Conv1D], index: torch.LongTensor, dim: Optional[int] = None\n-) -> Union[nn.Linear, Conv1D]:\n+def prune_layer(layer: nn.Linear | Conv1D, index: torch.LongTensor, dim: int | None = None) -> nn.Linear | Conv1D:\n     \"\"\"\n     Prune a Conv1D or linear layer to keep only entries in index.\n \n@@ -260,8 +258,8 @@ def forward(self, hidden_states):\n \n \n def find_pruneable_heads_and_indices(\n-    heads: List[int], n_heads: int, head_size: int, already_pruned_heads: Set[int]\n-) -> Tuple[Set[int], torch.LongTensor]:\n+    heads: list[int], n_heads: int, head_size: int, already_pruned_heads: set[int]\n+) -> tuple[set[int], torch.LongTensor]:\n     \"\"\"\n     Finds the heads and their indices taking `already_pruned_heads` into account.\n \n@@ -286,9 +284,7 @@ def find_pruneable_heads_and_indices(\n     return heads, index\n \n \n-def meshgrid(\n-    *tensors: Union[torch.Tensor, List[torch.Tensor]], indexing: Optional[str] = None\n-) -> Tuple[torch.Tensor, ...]:\n+def meshgrid(*tensors: torch.Tensor | list[torch.Tensor], indexing: str | None = None) -> tuple[torch.Tensor, ...]:\n     \"\"\"\n     Wrapper around torch.meshgrid to avoid warning messages about the introduced `indexing` argument.\n \n@@ -297,7 +293,7 @@ def meshgrid(\n     return torch.meshgrid(*tensors, indexing=indexing)\n \n \n-def id_tensor_storage(tensor: torch.Tensor) -> Tuple[torch.device, int, int]:\n+def id_tensor_storage(tensor: torch.Tensor) -> tuple[torch.device, int, int]:\n     \"\"\"\n     Unique identifier to a tensor storage. Multiple different tensors can share the same underlying storage. For\n     example, \"meta\" tensors all share the same storage, and thus their identifier will all be equal. This identifier is"
        },
        {
            "sha": "7a35e8f4acec62b7d9a6f37c517404f1faee47e0",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 9,
            "deletions": 10,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -33,12 +33,12 @@\n import time\n import unittest\n from collections import UserDict, defaultdict\n-from collections.abc import Mapping\n+from collections.abc import Generator, Iterable, Iterator, Mapping\n from dataclasses import MISSING, fields\n from functools import cache, wraps\n from io import StringIO\n from pathlib import Path\n-from typing import Any, Callable, Dict, Generator, Iterable, Iterator, List, Optional, Union\n+from typing import Any, Callable, Optional, Union\n from unittest import mock\n from unittest.mock import patch\n \n@@ -1456,14 +1456,13 @@ def get_steps_per_epoch(trainer: Trainer) -> int:\n \n \n def evaluate_side_effect_factory(\n-    side_effect_values: List[Dict[str, float]],\n-) -> Generator[Dict[str, float], None, None]:\n+    side_effect_values: list[dict[str, float]],\n+) -> Generator[dict[str, float], None, None]:\n     \"\"\"\n     Function that returns side effects for the _evaluate method.\n     Used when we're unsure of exactly how many times _evaluate will be called.\n     \"\"\"\n-    for side_effect_value in side_effect_values:\n-        yield side_effect_value\n+    yield from side_effect_values\n \n     while True:\n         yield side_effect_values[-1]\n@@ -2444,7 +2443,7 @@ def nested_simplify(obj, decimals=3):\n \n \n def check_json_file_has_correct_format(file_path):\n-    with open(file_path, \"r\") as f:\n+    with open(file_path) as f:\n         lines = f.readlines()\n         if len(lines) == 1:\n             # length can only be 1 if dict is empty\n@@ -2471,7 +2470,7 @@ class SubprocessCallException(Exception):\n     pass\n \n \n-def run_command(command: List[str], return_stdout=False):\n+def run_command(command: list[str], return_stdout=False):\n     \"\"\"\n     Runs `command` with `subprocess.check_output` and will potentially return the `stdout`. Will also properly capture\n     if an error occurred while running `command`\n@@ -2904,7 +2903,7 @@ def _find(self, tests, obj, name, module, source_lines, globs, seen) -> None:\n                 yield DoctestItem.from_parent(self, name=test.name, runner=runner, dtest=test)\n \n \n-def _device_agnostic_dispatch(device: str, dispatch_table: Dict[str, Callable], *args, **kwargs):\n+def _device_agnostic_dispatch(device: str, dispatch_table: dict[str, Callable], *args, **kwargs):\n     if device not in dispatch_table:\n         return dispatch_table[\"default\"](*args, **kwargs)\n \n@@ -2992,7 +2991,7 @@ def backend_device_count(device: str):\n \n         torch_device = device_name\n \n-        def update_mapping_from_spec(device_fn_dict: Dict[str, Callable], attribute_name: str):\n+        def update_mapping_from_spec(device_fn_dict: dict[str, Callable], attribute_name: str):\n             try:\n                 # Try to import the function directly\n                 spec_fn = getattr(device_spec_module, attribute_name)"
        },
        {
            "sha": "cf737315778798cadb0c69d0e9669a3bfb2c6312",
            "filename": "src/transformers/tf_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftf_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftf_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftf_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-from typing import List, Optional, Union\n+from typing import Optional, Union\n \n import numpy as np\n import tensorflow as tf\n@@ -25,7 +25,7 @@\n logger = logging.get_logger(__name__)\n \n \n-def shape_list(tensor: Union[tf.Tensor, np.ndarray]) -> List[int]:\n+def shape_list(tensor: Union[tf.Tensor, np.ndarray]) -> list[int]:\n     \"\"\"\n     Deal with dynamic shape in tensorflow cleanly.\n "
        },
        {
            "sha": "3a5cf4f2f4d8f636e623c07ae3400ca5e17b5891",
            "filename": "src/transformers/time_series_utils.py",
            "status": "modified",
            "additions": 8,
            "deletions": 9,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftime_series_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftime_series_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftime_series_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2023 The HuggingFace Inc. team.\n # Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n #\n@@ -17,7 +16,7 @@\n Time series distributional output classes and utilities.\n \"\"\"\n \n-from typing import Callable, Dict, Optional, Tuple\n+from typing import Callable, Optional\n \n import torch\n from torch import nn\n@@ -63,14 +62,14 @@ def stddev(self):\n \n class ParameterProjection(nn.Module):\n     def __init__(\n-        self, in_features: int, args_dim: Dict[str, int], domain_map: Callable[..., Tuple[torch.Tensor]], **kwargs\n+        self, in_features: int, args_dim: dict[str, int], domain_map: Callable[..., tuple[torch.Tensor]], **kwargs\n     ) -> None:\n         super().__init__(**kwargs)\n         self.args_dim = args_dim\n         self.proj = nn.ModuleList([nn.Linear(in_features, dim) for dim in args_dim.values()])\n         self.domain_map = domain_map\n \n-    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor]:\n+    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor]:\n         params_unbounded = [proj(x) for proj in self.proj]\n \n         return self.domain_map(*params_unbounded)\n@@ -88,7 +87,7 @@ def forward(self, x, *args):\n class DistributionOutput:\n     distribution_class: type\n     in_features: int\n-    args_dim: Dict[str, int]\n+    args_dim: dict[str, int]\n \n     def __init__(self, dim: int = 1) -> None:\n         self.dim = dim\n@@ -113,7 +112,7 @@ def distribution(\n             return AffineTransformed(distr, loc=loc, scale=scale, event_dim=self.event_dim)\n \n     @property\n-    def event_shape(self) -> Tuple:\n+    def event_shape(self) -> tuple:\n         r\"\"\"\n         Shape of each individual event contemplated by the distributions that this object constructs.\n         \"\"\"\n@@ -167,7 +166,7 @@ class StudentTOutput(DistributionOutput):\n     Student-T distribution output class.\n     \"\"\"\n \n-    args_dim: Dict[str, int] = {\"df\": 1, \"loc\": 1, \"scale\": 1}\n+    args_dim: dict[str, int] = {\"df\": 1, \"loc\": 1, \"scale\": 1}\n     distribution_class: type = StudentT\n \n     @classmethod\n@@ -182,7 +181,7 @@ class NormalOutput(DistributionOutput):\n     Normal distribution output class.\n     \"\"\"\n \n-    args_dim: Dict[str, int] = {\"loc\": 1, \"scale\": 1}\n+    args_dim: dict[str, int] = {\"loc\": 1, \"scale\": 1}\n     distribution_class: type = Normal\n \n     @classmethod\n@@ -196,7 +195,7 @@ class NegativeBinomialOutput(DistributionOutput):\n     Negative Binomial distribution output class.\n     \"\"\"\n \n-    args_dim: Dict[str, int] = {\"total_count\": 1, \"logits\": 1}\n+    args_dim: dict[str, int] = {\"total_count\": 1, \"logits\": 1}\n     distribution_class: type = NegativeBinomial\n \n     @classmethod"
        },
        {
            "sha": "dce4c581bf307366662543853d146fdbc444f001",
            "filename": "src/transformers/tokenization_utils.py",
            "status": "modified",
            "additions": 27,
            "deletions": 28,
            "changes": 55,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftokenization_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftokenization_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2020 The HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -22,7 +21,7 @@\n import re\n import unicodedata\n from collections import OrderedDict\n-from typing import Any, Dict, List, Optional, Tuple, Union, overload\n+from typing import Any, Optional, Union, overload\n \n from .tokenization_utils_base import (\n     ENCODE_KWARGS_DOCSTRING,\n@@ -103,7 +102,7 @@ def add(self, word: str):\n             ref = ref[char]\n         ref[self._termination_char] = 1\n \n-    def split(self, text: str) -> List[str]:\n+    def split(self, text: str) -> list[str]:\n         \"\"\"\n         Will look for the words added to the trie within `text`. Output is the original string splitted along the\n         boundaries of the words found.\n@@ -391,7 +390,7 @@ def _is_start_of_word(text):\n     return bool(_is_control(first_char) | _is_punctuation(first_char) | _is_whitespace(first_char))\n \n \n-def _insert_one_token_to_ordered_list(token_list: List[str], new_token: str):\n+def _insert_one_token_to_ordered_list(token_list: list[str], new_token: str):\n     \"\"\"\n     Inserts one token to an ordered list if it does not already exist. Note: token_list must be sorted.\n     \"\"\"\n@@ -425,11 +424,11 @@ def __init__(self, **kwargs):\n \n         # 2. init `_added_tokens_decoder` if child class did not\n         if not hasattr(self, \"_added_tokens_decoder\"):\n-            self._added_tokens_decoder: Dict[int, AddedToken] = {}\n+            self._added_tokens_decoder: dict[int, AddedToken] = {}\n \n         # 3. if a `added_tokens_decoder` is passed, we are loading from a saved tokenizer, we overwrite\n         self._added_tokens_decoder.update(kwargs.pop(\"added_tokens_decoder\", {}))\n-        self._added_tokens_encoder: Dict[str, int] = {k.content: v for v, k in self._added_tokens_decoder.items()}\n+        self._added_tokens_encoder: dict[str, int] = {k.content: v for v, k in self._added_tokens_decoder.items()}\n \n         # 4 init the parent class\n         super().__init__(**kwargs)\n@@ -455,15 +454,15 @@ def vocab_size(self) -> int:\n         raise NotImplementedError\n \n     @property\n-    def added_tokens_encoder(self) -> Dict[str, int]:\n+    def added_tokens_encoder(self) -> dict[str, int]:\n         \"\"\"\n         Returns the sorted mapping from string to index. The added tokens encoder is cached for performance\n         optimisation in `self._added_tokens_encoder` for the slow tokenizers.\n         \"\"\"\n         return {k.content: v for v, k in sorted(self._added_tokens_decoder.items(), key=lambda item: item[0])}\n \n     @property\n-    def added_tokens_decoder(self) -> Dict[int, AddedToken]:\n+    def added_tokens_decoder(self) -> dict[int, AddedToken]:\n         \"\"\"\n         Returns the added tokens in the vocabulary as a dictionary of index to AddedToken.\n \n@@ -473,7 +472,7 @@ def added_tokens_decoder(self) -> Dict[int, AddedToken]:\n         return dict(sorted(self._added_tokens_decoder.items(), key=lambda item: item[0]))\n \n     @added_tokens_decoder.setter\n-    def added_tokens_decoder(self, value: Dict[int, Union[AddedToken, str]]) -> Dict[int, AddedToken]:\n+    def added_tokens_decoder(self, value: dict[int, Union[AddedToken, str]]) -> dict[int, AddedToken]:\n         # Always raise an error if string because users should define the behavior\n         for index, token in value.items():\n             if not isinstance(token, (str, AddedToken)) or not isinstance(index, int):\n@@ -485,7 +484,7 @@ def added_tokens_decoder(self, value: Dict[int, Union[AddedToken, str]]) -> Dict\n             self._added_tokens_encoder[str(token)] = index\n         self._update_total_vocab_size()\n \n-    def get_added_vocab(self) -> Dict[str, int]:\n+    def get_added_vocab(self) -> dict[str, int]:\n         \"\"\"\n         Returns the added tokens in the vocabulary as a dictionary of token to index. Results might be different from\n         the fast call because for now we always add the tokens even if they are already in the vocabulary. This is\n@@ -510,7 +509,7 @@ def _update_total_vocab_size(self):\n         \"\"\"\n         self.total_vocab_size = len(self.get_vocab())\n \n-    def _add_tokens(self, new_tokens: Union[List[str], List[AddedToken]], special_tokens: bool = False) -> int:\n+    def _add_tokens(self, new_tokens: Union[list[str], list[AddedToken]], special_tokens: bool = False) -> int:\n         \"\"\"\n         Add a list of new tokens to the tokenizer class. If the new tokens are not in the vocabulary, they are added to\n         it with indices starting from length of the current vocabulary. Special tokens are sometimes already in the\n@@ -619,7 +618,7 @@ def num_special_tokens_to_add(self, pair: bool = False) -> int:\n         token_ids_1 = []\n         return len(self.build_inputs_with_special_tokens(token_ids_0, token_ids_1 if pair else None))\n \n-    def tokenize(self, text: TextInput, **kwargs) -> List[str]:\n+    def tokenize(self, text: TextInput, **kwargs) -> list[str]:\n         \"\"\"\n         Converts a string into a sequence of tokens, using the tokenizer.\n \n@@ -708,7 +707,7 @@ def _tokenize(self, text, **kwargs):\n         \"\"\"\n         raise NotImplementedError\n \n-    def convert_tokens_to_ids(self, tokens: Union[str, List[str]]) -> Union[int, List[int]]:\n+    def convert_tokens_to_ids(self, tokens: Union[str, list[str]]) -> Union[int, list[int]]:\n         \"\"\"\n         Converts a token string (or a sequence of tokens) in a single integer id (or a sequence of ids), using the\n         vocabulary.\n@@ -824,12 +823,12 @@ def get_input_ids(text):\n     def _batch_encode_plus(\n         self,\n         batch_text_or_text_pairs: Union[\n-            List[TextInput],\n-            List[TextInputPair],\n-            List[PreTokenizedInput],\n-            List[PreTokenizedInputPair],\n-            List[EncodedInput],\n-            List[EncodedInputPair],\n+            list[TextInput],\n+            list[TextInputPair],\n+            list[PreTokenizedInput],\n+            list[PreTokenizedInputPair],\n+            list[EncodedInput],\n+            list[EncodedInputPair],\n         ],\n         add_special_tokens: bool = True,\n         padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n@@ -913,7 +912,7 @@ def get_input_ids(text):\n     @add_end_docstrings(ENCODE_KWARGS_DOCSTRING, ENCODE_PLUS_ADDITIONAL_KWARGS_DOCSTRING)\n     def _batch_prepare_for_model(\n         self,\n-        batch_ids_pairs: List[Union[PreTokenizedInputPair, Tuple[List[int], None]]],\n+        batch_ids_pairs: list[Union[PreTokenizedInputPair, tuple[list[int], None]]],\n         add_special_tokens: bool = True,\n         padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n         truncation_strategy: TruncationStrategy = TruncationStrategy.DO_NOT_TRUNCATE,\n@@ -982,7 +981,7 @@ def _batch_prepare_for_model(\n \n     def prepare_for_tokenization(\n         self, text: str, is_split_into_words: bool = False, **kwargs\n-    ) -> Tuple[str, Dict[str, Any]]:\n+    ) -> tuple[str, dict[str, Any]]:\n         \"\"\"\n         Performs any necessary transformations before tokenization.\n \n@@ -1005,8 +1004,8 @@ def prepare_for_tokenization(\n         return (text, kwargs)\n \n     def get_special_tokens_mask(\n-        self, token_ids_0: List, token_ids_1: Optional[List] = None, already_has_special_tokens: bool = False\n-    ) -> List[int]:\n+        self, token_ids_0: list, token_ids_1: Optional[list] = None, already_has_special_tokens: bool = False\n+    ) -> list[int]:\n         \"\"\"\n         Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n         special tokens using the tokenizer `prepare_for_model` or `encode_plus` methods.\n@@ -1038,11 +1037,11 @@ def get_special_tokens_mask(\n     def convert_ids_to_tokens(self, ids: int, skip_special_tokens: bool = False) -> str: ...\n \n     @overload\n-    def convert_ids_to_tokens(self, ids: List[int], skip_special_tokens: bool = False) -> List[str]: ...\n+    def convert_ids_to_tokens(self, ids: list[int], skip_special_tokens: bool = False) -> list[str]: ...\n \n     def convert_ids_to_tokens(\n-        self, ids: Union[int, List[int]], skip_special_tokens: bool = False\n-    ) -> Union[str, List[str]]:\n+        self, ids: Union[int, list[int]], skip_special_tokens: bool = False\n+    ) -> Union[str, list[str]]:\n         \"\"\"\n         Converts a single index or a sequence of indices in a token or a sequence of tokens, using the vocabulary and\n         added tokens.\n@@ -1075,12 +1074,12 @@ def convert_ids_to_tokens(\n     def _convert_id_to_token(self, index: int) -> str:\n         raise NotImplementedError\n \n-    def convert_tokens_to_string(self, tokens: List[str]) -> str:\n+    def convert_tokens_to_string(self, tokens: list[str]) -> str:\n         return \" \".join(tokens)\n \n     def _decode(\n         self,\n-        token_ids: Union[int, List[int]],\n+        token_ids: Union[int, list[int]],\n         skip_special_tokens: bool = False,\n         clean_up_tokenization_spaces: bool = None,\n         spaces_between_special_tokens: bool = True,"
        },
        {
            "sha": "75819a1038b7178f6d28ed36c5e508e772a8b983",
            "filename": "src/transformers/tokenization_utils_fast.py",
            "status": "modified",
            "additions": 18,
            "deletions": 18,
            "changes": 36,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftokenization_utils_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftokenization_utils_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_utils_fast.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2020 The HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -21,7 +20,8 @@\n import json\n import os\n from collections import defaultdict\n-from typing import Any, Dict, Iterable, List, Optional, Tuple, Union\n+from collections.abc import Iterable\n+from typing import Any, Optional, Union\n \n import tokenizers.pre_tokenizers as pre_tokenizers_fast\n from tokenizers import Encoding as EncodingFast\n@@ -238,23 +238,23 @@ def vocab_size(self) -> int:\n         \"\"\"\n         return self._tokenizer.get_vocab_size(with_added_tokens=False)\n \n-    def get_vocab(self) -> Dict[str, int]:\n+    def get_vocab(self) -> dict[str, int]:\n         return self._tokenizer.get_vocab(with_added_tokens=True)\n \n     @property\n-    def vocab(self) -> Dict[str, int]:\n+    def vocab(self) -> dict[str, int]:\n         return self.get_vocab()\n \n     @property\n-    def added_tokens_encoder(self) -> Dict[str, int]:\n+    def added_tokens_encoder(self) -> dict[str, int]:\n         \"\"\"\n         Returns the sorted mapping from string to index. The added tokens encoder is cached for performance\n         optimisation in `self._added_tokens_encoder` for the slow tokenizers.\n         \"\"\"\n         return {k.content: v for v, k in sorted(self.added_tokens_decoder.items(), key=lambda item: item[0])}\n \n     @property\n-    def added_tokens_decoder(self) -> Dict[int, AddedToken]:\n+    def added_tokens_decoder(self) -> dict[int, AddedToken]:\n         \"\"\"\n         Returns the added tokens in the vocabulary as a dictionary of index to AddedToken.\n \n@@ -263,7 +263,7 @@ def added_tokens_decoder(self) -> Dict[int, AddedToken]:\n         \"\"\"\n         return self._tokenizer.get_added_tokens_decoder()\n \n-    def get_added_vocab(self) -> Dict[str, int]:\n+    def get_added_vocab(self) -> dict[str, int]:\n         \"\"\"\n         Returns the added tokens in the vocabulary as a dictionary of token to index.\n \n@@ -302,7 +302,7 @@ def _convert_encoding(\n         return_offsets_mapping: bool = False,\n         return_length: bool = False,\n         verbose: bool = True,\n-    ) -> Tuple[Dict[str, Any], List[EncodingFast]]:\n+    ) -> tuple[dict[str, Any], list[EncodingFast]]:\n         \"\"\"\n         Convert the encoding representation (from low-level HuggingFace tokenizer output) to a python Dict and a list\n         of encodings, take care of building a batch from overflowing tokens.\n@@ -339,7 +339,7 @@ def _convert_encoding(\n \n         return encoding_dict, encodings\n \n-    def convert_tokens_to_ids(self, tokens: Union[str, Iterable[str]]) -> Union[int, List[int]]:\n+    def convert_tokens_to_ids(self, tokens: Union[str, Iterable[str]]) -> Union[int, list[int]]:\n         \"\"\"\n         Converts a token string (or a sequence of tokens) in a single integer id (or a Iterable of ids), using the\n         vocabulary.\n@@ -364,7 +364,7 @@ def _convert_token_to_id_with_added_voc(self, token: str) -> int:\n     def _convert_id_to_token(self, index: int) -> Optional[str]:\n         return self._tokenizer.id_to_token(int(index))\n \n-    def _add_tokens(self, new_tokens: List[Union[str, AddedToken]], special_tokens=False) -> int:\n+    def _add_tokens(self, new_tokens: list[Union[str, AddedToken]], special_tokens=False) -> int:\n         if special_tokens:\n             return self._tokenizer.add_special_tokens(new_tokens)\n \n@@ -392,8 +392,8 @@ def num_special_tokens_to_add(self, pair: bool = False) -> int:\n         return self._tokenizer.num_special_tokens_to_add(pair)\n \n     def convert_ids_to_tokens(\n-        self, ids: Union[int, List[int]], skip_special_tokens: bool = False\n-    ) -> Union[str, List[str]]:\n+        self, ids: Union[int, list[int]], skip_special_tokens: bool = False\n+    ) -> Union[str, list[str]]:\n         \"\"\"\n         Converts a single index or a sequence of indices in a token or a sequence of tokens, using the vocabulary and\n         added tokens.\n@@ -417,7 +417,7 @@ def convert_ids_to_tokens(\n             tokens.append(self._tokenizer.id_to_token(index))\n         return tokens\n \n-    def tokenize(self, text: str, pair: Optional[str] = None, add_special_tokens: bool = False, **kwargs) -> List[str]:\n+    def tokenize(self, text: str, pair: Optional[str] = None, add_special_tokens: bool = False, **kwargs) -> list[str]:\n         return self.encode_plus(text=text, text_pair=pair, add_special_tokens=add_special_tokens, **kwargs).tokens()\n \n     def set_truncation_and_padding(\n@@ -498,7 +498,7 @@ def set_truncation_and_padding(\n     def _batch_encode_plus(\n         self,\n         batch_text_or_text_pairs: Union[\n-            List[TextInput], List[TextInputPair], List[PreTokenizedInput], List[PreTokenizedInputPair]\n+            list[TextInput], list[TextInputPair], list[PreTokenizedInput], list[PreTokenizedInputPair]\n         ],\n         add_special_tokens: bool = True,\n         padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n@@ -647,7 +647,7 @@ def _encode_plus(\n \n         return batched_output\n \n-    def convert_tokens_to_string(self, tokens: List[str]) -> str:\n+    def convert_tokens_to_string(self, tokens: list[str]) -> str:\n         return (\n             self.backend_tokenizer.decoder.decode(tokens)\n             if self.backend_tokenizer.decoder is not None\n@@ -656,7 +656,7 @@ def convert_tokens_to_string(self, tokens: List[str]) -> str:\n \n     def _decode(\n         self,\n-        token_ids: Union[int, List[int]],\n+        token_ids: Union[int, list[int]],\n         skip_special_tokens: bool = False,\n         clean_up_tokenization_spaces: bool = None,\n         **kwargs,\n@@ -681,10 +681,10 @@ def _decode(\n     def _save_pretrained(\n         self,\n         save_directory: Union[str, os.PathLike],\n-        file_names: Tuple[str],\n+        file_names: tuple[str],\n         legacy_format: Optional[bool] = None,\n         filename_prefix: Optional[str] = None,\n-    ) -> Tuple[str]:\n+    ) -> tuple[str]:\n         \"\"\"\n         Save a tokenizer using the slow-tokenizer/legacy format: vocabulary + added tokens as well as in a unique JSON\n         file containing {config + vocab + added-tokens}."
        },
        {
            "sha": "8533eb109fae54116644b957893e432accd108c9",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 47,
            "deletions": 48,
            "changes": 95,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2020-present the HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -34,7 +33,7 @@\n import warnings\n from collections.abc import Mapping\n from pathlib import Path\n-from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Type, Union\n+from typing import TYPE_CHECKING, Any, Callable, Optional, Union\n \n \n # Integrations must be imported before ML frameworks:\n@@ -419,16 +418,16 @@ def __init__(\n         args: TrainingArguments = None,\n         data_collator: Optional[DataCollator] = None,\n         train_dataset: Optional[Union[Dataset, IterableDataset, \"datasets.Dataset\"]] = None,\n-        eval_dataset: Optional[Union[Dataset, Dict[str, Dataset], \"datasets.Dataset\"]] = None,\n+        eval_dataset: Optional[Union[Dataset, dict[str, Dataset], \"datasets.Dataset\"]] = None,\n         processing_class: Optional[\n             Union[PreTrainedTokenizerBase, BaseImageProcessor, FeatureExtractionMixin, ProcessorMixin]\n         ] = None,\n         model_init: Optional[Callable[[], PreTrainedModel]] = None,\n         compute_loss_func: Optional[Callable] = None,\n-        compute_metrics: Optional[Callable[[EvalPrediction], Dict]] = None,\n-        callbacks: Optional[List[TrainerCallback]] = None,\n-        optimizers: Tuple[Optional[torch.optim.Optimizer], Optional[torch.optim.lr_scheduler.LambdaLR]] = (None, None),\n-        optimizer_cls_and_kwargs: Optional[Tuple[Type[torch.optim.Optimizer], Dict[str, Any]]] = None,\n+        compute_metrics: Optional[Callable[[EvalPrediction], dict]] = None,\n+        callbacks: Optional[list[TrainerCallback]] = None,\n+        optimizers: tuple[Optional[torch.optim.Optimizer], Optional[torch.optim.lr_scheduler.LambdaLR]] = (None, None),\n+        optimizer_cls_and_kwargs: Optional[tuple[type[torch.optim.Optimizer], dict[str, Any]]] = None,\n         preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,\n     ):\n         if args is None:\n@@ -1187,7 +1186,7 @@ def create_optimizer_and_scheduler(self, num_training_steps: int):\n             optimizer = self.optimizer\n         self.create_scheduler(num_training_steps=num_training_steps, optimizer=optimizer)\n \n-    def get_decay_parameter_names(self, model) -> List[str]:\n+    def get_decay_parameter_names(self, model) -> list[str]:\n         \"\"\"\n         Get all parameter names that weight decay will be applied to.\n \n@@ -1298,7 +1297,7 @@ def get_optimizer_group(self, param: Optional[Union[str, torch.nn.parameter.Para\n     @staticmethod\n     def get_optimizer_cls_and_kwargs(\n         args: TrainingArguments, model: Optional[PreTrainedModel] = None\n-    ) -> Tuple[Any, Any]:\n+    ) -> tuple[Any, Any]:\n         \"\"\"\n         Returns the optimizer class and optimizer parameters based on the training arguments.\n \n@@ -1324,10 +1323,10 @@ def get_optimizer_cls_and_kwargs(\n \n         def setup_low_rank_optimizer(\n             optimizer_name: str,\n-            optimizer_mapping: Dict[str, Any],\n-            optim_kwargs: Dict[str, Any],\n+            optimizer_mapping: dict[str, Any],\n+            optim_kwargs: dict[str, Any],\n             is_layerwise_supported: bool = True,\n-        ) -> Tuple[Any, Any]:\n+        ) -> tuple[Any, Any]:\n             \"\"\"\n             Helper function to set up low-rank optimizers like GaLore and Apollo.\n \n@@ -1783,7 +1782,7 @@ def num_tokens(train_dl: DataLoader, max_steps: Optional[int] = None) -> int:\n             logger.warning(\"Cannot get num_tokens from dataloader\")\n         return train_tokens\n \n-    def _hp_search_setup(self, trial: Union[\"optuna.Trial\", Dict[str, Any]]):\n+    def _hp_search_setup(self, trial: Union[\"optuna.Trial\", dict[str, Any]]):\n         \"\"\"HP search setup code\"\"\"\n         self._trial = trial\n \n@@ -1839,7 +1838,7 @@ def _hp_search_setup(self, trial: Union[\"optuna.Trial\", Dict[str, Any]]):\n \n         self.create_accelerator_and_postprocess()\n \n-    def _report_to_hp_search(self, trial: Union[\"optuna.Trial\", Dict[str, Any]], step: int, metrics: Dict[str, float]):\n+    def _report_to_hp_search(self, trial: Union[\"optuna.Trial\", dict[str, Any]], step: int, metrics: dict[str, float]):\n         if self.hp_search_backend is None or trial is None:\n             return\n         metrics = metrics.copy()\n@@ -2140,8 +2139,8 @@ def patched_optimizer_step(optimizer, barrier=False, optimizer_args={}):\n     def train(\n         self,\n         resume_from_checkpoint: Optional[Union[str, bool]] = None,\n-        trial: Union[\"optuna.Trial\", Dict[str, Any]] = None,\n-        ignore_keys_for_eval: Optional[List[str]] = None,\n+        trial: Union[\"optuna.Trial\", dict[str, Any]] = None,\n+        ignore_keys_for_eval: Optional[list[str]] = None,\n         **kwargs,\n     ):\n         \"\"\"\n@@ -3070,7 +3069,7 @@ def _maybe_log_save_evaluate(self, tr_loss, grad_norm, model, trial, epoch, igno\n             if is_torch_xla_available():\n                 xm.mark_step()\n \n-            logs: Dict[str, float] = {}\n+            logs: dict[str, float] = {}\n \n             # all_gather + mean() to get average loss over all processes\n             tr_loss_scalar = self._nested_gather(tr_loss).mean().item()\n@@ -3529,14 +3528,14 @@ def _load_callback_state(self):\n \n     def hyperparameter_search(\n         self,\n-        hp_space: Optional[Callable[[\"optuna.Trial\"], Dict[str, float]]] = None,\n-        compute_objective: Optional[Callable[[Dict[str, float]], float]] = None,\n+        hp_space: Optional[Callable[[\"optuna.Trial\"], dict[str, float]]] = None,\n+        compute_objective: Optional[Callable[[dict[str, float]], float]] = None,\n         n_trials: int = 20,\n-        direction: Union[str, List[str]] = \"minimize\",\n+        direction: Union[str, list[str]] = \"minimize\",\n         backend: Optional[Union[\"str\", HPSearchBackend]] = None,\n         hp_name: Optional[Callable[[\"optuna.Trial\"], str]] = None,\n         **kwargs,\n-    ) -> Union[BestRun, List[BestRun]]:\n+    ) -> Union[BestRun, list[BestRun]]:\n         \"\"\"\n         Launch an hyperparameter search using `optuna` or `Ray Tune` or `SigOpt`. The optimized quantity is determined\n         by `compute_objective`, which defaults to a function returning the evaluation loss when no metric is provided,\n@@ -3611,7 +3610,7 @@ def hyperparameter_search(\n         self.hp_search_backend = None\n         return best_run\n \n-    def log(self, logs: Dict[str, float], start_time: Optional[float] = None) -> None:\n+    def log(self, logs: dict[str, float], start_time: Optional[float] = None) -> None:\n         \"\"\"\n         Log `logs` on the various objects watching training.\n \n@@ -3652,7 +3651,7 @@ def _prepare_input(self, data: Union[torch.Tensor, Any]) -> Union[torch.Tensor,\n             return data.to(**kwargs)\n         return data\n \n-    def _prepare_inputs(self, inputs: Dict[str, Union[torch.Tensor, Any]]) -> Dict[str, Union[torch.Tensor, Any]]:\n+    def _prepare_inputs(self, inputs: dict[str, Union[torch.Tensor, Any]]) -> dict[str, Union[torch.Tensor, Any]]:\n         \"\"\"\n         Prepare `inputs` before feeding them to the model, converting them to tensors if they are not already and\n         handling potential state.\n@@ -3687,7 +3686,7 @@ def autocast_smart_context_manager(self, cache_enabled: Optional[bool] = True):\n         return ctx_manager\n \n     def training_step(\n-        self, model: nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]], num_items_in_batch=None\n+        self, model: nn.Module, inputs: dict[str, Union[torch.Tensor, Any]], num_items_in_batch=None\n     ) -> torch.Tensor:\n         \"\"\"\n         Perform a training step on a batch of inputs.\n@@ -4016,7 +4015,7 @@ def store_flos(self):\n \n     def _sorted_checkpoints(\n         self, output_dir=None, checkpoint_prefix=PREFIX_CHECKPOINT_DIR, use_mtime=False\n-    ) -> List[str]:\n+    ) -> list[str]:\n         ordering_and_checkpoint_path = []\n \n         glob_checkpoints = [str(x) for x in Path(output_dir).glob(f\"{checkpoint_prefix}-*\") if os.path.isdir(x)]\n@@ -4068,10 +4067,10 @@ def _rotate_checkpoints(self, use_mtime=False, output_dir=None) -> None:\n \n     def evaluate(\n         self,\n-        eval_dataset: Optional[Union[Dataset, Dict[str, Dataset]]] = None,\n-        ignore_keys: Optional[List[str]] = None,\n+        eval_dataset: Optional[Union[Dataset, dict[str, Dataset]]] = None,\n+        ignore_keys: Optional[list[str]] = None,\n         metric_key_prefix: str = \"eval\",\n-    ) -> Dict[str, float]:\n+    ) -> dict[str, float]:\n         \"\"\"\n         Run evaluation and returns metrics.\n \n@@ -4171,7 +4170,7 @@ def evaluate(\n         return output.metrics\n \n     def predict(\n-        self, test_dataset: Dataset, ignore_keys: Optional[List[str]] = None, metric_key_prefix: str = \"test\"\n+        self, test_dataset: Dataset, ignore_keys: Optional[list[str]] = None, metric_key_prefix: str = \"test\"\n     ) -> PredictionOutput:\n         \"\"\"\n         Run prediction and returns predictions and potential metrics.\n@@ -4239,7 +4238,7 @@ def evaluation_loop(\n         dataloader: DataLoader,\n         description: str,\n         prediction_loss_only: Optional[bool] = None,\n-        ignore_keys: Optional[List[str]] = None,\n+        ignore_keys: Optional[list[str]] = None,\n         metric_key_prefix: str = \"eval\",\n     ) -> EvalLoopOutput:\n         \"\"\"\n@@ -4339,11 +4338,11 @@ def evaluation_loop(\n \n             # Update containers\n             if losses is not None:\n-                losses = self.gather_function((losses.repeat(batch_size)))\n+                losses = self.gather_function(losses.repeat(batch_size))\n                 all_losses.add(losses)\n             if inputs_decode is not None:\n                 inputs_decode = self.accelerator.pad_across_processes(inputs_decode, dim=1, pad_index=-100)\n-                inputs_decode = self.gather_function((inputs_decode))\n+                inputs_decode = self.gather_function(inputs_decode)\n                 if not self.args.batch_eval_metrics or description == \"Prediction\":\n                     all_inputs.add(inputs_decode)\n             if labels is not None:\n@@ -4353,11 +4352,11 @@ def evaluation_loop(\n                 logits = self.accelerator.pad_across_processes(logits, dim=1, pad_index=-100)\n                 if self.preprocess_logits_for_metrics is not None:\n                     logits = self.preprocess_logits_for_metrics(logits, labels)\n-                logits = self.gather_function((logits))\n+                logits = self.gather_function(logits)\n                 if not self.args.batch_eval_metrics or description == \"Prediction\":\n                     all_preds.add(logits)\n             if labels is not None:\n-                labels = self.gather_function((labels))\n+                labels = self.gather_function(labels)\n                 if not self.args.batch_eval_metrics or description == \"Prediction\":\n                     all_labels.add(labels)\n \n@@ -4470,10 +4469,10 @@ def _nested_gather(self, tensors, name=None):\n     def prediction_step(\n         self,\n         model: nn.Module,\n-        inputs: Dict[str, Union[torch.Tensor, Any]],\n+        inputs: dict[str, Union[torch.Tensor, Any]],\n         prediction_loss_only: bool,\n-        ignore_keys: Optional[List[str]] = None,\n-    ) -> Tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]:\n+        ignore_keys: Optional[list[str]] = None,\n+    ) -> tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]:\n         \"\"\"\n         Perform an evaluation step on `model` using `inputs`.\n \n@@ -4572,7 +4571,7 @@ def prediction_step(\n \n         return (loss, logits, labels)\n \n-    def floating_point_ops(self, inputs: Dict[str, Union[torch.Tensor, Any]]):\n+    def floating_point_ops(self, inputs: dict[str, Union[torch.Tensor, Any]]):\n         \"\"\"\n         For models that inherit from [`PreTrainedModel`], uses that method to compute the number of floating point\n         operations for every backward + forward pass. If using another model, either implement such a method in the\n@@ -4612,13 +4611,13 @@ def create_model_card(\n         self,\n         language: Optional[str] = None,\n         license: Optional[str] = None,\n-        tags: Union[str, List[str], None] = None,\n+        tags: Union[str, list[str], None] = None,\n         model_name: Optional[str] = None,\n         finetuned_from: Optional[str] = None,\n-        tasks: Union[str, List[str], None] = None,\n-        dataset_tags: Union[str, List[str], None] = None,\n-        dataset: Union[str, List[str], None] = None,\n-        dataset_args: Union[str, List[str], None] = None,\n+        tasks: Union[str, list[str], None] = None,\n+        dataset_tags: Union[str, list[str], None] = None,\n+        dataset: Union[str, list[str], None] = None,\n+        dataset_args: Union[str, list[str], None] = None,\n     ):\n         \"\"\"\n         Creates a draft of a model card using the information available to the `Trainer`.\n@@ -4840,7 +4839,7 @@ def prediction_loop(\n         dataloader: DataLoader,\n         description: str,\n         prediction_loss_only: Optional[bool] = None,\n-        ignore_keys: Optional[List[str]] = None,\n+        ignore_keys: Optional[list[str]] = None,\n         metric_key_prefix: str = \"eval\",\n     ) -> EvalLoopOutput:\n         \"\"\"\n@@ -4904,9 +4903,9 @@ def prediction_loop(\n         logger.info(f\"  Batch size = {batch_size}\")\n \n         losses_host: torch.Tensor = None\n-        preds_host: Union[torch.Tensor, List[torch.Tensor]] = None\n-        labels_host: Union[torch.Tensor, List[torch.Tensor]] = None\n-        inputs_host: Union[torch.Tensor, List[torch.Tensor]] = None\n+        preds_host: Union[torch.Tensor, list[torch.Tensor]] = None\n+        labels_host: Union[torch.Tensor, list[torch.Tensor]] = None\n+        inputs_host: Union[torch.Tensor, list[torch.Tensor]] = None\n         metrics: Optional[dict] = None\n         eval_set_kwargs: dict = {}\n \n@@ -5047,7 +5046,7 @@ def _add_sm_patterns_to_gitignore(self) -> None:\n \n         # Get current .gitignore content\n         if os.path.exists(os.path.join(self.repo.local_dir, \".gitignore\")):\n-            with open(os.path.join(self.repo.local_dir, \".gitignore\"), \"r\") as f:\n+            with open(os.path.join(self.repo.local_dir, \".gitignore\")) as f:\n                 current_content = f.read()\n         else:\n             current_content = \"\""
        },
        {
            "sha": "ba54eb0def9e778a607413982f8eca4704d99a66",
            "filename": "src/transformers/trainer_callback.py",
            "status": "modified",
            "additions": 5,
            "deletions": 6,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftrainer_callback.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftrainer_callback.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer_callback.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2020-present the HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -20,7 +19,7 @@\n import json\n import math\n from dataclasses import dataclass\n-from typing import Dict, List, Optional, Union\n+from typing import Optional, Union\n \n import numpy as np\n from tqdm.auto import tqdm\n@@ -104,16 +103,16 @@ class TrainerState:\n     num_train_epochs: int = 0\n     num_input_tokens_seen: int = 0\n     total_flos: float = 0\n-    log_history: List[Dict[str, float]] = None\n+    log_history: list[dict[str, float]] = None\n     best_metric: Optional[float] = None\n     best_global_step: Optional[int] = None\n     best_model_checkpoint: Optional[str] = None\n     is_local_process_zero: bool = True\n     is_world_process_zero: bool = True\n     is_hyper_param_search: bool = False\n     trial_name: str = None\n-    trial_params: Dict[str, Union[str, float, int, bool]] = None\n-    stateful_callbacks: List[\"TrainerCallback\"] = None\n+    trial_params: dict[str, Union[str, float, int, bool]] = None\n+    stateful_callbacks: list[\"TrainerCallback\"] = None\n \n     def __post_init__(self):\n         if self.log_history is None:\n@@ -151,7 +150,7 @@ def save_to_json(self, json_path: str):\n     @classmethod\n     def load_from_json(cls, json_path: str):\n         \"\"\"Create an instance from the content of `json_path`.\"\"\"\n-        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n+        with open(json_path, encoding=\"utf-8\") as f:\n             text = f.read()\n         return cls(**json.loads(text))\n "
        },
        {
            "sha": "0fb8b47d4f44f0d6a0144a1df349655590630482",
            "filename": "src/transformers/trainer_pt_utils.py",
            "status": "modified",
            "additions": 8,
            "deletions": 9,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftrainer_pt_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftrainer_pt_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer_pt_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2020-present the HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -24,12 +23,12 @@\n import os\n import sys\n import warnings\n-from collections.abc import Mapping\n+from collections.abc import Iterator, Mapping\n from contextlib import contextmanager\n from dataclasses import dataclass, field\n from itertools import chain\n from logging import StreamHandler\n-from typing import Any, Dict, Iterator, List, Optional, Union\n+from typing import Any, Optional, Union\n \n import numpy as np\n import torch\n@@ -221,7 +220,7 @@ def distributed_concat(tensor: Any, num_total_examples: Optional[int] = None) ->\n \n \n def distributed_broadcast_scalars(\n-    scalars: List[Union[int, float]],\n+    scalars: list[Union[int, float]],\n     num_total_examples: Optional[int] = None,\n     device: Optional[torch.device] = torch.device(\"cuda\"),\n ) -> torch.Tensor:\n@@ -624,7 +623,7 @@ def __init__(\n         self,\n         batch_size: int,\n         dataset: Optional[Dataset] = None,\n-        lengths: Optional[List[int]] = None,\n+        lengths: Optional[list[int]] = None,\n         model_input_name: Optional[str] = None,\n         generator=None,\n     ):\n@@ -675,7 +674,7 @@ def __init__(\n         rank: Optional[int] = None,\n         seed: int = 0,\n         drop_last: bool = False,\n-        lengths: Optional[List[int]] = None,\n+        lengths: Optional[list[int]] = None,\n         model_input_name: Optional[str] = None,\n     ):\n         if dataset is None and lengths is None:\n@@ -936,7 +935,7 @@ def _secs2timedelta(secs):\n     return f\"{datetime.timedelta(seconds=int(secs))}.{msec:02d}\"\n \n \n-def metrics_format(self, metrics: Dict[str, float]) -> Dict[str, float]:\n+def metrics_format(self, metrics: dict[str, float]) -> dict[str, float]:\n     \"\"\"\n     Reformat Trainer metrics values to a human-readable format\n \n@@ -1080,7 +1079,7 @@ def save_metrics(self, split, metrics, combined=True):\n     if combined:\n         path = os.path.join(self.args.output_dir, \"all_results.json\")\n         if os.path.exists(path):\n-            with open(path, \"r\") as f:\n+            with open(path) as f:\n                 all_metrics = json.load(f)\n         else:\n             all_metrics = {}\n@@ -1300,7 +1299,7 @@ class AcceleratorConfig:\n         },\n     )\n \n-    gradient_accumulation_kwargs: Optional[Dict] = field(\n+    gradient_accumulation_kwargs: Optional[dict] = field(\n         default=None,\n         metadata={\n             \"help\": \"Additional kwargs to configure gradient accumulation, see [`accelerate.utils.GradientAccumulationPlugin`]. \""
        },
        {
            "sha": "9b2ab718a53708b33a25e8084bb8b048b14b5174",
            "filename": "src/transformers/trainer_seq2seq.py",
            "status": "modified",
            "additions": 11,
            "deletions": 11,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftrainer_seq2seq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftrainer_seq2seq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer_seq2seq.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -16,7 +16,7 @@\n import warnings\n from copy import deepcopy\n from pathlib import Path\n-from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union\n+from typing import TYPE_CHECKING, Any, Callable, Optional, Union\n \n import torch\n from torch import nn\n@@ -59,15 +59,15 @@ def __init__(\n         args: \"TrainingArguments\" = None,\n         data_collator: Optional[\"DataCollator\"] = None,\n         train_dataset: Optional[Union[Dataset, \"IterableDataset\", \"datasets.Dataset\"]] = None,\n-        eval_dataset: Optional[Union[Dataset, Dict[str, Dataset]]] = None,\n+        eval_dataset: Optional[Union[Dataset, dict[str, Dataset]]] = None,\n         processing_class: Optional[\n             Union[\"PreTrainedTokenizerBase\", \"BaseImageProcessor\", \"FeatureExtractionMixin\", \"ProcessorMixin\"]\n         ] = None,\n         model_init: Optional[Callable[[], \"PreTrainedModel\"]] = None,\n         compute_loss_func: Optional[Callable] = None,\n-        compute_metrics: Optional[Callable[[\"EvalPrediction\"], Dict]] = None,\n-        callbacks: Optional[List[\"TrainerCallback\"]] = None,\n-        optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None),\n+        compute_metrics: Optional[Callable[[\"EvalPrediction\"], dict]] = None,\n+        callbacks: Optional[list[\"TrainerCallback\"]] = None,\n+        optimizers: tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None),\n         preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,\n     ):\n         super().__init__(\n@@ -143,10 +143,10 @@ def load_generation_config(gen_config_arg: Union[str, GenerationConfig]) -> Gene\n     def evaluate(\n         self,\n         eval_dataset: Optional[Dataset] = None,\n-        ignore_keys: Optional[List[str]] = None,\n+        ignore_keys: Optional[list[str]] = None,\n         metric_key_prefix: str = \"eval\",\n         **gen_kwargs,\n-    ) -> Dict[str, float]:\n+    ) -> dict[str, float]:\n         \"\"\"\n         Run evaluation and returns metrics.\n \n@@ -199,7 +199,7 @@ def evaluate(\n     def predict(\n         self,\n         test_dataset: Dataset,\n-        ignore_keys: Optional[List[str]] = None,\n+        ignore_keys: Optional[list[str]] = None,\n         metric_key_prefix: str = \"test\",\n         **gen_kwargs,\n     ) -> \"PredictionOutput\":\n@@ -263,11 +263,11 @@ def predict(\n     def prediction_step(\n         self,\n         model: nn.Module,\n-        inputs: Dict[str, Union[torch.Tensor, Any]],\n+        inputs: dict[str, Union[torch.Tensor, Any]],\n         prediction_loss_only: bool,\n-        ignore_keys: Optional[List[str]] = None,\n+        ignore_keys: Optional[list[str]] = None,\n         **gen_kwargs,\n-    ) -> Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n+    ) -> tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n         \"\"\"\n         Perform an evaluation step on `model` using `inputs`.\n "
        },
        {
            "sha": "4d3dd6d6bb17fe0ca850c70bd58ffb534e99263b",
            "filename": "src/transformers/trainer_utils.py",
            "status": "modified",
            "additions": 19,
            "deletions": 20,
            "changes": 39,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftrainer_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftrainer_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer_utils.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -1,4 +1,3 @@\n-# coding=utf-8\n # Copyright 2020-present the HuggingFace Inc. team.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -25,7 +24,7 @@\n import re\n import threading\n import time\n-from typing import Any, Dict, List, NamedTuple, Optional, Tuple, Union\n+from typing import Any, NamedTuple, Optional, Union\n \n import numpy as np\n \n@@ -165,10 +164,10 @@ class EvalPrediction:\n \n     def __init__(\n         self,\n-        predictions: Union[np.ndarray, Tuple[np.ndarray]],\n-        label_ids: Union[np.ndarray, Tuple[np.ndarray]],\n-        inputs: Optional[Union[np.ndarray, Tuple[np.ndarray]]] = None,\n-        losses: Optional[Union[np.ndarray, Tuple[np.ndarray]]] = None,\n+        predictions: Union[np.ndarray, tuple[np.ndarray]],\n+        label_ids: Union[np.ndarray, tuple[np.ndarray]],\n+        inputs: Optional[Union[np.ndarray, tuple[np.ndarray]]] = None,\n+        losses: Optional[Union[np.ndarray, tuple[np.ndarray]]] = None,\n     ):\n         self.predictions = predictions\n         self.label_ids = label_ids\n@@ -190,22 +189,22 @@ def __getitem__(self, idx):\n \n \n class EvalLoopOutput(NamedTuple):\n-    predictions: Union[np.ndarray, Tuple[np.ndarray]]\n-    label_ids: Optional[Union[np.ndarray, Tuple[np.ndarray]]]\n-    metrics: Optional[Dict[str, float]]\n+    predictions: Union[np.ndarray, tuple[np.ndarray]]\n+    label_ids: Optional[Union[np.ndarray, tuple[np.ndarray]]]\n+    metrics: Optional[dict[str, float]]\n     num_samples: Optional[int]\n \n \n class PredictionOutput(NamedTuple):\n-    predictions: Union[np.ndarray, Tuple[np.ndarray]]\n-    label_ids: Optional[Union[np.ndarray, Tuple[np.ndarray]]]\n-    metrics: Optional[Dict[str, float]]\n+    predictions: Union[np.ndarray, tuple[np.ndarray]]\n+    label_ids: Optional[Union[np.ndarray, tuple[np.ndarray]]]\n+    metrics: Optional[dict[str, float]]\n \n \n class TrainOutput(NamedTuple):\n     global_step: int\n     training_loss: float\n-    metrics: Dict[str, float]\n+    metrics: dict[str, float]\n \n \n PREFIX_CHECKPOINT_DIR = \"checkpoint\"\n@@ -267,12 +266,12 @@ class BestRun(NamedTuple):\n     \"\"\"\n \n     run_id: str\n-    objective: Union[float, List[float]]\n-    hyperparameters: Dict[str, Any]\n+    objective: Union[float, list[float]]\n+    hyperparameters: dict[str, Any]\n     run_summary: Optional[Any] = None\n \n \n-def default_compute_objective(metrics: Dict[str, float]) -> float:\n+def default_compute_objective(metrics: dict[str, float]) -> float:\n     \"\"\"\n     The default objective to maximize/minimize when doing an hyperparameter search. It is the evaluation loss if no\n     metrics are provided to the [`Trainer`], the sum of all metrics otherwise.\n@@ -297,7 +296,7 @@ def default_compute_objective(metrics: Dict[str, float]) -> float:\n     return loss if len(metrics) == 0 else sum(metrics.values())\n \n \n-def default_hp_space_optuna(trial) -> Dict[str, float]:\n+def default_hp_space_optuna(trial) -> dict[str, float]:\n     from .integrations import is_optuna_available\n \n     assert is_optuna_available(), \"This function needs Optuna installed: `pip install optuna`\"\n@@ -309,7 +308,7 @@ def default_hp_space_optuna(trial) -> Dict[str, float]:\n     }\n \n \n-def default_hp_space_ray(trial) -> Dict[str, float]:\n+def default_hp_space_ray(trial) -> dict[str, float]:\n     from .integrations import is_ray_tune_available\n \n     assert is_ray_tune_available(), \"This function needs ray installed: `pip install ray[tune]`\"\n@@ -336,7 +335,7 @@ def default_hp_space_sigopt(trial):\n     ]\n \n \n-def default_hp_space_wandb(trial) -> Dict[str, float]:\n+def default_hp_space_wandb(trial) -> dict[str, float]:\n     from .integrations import is_wandb_available\n \n     if not is_wandb_available():\n@@ -867,7 +866,7 @@ def _remove_columns(self, feature: dict) -> dict:\n                 self.message_logged = True\n         return {k: v for k, v in feature.items() if k in self.signature_columns}\n \n-    def __call__(self, features: List[dict]):\n+    def __call__(self, features: list[dict]):\n         features = [self._remove_columns(feature) for feature in features]\n         return self.data_collator(features)\n "
        },
        {
            "sha": "6bbd4b89a7249d84db9a579fe75928a3bd5feafb",
            "filename": "src/transformers/training_args_tf.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftraining_args_tf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce091b1bda847bc3ba426cd5430a3d71e267cdae/src%2Ftransformers%2Ftraining_args_tf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftraining_args_tf.py?ref=ce091b1bda847bc3ba426cd5430a3d71e267cdae",
            "patch": "@@ -14,7 +14,7 @@\n \n import warnings\n from dataclasses import dataclass, field\n-from typing import Optional, Tuple\n+from typing import Optional\n \n from .training_args import TrainingArguments\n from .utils import cached_property, is_tf_available, logging, requires_backends\n@@ -189,7 +189,7 @@ class TFTrainingArguments(TrainingArguments):\n     xla: bool = field(default=False, metadata={\"help\": \"Whether to activate the XLA compilation or not\"})\n \n     @cached_property\n-    def _setup_strategy(self) -> Tuple[\"tf.distribute.Strategy\", int]:\n+    def _setup_strategy(self) -> tuple[\"tf.distribute.Strategy\", int]:\n         requires_backends(self, [\"tf\"])\n         logger.info(\"Tensorflow: setting up strategy\")\n "
        }
    ],
    "stats": {
        "total": 593,
        "additions": 285,
        "deletions": 308
    }
}