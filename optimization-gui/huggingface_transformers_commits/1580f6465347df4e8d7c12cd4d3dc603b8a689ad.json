{
    "author": "gante",
    "message": "[smollm3] add tokenizer mapping for `smollm3` (#39271)\n\nadd tok mapping to smollm3",
    "sha": "1580f6465347df4e8d7c12cd4d3dc603b8a689ad",
    "files": [
        {
            "sha": "dc1909bbb7aa24a60d6c5e6282b3224422e35267",
            "filename": "src/transformers/models/auto/tokenization_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/1580f6465347df4e8d7c12cd4d3dc603b8a689ad/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1580f6465347df4e8d7c12cd4d3dc603b8a689ad/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py?ref=1580f6465347df4e8d7c12cd4d3dc603b8a689ad",
            "patch": "@@ -580,6 +580,7 @@\n                 \"GemmaTokenizerFast\" if is_tokenizers_available() else None,\n             ),\n         ),\n+        (\"smollm3\", (None, \"PreTrainedTokenizerFast\" if is_tokenizers_available() else None)),\n         (\"speech_to_text\", (\"Speech2TextTokenizer\" if is_sentencepiece_available() else None, None)),\n         (\"speech_to_text_2\", (\"Speech2Text2Tokenizer\", None)),\n         (\"speecht5\", (\"SpeechT5Tokenizer\" if is_sentencepiece_available() else None, None)),"
        }
    ],
    "stats": {
        "total": 1,
        "additions": 1,
        "deletions": 0
    }
}