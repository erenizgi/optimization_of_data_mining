{
    "author": "qubvel",
    "message": "Update I-JEPA checkpoints path (#35120)\n\nUpdate checkpoints path",
    "sha": "c8c8dffbe45ebef0a8dba4a51024e5e5e498596b",
    "files": [
        {
            "sha": "32944e2617eae1d8c19c5469124e5b06c7552a16",
            "filename": "docs/source/en/model_doc/ijepa.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/c8c8dffbe45ebef0a8dba4a51024e5e5e498596b/docs%2Fsource%2Fen%2Fmodel_doc%2Fijepa.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/c8c8dffbe45ebef0a8dba4a51024e5e5e498596b/docs%2Fsource%2Fen%2Fmodel_doc%2Fijepa.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fijepa.md?ref=c8c8dffbe45ebef0a8dba4a51024e5e5e498596b",
            "patch": "@@ -45,7 +45,7 @@ url_2 = \"http://images.cocodataset.org/val2017/000000219578.jpg\"\n image_1 = Image.open(requests.get(url_1, stream=True).raw)\n image_2 = Image.open(requests.get(url_2, stream=True).raw)\n \n-model_id = \"jmtzt/ijepa_vith14_1k\"\n+model_id = \"facebook/ijepa_vith14_1k\"\n processor = AutoProcessor.from_pretrained(model_id)\n model = AutoModel.from_pretrained(model_id)\n "
        },
        {
            "sha": "3b3756dd5ce6970cad53ed5215db3e35a8359b1f",
            "filename": "src/transformers/models/ijepa/modular_ijepa.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/c8c8dffbe45ebef0a8dba4a51024e5e5e498596b/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodular_ijepa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c8c8dffbe45ebef0a8dba4a51024e5e5e498596b/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodular_ijepa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodular_ijepa.py?ref=c8c8dffbe45ebef0a8dba4a51024e5e5e498596b",
            "patch": "@@ -155,7 +155,7 @@ def __init__(self, config: IJepaConfig, add_pooling_layer: bool = False, use_mas\n         self.embeddings = IJepaEmbeddings(config, use_mask_token=use_mask_token)\n \n \n-_IMAGE_CLASS_CHECKPOINT = \"jmtzt/ijepa_vith14_1k\"\n+_IMAGE_CLASS_CHECKPOINT = \"facebook/ijepa_vith14_1k\"\n _IMAGE_CLASS_EXPECTED_OUTPUT = \"Egyptian cat\"\n \n "
        },
        {
            "sha": "723ddcf7988826e3170656d267e862e505c11740",
            "filename": "tests/models/ijepa/test_modeling_ijepa.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/c8c8dffbe45ebef0a8dba4a51024e5e5e498596b/tests%2Fmodels%2Fijepa%2Ftest_modeling_ijepa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c8c8dffbe45ebef0a8dba4a51024e5e5e498596b/tests%2Fmodels%2Fijepa%2Ftest_modeling_ijepa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fijepa%2Ftest_modeling_ijepa.py?ref=c8c8dffbe45ebef0a8dba4a51024e5e5e498596b",
            "patch": "@@ -250,7 +250,7 @@ def test_for_image_classification(self):\n \n     @slow\n     def test_model_from_pretrained(self):\n-        model_name = \"jmtzt/ijepa_vith14_1k\"\n+        model_name = \"facebook/ijepa_vith14_1k\"\n         model = IJepaModel.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n@@ -266,11 +266,11 @@ def prepare_img():\n class IJepaModelIntegrationTest(unittest.TestCase):\n     @cached_property\n     def default_image_processor(self):\n-        return ViTImageProcessor.from_pretrained(\"jmtzt/ijepa_vith14_1k\") if is_vision_available() else None\n+        return ViTImageProcessor.from_pretrained(\"facebook/ijepa_vith14_1k\") if is_vision_available() else None\n \n     @slow\n     def test_inference_no_head(self):\n-        model = IJepaModel.from_pretrained(\"jmtzt/ijepa_vith14_1k\").to(torch_device)\n+        model = IJepaModel.from_pretrained(\"facebook/ijepa_vith14_1k\").to(torch_device)\n \n         image_processor = self.default_image_processor\n         image = prepare_img()\n@@ -299,7 +299,7 @@ def test_inference_fp16(self):\n         A small test to make sure that inference work in half precision without any problem.\n         \"\"\"\n         model = IJepaModel.from_pretrained(\n-            \"jmtzt/ijepa_vith14_1k\",\n+            \"facebook/ijepa_vith14_1k\",\n             torch_dtype=torch.float16,\n             device_map=\"auto\",\n         )\n@@ -319,7 +319,7 @@ def test_inference_interpolate_pos_encoding(self):\n         # allowing to interpolate the pre-trained position embeddings in order to use\n         # the model on higher resolutions. The DINO model by Facebook AI leverages this\n         # to visualize self-attention on higher resolution images.\n-        model = IJepaModel.from_pretrained(\"jmtzt/ijepa_vith14_1k\").to(torch_device)\n+        model = IJepaModel.from_pretrained(\"facebook/ijepa_vith14_1k\").to(torch_device)\n \n         image_processor = self.default_image_processor\n         image = prepare_img()"
        }
    ],
    "stats": {
        "total": 14,
        "additions": 7,
        "deletions": 7
    }
}