{
    "author": "winglian",
    "message": "make sure to disable gradients for integer tensor (#32943)",
    "sha": "36759f33123208e0b5cd346d6c4ac64487652933",
    "files": [
        {
            "sha": "dd067c99a0b97dccb56a86272d98952f640c7719",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/36759f33123208e0b5cd346d6c4ac64487652933/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/36759f33123208e0b5cd346d6c4ac64487652933/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=36759f33123208e0b5cd346d6c4ac64487652933",
            "patch": "@@ -927,7 +927,10 @@ def _load_state_dict_into_meta_model(\n                 param_to = \"cpu\"\n                 if is_fsdp_enabled() and not is_local_dist_rank_0():\n                     param_to = \"meta\"\n-                value = type(value)(value.data.to(param_to), **value.__dict__)\n+                val_kwargs = {}\n+                if hasattr(module, \"weight\") and module.weight.__class__.__name__ == \"Int8Params\":\n+                    val_kwargs[\"requires_grad\"] = False\n+                value = type(value)(value.data.to(param_to), **val_kwargs, **value.__dict__)\n                 setattr(module, tensor_name, value)\n             # TODO: consider removing used param_parts from state_dict before return\n "
        }
    ],
    "stats": {
        "total": 5,
        "additions": 4,
        "deletions": 1
    }
}