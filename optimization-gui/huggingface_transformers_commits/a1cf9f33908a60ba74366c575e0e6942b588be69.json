{
    "author": "capemox",
    "message": "Fixed datatype related issues in `DataCollatorForLanguageModeling` (#36457)\n\nFixed 2 issues regarding `tests/trainer/test_data_collator.py::TFDataCollatorIntegrationTest::test_all_mask_replacement`:\n1. I got the error `RuntimeError: \"bernoulli_tensor_cpu_p_\" not implemented for 'Long'`. This is because the `mask_replacement_prob=1` and `torch.bernoulli` doesn't accept this type (which would be a `torch.long` dtype instead. I fixed this by manually casting the probability arguments in the `__post_init__` function of `DataCollatorForLanguageModeling`.\n2. I also got the error `tensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute Equal as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Equal]` due to the line `tf.reduce_all((batch[\"input_ids\"] == inputs) | (batch[\"input_ids\"] == tokenizer.mask_token_id))` in `test_data_collator.py`. This occurs because the type of the `inputs` variable is `tf.int32`. Solved this by manually casting it to `tf.int64` in the test, as the expected return type of `batch[\"input_ids\"]` is `tf.int64`.",
    "sha": "a1cf9f33908a60ba74366c575e0e6942b588be69",
    "files": [
        {
            "sha": "1de846857124aa835c7011cbb77a3dc818369c49",
            "filename": "src/transformers/data/data_collator.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/a1cf9f33908a60ba74366c575e0e6942b588be69/src%2Ftransformers%2Fdata%2Fdata_collator.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a1cf9f33908a60ba74366c575e0e6942b588be69/src%2Ftransformers%2Fdata%2Fdata_collator.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdata%2Fdata_collator.py?ref=a1cf9f33908a60ba74366c575e0e6942b588be69",
            "patch": "@@ -843,6 +843,10 @@ def __post_init__(self):\n         if self.random_replace_prob < 0 or self.random_replace_prob > 1:\n             raise ValueError(\"random_replace_prob should be between 0 and 1.\")\n \n+        self.mlm_probability = float(self.mlm_probability)\n+        self.mask_replace_prob = float(self.mask_replace_prob)\n+        self.random_replace_prob = float(self.random_replace_prob)\n+\n         if self.tf_experimental_compile:\n             import tensorflow as tf\n "
        },
        {
            "sha": "d631299c01f692ae2c198e5acbb6ab1acdd49bca",
            "filename": "tests/trainer/test_data_collator.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/a1cf9f33908a60ba74366c575e0e6942b588be69/tests%2Ftrainer%2Ftest_data_collator.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a1cf9f33908a60ba74366c575e0e6942b588be69/tests%2Ftrainer%2Ftest_data_collator.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_data_collator.py?ref=a1cf9f33908a60ba74366c575e0e6942b588be69",
            "patch": "@@ -1052,7 +1052,9 @@ def test_all_mask_replacement(self):\n \n         # confirm that every token is either the original token or [MASK]\n         self.assertTrue(\n-            tf.reduce_all((batch[\"input_ids\"] == inputs) | (batch[\"input_ids\"] == tokenizer.mask_token_id))\n+            tf.reduce_all(\n+                (batch[\"input_ids\"] == tf.cast(inputs, tf.int64)) | (batch[\"input_ids\"] == tokenizer.mask_token_id)\n+            )\n         )\n \n         # numpy call"
        }
    ],
    "stats": {
        "total": 8,
        "additions": 7,
        "deletions": 1
    }
}