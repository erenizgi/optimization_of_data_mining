{
    "author": "ylacombe",
    "message": "[Whisper test] Fix some failing tests (#33450)\n\n* Fix failing tensor placement in Whisper\r\n\r\n* fix long form generation tests\r\n\r\n* more return_timestamps=True\r\n\r\n* make fixup\r\n\r\n* [run_slow] whisper\r\n\r\n* [run_slow] whisper",
    "sha": "98adf24883b007c2a7fb17bab1c01b1614673433",
    "files": [
        {
            "sha": "ebc9ce5ec358eb8d8753d788fe5f06ec79a35f31",
            "filename": "tests/models/whisper/test_modeling_whisper.py",
            "status": "modified",
            "additions": 14,
            "deletions": 11,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/98adf24883b007c2a7fb17bab1c01b1614673433/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/98adf24883b007c2a7fb17bab1c01b1614673433/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py?ref=98adf24883b007c2a7fb17bab1c01b1614673433",
            "patch": "@@ -1683,9 +1683,9 @@ def test_labels_sequence_max_length_correct(self):\n             input_features = input_dict[\"input_features\"]\n \n             labels_length = config.max_target_positions\n-            labels = torch.ones(1, labels_length, dtype=torch.int64)\n+            labels = torch.ones(1, labels_length, dtype=torch.int64).to(torch_device)\n \n-            model = model_class(config)\n+            model = model_class(config).to(torch_device)\n             model(input_features=input_features, labels=labels)\n \n     def test_labels_sequence_max_length_correct_after_changing_config(self):\n@@ -1697,9 +1697,9 @@ def test_labels_sequence_max_length_correct_after_changing_config(self):\n             config.max_target_positions += 100\n \n             labels_length = config.max_target_positions\n-            labels = torch.ones(1, labels_length, dtype=torch.int64)\n+            labels = torch.ones(1, labels_length, dtype=torch.int64).to(torch_device)\n \n-            model = model_class(config)\n+            model = model_class(config).to(torch_device)\n             model(input_features=input_features, labels=labels)\n \n     def test_labels_sequence_max_length_error(self):\n@@ -1709,21 +1709,21 @@ def test_labels_sequence_max_length_error(self):\n             input_features = input_dict[\"input_features\"]\n \n             labels_length = config.max_target_positions + 1\n-            labels = torch.ones(1, labels_length, dtype=torch.int64)\n+            labels = torch.ones(1, labels_length, dtype=torch.int64).to(torch_device)\n \n-            model = model_class(config)\n+            model = model_class(config).to(torch_device)\n             with self.assertRaises(ValueError):\n                 model(input_features=input_features, labels=labels)\n \n     def test_labels_sequence_max_length_error_after_changing_config(self):\n         config, input_dict = self.model_tester.prepare_config_and_inputs_for_common()\n \n         for model_class in self.all_generative_model_classes:\n-            model = model_class(config)\n+            model = model_class(config).to(torch_device)\n             input_features = input_dict[\"input_features\"]\n \n             labels_length = config.max_target_positions + 1\n-            labels = torch.ones(1, labels_length, dtype=torch.int64)\n+            labels = torch.ones(1, labels_length, dtype=torch.int64).to(torch_device)\n \n             new_max_length = config.max_target_positions + 100\n             model.config.max_length = new_max_length\n@@ -2385,7 +2385,9 @@ def test_tiny_token_timestamp_generation_longform(self):\n         )\n \n         inputs = inputs.to(torch_device)\n-        generate_outputs = model.generate(**inputs, return_segments=True, return_token_timestamps=True)\n+        generate_outputs = model.generate(\n+            **inputs, return_segments=True, return_token_timestamps=True, return_timestamps=True\n+        )\n \n         token_timestamps_shape = [\n             [segment[\"token_timestamps\"].shape for segment in segment_list]\n@@ -2550,14 +2552,14 @@ def test_default_multilingual_transcription_long_form(self):\n         ).input_features.to(torch_device)\n \n         # task defaults to transcribe\n-        sequences = model.generate(input_features)\n+        sequences = model.generate(input_features, return_timestamps=True)\n \n         transcription = processor.batch_decode(sequences)[0]\n \n         assert transcription == \" मिर्ची में कितने विबिन्द प्रजातियां हैं? मिर्ची में कितने विबिन्द प्रजातियां हैं?\"\n \n         # set task to translate\n-        sequences = model.generate(input_features, task=\"translate\")\n+        sequences = model.generate(input_features, task=\"translate\", return_timestamps=True)\n         transcription = processor.batch_decode(sequences)[0]\n \n         assert (\n@@ -3264,6 +3266,7 @@ def test_whisper_empty_longform(self):\n             \"num_beams\": 5,\n             \"language\": \"fr\",\n             \"task\": \"transcribe\",\n+            \"return_timestamps\": True,\n         }\n \n         torch.manual_seed(0)"
        }
    ],
    "stats": {
        "total": 25,
        "additions": 14,
        "deletions": 11
    }
}