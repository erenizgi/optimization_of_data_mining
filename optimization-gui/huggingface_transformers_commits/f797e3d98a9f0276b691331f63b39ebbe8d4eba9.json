{
    "author": "LysandreJik",
    "message": "Fix the test fetcher (#37452)\n\nTest fetcher",
    "sha": "f797e3d98a9f0276b691331f63b39ebbe8d4eba9",
    "files": [
        {
            "sha": "3c751bceaac9731effd4da9697ef9f3f1cade262",
            "filename": "src/transformers/utils/import_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/f797e3d98a9f0276b691331f63b39ebbe8d4eba9/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f797e3d98a9f0276b691331f63b39ebbe8d4eba9/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fimport_utils.py?ref=f797e3d98a9f0276b691331f63b39ebbe8d4eba9",
            "patch": "@@ -2378,6 +2378,7 @@ def flatten_dict(_dict, previous_key=None):\n     return flattened_import_structure\n \n \n+@lru_cache()\n def define_import_structure(module_path: str, prefix: str = None) -> IMPORT_STRUCTURE_T:\n     \"\"\"\n     This method takes a module_path as input and creates an import structure digestible by a _LazyModule."
        },
        {
            "sha": "e2a256dfd6f69fae68535f0580a5f9fcfa639270",
            "filename": "utils/tests_fetcher.py",
            "status": "modified",
            "additions": 17,
            "deletions": 12,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/f797e3d98a9f0276b691331f63b39ebbe8d4eba9/utils%2Ftests_fetcher.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f797e3d98a9f0276b691331f63b39ebbe8d4eba9/utils%2Ftests_fetcher.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Ftests_fetcher.py?ref=f797e3d98a9f0276b691331f63b39ebbe8d4eba9",
            "patch": "@@ -736,7 +736,7 @@ def get_module_dependencies(module_fname: str, cache: Dict[str, List[str]] = Non\n             # the object is fully defined in the __init__)\n             if module.endswith(\"__init__.py\"):\n                 # So we get the imports from that init then try to find where our objects come from.\n-                new_imported_modules = extract_imports(module, cache=cache)\n+                new_imported_modules = dict(extract_imports(module, cache=cache))\n \n                 # Add imports via `define_import_structure` after the #35167 as we remove explicit import in `__init__.py`\n                 from transformers.utils.import_utils import define_import_structure\n@@ -749,9 +749,15 @@ def get_module_dependencies(module_fname: str, cache: Dict[str, List[str]] = Non\n                         # We replace with os.path.sep so that it's Windows-compatible\n                         _module = _module.replace(\".\", os.path.sep)\n                         _module = module.replace(\"__init__.py\", f\"{_module}.py\")\n-                        new_imported_modules.append((_module, list(_imports)))\n-\n-                for new_module, new_imports in new_imported_modules:\n+                        if _module not in new_imported_modules:\n+                            new_imported_modules[_module] = list(_imports)\n+                        else:\n+                            original_imports = new_imported_modules[_module]\n+                            for potential_new_item in list(_imports):\n+                                if potential_new_item not in original_imports:\n+                                    new_imported_modules[_module].append(potential_new_item)\n+\n+                for new_module, new_imports in new_imported_modules.items():\n                     if any(i in new_imports for i in imports):\n                         if new_module not in dependencies:\n                             new_modules.append((new_module, [i for i in new_imports if i in imports]))\n@@ -1041,18 +1047,17 @@ def infer_tests_to_run(\n     \"\"\"\n     if not test_all:\n         modified_files = get_modified_python_files(diff_with_last_commit=diff_with_last_commit)\n-        reverse_map = create_reverse_dependency_map()\n-        impacted_files = modified_files.copy()\n-        for f in modified_files:\n-            if f in reverse_map:\n-                impacted_files.extend(reverse_map[f])\n     else:\n-        impacted_files = modified_files = [\n-            str(k) for k in PATH_TO_TESTS.glob(\"*/*\") if str(k).endswith(\".py\") and \"test_\" in str(k)\n-        ]\n+        modified_files = [str(k) for k in PATH_TO_TESTS.glob(\"*/*\") if str(k).endswith(\".py\") and \"test_\" in str(k)]\n         print(\"\\n### test_all is TRUE, FETCHING ALL FILES###\\n\")\n     print(f\"\\n### MODIFIED FILES ###\\n{_print_list(modified_files)}\")\n \n+    reverse_map = create_reverse_dependency_map()\n+    impacted_files = modified_files.copy()\n+    for f in modified_files:\n+        if f in reverse_map:\n+            impacted_files.extend(reverse_map[f])\n+\n     # Remove duplicates\n     impacted_files = sorted(set(impacted_files))\n     print(f\"\\n### IMPACTED FILES ###\\n{_print_list(impacted_files)}\")"
        }
    ],
    "stats": {
        "total": 30,
        "additions": 18,
        "deletions": 12
    }
}