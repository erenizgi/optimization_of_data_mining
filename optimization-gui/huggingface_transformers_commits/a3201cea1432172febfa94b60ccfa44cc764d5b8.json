{
    "author": "gante",
    "message": "[CI] Automatic rerun of certain test failures (#36694)",
    "sha": "a3201cea1432172febfa94b60ccfa44cc764d5b8",
    "files": [
        {
            "sha": "eba90dac366c531ae09cdc86f0501cfdff634ea7",
            "filename": ".circleci/create_circleci_config.py",
            "status": "modified",
            "additions": 24,
            "deletions": 2,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/a3201cea1432172febfa94b60ccfa44cc764d5b8/.circleci%2Fcreate_circleci_config.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a3201cea1432172febfa94b60ccfa44cc764d5b8/.circleci%2Fcreate_circleci_config.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.circleci%2Fcreate_circleci_config.py?ref=a3201cea1432172febfa94b60ccfa44cc764d5b8",
            "patch": "@@ -33,6 +33,26 @@\n COMMON_PYTEST_OPTIONS = {\"max-worker-restart\": 0, \"dist\": \"loadfile\", \"vvv\": None, \"rsfE\":None}\n DEFAULT_DOCKER_IMAGE = [{\"image\": \"cimg/python:3.8.12\"}]\n \n+# Strings that commonly appear in the output of flaky tests when they fail. These are used with `pytest-rerunfailures`\n+# to rerun the tests that match these patterns.\n+FLAKY_TEST_FAILURE_PATTERNS = [\n+    \"OSError\",  # Machine/connection transient error\n+    \"Timeout\",  # Machine/connection transient error\n+    \"ConnectionError\",  # Connection transient error\n+    \"FileNotFoundError\",  # Raised by `datasets` on Hub failures\n+    \"PIL.UnidentifiedImageError\",  # Raised by `PIL.Image.open` on connection issues\n+    \"HTTPError.*502\",  # Hub-related\n+    \"HTTPError.*504\",  # Hub-related\n+    \"AssertionError: Tensor-likes are not close!\",  # `torch.testing.assert_close`, we might have unlucky random values\n+    # TODO: error downloading tokenizer's `merged.txt` from hub can cause all the exceptions below. Throw and handle\n+    # them under a single message.\n+    \"TypeError: expected str, bytes or os.PathLike object, not NoneType\",\n+    \"TypeError: stat: path should be string, bytes, os.PathLike or integer, not NoneType\",\n+    \"Converting from Tiktoken failed\",\n+    \"KeyError: <class \",\n+    \"TypeError: not a string\",\n+]\n+\n \n class EmptyJob:\n     job_name = \"empty\"\n@@ -124,7 +144,9 @@ def to_dict(self):\n                 # Examples special case: we need to download NLTK files in advance to avoid cuncurrency issues\n         timeout_cmd = f\"timeout {self.command_timeout} \" if self.command_timeout else \"\"\n         marker_cmd = f\"-m '{self.marker}'\" if self.marker is not None else \"\"\n-        additional_flags = f\" -p no:warning -o junit_family=xunit1 --junitxml=test-results/junit.xml\"\n+        junit_flags = f\" -p no:warning -o junit_family=xunit1 --junitxml=test-results/junit.xml\"\n+        joined_flaky_patterns = \"|\".join(FLAKY_TEST_FAILURE_PATTERNS)\n+        repeat_on_failure_flags = f\"--reruns 5 --reruns-delay 2 --only-rerun '({joined_flaky_patterns})'\"\n         parallel = f' << pipeline.parameters.{self.job_name}_parallelism >> '\n         steps = [\n             \"checkout\",\n@@ -152,7 +174,7 @@ def to_dict(self):\n             },\n             {\"run\": {\n                 \"name\": \"Run tests\",\n-                \"command\": f\"({timeout_cmd} python3 -m pytest {marker_cmd} -n {self.pytest_num_workers} {additional_flags} {' '.join(pytest_flags)} $(cat splitted_tests.txt) | tee tests_output.txt)\"}\n+                \"command\": f\"({timeout_cmd} python3 -m pytest {marker_cmd} -n {self.pytest_num_workers} {junit_flags} {repeat_on_failure_flags} {' '.join(pytest_flags)} $(cat splitted_tests.txt) | tee tests_output.txt)\"}\n             },\n             {\"run\": {\"name\": \"Expand to show skipped tests\", \"when\": \"always\", \"command\": f\"python3 .circleci/parse_test_outputs.py --file tests_output.txt --skip\"}},\n             {\"run\": {\"name\": \"Failed tests: show reasons\",   \"when\": \"always\", \"command\": f\"python3 .circleci/parse_test_outputs.py --file tests_output.txt --fail\"}},"
        },
        {
            "sha": "2261c44099c9dc172c4fb29ef30f9d9321482522",
            "filename": "docker/custom-tokenizers.dockerfile",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/a3201cea1432172febfa94b60ccfa44cc764d5b8/docker%2Fcustom-tokenizers.dockerfile",
            "raw_url": "https://github.com/huggingface/transformers/raw/a3201cea1432172febfa94b60ccfa44cc764d5b8/docker%2Fcustom-tokenizers.dockerfile",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docker%2Fcustom-tokenizers.dockerfile?ref=a3201cea1432172febfa94b60ccfa44cc764d5b8",
            "patch": "@@ -1,5 +1,6 @@\n FROM python:3.9-slim\n ENV PYTHONDONTWRITEBYTECODE=1\n+ARG REF=main\n USER root\n RUN apt-get update && apt-get install -y libsndfile1-dev espeak-ng time git cmake wget xz-utils build-essential g++5 libprotobuf-dev protobuf-compiler\n ENV UV_PYTHON=/usr/local/bin/python\n@@ -16,11 +17,11 @@ RUN make install -j 10\n \n \n RUN uv pip install --no-cache --upgrade 'torch' --index-url https://download.pytorch.org/whl/cpu\n-RUN uv pip install --no-cache-dir  --no-deps accelerate --extra-index-url https://download.pytorch.org/whl/cpu \n-RUN uv pip install  --no-cache-dir \"transformers[ja,testing,sentencepiece,jieba,spacy,ftfy,rjieba]\" unidic unidic-lite\n+RUN uv pip install --no-cache-dir  --no-deps accelerate --extra-index-url https://download.pytorch.org/whl/cpu\n+RUN uv pip install  --no-cache-dir \"git+https://github.com/huggingface/transformers.git@${REF}#egg=transformers[ja,testing,sentencepiece,jieba,spacy,ftfy,rjieba]\" unidic unidic-lite\n # spacy is not used so not tested. Causes to failures. TODO fix later\n RUN python3 -m unidic download\n RUN pip uninstall -y transformers\n \n RUN apt-get clean && rm -rf /var/lib/apt/lists/*\n-RUN apt remove -y g++ cmake  xz-utils libprotobuf-dev protobuf-compiler\n\\ No newline at end of file\n+RUN apt remove -y g++ cmake  xz-utils libprotobuf-dev protobuf-compiler"
        },
        {
            "sha": "16899e2a446304863bd8847f6dc0d1b45f28dcc4",
            "filename": "docker/examples-tf.dockerfile",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/a3201cea1432172febfa94b60ccfa44cc764d5b8/docker%2Fexamples-tf.dockerfile",
            "raw_url": "https://github.com/huggingface/transformers/raw/a3201cea1432172febfa94b60ccfa44cc764d5b8/docker%2Fexamples-tf.dockerfile",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docker%2Fexamples-tf.dockerfile?ref=a3201cea1432172febfa94b60ccfa44cc764d5b8",
            "patch": "@@ -1,12 +1,13 @@\n FROM python:3.9-slim\n ENV PYTHONDONTWRITEBYTECODE=1\n+ARG REF=main\n USER root\n RUN apt-get update && apt-get install -y libsndfile1-dev espeak-ng time git\n RUN apt-get install -y g++ cmake\n ENV UV_PYTHON=/usr/local/bin/python\n RUN pip --no-cache-dir install uv && uv venv\n RUN uv pip install --no-cache-dir -U pip setuptools albumentations seqeval\n-RUN pip install  --upgrade --no-cache-dir \"transformers[tf-cpu,sklearn,testing,sentencepiece,tf-speech,vision]\"\n-RUN uv pip install --no-cache-dir  \"protobuf==3.20.3\" \n+RUN pip install  --upgrade --no-cache-dir \"git+https://github.com/huggingface/transformers.git@${REF}#egg=transformers[tf-cpu,sklearn,testing,sentencepiece,tf-speech,vision]\"\n+RUN uv pip install --no-cache-dir  \"protobuf==3.20.3\"\n RUN pip uninstall -y transformers\n-RUN apt-get clean && rm -rf /var/lib/apt/lists/*\n\\ No newline at end of file\n+RUN apt-get clean && rm -rf /var/lib/apt/lists/*"
        },
        {
            "sha": "ec868cb10a13361a6c08fdcc138d2dbf287789b3",
            "filename": "docker/examples-torch.dockerfile",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/a3201cea1432172febfa94b60ccfa44cc764d5b8/docker%2Fexamples-torch.dockerfile",
            "raw_url": "https://github.com/huggingface/transformers/raw/a3201cea1432172febfa94b60ccfa44cc764d5b8/docker%2Fexamples-torch.dockerfile",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docker%2Fexamples-torch.dockerfile?ref=a3201cea1432172febfa94b60ccfa44cc764d5b8",
            "patch": "@@ -1,11 +1,12 @@\n FROM python:3.9-slim\n ENV PYTHONDONTWRITEBYTECODE=1\n+ARG REF=main\n USER root\n RUN apt-get update &&  apt-get install -y --no-install-recommends libsndfile1-dev espeak-ng time git g++ cmake pkg-config openssh-client git\n ENV UV_PYTHON=/usr/local/bin/python\n RUN pip --no-cache-dir install uv && uv venv && uv pip install --no-cache-dir -U pip setuptools\n RUN pip install --no-cache-dir 'torch' 'torchvision' 'torchaudio' --index-url https://download.pytorch.org/whl/cpu\n-RUN uv pip install --no-deps timm accelerate --extra-index-url https://download.pytorch.org/whl/cpu \n-RUN uv pip install --no-cache-dir librosa \"transformers[sklearn,sentencepiece,vision,testing]\" seqeval albumentations jiwer\n+RUN uv pip install --no-deps timm accelerate --extra-index-url https://download.pytorch.org/whl/cpu\n+RUN uv pip install --no-cache-dir librosa \"git+https://github.com/huggingface/transformers.git@${REF}#egg=transformers[sklearn,sentencepiece,vision,testing]\" seqeval albumentations jiwer\n RUN pip uninstall -y transformers\n-RUN apt-get clean && rm -rf /var/lib/apt/lists/*\n\\ No newline at end of file\n+RUN apt-get clean && rm -rf /var/lib/apt/lists/*"
        },
        {
            "sha": "e194982185b56e916d5dea025aae10777cf513b7",
            "filename": "setup.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/a3201cea1432172febfa94b60ccfa44cc764d5b8/setup.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a3201cea1432172febfa94b60ccfa44cc764d5b8/setup.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/setup.py?ref=a3201cea1432172febfa94b60ccfa44cc764d5b8",
            "patch": "@@ -150,6 +150,7 @@\n     \"pydantic\",\n     \"pytest>=7.2.0,<8.0.0\",\n     \"pytest-asyncio\",\n+    \"pytest-rerunfailures\",\n     \"pytest-timeout\",\n     \"pytest-xdist\",\n     \"pytest-order\",\n@@ -326,6 +327,7 @@ def run(self):\n         \"pytest-rich\",\n         \"pytest-xdist\",\n         \"pytest-order\",\n+        \"pytest-rerunfailures\",\n         \"timeout-decorator\",\n         \"parameterized\",\n         \"psutil\","
        },
        {
            "sha": "3fc3aafdbe8fe529984335162b94925438343e7d",
            "filename": "src/transformers/dependency_versions_table.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/a3201cea1432172febfa94b60ccfa44cc764d5b8/src%2Ftransformers%2Fdependency_versions_table.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a3201cea1432172febfa94b60ccfa44cc764d5b8/src%2Ftransformers%2Fdependency_versions_table.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdependency_versions_table.py?ref=a3201cea1432172febfa94b60ccfa44cc764d5b8",
            "patch": "@@ -56,6 +56,7 @@\n     \"pydantic\": \"pydantic\",\n     \"pytest\": \"pytest>=7.2.0,<8.0.0\",\n     \"pytest-asyncio\": \"pytest-asyncio\",\n+    \"pytest-rerunfailures\": \"pytest-rerunfailures\",\n     \"pytest-timeout\": \"pytest-timeout\",\n     \"pytest-xdist\": \"pytest-xdist\",\n     \"pytest-order\": \"pytest-order\","
        },
        {
            "sha": "6d25738691053000b0ece36f3c161908cd183ae6",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/a3201cea1432172febfa94b60ccfa44cc764d5b8/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a3201cea1432172febfa94b60ccfa44cc764d5b8/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=a3201cea1432172febfa94b60ccfa44cc764d5b8",
            "patch": "@@ -2518,6 +2518,11 @@ def is_flaky(max_attempts: int = 5, wait_before_retry: Optional[float] = None, d\n     \"\"\"\n     To decorate flaky tests. They will be retried on failures.\n \n+    Please note that our push tests use `pytest-rerunfailures`, which prompts the CI to rerun certain types of\n+    failed tests. More specifically, if the test exception contains any substring in `FLAKY_TEST_FAILURE_PATTERNS`\n+    (in `.circleci/create_circleci_config.py`), it will be rerun. If you find a recurrent pattern of failures,\n+    expand `FLAKY_TEST_FAILURE_PATTERNS` in our CI configuration instead of using `is_flaky`.\n+\n     Args:\n         max_attempts (`int`, *optional*, defaults to 5):\n             The maximum number of attempts to retry the flaky test."
        }
    ],
    "stats": {
        "total": 55,
        "additions": 44,
        "deletions": 11
    }
}