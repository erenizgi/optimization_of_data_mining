{
    "author": "bzhong-solink",
    "message": "Apply torchfix to replace deprecated functions: `_pytree._register_pytree_node` and `torch.cpu.amp.autocast` (#37372)\n\nfix: apply torchfix",
    "sha": "71b35387fd6d71487bd29e694ed10d925203e031",
    "files": [
        {
            "sha": "5b46763ecc5e8db2672897c39912fa1ca2a064ee",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/71b35387fd6d71487bd29e694ed10d925203e031/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/71b35387fd6d71487bd29e694ed10d925203e031/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=71b35387fd6d71487bd29e694ed10d925203e031",
            "patch": "@@ -3689,7 +3689,7 @@ def autocast_smart_context_manager(self, cache_enabled: Optional[bool] = True):\n         arguments, depending on the situation.\n         \"\"\"\n         if self.use_cpu_amp:\n-            ctx_manager = torch.cpu.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n+            ctx_manager = torch.amp.autocast(\"cpu\", cache_enabled=cache_enabled, dtype=self.amp_dtype)\n         else:\n             ctx_manager = contextlib.nullcontext()\n "
        },
        {
            "sha": "5e06241205d64d26666a9459abf3af6fa7a16685",
            "filename": "src/transformers/utils/generic.py",
            "status": "modified",
            "additions": 6,
            "deletions": 2,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/71b35387fd6d71487bd29e694ed10d925203e031/src%2Ftransformers%2Futils%2Fgeneric.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/71b35387fd6d71487bd29e694ed10d925203e031/src%2Ftransformers%2Futils%2Fgeneric.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fgeneric.py?ref=71b35387fd6d71487bd29e694ed10d925203e031",
            "patch": "@@ -343,14 +343,18 @@ def __init_subclass__(cls) -> None:\n         \"\"\"\n         if is_torch_available():\n             if version.parse(get_torch_version()) >= version.parse(\"2.2\"):\n-                _torch_pytree.register_pytree_node(\n+                from torch.utils._pytree import register_pytree_node\n+\n+                register_pytree_node(\n                     cls,\n                     _model_output_flatten,\n                     partial(_model_output_unflatten, output_type=cls),\n                     serialized_type_name=f\"{cls.__module__}.{cls.__name__}\",\n                 )\n             else:\n-                _torch_pytree._register_pytree_node(\n+                from torch.utils._pytree import register_pytree_node\n+\n+                register_pytree_node(\n                     cls,\n                     _model_output_flatten,\n                     partial(_model_output_unflatten, output_type=cls),"
        }
    ],
    "stats": {
        "total": 10,
        "additions": 7,
        "deletions": 3
    }
}