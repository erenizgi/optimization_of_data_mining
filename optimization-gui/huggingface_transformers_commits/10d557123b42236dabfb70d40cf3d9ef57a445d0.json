{
    "author": "ydshieh",
    "message": "Update some workflow files (#41892)\n\n* update\n\n* update\n\n* final check\n\n* final check\n\n* final clean\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "10d557123b42236dabfb70d40cf3d9ef57a445d0",
    "files": [
        {
            "sha": "711931a24d5a149a187a0369053c767931ebe024",
            "filename": ".github/workflows/benchmark.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/10d557123b42236dabfb70d40cf3d9ef57a445d0/.github%2Fworkflows%2Fbenchmark.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/10d557123b42236dabfb70d40cf3d9ef57a445d0/.github%2Fworkflows%2Fbenchmark.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fbenchmark.yml?ref=10d557123b42236dabfb70d40cf3d9ef57a445d0",
            "patch": "@@ -28,7 +28,7 @@ jobs:\n       (github.event_name == 'pull_request' && contains( github.event.pull_request.labels.*.name, 'run-benchmark') )||\r\n       (github.event_name == 'push' && github.ref == 'refs/heads/main')\r\n     container:\r\n-      image: huggingface/transformers-pytorch-gpu\r\n+      image: huggingface/transformers-all-latest-gpu\r\n       options: --gpus all --privileged --ipc host\r\n     steps:\r\n       - name: Get repo\r"
        },
        {
            "sha": "ba5bc2c9cb86b56f10c48cd2577ee0d00eb0de60",
            "filename": ".github/workflows/benchmark_v2_a10_caller.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/10d557123b42236dabfb70d40cf3d9ef57a445d0/.github%2Fworkflows%2Fbenchmark_v2_a10_caller.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/10d557123b42236dabfb70d40cf3d9ef57a445d0/.github%2Fworkflows%2Fbenchmark_v2_a10_caller.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fbenchmark_v2_a10_caller.yml?ref=10d557123b42236dabfb70d40cf3d9ef57a445d0",
            "patch": "@@ -9,7 +9,7 @@ jobs:\n     uses: ./.github/workflows/benchmark_v2.yml\n     with:\n       runner: aws-g5-4xlarge-cache-use1-public-80\n-      container_image: huggingface/transformers-pytorch-gpu\n+      container_image: huggingface/transformers-all-latest-gpu\n       container_options: --gpus all --privileged --ipc host --shm-size \"16gb\"\n       commit_sha: ${{ github.sha }}\n       run_id: ${{ github.run_id }}"
        },
        {
            "sha": "ccc0659409d229ee52d71c373bafc79db66717bf",
            "filename": ".github/workflows/build-docker-images.yml",
            "status": "modified",
            "additions": 20,
            "deletions": 103,
            "changes": 123,
            "blob_url": "https://github.com/huggingface/transformers/blob/10d557123b42236dabfb70d40cf3d9ef57a445d0/.github%2Fworkflows%2Fbuild-docker-images.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/10d557123b42236dabfb70d40cf3d9ef57a445d0/.github%2Fworkflows%2Fbuild-docker-images.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fbuild-docker-images.yml?ref=10d557123b42236dabfb70d40cf3d9ef57a445d0",
            "patch": "@@ -45,33 +45,20 @@ jobs:\n             REF=main\n           push: true\n           tags: huggingface/transformers-all-latest-gpu${{ inputs.image_postfix }}\n-      # Push CI images still need to be re-built daily\n-      -\n-        name: Build and push (for Push CI) in a daily basis\n-        # This condition allows `schedule` events, or `push` events that trigger this workflow NOT via `workflow_call`.\n-        # The later case is useful for manual image building for debugging purpose. Use another tag in this case!\n-        if: inputs.image_postfix != '-push-ci'\n-        uses: docker/build-push-action@v5\n-        with:\n-          context: ./docker/transformers-all-latest-gpu\n-          build-args: |\n-            REF=main\n-          push: true\n-          tags: huggingface/transformers-all-latest-gpu-push-ci\n \n       - name: Post to Slack\n         if: always()\n         uses: huggingface/hf-workflows/.github/actions/post-slack@main\n         with:\n           slack_channel: ${{ secrets.CI_SLACK_CHANNEL_DOCKER }}\n-          title: ðŸ¤— Results of the transformers-all-latest-gpu-push-ci docker build\n+          title: ðŸ¤— Results of the transformers-all-latest-gpu docker build\n           status: ${{ job.status }}\n           slack_token: ${{ secrets.SLACK_CIFEEDBACK_BOT_TOKEN }}\n \n-  latest-torch-deepspeed-docker:\n-    name: \"Latest PyTorch + DeepSpeed\"\n+  flash-attn-ci-image:\n+    name: \"PyTorch with Flash Attn [dev]\"\n     runs-on:\n-      group: aws-g4dn-2xlarge-cache\n+      group: aws-general-8-plus\n     steps:\n       -\n         name: Set up Docker Buildx\n@@ -89,26 +76,28 @@ jobs:\n         name: Build and push\n         uses: docker/build-push-action@v5\n         with:\n-          context: ./docker/transformers-pytorch-deepspeed-latest-gpu\n+          context: ./docker/transformers-all-latest-gpu\n           build-args: |\n-            REF=main\n+            REF=update_dockerfile\n+            PYTORCH=2.8.0\n+            TORCHCODEC=0.7.0\n+            FLASH_ATTN=yes\n           push: true\n-          tags: huggingface/transformers-pytorch-deepspeed-latest-gpu${{ inputs.image_postfix }}\n+          tags: huggingface/transformers-all-latest-gpu${{ inputs.image_postfix }}:flash-attn\n \n       - name: Post to Slack\n         if: always()\n         uses: huggingface/hf-workflows/.github/actions/post-slack@main\n         with:\n-          slack_channel: ${{ secrets.CI_SLACK_CHANNEL_DOCKER}}\n-          title: ðŸ¤— Results of the transformers-pytorch-deepspeed-latest-gpu docker build\n+          slack_channel: ${{ secrets.CI_SLACK_CHANNEL_DOCKER }}\n+          title: ðŸ¤— Results of the transformers-all-latest-gpu docker build\n           status: ${{ job.status }}\n           slack_token: ${{ secrets.SLACK_CIFEEDBACK_BOT_TOKEN }}\n \n-  # Can't build 2 images in a single job `latest-torch-deepspeed-docker` (for `nvcr.io/nvidia`)\n-  latest-torch-deepspeed-docker-for-push-ci-daily-build:\n-    name: \"Latest PyTorch + DeepSpeed (Push CI - Daily Build)\"\n+  latest-torch-deepspeed-docker:\n+    name: \"Latest PyTorch + DeepSpeed\"\n     runs-on:\n-      group: aws-general-8-plus\n+      group: aws-g4dn-2xlarge-cache\n     steps:\n       -\n         name: Set up Docker Buildx\n@@ -122,33 +111,27 @@ jobs:\n         with:\n           username: ${{ secrets.DOCKERHUB_USERNAME }}\n           password: ${{ secrets.DOCKERHUB_PASSWORD }}\n-      # Push CI images still need to be re-built daily\n       -\n-        name: Build and push (for Push CI) in a daily basis\n-        # This condition allows `schedule` events, or `push` events that trigger this workflow NOT via `workflow_call`.\n-        # The later case is useful for manual image building for debugging purpose. Use another tag in this case!\n-        if: inputs.image_postfix != '-push-ci'\n+        name: Build and push\n         uses: docker/build-push-action@v5\n         with:\n           context: ./docker/transformers-pytorch-deepspeed-latest-gpu\n           build-args: |\n             REF=main\n           push: true\n-          tags: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n+          tags: huggingface/transformers-pytorch-deepspeed-latest-gpu${{ inputs.image_postfix }}\n \n       - name: Post to Slack\n         if: always()\n         uses: huggingface/hf-workflows/.github/actions/post-slack@main\n         with:\n-          slack_channel: ${{ secrets.CI_SLACK_CHANNEL_DOCKER }}\n-          title: ðŸ¤— Results of the transformers-pytorch-deepspeed-latest-gpu-push-ci docker build\n+          slack_channel: ${{ secrets.CI_SLACK_CHANNEL_DOCKER}}\n+          title: ðŸ¤— Results of the transformers-pytorch-deepspeed-latest-gpu docker build\n           status: ${{ job.status }}\n           slack_token: ${{ secrets.SLACK_CIFEEDBACK_BOT_TOKEN }}\n \n   doc-builder:\n     name: \"Doc builder\"\n-    # Push CI doesn't need this image\n-    if: inputs.image_postfix != '-push-ci'\n     runs-on:\n       group: aws-general-8-plus\n     steps:\n@@ -181,44 +164,6 @@ jobs:\n           status: ${{ job.status }}\n           slack_token: ${{ secrets.SLACK_CIFEEDBACK_BOT_TOKEN }}\n \n-  latest-pytorch:\n-    name: \"Latest PyTorch [dev]\"\n-    # Push CI doesn't need this image\n-    if: inputs.image_postfix != '-push-ci'\n-    runs-on:\n-      group: aws-general-8-plus\n-    steps:\n-      -\n-        name: Set up Docker Buildx\n-        uses: docker/setup-buildx-action@v3\n-      -\n-        name: Check out code\n-        uses: actions/checkout@v4\n-      -\n-        name: Login to DockerHub\n-        uses: docker/login-action@v3\n-        with:\n-          username: ${{ secrets.DOCKERHUB_USERNAME }}\n-          password: ${{ secrets.DOCKERHUB_PASSWORD }}\n-      -\n-        name: Build and push\n-        uses: docker/build-push-action@v5\n-        with:\n-          context: ./docker/transformers-pytorch-gpu\n-          build-args: |\n-            REF=main\n-          push: true\n-          tags: huggingface/transformers-pytorch-gpu\n-\n-      - name: Post to Slack\n-        if: always()\n-        uses: huggingface/hf-workflows/.github/actions/post-slack@main\n-        with:\n-          slack_channel: ${{ secrets.CI_SLACK_CHANNEL_DOCKER }}\n-          title: ðŸ¤— Results of the huggingface/transformers-pytorch-gpudocker build\n-          status: ${{ job.status }}\n-          slack_token: ${{ secrets.SLACK_CIFEEDBACK_BOT_TOKEN }}\n-\n   latest-pytorch-amd:\n     name: \"Latest PyTorch (AMD) [dev]\"\n     runs-on:\n@@ -245,26 +190,13 @@ jobs:\n             REF=main\n           push: true\n           tags: huggingface/transformers-pytorch-amd-gpu${{ inputs.image_postfix }}\n-      # Push CI images still need to be re-built daily\n-      -\n-        name: Build and push (for Push CI) in a daily basis\n-        # This condition allows `schedule` events, or `push` events that trigger this workflow NOT via `workflow_call`.\n-        # The later case is useful for manual image building for debugging purpose. Use another tag in this case!\n-        if: inputs.image_postfix != '-push-ci'\n-        uses: docker/build-push-action@v5\n-        with:\n-          context: ./docker/transformers-pytorch-amd-gpu\n-          build-args: |\n-            REF=main\n-          push: true\n-          tags: huggingface/transformers-pytorch-amd-gpu-push-ci\n \n       - name: Post to Slack\n         if: always()\n         uses: huggingface/hf-workflows/.github/actions/post-slack@main\n         with:\n           slack_channel: ${{ secrets.CI_SLACK_CHANNEL_DOCKER }}\n-          title: ðŸ¤— Results of the huggingface/transformers-pytorch-amd-gpu-push-ci build\n+          title: ðŸ¤— Results of the huggingface/transformers-pytorch-amd-gpu build\n           status: ${{ job.status }}\n           slack_token: ${{ secrets.SLACK_CIFEEDBACK_BOT_TOKEN }}\n \n@@ -294,19 +226,6 @@ jobs:\n             REF=main\n           push: true\n           tags: huggingface/transformers-pytorch-deepspeed-amd-gpu${{ inputs.image_postfix }}\n-      # Push CI images still need to be re-built daily\n-      -\n-        name: Build and push (for Push CI) in a daily basis\n-        # This condition allows `schedule` events, or `push` events that trigger this workflow NOT via `workflow_call`.\n-        # The later case is useful for manual image building for debugging purpose. Use another tag in this case!\n-        if: inputs.image_postfix != '-push-ci'\n-        uses: docker/build-push-action@v5\n-        with:\n-          context: ./docker/transformers-pytorch-deepspeed-amd-gpu\n-          build-args: |\n-            REF=main\n-          push: true\n-          tags: huggingface/transformers-pytorch-deepspeed-amd-gpu-push-ci\n \n       - name: Post to Slack\n         if: always()\n@@ -319,8 +238,6 @@ jobs:\n \n   latest-quantization-torch-docker:\n     name: \"Latest Pytorch + Quantization [dev]\"\n-     # Push CI doesn't need this image\n-    if: inputs.image_postfix != '-push-ci'\n     runs-on:\n       group: aws-general-8-plus\n     steps:"
        },
        {
            "sha": "cf0dbb162386cb5526380443bad786687641ba76",
            "filename": ".github/workflows/push-important-models.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/10d557123b42236dabfb70d40cf3d9ef57a445d0/.github%2Fworkflows%2Fpush-important-models.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/10d557123b42236dabfb70d40cf3d9ef57a445d0/.github%2Fworkflows%2Fpush-important-models.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fpush-important-models.yml?ref=10d557123b42236dabfb70d40cf3d9ef57a445d0",
            "patch": "@@ -149,7 +149,7 @@ jobs:\n     with:\n       job: run_models_gpu\n       slack_report_channel: \"#transformers-ci-push\"\n-      docker: huggingface/transformers-all-latest-gpu\n+      docker: huggingface/transformers-all-latest-gpu:flash-attn\n       ci_event: push\n       report_repo_id: hf-internal-testing/transformers_ci_push\n       commit_sha: ${{ github.sha }}"
        },
        {
            "sha": "45b325f7b357bf838f2f876bb7f4748ed6204ee2",
            "filename": ".github/workflows/self-push-amd-mi210-caller.yml",
            "status": "removed",
            "additions": 0,
            "deletions": 25,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/259d174e368e3b1d430712c605229321f30c7c13/.github%2Fworkflows%2Fself-push-amd-mi210-caller.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/259d174e368e3b1d430712c605229321f30c7c13/.github%2Fworkflows%2Fself-push-amd-mi210-caller.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-push-amd-mi210-caller.yml?ref=259d174e368e3b1d430712c605229321f30c7c13",
            "patch": "@@ -1,25 +0,0 @@\n-name: Self-hosted runner (AMD mi210 CI caller)\n-\n-on:\n-  #workflow_run:\n-  #  workflows: [\"Self-hosted runner (push-caller)\"]\n-  #  branches: [\"main\"]\n-  #  types: [completed]\n-  push:\n-    branches:\n-      - run_amd_push_ci_caller*\n-    paths:\n-      - \"src/**\"\n-      - \"tests/**\"\n-      - \".github/**\"\n-      - \"templates/**\"\n-      - \"utils/**\"\n-\n-jobs:\n-  run_amd_ci:\n-    name: AMD mi210\n-    if: (cancelled() != true) && ((github.event_name == 'workflow_run') || ((github.event_name == 'push') && startsWith(github.ref_name, 'run_amd_push_ci_caller')))\n-    uses: ./.github/workflows/self-push-amd.yml\n-    with:\n-      gpu_flavor: mi210\n-    secrets: inherit"
        },
        {
            "sha": "91b978b593d0b5b37d2415677a35c8f73c434dac",
            "filename": ".github/workflows/self-push-amd-mi250-caller.yml",
            "status": "removed",
            "additions": 0,
            "deletions": 25,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/259d174e368e3b1d430712c605229321f30c7c13/.github%2Fworkflows%2Fself-push-amd-mi250-caller.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/259d174e368e3b1d430712c605229321f30c7c13/.github%2Fworkflows%2Fself-push-amd-mi250-caller.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-push-amd-mi250-caller.yml?ref=259d174e368e3b1d430712c605229321f30c7c13",
            "patch": "@@ -1,25 +0,0 @@\n-name: Self-hosted runner (AMD mi250 CI caller)\n-\n-on:\n-  #workflow_run:\n-  #  workflows: [\"Self-hosted runner (push-caller)\"]\n-  #  branches: [\"main\"]\n-  #  types: [completed]\n-  push:\n-    branches:\n-      - run_amd_push_ci_caller*\n-    paths:\n-      - \"src/**\"\n-      - \"tests/**\"\n-      - \".github/**\"\n-      - \"templates/**\"\n-      - \"utils/**\"\n-\n-jobs:\n-  run_amd_ci:\n-    name: AMD mi250\n-    if: (cancelled() != true) && ((github.event_name == 'workflow_run') || ((github.event_name == 'push') && startsWith(github.ref_name, 'run_amd_push_ci_caller')))\n-    uses: ./.github/workflows/self-push-amd.yml\n-    with:\n-      gpu_flavor: mi250\n-    secrets: inherit"
        },
        {
            "sha": "621061988949d3f57aa47b2a3740603c86800733",
            "filename": ".github/workflows/self-push-amd.yml",
            "status": "removed",
            "additions": 0,
            "deletions": 334,
            "changes": 334,
            "blob_url": "https://github.com/huggingface/transformers/blob/259d174e368e3b1d430712c605229321f30c7c13/.github%2Fworkflows%2Fself-push-amd.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/259d174e368e3b1d430712c605229321f30c7c13/.github%2Fworkflows%2Fself-push-amd.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-push-amd.yml?ref=259d174e368e3b1d430712c605229321f30c7c13",
            "patch": "@@ -1,334 +0,0 @@\n-name: Self-hosted runner AMD GPU (push)\n-\n-on:\n-  workflow_call:\n-    inputs:\n-      gpu_flavor:\n-        required: true\n-        type: string\n-\n-env:\n-  HF_HOME: /mnt/cache\n-  TRANSFORMERS_IS_CI: yes\n-  OMP_NUM_THREADS: 8\n-  MKL_NUM_THREADS: 8\n-  PYTEST_TIMEOUT: 60\n-  TF_FORCE_GPU_ALLOW_GROWTH: true\n-  HF_HUB_READ_TOKEN: ${{ secrets.HF_HUB_READ_TOKEN }}\n-\n-jobs:\n-  check_runner_status:\n-    name: Check Runner Status\n-    runs-on: ubuntu-22.04\n-    steps:\n-      - name: Checkout transformers\n-        uses: actions/checkout@v4\n-        with:\n-          fetch-depth: 2\n-\n-      - name: Check Runner Status\n-        run: python utils/check_self_hosted_runner.py --target_runners amd-mi210-single-gpu-ci-runner-docker --token ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n-\n-  check_runners:\n-    name: Check Runners\n-    needs: check_runner_status\n-    strategy:\n-      matrix:\n-        machine_type: [single-gpu, multi-gpu]\n-    runs-on: [self-hosted, amd-gpu, '${{ matrix.machine_type }}', '${{ inputs.gpu_flavor }}']\n-    container:\n-      image: huggingface/transformers-pytorch-amd-gpu-push-ci  # <--- We test only for PyTorch for now\n-      options: --device /dev/kfd --device /dev/dri --env ROCR_VISIBLE_DEVICES --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n-    steps:\n-      - name: ROCM-SMI\n-        run: |\n-          rocm-smi\n-      - name: ROCM-INFO\n-        run: |\n-          rocminfo  | grep \"Agent\" -A 14\n-      - name: Show ROCR environment\n-        run: |\n-          echo \"ROCR: $ROCR_VISIBLE_DEVICES\"\n-\n-  setup_gpu:\n-    name: Setup\n-    needs: check_runners\n-    strategy:\n-      matrix:\n-        machine_type: [single-gpu, multi-gpu]\n-    runs-on: [self-hosted, amd-gpu, '${{ matrix.machine_type }}', '${{ inputs.gpu_flavor }}']\n-    container:\n-      image: huggingface/transformers-pytorch-amd-gpu-push-ci  # <--- We test only for PyTorch for now\n-      options: --device /dev/kfd --device /dev/dri --env ROCR_VISIBLE_DEVICES --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n-    outputs:\n-      matrix: ${{ steps.set-matrix.outputs.matrix }}\n-      test_map: ${{ steps.set-matrix.outputs.test_map }}\n-    env:\n-      # `CI_BRANCH_PUSH`: The branch name from the push event\n-      # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n-      # `CI_SHA_PUSH`: The commit SHA from the push event\n-      # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n-      CI_BRANCH_PUSH: ${{ github.event.ref }}\n-      CI_BRANCH_WORKFLOW_RUN: ${{ github.event.workflow_run.head_branch }}\n-      CI_SHA_PUSH: ${{ github.event.head_commit.id }}\n-      CI_SHA_WORKFLOW_RUN: ${{ github.event.workflow_run.head_sha }}\n-    steps:\n-      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n-      # We also take into account the `push` event (we might want to test some changes in a branch)\n-      - name: Prepare custom environment variables\n-        shell: bash\n-        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n-        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n-        run: |\n-          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n-          echo $CI_BRANCH_PUSH\n-          echo $CI_BRANCH_WORKFLOW_RUN\n-          echo $CI_SHA_PUSH\n-          echo $CI_SHA_WORKFLOW_RUN\n-          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n-          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n-\n-      - name: print environment variables\n-        run: |\n-          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n-          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n-\n-      - name: Update clone using environment variables\n-        working-directory: /transformers\n-        run: |\n-          echo \"original branch = $(git branch --show-current)\"\n-          git fetch && git checkout ${{ env.CI_BRANCH }}\n-          echo \"updated branch = $(git branch --show-current)\"\n-          git checkout ${{ env.CI_SHA }}\n-          echo \"log = $(git log -n 1)\"\n-\n-      - name: Cleanup\n-        working-directory: /transformers\n-        run: |\n-          rm -rf tests/__pycache__\n-          rm -rf tests/models/__pycache__\n-          rm -rf reports\n-\n-      - name: Show installed libraries and their versions\n-        working-directory: /transformers\n-        run: pip freeze\n-\n-      - name: Fetch the tests to run\n-        working-directory: /transformers\n-        # TODO: add `git-python` in the docker images\n-        run: |\n-          pip install --upgrade git-python\n-          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n-\n-      - name: Report fetched tests\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: test_fetched\n-          path: /transformers/test_preparation.txt\n-\n-      - id: set-matrix\n-        name: Organize tests into models\n-        working-directory: /transformers\n-        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n-        # The `test_map` is used to get the actual identified test files under each key.\n-        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n-        run: |\n-          if [ -f test_map.json ]; then\n-              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n-              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n-          else\n-              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n-              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n-          fi\n-          echo $keys\n-          echo $test_map\n-          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n-          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n-\n-  run_models_gpu:\n-    name: Model tests\n-    needs: setup_gpu\n-    # `dummy` means there is no test to run\n-    if: contains(fromJson(needs.setup_gpu.outputs.matrix), 'dummy') != true\n-    strategy:\n-      fail-fast: false\n-      matrix:\n-        folders: ${{ fromJson(needs.setup_gpu.outputs.matrix) }}\n-        machine_type: [single-gpu, multi-gpu]\n-    runs-on: [self-hosted, amd-gpu, '${{ matrix.machine_type }}', '${{ inputs.gpu_flavor }}']\n-    container:\n-      image: huggingface/transformers-pytorch-amd-gpu-push-ci  # <--- We test only for PyTorch for now\n-      options: --device /dev/kfd --device /dev/dri --env ROCR_VISIBLE_DEVICES --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n-    env:\n-      # For the meaning of these environment variables, see the job `Setup`\n-      CI_BRANCH_PUSH: ${{ github.event.ref }}\n-      CI_BRANCH_WORKFLOW_RUN: ${{ github.event.workflow_run.head_branch }}\n-      CI_SHA_PUSH: ${{ github.event.head_commit.id }}\n-      CI_SHA_WORKFLOW_RUN: ${{ github.event.workflow_run.head_sha }}\n-    steps:\n-      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n-      # We also take into account the `push` event (we might want to test some changes in a branch)\n-      - name: Prepare custom environment variables\n-        shell: bash\n-        # For the meaning of these environment variables, see the job `Setup`\n-        run: |\n-          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n-          echo $CI_BRANCH_PUSH\n-          echo $CI_BRANCH_WORKFLOW_RUN\n-          echo $CI_SHA_PUSH\n-          echo $CI_SHA_WORKFLOW_RUN\n-          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n-          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n-\n-      - name: print environment variables\n-        run: |\n-          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n-          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n-\n-      - name: Update clone using environment variables\n-        working-directory: /transformers\n-        run: |\n-          echo \"original branch = $(git branch --show-current)\"\n-          git fetch && git checkout ${{ env.CI_BRANCH }}\n-          echo \"updated branch = $(git branch --show-current)\"\n-          git checkout ${{ env.CI_SHA }}\n-          echo \"log = $(git log -n 1)\"\n-\n-      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n-        working-directory: /transformers\n-        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n-\n-      - name: Echo folder ${{ matrix.folders }}\n-        shell: bash\n-        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n-        # set the artifact folder names (because the character `/` is not allowed).\n-        run: |\n-          echo \"${{ matrix.folders }}\"\n-          echo \"${{ fromJson(needs.setup_gpu.outputs.test_map)[matrix.folders] }}\"\n-          matrix_folders=${{ matrix.folders }}\n-          matrix_folders=${matrix_folders/'models/'/'models_'}\n-          echo \"$matrix_folders\"\n-          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n-\n-      - name: ROCM-SMI\n-        run: |\n-          rocm-smi\n-      - name: ROCM-INFO\n-        run: |\n-          rocminfo  | grep \"Agent\" -A 14\n-      - name: Show ROCR environment\n-        run: |\n-          echo \"ROCR: $ROCR_VISIBLE_DEVICES\"\n-\n-      - name: Environment\n-        working-directory: /transformers\n-        run: |\n-          python3 utils/print_env.py\n-\n-      - name: Show installed libraries and their versions\n-        working-directory: /transformers\n-        run: pip freeze\n-\n-      - name: Run all non-slow selected tests on GPU\n-        working-directory: /transformers\n-        run: |\n-          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports ${{ fromJson(needs.setup_gpu.outputs.test_map)[matrix.folders] }} -m \"not not_device_test\"\n-\n-      - name: Failure short reports\n-        if: ${{ failure() }}\n-        continue-on-error: true\n-        run: cat /transformers/reports/${{ matrix.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports/failures_short.txt\n-\n-      - name: \"Test suite reports artifacts: ${{ matrix.machine_type }}_run_models_gpu_${{ env.matrix_folders }}_test_reports\"\n-        if: ${{ always() }}\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: ${{ matrix.machine_type }}_run_models_gpu_${{ env.matrix_folders }}_test_reports\n-          path: /transformers/reports/${{ matrix.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports\n-\n-  send_results:\n-    name: Send results to webhook\n-    runs-on: ubuntu-22.04\n-    if: always()\n-    needs: [\n-        check_runner_status,\n-        check_runners,\n-        setup_gpu,\n-        run_models_gpu,\n-#        run_tests_torch_cuda_extensions_single_gpu,\n-#        run_tests_torch_cuda_extensions_multi_gpu\n-    ]\n-    env:\n-      # For the meaning of these environment variables, see the job `Setup`\n-      CI_BRANCH_PUSH: ${{ github.event.ref }}\n-      CI_BRANCH_WORKFLOW_RUN: ${{ github.event.workflow_run.head_branch }}\n-      CI_SHA_PUSH: ${{ github.event.head_commit.id }}\n-      CI_SHA_WORKFLOW_RUN: ${{ github.event.workflow_run.head_sha }}\n-    steps:\n-      - name: Preliminary job status\n-        shell: bash\n-        # For the meaning of these environment variables, see the job `Setup`\n-        run: |\n-          echo \"Runner availability: ${{ needs.check_runner_status.result }}\"\n-          echo \"Setup status: ${{ needs.setup_gpu.result }}\"\n-          echo \"Runner status: ${{ needs.check_runners.result }}\"\n-\n-      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n-      # We also take into account the `push` event (we might want to test some changes in a branch)\n-      - name: Prepare custom environment variables\n-        shell: bash\n-        # For the meaning of these environment variables, see the job `Setup`\n-        run: |\n-          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n-          echo $CI_BRANCH_PUSH\n-          echo $CI_BRANCH_WORKFLOW_RUN\n-          echo $CI_SHA_PUSH\n-          echo $CI_SHA_WORKFLOW_RUN\n-          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n-          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n-\n-      - name: print environment variables\n-        run: |\n-          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n-          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n-\n-      - uses: actions/checkout@v4\n-        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n-        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n-        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n-        with:\n-          fetch-depth: 20\n-\n-      - name: Update clone using environment variables\n-        run: |\n-          echo \"original branch = $(git branch --show-current)\"\n-          git fetch && git checkout ${{ env.CI_BRANCH }}\n-          echo \"updated branch = $(git branch --show-current)\"\n-          git checkout ${{ env.CI_SHA }}\n-          echo \"log = $(git log -n 1)\"\n-\n-      - uses: actions/download-artifact@v4\n-      - name: Send message to Slack\n-        env:\n-          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n-          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n-          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n-          CI_SLACK_CHANNEL_ID_AMD: ${{ secrets.CI_SLACK_CHANNEL_ID_AMD }}\n-          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n-          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID_AMD }}\n-          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n-          CI_EVENT: Push CI (AMD) - ${{ inputs.gpu_flavor }}\n-          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n-          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n-          CI_SHA: ${{ env.CI_SHA }}\n-          RUNNER_STATUS: ${{ needs.check_runner_status.result }}\n-          RUNNER_ENV_STATUS: ${{ needs.check_runners.result }}\n-          SETUP_STATUS: ${{ needs.setup_gpu.result }}\n-\n-        # We pass `needs.setup_gpu.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n-        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n-        run: |\n-          pip install huggingface_hub\n-          pip install slack_sdk\n-          pip show slack_sdk\n-          python utils/notification_service.py \"${{ needs.setup_gpu.outputs.matrix }}\""
        },
        {
            "sha": "56299f30e517222b13f00d2dbd7ba60ff1a7e53f",
            "filename": ".github/workflows/self-push-caller.yml",
            "status": "removed",
            "additions": 0,
            "deletions": 54,
            "changes": 54,
            "blob_url": "https://github.com/huggingface/transformers/blob/259d174e368e3b1d430712c605229321f30c7c13/.github%2Fworkflows%2Fself-push-caller.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/259d174e368e3b1d430712c605229321f30c7c13/.github%2Fworkflows%2Fself-push-caller.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-push-caller.yml?ref=259d174e368e3b1d430712c605229321f30c7c13",
            "patch": "@@ -1,54 +0,0 @@\n-# Used to trigger self-push CI\n-name: Self-hosted runner (push-caller)\n-\n-on:\n-  push:\n-    branches:\n-      - main\n-    paths:\n-      - \"src/**\"\n-      - \"tests/**\"\n-      - \".github/**\"\n-      - \"templates/**\"\n-      - \"utils/**\"\n-\n-jobs:\n-  check-for-setup:\n-      runs-on: ubuntu-22.04\n-      name: Check if setup was changed\n-      outputs:\n-        changed: ${{ steps.was_changed.outputs.changed }}\n-      steps:\n-        - uses: actions/checkout@v4\n-          with: \n-            fetch-depth: \"2\"\n-        \n-        - name: Get changed files\n-          id: changed-files\n-          uses: tj-actions/changed-files@1c8e6069583811afb28f97afeaf8e7da80c6be5c\n-        \n-        - name: Was setup changed \n-          id: was_changed\n-          run: |\n-            for file in ${{ steps.changed-files.outputs.all_changed_files }}; do\n-              if [ `basename \"${file}\"` = \"setup.py\" ]; then\n-                echo \"changed=1\" >> $GITHUB_OUTPUT\n-              fi\n-            done\n-\n-  build-docker-containers:\n-    needs: check-for-setup\n-    if: (github.event_name == 'push') && (needs.check-for-setup.outputs.changed == '1')\n-    uses: ./.github/workflows/build-docker-images.yml\n-    with:\n-      image_postfix: \"-push-ci\"\n-    secrets: inherit\n-\n-  run_push_ci:\n-    name: Trigger Push CI\n-    runs-on: ubuntu-22.04\n-    if: ${{ always() }}\n-    needs: build-docker-containers\n-    steps:\n-      - name: Trigger push CI via workflow_run\n-        run: echo \"Trigger push CI via workflow_run\""
        },
        {
            "sha": "67aedfc6c090233e9ecb88449e61948e3d2b53ba",
            "filename": ".github/workflows/self-push.yml",
            "status": "removed",
            "additions": 0,
            "deletions": 652,
            "changes": 652,
            "blob_url": "https://github.com/huggingface/transformers/blob/259d174e368e3b1d430712c605229321f30c7c13/.github%2Fworkflows%2Fself-push.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/259d174e368e3b1d430712c605229321f30c7c13/.github%2Fworkflows%2Fself-push.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-push.yml?ref=259d174e368e3b1d430712c605229321f30c7c13",
            "patch": "@@ -1,652 +0,0 @@\n-name: Self-hosted runner (push)\n-\n-on:\n-  workflow_run:\n-    workflows: [\"Self-hosted runner (push-caller)\"]\n-    branches: [\"main\"]\n-    types: [completed]\n-  push:\n-    branches:\n-      - ci_*\n-      - ci-*\n-    paths:\n-      - \"src/**\"\n-      - \"tests/**\"\n-      - \".github/**\"\n-      - \"templates/**\"\n-      - \"utils/**\"\n-  repository_dispatch:\n-\n-env:\n-  HF_HOME: /mnt/cache\n-  TRANSFORMERS_IS_CI: yes\n-  OMP_NUM_THREADS: 8\n-  MKL_NUM_THREADS: 8\n-  PYTEST_TIMEOUT: 60\n-  TF_FORCE_GPU_ALLOW_GROWTH: true\n-  CUDA_VISIBLE_DEVICES: 0,1\n-\n-jobs:\n-  setup:\n-    name: Setup\n-    strategy:\n-      matrix:\n-        machine_type: [aws-g5-4xlarge-cache, aws-g5-12xlarge-cache]\n-    runs-on:\n-      group: '${{ matrix.machine_type }}'\n-    container:\n-      image: huggingface/transformers-all-latest-gpu-push-ci\n-      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n-    outputs:\n-      matrix: ${{ steps.set-matrix.outputs.matrix }}\n-      test_map: ${{ steps.set-matrix.outputs.test_map }}\n-    env:\n-      # `CI_BRANCH_PUSH`: The branch name from the push event\n-      # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n-      # `CI_SHA_PUSH`: The commit SHA from the push event\n-      # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n-      CI_BRANCH_PUSH: ${{ github.event.ref }}\n-      CI_BRANCH_WORKFLOW_RUN: ${{ github.event.workflow_run.head_branch }}\n-      CI_SHA_PUSH: ${{ github.event.head_commit.id }}\n-      CI_SHA_WORKFLOW_RUN: ${{ github.event.workflow_run.head_sha }}\n-    steps:\n-      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n-      # We also take into account the `push` event (we might want to test some changes in a branch)\n-      - name: Prepare custom environment variables\n-        shell: bash\n-        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n-        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n-        run: |\n-          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n-          echo $CI_BRANCH_PUSH\n-          echo $CI_BRANCH_WORKFLOW_RUN\n-          echo $CI_SHA_PUSH\n-          echo $CI_SHA_WORKFLOW_RUN\n-          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n-          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n-\n-      - name: print environment variables\n-        run: |\n-          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n-          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n-\n-      - name: Update clone using environment variables\n-        working-directory: /transformers\n-        run: |\n-          echo \"original branch = $(git branch --show-current)\"\n-          git fetch && git checkout ${{ env.CI_BRANCH }}\n-          echo \"updated branch = $(git branch --show-current)\"\n-          git checkout ${{ env.CI_SHA }}\n-          echo \"log = $(git log -n 1)\"\n-\n-      - name: Cleanup\n-        working-directory: /transformers\n-        run: |\n-          rm -rf tests/__pycache__\n-          rm -rf tests/models/__pycache__\n-          rm -rf reports\n-\n-      - name: Show installed libraries and their versions\n-        working-directory: /transformers\n-        run: pip freeze\n-\n-      - name: Fetch the tests to run\n-        working-directory: /transformers\n-        # TODO: add `git-python` in the docker images\n-        run: |\n-          pip install --upgrade git-python\n-          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n-\n-      - name: Report fetched tests\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: test_fetched\n-          path: /transformers/test_preparation.txt\n-\n-      - id: set-matrix\n-        name: Organize tests into models\n-        working-directory: /transformers\n-        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n-        # The `test_map` is used to get the actual identified test files under each key.\n-        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n-        run: |\n-          if [ -f test_map.json ]; then\n-              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n-              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n-          else\n-              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n-              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n-          fi\n-          echo $keys\n-          echo $test_map\n-          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n-          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n-\n-  run_tests_single_gpu:\n-    name: Model tests\n-    needs: setup\n-    # `dummy` means there is no test to run\n-    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n-    strategy:\n-      fail-fast: false\n-      matrix:\n-        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n-        machine_type: [aws-g5-4xlarge-cache]\n-    runs-on:\n-      group: '${{ matrix.machine_type }}'\n-    container:\n-      image: huggingface/transformers-all-latest-gpu-push-ci\n-      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n-    env:\n-      # For the meaning of these environment variables, see the job `Setup`\n-      CI_BRANCH_PUSH: ${{ github.event.ref }}\n-      CI_BRANCH_WORKFLOW_RUN: ${{ github.event.workflow_run.head_branch }}\n-      CI_SHA_PUSH: ${{ github.event.head_commit.id }}\n-      CI_SHA_WORKFLOW_RUN: ${{ github.event.workflow_run.head_sha }}\n-    steps:\n-      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n-      # We also take into account the `push` event (we might want to test some changes in a branch)\n-      - name: Prepare custom environment variables\n-        shell: bash\n-        # For the meaning of these environment variables, see the job `Setup`\n-        run: |\n-          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n-          echo $CI_BRANCH_PUSH\n-          echo $CI_BRANCH_WORKFLOW_RUN\n-          echo $CI_SHA_PUSH\n-          echo $CI_SHA_WORKFLOW_RUN\n-          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n-          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n-\n-      - name: print environment variables\n-        run: |\n-          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n-          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n-\n-      - name: Set `machine_type` for report and artifact names\n-        working-directory: /transformers\n-        shell: bash\n-        run: |\n-          echo \"${{ matrix.machine_type }}\"\n-\n-          if [ \"${{ matrix.machine_type }}\" = \"aws-g5-4xlarge-cache\" ]; then\n-            machine_type=single-gpu\n-          elif [ \"${{ matrix.machine_type }}\" = \"aws-g5-12xlarge-cache\" ]; then\n-            machine_type=multi-gpu\n-          else\n-            machine_type=${{ matrix.machine_type }}\n-          fi\n-\n-          echo \"$machine_type\"\n-          echo \"machine_type=$machine_type\" >> $GITHUB_ENV\n-\n-      - name: Update clone using environment variables\n-        working-directory: /transformers\n-        run: |\n-          echo \"original branch = $(git branch --show-current)\"\n-          git fetch && git checkout ${{ env.CI_BRANCH }}\n-          echo \"updated branch = $(git branch --show-current)\"\n-          git checkout ${{ env.CI_SHA }}\n-          echo \"log = $(git log -n 1)\"\n-\n-      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n-        working-directory: /transformers\n-        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n-\n-      - name: Echo folder ${{ matrix.folders }}\n-        shell: bash\n-        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n-        # set the artifact folder names (because the character `/` is not allowed).\n-        run: |\n-          echo \"${{ matrix.folders }}\"\n-          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n-          matrix_folders=${{ matrix.folders }}\n-          matrix_folders=${matrix_folders/'models/'/'models_'}\n-          echo \"$matrix_folders\"\n-          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n-\n-      - name: NVIDIA-SMI\n-        run: |\n-          nvidia-smi\n-\n-      - name: Environment\n-        working-directory: /transformers\n-        run: |\n-          python3 utils/print_env.py\n-\n-      - name: Show installed libraries and their versions\n-        working-directory: /transformers\n-        run: pip freeze\n-\n-      - name: Run all non-slow selected tests on GPU\n-        working-directory: /transformers\n-        run: |\n-          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ env.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n-\n-      - name: Failure short reports\n-        if: ${{ failure() }}\n-        continue-on-error: true\n-        run: cat /transformers/reports/${{ env.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n-\n-      - name: \"Test suite reports artifacts: ${{ env.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\"\n-        if: ${{ always() }}\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: ${{ env.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n-          path: /transformers/reports/${{ env.machine_type }}_tests_gpu_${{ matrix.folders }}\n-\n-  run_tests_multi_gpu:\n-    name: Model tests\n-    needs: setup\n-    # `dummy` means there is no test to run\n-    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n-    strategy:\n-      fail-fast: false\n-      matrix:\n-        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n-        machine_type: [aws-g5-12xlarge-cache]\n-    runs-on:\n-      group: '${{ matrix.machine_type }}'\n-    container:\n-      image: huggingface/transformers-all-latest-gpu-push-ci\n-      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n-    env:\n-      # For the meaning of these environment variables, see the job `Setup`\n-      CI_BRANCH_PUSH: ${{ github.event.ref }}\n-      CI_BRANCH_WORKFLOW_RUN: ${{ github.event.workflow_run.head_branch }}\n-      CI_SHA_PUSH: ${{ github.event.head_commit.id }}\n-      CI_SHA_WORKFLOW_RUN: ${{ github.event.workflow_run.head_sha }}\n-    steps:\n-      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n-      # We also take into account the `push` event (we might want to test some changes in a branch)\n-      - name: Prepare custom environment variables\n-        shell: bash\n-        # For the meaning of these environment variables, see the job `Setup`\n-        run: |\n-          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n-          echo $CI_BRANCH_PUSH\n-          echo $CI_BRANCH_WORKFLOW_RUN\n-          echo $CI_SHA_PUSH\n-          echo $CI_SHA_WORKFLOW_RUN\n-          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n-          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n-\n-      - name: print environment variables\n-        run: |\n-          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n-          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n-\n-      - name: Set `machine_type` for report and artifact names\n-        working-directory: /transformers\n-        shell: bash\n-        run: |\n-          echo \"${{ matrix.machine_type }}\"\n-\n-          if [ \"${{ matrix.machine_type }}\" = \"aws-g5-4xlarge-cache\" ]; then\n-            machine_type=single-gpu\n-          elif [ \"${{ matrix.machine_type }}\" = \"aws-g5-12xlarge-cache\" ]; then\n-            machine_type=multi-gpu\n-          else\n-            machine_type=${{ matrix.machine_type }}\n-          fi\n-\n-          echo \"$machine_type\"\n-          echo \"machine_type=$machine_type\" >> $GITHUB_ENV\n-\n-      - name: Update clone using environment variables\n-        working-directory: /transformers\n-        run: |\n-          echo \"original branch = $(git branch --show-current)\"\n-          git fetch && git checkout ${{ env.CI_BRANCH }}\n-          echo \"updated branch = $(git branch --show-current)\"\n-          git checkout ${{ env.CI_SHA }}\n-          echo \"log = $(git log -n 1)\"\n-\n-      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n-        working-directory: /transformers\n-        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n-\n-      - name: Echo folder ${{ matrix.folders }}\n-        shell: bash\n-        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n-        # set the artifact folder names (because the character `/` is not allowed).\n-        run: |\n-          echo \"${{ matrix.folders }}\"\n-          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n-          matrix_folders=${{ matrix.folders }}\n-          matrix_folders=${matrix_folders/'models/'/'models_'}\n-          echo \"$matrix_folders\"\n-          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n-\n-      - name: NVIDIA-SMI\n-        run: |\n-          nvidia-smi\n-\n-      - name: Environment\n-        working-directory: /transformers\n-        run: |\n-          python3 utils/print_env.py\n-\n-      - name: Show installed libraries and their versions\n-        working-directory: /transformers\n-        run: pip freeze\n-\n-      - name: Run all non-slow selected tests on GPU\n-        env:\n-          MKL_SERVICE_FORCE_INTEL: 1\n-        working-directory: /transformers\n-        run: |\n-          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ env.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n-\n-      - name: Failure short reports\n-        if: ${{ failure() }}\n-        continue-on-error: true\n-        run: cat /transformers/reports/${{ env.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n-\n-      - name: \"Test suite reports artifacts: ${{ env.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\"\n-        if: ${{ always() }}\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: ${{ env.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n-          path: /transformers/reports/${{ env.machine_type }}_tests_gpu_${{ matrix.folders }}\n-\n-  run_tests_torch_cuda_extensions_single_gpu:\n-    name: Torch CUDA extension tests\n-    needs: setup\n-    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n-    strategy:\n-      fail-fast: false\n-      matrix:\n-        machine_type: [aws-g5-4xlarge-cache]\n-    runs-on:\n-      group: '${{ matrix.machine_type }}'\n-    container:\n-      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n-      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n-    env:\n-      # For the meaning of these environment variables, see the job `Setup`\n-      CI_BRANCH_PUSH: ${{ github.event.ref }}\n-      CI_BRANCH_WORKFLOW_RUN: ${{ github.event.workflow_run.head_branch }}\n-      CI_SHA_PUSH: ${{ github.event.head_commit.id }}\n-      CI_SHA_WORKFLOW_RUN: ${{ github.event.workflow_run.head_sha }}\n-    steps:\n-      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n-      # We also take into account the `push` event (we might want to test some changes in a branch)\n-      - name: Prepare custom environment variables\n-        shell: bash\n-        # For the meaning of these environment variables, see the job `Setup`\n-        run: |\n-          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n-          echo $CI_BRANCH_PUSH\n-          echo $CI_BRANCH_WORKFLOW_RUN\n-          echo $CI_SHA_PUSH\n-          echo $CI_SHA_WORKFLOW_RUN\n-          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n-          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n-\n-      - name: print environment variables\n-        run: |\n-          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n-          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n-\n-      - name: Set `machine_type` for report and artifact names\n-        working-directory: /workspace/transformers\n-        shell: bash\n-        run: |\n-          echo \"${{ matrix.machine_type }}\"\n-\n-          if [ \"${{ matrix.machine_type }}\" = \"aws-g5-4xlarge-cache\" ]; then\n-            machine_type=single-gpu\n-          elif [ \"${{ matrix.machine_type }}\" = \"aws-g5-12xlarge-cache\" ]; then\n-            machine_type=multi-gpu\n-          else\n-            machine_type=${{ matrix.machine_type }}\n-          fi\n-\n-          echo \"$machine_type\"\n-          echo \"machine_type=$machine_type\" >> $GITHUB_ENV\n-\n-      - name: Update clone using environment variables\n-        working-directory: /workspace/transformers\n-        run: |\n-          echo \"original branch = $(git branch --show-current)\"\n-          git fetch && git checkout ${{ env.CI_BRANCH }}\n-          echo \"updated branch = $(git branch --show-current)\"\n-          git checkout ${{ env.CI_SHA }}\n-          echo \"log = $(git log -n 1)\"\n-\n-      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n-        working-directory: /workspace/transformers\n-        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n-\n-      - name: Remove cached torch extensions\n-        run: rm -rf /github/home/.cache/torch_extensions/\n-\n-      # To avoid unknown test failures\n-      - name: Pre build DeepSpeed *again*\n-        working-directory: /workspace\n-        run: |\n-          python3 -m pip uninstall -y deepspeed\n-          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n-\n-      - name: NVIDIA-SMI\n-        run: |\n-          nvidia-smi\n-\n-      - name: Environment\n-        working-directory: /workspace/transformers\n-        run: |\n-          python utils/print_env.py\n-\n-      - name: Show installed libraries and their versions\n-        working-directory: /workspace/transformers\n-        run: pip freeze\n-\n-      - name: Run all non-slow selected tests on GPU\n-        working-directory: /workspace/transformers\n-        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n-        run: |\n-          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ env.machine_type }}_run_torch_cuda_extensions_gpu_test_reports tests/deepspeed tests/extended\n-\n-      - name: Failure short reports\n-        if: ${{ failure() }}\n-        continue-on-error: true\n-        run: cat /workspace/transformers/reports/${{ env.machine_type }}_run_torch_cuda_extensions_gpu_test_reports/failures_short.txt\n-\n-      - name: \"Test suite reports artifacts: ${{ env.machine_type }}_run_torch_cuda_extensions_gpu_test_reports\"\n-        if: ${{ always() }}\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: ${{ env.machine_type }}_run_torch_cuda_extensions_gpu_test_reports\n-          path: /workspace/transformers/reports/${{ env.machine_type }}_run_torch_cuda_extensions_gpu_test_reports\n-\n-  run_tests_torch_cuda_extensions_multi_gpu:\n-    name: Torch CUDA extension tests\n-    needs: setup\n-    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n-    strategy:\n-      fail-fast: false\n-      matrix:\n-        machine_type: [aws-g5-12xlarge-cache]\n-    runs-on:\n-      group: '${{ matrix.machine_type }}'\n-    container:\n-      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n-      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n-    env:\n-      # For the meaning of these environment variables, see the job `Setup`\n-      CI_BRANCH_PUSH: ${{ github.event.ref }}\n-      CI_BRANCH_WORKFLOW_RUN: ${{ github.event.workflow_run.head_branch }}\n-      CI_SHA_PUSH: ${{ github.event.head_commit.id }}\n-      CI_SHA_WORKFLOW_RUN: ${{ github.event.workflow_run.head_sha }}\n-    steps:\n-      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n-      # We also take into account the `push` event (we might want to test some changes in a branch)\n-      - name: Prepare custom environment variables\n-        shell: bash\n-        # For the meaning of these environment variables, see the job `Setup`\n-        run: |\n-          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n-          echo $CI_BRANCH_PUSH\n-          echo $CI_BRANCH_WORKFLOW_RUN\n-          echo $CI_SHA_PUSH\n-          echo $CI_SHA_WORKFLOW_RUN\n-          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n-          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n-\n-      - name: print environment variables\n-        run: |\n-          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n-          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n-\n-      - name: Set `machine_type` for report and artifact names\n-        working-directory: /workspace/transformers\n-        shell: bash\n-        run: |\n-          echo \"${{ matrix.machine_type }}\"\n-\n-          if [ \"${{ matrix.machine_type }}\" = \"aws-g5-4xlarge-cache\" ]; then\n-            machine_type=single-gpu\n-          elif [ \"${{ matrix.machine_type }}\" = \"aws-g5-12xlarge-cache\" ]; then\n-            machine_type=multi-gpu\n-          else\n-            machine_type=${{ matrix.machine_type }}\n-          fi\n-\n-          echo \"$machine_type\"\n-          echo \"machine_type=$machine_type\" >> $GITHUB_ENV\n-\n-      - name: Update clone using environment variables\n-        working-directory: /workspace/transformers\n-        run: |\n-          echo \"original branch = $(git branch --show-current)\"\n-          git fetch && git checkout ${{ env.CI_BRANCH }}\n-          echo \"updated branch = $(git branch --show-current)\"\n-          git checkout ${{ env.CI_SHA }}\n-          echo \"log = $(git log -n 1)\"\n-\n-      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n-        working-directory: /workspace/transformers\n-        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n-\n-      - name: Remove cached torch extensions\n-        run: rm -rf /github/home/.cache/torch_extensions/\n-\n-      # To avoid unknown test failures\n-      - name: Pre build DeepSpeed *again*\n-        working-directory: /workspace\n-        run: |\n-          python3 -m pip uninstall -y deepspeed\n-          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n-\n-      - name: NVIDIA-SMI\n-        run: |\n-          nvidia-smi\n-\n-      - name: Environment\n-        working-directory: /workspace/transformers\n-        run: |\n-          python utils/print_env.py\n-\n-      - name: Show installed libraries and their versions\n-        working-directory: /workspace/transformers\n-        run: pip freeze\n-\n-      - name: Run all non-slow selected tests on GPU\n-        working-directory: /workspace/transformers\n-        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n-        run: |\n-          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ env.machine_type }}_run_torch_cuda_extensions_gpu_test_reports tests/deepspeed tests/extended\n-\n-      - name: Failure short reports\n-        if: ${{ failure() }}\n-        continue-on-error: true\n-        run: cat /workspace/transformers/reports/${{ env.machine_type }}_run_torch_cuda_extensions_gpu_test_reports/failures_short.txt\n-\n-      - name: \"Test suite reports artifacts: ${{ env.machine_type }}_run_torch_cuda_extensions_gpu_test_reports\"\n-        if: ${{ always() }}\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: ${{ env.machine_type }}_run_torch_cuda_extensions_gpu_test_reports\n-          path: /workspace/transformers/reports/${{ env.machine_type }}_run_torch_cuda_extensions_gpu_test_reports\n-\n-  send_results:\n-    name: Send results to webhook\n-    runs-on: ubuntu-22.04\n-    if: always()\n-    needs: [\n-        setup,\n-        run_tests_single_gpu,\n-        run_tests_multi_gpu,\n-        run_tests_torch_cuda_extensions_single_gpu,\n-        run_tests_torch_cuda_extensions_multi_gpu\n-    ]\n-    env:\n-      # For the meaning of these environment variables, see the job `Setup`\n-      CI_BRANCH_PUSH: ${{ github.event.ref }}\n-      CI_BRANCH_WORKFLOW_RUN: ${{ github.event.workflow_run.head_branch }}\n-      CI_SHA_PUSH: ${{ github.event.head_commit.id }}\n-      CI_SHA_WORKFLOW_RUN: ${{ github.event.workflow_run.head_sha }}\n-    steps:\n-      - name: Preliminary job status\n-        shell: bash\n-        # For the meaning of these environment variables, see the job `Setup`\n-        run: |\n-          echo \"Setup status: ${{ needs.setup.result }}\"\n-\n-      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n-      # We also take into account the `push` event (we might want to test some changes in a branch)\n-      - name: Prepare custom environment variables\n-        shell: bash\n-        # For the meaning of these environment variables, see the job `Setup`\n-        run: |\n-          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n-          echo $CI_BRANCH_PUSH\n-          echo $CI_BRANCH_WORKFLOW_RUN\n-          echo $CI_SHA_PUSH\n-          echo $CI_SHA_WORKFLOW_RUN\n-          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n-          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n-\n-      - name: print environment variables\n-        run: |\n-          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n-          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n-\n-      - uses: actions/checkout@v4\n-        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n-        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n-        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n-        with:\n-          fetch-depth: 20\n-\n-      - name: Update clone using environment variables\n-        run: |\n-          echo \"original branch = $(git branch --show-current)\"\n-          git fetch && git checkout ${{ env.CI_BRANCH }}\n-          echo \"updated branch = $(git branch --show-current)\"\n-          git checkout ${{ env.CI_SHA }}\n-          echo \"log = $(git log -n 1)\"\n-\n-      - uses: actions/download-artifact@v4\n-      - name: Send message to Slack\n-        env:\n-          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n-          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n-          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n-          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n-          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n-          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n-          CI_EVENT: push\n-          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n-          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n-          CI_SHA: ${{ env.CI_SHA }}\n-          SETUP_STATUS: ${{ needs.setup.result }}\n-\n-        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n-        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n-        run: |\n-          pip install huggingface_hub\n-          pip install slack_sdk\n-          pip show slack_sdk\n-          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\""
        },
        {
            "sha": "fea2d9ef66c8ed1576e242ac78a3c70fd7a5d611",
            "filename": ".github/workflows/self-scheduled-caller.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/10d557123b42236dabfb70d40cf3d9ef57a445d0/.github%2Fworkflows%2Fself-scheduled-caller.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/10d557123b42236dabfb70d40cf3d9ef57a445d0/.github%2Fworkflows%2Fself-scheduled-caller.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-scheduled-caller.yml?ref=10d557123b42236dabfb70d40cf3d9ef57a445d0",
            "patch": "@@ -63,7 +63,7 @@ jobs:\n     with:\n       job: run_pipelines_torch_gpu\n       slack_report_channel: \"#transformers-ci-daily-pipeline-torch\"\n-      docker: huggingface/transformers-pytorch-gpu\n+      docker: huggingface/transformers-all-latest-gpu\n       ci_event: Daily CI\n       report_repo_id: hf-internal-testing/transformers_daily_ci\n       commit_sha: ${{ github.sha }}"
        },
        {
            "sha": "ff990f2808b725009e64716f111712c16fe3716d",
            "filename": ".github/workflows/self-scheduled-flash-attn-caller.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/10d557123b42236dabfb70d40cf3d9ef57a445d0/.github%2Fworkflows%2Fself-scheduled-flash-attn-caller.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/10d557123b42236dabfb70d40cf3d9ef57a445d0/.github%2Fworkflows%2Fself-scheduled-flash-attn-caller.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-scheduled-flash-attn-caller.yml?ref=10d557123b42236dabfb70d40cf3d9ef57a445d0",
            "patch": "@@ -51,7 +51,7 @@ jobs:\n     with:\n       job: run_models_gpu\n       slack_report_channel: \"#transformers-ci-flash-attn\"\n-      docker: huggingface/transformers-all-latest-gpu\n+      docker: huggingface/transformers-all-latest-gpu:flash-attn\n       ci_event: Daily CI\n       runner_type: \"a10\"\n       report_repo_id: hf-internal-testing/transformers_flash_attn_ci"
        },
        {
            "sha": "d18428fd0d82747f1377778a9014c16e5b6cba78",
            "filename": ".github/workflows/self-scheduled.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/10d557123b42236dabfb70d40cf3d9ef57a445d0/.github%2Fworkflows%2Fself-scheduled.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/10d557123b42236dabfb70d40cf3d9ef57a445d0/.github%2Fworkflows%2Fself-scheduled.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-scheduled.yml?ref=10d557123b42236dabfb70d40cf3d9ef57a445d0",
            "patch": "@@ -165,7 +165,7 @@ jobs:\n     runs-on:\n       group: '${{ matrix.machine_type }}'\n     container:\n-      image: huggingface/transformers-pytorch-gpu\n+      image: huggingface/transformers-all-latest-gpu\n       options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n     steps:\n       - name: Update clone"
        },
        {
            "sha": "20c599dc25be0b84b05a9f08106a9e2be34f0783",
            "filename": "docker/transformers-all-latest-gpu/Dockerfile",
            "status": "modified",
            "additions": 44,
            "deletions": 6,
            "changes": 50,
            "blob_url": "https://github.com/huggingface/transformers/blob/10d557123b42236dabfb70d40cf3d9ef57a445d0/docker%2Ftransformers-all-latest-gpu%2FDockerfile",
            "raw_url": "https://github.com/huggingface/transformers/raw/10d557123b42236dabfb70d40cf3d9ef57a445d0/docker%2Ftransformers-all-latest-gpu%2FDockerfile",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docker%2Ftransformers-all-latest-gpu%2FDockerfile?ref=10d557123b42236dabfb70d40cf3d9ef57a445d0",
            "patch": "@@ -9,10 +9,15 @@ SHELL [\"sh\", \"-lc\"]\n # The following `ARG` are mainly used to specify the versions explicitly & directly in this docker file, and not meant\n # to be used as arguments for docker build (so far).\n \n-ARG PYTORCH='2.8.0'\n+ARG PYTORCH='2.9.0'\n # Example: `cu102`, `cu113`, etc.\n ARG CUDA='cu126'\n \n+# This needs to be compatible with the above `PYTORCH`.\n+ARG TORCHCODEC='0.8.0'\n+\n+ARG FLASH_ATTN='false'\n+\n RUN apt update\n RUN apt install -y git libsndfile1-dev tesseract-ocr espeak-ng python3 python3-pip ffmpeg git-lfs\n RUN git lfs install\n@@ -21,11 +26,44 @@ RUN python3 -m pip install --no-cache-dir --upgrade pip\n ARG REF=main\n RUN git clone https://github.com/huggingface/transformers && cd transformers && git checkout $REF\n \n+RUN python3 -m pip install --no-cache-dir -e ./transformers[dev]\n+\n # 1. Put several commands in a single `RUN` to avoid image/layer exporting issue. Could be revised in the future.\n-# 2. Regarding `torch` part, We might need to specify proper versions for `torchvision` and `torchaudio`.\n-#    Currently, let's not bother to specify their versions explicitly (so installed with their latest release versions).\n-# 3. For `torchcodec<0.8`: this is quickly added as torch 2.9.0 + torchcodec 0.8.0 fails on our CI env. Need to remove later once they work.\n-RUN python3 -m pip install --no-cache-dir -e ./transformers[dev,onnxruntime] && [ ${#PYTORCH} -gt 0 -a \"$PYTORCH\" != \"pre\" ] && VERSION='torch=='$PYTORCH'.*' ||  VERSION='torch'; echo \"export VERSION='$VERSION'\" >> ~/.profile && echo torch=$VERSION && [ \"$PYTORCH\" != \"pre\" ] && python3 -m pip install --no-cache-dir -U $VERSION torchvision torchaudio \"torchcodec<0.8\" --extra-index-url https://download.pytorch.org/whl/$CUDA || python3 -m pip install --no-cache-dir -U --pre torch torchvision torchaudio torchcodec --extra-index-url https://download.pytorch.org/whl/nightly/$CUDA\n+# 2. For `torchcodec`, use `cpu` as we don't have `libnvcuvid.so` on the host runner. See https://github.com/meta-pytorch/torchcodec/issues/912\n+#    **Important**: We need to specify `torchcodec` version if the torch version is not the latest stable one.\n+# 3. `set -e` means \"exit immediately if any command fails\".\n+RUN set -e; \\\n+    # Determine torch version\n+    if [ ${#PYTORCH} -gt 0 ] && [ \"$PYTORCH\" != \"pre\" ]; then \\\n+        VERSION=\"torch==${PYTORCH}.*\"; \\\n+        TORCHCODEC_VERSION=\"torchcodec==${TORCHCODEC}.*\"; \\\n+    else \\\n+        VERSION=\"torch\"; \\\n+        TORCHCODEC_VERSION=\"torchcodec\"; \\\n+    fi; \\\n+    \\\n+    # Log the version being installed\n+    echo \"Installing torch version: $VERSION\"; \\\n+    \\\n+    # Install PyTorch packages\n+    if [ \"$PYTORCH\" != \"pre\" ]; then \\\n+        python3 -m pip install --no-cache-dir -U \\\n+            $VERSION \\\n+            torchvision \\\n+            torchaudio \\\n+            --extra-index-url https://download.pytorch.org/whl/$CUDA; \\\n+        # We need to specify the version if the torch version is not the latest stable one.\n+        python3 -m pip install --no-cache-dir -U \\\n+            $TORCHCODEC_VERSION --extra-index-url https://download.pytorch.org/whl/cpu; \\\n+    else \\\n+        python3 -m pip install --no-cache-dir -U --pre \\\n+            torch \\\n+            torchvision \\\n+            torchaudio \\\n+            --extra-index-url https://download.pytorch.org/whl/nightly/$CUDA; \\\n+        python3 -m pip install --no-cache-dir -U --pre \\\n+            torchcodec --extra-index-url https://download.pytorch.org/whl/nightly/cpu; \\\n+    fi\n \n RUN python3 -m pip install --no-cache-dir -U timm\n \n@@ -54,7 +92,7 @@ RUN python3 -m pip install --no-cache-dir bitsandbytes\n RUN python3 -m pip install --no-cache-dir quanto\n \n # After using A10 as CI runner, let's run FA2 tests\n-RUN [ \"$PYTORCH\" != \"pre\" ] && python3 -m pip uninstall -y ninja && python3 -m pip install --no-cache-dir ninja && python3 -m pip install flash-attn --no-cache-dir --no-build-isolation || echo \"Don't install FA2 with nightly torch\"\n+RUN [ \"$FLASH_ATTN\" != \"false\" ] && python3 -m pip uninstall -y ninja && python3 -m pip install --no-cache-dir ninja && python3 -m pip install flash-attn --no-cache-dir --no-build-isolation || echo \"Don't install FA2 with nightly torch\"\n \n # TODO (ydshieh): check this again\n # `quanto` will install `ninja` which leads to many `CUDA error: an illegal memory access ...` in some model tests"
        }
    ],
    "stats": {
        "total": 1275,
        "additions": 70,
        "deletions": 1205
    }
}