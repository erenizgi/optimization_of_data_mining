{
    "author": "Narsil",
    "message": "Fixing the docs corresponding to the breaking change in torch 2.6. (#36420)",
    "sha": "b4965cecc5c66e371d17b96ccd6addc7353a4241",
    "files": [
        {
            "sha": "37c193359ac1cd7471605a0c9827a3b980e084bb",
            "filename": "docs/source/en/perf_infer_gpu_multi.md",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/b4965cecc5c66e371d17b96ccd6addc7353a4241/docs%2Fsource%2Fen%2Fperf_infer_gpu_multi.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/b4965cecc5c66e371d17b96ccd6addc7353a4241/docs%2Fsource%2Fen%2Fperf_infer_gpu_multi.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fperf_infer_gpu_multi.md?ref=b4965cecc5c66e371d17b96ccd6addc7353a4241",
            "patch": "@@ -29,6 +29,7 @@ model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n # Initialize distributed\n rank = int(os.environ[\"RANK\"])\n device = torch.device(f\"cuda:{rank}\")\n+torch.cuda.set_device(device)\n torch.distributed.init_process_group(\"nccl\", device_id=device)\n \n # Retrieve tensor parallel model"
        },
        {
            "sha": "91a54e1d3f5fc71d49fc1bdd43a6991c453d95ac",
            "filename": "docs/source/zh/perf_infer_gpu_multi.md",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/b4965cecc5c66e371d17b96ccd6addc7353a4241/docs%2Fsource%2Fzh%2Fperf_infer_gpu_multi.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/b4965cecc5c66e371d17b96ccd6addc7353a4241/docs%2Fsource%2Fzh%2Fperf_infer_gpu_multi.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fperf_infer_gpu_multi.md?ref=b4965cecc5c66e371d17b96ccd6addc7353a4241",
            "patch": "@@ -29,6 +29,7 @@ model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n # 初始化分布式环境\n rank = int(os.environ[\"RANK\"])\n device = torch.device(f\"cuda:{rank}\")\n+torch.cuda.set_device(device)\n torch.distributed.init_process_group(\"nccl\", device_id=device)\n \n # 获取支持张量并行的模型"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 2,
        "deletions": 0
    }
}