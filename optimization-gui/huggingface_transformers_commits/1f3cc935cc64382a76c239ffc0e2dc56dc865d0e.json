{
    "author": "zucchini-nlp",
    "message": "Load a tiny video to make CI faster (#40684)\n\n* load a tiny video to make CI faster\n\n* add video in url_to_local_path",
    "sha": "1f3cc935cc64382a76c239ffc0e2dc56dc865d0e",
    "files": [
        {
            "sha": "6c607b0fa340c4ffbd79db06d695f87321476359",
            "filename": "tests/models/glm4v/test_processor_glm4v.py",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/1f3cc935cc64382a76c239ffc0e2dc56dc865d0e/tests%2Fmodels%2Fglm4v%2Ftest_processor_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1f3cc935cc64382a76c239ffc0e2dc56dc865d0e/tests%2Fmodels%2Fglm4v%2Ftest_processor_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fglm4v%2Ftest_processor_glm4v.py?ref=1f3cc935cc64382a76c239ffc0e2dc56dc865d0e",
            "patch": "@@ -204,12 +204,12 @@ def test_apply_chat_template_video_frame_sampling(self):\n         messages[0][0][\"content\"][0] = {\n             \"type\": \"video\",\n             \"url\": url_to_local_path(\n-                \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\"\n+                \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/tiny_video.mp4\"\n             ),\n         }\n \n         # Load with `video_fps` arg\n-        video_fps = 1\n+        video_fps = 10\n         out_dict_with_video = processor.apply_chat_template(\n             messages,\n             add_generation_prompt=True,\n@@ -218,17 +218,18 @@ def test_apply_chat_template_video_frame_sampling(self):\n             video_fps=video_fps,\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 20)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 8)\n \n-        # Load without any arg should load the whole video\n+        # Load the whole video\n         out_dict_with_video = processor.apply_chat_template(\n             messages,\n             add_generation_prompt=True,\n             tokenize=True,\n             return_dict=True,\n+            do_sample_frames=False,\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 40)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 24)\n \n         # Load video as a list of frames (i.e. images). NOTE: each frame should have same size\n         # because we assume they come from one video"
        },
        {
            "sha": "a75ce0c3bbda640bc1244493582c06a14970c92c",
            "filename": "tests/models/qwen2_5_omni/test_processing_qwen2_5_omni.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/1f3cc935cc64382a76c239ffc0e2dc56dc865d0e/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_processing_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1f3cc935cc64382a76c239ffc0e2dc56dc865d0e/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_processing_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_omni%2Ftest_processing_qwen2_5_omni.py?ref=1f3cc935cc64382a76c239ffc0e2dc56dc865d0e",
            "patch": "@@ -457,7 +457,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n             {\n                 \"type\": \"video\",\n                 \"url\": url_to_local_path(\n-                    \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\"\n+                    \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/tiny_video.mp4\"\n                 ),\n             }\n         )\n@@ -482,7 +482,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n             fps=fps,\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 14400)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 5760)\n \n         # Load with `fps` and `num_frames` args, should raise an error\n         with self.assertRaises(ValueError):\n@@ -503,7 +503,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n             return_dict=True,\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 432000)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 17280)\n \n         # Load video as a list of frames (i.e. images). NOTE: each frame should have same size\n         # because we assume they come from one video"
        },
        {
            "sha": "d5b72c803b6fb948c2ef99362e0e3cfad75ce23a",
            "filename": "tests/models/qwen2_5_vl/test_processing_qwen2_5_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/1f3cc935cc64382a76c239ffc0e2dc56dc865d0e/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_processing_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1f3cc935cc64382a76c239ffc0e2dc56dc865d0e/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_processing_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_processing_qwen2_5_vl.py?ref=1f3cc935cc64382a76c239ffc0e2dc56dc865d0e",
            "patch": "@@ -275,7 +275,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n         messages[0][0][\"content\"][0] = {\n             \"type\": \"video\",\n             \"url\": url_to_local_path(\n-                \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\"\n+                \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/tiny_video.mp4\"\n             ),\n         }\n         num_frames = 3\n@@ -299,7 +299,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n             fps=fps,\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 900)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 360)\n \n         # Load with `fps` and `num_frames` args, should raise an error\n         with self.assertRaises(ValueError):\n@@ -320,7 +320,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n             return_dict=True,\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 27000)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 1080)\n \n         # Load video as a list of frames (i.e. images). NOTE: each frame should have same size\n         # because we assume they come from one video"
        },
        {
            "sha": "2183bd8c9609139d61b507532dc1f61e8268210e",
            "filename": "tests/models/qwen2_vl/test_processing_qwen2_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/1f3cc935cc64382a76c239ffc0e2dc56dc865d0e/tests%2Fmodels%2Fqwen2_vl%2Ftest_processing_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1f3cc935cc64382a76c239ffc0e2dc56dc865d0e/tests%2Fmodels%2Fqwen2_vl%2Ftest_processing_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_vl%2Ftest_processing_qwen2_vl.py?ref=1f3cc935cc64382a76c239ffc0e2dc56dc865d0e",
            "patch": "@@ -275,7 +275,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n         messages[0][0][\"content\"][0] = {\n             \"type\": \"video\",\n             \"url\": url_to_local_path(\n-                \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\"\n+                \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/tiny_video.mp4\"\n             ),\n         }\n         num_frames = 3\n@@ -299,7 +299,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n             fps=fps,\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 900)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 360)\n \n         # Load with `fps` and `num_frames` args, should raise an error\n         with self.assertRaises(ValueError):\n@@ -320,7 +320,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n             return_dict=True,\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 27000)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 1080)\n \n         # Load video as a list of frames (i.e. images). NOTE: each frame should have same size\n         # because we assume they come from one video"
        },
        {
            "sha": "3a11103d6efba73cf2e50fb2c74ad1217ba83680",
            "filename": "tests/models/smolvlm/test_processing_smolvlm.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/1f3cc935cc64382a76c239ffc0e2dc56dc865d0e/tests%2Fmodels%2Fsmolvlm%2Ftest_processing_smolvlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1f3cc935cc64382a76c239ffc0e2dc56dc865d0e/tests%2Fmodels%2Fsmolvlm%2Ftest_processing_smolvlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsmolvlm%2Ftest_processing_smolvlm.py?ref=1f3cc935cc64382a76c239ffc0e2dc56dc865d0e",
            "patch": "@@ -393,7 +393,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n                         {\n                             \"type\": \"video\",\n                             \"url\": url_to_local_path(\n-                                \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/Big_Buck_Bunny_720_10s_10MB.mp4\"\n+                                \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/tiny_video.mp4\"\n                             ),\n                         },\n                         {\"type\": \"text\", \"text\": \"What is shown in this video?\"},\n@@ -414,10 +414,10 @@ def test_apply_chat_template_video_frame_sampling(self):\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n         self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 1)\n         # SmolVLM doesn't sample `num_frames` exactly, by uses other sampling method\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name][0]), 3)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name][0]), 1)\n \n         # Load with `fps` arg\n-        fps = 1\n+        fps = 10\n         out_dict_with_video = processor.apply_chat_template(\n             messages,\n             add_generation_prompt=True,\n@@ -429,7 +429,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n         self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 1)\n         # SmolVLM doesn't sample 1 frame per second exactly, by uses other sampling method\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name][0]), fps * 10)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name][0]), 4)\n \n         # NOTE: the last assert checks are removed\n         # Loading video as a list of frames (i.e. images) is not supported in SmolVLM"
        },
        {
            "sha": "8b409be555e656c679cb21f626cd03cac439e7d5",
            "filename": "tests/test_processing_common.py",
            "status": "modified",
            "additions": 9,
            "deletions": 6,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/1f3cc935cc64382a76c239ffc0e2dc56dc865d0e/tests%2Ftest_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1f3cc935cc64382a76c239ffc0e2dc56dc865d0e/tests%2Ftest_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_processing_common.py?ref=1f3cc935cc64382a76c239ffc0e2dc56dc865d0e",
            "patch": "@@ -1132,7 +1132,9 @@ def test_apply_chat_template_video_frame_sampling(self):\n                     \"content\": [\n                         {\n                             \"type\": \"video\",\n-                            \"url\": \"https://test-videos.co.uk/vids/bigbuckbunny/mp4/h264/720/Big_Buck_Bunny_720_10s_10MB.mp4\",\n+                            \"url\": url_to_local_path(\n+                                \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/tiny_video.mp4\"\n+                            ),\n                         },\n                         {\"type\": \"text\", \"text\": \"What is shown in this video?\"},\n                     ],\n@@ -1154,7 +1156,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n         self.assertEqual(len(out_dict_with_video[self.videos_input_name][0]), num_frames)\n \n         # Load with `fps` arg\n-        fps = 1\n+        fps = 10\n         out_dict_with_video = processor.apply_chat_template(\n             messages,\n             add_generation_prompt=True,\n@@ -1165,10 +1167,11 @@ def test_apply_chat_template_video_frame_sampling(self):\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n         self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 1)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name][0]), fps * 10)\n+        # 3 frames are inferred from input video's length and FPS, so can be hardcoded\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name][0]), 3)\n \n         # Whan `do_sample_frames=False` no sampling is done and whole video is loaded, even if number of frames is passed\n-        fps = 1\n+        fps = 10\n         out_dict_with_video = processor.apply_chat_template(\n             messages,\n             add_generation_prompt=True,\n@@ -1180,7 +1183,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n         self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 1)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name][0]), 300)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name][0]), 11)\n \n         # Load with `fps` and `num_frames` args, should raise an error\n         with self.assertRaises(ValueError):\n@@ -1202,7 +1205,7 @@ def test_apply_chat_template_video_frame_sampling(self):\n         )\n         self.assertTrue(self.videos_input_name in out_dict_with_video)\n         self.assertEqual(len(out_dict_with_video[self.videos_input_name]), 1)\n-        self.assertEqual(len(out_dict_with_video[self.videos_input_name][0]), 300)\n+        self.assertEqual(len(out_dict_with_video[self.videos_input_name][0]), 11)\n \n         # Load video as a list of frames (i.e. images).\n         # NOTE: each frame should have same size because we assume they come from one video"
        },
        {
            "sha": "400b41bf3943f85fcfed33eaa2f4ca17ee4d1523",
            "filename": "utils/fetch_hub_objects_for_ci.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/1f3cc935cc64382a76c239ffc0e2dc56dc865d0e/utils%2Ffetch_hub_objects_for_ci.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1f3cc935cc64382a76c239ffc0e2dc56dc865d0e/utils%2Ffetch_hub_objects_for_ci.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Ffetch_hub_objects_for_ci.py?ref=1f3cc935cc64382a76c239ffc0e2dc56dc865d0e",
            "patch": "@@ -32,6 +32,8 @@\n     \"https://huggingface.co/kirp/kosmos2_5/resolve/main/receipt_00008.png\",\n     \"https://huggingface.co/microsoft/kosmos-2-patch14-224/resolve/main/two_dogs.jpg\",\n     \"https://llava-vl.github.io/static/images/view.jpg\",\n+    \"https://huggingface.co/datasets/hf-internal-testing/fixtures_videos/resolve/main/tennis.mp4\",\n+    \"https://huggingface.co/datasets/raushan-testing-hf/videos-test/resolve/main/tiny_video.mp4\",\n     \"https://thumbs.dreamstime.com/b/golden-gate-bridge-san-francisco-purple-flowers-california-echium-candicans-36805947.jpg\",\n ]\n "
        }
    ],
    "stats": {
        "total": 54,
        "additions": 30,
        "deletions": 24
    }
}