{
    "author": "JinukHong",
    "message": "ğŸŒ [i18n-KO] Translated `knowledge_distillation_for_image_classification.md to Korean\"  (#32334)\n\n* docs: ko: tasks/knowledge_distillation_for_image_classification.md\r\n\r\n* feat: nmt draft\r\n\r\n* fix: manual edits\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: Chulhwa (Evan) Han <cjfghk5697@ajou.ac.kr>\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: Chulhwa (Evan) Han <cjfghk5697@ajou.ac.kr>\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: Ahnjj_DEV <ahnjj.dev@gmail.com>\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: Ahnjj_DEV <ahnjj.dev@gmail.com>\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: Ahnjj_DEV <ahnjj.dev@gmail.com>\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: Chulhwa (Evan) Han <cjfghk5697@ajou.ac.kr>\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: Chulhwa (Evan) Han <cjfghk5697@ajou.ac.kr>\r\n\r\n* Apply suggestions from code review\r\n\r\nCo-authored-by: Chulhwa (Evan) Han <cjfghk5697@ajou.ac.kr>\r\n\r\n* Apply suggestions from code review\r\n\r\n* Apply suggestions from code review\r\n\r\n* Apply suggestions from code review\r\n\r\n* Apply suggestions from code review\r\n\r\n---------\r\n\r\nCo-authored-by: Chulhwa (Evan) Han <cjfghk5697@ajou.ac.kr>\r\nCo-authored-by: Ahnjj_DEV <ahnjj.dev@gmail.com>",
    "sha": "09e6579d2d08040b34015556425d3f22f2460602",
    "files": [
        {
            "sha": "05a8622358f0d68867dca67227fa49c9cf3d5a5a",
            "filename": "docs/source/ko/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/09e6579d2d08040b34015556425d3f22f2460602/docs%2Fsource%2Fko%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/09e6579d2d08040b34015556425d3f22f2460602/docs%2Fsource%2Fko%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2F_toctree.yml?ref=09e6579d2d08040b34015556425d3f22f2460602",
            "patch": "@@ -79,8 +79,8 @@\n         title: ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ\n       - local: tasks/mask_generation\n         title: ë§ˆìŠ¤í¬ ìƒì„±\n-      - local: in_translation\n-        title: (ë²ˆì—­ì¤‘) Knowledge Distillation for Computer Vision\n+      - local: tasks/knowledge_distillation_for_image_classification\n+        title: ì»´í“¨í„° ë¹„ì „(ì´ë¯¸ì§€ ë¶„ë¥˜)ë¥¼ ìœ„í•œ ì§€ì‹ ì¦ë¥˜(knowledge distillation)\n     title: ì»´í“¨í„° ë¹„ì „\n   - isExpanded: false\n     sections:"
        },
        {
            "sha": "37c0cc25083e0c0f8e2d298d13df18adf8c6efb6",
            "filename": "docs/source/ko/tasks/knowledge_distillation_for_image_classification.md",
            "status": "added",
            "additions": 193,
            "deletions": 0,
            "changes": 193,
            "blob_url": "https://github.com/huggingface/transformers/blob/09e6579d2d08040b34015556425d3f22f2460602/docs%2Fsource%2Fko%2Ftasks%2Fknowledge_distillation_for_image_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/09e6579d2d08040b34015556425d3f22f2460602/docs%2Fsource%2Fko%2Ftasks%2Fknowledge_distillation_for_image_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Fknowledge_distillation_for_image_classification.md?ref=09e6579d2d08040b34015556425d3f22f2460602",
            "patch": "@@ -0,0 +1,193 @@\n+<!--Copyright 2023 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n+\n+âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+# ì»´í“¨í„° ë¹„ì „ì„ ìœ„í•œ ì§€ì‹ ì¦ë¥˜[[Knowledge-Distillation-for-Computer-Vision]]\n+\n+[[open-in-colab]]\n+\n+ì§€ì‹ ì¦ë¥˜(Knowledge distillation)ëŠ” ë” í¬ê³  ë³µì¡í•œ ëª¨ë¸(êµì‚¬)ì—ì„œ ë” ì‘ê³  ê°„ë‹¨í•œ ëª¨ë¸(í•™ìƒ)ë¡œ ì§€ì‹ì„ ì „ë‹¬í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. í•œ ëª¨ë¸ì—ì„œ ë‹¤ë¥¸ ëª¨ë¸ë¡œ ì§€ì‹ì„ ì¦ë¥˜í•˜ê¸° ìœ„í•´, íŠ¹ì • ì‘ì—…(ì´ ê²½ìš° ì´ë¯¸ì§€ ë¶„ë¥˜)ì— ëŒ€í•´ í•™ìŠµëœ ì‚¬ì „ í›ˆë ¨ëœ êµì‚¬ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³ , ëœë¤ìœ¼ë¡œ ì´ˆê¸°í™”ëœ í•™ìƒ ëª¨ë¸ì„ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‘ì—…ì— ëŒ€í•´ í•™ìŠµí•©ë‹ˆë‹¤. ê·¸ë‹¤ìŒ, í•™ìƒ ëª¨ë¸ì´ êµì‚¬ ëª¨ë¸ì˜ ì¶œë ¥ì„ ëª¨ë°©í•˜ì—¬ ë‘ ëª¨ë¸ì˜ ì¶œë ¥ ì°¨ì´ë¥¼ ìµœì†Œí™”í•˜ë„ë¡ í›ˆë ¨í•©ë‹ˆë‹¤. ì´ ê¸°ë²•ì€ Hinton ë“± ì—°êµ¬ì§„ì˜ [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)ì—ì„œ ì²˜ìŒ ì†Œê°œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ê°€ì´ë“œì—ì„œëŠ” íŠ¹ì • ì‘ì—…ì— ë§ì¶˜ ì§€ì‹ ì¦ë¥˜ë¥¼ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤. ì´ë²ˆì—ëŠ” [beans dataset](https://huggingface.co/datasets/beans)ì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.\n+\n+ì´ ê°€ì´ë“œëŠ” [ë¯¸ì„¸ ì¡°ì •ëœ ViT ëª¨ë¸](https://huggingface.co/merve/vit-mobilenet-beans-224) (êµì‚¬ ëª¨ë¸)ì„ [MobileNet](https://huggingface.co/google/mobilenet_v2_1.4_224) (í•™ìƒ ëª¨ë¸)ìœ¼ë¡œ ì¦ë¥˜í•˜ëŠ” ë°©ë²•ì„ ğŸ¤— Transformersì˜ [Trainer API](https://huggingface.co/docs/transformers/en/main_classes/trainer#trainer) ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.\n+\n+ì¦ë¥˜ì™€ ê³¼ì • í‰ê°€ë¥¼ ìœ„í•´ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ ë´…ì‹œë‹¤.\n+\n+\n+```bash\n+pip install transformers datasets accelerate tensorboard evaluate --upgrade\n+```\n+\n+ì´ ì˜ˆì œì—ì„œëŠ” `merve/beans-vit-224` ëª¨ë¸ì„ êµì‚¬ ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ beans ë°ì´í„°ì…‹ì—ì„œ íŒŒì¸ íŠœë‹ëœ `google/vit-base-patch16-224-in21k` ê¸°ë°˜ì˜ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì„ ë¬´ì‘ìœ„ë¡œ ì´ˆê¸°í™”ëœ MobileNetV2ë¡œ ì¦ë¥˜í•´ë³¼ ê²ƒì…ë‹ˆë‹¤.\n+\n+ì´ì œ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê² ìŠµë‹ˆë‹¤.\n+\n+```python\n+from datasets import load_dataset\n+\n+dataset = load_dataset(\"beans\")\n+```\n+\n+ì´ ê²½ìš° ë‘ ëª¨ë¸ì˜ ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œê°€ ë™ì¼í•œ í•´ìƒë„ë¡œ ë™ì¼í•œ ì¶œë ¥ì„ ë°˜í™˜í•˜ê¸° ë•Œë¬¸ì—, ë‘ê°€ì§€ë¥¼ ëª¨ë‘ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ì˜ ëª¨ë“  ë¶„í• ë§ˆë‹¤ ì „ì²˜ë¦¬ë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ `dataset`ì˜ `map()` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•  ê²ƒ ì…ë‹ˆë‹¤.\n+\n+\n+```python\n+from transformers import AutoImageProcessor\n+teacher_processor = AutoImageProcessor.from_pretrained(\"merve/beans-vit-224\")\n+\n+def process(examples):\n+    processed_inputs = teacher_processor(examples[\"image\"])\n+    return processed_inputs\n+\n+processed_datasets = dataset.map(process, batched=True)\n+```\n+\n+í•™ìƒ ëª¨ë¸(ë¬´ì‘ìœ„ë¡œ ì´ˆê¸°í™”ëœ MobileNet)ì´ êµì‚¬ ëª¨ë¸(íŒŒì¸ íŠœë‹ëœ ë¹„ì „ íŠ¸ëœìŠ¤í¬ë¨¸)ì„ ëª¨ë°©í•˜ë„ë¡ í•  ê²ƒ ì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë¨¼ì € êµì‚¬ì™€ í•™ìƒ ëª¨ë¸ì˜ ë¡œì§“ ì¶œë ¥ê°’ì„ êµ¬í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ê° ì¶œë ¥ê°’ì„ ë§¤ê°œë³€ìˆ˜ `temperature` ê°’ìœ¼ë¡œ ë‚˜ëˆ„ëŠ”ë°, ì´ ë§¤ê°œë³€ìˆ˜ëŠ” ê° ì†Œí”„íŠ¸ íƒ€ê²Ÿì˜ ì¤‘ìš”ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ë§¤ê°œë³€ìˆ˜ `lambda` ëŠ” ì¦ë¥˜ ì†ì‹¤ì˜ ì¤‘ìš”ë„ì— ê°€ì¤‘ì¹˜ë¥¼ ì¤ë‹ˆë‹¤. ì´ ì˜ˆì œì—ì„œëŠ” `temperature=5`ì™€ `lambda=0.5`ë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. í•™ìƒê³¼ êµì‚¬ ê°„ì˜ ë°œì‚°ì„ ê³„ì‚°í•˜ê¸° ìœ„í•´ Kullback-Leibler Divergence ì†ì‹¤ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‘ ë°ì´í„° Pì™€ Qê°€ ì£¼ì–´ì¡Œì„ ë•Œ, KL DivergenceëŠ” Që¥¼ ì‚¬ìš©í•˜ì—¬ Pë¥¼ í‘œí˜„í•˜ëŠ” ë° ì–¼ë§Œí¼ì˜ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œì§€ë¥¼ ë§í•´ì¤ë‹ˆë‹¤. ë‘ ë°ì´í„°ê°€ ë™ì¼í•˜ë‹¤ë©´, KL DivergenceëŠ” 0ì´ë©°, Që¡œ Pë¥¼ ì„¤ëª…í•˜ëŠ” ë° ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ì§€ ì•ŠìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì§€ì‹ ì¦ë¥˜ì˜ ë§¥ë½ì—ì„œ KL DivergenceëŠ” ìœ ìš©í•©ë‹ˆë‹¤.\n+\n+\n+```python\n+from transformers import TrainingArguments, Trainer\n+import torch\n+import torch.nn as nn\n+import torch.nn.functional as F\n+\n+\n+class ImageDistilTrainer(Trainer):\n+    def __init__(self, teacher_model=None, student_model=None, temperature=None, lambda_param=None,  *args, **kwargs):\n+        super().__init__(model=student_model, *args, **kwargs)\n+        self.teacher = teacher_model\n+        self.student = student_model\n+        self.loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n+        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n+        self.teacher.to(device)\n+        self.teacher.eval()\n+        self.temperature = temperature\n+        self.lambda_param = lambda_param\n+\n+    def compute_loss(self, student, inputs, return_outputs=False):\n+        student_output = self.student(**inputs)\n+\n+        with torch.no_grad():\n+          teacher_output = self.teacher(**inputs)\n+\n+        #  êµì‚¬ì™€ í•™ìƒì˜ ì†Œí”„íŠ¸ íƒ€ê²Ÿ(soft targets) ê³„ì‚°\n+\n+        soft_teacher = F.softmax(teacher_output.logits / self.temperature, dim=-1)\n+        soft_student = F.log_softmax(student_output.logits / self.temperature, dim=-1)\n+\n+        # ì†ì‹¤(loss) ê³„ì‚°\n+        distillation_loss = self.loss_function(soft_student, soft_teacher) * (self.temperature ** 2)\n+\n+        # ì‹¤ì œ ë ˆì´ë¸” ì†ì‹¤ ê³„ì‚°\n+        student_target_loss = student_output.loss\n+\n+        # ìµœì¢… ì†ì‹¤ ê³„ì‚°\n+        loss = (1. - self.lambda_param) * student_target_loss + self.lambda_param * distillation_loss\n+        return (loss, student_output) if return_outputs else loss\n+```\n+\n+ì´ì œ Hugging Face Hubì— ë¡œê·¸ì¸í•˜ì—¬ `Trainer`ë¥¼ í†µí•´ Hugging Face Hubì— ëª¨ë¸ì„ í‘¸ì‹œí•  ìˆ˜ ìˆë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n+\n+\n+```python\n+from huggingface_hub import notebook_login\n+\n+notebook_login()\n+```\n+\n+ì´ì œ `TrainingArguments`, êµì‚¬ ëª¨ë¸ê³¼ í•™ìƒ ëª¨ë¸ì„ ì„¤ì •í•˜ê² ìŠµë‹ˆë‹¤.\n+\n+\n+```python\n+from transformers import AutoModelForImageClassification, MobileNetV2Config, MobileNetV2ForImageClassification\n+\n+training_args = TrainingArguments(\n+    output_dir=\"my-awesome-model\",\n+    num_train_epochs=30,\n+    fp16=True,\n+    logging_dir=f\"{repo_name}/logs\",\n+    logging_strategy=\"epoch\",\n+    eval_strategy=\"epoch\",\n+    save_strategy=\"epoch\",\n+    load_best_model_at_end=True,\n+    metric_for_best_model=\"accuracy\",\n+    report_to=\"tensorboard\",\n+    push_to_hub=True,\n+    hub_strategy=\"every_save\",\n+    hub_model_id=repo_name,\n+    )\n+\n+num_labels = len(processed_datasets[\"train\"].features[\"labels\"].names)\n+\n+# ëª¨ë¸ ì´ˆê¸°í™”\n+teacher_model = AutoModelForImageClassification.from_pretrained(\n+    \"merve/beans-vit-224\",\n+    num_labels=num_labels,\n+    ignore_mismatched_sizes=True\n+)\n+\n+# MobileNetV2 ë°‘ë°”ë‹¥ë¶€í„° í•™ìŠµ\n+student_config = MobileNetV2Config()\n+student_config.num_labels = num_labels\n+student_model = MobileNetV2ForImageClassification(student_config)\n+```\n+\n+`compute_metrics` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ëª¨ë¸ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” í›ˆë ¨ ê³¼ì •ì—ì„œ ëª¨ë¸ì˜ `accuracy`ì™€ `f1`ì„ ê³„ì‚°í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n+\n+\n+```python\n+import evaluate\n+import numpy as np\n+\n+accuracy = evaluate.load(\"accuracy\")\n+\n+def compute_metrics(eval_pred):\n+    predictions, labels = eval_pred\n+    acc = accuracy.compute(references=labels, predictions=np.argmax(predictions, axis=1))\n+    return {\"accuracy\": acc[\"accuracy\"]}\n+```\n+\n+ì •ì˜í•œ í›ˆë ¨ ì¸ìˆ˜ë¡œ `Trainer`ë¥¼ ì´ˆê¸°í™”í•´ë´…ì‹œë‹¤. ë˜í•œ ë°ì´í„° ì½œë ˆì´í„°(data collator)ë¥¼ ì´ˆê¸°í™”í•˜ê² ìŠµë‹ˆë‹¤.\n+\n+```python\n+from transformers import DefaultDataCollator\n+\n+data_collator = DefaultDataCollator()\n+trainer = ImageDistilTrainer(\n+    student_model=student_model,\n+    teacher_model=teacher_model,\n+    training_args=training_args,\n+    train_dataset=processed_datasets[\"train\"],\n+    eval_dataset=processed_datasets[\"validation\"],\n+    data_collator=data_collator,\n+    tokenizer=teacher_processor,\n+    compute_metrics=compute_metrics,\n+    temperature=5,\n+    lambda_param=0.5\n+)\n+```\n+\n+ì´ì œ ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+```python\n+trainer.train()\n+```\n+\n+ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+```python\n+trainer.evaluate(processed_datasets[\"test\"])\n+```\n+\n+\n+í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ëª¨ë¸ì˜ ì •í™•ë„ëŠ” 72%ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ì¦ë¥˜ì˜ íš¨ìœ¨ì„±ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ ë™ì¼í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ beans ë°ì´í„°ì…‹ì—ì„œ MobileNetì„ ì²˜ìŒë¶€í„° í›ˆë ¨í•˜ì˜€ê³ , í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œì˜ ì •í™•ë„ëŠ” 63% ì˜€ìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ì‚¬ì „ í›ˆë ¨ëœ êµì‚¬ ëª¨ë¸, í•™ìƒ êµ¬ì¡°, ì¦ë¥˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‹œë„í•´ë³´ì‹œê³  ê²°ê³¼ë¥¼ ë³´ê³ í•˜ê¸°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤. ì¦ë¥˜ëœ ëª¨ë¸ì˜ í›ˆë ¨ ë¡œê·¸ì™€ ì²´í¬í¬ì¸íŠ¸ëŠ” [ì´ ì €ì¥ì†Œ](https://huggingface.co/merve/vit-mobilenet-beans-224)ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìœ¼ë©°, ì²˜ìŒë¶€í„° í›ˆë ¨ëœ MobileNetV2ëŠ” ì´ [ì €ì¥ì†Œ](https://huggingface.co/merve/resnet-mobilenet-beans-5)ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        }
    ],
    "stats": {
        "total": 197,
        "additions": 195,
        "deletions": 2
    }
}