{
    "author": "ydshieh",
    "message": "Remove overwritten `GitModelTest::test_beam_search_generate` (#40666)\n\nfix\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "afd1393df1f53bdebd6cf2778130c1d30d05d845",
    "files": [
        {
            "sha": "493c525751bf44fe3b486f759c8729de2b2f3206",
            "filename": "tests/models/git/test_modeling_git.py",
            "status": "modified",
            "additions": 0,
            "deletions": 22,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/afd1393df1f53bdebd6cf2778130c1d30d05d845/tests%2Fmodels%2Fgit%2Ftest_modeling_git.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/afd1393df1f53bdebd6cf2778130c1d30d05d845/tests%2Fmodels%2Fgit%2Ftest_modeling_git.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgit%2Ftest_modeling_git.py?ref=afd1393df1f53bdebd6cf2778130c1d30d05d845",
            "patch": "@@ -331,24 +331,6 @@ def create_and_check_for_causal_lm(self, config, input_ids, input_mask, pixel_va\n         self.parent.assertEqual(result.loss.shape, ())\n         self.parent.assertTrue(result.loss.item() > 0)\n \n-    def _test_beam_search_generate(self, config, input_ids, input_mask, pixel_values):\n-        model = GitForCausalLM(config=config)\n-        model.to(torch_device)\n-        model.eval()\n-\n-        # generate\n-        generated_ids = model.generate(\n-            input_ids,\n-            attention_mask=input_mask,\n-            pixel_values=pixel_values,\n-            do_sample=False,\n-            max_length=20,\n-            num_beams=2,\n-            num_return_sequences=2,\n-        )\n-\n-        self.parent.assertEqual(generated_ids.shape, (self.batch_size * 2, 20))\n-\n     def _test_batched_generate_captioning(self, config, input_ids, input_mask, pixel_values):\n         model = GitForCausalLM(config=config)\n         model.to(torch_device)\n@@ -431,10 +413,6 @@ def test_for_causal_lm(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_for_causal_lm(*config_and_inputs)\n \n-    def test_beam_search_generate(self):\n-        config_and_inputs = self.model_tester.prepare_config_and_inputs()\n-        self.model_tester._test_beam_search_generate(*config_and_inputs)\n-\n     def test_batched_generate_captioning(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester._test_batched_generate_captioning(*config_and_inputs)"
        }
    ],
    "stats": {
        "total": 22,
        "additions": 0,
        "deletions": 22
    }
}