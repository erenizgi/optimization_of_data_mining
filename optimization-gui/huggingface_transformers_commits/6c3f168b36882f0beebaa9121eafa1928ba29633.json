{
    "author": "blueingman",
    "message": "[i18n-zh]Translated tiktoken.md into chinese (#34936)\n\n* Add translation for tiktoken documentation\r\n\r\n* Update tiktoken.md\r\n\r\n* Update tiktoken.md",
    "sha": "6c3f168b36882f0beebaa9121eafa1928ba29633",
    "files": [
        {
            "sha": "3c6c0a203c18df190f0f7479994993bc8b9b25d1",
            "filename": "docs/source/zh/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/6c3f168b36882f0beebaa9121eafa1928ba29633/docs%2Fsource%2Fzh%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/6c3f168b36882f0beebaa9121eafa1928ba29633/docs%2Fsource%2Fzh%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2F_toctree.yml?ref=6c3f168b36882f0beebaa9121eafa1928ba29633",
            "patch": "@@ -52,6 +52,8 @@\n     title: å¯¼å‡ºä¸º TorchScript\n   - local: gguf\n     title: ä¸ GGUF æ ¼å¼çš„äº’æ“ä½œæ€§\n+  - local: tiktoken\n+    title: ä¸ Tiktoken æ–‡ä»¶çš„äº’æ“ä½œæ€§\n   title: å¼€å‘è€…æŒ‡å—\n - sections:\n   - local: performance"
        },
        {
            "sha": "c8ef6b129eccc0001b8b74b15ffee2f80d48e451",
            "filename": "docs/source/zh/tiktoken.md",
            "status": "added",
            "additions": 55,
            "deletions": 0,
            "changes": 55,
            "blob_url": "https://github.com/huggingface/transformers/blob/6c3f168b36882f0beebaa9121eafa1928ba29633/docs%2Fsource%2Fzh%2Ftiktoken.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/6c3f168b36882f0beebaa9121eafa1928ba29633/docs%2Fsource%2Fzh%2Ftiktoken.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Ftiktoken.md?ref=6c3f168b36882f0beebaa9121eafa1928ba29633",
            "patch": "@@ -0,0 +1,55 @@\n+<!--Copyright 2024 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n+``\n+âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+\n+# Transformersä¸Tiktonkençš„äº’æ“ä½œæ€§\n+\n+åœ¨ğŸ¤— transformersä¸­ï¼Œå½“ä½¿ç”¨`from_pretrained`æ–¹æ³•ä»HubåŠ è½½æ¨¡å‹æ—¶ï¼Œå¦‚æœæ¨¡å‹åŒ…å«tiktokenæ ¼å¼çš„`tokenizer.model`æ–‡ä»¶ï¼Œæ¡†æ¶å¯ä»¥æ— ç¼æ”¯æŒtiktokenæ¨¡å‹æ–‡ä»¶ï¼Œå¹¶è‡ªåŠ¨å°†å…¶è½¬æ¢ä¸ºæˆ‘ä»¬çš„[å¿«é€Ÿè¯ç¬¦åŒ–å™¨](https://huggingface.co/docs/transformers/main/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)ã€‚\n+\n+### å·²çŸ¥åŒ…å«`tiktoken.model`æ–‡ä»¶å‘å¸ƒçš„æ¨¡å‹ï¼š\n+    - gpt2\n+    - llama3\n+\n+## ä½¿ç”¨ç¤ºä¾‹\n+\n+ä¸ºäº†åœ¨transformersä¸­æ­£ç¡®åŠ è½½`tiktoken`æ–‡ä»¶ï¼Œè¯·ç¡®ä¿`tiktoken.model`æ–‡ä»¶æ˜¯tiktokenæ ¼å¼çš„ï¼Œå¹¶ä¸”ä¼šåœ¨åŠ è½½`from_pretrained`æ—¶è‡ªåŠ¨åŠ è½½ã€‚ä»¥ä¸‹å±•ç¤ºå¦‚ä½•ä»åŒä¸€ä¸ªæ–‡ä»¶ä¸­åŠ è½½è¯ç¬¦åŒ–å™¨(tokenizer)å’Œæ¨¡å‹ï¼š\n+\n+```py\n+from transformers import AutoTokenizer\n+\n+model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n+tokenizer = AutoTokenizer.from_pretrained(model_id, subfolder=\"original\") \n+```\n+## åˆ›å»ºtiktokenè¯ç¬¦åŒ–å™¨(tokenizer)\n+\n+`tokenizer.model`æ–‡ä»¶ä¸­ä¸åŒ…å«ä»»ä½•é¢å¤–çš„è¯ç¬¦(token)æˆ–æ¨¡å¼å­—ç¬¦ä¸²(pattern strings)çš„ä¿¡æ¯ã€‚å¦‚æœè¿™äº›ä¿¡æ¯å¾ˆé‡è¦ï¼Œéœ€è¦å°†è¯ç¬¦åŒ–å™¨(tokenizer)è½¬æ¢ä¸ºé€‚ç”¨äº[`PreTrainedTokenizerFast`]ç±»çš„`tokenizer.json`æ ¼å¼ã€‚\n+\n+ä½¿ç”¨[tiktoken.get_encoding](https://github.com/openai/tiktoken/blob/63527649963def8c759b0f91f2eb69a40934e468/tiktoken/registry.py#L63)ç”Ÿæˆ`tokenizer.model`æ–‡ä»¶ï¼Œå†ä½¿ç”¨[`convert_tiktoken_to_fast`]å‡½æ•°å°†å…¶è½¬æ¢ä¸º`tokenizer.json`æ–‡ä»¶ã€‚\n+\n+```py\n+\n+from transformers.integrations.tiktoken import convert_tiktoken_to_fast\n+from tiktoken import get_encoding\n+\n+# You can load your custom encoding or the one provided by OpenAI\n+encoding = get_encoding(\"gpt2\")\n+convert_tiktoken_to_fast(encoding, \"config/save/dir\")\n+```\n+\n+ç”Ÿæˆçš„`tokenizer.json`æ–‡ä»¶å°†è¢«ä¿å­˜åˆ°æŒ‡å®šçš„ç›®å½•ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡[`PreTrainedTokenizerFast`]ç±»æ¥åŠ è½½ã€‚\n+\n+```py\n+tokenizer = PreTrainedTokenizerFast.from_pretrained(\"config/save/dir\")\n+```"
        }
    ],
    "stats": {
        "total": 57,
        "additions": 57,
        "deletions": 0
    }
}