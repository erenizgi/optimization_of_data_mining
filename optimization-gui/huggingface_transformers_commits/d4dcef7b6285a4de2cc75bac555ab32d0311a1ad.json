{
    "author": "Yacklin",
    "message": "Fixed-wrong-ZeRO3-json-snippet-found-in-deepspeed-markdown-file (#42346)\n\n* Correct syntax error in trainer.md\n\nA comma is missing between two parameters in the signature of compute_loss function.\n\n* Correct syntax error in trainer.md\n\nA comma is missing between two parameters in the signature of compute_loss function.\n\n* aio section should not be included in zero_optimization dictionary, according to deepspeed json docs and issue: https://github.com/deepspeedai/DeepSpeed/issues/2721\n\n* I noticed that another language version of it is also problematic. I would just fix it anyway.",
    "sha": "d4dcef7b6285a4de2cc75bac555ab32d0311a1ad",
    "files": [
        {
            "sha": "ae304404f615d0d264a9b14661270739ed65929f",
            "filename": "docs/source/en/deepspeed.md",
            "status": "modified",
            "additions": 7,
            "deletions": 8,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/d4dcef7b6285a4de2cc75bac555ab32d0311a1ad/docs%2Fsource%2Fen%2Fdeepspeed.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/d4dcef7b6285a4de2cc75bac555ab32d0311a1ad/docs%2Fsource%2Fen%2Fdeepspeed.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fdeepspeed.md?ref=d4dcef7b6285a4de2cc75bac555ab32d0311a1ad",
            "patch": "@@ -341,13 +341,6 @@ The example ZeRO-3 and ZeRO-Infinity config below sets most of the parameter val\n             \"buffer_size\": 1e8,\n             \"max_in_cpu\": 1e9\n         },\n-        \"aio\": {\n-            \"block_size\": 262144,\n-            \"queue_depth\": 32,\n-            \"thread_count\": 1,\n-            \"single_submit\": false,\n-            \"overlap_events\": true\n-        },\n         \"overlap_comm\": true,\n         \"contiguous_gradients\": true,\n         \"sub_group_size\": 1e9,\n@@ -358,7 +351,13 @@ The example ZeRO-3 and ZeRO-Infinity config below sets most of the parameter val\n         \"stage3_max_reuse_distance\": 1e9,\n         \"stage3_gather_16bit_weights_on_model_save\": true\n     },\n-\n+    \"aio\": {\n+        \"block_size\": 262144,\n+        \"queue_depth\": 32,\n+        \"thread_count\": 1,\n+        \"single_submit\": false,\n+        \"overlap_events\": true\n+    },\n     \"gradient_accumulation_steps\": \"auto\",\n     \"gradient_clipping\": \"auto\",\n     \"steps_per_print\": 2000,"
        },
        {
            "sha": "0390f65197ec946bce278ca41456136dfc685f78",
            "filename": "docs/source/ko/deepspeed.md",
            "status": "modified",
            "additions": 7,
            "deletions": 8,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/d4dcef7b6285a4de2cc75bac555ab32d0311a1ad/docs%2Fsource%2Fko%2Fdeepspeed.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/d4dcef7b6285a4de2cc75bac555ab32d0311a1ad/docs%2Fsource%2Fko%2Fdeepspeed.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fdeepspeed.md?ref=d4dcef7b6285a4de2cc75bac555ab32d0311a1ad",
            "patch": "@@ -354,13 +354,6 @@ ZeRO-3로 대규모 모델을 초기화하고 매개변수에 액세스하는 \n             \"buffer_size\": 1e8,\n             \"max_in_cpu\": 1e9\n         },\n-        \"aio\": {\n-            \"block_size\": 262144,\n-            \"queue_depth\": 32,\n-            \"thread_count\": 1,\n-            \"single_submit\": false,\n-            \"overlap_events\": true\n-        },\n         \"overlap_comm\": true,\n         \"contiguous_gradients\": true,\n         \"sub_group_size\": 1e9,\n@@ -371,7 +364,13 @@ ZeRO-3로 대규모 모델을 초기화하고 매개변수에 액세스하는 \n         \"stage3_max_reuse_distance\": 1e9,\n         \"stage3_gather_16bit_weights_on_model_save\": true\n     },\n-\n+    \"aio\": {\n+        \"block_size\": 262144,\n+        \"queue_depth\": 32,\n+        \"thread_count\": 1,\n+        \"single_submit\": false,\n+        \"overlap_events\": true\n+    },\n     \"gradient_accumulation_steps\": \"auto\",\n     \"gradient_clipping\": \"auto\",\n     \"steps_per_print\": 2000,"
        }
    ],
    "stats": {
        "total": 30,
        "additions": 14,
        "deletions": 16
    }
}