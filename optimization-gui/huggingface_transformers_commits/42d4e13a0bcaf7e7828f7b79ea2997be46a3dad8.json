{
    "author": "konstantinos-p",
    "message": "RT-Detr correct 2d positional embeddings for non-square images (#41380)\n\n* Correct 2d positional embeddings for non-square images\n\n* Simplify bug fix propagate changes to other models\n\n---------\n\nCo-authored-by: Konstantinos Pitas <kostasp210@gmail.com>\nCo-authored-by: Yoni Gozlan <74535834+yonigozlan@users.noreply.github.com>",
    "sha": "42d4e13a0bcaf7e7828f7b79ea2997be46a3dad8",
    "files": [
        {
            "sha": "cd3275f486b7ed56204350ecbc9489960d18d4b0",
            "filename": "src/transformers/models/d_fine/modeling_d_fine.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/42d4e13a0bcaf7e7828f7b79ea2997be46a3dad8/src%2Ftransformers%2Fmodels%2Fd_fine%2Fmodeling_d_fine.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/42d4e13a0bcaf7e7828f7b79ea2997be46a3dad8/src%2Ftransformers%2Fmodels%2Fd_fine%2Fmodeling_d_fine.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fd_fine%2Fmodeling_d_fine.py?ref=42d4e13a0bcaf7e7828f7b79ea2997be46a3dad8",
            "patch": "@@ -2064,7 +2064,7 @@ def build_2d_sincos_position_embedding(\n     ):\n         grid_w = torch.arange(torch_int(width), device=device).to(dtype)\n         grid_h = torch.arange(torch_int(height), device=device).to(dtype)\n-        grid_w, grid_h = torch.meshgrid(grid_w, grid_h, indexing=\"ij\")\n+        grid_w, grid_h = torch.meshgrid(grid_w, grid_h, indexing=\"xy\")\n         if embed_dim % 4 != 0:\n             raise ValueError(\"Embed dimension must be divisible by 4 for 2D sin-cos position embedding\")\n         pos_dim = embed_dim // 4\n@@ -2074,7 +2074,7 @@ def build_2d_sincos_position_embedding(\n         out_w = grid_w.flatten()[..., None] @ omega[None]\n         out_h = grid_h.flatten()[..., None] @ omega[None]\n \n-        return torch.concat([out_w.sin(), out_w.cos(), out_h.sin(), out_h.cos()], dim=1)[None, :, :]\n+        return torch.concat([out_h.sin(), out_h.cos(), out_w.sin(), out_w.cos()], dim=1)[None, :, :]\n \n     def forward(\n         self,"
        },
        {
            "sha": "d2e746973ad986a8ce8cbe0c9f8947e4d6357764",
            "filename": "src/transformers/models/rt_detr/modeling_rt_detr.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/42d4e13a0bcaf7e7828f7b79ea2997be46a3dad8/src%2Ftransformers%2Fmodels%2Frt_detr%2Fmodeling_rt_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/42d4e13a0bcaf7e7828f7b79ea2997be46a3dad8/src%2Ftransformers%2Fmodels%2Frt_detr%2Fmodeling_rt_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frt_detr%2Fmodeling_rt_detr.py?ref=42d4e13a0bcaf7e7828f7b79ea2997be46a3dad8",
            "patch": "@@ -1151,7 +1151,7 @@ def build_2d_sincos_position_embedding(\n     ):\n         grid_w = torch.arange(torch_int(width), device=device).to(dtype)\n         grid_h = torch.arange(torch_int(height), device=device).to(dtype)\n-        grid_w, grid_h = torch.meshgrid(grid_w, grid_h, indexing=\"ij\")\n+        grid_w, grid_h = torch.meshgrid(grid_w, grid_h, indexing=\"xy\")\n         if embed_dim % 4 != 0:\n             raise ValueError(\"Embed dimension must be divisible by 4 for 2D sin-cos position embedding\")\n         pos_dim = embed_dim // 4\n@@ -1161,7 +1161,7 @@ def build_2d_sincos_position_embedding(\n         out_w = grid_w.flatten()[..., None] @ omega[None]\n         out_h = grid_h.flatten()[..., None] @ omega[None]\n \n-        return torch.concat([out_w.sin(), out_w.cos(), out_h.sin(), out_h.cos()], dim=1)[None, :, :]\n+        return torch.concat([out_h.sin(), out_h.cos(), out_w.sin(), out_w.cos()], dim=1)[None, :, :]\n \n     def forward(\n         self,"
        },
        {
            "sha": "b67024e6605ad79cdd94abdcc68ea56c0faae518",
            "filename": "src/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/42d4e13a0bcaf7e7828f7b79ea2997be46a3dad8/src%2Ftransformers%2Fmodels%2Frt_detr_v2%2Fmodeling_rt_detr_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/42d4e13a0bcaf7e7828f7b79ea2997be46a3dad8/src%2Ftransformers%2Fmodels%2Frt_detr_v2%2Fmodeling_rt_detr_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frt_detr_v2%2Fmodeling_rt_detr_v2.py?ref=42d4e13a0bcaf7e7828f7b79ea2997be46a3dad8",
            "patch": "@@ -1107,7 +1107,7 @@ def build_2d_sincos_position_embedding(\n     ):\n         grid_w = torch.arange(torch_int(width), device=device).to(dtype)\n         grid_h = torch.arange(torch_int(height), device=device).to(dtype)\n-        grid_w, grid_h = torch.meshgrid(grid_w, grid_h, indexing=\"ij\")\n+        grid_w, grid_h = torch.meshgrid(grid_w, grid_h, indexing=\"xy\")\n         if embed_dim % 4 != 0:\n             raise ValueError(\"Embed dimension must be divisible by 4 for 2D sin-cos position embedding\")\n         pos_dim = embed_dim // 4\n@@ -1117,7 +1117,7 @@ def build_2d_sincos_position_embedding(\n         out_w = grid_w.flatten()[..., None] @ omega[None]\n         out_h = grid_h.flatten()[..., None] @ omega[None]\n \n-        return torch.concat([out_w.sin(), out_w.cos(), out_h.sin(), out_h.cos()], dim=1)[None, :, :]\n+        return torch.concat([out_h.sin(), out_h.cos(), out_w.sin(), out_w.cos()], dim=1)[None, :, :]\n \n     def forward(\n         self,"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 6,
        "deletions": 6
    }
}