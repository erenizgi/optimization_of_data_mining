{
    "author": "merveenoyan",
    "message": "Added image-text-to-text pipeline to task guide (#34783)\n\n* Added image-text-to-text pipeline to task guide\r\n\r\n* Update docs/source/en/tasks/image_text_to_text.md\r\n\r\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\r\n\r\n* Update docs/source/en/tasks/image_text_to_text.md\r\n\r\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\r\n\r\n* Update docs/source/en/tasks/image_text_to_text.md\r\n\r\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\r\n\r\n* Update docs/source/en/tasks/image_text_to_text.md\r\n\r\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\r\n\r\n* Merge codeblocks\r\n\r\n---------\r\n\r\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
    "sha": "befbbf2f98492e2164f185708e62c06fd30f75d1",
    "files": [
        {
            "sha": "041efb06c575b411b25c981c73cb68471de80fee",
            "filename": "docs/source/en/tasks/image_text_to_text.md",
            "status": "modified",
            "additions": 40,
            "deletions": 0,
            "changes": 40,
            "blob_url": "https://github.com/huggingface/transformers/blob/befbbf2f98492e2164f185708e62c06fd30f75d1/docs%2Fsource%2Fen%2Ftasks%2Fimage_text_to_text.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/befbbf2f98492e2164f185708e62c06fd30f75d1/docs%2Fsource%2Fen%2Ftasks%2Fimage_text_to_text.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftasks%2Fimage_text_to_text.md?ref=befbbf2f98492e2164f185708e62c06fd30f75d1",
            "patch": "@@ -120,6 +120,46 @@ print(generated_texts)\n ## ['User: What do we see in this image? \\nAssistant: In this image we can see two cats on the nets. \\nUser: And how about this image? \\nAssistant: In this image we can see flowers, plants and insect.']\n ```\n \n+## Pipeline\n+\n+The fastest way to get started is to use the [`Pipeline`] API. Specify the `\"image-text-to-text\"` task and the model you want to use.\n+\n+```python\n+from transformers import pipeline\n+pipe = pipeline(\"image-text-to-text\", model=\"llava-hf/llava-interleave-qwen-0.5b-hf\")\n+```\n+\n+The example below uses chat templates to format the text inputs.\n+\n+```python\n+messages = [\n+     {\n+         \"role\": \"user\",\n+         \"content\": [\n+             {\n+                 \"type\": \"image\",\n+                 \"image\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\",\n+             },\n+             {\"type\": \"text\", \"text\": \"Describe this image.\"},\n+         ],\n+     },\n+     {\n+         \"role\": \"assistant\",\n+         \"content\": [\n+             {\"type\": \"text\", \"text\": \"There's a pink flower\"},\n+         ],\n+     },\n+ ]\n+```\n+\n+Pass the chat template formatted text and image to [`Pipeline`] and set `return_full_text=False` to remove the input from the generated output.\n+\n+```python\n+outputs = pipe(text=messages, max_new_tokens=20, return_full_text=False)\n+outputs[0][\"generated_text\"]\n+#  with a yellow center in the foreground. The flower is surrounded by red and white flowers with green stems\n+```\n+\n ## Streaming\n \n We can use [text streaming](./generation_strategies#streaming) for a better generation experience. Transformers supports streaming with the [`TextStreamer`] or [`TextIteratorStreamer`] classes. We will use the [`TextIteratorStreamer`] with IDEFICS-8B."
        }
    ],
    "stats": {
        "total": 40,
        "additions": 40,
        "deletions": 0
    }
}