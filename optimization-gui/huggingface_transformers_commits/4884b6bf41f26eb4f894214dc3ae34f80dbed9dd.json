{
    "author": "hmellor",
    "message": "Fix link in \"Inference server backends\" doc (#39589)\n\nSigned-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>",
    "sha": "4884b6bf41f26eb4f894214dc3ae34f80dbed9dd",
    "files": [
        {
            "sha": "422cc4a121e97ed51865f226d9bd8729338625c7",
            "filename": "docs/source/en/transformers_as_backend.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/4884b6bf41f26eb4f894214dc3ae34f80dbed9dd/docs%2Fsource%2Fen%2Ftransformers_as_backend.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/4884b6bf41f26eb4f894214dc3ae34f80dbed9dd/docs%2Fsource%2Fen%2Ftransformers_as_backend.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftransformers_as_backend.md?ref=4884b6bf41f26eb4f894214dc3ae34f80dbed9dd",
            "patch": "@@ -40,7 +40,7 @@ vllm serve meta-llama/Llama-3.2-1B \\\n     --model-impl transformers\n ```\n \n-Refer to the [vLLM docs](https://docs.vllm.ai/en/latest/models/transformers_backend.html) for more usage examples and tips on using a Transformers as the backend.\n+Refer to the [vLLM docs](https://docs.vllm.ai/en/latest/models/supported_models.html#transformers) for more usage examples and tips on using a Transformers as the backend.\n \n \n ## SGLang"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}