{
    "author": "jiangwangyi",
    "message": "Remove deprecated audio utils functions (#39330)\n\nCo-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>",
    "sha": "30c508dbcbc2d4e19507da5af46a32a7de73c5e9",
    "files": [
        {
            "sha": "e8684ab7021850312c6d0089c67ba3b249636c29",
            "filename": "src/transformers/audio_utils.py",
            "status": "modified",
            "additions": 0,
            "deletions": 143,
            "changes": 143,
            "blob_url": "https://github.com/huggingface/transformers/blob/30c508dbcbc2d4e19507da5af46a32a7de73c5e9/src%2Ftransformers%2Faudio_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/30c508dbcbc2d4e19507da5af46a32a7de73c5e9/src%2Ftransformers%2Faudio_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Faudio_utils.py?ref=30c508dbcbc2d4e19507da5af46a32a7de73c5e9",
            "patch": "@@ -1081,146 +1081,3 @@ def amplitude_to_db_batch(\n         spectrogram = np.clip(spectrogram, a_min=max_values - db_range, a_max=None)\n \n     return spectrogram\n-\n-\n-### deprecated functions below this line ###\n-\n-\n-def get_mel_filter_banks(\n-    nb_frequency_bins: int,\n-    nb_mel_filters: int,\n-    frequency_min: float,\n-    frequency_max: float,\n-    sample_rate: int,\n-    norm: Optional[str] = None,\n-    mel_scale: str = \"htk\",\n-) -> np.array:\n-    warnings.warn(\n-        \"The function `get_mel_filter_banks` is deprecated and will be removed in version 4.31.0 of Transformers\",\n-        FutureWarning,\n-    )\n-    return mel_filter_bank(\n-        num_frequency_bins=nb_frequency_bins,\n-        num_mel_filters=nb_mel_filters,\n-        min_frequency=frequency_min,\n-        max_frequency=frequency_max,\n-        sampling_rate=sample_rate,\n-        norm=norm,\n-        mel_scale=mel_scale,\n-    )\n-\n-\n-def fram_wave(waveform: np.array, hop_length: int = 160, fft_window_size: int = 400, center: bool = True):\n-    \"\"\"\n-    In order to compute the short time fourier transform, the waveform needs to be split in overlapping windowed\n-    segments called `frames`.\n-\n-    The window length (window_length) defines how much of the signal is contained in each frame, while the hop length\n-    defines the step between the beginning of each new frame.\n-\n-\n-    Args:\n-        waveform (`np.array` of shape `(sample_length,)`):\n-            The raw waveform which will be split into smaller chunks.\n-        hop_length (`int`, *optional*, defaults to 160):\n-            Step between each window of the waveform.\n-        fft_window_size (`int`, *optional*, defaults to 400):\n-            Defines the size of the window.\n-        center (`bool`, defaults to `True`):\n-            Whether or not to center each frame around the middle of the frame. Centering is done by reflecting the\n-            waveform on the left and on the right.\n-\n-    Return:\n-        framed_waveform (`np.array` of shape `(waveform.shape // hop_length , fft_window_size)`):\n-            The framed waveforms that can be fed to `np.fft`.\n-    \"\"\"\n-    warnings.warn(\n-        \"The function `fram_wave` is deprecated and will be removed in version 4.31.0 of Transformers\",\n-        FutureWarning,\n-    )\n-    frames = []\n-    for i in range(0, waveform.shape[0] + 1, hop_length):\n-        if center:\n-            half_window = (fft_window_size - 1) // 2 + 1\n-            start = i - half_window if i > half_window else 0\n-            end = i + half_window if i < waveform.shape[0] - half_window else waveform.shape[0]\n-            frame = waveform[start:end]\n-            if start == 0:\n-                padd_width = (-i + half_window, 0)\n-                frame = np.pad(frame, pad_width=padd_width, mode=\"reflect\")\n-\n-            elif end == waveform.shape[0]:\n-                padd_width = (0, (i - waveform.shape[0] + half_window))\n-                frame = np.pad(frame, pad_width=padd_width, mode=\"reflect\")\n-\n-        else:\n-            frame = waveform[i : i + fft_window_size]\n-            frame_width = frame.shape[0]\n-            if frame_width < waveform.shape[0]:\n-                frame = np.pad(frame, pad_width=(0, fft_window_size - frame_width), mode=\"constant\", constant_values=0)\n-        frames.append(frame)\n-\n-    frames = np.stack(frames, 0)\n-    return frames\n-\n-\n-def stft(frames: np.array, windowing_function: np.array, fft_window_size: Optional[int] = None):\n-    \"\"\"\n-    Calculates the complex Short-Time Fourier Transform (STFT) of the given framed signal. Should give the same results\n-    as `torch.stft`.\n-\n-    Args:\n-        frames (`np.array` of dimension `(num_frames, fft_window_size)`):\n-            A framed audio signal obtained using `audio_utils.fram_wav`.\n-        windowing_function (`np.array` of dimension `(nb_frequency_bins, nb_mel_filters)`:\n-            A array representing the function that will be used to reduces the amplitude of the discontinuities at the\n-            boundaries of each frame when computing the STFT. Each frame will be multiplied by the windowing_function.\n-            For more information on the discontinuities, called *Spectral leakage*, refer to [this\n-            tutorial]https://download.ni.com/evaluation/pxi/Understanding%20FFTs%20and%20Windowing.pdf\n-        fft_window_size (`int`, *optional*):\n-            Size of the window om which the Fourier transform is applied. This controls the frequency resolution of the\n-            spectrogram. 400 means that the fourier transform is computed on windows of 400 samples. The number of\n-            frequency bins (`nb_frequency_bins`) used to divide the window into equal strips is equal to\n-            `(1+fft_window_size)//2`. An increase of the fft_window_size slows the calculus time proportionally.\n-\n-    Example:\n-\n-    ```python\n-    >>> from transformers.audio_utils import stft, fram_wave\n-    >>> import numpy as np\n-\n-    >>> audio = np.random.rand(50)\n-    >>> fft_window_size = 10\n-    >>> hop_length = 2\n-    >>> framed_audio = fram_wave(audio, hop_length, fft_window_size)\n-    >>> spectrogram = stft(framed_audio, np.hanning(fft_window_size + 1))\n-    ```\n-\n-    Returns:\n-        spectrogram (`np.ndarray`):\n-            A spectrogram of shape `(num_frames, nb_frequency_bins)` obtained using the STFT algorithm\n-    \"\"\"\n-    warnings.warn(\n-        \"The function `stft` is deprecated and will be removed in version 4.31.0 of Transformers\",\n-        FutureWarning,\n-    )\n-    frame_size = frames.shape[1]\n-\n-    if fft_window_size is None:\n-        fft_window_size = frame_size\n-\n-    if fft_window_size < frame_size:\n-        raise ValueError(\"FFT size must greater or equal the frame size\")\n-    # number of FFT bins to store\n-    nb_frequency_bins = (fft_window_size >> 1) + 1\n-\n-    spectrogram = np.empty((len(frames), nb_frequency_bins), dtype=np.complex64)\n-    fft_signal = np.zeros(fft_window_size)\n-\n-    for f, frame in enumerate(frames):\n-        if windowing_function is not None:\n-            np.multiply(frame, windowing_function, out=fft_signal[:frame_size])\n-        else:\n-            fft_signal[:frame_size] = frame\n-        spectrogram[f] = np.fft.fft(fft_signal, axis=0)[:nb_frequency_bins]\n-    return spectrogram.T"
        }
    ],
    "stats": {
        "total": 143,
        "additions": 0,
        "deletions": 143
    }
}