{
    "author": "aymeric-roucher",
    "message": "Decorator for easier tool building (#33439)\n\n* Decorator for tool building",
    "sha": "e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
    "files": [
        {
            "sha": "ac06c04d9baaa533f0f006b9ece0e61d4d27317c",
            "filename": "docs/source/en/agents.md",
            "status": "modified",
            "additions": 25,
            "deletions": 51,
            "changes": 76,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/docs%2Fsource%2Fen%2Fagents.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/docs%2Fsource%2Fen%2Fagents.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fagents.md?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -325,62 +325,37 @@ model = next(iter(list_models(filter=task, sort=\"downloads\", direction=-1)))\n print(model.id)\n ```\n \n-This code can be converted into a class that inherits from the [`Tool`] superclass.\n+This code can quickly be converted into a tool, just by wrapping it in a function and adding the `tool` decorator:\n \n \n-The custom tool needs:\n-- An attribute `name`, which corresponds to the name of the tool itself. The name usually describes what the tool does. Since the code returns the model with the most downloads for a task, let's name is `model_download_counter`.\n-- An attribute `description` is used to populate the agent's system prompt.\n-- An `inputs` attribute, which is a dictionary with keys `\"type\"` and `\"description\"`. It contains information that helps the Python interpreter make educated choices about the input.\n-- An `output_type` attribute, which specifies the output type.\n-- A `forward` method which contains the inference code to be executed.\n-\n-\n-```python\n-from transformers import Tool\n-from huggingface_hub import list_models\n-\n-class HFModelDownloadsTool(Tool):\n-    name = \"model_download_counter\"\n-    description = (\n-        \"This is a tool that returns the most downloaded model of a given task on the Hugging Face Hub. \"\n-        \"It returns the name of the checkpoint.\"\n-    )\n-\n-    inputs = {\n-        \"task\": {\n-            \"type\": \"text\",\n-            \"description\": \"the task category (such as text-classification, depth-estimation, etc)\",\n-        }\n-    }\n-    output_type = \"text\"\n-\n-    def forward(self, task: str):\n-        model = next(iter(list_models(filter=task, sort=\"downloads\", direction=-1)))\n-        return model.id\n-```\n-\n-Now that the custom `HfModelDownloadsTool` class is ready, you can save it to a file named `model_downloads.py` and import it for use.\n-\n-\n-```python\n-from model_downloads import HFModelDownloadsTool\n-\n-tool = HFModelDownloadsTool()\n-```\n-\n-You can also share your custom tool to the Hub by calling [`~Tool.push_to_hub`] on the tool. Make sure you've created a repository for it on the Hub and are using a token with read access.\n-\n-```python\n-tool.push_to_hub(\"{your_username}/hf-model-downloads\")\n+```py\n+from transformers import tool\n+\n+@tool\n+def model_download_counter(task: str) -> str:\n+    \"\"\"\n+    This is a tool that returns the most downloaded model of a given task on the Hugging Face Hub.\n+    It returns the name of the checkpoint.\n+\n+    Args:\n+        task: The task for which\n+    \"\"\"\n+    model = next(iter(list_models(filter=\"text-classification\", sort=\"downloads\", direction=-1)))\n+    return model.id\n ```\n \n-Load the tool with the [`~Tool.load_tool`] function and pass it to the `tools` parameter in your agent.\n+The function needs:\n+- A clear name. The name usually describes what the tool does. Since the code returns the model with the most downloads for a task, let's put `model_download_counter`.\n+- Type hints on both inputs and output\n+- A description, that includes an 'Args:' part where each argument is described (without a type indication this time, it will be pulled from the type hint).\n+All these will be automatically baked into the agent's system prompt upon initialization: so strive to make them as clear as possible!\n \n-```python\n-from transformers import load_tool, CodeAgent\n+> [!TIP]\n+> This definition format is the same as tool schemas used in `apply_chat_template`, the only difference is the added `tool` decorator: read more on our tool use API [here](https://huggingface.co/blog/unified-tool-use#passing-tools-to-a-chat-template).\n \n-model_download_tool = load_tool(\"m-ric/hf-model-downloads\")\n+Then you can directly initialize your agent:\n+```py\n+from transformers import CodeAgent\n agent = CodeAgent(tools=[model_download_tool], llm_engine=llm_engine)\n agent.run(\n     \"Can you give me the name of the model that has the most downloads in the 'text-to-video' task on the Hugging Face Hub?\"\n@@ -400,7 +375,6 @@ print(f\"The most downloaded model for the 'text-to-video' task is {most_download\n And the output:\n `\"The most downloaded model for the 'text-to-video' task is ByteDance/AnimateDiff-Lightning.\"`\n \n-\n ### Manage your agent's toolbox\n \n If you have already initialized an agent, it is inconvenient to reinitialize it from scratch with a tool you want to use. With Transformers, you can manage an agent's toolbox by adding or replacing a tool."
        },
        {
            "sha": "2327357525d8d903c7f9be372dd7f639f23b6e19",
            "filename": "docs/source/en/agents_advanced.md",
            "status": "modified",
            "additions": 62,
            "deletions": 1,
            "changes": 63,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/docs%2Fsource%2Fen%2Fagents_advanced.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/docs%2Fsource%2Fen%2Fagents_advanced.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fagents_advanced.md?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -60,7 +60,68 @@ manager_agent.run(\"Who is the CEO of Hugging Face?\")\n > For an in-depth example of an efficient multi-agent implementation, see [how we pushed our multi-agent system to the top of the GAIA leaderboard](https://huggingface.co/blog/beating-gaia).\n \n \n-## Use tools from gradio or LangChain\n+## Advanced tool usage\n+\n+### Directly define a tool by subclassing Tool, and share it to the Hub\n+\n+Let's take again the tool example from main documentation, for which we had implemented a `tool` decorator.\n+\n+If you need to add variation, like custom attributes for your too, you can build your tool following the fine-grained method: building a class that inherits from the [`Tool`] superclass.\n+\n+The custom tool needs:\n+- An attribute `name`, which corresponds to the name of the tool itself. The name usually describes what the tool does. Since the code returns the model with the most downloads for a task, let's name is `model_download_counter`.\n+- An attribute `description` is used to populate the agent's system prompt.\n+- An `inputs` attribute, which is a dictionary with keys `\"type\"` and `\"description\"`. It contains information that helps the Python interpreter make educated choices about the input.\n+- An `output_type` attribute, which specifies the output type.\n+- A `forward` method which contains the inference code to be executed.\n+\n+The types for both `inputs` and `output_type` should be amongst [Pydantic formats](https://docs.pydantic.dev/latest/concepts/json_schema/#generating-json-schema).\n+\n+```python\n+from transformers import Tool\n+from huggingface_hub import list_models\n+\n+class HFModelDownloadsTool(Tool):\n+    name = \"model_download_counter\"\n+    description = \"\"\"\n+    This is a tool that returns the most downloaded model of a given task on the Hugging Face Hub.\n+    It returns the name of the checkpoint.\"\"\"\n+\n+    inputs = {\n+        \"task\": {\n+            \"type\": \"string\",\n+            \"description\": \"the task category (such as text-classification, depth-estimation, etc)\",\n+        }\n+    }\n+    output_type = \"string\"\n+\n+    def forward(self, task: str):\n+        model = next(iter(list_models(filter=task, sort=\"downloads\", direction=-1)))\n+        return model.id\n+```\n+\n+Now that the custom `HfModelDownloadsTool` class is ready, you can save it to a file named `model_downloads.py` and import it for use.\n+\n+\n+```python\n+from model_downloads import HFModelDownloadsTool\n+\n+tool = HFModelDownloadsTool()\n+```\n+\n+You can also share your custom tool to the Hub by calling [`~Tool.push_to_hub`] on the tool. Make sure you've created a repository for it on the Hub and are using a token with read access.\n+\n+```python\n+tool.push_to_hub(\"{your_username}/hf-model-downloads\")\n+```\n+\n+Load the tool with the [`~Tool.load_tool`] function and pass it to the `tools` parameter in your agent.\n+\n+```python\n+from transformers import load_tool, CodeAgent\n+\n+model_download_tool = load_tool(\"m-ric/hf-model-downloads\")\n+```\n \n ### Use gradio-tools\n "
        },
        {
            "sha": "ed0486b60128ec84c9b99099cb4b8f5e5163508b",
            "filename": "docs/source/en/main_classes/agent.md",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/docs%2Fsource%2Fen%2Fmain_classes%2Fagent.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/docs%2Fsource%2Fen%2Fmain_classes%2Fagent.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmain_classes%2Fagent.md?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -60,6 +60,10 @@ We provide two types of agents, based on the main [`Agent`] class:\n \n [[autodoc]] load_tool\n \n+### tool\n+\n+[[autodoc]] tool\n+\n ### Tool\n \n [[autodoc]] Tool"
        },
        {
            "sha": "bfd0d37916b5539062d8c7d99a3db5b3e31029eb",
            "filename": "src/transformers/__init__.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2F__init__.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -70,6 +70,7 @@\n         \"launch_gradio_demo\",\n         \"load_tool\",\n         \"stream_to_gradio\",\n+        \"tool\",\n     ],\n     \"audio_utils\": [],\n     \"benchmark\": [],\n@@ -4819,6 +4820,7 @@\n         launch_gradio_demo,\n         load_tool,\n         stream_to_gradio,\n+        tool,\n     )\n     from .configuration_utils import PretrainedConfig\n "
        },
        {
            "sha": "70762c252a832882a53c1baf515c58356dffe1a1",
            "filename": "src/transformers/agents/__init__.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fagents%2F__init__.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -27,7 +27,7 @@\n     \"agents\": [\"Agent\", \"CodeAgent\", \"ManagedAgent\", \"ReactAgent\", \"ReactCodeAgent\", \"ReactJsonAgent\", \"Toolbox\"],\n     \"llm_engine\": [\"HfApiEngine\", \"TransformersEngine\"],\n     \"monitoring\": [\"stream_to_gradio\"],\n-    \"tools\": [\"PipelineTool\", \"Tool\", \"ToolCollection\", \"launch_gradio_demo\", \"load_tool\"],\n+    \"tools\": [\"PipelineTool\", \"Tool\", \"ToolCollection\", \"launch_gradio_demo\", \"load_tool\", \"tool\"],\n }\n \n try:\n@@ -48,7 +48,7 @@\n     from .agents import Agent, CodeAgent, ManagedAgent, ReactAgent, ReactCodeAgent, ReactJsonAgent, Toolbox\n     from .llm_engine import HfApiEngine, TransformersEngine\n     from .monitoring import stream_to_gradio\n-    from .tools import PipelineTool, Tool, ToolCollection, launch_gradio_demo, load_tool\n+    from .tools import PipelineTool, Tool, ToolCollection, launch_gradio_demo, load_tool, tool\n \n     try:\n         if not is_torch_available():"
        },
        {
            "sha": "f5be7462657c78ea9ddced08f0acff95fd63902a",
            "filename": "src/transformers/agents/agent_types.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fagent_types.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fagent_types.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fagents%2Fagent_types.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -234,7 +234,7 @@ def to_string(self):\n             return self._path\n \n \n-AGENT_TYPE_MAPPING = {\"text\": AgentText, \"image\": AgentImage, \"audio\": AgentAudio}\n+AGENT_TYPE_MAPPING = {\"string\": AgentText, \"image\": AgentImage, \"audio\": AgentAudio}\n INSTANCE_TYPE_MAPPING = {str: AgentText, ImageType: AgentImage}\n \n if is_torch_available():"
        },
        {
            "sha": "73b7186d25a3c75b42a98ad96d54c0b9000a3352",
            "filename": "src/transformers/agents/agents.py",
            "status": "modified",
            "additions": 7,
            "deletions": 11,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fagents.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fagents.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fagents%2Fagents.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -22,7 +22,7 @@\n from .. import is_torch_available\n from ..utils import logging as transformers_logging\n from ..utils.import_utils import is_pygments_available\n-from .agent_types import AgentAudio, AgentImage, AgentText\n+from .agent_types import AgentAudio, AgentImage\n from .default_tools import BASE_PYTHON_TOOLS, FinalAnswerTool, setup_default_tools\n from .llm_engine import HfApiEngine, MessageRole\n from .prompts import (\n@@ -626,10 +626,9 @@ def run(self, task: str, return_generated_code: bool = False, **kwargs):\n         Example:\n \n         ```py\n-        from transformers.agents import CodeAgent, PythonInterpreterTool\n+        from transformers.agents import CodeAgent\n \n-        python_interpreter = PythonInterpreterTool()\n-        agent = CodeAgent(tools=[python_interpreter])\n+        agent = CodeAgent(tools=[])\n         agent.run(\"What is the result of 2 power 3.7384?\")\n         ```\n         \"\"\"\n@@ -1019,20 +1018,17 @@ def step(self):\n                 arguments = {}\n             observation = self.execute_tool_call(tool_name, arguments)\n             observation_type = type(observation)\n-            if observation_type == AgentText:\n-                updated_information = str(observation).strip()\n-            else:\n-                # TODO: observation naming could allow for different names of same type\n+            if observation_type in [AgentImage, AgentAudio]:\n                 if observation_type == AgentImage:\n                     observation_name = \"image.png\"\n                 elif observation_type == AgentAudio:\n                     observation_name = \"audio.mp3\"\n-                else:\n-                    observation_name = \"object.object\"\n+                # TODO: observation naming could allow for different names of same type\n \n                 self.state[observation_name] = observation\n                 updated_information = f\"Stored '{observation_name}' in memory.\"\n-\n+            else:\n+                updated_information = str(observation).strip()\n             self.logger.info(updated_information)\n             current_step_logs[\"observation\"] = updated_information\n             return current_step_logs"
        },
        {
            "sha": "3946aa9f873503c9a9564da2d5e0dbba7773db89",
            "filename": "src/transformers/agents/default_tools.py",
            "status": "modified",
            "additions": 4,
            "deletions": 5,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fdefault_tools.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fdefault_tools.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fagents%2Fdefault_tools.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -152,8 +152,7 @@ class PythonInterpreterTool(Tool):\n     name = \"python_interpreter\"\n     description = \"This is a tool that evaluates python code. It can be used to perform calculations.\"\n \n-    output_type = \"text\"\n-    available_tools = BASE_PYTHON_TOOLS.copy()\n+    output_type = \"string\"\n \n     def __init__(self, *args, authorized_imports=None, **kwargs):\n         if authorized_imports is None:\n@@ -162,7 +161,7 @@ def __init__(self, *args, authorized_imports=None, **kwargs):\n             self.authorized_imports = list(set(LIST_SAFE_MODULES) | set(authorized_imports))\n         self.inputs = {\n             \"code\": {\n-                \"type\": \"text\",\n+                \"type\": \"string\",\n                 \"description\": (\n                     \"The code snippet to evaluate. All variables used in this snippet must be defined in this same snippet, \"\n                     f\"else you will get an error. This code can only import the following python libraries: {authorized_imports}.\"\n@@ -173,15 +172,15 @@ def __init__(self, *args, authorized_imports=None, **kwargs):\n \n     def forward(self, code):\n         output = str(\n-            evaluate_python_code(code, static_tools=self.available_tools, authorized_imports=self.authorized_imports)\n+            evaluate_python_code(code, static_tools=BASE_PYTHON_TOOLS, authorized_imports=self.authorized_imports)\n         )\n         return output\n \n \n class FinalAnswerTool(Tool):\n     name = \"final_answer\"\n     description = \"Provides a final answer to the given problem.\"\n-    inputs = {\"answer\": {\"type\": \"text\", \"description\": \"The final answer to the problem\"}}\n+    inputs = {\"answer\": {\"type\": \"any\", \"description\": \"The final answer to the problem\"}}\n     output_type = \"any\"\n \n     def forward(self, answer):"
        },
        {
            "sha": "23ae5b0429120dd6dd9c2eb7f454959c92625012",
            "filename": "src/transformers/agents/document_question_answering.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fdocument_question_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fdocument_question_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fagents%2Fdocument_question_answering.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -31,7 +31,7 @@\n \n class DocumentQuestionAnsweringTool(PipelineTool):\n     default_checkpoint = \"naver-clova-ix/donut-base-finetuned-docvqa\"\n-    description = \"This is a tool that answers a question about an document (pdf). It returns a text that contains the answer to the question.\"\n+    description = \"This is a tool that answers a question about an document (pdf). It returns a string that contains the answer to the question.\"\n     name = \"document_qa\"\n     pre_processor_class = AutoProcessor\n     model_class = VisionEncoderDecoderModel\n@@ -41,9 +41,9 @@ class DocumentQuestionAnsweringTool(PipelineTool):\n             \"type\": \"image\",\n             \"description\": \"The image containing the information. Can be a PIL Image or a string path to the image.\",\n         },\n-        \"question\": {\"type\": \"text\", \"description\": \"The question in English\"},\n+        \"question\": {\"type\": \"string\", \"description\": \"The question in English\"},\n     }\n-    output_type = \"text\"\n+    output_type = \"string\"\n \n     def __init__(self, *args, **kwargs):\n         if not is_vision_available():"
        },
        {
            "sha": "de0efb7b6f380b899c396bc16e101c306b77f11f",
            "filename": "src/transformers/agents/image_question_answering.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fimage_question_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fimage_question_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fagents%2Fimage_question_answering.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -38,9 +38,9 @@ class ImageQuestionAnsweringTool(PipelineTool):\n             \"type\": \"image\",\n             \"description\": \"The image containing the information. Can be a PIL Image or a string path to the image.\",\n         },\n-        \"question\": {\"type\": \"text\", \"description\": \"The question in English\"},\n+        \"question\": {\"type\": \"string\", \"description\": \"The question in English\"},\n     }\n-    output_type = \"text\"\n+    output_type = \"string\"\n \n     def __init__(self, *args, **kwargs):\n         requires_backends(self, [\"vision\"])"
        },
        {
            "sha": "7a84b1db44faba92c96f8d8294b3cdd035ab0e5e",
            "filename": "src/transformers/agents/prompts.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fprompts.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fprompts.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fagents%2Fprompts.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -199,7 +199,7 @@ def download_prompt(prompt_or_repo_id, agent_name, mode=\"run\"):\n Action:\n {\n   \"action\": \"image_generator\",\n-  \"action_input\": {\"text\": \"\"A portrait of John Doe, a 55-year-old man living in Canada.\"\"}\n+  \"action_input\": {\"prompt\": \"A portrait of John Doe, a 55-year-old man living in Canada.\"}\n }<end_action>\n Observation: \"image.png\"\n "
        },
        {
            "sha": "f50a7c6ab8f94e1696e3a72ad3ec3ff29470d447",
            "filename": "src/transformers/agents/search.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fsearch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fsearch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fagents%2Fsearch.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -26,7 +26,7 @@ class DuckDuckGoSearchTool(Tool):\n     name = \"web_search\"\n     description = \"\"\"Perform a web search based on your query (think a Google search) then returns the top search results as a list of dict elements.\n     Each result has keys 'title', 'href' and 'body'.\"\"\"\n-    inputs = {\"query\": {\"type\": \"text\", \"description\": \"The search query to perform.\"}}\n+    inputs = {\"query\": {\"type\": \"string\", \"description\": \"The search query to perform.\"}}\n     output_type = \"any\"\n \n     def forward(self, query: str) -> str:\n@@ -45,11 +45,11 @@ class VisitWebpageTool(Tool):\n     description = \"Visits a wbepage at the given url and returns its content as a markdown string.\"\n     inputs = {\n         \"url\": {\n-            \"type\": \"text\",\n+            \"type\": \"string\",\n             \"description\": \"The url of the webpage to visit.\",\n         }\n     }\n-    output_type = \"text\"\n+    output_type = \"string\"\n \n     def forward(self, url: str) -> str:\n         try:"
        },
        {
            "sha": "8061651a086479475a7096541b9552f0409d36f5",
            "filename": "src/transformers/agents/speech_to_text.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fspeech_to_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Fspeech_to_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fagents%2Fspeech_to_text.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -27,7 +27,7 @@ class SpeechToTextTool(PipelineTool):\n     model_class = WhisperForConditionalGeneration\n \n     inputs = {\"audio\": {\"type\": \"audio\", \"description\": \"The audio to transcribe\"}}\n-    output_type = \"text\"\n+    output_type = \"string\"\n \n     def encode(self, audio):\n         return self.pre_processor(audio, return_tensors=\"pt\")"
        },
        {
            "sha": "ed41ef6017ae328d850b559098ff4215b7e0e566",
            "filename": "src/transformers/agents/text_to_speech.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Ftext_to_speech.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Ftext_to_speech.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fagents%2Ftext_to_speech.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -36,7 +36,7 @@ class TextToSpeechTool(PipelineTool):\n     model_class = SpeechT5ForTextToSpeech\n     post_processor_class = SpeechT5HifiGan\n \n-    inputs = {\"text\": {\"type\": \"text\", \"description\": \"The text to read out loud (in English)\"}}\n+    inputs = {\"text\": {\"type\": \"string\", \"description\": \"The text to read out loud (in English)\"}}\n     output_type = \"audio\"\n \n     def setup(self):"
        },
        {
            "sha": "cfb1e4cf95ced9316236648bfd8e2a1b8dff9480",
            "filename": "src/transformers/agents/tools.py",
            "status": "modified",
            "additions": 81,
            "deletions": 11,
            "changes": 92,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Ftools.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Ftools.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fagents%2Ftools.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -16,12 +16,13 @@\n # limitations under the License.\n import base64\n import importlib\n+import inspect\n import io\n import json\n import os\n import tempfile\n-from functools import lru_cache\n-from typing import Any, Dict, List, Optional, Union\n+from functools import lru_cache, wraps\n+from typing import Any, Callable, Dict, List, Optional, Union\n \n from huggingface_hub import create_repo, get_collection, hf_hub_download, metadata_update, upload_folder\n from huggingface_hub.utils import RepositoryNotFoundError, build_hf_headers, get_session\n@@ -35,7 +36,9 @@\n from ..models.auto import AutoProcessor\n from ..utils import (\n     CONFIG_NAME,\n+    TypeHintParsingException,\n     cached_file,\n+    get_json_schema,\n     is_accelerate_available,\n     is_torch_available,\n     is_vision_available,\n@@ -84,6 +87,20 @@ def get_repo_type(repo_id, repo_type=None, **hub_kwargs):\n \"\"\"\n \n \n+def validate_after_init(cls):\n+    original_init = cls.__init__\n+\n+    @wraps(original_init)\n+    def new_init(self, *args, **kwargs):\n+        original_init(self, *args, **kwargs)\n+        if not isinstance(self, PipelineTool):\n+            self.validate_arguments()\n+\n+    cls.__init__ = new_init\n+    return cls\n+\n+\n+@validate_after_init\n class Tool:\n     \"\"\"\n     A base class for the functions used by the agent. Subclass this and implement the `__call__` method as well as the\n@@ -114,17 +131,35 @@ class Tool:\n     def __init__(self, *args, **kwargs):\n         self.is_initialized = False\n \n-    def validate_attributes(self):\n+    def validate_arguments(self):\n         required_attributes = {\n             \"description\": str,\n             \"name\": str,\n             \"inputs\": Dict,\n-            \"output_type\": type,\n+            \"output_type\": str,\n         }\n+        authorized_types = [\"string\", \"integer\", \"number\", \"image\", \"audio\", \"any\"]\n+\n         for attr, expected_type in required_attributes.items():\n             attr_value = getattr(self, attr, None)\n             if not isinstance(attr_value, expected_type):\n-                raise TypeError(f\"Instance attribute {attr} must exist and be of type {expected_type.__name__}\")\n+                raise TypeError(f\"You must set an attribute {attr} of type {expected_type.__name__}.\")\n+        for input_name, input_content in self.inputs.items():\n+            assert \"type\" in input_content, f\"Input '{input_name}' should specify a type.\"\n+            if input_content[\"type\"] not in authorized_types:\n+                raise Exception(\n+                    f\"Input '{input_name}': type '{input_content['type']}' is not an authorized value, should be one of {authorized_types}.\"\n+                )\n+            assert \"description\" in input_content, f\"Input '{input_name}' should have a description.\"\n+\n+        assert getattr(self, \"output_type\", None) in authorized_types\n+\n+        if not isinstance(self, PipelineTool):\n+            signature = inspect.signature(self.forward)\n+            if not set(signature.parameters.keys()) == set(self.inputs.keys()):\n+                raise Exception(\n+                    \"Tool's 'forward' method should take 'self' as its first argument, then its next arguments should match the keys of tool attribute 'inputs'.\"\n+                )\n \n     def forward(self, *args, **kwargs):\n         return NotImplemented(\"Write this method in your subclass of `Tool`.\")\n@@ -382,7 +417,7 @@ def __init__(self, _gradio_tool):\n                 super().__init__()\n                 self.name = _gradio_tool.name\n                 self.description = _gradio_tool.description\n-                self.output_type = \"text\"\n+                self.output_type = \"string\"\n                 self._gradio_tool = _gradio_tool\n                 func_args = list(inspect.signature(_gradio_tool.run).parameters.keys())\n                 self.inputs = {key: \"\" for key in func_args}\n@@ -404,7 +439,7 @@ def __init__(self, _langchain_tool):\n                 self.name = _langchain_tool.name.lower()\n                 self.description = _langchain_tool.description\n                 self.inputs = parse_langchain_args(_langchain_tool.args)\n-                self.output_type = \"text\"\n+                self.output_type = \"string\"\n                 self.langchain_tool = _langchain_tool\n \n             def forward(self, *args, **kwargs):\n@@ -421,6 +456,7 @@ def forward(self, *args, **kwargs):\n DEFAULT_TOOL_DESCRIPTION_TEMPLATE = \"\"\"\n - {{ tool.name }}: {{ tool.description }}\n     Takes inputs: {{tool.inputs}}\n+    Returns an output of type: {{tool.output_type}}\n \"\"\"\n \n \n@@ -621,18 +657,18 @@ def fn(*args, **kwargs):\n     gradio_inputs = []\n     for input_name, input_details in tool_class.inputs.items():\n         input_type = input_details[\"type\"]\n-        if input_type == \"text\":\n-            gradio_inputs.append(gr.Textbox(label=input_name))\n-        elif input_type == \"image\":\n+        if input_type == \"image\":\n             gradio_inputs.append(gr.Image(label=input_name))\n         elif input_type == \"audio\":\n             gradio_inputs.append(gr.Audio(label=input_name))\n+        elif input_type in [\"string\", \"integer\", \"number\"]:\n+            gradio_inputs.append(gr.Textbox(label=input_name))\n         else:\n             error_message = f\"Input type '{input_type}' not supported.\"\n             raise ValueError(error_message)\n \n     gradio_output = tool_class.output_type\n-    assert gradio_output in [\"text\", \"image\", \"audio\"], f\"Output type '{gradio_output}' not supported.\"\n+    assert gradio_output in [\"string\", \"image\", \"audio\"], f\"Output type '{gradio_output}' not supported.\"\n \n     gr.Interface(\n         fn=fn,\n@@ -808,3 +844,37 @@ def __init__(self, collection_slug: str, token: Optional[str] = None):\n         self._collection = get_collection(collection_slug, token=token)\n         self._hub_repo_ids = {item.item_id for item in self._collection.items if item.item_type == \"space\"}\n         self.tools = {Tool.from_hub(repo_id) for repo_id in self._hub_repo_ids}\n+\n+\n+def tool(tool_function: Callable) -> Tool:\n+    \"\"\"\n+    Converts a function into an instance of a Tool subclass.\n+\n+    Args:\n+        tool_function: Your function. Should have type hints for each input and a type hint for the output.\n+        Should also have a docstring description including an 'Args:' part where each argument is described.\n+    \"\"\"\n+    parameters = get_json_schema(tool_function)[\"function\"]\n+    if \"return\" not in parameters:\n+        raise TypeHintParsingException(\"Tool return type not found: make sure your function has a return type hint!\")\n+    class_name = f\"{parameters['name'].capitalize()}Tool\"\n+\n+    class SpecificTool(Tool):\n+        name = parameters[\"name\"]\n+        description = parameters[\"description\"]\n+        inputs = parameters[\"parameters\"][\"properties\"]\n+        output_type = parameters[\"return\"][\"type\"]\n+\n+        @wraps(tool_function)\n+        def forward(self, *args, **kwargs):\n+            return tool_function(*args, **kwargs)\n+\n+    original_signature = inspect.signature(tool_function)\n+    new_parameters = [inspect.Parameter(\"self\", inspect.Parameter.POSITIONAL_OR_KEYWORD)] + list(\n+        original_signature.parameters.values()\n+    )\n+    new_signature = original_signature.replace(parameters=new_parameters)\n+    SpecificTool.forward.__signature__ = new_signature\n+\n+    SpecificTool.__name__ = class_name\n+    return SpecificTool()"
        },
        {
            "sha": "7ae61f9679b8487bfc9085858afc8ac214d93ae7",
            "filename": "src/transformers/agents/translation.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Ftranslation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Fagents%2Ftranslation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fagents%2Ftranslation.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -249,17 +249,17 @@ class TranslationTool(PipelineTool):\n     model_class = AutoModelForSeq2SeqLM\n \n     inputs = {\n-        \"text\": {\"type\": \"text\", \"description\": \"The text to translate\"},\n+        \"text\": {\"type\": \"string\", \"description\": \"The text to translate\"},\n         \"src_lang\": {\n-            \"type\": \"text\",\n+            \"type\": \"string\",\n             \"description\": \"The language of the text to translate. Written in plain English, such as 'Romanian', or 'Albanian'\",\n         },\n         \"tgt_lang\": {\n-            \"type\": \"text\",\n+            \"type\": \"string\",\n             \"description\": \"The language for the desired ouput language. Written in plain English, such as 'Romanian', or 'Albanian'\",\n         },\n     }\n-    output_type = \"text\"\n+    output_type = \"string\"\n \n     def encode(self, text, src_lang, tgt_lang):\n         if src_lang not in self.lang_to_code:"
        },
        {
            "sha": "74912ce30146c6eb3c156285c47761dcc5c290b7",
            "filename": "src/transformers/utils/chat_template_utils.py",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Futils%2Fchat_template_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/src%2Ftransformers%2Futils%2Fchat_template_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fchat_template_utils.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -22,7 +22,7 @@\n \n from packaging import version\n \n-from .import_utils import is_jinja_available\n+from .import_utils import is_jinja_available, is_torch_available, is_vision_available\n \n \n if is_jinja_available():\n@@ -32,6 +32,12 @@\n else:\n     jinja2 = None\n \n+if is_vision_available():\n+    from PIL.Image import Image\n+\n+if is_torch_available():\n+    from torch import Tensor\n+\n \n BASIC_TYPES = (int, float, str, bool, Any, type(None), ...)\n # Extracts the initial segment of the docstring, containing the function description\n@@ -70,6 +76,8 @@ def _get_json_schema_type(param_type: str) -> Dict[str, str]:\n         float: {\"type\": \"number\"},\n         str: {\"type\": \"string\"},\n         bool: {\"type\": \"boolean\"},\n+        Image: {\"type\": \"image\"},\n+        Tensor: {\"type\": \"audio\"},\n         Any: {},\n     }\n     return type_mapping.get(param_type, {\"type\": \"object\"})"
        },
        {
            "sha": "4f24abbeedd8f183ed108ddd8ee9d2b7d4cd7238",
            "filename": "tests/agents/test_agents.py",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/tests%2Fagents%2Ftest_agents.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/tests%2Fagents%2Ftest_agents.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fagents%2Ftest_agents.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -68,7 +68,6 @@ def fake_react_code_llm(messages, stop_sequences=None, grammar=None) -> str:\n Code:\n ```py\n result = 2**3.6452\n-print(result)\n ```<end_code>\n \"\"\"\n     else:  # We're at step 2\n@@ -181,7 +180,6 @@ def test_fake_react_code_agent(self):\n         assert isinstance(output, float)\n         assert output == 7.2904\n         assert agent.logs[0][\"task\"] == \"What is 2 multiplied by 3.6452?\"\n-        assert float(agent.logs[1][\"observation\"].strip()) - 12.511648 < 1e-6\n         assert agent.logs[2][\"tool_call\"] == {\n             \"tool_arguments\": \"final_answer(7.2904)\",\n             \"tool_name\": \"code interpreter\",\n@@ -234,7 +232,7 @@ def test_init_agent_with_different_toolsets(self):\n \n         # check that python_interpreter base tool does not get added to code agents\n         agent = ReactCodeAgent(tools=[], llm_engine=fake_react_code_llm, add_base_tools=True)\n-        assert len(agent.toolbox.tools) == 6  # added final_answer tool + 5 base tools (excluding interpreter)\n+        assert len(agent.toolbox.tools) == 7  # added final_answer tool + 6 base tools (excluding interpreter)\n \n     def test_function_persistence_across_steps(self):\n         agent = ReactCodeAgent("
        },
        {
            "sha": "91bdd65e89a822a5ee457360dbacde69e64e3b52",
            "filename": "tests/agents/test_final_answer.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/tests%2Fagents%2Ftest_final_answer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/tests%2Fagents%2Ftest_final_answer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fagents%2Ftest_final_answer.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -19,8 +19,9 @@\n import numpy as np\n from PIL import Image\n \n-from transformers import is_torch_available, load_tool\n+from transformers import is_torch_available\n from transformers.agents.agent_types import AGENT_TYPE_MAPPING\n+from transformers.agents.default_tools import FinalAnswerTool\n from transformers.testing_utils import get_tests_dir, require_torch\n \n from .test_tools_common import ToolTesterMixin\n@@ -33,8 +34,7 @@\n class FinalAnswerToolTester(unittest.TestCase, ToolTesterMixin):\n     def setUp(self):\n         self.inputs = {\"answer\": \"Final answer\"}\n-        self.tool = load_tool(\"final_answer\")\n-        self.tool.setup()\n+        self.tool = FinalAnswerTool()\n \n     def test_exact_match_arg(self):\n         result = self.tool(\"Final answer\")\n@@ -52,7 +52,7 @@ def create_inputs(self):\n             )\n         }\n         inputs_audio = {\"answer\": torch.Tensor(np.ones(3000))}\n-        return {\"text\": inputs_text, \"image\": inputs_image, \"audio\": inputs_audio}\n+        return {\"string\": inputs_text, \"image\": inputs_image, \"audio\": inputs_audio}\n \n     @require_torch\n     def test_agent_type_output(self):"
        },
        {
            "sha": "15e5ad7bb3a3c78516eee3ea2070bdaaa607234e",
            "filename": "tests/agents/test_python_interpreter.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/tests%2Fagents%2Ftest_python_interpreter.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/tests%2Fagents%2Ftest_python_interpreter.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fagents%2Ftest_python_interpreter.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -391,8 +391,9 @@ def test_if_conditions(self):\n         code = \"\"\"char='a'\n if char.isalpha():\n     print('2')\"\"\"\n-        result = evaluate_python_code(code, BASE_PYTHON_TOOLS, state={})\n-        assert result == \"2\"\n+        state = {}\n+        evaluate_python_code(code, BASE_PYTHON_TOOLS, state=state)\n+        assert state[\"print_outputs\"] == \"2\\n\"\n \n     def test_imports(self):\n         code = \"import math\\nmath.sqrt(4)\"\n@@ -469,7 +470,7 @@ def test_print_output(self):\n         code = \"print('Hello world!')\\nprint('Ok no one cares')\"\n         state = {}\n         result = evaluate_python_code(code, BASE_PYTHON_TOOLS, state=state)\n-        assert result == \"Ok no one cares\"\n+        assert result is None\n         assert state[\"print_outputs\"] == \"Hello world!\\nOk no one cares\\n\"\n \n         # test print in function\n@@ -593,8 +594,7 @@ def method_that_raises(self):\n     def test_print(self):\n         code = \"print(min([1, 2, 3]))\"\n         state = {}\n-        result = evaluate_python_code(code, {\"min\": min, \"print\": print}, state=state)\n-        assert result == \"1\"\n+        evaluate_python_code(code, {\"min\": min, \"print\": print}, state=state)\n         assert state[\"print_outputs\"] == \"1\\n\"\n \n     def test_types_as_objects(self):"
        },
        {
            "sha": "8226e7109884e6b913a406c92be0bb2c0d4e72ed",
            "filename": "tests/agents/test_tools_common.py",
            "status": "modified",
            "additions": 72,
            "deletions": 3,
            "changes": 75,
            "blob_url": "https://github.com/huggingface/transformers/blob/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/tests%2Fagents%2Ftest_tools_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6/tests%2Fagents%2Ftest_tools_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fagents%2Ftest_tools_common.py?ref=e6d9f39dd7551d1a95be081cbb59f94c54c3dbf6",
            "patch": "@@ -12,13 +12,16 @@\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.\n+import unittest\n from pathlib import Path\n from typing import Dict, Union\n \n import numpy as np\n+import pytest\n \n from transformers import is_torch_available, is_vision_available\n from transformers.agents.agent_types import AGENT_TYPE_MAPPING, AgentAudio, AgentImage, AgentText\n+from transformers.agents.tools import Tool, tool\n from transformers.testing_utils import get_tests_dir, is_agent_test\n \n \n@@ -29,7 +32,7 @@\n     from PIL import Image\n \n \n-AUTHORIZED_TYPES = [\"text\", \"audio\", \"image\", \"any\"]\n+AUTHORIZED_TYPES = [\"string\", \"boolean\", \"integer\", \"number\", \"audio\", \"image\", \"any\"]\n \n \n def create_inputs(tool_inputs: Dict[str, Dict[Union[str, type], str]]):\n@@ -38,7 +41,7 @@ def create_inputs(tool_inputs: Dict[str, Dict[Union[str, type], str]]):\n     for input_name, input_desc in tool_inputs.items():\n         input_type = input_desc[\"type\"]\n \n-        if input_type == \"text\":\n+        if input_type == \"string\":\n             inputs[input_name] = \"Text input\"\n         elif input_type == \"image\":\n             inputs[input_name] = Image.open(\n@@ -54,7 +57,7 @@ def create_inputs(tool_inputs: Dict[str, Dict[Union[str, type], str]]):\n \n def output_type(output):\n     if isinstance(output, (str, AgentText)):\n-        return \"text\"\n+        return \"string\"\n     elif isinstance(output, (Image.Image, AgentImage)):\n         return \"image\"\n     elif isinstance(output, (torch.Tensor, AgentAudio)):\n@@ -100,3 +103,69 @@ def test_agent_types_inputs(self):\n         for _input, expected_input in zip(inputs, self.tool.inputs.values()):\n             input_type = expected_input[\"type\"]\n             _inputs.append(AGENT_TYPE_MAPPING[input_type](_input))\n+\n+\n+class ToolTests(unittest.TestCase):\n+    def test_tool_init_with_decorator(self):\n+        @tool\n+        def coolfunc(a: str, b: int) -> float:\n+            \"\"\"Cool function\n+\n+            Args:\n+                a: The first argument\n+                b: The second one\n+            \"\"\"\n+            return b + 2, a\n+\n+        assert coolfunc.output_type == \"number\"\n+\n+    def test_tool_init_vanilla(self):\n+        class HFModelDownloadsTool(Tool):\n+            name = \"model_download_counter\"\n+            description = \"\"\"\n+            This is a tool that returns the most downloaded model of a given task on the Hugging Face Hub.\n+            It returns the name of the checkpoint.\"\"\"\n+\n+            inputs = {\n+                \"task\": {\n+                    \"type\": \"string\",\n+                    \"description\": \"the task category (such as text-classification, depth-estimation, etc)\",\n+                }\n+            }\n+            output_type = \"integer\"\n+\n+            def forward(self, task):\n+                return \"best model\"\n+\n+        tool = HFModelDownloadsTool()\n+        assert list(tool.inputs.keys())[0] == \"task\"\n+\n+    def test_tool_init_decorator_raises_issues(self):\n+        with pytest.raises(Exception) as e:\n+\n+            @tool\n+            def coolfunc(a: str, b: int):\n+                \"\"\"Cool function\n+\n+                Args:\n+                    a: The first argument\n+                    b: The second one\n+                \"\"\"\n+                return a + b\n+\n+            assert coolfunc.output_type == \"number\"\n+        assert \"Tool return type not found\" in str(e)\n+\n+        with pytest.raises(Exception) as e:\n+\n+            @tool\n+            def coolfunc(a: str, b: int) -> int:\n+                \"\"\"Cool function\n+\n+                Args:\n+                    a: The first argument\n+                \"\"\"\n+                return b + a\n+\n+            assert coolfunc.output_type == \"number\"\n+        assert \"docstring has no description for the argument\" in str(e)"
        }
    ],
    "stats": {
        "total": 407,
        "additions": 294,
        "deletions": 113
    }
}