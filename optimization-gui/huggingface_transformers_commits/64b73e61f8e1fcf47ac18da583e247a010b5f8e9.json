{
    "author": "AhmedAlmaghz",
    "message": "[i18n-ar] Translated file : `docs/source/ar/benchmarks.md` into Arabic (#33023)\n\n* Add docs/source/ar/benchmarks.md to Add_docs_source_ar_benchmarks.md\r\n\r\n* Update docs/source/ar/benchmarks.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/benchmarks.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/benchmarks.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/benchmarks.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/benchmarks.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/benchmarks.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/benchmarks.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/benchmarks.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/benchmarks.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/benchmarks.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/benchmarks.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update _toctree.yml\r\n\r\n* Update benchmarks.md\r\n\r\n---------\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>",
    "sha": "64b73e61f8e1fcf47ac18da583e247a010b5f8e9",
    "files": [
        {
            "sha": "eacd54d540e1f59b54c97ebae9ca16b15b588430",
            "filename": "docs/source/ar/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/64b73e61f8e1fcf47ac18da583e247a010b5f8e9/docs%2Fsource%2Far%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/64b73e61f8e1fcf47ac18da583e247a010b5f8e9/docs%2Fsource%2Far%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2F_toctree.yml?ref=64b73e61f8e1fcf47ac18da583e247a010b5f8e9",
            "patch": "@@ -129,8 +129,8 @@\n     title: ุงูุชุตุฏูุฑ ุฅูู TFLite\n   - local: torchscript\n     title: ุงูุชุตุฏูุฑ ุฅูู TorchScript\n-#   - local: benchmarks\n-#     title: ุงููุนุงููุฑ\n+  - local: benchmarks\n+    title: ุงููุนุงููุฑ\n #   - local: notebooks\n #     title: ุฏูุงุชุฑ ุงูููุงุญุธุงุช ูุน ุงูุฃูุซูุฉ\n #   - local: community"
        },
        {
            "sha": "71e1829e6433509529f13e839f350226770971d4",
            "filename": "docs/source/ar/benchmarks.md",
            "status": "added",
            "additions": 352,
            "deletions": 0,
            "changes": 352,
            "blob_url": "https://github.com/huggingface/transformers/blob/64b73e61f8e1fcf47ac18da583e247a010b5f8e9/docs%2Fsource%2Far%2Fbenchmarks.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/64b73e61f8e1fcf47ac18da583e247a010b5f8e9/docs%2Fsource%2Far%2Fbenchmarks.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fbenchmarks.md?ref=64b73e61f8e1fcf47ac18da583e247a010b5f8e9",
            "patch": "@@ -0,0 +1,352 @@\n+# ูุนุงููุฑ ุงูุฃุฏุงุก\n+<Tip warning={true}>\n+\n+ุฃุฏูุงุช ููุงุณ ุงูุฃุฏุงุก ูู Hugging Face ุฃุตุจุญุช ูุฏููุฉุููููุตุญ ุจุงุณุชุฎุฏุงู ููุชุจุงุช ุฎุงุฑุฌูุฉ ูููุงุณ ุณุฑุนุฉ ูุชุนููุฏ ุงูุฐุงูุฑุฉ ูููุงุฐุฌ Transformer.\n+\n+</Tip>\n+\n+[[open-in-colab]]\n+\n+ูููู ูุธุฑุฉ ุนูู ููููุฉ ุชูููู ุฃุฏุงุก ููุงุฐุฌ ๐ค Transformersุ ูุฃูุถู ุงูููุงุฑุณุงุชุ ููุนุงููุฑ ุงูุฃุฏุงุก ุงููุชุงุญุฉ ุจุงููุนู.\n+\n+ููููู ุงูุนุซูุฑ ุนูู ุฏูุชุฑ ููุงุญุธุงุช ูุดุฑุญ ุจุงูุชูุตูู ููููุฉ ููุงุณ ุฃุฏุงุก ููุงุฐุฌ ๐ค Transformers [ููุง](https://github.com/huggingface/notebooks/tree/main/examples/benchmark.ipynb).\n+\n+## ููููุฉ ููุงุณ ุฃุฏุงุก ููุงุฐุฌ ๐ค Transformers\n+\n+ุชุณูุญ ุงููุฆุชุงู [`PyTorchBenchmark`] ู [`TensorFlowBenchmark`] ุจุชูููู ุฃุฏุงุก ููุงุฐุฌ ๐ค Transformers ุจูุฑููุฉ. ุชุชูุญ ููุง ูุฆุงุช ุงูุชูููู ููุงุณ ุงูุฃุฏุงุก ููุงุณ _ุงูุงุณุชุฎุฏุงู ุงูุฃูุตู ููุฐุงูุฑุฉ_ ู _ุงูููุช ุงููุงุฒู_ ููู ูู _ุงูุงุณุชุฏูุงู_ ู _ุงูุชุฏุฑูุจ_.\n+\n+<Tip>\n+\n+ููุงุ ูููุนุฑููู _ุงูุงุณุชุฏูุงู_ ุจุฃูู ุชูุฑูุฑุฉ ุฃูุงููุฉ ูุงุญุฏุฉุ ููุชู ุชุนุฑูู _ุงูุชุฏุฑูุจ_ ุจุฃูู ุชูุฑูุฑุฉ ุฃูุงููุฉ ูุงุญุฏุฉ ูุชูุฑูุฑุฉ ุฎูููุฉ ูุงุญุฏุฉ.\n+\n+</Tip>\n+\n+ุชุชููุน ูุฆุงุช ุชูููู ุงูุฃุฏุงุก [`PyTorchBenchmark`] ู [`TensorFlowBenchmark`] ูุงุฆููุง ูู ุงูููุน [`PyTorchBenchmarkArguments`] ู [`TensorFlowBenchmarkArguments`]ุ ุนูู ุงูุชูุงููุ ููุชูููุฐ. [`PyTorchBenchmarkArguments`] ู [`TensorFlowBenchmarkArguments`] ูู ูุฆุงุช ุจูุงูุงุช ูุชุญุชูู ุนูู ุฌููุน ุงูุชููููุงุช ุฐุงุช ุงูุตูุฉ ููุฆุฉ ุชูููู ุงูุฃุฏุงุก ุงูููุงุจูุฉ. ูู ุงููุซุงู ุงูุชุงููุ ูุชู ุชูุถูุญ ููููุฉ ุชูููู ุฃุฏุงุก ูููุฐุฌ BERT ูู ุงูููุน _bert-base-cased_.\n+\n+<frameworkcontent>\n+<pt>\n+  \n+```py\n+>>> from transformers import PyTorchBenchmark, PyTorchBenchmarkArguments\n+\n+>>> args = PyTorchBenchmarkArguments(models=[\"google-bert/bert-base-uncased\"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512])\n+>>> benchmark = PyTorchBenchmark(args)\n+```\n+</pt>\n+<tf>\n+  \n+```py\n+>>> from transformers import TensorFlowBenchmark, TensorFlowBenchmarkArguments\n+\n+>>> args = TensorFlowBenchmarkArguments(\n+...     models=[\"google-bert/bert-base-uncased\"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512]\n+... )\n+>>> benchmark = TensorFlowBenchmark(args)\n+```\n+</tf>\n+</frameworkcontent>\n+\n+ููุงุ ูุชู ุชูุฑูุฑ ุซูุงุซุฉ ูุนุงู๏ปปุช ุฅูู ูุฆุงุช ุจูุงูุงุช ุญุฌุฉ ููุงุณ ุงูุฃุฏุงุกุ ููู `models` ู `batch_sizes` ู `sequence_lengths`. ุงููุนุงูู `models` ูุทููุจุฉ ูุชุชููุน `ูุงุฆูุฉ` ูู ุจูุนุฑููุงุช ุงููููุฐุฌ ูู [ูุฑูุฒ ุงูููุงุฐุฌ](https://huggingface.co/models) ุชุญุฏุฏ ูุนุงู๏ปปุช ุงููุงุฆูุฉ `batch_sizes` ู `sequence_lengths` ุญุฌู `input_ids` ุงูุฐู ูุชู ููุงุณ ุฃุฏุงุก ุงููููุฐุฌ ุนููู. ููุงู ุงูุนุฏูุฏ ูู ุงููุนููุงุช ุงูุฃุฎุฑู ุงูุชู ูููู ุชูููููุง ุนุจุฑ ูุฆุงุช ุจูุงูุงุช ูุนุงู ููุงุณ ุงูุฃุฏุงุก. ููุฒูุฏ ูู ุงูุชูุงุตูู ุญูู ูุฐู ุงููุนููุงุชุ ููููู ุฅูุง ุงูุฑุฌูุน ูุจุงุดุฑุฉ ุฅูู ุงููููุงุช `src/transformers/benchmark/benchmark_args_utils.py`ุ `src/transformers/benchmark/benchmark_args.py` (ูู PyTorch) ู `src/transformers/benchmark/benchmark_args_tf.py` (ูู Tensorflow). ุฃูุ ุจุฏูุงู ูู ุฐููุ ูู ุจุชุดุบูู ุฃูุงูุฑ shell ุงูุชุงููุฉ ูู ุงููุฌูุฏ ุงูุฑุฆูุณู ูุทุจุงุนุฉ ูุงุฆูุฉ ูุตููุฉ ุจุฌููุน ุงููุนููุงุช ุงููุงุจูุฉ ููุชูููู ูู PyTorch ู Tensorflow ุนูู ุงูุชูุงูู.\n+\n+<frameworkcontent>\n+<pt>\n+  \n+```bash\n+python examples/pytorch/benchmarking/run_benchmark.py --help\n+```\n+\n+ููููู ุจุจุณุงุทุฉ ุชุดุบูู ูุงุฆู ุงูุชูููู ุงูุฐู ุชู ุชููุฆุชู ุนู ุทุฑูู ุงุณุชุฏุนุงุก `benchmark.run()`.\n+\n+```py\n+>>> results = benchmark.run()\n+>>> print(results)\n+====================       INFERENCE - SPEED - RESULT       ====================\n+--------------------------------------------------------------------------------\n+Model Name             Batch Size     Seq Length     Time in s                  \n+--------------------------------------------------------------------------------\n+google-bert/bert-base-uncased          8               8             0.006     \n+google-bert/bert-base-uncased          8               32            0.006     \n+google-bert/bert-base-uncased          8              128            0.018     \n+google-bert/bert-base-uncased          8              512            0.088     \n+--------------------------------------------------------------------------------\n+\n+====================      INFERENCE - MEMORY - RESULT       ====================\n+--------------------------------------------------------------------------------\n+Model Name             Batch Size     Seq Length    Memory in MB \n+--------------------------------------------------------------------------------\n+google-bert/bert-base-uncased          8               8             1227\n+google-bert/bert-base-uncased          8               32            1281\n+google-bert/bert-base-uncased          8              128            1307\n+google-bert/bert-base-uncased          8              512            1539\n+--------------------------------------------------------------------------------\n+\n+====================        ENVIRONMENT INFORMATION         ====================\n+\n+- transformers_version: 2.11.0\n+- framework: PyTorch\n+- use_torchscript: False\n+- framework_version: 1.4.0\n+- python_version: 3.6.10\n+- system: Linux\n+- cpu: x86_64\n+- architecture: 64bit\n+- date: 2020-06-29\n+- time: 08:58:43.371351\n+- fp16: False\n+- use_multiprocessing: True\n+- only_pretrain_model: False\n+- cpu_ram_mb: 32088\n+- use_gpu: True\n+- num_gpus: 1\n+- gpu: TITAN RTX\n+- gpu_ram_mb: 24217\n+- gpu_power_watts: 280.0\n+- gpu_performance_state: 2\n+- use_tpu: False\n+```\n+</pt>\n+<tf>\n+  \n+```bash\n+python examples/tensorflow/benchmarking/run_benchmark_tf.py --help\n+```\n+\n+ููููู ุจุนุฏ ุฐูู ุชุดุบูู ูุงุฆู ููุงุณ ุงูุฃุฏุงุก ุงูุฐู ุชู ุชููุฆุชู ุนู ุทุฑูู ุงุณุชุฏุนุงุก `benchmark.run()`.\n+\n+```py\n+>>> results = benchmark.run()\n+>>> print(results)\n+>>> results = benchmark.run()\n+>>> print(results)\n+====================       INFERENCE - SPEED - RESULT       ====================\n+--------------------------------------------------------------------------------\n+Model Name             Batch Size     Seq Length     Time in s                  \n+--------------------------------------------------------------------------------\n+google-bert/bert-base-uncased          8               8             0.005\n+google-bert/bert-base-uncased          8               32            0.008\n+google-bert/bert-base-uncased          8              128            0.022\n+google-bert/bert-base-uncased          8              512            0.105\n+--------------------------------------------------------------------------------\n+\n+====================      INFERENCE - MEMORY - RESULT       ====================\n+--------------------------------------------------------------------------------\n+Model Name             Batch Size     Seq Length    Memory in MB \n+--------------------------------------------------------------------------------\n+google-bert/bert-base-uncased          8               8             1330\n+google-bert/bert-base-uncased          8               32            1330\n+google-bert/bert-base-uncased          8              128            1330\n+google-bert/bert-base-uncased          8              512            1770\n+--------------------------------------------------------------------------------\n+\n+====================        ENVIRONMENT INFORMATION         ====================\n+\n+- transformers_version: 202.11.0\n+- framework: Tensorflow\n+- use_xla: False\n+- framework_version: 2.2.0\n+- python_version: 3.6.10\n+- system: Linux\n+- cpu: x86_64\n+- architecture: 64bit\n+- date: 2020-06-29\n+- time: 09:26:35.617317\n+- fp16: False\n+- use_multiprocessing: True\n+- only_pretrain_model: False\n+- cpu_ram_mb: 32088\n+- use_gpu: True\n+- num_gpus: 1\n+- gpu: TITAN RTX\n+- gpu_ram_mb: 24217\n+- gpu_power_watts: 280.0\n+- gpu_performance_state: 2\n+- use_tpu: False\n+```\n+</tf>\n+</frameworkcontent>\n+\n+ุจุดูู ุงูุชุฑุงุถูุ ูุชู ุชูููู _ุงูููุช_ ู _ุงูุฐุงูุฑุฉ ุงููุทููุจุฉ_ ูู _ุงูุงุณุชุฏูุงู_. ูู ูุซุงู ุงููุฎุฑุฌุงุช ุฃุนูุงูุ ููุธูุฑ ุงููุณูุงู ุงูุฃููุงู ุงููุชูุฌุฉ ุงูููุงุจูุฉ ูู _ููุช ุงูุงุณุชุฏูุงู_ ู _ุฐุงูุฑุฉ ุงูุงุณุชุฏูุงู_. ุจุงูุฅุถุงูุฉ ุฅูู ุฐููุ ูุชู ุทุจุงุนุฉ ุฌููุน ุงููุนูููุงุช ุฐุงุช ุงูุตูุฉ ุญูู ุจูุฆุฉ ุงูุญูุณุจุฉุ ุนูู ุณุจูู ุงููุซุงู ููุน ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU)ุ ูุงููุธุงูุ ูุฅุตุฏุงุฑุงุช ุงูููุชุจุฉุ ููุง ุฅูู ุฐููุ ูู ุงููุณู ุงูุซุงูุซ ุชุญุช _ูุนูููุงุช ุงูุจูุฆุฉ_. ูููู ุญูุธ ูุฐู ุงููุนูููุงุช ุจุดูู ุงุฎุชูุงุฑู ูู ููู _.csv_ ุนูุฏ ุฅุถุงูุฉ ุงููุนุงูู `save_to_csv=True` ุฅูู [`PyTorchBenchmarkArguments`] ู [`TensorFlowBenchmarkArguments`] ุนูู ุงูุชูุงูู. ูู ูุฐู ุงูุญุงูุฉุ ูุชู ุญูุธ ูู ูุณู ูู ููู _.csv_ ูููุตู. ูููู ุงุฎุชูุงุฑูุง ุชุญุฏูุฏ ูุณุงุฑ ูู ููู _.csv_ ุนุจุฑ ูุฆุงุช ุจูุงูุงุช ูุนุงูู ููุงุณ ุงูุฃุฏุงุก.\n+\n+ุจุฏูุงู ูู ุชูููู ุงูููุงุฐุฌ ุงููุฏุฑุจุฉ ูุณุจููุง ุนุจุฑ ูุนุฑูู ุงููููุฐุฌุ ุนูู ุณุจูู ุงููุซุงู `google-bert/bert-base-uncased`ุ ููููู ูููุณุชุฎุฏู ุจุฏูุงู ูู ุฐูู ููุงุณ ุฃุฏุงุก ุชูููู ุนุดูุงุฆู ูุฃู ูุฆุฉ ูููุฐุฌ ูุชุงุญุฉ. ูู ูุฐู ุงูุญุงูุฉุ ูุฌุจ ุฅุฏุฑุงุฌ \"ูุงุฆูุฉ\" ูู ุงูุชููููุงุช ูุน ูุนุงูู ููุงุณ ุงูุฃุฏุงุก ููุง ูู ููุถุญ ุฃุฏูุงู.\n+\n+<frameworkcontent>\n+<pt>\n+  \n+```py\n+>>> from transformers import PyTorchBenchmarkุ PyTorchBenchmarkArgumentsุ BertConfig\n+\n+>>> args = PyTorchBenchmarkArguments(\n+...     models=[\"bert-base\"ุ \"bert-384-hid\"ุ \"bert-6-lay\"]ุ batch_sizes=[8]ุ sequence_lengths=[8ุ 32ุ 128ุ 512]\n+... )\n+>>> config_base = BertConfig()\n+>>> config_384_hid = BertConfig(hidden_size=384)\n+>>> config_6_lay = BertConfig(num_hidden_layers=6)\n+\n+>>> benchmark = PyTorchBenchmark(argsุ configs=[config_baseุ config_384_hidุ config_6_lay])\n+>>> benchmark.run()\n+====================       INFERENCE - SPEED - RESULT       ====================\n+--------------------------------------------------------------------------------\n+Model Name             Batch Size     Seq Length       Time in s                  \n+--------------------------------------------------------------------------------\n+bert-base                  8              128            0.006\n+bert-base                  8              512            0.006\n+bert-base                  8              128            0.018     \n+bert-base                  8              512            0.088     \n+bert-384-hid              8               8             0.006     \n+bert-384-hid              8               32            0.006     \n+bert-384-hid              8              128            0.011     \n+bert-384-hid              8              512            0.054     \n+bert-6-lay                 8               8             0.003     \n+bert-6-lay                 8               32            0.004     \n+bert-6-lay                 8              128            0.009     \n+bert-6-lay                 8              512            0.044\n+--------------------------------------------------------------------------------\n+\n+====================      INFERENCE - MEMORY - RESULT       ====================\n+--------------------------------------------------------------------------------\n+Model Name             Batch Size     Seq Length      Memory in MB\n+## ูุชุงุฆุฌ ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก\n+\n+ูู ูุฐุง ุงููุณูุ ูุชู ููุงุณ _ููุช ุงูุงุณุชุฏูุงู_ ู _ุงูุฐุงูุฑุฉ ุงููุทููุจุฉ_ ููุงุณุชุฏูุงูุ ููุฎุชูู ุชููููุงุช `BertModel`. ูุชู ุนุฑุถ ุงููุชุงุฆุฌ ูู ุฌุฏููุ ูุน ุชูุณูู ูุฎุชูู ููููุงู ููู ูู PyTorch ู TensorFlow.\n+\n+--------------------------------------------------------------------------------\n+| ุงุณู ุงููููุฐุฌ | ุญุฌู ุงูุฏูุนุฉ | ุทูู ุงูุชุณูุณู | ุงูุฐุงูุฑุฉ ุจุงูููุบุงุจุงูุช |\n+--------------------------------------------------------------------------------\n+| bert-base | 8 | 8 | 1277 |\n+| bert-base | 8 | 32 | 1281 |\n+| bert-base | 8 | 128 | 1307 |\n+| bert-base | 8 | 512 | 1539 |\n+| bert-384-hid | 8 | 8 | 1005 |\n+| bert-384-hid | 8 | 32 | 1027 |\n+| bert-384-hid | 8 | 128 | 1035 |\n+| bert-384-hid | 8 | 512 | 1255 |\n+| bert-6-lay | 8 | 8 | 1097 |\n+| bert-6-lay | 8 | 32 | 1101 |\n+| bert-6-lay | 8 | 128 | 1127 |\n+| bert-6-lay | 8 | 512 | 1359 |\n+--------------------------------------------------------------------------------\n+\n+==================== ูุนูููุงุช ุงูุจูุฆุฉ ====================\n+\n+- transformers_version: 2.11.0\n+- framework: PyTorch\n+- use_torchscript: False\n+- framework_version: 1.4.0\n+- python_version: 3.6.10\n+- system: Linux\n+- cpu: x86_64\n+- architecture: 64bit\n+- date: 2020-06-29\n+- time: 09:35:25.143267\n+- fp16: False\n+- use_multiprocessing: True\n+- only_pretrain_model: False\n+- cpu_ram_mb: 32088\n+- use_gpu: True\n+- num_gpus: 1\n+- gpu: TITAN RTX\n+- gpu_ram_mb: 24217\n+- gpu_power_watts: 280.0\n+- gpu_performance_state: 2\n+- use_tpu: False\n+```\n+</pt>\n+<tf>\n+  \n+```py\n+>>> from transformers import TensorFlowBenchmark, TensorFlowBenchmarkArguments, BertConfig\n+\n+>>> args = TensorFlowBenchmarkArguments(\n+...     models=[\"bert-base\", \"bert-384-hid\", \"bert-6-lay\"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512]\n+... )\n+>>> config_base = BertConfig()\n+>>> config_384_hid = BertConfig(hidden_size=384)\n+>>> config_6_lay = BertConfig(num_hidden_layers=6)\n+\n+>>> benchmark = TensorFlowBenchmark(args, configs=[config_base, config_384_hid, config_6_lay])\n+>>> benchmark.run()\n+==================== ูุชุงุฆุฌ ุงูุณุฑุนุฉ ูู ุงูุงุณุชุฏูุงู ====================\n+--------------------------------------------------------------------------------\n+| ุงุณู ุงููููุฐุฌ | ุญุฌู ุงูุฏูุนุฉ | ุทูู ุงูุชุณูุณู | ุงูููุช ุจุงูุซุงููุฉ |\n+--------------------------------------------------------------------------------\n+| bert-base | 8 | 8 | 0.005 |\n+| bert-base | 8 | 32 | 0.008 |\n+| bert-base | 8 | 128 | 0.022 |\n+| bert-base | 8 | 512 | 0.106 |\n+| bert-384-hid | 8 | 8 | 0.005 |\n+| bert-384-hid | 8 | 32 | 0.007 |\n+| bert-384-hid | 8 | 128 | 0.018 |\n+| bert-384-hid | 8 | 512 | 0.064 |\n+| bert-6-lay | 8 | 8 | 0.002 |\n+| bert-6-lay | 8 | 32 | 0.003 |\n+| bert-6-lay | 8 | 128 | 0.0011 |\n+| bert-6-lay | 8 | 512 | 0.074 |\n+--------------------------------------------------------------------------------\n+\n+==================== ูุชุงุฆุฌ ุงูุฐุงูุฑุฉ ูู ุงูุงุณุชุฏูุงู ====================\n+--------------------------------------------------------------------------------\n+| ุงุณู ุงููููุฐุฌ | ุญุฌู ุงูุฏูุนุฉ | ุทูู ุงูุชุณูุณู | ุงูุฐุงูุฑุฉ ุจุงูููุบุงุจุงูุช |\n+--------------------------------------------------------------------------------\n+| ุงุณู ุงููููุฐุฌ | ุญุฌู ุงูุฏูุนุฉ | ุทูู ุงูุชุณูุณู | ุงูุฐุงูุฑุฉ ุจุงูููุบุงุจุงูุช |\n+--------------------------------------------------------------------------------\n+| bert-base | 8 | 8 | 1330 |\n+| bert-base | 8 | 32 | 1330 |\n+| bert-base | 8 | 128 | 1330 |\n+| bert-base | 8 | 512 | 1770 |\n+| bert-384-hid | 8 | 8 | 1330 |\n+| bert-384-hid | 8 | 32 | 1330 |\n+| bert-384-hid | 8 | 128 | 1330 |\n+| bert-384-hid | 8 | 512 | 1540 |\n+| bert-6-lay | 8 | 8 | 1330 |\n+| bert-6-lay | 8 | 32 | 1330 |\n+| bert-6-lay | 8 | 128 | 1330 |\n+| bert-6-lay | 8 | 512 | 1540 |\n+--------------------------------------------------------------------------------\n+\n+==================== ูุนูููุงุช ุงูุจูุฆุฉ ====================\n+\n+- transformers_version: 2.11.0\n+- framework: Tensorflow\n+- use_xla: False\n+- framework_version: 2.2.0\n+- python_version: 3.6.10\n+- system: Linux\n+- cpu: x86_64\n+- architecture: 64bit\n+- date: 2020-06-29\n+- time: 09:38:15.487125\n+- fp16: False\n+- use_multiprocessing: True\n+- only_pretrain_model: False\n+- cpu_ram_mb: 32088\n+- use_gpu: True\n+- num_gpus: 1\n+- gpu: TITAN RTX\n+- gpu_ram_mb: 24217\n+- gpu_power_watts: 280.0\n+- gpu_performance_state: 2\n+- use_tpu: False\n+```\n+</tf>\n+</frameworkcontent>\n+\n+ูุฑุฉ ุฃุฎุฑูุ ูุชู ููุงุณ _ููุช ุงูุงุณุชุฏูุงู_ ู _ุงูุฐุงูุฑุฉ ุงููุทููุจุฉ_ ููุงุณุชุฏูุงูุ ูููู ูุฐู ุงููุฑุฉ ูุชููููุงุช ูุฎุตุตุฉ ูู `BertModel`. ูููู ุฃู ุชููู ูุฐู ุงูููุฒุฉ ูููุฏุฉ ุจุดูู ุฎุงุต ุนูุฏ ุงุชุฎุงุฐ ูุฑุงุฑ ุจุดุฃู ุงูุชูููู ุงูุฐู ูุฌุจ ุชุฏุฑูุจ ุงููููุฐุฌ ุนููู.\n+\n+## ุฃูุถู ุงูููุงุฑุณุงุช ูู ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก\n+\n+ูุณุฑุฏ ูุฐุง ุงููุณู ุจุนุถ ุฃูุถู ุงูููุงุฑุณุงุช ุงูุชู ูุฌุจ ูุฑุงุนุงุชูุง ุนูุฏ ุฅุฌุฑุงุก ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ููููุฐุฌ ูุง.\n+\n+- ุญุงููุงูุ ูุชู ุฏุนู ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ุนูู ุฌูุงุฒ ูุงุญุฏ ููุท. ุนูุฏ ุฅุฌุฑุงุก ุงูุงุฎุชุจุงุฑ ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU)ุ ููุตู ุจุฃู ูููู ุงููุณุชุฎุฏู ุจุชุญุฏูุฏ ุงูุฌูุงุฒ ุงูุฐู ูุฌุจ ุชุดุบูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุนููู ูู ุฎูุงู ุชุนููู ูุชุบูุฑ ุงูุจูุฆุฉ `CUDA_VISIBLE_DEVICES` ูู ุงูุดูุ ุนูู ุณุจูู ุงููุซุงู `export CUDA_VISIBLE_DEVICES=0` ูุจู ุชุดุบูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ.\n+- ูุฌุจ ุชุนููู ุงูุฎูุงุฑ `no_multi_processing` ุฅูู `True` ููุท ูุฃุบุฑุงุถ ุงูุงุฎุชุจุงุฑ ูุงูุชุตุญูุญ. ููุถูุงู ููุงุณ ุงูุฐุงูุฑุฉ ุจุฏูุฉุ ููุตู ุจุชุดุบูู ูู ุงุฎุชุจุงุฑ ุฐุงูุฑุฉ ูู ุนูููุฉ ูููุตูุฉ ูุงูุชุฃูุฏ ูู ุชุนููู `no_multi_processing` ุฅูู `True`.\n+- ูุฌุจ ุฏุงุฆููุง ุฐูุฑ ูุนูููุงุช ุงูุจูุฆุฉ ุนูุฏ ูุดุงุฑูุฉ ูุชุงุฆุฌ ุชูููู ุงููููุฐุฌ. ููููู ุฃู ุชุฎุชูู ุงููุชุงุฆุฌ ุงุฎุชูุงููุง ูุจูุฑูุง ุจูู ุฃุฌูุฒุฉ GPU ุงููุฎุชููุฉ ูุฅุตุฏุงุฑุงุช ุงูููุชุจุงุชุ ููุง ุฅูู ุฐููุ ูุฐูู ูุฅู ูุชุงุฆุฌ ุงูุงุฎุชุจุงุฑ ุจููุฑุฏูุง ููุณุช ูููุฏุฉ ุฌุฏูุง ูููุฌุชูุน.\n+\n+## ูุดุงุฑูุฉ ูุชุงุฆุฌ ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ุงูุฎุงุต ุจู\n+\n+ูู ุงูุณุงุจูุ ุชู ุฅุฌุฑุงุก ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ูุฌููุน ุงูููุงุฐุฌ ุงูุฃุณุงุณูุฉ ุงููุชุงุญุฉ (10 ูู ุฐูู ุงูููุช) ูููุงุณ _ููุช ุงูุงุณุชุฏูุงู_ุ ุนุจุฑ ุงูุนุฏูุฏ ูู ุงูุฅุนุฏุงุฏุงุช ุงููุฎุชููุฉ: ุจุงุณุชุฎุฏุงู PyTorchุ ูุน TorchScript ูุจุฏูููุงุ ุจุงุณุชุฎุฏุงู TensorFlowุ ูุน XLA ูุจุฏููู. ุชู ุฅุฌุฑุงุก ุฌููุน ูุฐู ุงูุงุฎุชุจุงุฑุงุช ุนูู ูุญุฏุงุช ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU) (ุจุงุณุชุซูุงุก XLA TensorFlow) ููุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU).\n+\n+ูุชู ุดุฑุญ ูุฐุง ุงูููุฌ ุจุงูุชูุตูู ูู [ููุดูุฑ ุงููุฏููุฉ ูุฐุง](https://medium.com/huggingface/benchmarking-transformers-pytorch-and-tensorflow-e2917fb891c2) ูุชุชููุฑ ุงููุชุงุฆุฌ [ููุง](https://docs.google.com/spreadsheets/d/1sryqufw2D0XlUH4sq3e9Wnxu5EAQkaohzrJbd5HdQ_w/edit?usp=sharing).\n+\n+ูุน ุฃุฏูุงุช ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ุงูุฌุฏูุฏุฉุ ุฃุตุจุญ ูู ุงูุฃุณูู ูู ุฃู ููุช ูุถู ูุดุงุฑูุฉ ูุชุงุฆุฌ ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ุงูุฎุงุต ุจู ูุน ุงููุฌุชูุน:\n+\n+- [ูุชุงุฆุฌ ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ูู PyTorch](https://github.com/huggingface/transformers/tree/main/examples/pytorch/benchmarking/README.md).\n+- [ูุชุงุฆุฌ ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ูู TensorFlow](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/benchmarking/README.md)."
        }
    ],
    "stats": {
        "total": 356,
        "additions": 354,
        "deletions": 2
    }
}