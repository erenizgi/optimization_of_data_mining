{
    "author": "mfarre",
    "message": "bugfix Idefics3 processor - handle gracefully cases with text and no images (#35363)\n\n* bugfix processing empty images\n\n* fix\n\n* fix\n\n* Update src/transformers/models/idefics3/processing_idefics3.py\n\nCo-authored-by: Yoni Gozlan <74535834+yonigozlan@users.noreply.github.com>\n\n* adding tests\n\n* fix\n\n* fix\n\n* fix\n\n---------\n\nCo-authored-by: Yoni Gozlan <74535834+yonigozlan@users.noreply.github.com>",
    "sha": "a1780b7ba5da0e4d9f7035b4224fafe13727be6b",
    "files": [
        {
            "sha": "7ca5829e2063d8ce1357bf9e05ae279da170f314",
            "filename": "src/transformers/models/idefics3/processing_idefics3.py",
            "status": "modified",
            "additions": 43,
            "deletions": 35,
            "changes": 78,
            "blob_url": "https://github.com/huggingface/transformers/blob/a1780b7ba5da0e4d9f7035b4224fafe13727be6b/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a1780b7ba5da0e4d9f7035b4224fafe13727be6b/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py?ref=a1780b7ba5da0e4d9f7035b4224fafe13727be6b",
            "patch": "@@ -283,45 +283,53 @@ def __call__(\n             image_inputs = self.image_processor(images, **output_kwargs[\"images_kwargs\"])\n             inputs.update(image_inputs)\n \n-        if text is not None:\n-            if n_images_in_images != n_images_in_text:\n-                raise ValueError(\n-                    f\"The number of images in the text {n_images_in_text} and images  {n_images_in_images} should be the same.\"\n-                )\n-\n-            image_rows = inputs.pop(\"rows\", [[0] * len(text)])\n-            image_cols = inputs.pop(\"cols\", [[0] * len(text)])\n-\n-            fake_image_token = self.fake_image_token.content\n-            image_token = self.image_token.content\n-            global_img_token = self.global_image_tag\n-\n-            prompt_strings = []\n-            for sample, sample_rows, sample_cols in zip(text, image_rows, image_cols):\n-                # Replace the image token with fake tokens around the expanded image token sequence of length `image_seq_len`\n-                image_prompt_strings = []\n-                for n_rows, n_cols in zip(sample_rows, sample_cols):\n-                    image_prompt_string = get_image_prompt_string(\n-                        n_rows,\n-                        n_cols,\n-                        image_seq_len,\n-                        image_token=image_token,\n-                        fake_token_around_image=fake_image_token,\n-                        global_img_token=global_img_token,\n+            if text is not None:\n+                if n_images_in_images != n_images_in_text:\n+                    raise ValueError(\n+                        f\"The number of images in the text {n_images_in_text} and images {n_images_in_images} should be the same.\"\n                     )\n-                    image_prompt_strings.append(image_prompt_string)\n \n-                split_sample = sample.split(image_token)\n-                if len(split_sample) == 0:\n-                    raise ValueError(\"The image token should be present in the text.\")\n+                image_rows = inputs.pop(\"rows\", [[0] * len(text)])\n+                image_cols = inputs.pop(\"cols\", [[0] * len(text)])\n+\n+                fake_image_token = self.fake_image_token.content\n+                image_token = self.image_token.content\n+                global_img_token = self.global_image_tag\n+\n+                prompt_strings = []\n+                for sample, sample_rows, sample_cols in zip(text, image_rows, image_cols):\n+                    # Replace the image token with fake tokens around the expanded image token sequence of length `image_seq_len`\n+                    image_prompt_strings = []\n+                    for n_rows, n_cols in zip(sample_rows, sample_cols):\n+                        image_prompt_string = get_image_prompt_string(\n+                            n_rows,\n+                            n_cols,\n+                            image_seq_len,\n+                            image_token=image_token,\n+                            fake_token_around_image=fake_image_token,\n+                            global_img_token=global_img_token,\n+                        )\n+                        image_prompt_strings.append(image_prompt_string)\n \n-                # Place in the image prompt strings where the image tokens are\n-                sample = split_sample[0]\n-                for i, image_prompt_string in enumerate(image_prompt_strings):\n-                    sample += image_prompt_string + split_sample[i + 1]\n-                prompt_strings.append(sample)\n+                    split_sample = sample.split(image_token)\n+                    if len(split_sample) == 0:\n+                        raise ValueError(\"The image token should be present in the text.\")\n \n-            text_inputs = self.tokenizer(text=prompt_strings, **output_kwargs[\"text_kwargs\"])\n+                    # Place in the image prompt strings where the image tokens are\n+                    sample = split_sample[0]\n+                    for i, image_prompt_string in enumerate(image_prompt_strings):\n+                        sample += image_prompt_string + split_sample[i + 1]\n+                    prompt_strings.append(sample)\n+\n+                text_inputs = self.tokenizer(text=prompt_strings, **output_kwargs[\"text_kwargs\"])\n+                inputs.update(text_inputs)\n+\n+        elif text is not None:\n+            if any(n_images_in_text):\n+                raise ValueError(\n+                    f\"Found {sum(n_images_in_text)} {self.image_token.content} tokens in the text but no images were passed.\"\n+                )\n+            text_inputs = self.tokenizer(text=text, **output_kwargs[\"text_kwargs\"])\n             inputs.update(text_inputs)\n \n         return inputs"
        },
        {
            "sha": "36c5d2948449395d3921c855f4115f86b1250627",
            "filename": "tests/models/idefics3/test_processor_idefics3.py",
            "status": "modified",
            "additions": 71,
            "deletions": 0,
            "changes": 71,
            "blob_url": "https://github.com/huggingface/transformers/blob/a1780b7ba5da0e4d9f7035b4224fafe13727be6b/tests%2Fmodels%2Fidefics3%2Ftest_processor_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a1780b7ba5da0e4d9f7035b4224fafe13727be6b/tests%2Fmodels%2Fidefics3%2Ftest_processor_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fidefics3%2Ftest_processor_idefics3.py?ref=a1780b7ba5da0e4d9f7035b4224fafe13727be6b",
            "patch": "@@ -505,3 +505,74 @@ def test_unstructured_kwargs(self):\n \n         self.assertEqual(inputs[\"pixel_values\"].shape[3], 32)\n         self.assertEqual(len(inputs[\"input_ids\"][0]), 120)\n+\n+    @require_torch\n+    @require_vision\n+    def test_text_only_inference(self):\n+        \"\"\"Test that the processor works correctly with text-only input.\"\"\"\n+        processor = self.get_processor()\n+\n+        text = \"This is a simple text without images.\"\n+        inputs = processor(text=text)\n+\n+        tokenized_sentence = processor.tokenizer(text, add_special_tokens=False)\n+        expected_input_ids = [[self.bos_token_id] + tokenized_sentence[\"input_ids\"]]\n+\n+        self.assertEqual(inputs[\"input_ids\"], expected_input_ids)\n+        self.assertEqual(inputs[\"attention_mask\"], [[1] * len(expected_input_ids[0])])\n+        self.assertTrue(\"pixel_values\" not in inputs)\n+        self.assertTrue(\"pixel_attention_mask\" not in inputs)\n+\n+        # Test batch of texts without image tokens\n+        texts = [\"First text.\", \"Second piece of text.\"]\n+        batch_inputs = processor(text=texts, padding=True)\n+\n+        tokenized_1 = processor.tokenizer(texts[0], add_special_tokens=False)\n+        tokenized_2 = processor.tokenizer(texts[1], add_special_tokens=False)\n+\n+        expected_1 = [self.bos_token_id] + tokenized_1[\"input_ids\"]\n+        expected_2 = [self.bos_token_id] + tokenized_2[\"input_ids\"]\n+\n+        # Pad the shorter sequence\n+        pad_len = len(expected_2) - len(expected_1)\n+        if pad_len > 0:\n+            padded_expected_1 = [self.padding_token_id] * pad_len + expected_1\n+            expected_attention_1 = [0] * pad_len + [1] * len(expected_1)\n+            self.assertEqual(batch_inputs[\"input_ids\"], [padded_expected_1, expected_2])\n+            self.assertEqual(batch_inputs[\"attention_mask\"], [expected_attention_1, [1] * len(expected_2)])\n+        else:\n+            pad_len = -pad_len\n+            padded_expected_2 = [self.padding_token_id] * pad_len + expected_2\n+            expected_attention_2 = [0] * pad_len + [1] * len(expected_2)\n+            self.assertEqual(batch_inputs[\"input_ids\"], [expected_1, padded_expected_2])\n+            self.assertEqual(batch_inputs[\"attention_mask\"], [[1] * len(expected_1), expected_attention_2])\n+\n+    @require_torch\n+    @require_vision\n+    def test_missing_images_error(self):\n+        \"\"\"Test that appropriate error is raised when images are referenced but not provided.\"\"\"\n+        processor = self.get_processor()\n+\n+        # Test single text with image token but no image\n+        text = \"Let me show you this image: <image> What do you think?\"\n+        with self.assertRaises(ValueError) as context:\n+            processor(text=text)\n+        self.assertTrue(\"tokens in the text but no images were passed\" in str(context.exception))\n+\n+        # Test batch with image tokens but no images\n+        texts = [\n+            \"First text with <image> token.\",\n+            \"Second text <image> with token.\",\n+        ]\n+        with self.assertRaises(ValueError) as context:\n+            processor(text=texts)\n+        self.assertTrue(\"tokens in the text but no images were passed\" in str(context.exception))\n+\n+        # Test with None as Images\n+        with self.assertRaises(ValueError) as context:\n+            processor(text=text, images=None)\n+        self.assertTrue(\"tokens in the text but no images were passed\" in str(context.exception))\n+\n+        with self.assertRaises(ValueError) as context:\n+            processor(text=texts, images=None)\n+        self.assertTrue(\"tokens in the text but no images were passed\" in str(context.exception))"
        }
    ],
    "stats": {
        "total": 149,
        "additions": 114,
        "deletions": 35
    }
}