{
    "author": "xin3he",
    "message": "Ensure e_score_correction_bias dtype of DeepSeek-V3/R1 is FP32 (#42580)\n\n* Ensure e_score_correction_bias dtype of DeepSeek-V3/R1 is FP32\n\n* fix CI\n\nSigned-off-by: He, Xin3 <xin3.he@intel.com>\n\n---------\n\nSigned-off-by: He, Xin3 <xin3.he@intel.com>",
    "sha": "2e29a9a664fc3869794fbb2b9ace4ccae6cdea57",
    "files": [
        {
            "sha": "3ff27e85502e3ba135a78980b5e34500c29da011",
            "filename": "src/transformers/models/deepseek_v3/modeling_deepseek_v3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/2e29a9a664fc3869794fbb2b9ace4ccae6cdea57/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2e29a9a664fc3869794fbb2b9ace4ccae6cdea57/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py?ref=2e29a9a664fc3869794fbb2b9ace4ccae6cdea57",
            "patch": "@@ -548,6 +548,7 @@ class DeepseekV3PreTrainedModel(PreTrainedModel):\n         \"hidden_states\": DeepseekV3DecoderLayer,\n         \"attentions\": DeepseekV3Attention,\n     }\n+    _keep_in_fp32_modules_strict = [\"e_score_correction_bias\"]\n \n     @torch.no_grad()\n     def _init_weights(self, module):"
        },
        {
            "sha": "cb520e73a3cbf402e75647c5e0ed72556add2570",
            "filename": "src/transformers/models/deepseek_v3/modular_deepseek_v3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/2e29a9a664fc3869794fbb2b9ace4ccae6cdea57/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodular_deepseek_v3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2e29a9a664fc3869794fbb2b9ace4ccae6cdea57/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodular_deepseek_v3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodular_deepseek_v3.py?ref=2e29a9a664fc3869794fbb2b9ace4ccae6cdea57",
            "patch": "@@ -304,6 +304,7 @@ def __init__(self, config: DeepseekV3Config, layer_idx: int):\n \n class DeepseekV3PreTrainedModel(LlamaPreTrainedModel):\n     _can_compile_fullgraph = False\n+    _keep_in_fp32_modules_strict = [\"e_score_correction_bias\"]\n \n     @torch.no_grad()\n     def _init_weights(self, module):"
        },
        {
            "sha": "0a8f3f229064528f7f9cd1760c4b2e1638479f5c",
            "filename": "src/transformers/models/dots1/modeling_dots1.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/2e29a9a664fc3869794fbb2b9ace4ccae6cdea57/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2e29a9a664fc3869794fbb2b9ace4ccae6cdea57/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py?ref=2e29a9a664fc3869794fbb2b9ace4ccae6cdea57",
            "patch": "@@ -469,6 +469,7 @@ class Dots1PreTrainedModel(PreTrainedModel):\n         \"hidden_states\": Dots1DecoderLayer,\n         \"attentions\": Dots1Attention,\n     }\n+    _keep_in_fp32_modules_strict = [\"e_score_correction_bias\"]\n \n     @torch.no_grad()\n     def _init_weights(self, module):"
        },
        {
            "sha": "45e297fc15950c079bba5e4779c522657662b98b",
            "filename": "src/transformers/models/glm4_moe/modeling_glm4_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/2e29a9a664fc3869794fbb2b9ace4ccae6cdea57/src%2Ftransformers%2Fmodels%2Fglm4_moe%2Fmodeling_glm4_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2e29a9a664fc3869794fbb2b9ace4ccae6cdea57/src%2Ftransformers%2Fmodels%2Fglm4_moe%2Fmodeling_glm4_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4_moe%2Fmodeling_glm4_moe.py?ref=2e29a9a664fc3869794fbb2b9ace4ccae6cdea57",
            "patch": "@@ -492,6 +492,7 @@ class Glm4MoePreTrainedModel(PreTrainedModel):\n         \"hidden_states\": Glm4MoeDecoderLayer,\n         \"attentions\": Glm4MoeAttention,\n     }\n+    _keep_in_fp32_modules_strict = [\"e_score_correction_bias\"]\n \n     @torch.no_grad()\n     def _init_weights(self, module):"
        },
        {
            "sha": "cab52308b873b0a08d6d9d33e44ea60cf09c9277",
            "filename": "src/transformers/models/glm4v_moe/modeling_glm4v_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/2e29a9a664fc3869794fbb2b9ace4ccae6cdea57/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2e29a9a664fc3869794fbb2b9ace4ccae6cdea57/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py?ref=2e29a9a664fc3869794fbb2b9ace4ccae6cdea57",
            "patch": "@@ -594,6 +594,7 @@ class Glm4vMoePreTrainedModel(PreTrainedModel):\n         \"attentions\": Glm4vMoeTextAttention,\n         \"router_logits\": OutputRecorder(nn.Linear, layer_name=\"mlp.gate\", index=0),\n     }\n+    _keep_in_fp32_modules_strict = [\"e_score_correction_bias\"]\n     input_modalities = (\"text\", \"image\", \"video\")\n \n     @torch.no_grad()"
        }
    ],
    "stats": {
        "total": 5,
        "additions": 5,
        "deletions": 0
    }
}