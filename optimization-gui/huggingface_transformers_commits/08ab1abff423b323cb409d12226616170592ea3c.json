{
    "author": "Ben-Schneider-code",
    "message": "Add reminder config to issue template and print DS version in env (#35156)\n\n* update env command to log deepspeed version\n\n* suppress deepspeed import logging\n\n* Add reminder to include configs to repro description in bug report.\n\n* make fixup\n\n* [WIP] update import utils for deepspeed\n\n* Change to using is_deepspeed_available() from integrations.\n\n* make fixup",
    "sha": "08ab1abff423b323cb409d12226616170592ea3c",
    "files": [
        {
            "sha": "9b2c00bac50d6db2f437fe568b48dc5eb050b6de",
            "filename": ".github/ISSUE_TEMPLATE/bug-report.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/08ab1abff423b323cb409d12226616170592ea3c/.github%2FISSUE_TEMPLATE%2Fbug-report.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/08ab1abff423b323cb409d12226616170592ea3c/.github%2FISSUE_TEMPLATE%2Fbug-report.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2FISSUE_TEMPLATE%2Fbug-report.yml?ref=08ab1abff423b323cb409d12226616170592ea3c",
            "patch": "@@ -106,6 +106,7 @@ body:\n       label: Reproduction\n       description: |\n         Please provide a code sample that reproduces the problem you ran into. It can be a Colab link or just a code snippet.\n+        Please include relevant config information with your code, for example your Trainers, TRL, Peft, and DeepSpeed configs.\n         If you have code snippets, error messages, stack traces please provide them here as well.\n         Important! Use code tags to correctly format your code. See https://help.github.com/en/github/writing-on-github/creating-and-highlighting-code-blocks#syntax-highlighting\n         Do not use screenshots, as they are hard to read and (more importantly) don't allow others to copy-and-paste your code."
        },
        {
            "sha": "855bbc961bc2adf92750927be655e4304ff57a5e",
            "filename": "src/transformers/commands/env.py",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/08ab1abff423b323cb409d12226616170592ea3c/src%2Ftransformers%2Fcommands%2Fenv.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/08ab1abff423b323cb409d12226616170592ea3c/src%2Ftransformers%2Fcommands%2Fenv.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fenv.py?ref=08ab1abff423b323cb409d12226616170592ea3c",
            "patch": "@@ -12,14 +12,18 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n+\n+import contextlib\n import importlib.util\n+import io\n import os\n import platform\n from argparse import ArgumentParser\n \n import huggingface_hub\n \n from .. import __version__ as version\n+from ..integrations.deepspeed import is_deepspeed_available\n from ..utils import (\n     is_accelerate_available,\n     is_flax_available,\n@@ -104,6 +108,13 @@ def run(self):\n                 # returns list of devices, convert to bool\n                 tf_cuda_available = bool(tf.config.list_physical_devices(\"GPU\"))\n \n+        deepspeed_version = \"not installed\"\n+        if is_deepspeed_available():\n+            # Redirect command line output to silence deepspeed import output.\n+            with contextlib.redirect_stdout(io.StringIO()):\n+                import deepspeed\n+            deepspeed_version = deepspeed.__version__\n+\n         flax_version = \"not installed\"\n         jax_version = \"not installed\"\n         jaxlib_version = \"not installed\"\n@@ -126,6 +137,7 @@ def run(self):\n             \"Safetensors version\": f\"{safetensors_version}\",\n             \"Accelerate version\": f\"{accelerate_version}\",\n             \"Accelerate config\": f\"{accelerate_config_str}\",\n+            \"DeepSpeed version\": f\"{deepspeed_version}\",\n             \"PyTorch version (GPU?)\": f\"{pt_version} ({pt_cuda_available})\",\n             \"Tensorflow version (GPU?)\": f\"{tf_version} ({tf_cuda_available})\",\n             \"Flax version (CPU?/GPU?/TPU?)\": f\"{flax_version} ({jax_backend})\","
        }
    ],
    "stats": {
        "total": 13,
        "additions": 13,
        "deletions": 0
    }
}