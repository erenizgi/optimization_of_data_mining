{
    "author": "niqodea",
    "message": "fix: repair depth estimation multiprocessing (#33759)\n\n* fix: repair depth estimation multiprocessing\r\n\r\n* test: add test for multiprocess depth estimation",
    "sha": "0256520794529ef86b2d3e9fbefd20b54b0c7426",
    "files": [
        {
            "sha": "be45bdde8de5711b230b33b3e8daedee0ed42753",
            "filename": "src/transformers/pipelines/depth_estimation.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/0256520794529ef86b2d3e9fbefd20b54b0c7426/src%2Ftransformers%2Fpipelines%2Fdepth_estimation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0256520794529ef86b2d3e9fbefd20b54b0c7426/src%2Ftransformers%2Fpipelines%2Fdepth_estimation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fdepth_estimation.py?ref=0256520794529ef86b2d3e9fbefd20b54b0c7426",
            "patch": "@@ -89,20 +89,22 @@ def _sanitize_parameters(self, timeout=None, **kwargs):\n \n     def preprocess(self, image, timeout=None):\n         image = load_image(image, timeout)\n-        self.image_size = image.size\n         model_inputs = self.image_processor(images=image, return_tensors=self.framework)\n         if self.framework == \"pt\":\n             model_inputs = model_inputs.to(self.torch_dtype)\n+        model_inputs[\"target_size\"] = image.size[::-1]\n         return model_inputs\n \n     def _forward(self, model_inputs):\n+        target_size = model_inputs.pop(\"target_size\")\n         model_outputs = self.model(**model_inputs)\n+        model_outputs[\"target_size\"] = target_size\n         return model_outputs\n \n     def postprocess(self, model_outputs):\n         predicted_depth = model_outputs.predicted_depth\n         prediction = torch.nn.functional.interpolate(\n-            predicted_depth.unsqueeze(1), size=self.image_size[::-1], mode=\"bicubic\", align_corners=False\n+            predicted_depth.unsqueeze(1), size=model_outputs[\"target_size\"], mode=\"bicubic\", align_corners=False\n         )\n         output = prediction.squeeze().cpu().numpy()\n         formatted = (output * 255 / np.max(output)).astype(\"uint8\")"
        },
        {
            "sha": "16edeed453619c154525ba39a4e2c57fb18ff83e",
            "filename": "tests/pipelines/test_pipelines_depth_estimation.py",
            "status": "modified",
            "additions": 20,
            "deletions": 0,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/0256520794529ef86b2d3e9fbefd20b54b0c7426/tests%2Fpipelines%2Ftest_pipelines_depth_estimation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0256520794529ef86b2d3e9fbefd20b54b0c7426/tests%2Fpipelines%2Ftest_pipelines_depth_estimation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_depth_estimation.py?ref=0256520794529ef86b2d3e9fbefd20b54b0c7426",
            "patch": "@@ -116,3 +116,23 @@ def test_large_model_pt(self):\n     def test_small_model_pt(self):\n         # This is highly irregular to have no small tests.\n         self.skipTest(reason=\"There is not hf-internal-testing tiny model for either GLPN nor DPT\")\n+\n+    @require_torch\n+    def test_multiprocess(self):\n+        depth_estimator = pipeline(\n+            model=\"hf-internal-testing/tiny-random-DepthAnythingForDepthEstimation\",\n+            num_workers=2,\n+        )\n+        outputs = depth_estimator(\n+            [\n+                \"./tests/fixtures/tests_samples/COCO/000000039769.png\",\n+                \"./tests/fixtures/tests_samples/COCO/000000039769.png\",\n+            ]\n+        )\n+        self.assertEqual(\n+            [\n+                {\"predicted_depth\": ANY(torch.Tensor), \"depth\": ANY(Image.Image)},\n+                {\"predicted_depth\": ANY(torch.Tensor), \"depth\": ANY(Image.Image)},\n+            ],\n+            outputs,\n+        )"
        }
    ],
    "stats": {
        "total": 26,
        "additions": 24,
        "deletions": 2
    }
}