{
    "author": "asdkfjsd",
    "message": "[i18n-<languageCode>] Translating Benchmarks.md to Chinese (#35137)\n\n* add \"Translating Benchmarks.md to Chinese \"\r\n\r\n* Removed all the English original text (which was previously kept as comments in the document) and refined some of the Chinese expressions.",
    "sha": "91b8ab18b778ae9e2f8191866e018cd1dc7097be",
    "files": [
        {
            "sha": "c4c5890ed0b3f4cea493b6424a28affee0c518f2",
            "filename": "docs/source/zh/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/91b8ab18b778ae9e2f8191866e018cd1dc7097be/docs%2Fsource%2Fzh%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/91b8ab18b778ae9e2f8191866e018cd1dc7097be/docs%2Fsource%2Fzh%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2F_toctree.yml?ref=91b8ab18b778ae9e2f8191866e018cd1dc7097be",
            "patch": "@@ -50,6 +50,8 @@\n     title: å¯¼å‡ºä¸º TFLite\n   - local: torchscript\n     title: å¯¼å‡ºä¸º TorchScript\n+  - local: benchmarks\n+    title: å¯¹æ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•\n   - local: gguf\n     title: ä¸ GGUF æ ¼å¼çš„äº’æ“ä½œæ€§\n   - local: tiktoken"
        },
        {
            "sha": "2e9787c9a3bb6bf2384ac2fb1eb5cd75c8379424",
            "filename": "docs/source/zh/benchmarks.md",
            "status": "added",
            "additions": 377,
            "deletions": 0,
            "changes": 377,
            "blob_url": "https://github.com/huggingface/transformers/blob/91b8ab18b778ae9e2f8191866e018cd1dc7097be/docs%2Fsource%2Fzh%2Fbenchmarks.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/91b8ab18b778ae9e2f8191866e018cd1dc7097be/docs%2Fsource%2Fzh%2Fbenchmarks.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fbenchmarks.md?ref=91b8ab18b778ae9e2f8191866e018cd1dc7097be",
            "patch": "@@ -0,0 +1,377 @@\n+<!--Copyright 2020 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n+\n+âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+\n+# åŸºå‡†æµ‹è¯•\n+\n+<Tip warning={true}>\n+\n+å°æç¤ºï¼šHugging Faceçš„åŸºå‡†æµ‹è¯•å·¥å…·å·²ç»ä¸å†æ›´æ–°ï¼Œå»ºè®®ä½¿ç”¨å¤–éƒ¨åŸºå‡†æµ‹è¯•åº“æ¥è¡¡é‡Transformeræ¨¡\n+å‹çš„é€Ÿåº¦å’Œå†…å­˜å¤æ‚åº¦ã€‚\n+\n+</Tip>\n+\n+[[open-in-colab]]\n+\n+è®©æˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•å¯¹ğŸ¤— Transformersæ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œä»¥åŠè¿›è¡Œæµ‹è¯•çš„æ¨èç­–ç•¥å’Œå·²æœ‰çš„åŸºå‡†æµ‹è¯•ç»“æœã€‚\n+\n+å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„å›ç­”ï¼Œå¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/huggingface/notebooks/tree/main/examples/benchmark.ipynb)æ‰¾åˆ°æ›´å¤šå…³äºåŸºå‡†æµ‹è¯•çš„å†…å®¹ã€‚\n+\n+\n+## å¦‚ä½•å¯¹ğŸ¤— Transformersæ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•\n+\n+ä½¿ç”¨[`PyTorchBenchmark`]å’Œ[`TensorFlowBenchmark`]ç±»å¯ä»¥çµæ´»åœ°å¯¹ğŸ¤— Transformersæ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚è¿™äº›åŸºå‡†æµ‹è¯•ç±»å¯ä»¥è¡¡é‡æ¨¡å‹åœ¨**æ¨ç†**å’Œ**è®­ç»ƒ**è¿‡ç¨‹ä¸­æ‰€éœ€çš„**å³°å€¼å†…å­˜**å’Œ**æ—¶é—´**ã€‚\n+\n+<Tip>\n+\n+è¿™é‡Œçš„**æ¨ç†**æŒ‡çš„æ˜¯ä¸€æ¬¡å‰å‘ä¼ æ’­(forward pass)ï¼Œè€Œè®­ç»ƒåˆ™æŒ‡ä¸€æ¬¡å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­(backward pass)ã€‚\n+\n+</Tip>\n+\n+\n+åŸºå‡†æµ‹è¯•ç±» [`PyTorchBenchmark`] å’Œ [`TensorFlowBenchmark`] éœ€è¦åˆ†åˆ«ä¼ å…¥ [`PyTorchBenchmarkArguments`] å’Œ [`TensorFlowBenchmarkArguments`] ç±»å‹çš„å¯¹è±¡æ¥è¿›è¡Œå®ä¾‹åŒ–ã€‚è¿™äº›ç±»æ˜¯æ•°æ®ç±»å‹ï¼ŒåŒ…å«äº†æ‰€æœ‰ç›¸å…³çš„é…ç½®å‚æ•°ï¼Œç”¨äºå…¶å¯¹åº”çš„åŸºå‡†æµ‹è¯•ç±»ã€‚\n+\n+åœ¨ä¸‹é¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•å¯¹ç±»å‹ä¸º **bert-base-cased** çš„BERTæ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼š\n+\n+<frameworkcontent>\n+<pt>\n+```py\n+>>> from transformers import PyTorchBenchmark, PyTorchBenchmarkArguments\n+\n+>>> args = PyTorchBenchmarkArguments(models=[\"google-bert/bert-base-uncased\"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512])\n+>>> benchmark = PyTorchBenchmark(args)\n+```\n+</pt>\n+<tf>\n+```py\n+>>> from transformers import TensorFlowBenchmark, TensorFlowBenchmarkArguments\n+\n+>>> args = TensorFlowBenchmarkArguments(\n+...     models=[\"google-bert/bert-base-uncased\"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512]\n+... )\n+>>> benchmark = TensorFlowBenchmark(args)\n+```\n+</tf>\n+</frameworkcontent>\n+\n+åœ¨è¿™é‡Œï¼ŒåŸºå‡†æµ‹è¯•çš„å‚æ•°æ•°æ®ç±»æ¥å—äº†ä¸‰ä¸ªä¸»è¦çš„å‚æ•°ï¼Œå³ `models`ã€`batch_sizes` å’Œ`sequence_lengths`ã€‚å…¶ä¸­ï¼Œ`models` æ˜¯å¿…éœ€çš„å‚æ•°ï¼Œå®ƒæœŸæœ›ä¸€ä¸ªæ¥è‡ª[æ¨¡å‹åº“](https://huggingface.co/models)çš„æ¨¡å‹æ ‡è¯†ç¬¦åˆ—è¡¨ã€‚`batch_sizes` å’Œ `sequence_lengths` æ˜¯åˆ—è¡¨ç±»å‹çš„å‚æ•°ï¼Œå®šä¹‰äº†è¿›è¡ŒåŸºå‡†æµ‹è¯•æ—¶ `input_ids` çš„æ‰¹é‡å¤§å°å’Œåºåˆ—é•¿åº¦ã€‚\n+\n+è¿™äº›æ˜¯åŸºå‡†æµ‹è¯•æ•°æ®ç±»ä¸­å¯ä»¥é…ç½®çš„ä¸€äº›ä¸»è¦å‚æ•°ã€‚é™¤æ­¤ä¹‹å¤–ï¼ŒåŸºå‡†æµ‹è¯•æ•°æ®ç±»ä¸­è¿˜å¯ä»¥é…ç½®å¾ˆå¤šå…¶ä»–å‚æ•°ã€‚å¦‚éœ€è¦æŸ¥çœ‹æ›´è¯¦ç»†çš„é…ç½®å‚æ•°ï¼Œå¯ä»¥ç›´æ¥æŸ¥çœ‹ä»¥ä¸‹æ–‡ä»¶ï¼š\n+\n+* `src/transformers/benchmark/benchmark_args_utils.py`\n+* `src/transformers/benchmark/benchmark_args.py`ï¼ˆé’ˆå¯¹ PyTorchï¼‰\n+* `src/transformers/benchmark/benchmark_args_tf.py`ï¼ˆé’ˆå¯¹ TensorFlowï¼‰\n+  \n+å¦å¤–ï¼Œæ‚¨è¿˜å¯ä»¥é€šè¿‡åœ¨æ ¹ç›®å½•ä¸‹è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼ŒæŸ¥çœ‹é’ˆå¯¹ PyTorch å’Œ TensorFlow çš„æ‰€æœ‰å¯é…ç½®å‚æ•°çš„æè¿°åˆ—è¡¨ï¼š\n+``` bash python examples/pytorch/benchmarking/run_benchmark.py --help ```\n+è¿™äº›å‘½ä»¤å°†åˆ—å‡ºæ‰€æœ‰å¯ä»¥é…ç½®çš„å‚æ•°ï¼Œå®ƒä»¬å¯ä»¥å¸®åŠ©æ‚¨æ›´åŠ çµæ´»åœ°è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚\n+\n+\n+\n+<frameworkcontent>\n+<pt>\n+\n+ä»¥ä¸‹ä»£ç é€šè¿‡`PyTorchBenchmarkArguments`è®¾ç½®æ¨¡å‹æ‰¹å¤„ç†å¤§å°å’Œåºåˆ—é•¿åº¦ï¼Œç„¶åè°ƒç”¨`benchmark.run()`æ‰§è¡ŒåŸºå‡†æµ‹è¯•ã€‚\n+\n+```py\n+>>> results = benchmark.run()\n+>>> print(results)\n+====================       INFERENCE - SPEED - RESULT       ====================\n+--------------------------------------------------------------------------------\n+Model Name             Batch Size     Seq Length     Time in s                  \n+--------------------------------------------------------------------------------\n+google-bert/bert-base-uncased          8               8             0.006     \n+google-bert/bert-base-uncased          8               32            0.006     \n+google-bert/bert-base-uncased          8              128            0.018     \n+google-bert/bert-base-uncased          8              512            0.088     \n+--------------------------------------------------------------------------------\n+\n+====================      INFERENCE - MEMORY - RESULT       ====================\n+--------------------------------------------------------------------------------\n+Model Name             Batch Size     Seq Length    Memory in MB \n+--------------------------------------------------------------------------------\n+google-bert/bert-base-uncased          8               8             1227\n+google-bert/bert-base-uncased          8               32            1281\n+google-bert/bert-base-uncased          8              128            1307\n+google-bert/bert-base-uncased          8              512            1539\n+--------------------------------------------------------------------------------\n+\n+====================        ENVIRONMENT INFORMATION         ====================\n+\n+- transformers_version: 2.11.0\n+- framework: PyTorch\n+- use_torchscript: False\n+- framework_version: 1.4.0\n+- python_version: 3.6.10\n+- system: Linux\n+- cpu: x86_64\n+- architecture: 64bit\n+- date: 2020-06-29\n+- time: 08:58:43.371351\n+- fp16: False\n+- use_multiprocessing: True\n+- only_pretrain_model: False\n+- cpu_ram_mb: 32088\n+- use_gpu: True\n+- num_gpus: 1\n+- gpu: TITAN RTX\n+- gpu_ram_mb: 24217\n+- gpu_power_watts: 280.0\n+- gpu_performance_state: 2\n+- use_tpu: False\n+```\n+</pt>\n+<tf>\n+```bash\n+python examples/tensorflow/benchmarking/run_benchmark_tf.py --help\n+```\n+\n+æ¥ä¸‹æ¥ï¼Œåªéœ€è¦è°ƒç”¨ `benchmark.run()` å°±èƒ½è½»æ¾è¿è¡Œå·²ç»å®ä¾‹åŒ–çš„åŸºå‡†æµ‹è¯•å¯¹è±¡ã€‚\n+\n+```py\n+>>> results = benchmark.run()\n+>>> print(results)\n+>>> results = benchmark.run()\n+>>> print(results)\n+====================       INFERENCE - SPEED - RESULT       ====================\n+--------------------------------------------------------------------------------\n+Model Name             Batch Size     Seq Length     Time in s                  \n+--------------------------------------------------------------------------------\n+google-bert/bert-base-uncased          8               8             0.005\n+google-bert/bert-base-uncased          8               32            0.008\n+google-bert/bert-base-uncased          8              128            0.022\n+google-bert/bert-base-uncased          8              512            0.105\n+--------------------------------------------------------------------------------\n+\n+====================      INFERENCE - MEMORY - RESULT       ====================\n+--------------------------------------------------------------------------------\n+Model Name             Batch Size     Seq Length    Memory in MB \n+--------------------------------------------------------------------------------\n+google-bert/bert-base-uncased          8               8             1330\n+google-bert/bert-base-uncased          8               32            1330\n+google-bert/bert-base-uncased          8              128            1330\n+google-bert/bert-base-uncased          8              512            1770\n+--------------------------------------------------------------------------------\n+\n+====================        ENVIRONMENT INFORMATION         ====================\n+\n+- transformers_version: 2.11.0\n+- framework: Tensorflow\n+- use_xla: False\n+- framework_version: 2.2.0\n+- python_version: 3.6.10\n+- system: Linux\n+- cpu: x86_64\n+- architecture: 64bit\n+- date: 2020-06-29\n+- time: 09:26:35.617317\n+- fp16: False\n+- use_multiprocessing: True\n+- only_pretrain_model: False\n+- cpu_ram_mb: 32088\n+- use_gpu: True\n+- num_gpus: 1\n+- gpu: TITAN RTX\n+- gpu_ram_mb: 24217\n+- gpu_power_watts: 280.0\n+- gpu_performance_state: 2\n+- use_tpu: False\n+```\n+</tf>\n+</frameworkcontent>\n+\n+\n+\n+åœ¨ä¸€èˆ¬æƒ…å†µä¸‹ï¼ŒåŸºå‡†æµ‹è¯•ä¼šæµ‹é‡æ¨ç†ï¼ˆinferenceï¼‰çš„**æ—¶é—´**å’Œ**æ‰€éœ€å†…å­˜**ã€‚åœ¨ä¸Šé¢çš„ç¤ºä¾‹è¾“å‡ºä¸­ï¼Œå‰ä¸¤éƒ¨åˆ†æ˜¾ç¤ºäº†ä¸**æ¨ç†æ—¶é—´**å’Œ**æ¨ç†å†…å­˜**å¯¹åº”çš„ç»“æœã€‚ä¸æ­¤åŒæ—¶ï¼Œå…³äºè®¡ç®—ç¯å¢ƒçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ï¼ˆä¾‹å¦‚ GPU ç±»å‹ã€ç³»ç»Ÿã€åº“ç‰ˆæœ¬ç­‰ï¼‰ä¼šåœ¨ç¬¬ä¸‰éƒ¨åˆ†çš„**ç¯å¢ƒä¿¡æ¯**ä¸­æ‰“å°å‡ºæ¥ã€‚ä½ å¯ä»¥é€šè¿‡åœ¨ [`PyTorchBenchmarkArguments`] å’Œ [`TensorFlowBenchmarkArguments`] ä¸­æ·»åŠ  `save_to_csv=True`å‚æ•°ï¼Œå°†è¿™äº›ä¿¡æ¯ä¿å­˜åˆ°ä¸€ä¸ª .csv æ–‡ä»¶ä¸­ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¯ä¸€éƒ¨åˆ†çš„ä¿¡æ¯ä¼šåˆ†åˆ«ä¿å­˜åœ¨ä¸åŒçš„ .csv æ–‡ä»¶ä¸­ã€‚æ¯ä¸ª .csv æ–‡ä»¶çš„è·¯å¾„ä¹Ÿå¯ä»¥é€šè¿‡å‚æ•°æ•°æ®ç±»è¿›è¡Œå®šä¹‰ã€‚\n+\n+\n+æ‚¨å¯ä»¥é€‰æ‹©ä¸é€šè¿‡é¢„è®­ç»ƒæ¨¡å‹çš„æ¨¡å‹æ ‡è¯†ç¬¦ï¼ˆå¦‚ `google-bert/bert-base-uncased`ï¼‰è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œè€Œæ˜¯å¯¹ä»»ä½•å¯ç”¨æ¨¡å‹ç±»çš„ä»»æ„é…ç½®è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¿…é¡»å°†ä¸€ç³»åˆ—é…ç½®ä¸åŸºå‡†æµ‹è¯•å‚æ•°ä¸€èµ·ä¼ å…¥ï¼Œæ–¹æ³•å¦‚ä¸‹ï¼š\n+\n+<frameworkcontent>\n+<pt>\n+```py\n+>>> from transformers import PyTorchBenchmark, PyTorchBenchmarkArguments, BertConfig\n+\n+>>> args = PyTorchBenchmarkArguments(\n+...     models=[\"bert-base\", \"bert-384-hid\", \"bert-6-lay\"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512]\n+... )\n+>>> config_base = BertConfig()\n+>>> config_384_hid = BertConfig(hidden_size=384)\n+>>> config_6_lay = BertConfig(num_hidden_layers=6)\n+\n+>>> benchmark = PyTorchBenchmark(args, configs=[config_base, config_384_hid, config_6_lay])\n+>>> benchmark.run()\n+====================       INFERENCE - SPEED - RESULT       ====================\n+--------------------------------------------------------------------------------\n+Model Name             Batch Size     Seq Length       Time in s                  \n+--------------------------------------------------------------------------------\n+bert-base                  8              128            0.006\n+bert-base                  8              512            0.006\n+bert-base                  8              128            0.018     \n+bert-base                  8              512            0.088     \n+bert-384-hid              8               8             0.006     \n+bert-384-hid              8               32            0.006     \n+bert-384-hid              8              128            0.011     \n+bert-384-hid              8              512            0.054     \n+bert-6-lay                 8               8             0.003     \n+bert-6-lay                 8               32            0.004     \n+bert-6-lay                 8              128            0.009     \n+bert-6-lay                 8              512            0.044\n+--------------------------------------------------------------------------------\n+\n+====================      INFERENCE - MEMORY - RESULT       ====================\n+--------------------------------------------------------------------------------\n+Model Name             Batch Size     Seq Length      Memory in MB \n+--------------------------------------------------------------------------------\n+bert-base                  8               8             1277\n+bert-base                  8               32            1281\n+bert-base                  8              128            1307     \n+bert-base                  8              512            1539     \n+bert-384-hid              8               8             1005     \n+bert-384-hid              8               32            1027     \n+bert-384-hid              8              128            1035     \n+bert-384-hid              8              512            1255     \n+bert-6-lay                 8               8             1097     \n+bert-6-lay                 8               32            1101     \n+bert-6-lay                 8              128            1127     \n+bert-6-lay                 8              512            1359\n+--------------------------------------------------------------------------------\n+\n+====================        ENVIRONMENT INFORMATION         ====================\n+\n+- transformers_version: 2.11.0\n+- framework: PyTorch\n+- use_torchscript: False\n+- framework_version: 1.4.0\n+- python_version: 3.6.10\n+- system: Linux\n+- cpu: x86_64\n+- architecture: 64bit\n+- date: 2020-06-29\n+- time: 09:35:25.143267\n+- fp16: False\n+- use_multiprocessing: True\n+- only_pretrain_model: False\n+- cpu_ram_mb: 32088\n+- use_gpu: True\n+- num_gpus: 1\n+- gpu: TITAN RTX\n+- gpu_ram_mb: 24217\n+- gpu_power_watts: 280.0\n+- gpu_performance_state: 2\n+- use_tpu: False\n+```\n+</pt>\n+<tf>\n+```py\n+>>> from transformers import TensorFlowBenchmark, TensorFlowBenchmarkArguments, BertConfig\n+\n+>>> args = TensorFlowBenchmarkArguments(\n+...     models=[\"bert-base\", \"bert-384-hid\", \"bert-6-lay\"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512]\n+... )\n+>>> config_base = BertConfig()\n+>>> config_384_hid = BertConfig(hidden_size=384)\n+>>> config_6_lay = BertConfig(num_hidden_layers=6)\n+\n+>>> benchmark = TensorFlowBenchmark(args, configs=[config_base, config_384_hid, config_6_lay])\n+>>> benchmark.run()\n+====================       INFERENCE - SPEED - RESULT       ====================\n+--------------------------------------------------------------------------------\n+Model Name             Batch Size     Seq Length       Time in s                  \n+--------------------------------------------------------------------------------\n+bert-base                  8               8             0.005\n+bert-base                  8               32            0.008\n+bert-base                  8              128            0.022\n+bert-base                  8              512            0.106\n+bert-384-hid              8               8             0.005\n+bert-384-hid              8               32            0.007\n+bert-384-hid              8              128            0.018\n+bert-384-hid              8              512            0.064\n+bert-6-lay                 8               8             0.002\n+bert-6-lay                 8               32            0.003\n+bert-6-lay                 8              128            0.0011\n+bert-6-lay                 8              512            0.074\n+--------------------------------------------------------------------------------\n+\n+====================      INFERENCE - MEMORY - RESULT       ====================\n+--------------------------------------------------------------------------------\n+Model Name             Batch Size     Seq Length      Memory in MB \n+--------------------------------------------------------------------------------\n+bert-base                  8               8             1330\n+bert-base                  8               32            1330\n+bert-base                  8              128            1330\n+bert-base                  8              512            1770\n+bert-384-hid              8               8             1330\n+bert-384-hid              8               32            1330\n+bert-384-hid              8              128            1330\n+bert-384-hid              8              512            1540\n+bert-6-lay                 8               8             1330\n+bert-6-lay                 8               32            1330\n+bert-6-lay                 8              128            1330\n+bert-6-lay                 8              512            1540\n+--------------------------------------------------------------------------------\n+\n+====================        ENVIRONMENT INFORMATION         ====================\n+\n+- transformers_version: 2.11.0\n+- framework: Tensorflow\n+- use_xla: False\n+- framework_version: 2.2.0\n+- python_version: 3.6.10\n+- system: Linux\n+- cpu: x86_64\n+- architecture: 64bit\n+- date: 2020-06-29\n+- time: 09:38:15.487125\n+- fp16: False\n+- use_multiprocessing: True\n+- only_pretrain_model: False\n+- cpu_ram_mb: 32088\n+- use_gpu: True\n+- num_gpus: 1\n+- gpu: TITAN RTX\n+- gpu_ram_mb: 24217\n+- gpu_power_watts: 280.0\n+- gpu_performance_state: 2\n+- use_tpu: False\n+```\n+</tf>\n+</frameworkcontent>\n+\n+\n+ **æ¨ç†æ—¶é—´**å’Œ**æ¨ç†æ‰€éœ€å†…å­˜**ä¼šè¢«é‡æ–°æµ‹é‡ï¼Œä¸è¿‡è¿™æ¬¡æ˜¯é’ˆå¯¹ `BertModel` ç±»çš„è‡ªå®šä¹‰é…ç½®è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚è¿™ä¸ªåŠŸèƒ½åœ¨å†³å®šæ¨¡å‹åº”è¯¥ä½¿ç”¨å“ªç§é…ç½®è¿›è¡Œè®­ç»ƒæ—¶å°¤å…¶æœ‰ç”¨ã€‚\n+\n+\n+## åŸºå‡†æµ‹è¯•çš„æ¨èç­–ç•¥\n+æœ¬èŠ‚åˆ—å‡ºäº†ä¸€äº›åœ¨å¯¹æ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•æ—¶æ¯”è¾ƒæ¨èçš„ç­–ç•¥ï¼š\n+\n+* ç›®å‰ï¼Œè¯¥æ¨¡å—åªæ”¯æŒå•è®¾å¤‡åŸºå‡†æµ‹è¯•ã€‚åœ¨è¿›è¡Œ GPU åŸºå‡†æµ‹è¯•æ—¶ï¼Œå»ºè®®ç”¨æˆ·é€šè¿‡è®¾ç½® `CUDA_VISIBLE_DEVICES` ç¯å¢ƒå˜é‡æ¥æŒ‡å®šä»£ç åº”åœ¨å“ªä¸ªè®¾å¤‡ä¸Šè¿è¡Œï¼Œä¾‹å¦‚åœ¨è¿è¡Œä»£ç å‰æ‰§è¡Œ `export CUDA_VISIBLE_DEVICES=0`ã€‚\n+* `no_multi_processing` é€‰é¡¹ä»…åº”åœ¨æµ‹è¯•å’Œè°ƒè¯•æ—¶è®¾ç½®ä¸º `True`ã€‚ä¸ºäº†ç¡®ä¿å†…å­˜æµ‹é‡çš„å‡†ç¡®æ€§ï¼Œå»ºè®®å°†æ¯ä¸ªå†…å­˜åŸºå‡†æµ‹è¯•å•ç‹¬è¿è¡Œåœ¨ä¸€ä¸ªè¿›ç¨‹ä¸­ï¼Œå¹¶ç¡®ä¿ `no_multi_processing` è®¾ç½®ä¸º `True`ã€‚\n+* å½“æ‚¨åˆ†äº«æ¨¡å‹åŸºå‡†æµ‹è¯•ç»“æœæ—¶ï¼Œåº”å§‹ç»ˆæä¾›ç¯å¢ƒä¿¡æ¯ã€‚ç”±äº GPU è®¾å¤‡ã€åº“ç‰ˆæœ¬ç­‰ä¹‹é—´å¯èƒ½å­˜åœ¨è¾ƒå¤§å·®å¼‚ï¼Œå•ç‹¬çš„åŸºå‡†æµ‹è¯•ç»“æœå¯¹ç¤¾åŒºçš„å¸®åŠ©æœ‰é™ã€‚\n+\n+\n+## åˆ†äº«æ‚¨çš„åŸºå‡†æµ‹è¯•ç»“æœ\n+\n+å…ˆå‰çš„æ‰€æœ‰å¯ç”¨çš„æ ¸å¿ƒæ¨¡å‹ï¼ˆå½“æ—¶æœ‰10ä¸ªï¼‰éƒ½å·²é’ˆå¯¹ **æ¨ç†æ—¶é—´** è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–äº†å¤šç§ä¸åŒçš„è®¾ç½®ï¼šä½¿ç”¨ PyTorchï¼ˆåŒ…ä¸åŒ…å« TorchScriptï¼‰ï¼Œä½¿ç”¨ TensorFlowï¼ˆåŒ…ä¸åŒ…å« XLAï¼‰ã€‚æ‰€æœ‰çš„æµ‹è¯•éƒ½åœ¨ CPUï¼ˆé™¤äº† TensorFlow XLAï¼‰å’Œ GPU ä¸Šè¿›è¡Œã€‚\n+\n+è¿™ç§æ–¹æ³•çš„è¯¦ç»†ä¿¡æ¯å¯ä»¥åœ¨ [è¿™ç¯‡åšå®¢](https://medium.com/huggingface/benchmarking-transformers-pytorch-and-tensorflow-e2917fb891c2) ä¸­æ‰¾åˆ°ï¼Œæµ‹è¯•ç»“æœå¯ä»¥åœ¨ [è¿™é‡Œ](https://docs.google.com/spreadsheets/d/1sryqufw2D0XlUH4sq3e9Wnxu5EAQkaohzrJbd5HdQ_w/edit?usp=sharing) æŸ¥çœ‹ã€‚\n+\n+\n+æ‚¨å¯ä»¥å€ŸåŠ©æ–°çš„ **åŸºå‡†æµ‹è¯•** å·¥å…·æ¯”ä»¥å¾€ä»»ä½•æ—¶å€™éƒ½æ›´å®¹æ˜“åœ°åˆ†äº«æ‚¨çš„åŸºå‡†æµ‹è¯•ç»“æœï¼\n+\n+- [PyTorch åŸºå‡†æµ‹è¯•ç»“æœ](https://github.com/huggingface/transformers/tree/main/examples/pytorch/benchmarking/README.md)\n+- [TensorFlow åŸºå‡†æµ‹è¯•ç»“æœ](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/benchmarking/README.md)\n+\n+"
        }
    ],
    "stats": {
        "total": 379,
        "additions": 379,
        "deletions": 0
    }
}