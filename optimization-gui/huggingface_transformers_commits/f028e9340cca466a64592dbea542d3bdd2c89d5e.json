{
    "author": "SunMarc",
    "message": "Fix model name test for compressed tensors  (#42128)\n\n* fix models\n\n* fix output",
    "sha": "f028e9340cca466a64592dbea542d3bdd2c89d5e",
    "files": [
        {
            "sha": "47ab72e1e071af4218e6510cc741886af96fb5e8",
            "filename": "tests/quantization/compressed_tensors_integration/test_compressed_models.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f028e9340cca466a64592dbea542d3bdd2c89d5e/tests%2Fquantization%2Fcompressed_tensors_integration%2Ftest_compressed_models.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f028e9340cca466a64592dbea542d3bdd2c89d5e/tests%2Fquantization%2Fcompressed_tensors_integration%2Ftest_compressed_models.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fquantization%2Fcompressed_tensors_integration%2Ftest_compressed_models.py?ref=f028e9340cca466a64592dbea542d3bdd2c89d5e",
            "patch": "@@ -155,8 +155,8 @@ def test_no_warnings_for_all_models(self):\n @require_compressed_tensors\n @require_torch\n class RunCompressedTest(unittest.TestCase):\n-    tinyllama_w4a16 = \"nm-testing/tinyllama-w4a16-compressed-hf-quantizer\"\n-    tinyllama_w8a8 = \"nm-testing/tinyllama-w8a8-compressed-hf-quantizer\"\n+    tinyllama_w4a16 = \"nm-testing/tinyllama-w4a16-compressed\"\n+    tinyllama_w8a8 = \"nm-testing/tinyllama-w8a8-compressed\"\n \n     prompt = \"Paris is the capital of which country?\"\n "
        },
        {
            "sha": "f4e502dc73fa0ddc05147c37f8ff7c2808498b17",
            "filename": "tests/quantization/compressed_tensors_integration/test_compressed_tensors.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f028e9340cca466a64592dbea542d3bdd2c89d5e/tests%2Fquantization%2Fcompressed_tensors_integration%2Ftest_compressed_tensors.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f028e9340cca466a64592dbea542d3bdd2c89d5e/tests%2Fquantization%2Fcompressed_tensors_integration%2Ftest_compressed_tensors.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fquantization%2Fcompressed_tensors_integration%2Ftest_compressed_tensors.py?ref=f028e9340cca466a64592dbea542d3bdd2c89d5e",
            "patch": "@@ -13,9 +13,9 @@\n @require_compressed_tensors\n @require_torch\n class CompressedTensorsTest(unittest.TestCase):\n-    tinyllama_w8a16 = \"nm-testing/tinyllama-w8a16-dense-hf-quantizer\"\n-    tinyllama_w4a16 = \"nm-testing/tinyllama-w4a16-compressed-hf-quantizer\"\n-    tinyllama_w8a8 = \"nm-testing/tinyllama-w8a8-compressed-hf-quantizer\"\n+    tinyllama_w8a16 = \"nm-testing/tinyllama-w8a16-dense\"\n+    tinyllama_w4a16 = \"nm-testing/tinyllama-w4a16-compressed\"\n+    tinyllama_w8a8 = \"nm-testing/tinyllama-w8a8-compressed\"\n     llama3_8b_fp8 = \"nm-testing/Meta-Llama-3-8B-Instruct-fp8-hf_compat\"\n \n     prompt = \"Paris is the capital of which country?\"\n@@ -59,7 +59,7 @@ def test_tinyllama_w8a16(self):\n         self._test_quantized_model(self.tinyllama_w8a16, expected_out)\n \n     def test_llama_8b_fp8(self):\n-        expected_out = \"<|begin_of_text|>Paris is the capital of which country? France\\nWhat is the name of the famous art museum in Paris? The Louvre\\nWhat is the name of the famous opera house in Paris? Palais Garnier\\nWhat is the name of the\"\n+        expected_out = \"<|begin_of_text|>Paris is the capital of which country? France\\nWhat is the name of the famous art museum in Paris? The Louvre\\nWhat is the name of the famous bridge in Paris? Pont des Arts\\nWhat is the name of the famous opera? \"\n         self._test_quantized_model(self.llama3_8b_fp8, expected_out)\n \n     def _test_quantized_model(self, model_name: str, expected_output: str):"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 6,
        "deletions": 6
    }
}