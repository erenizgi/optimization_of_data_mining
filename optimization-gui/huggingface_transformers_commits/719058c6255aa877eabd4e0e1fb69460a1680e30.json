{
    "author": "tanuj-rai",
    "message": "Update attention_visualizer.py (#37860)",
    "sha": "719058c6255aa877eabd4e0e1fb69460a1680e30",
    "files": [
        {
            "sha": "202c0a1b5a6ca1cfe46ac5fb3a01ee6b9463b179",
            "filename": "src/transformers/utils/attention_visualizer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/719058c6255aa877eabd4e0e1fb69460a1680e30/src%2Ftransformers%2Futils%2Fattention_visualizer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/719058c6255aa877eabd4e0e1fb69460a1680e30/src%2Ftransformers%2Futils%2Fattention_visualizer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fattention_visualizer.py?ref=719058c6255aa877eabd4e0e1fb69460a1680e30",
            "patch": "@@ -151,7 +151,7 @@ def __init__(self, model_name: str):\n         config = AutoConfig.from_pretrained(model_name)\n         self.image_token = \"<img>\"\n         if hasattr(config.get_text_config(), \"sliding_window\"):\n-            config.sliding_window = 5\n+            self.sliding_window = getattr(config.get_text_config(), \"sliding_window\", None)\n         try:\n             mapped_cls = _get_model_class(config, MODEL_MAPPING)\n         except Exception:"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}