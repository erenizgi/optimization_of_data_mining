{
    "author": "Cyrilvallez",
    "message": "Revert #37031 (#37178)\n\nUpdate modeling_utils.py",
    "sha": "41f5c3216c9c5260efa2b471ede064d4f856f912",
    "files": [
        {
            "sha": "f1022b100700a5514ba3abe2908f704904a2a853",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 0,
            "deletions": 9,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/41f5c3216c9c5260efa2b471ede064d4f856f912/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/41f5c3216c9c5260efa2b471ede064d4f856f912/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=41f5c3216c9c5260efa2b471ede064d4f856f912",
            "patch": "@@ -761,9 +761,6 @@ def _load_state_dict_into_meta_model(\n     if is_meta_state_dict:\n         file_pointer = safe_open(shard_file, framework=\"pt\", device=tensor_device)\n \n-    # Used to fix the issue mentioned in #37031: when loading a model with tied weights in state_dict + `tie_word_embeddings = False`,\n-    # we need to make sure they are not loaded as tied weights!\n-    data_ptrs = set()\n     for param_name, empty_param in state_dict.items():\n         if param_name not in expected_keys:\n             continue\n@@ -833,14 +830,8 @@ def _load_state_dict_into_meta_model(\n                 if is_fsdp_enabled():\n                     param_device = \"cpu\" if is_local_dist_rank_0() else \"meta\"\n \n-                # avoid tied weights\n-                if param.data_ptr() in data_ptrs:\n-                    param = param.clone()\n-\n                 _load_parameter_into_model(model, param_name, param.to(param_device))\n \n-                # Add `data_ptr` of `model.state_dict()[param_name]` to avoid tied weights\n-                data_ptrs.add(model.state_dict()[param_name].data_ptr())\n             else:\n                 hf_quantizer.create_quantized_param(\n                     model, param, param_name, param_device, state_dict, unexpected_keys"
        }
    ],
    "stats": {
        "total": 9,
        "additions": 0,
        "deletions": 9
    }
}