{
    "author": "vasqu",
    "message": "[`Masks`] Fix mask handling in eager for vision models (#41625)\n\nadd mask handling in case of models that do use it",
    "sha": "bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
    "files": [
        {
            "sha": "63aaf542292c88c2d5859829f2554512a274cf50",
            "filename": "src/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py?ref=bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
            "patch": "@@ -96,25 +96,28 @@ def forward(self, input_values: torch.Tensor) -> torch.Tensor:\n         return embeddings\n \n \n-# Copied from transformers.models.vit.modeling_vit.eager_attention_forward\n+# Copied from transformers.models.bert.modeling_bert.eager_attention_forward\n def eager_attention_forward(\n     module: nn.Module,\n     query: torch.Tensor,\n     key: torch.Tensor,\n     value: torch.Tensor,\n     attention_mask: Optional[torch.Tensor],\n-    scaling: float,\n+    scaling: Optional[float] = None,\n     dropout: float = 0.0,\n-    **kwargs,\n+    **kwargs: Unpack[TransformersKwargs],\n ):\n+    if scaling is None:\n+        scaling = query.size(-1) ** -0.5\n+\n     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n-    attn_weights = torch.matmul(query, key.transpose(-1, -2)) * scaling\n+    attn_weights = torch.matmul(query, key.transpose(2, 3)) * scaling\n \n-    # Normalize the attention scores to probabilities.\n-    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n+    if attention_mask is not None:\n+        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n+        attn_weights = attn_weights + attention_mask\n \n-    # This is actually dropping out entire tokens to attend to, which might\n-    # seem a bit unusual, but is taken from the original Transformer paper.\n+    attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n     attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n \n     attn_output = torch.matmul(attn_weights, value)"
        },
        {
            "sha": "73f2b2bd706a04953831a07c6b4785a54f274a28",
            "filename": "src/transformers/models/deit/modeling_deit.py",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py?ref=bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
            "patch": "@@ -161,25 +161,28 @@ def forward(self, pixel_values: torch.Tensor) -> torch.Tensor:\n         return x\n \n \n-# Copied from transformers.models.vit.modeling_vit.eager_attention_forward\n+# Copied from transformers.models.bert.modeling_bert.eager_attention_forward\n def eager_attention_forward(\n     module: nn.Module,\n     query: torch.Tensor,\n     key: torch.Tensor,\n     value: torch.Tensor,\n     attention_mask: Optional[torch.Tensor],\n-    scaling: float,\n+    scaling: Optional[float] = None,\n     dropout: float = 0.0,\n-    **kwargs,\n+    **kwargs: Unpack[TransformersKwargs],\n ):\n+    if scaling is None:\n+        scaling = query.size(-1) ** -0.5\n+\n     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n-    attn_weights = torch.matmul(query, key.transpose(-1, -2)) * scaling\n+    attn_weights = torch.matmul(query, key.transpose(2, 3)) * scaling\n \n-    # Normalize the attention scores to probabilities.\n-    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n+    if attention_mask is not None:\n+        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n+        attn_weights = attn_weights + attention_mask\n \n-    # This is actually dropping out entire tokens to attend to, which might\n-    # seem a bit unusual, but is taken from the original Transformer paper.\n+    attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n     attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n \n     attn_output = torch.matmul(attn_weights, value)"
        },
        {
            "sha": "30eadb38998c9a0e32eb77811b36024dbe3c2b90",
            "filename": "src/transformers/models/dinov2/modeling_dinov2.py",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py?ref=bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
            "patch": "@@ -149,25 +149,28 @@ def forward(self, pixel_values: torch.Tensor) -> torch.Tensor:\n         return embeddings\n \n \n-# Copied from transformers.models.vit.modeling_vit.eager_attention_forward\n+# Copied from transformers.models.bert.modeling_bert.eager_attention_forward\n def eager_attention_forward(\n     module: nn.Module,\n     query: torch.Tensor,\n     key: torch.Tensor,\n     value: torch.Tensor,\n     attention_mask: Optional[torch.Tensor],\n-    scaling: float,\n+    scaling: Optional[float] = None,\n     dropout: float = 0.0,\n-    **kwargs,\n+    **kwargs: Unpack[TransformersKwargs],\n ):\n+    if scaling is None:\n+        scaling = query.size(-1) ** -0.5\n+\n     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n-    attn_weights = torch.matmul(query, key.transpose(-1, -2)) * scaling\n+    attn_weights = torch.matmul(query, key.transpose(2, 3)) * scaling\n \n-    # Normalize the attention scores to probabilities.\n-    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n+    if attention_mask is not None:\n+        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n+        attn_weights = attn_weights + attention_mask\n \n-    # This is actually dropping out entire tokens to attend to, which might\n-    # seem a bit unusual, but is taken from the original Transformer paper.\n+    attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n     attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n \n     attn_output = torch.matmul(attn_weights, value)"
        },
        {
            "sha": "2ad5c97c6b20dc09a6e3aae18b21a59c87ff9c22",
            "filename": "src/transformers/models/dinov2_with_registers/modeling_dinov2_with_registers.py",
            "status": "modified",
            "additions": 10,
            "deletions": 7,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py?ref=bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
            "patch": "@@ -176,18 +176,21 @@ def eager_attention_forward(\n     key: torch.Tensor,\n     value: torch.Tensor,\n     attention_mask: Optional[torch.Tensor],\n-    scaling: float,\n+    scaling: Optional[float] = None,\n     dropout: float = 0.0,\n-    **kwargs,\n+    **kwargs: Unpack[TransformersKwargs],\n ):\n+    if scaling is None:\n+        scaling = query.size(-1) ** -0.5\n+\n     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n-    attn_weights = torch.matmul(query, key.transpose(-1, -2)) * scaling\n+    attn_weights = torch.matmul(query, key.transpose(2, 3)) * scaling\n \n-    # Normalize the attention scores to probabilities.\n-    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n+    if attention_mask is not None:\n+        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n+        attn_weights = attn_weights + attention_mask\n \n-    # This is actually dropping out entire tokens to attend to, which might\n-    # seem a bit unusual, but is taken from the original Transformer paper.\n+    attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n     attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n \n     attn_output = torch.matmul(attn_weights, value)"
        },
        {
            "sha": "03d7685864a79dc461ad92f45a8d5b2ee9e9f7e6",
            "filename": "src/transformers/models/dinov3_vit/modeling_dinov3_vit.py",
            "status": "modified",
            "additions": 10,
            "deletions": 7,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodeling_dinov3_vit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodeling_dinov3_vit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov3_vit%2Fmodeling_dinov3_vit.py?ref=bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
            "patch": "@@ -194,18 +194,21 @@ def eager_attention_forward(\n     key: torch.Tensor,\n     value: torch.Tensor,\n     attention_mask: Optional[torch.Tensor],\n-    scaling: float,\n+    scaling: Optional[float] = None,\n     dropout: float = 0.0,\n-    **kwargs,\n+    **kwargs: Unpack[TransformersKwargs],\n ):\n+    if scaling is None:\n+        scaling = query.size(-1) ** -0.5\n+\n     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n-    attn_weights = torch.matmul(query, key.transpose(-1, -2)) * scaling\n+    attn_weights = torch.matmul(query, key.transpose(2, 3)) * scaling\n \n-    # Normalize the attention scores to probabilities.\n-    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n+    if attention_mask is not None:\n+        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n+        attn_weights = attn_weights + attention_mask\n \n-    # This is actually dropping out entire tokens to attend to, which might\n-    # seem a bit unusual, but is taken from the original Transformer paper.\n+    attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n     attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n \n     attn_output = torch.matmul(attn_weights, value)"
        },
        {
            "sha": "5ff420ddf0e580c22809018d27ac300f09a522ec",
            "filename": "src/transformers/models/dpt/modeling_dpt.py",
            "status": "modified",
            "additions": 13,
            "deletions": 9,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py?ref=bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
            "patch": "@@ -32,7 +32,8 @@\n from ...modeling_layers import GradientCheckpointingLayer\n from ...modeling_outputs import BaseModelOutput, DepthEstimatorOutput, SemanticSegmenterOutput\n from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n-from ...utils import ModelOutput, auto_docstring, logging, torch_int\n+from ...processing_utils import Unpack\n+from ...utils import ModelOutput, TransformersKwargs, auto_docstring, logging, torch_int\n from ...utils.backbone_utils import load_backbone\n from ...utils.generic import can_return_tuple, check_model_inputs\n from .configuration_dpt import DPTConfig\n@@ -267,25 +268,28 @@ def forward(self, pixel_values: torch.Tensor) -> torch.Tensor:\n         return embeddings\n \n \n-# Copied from transformers.models.vit.modeling_vit.eager_attention_forward\n+# Copied from transformers.models.bert.modeling_bert.eager_attention_forward\n def eager_attention_forward(\n     module: nn.Module,\n     query: torch.Tensor,\n     key: torch.Tensor,\n     value: torch.Tensor,\n     attention_mask: Optional[torch.Tensor],\n-    scaling: float,\n+    scaling: Optional[float] = None,\n     dropout: float = 0.0,\n-    **kwargs,\n+    **kwargs: Unpack[TransformersKwargs],\n ):\n+    if scaling is None:\n+        scaling = query.size(-1) ** -0.5\n+\n     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n-    attn_weights = torch.matmul(query, key.transpose(-1, -2)) * scaling\n+    attn_weights = torch.matmul(query, key.transpose(2, 3)) * scaling\n \n-    # Normalize the attention scores to probabilities.\n-    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n+    if attention_mask is not None:\n+        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n+        attn_weights = attn_weights + attention_mask\n \n-    # This is actually dropping out entire tokens to attend to, which might\n-    # seem a bit unusual, but is taken from the original Transformer paper.\n+    attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n     attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n \n     attn_output = torch.matmul(attn_weights, value)"
        },
        {
            "sha": "3418d8ee64d2b2833ed4469f07a1a2881af527a2",
            "filename": "src/transformers/models/ijepa/modeling_ijepa.py",
            "status": "modified",
            "additions": 10,
            "deletions": 7,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py?ref=bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
            "patch": "@@ -147,18 +147,21 @@ def eager_attention_forward(\n     key: torch.Tensor,\n     value: torch.Tensor,\n     attention_mask: Optional[torch.Tensor],\n-    scaling: float,\n+    scaling: Optional[float] = None,\n     dropout: float = 0.0,\n-    **kwargs,\n+    **kwargs: Unpack[TransformersKwargs],\n ):\n+    if scaling is None:\n+        scaling = query.size(-1) ** -0.5\n+\n     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n-    attn_weights = torch.matmul(query, key.transpose(-1, -2)) * scaling\n+    attn_weights = torch.matmul(query, key.transpose(2, 3)) * scaling\n \n-    # Normalize the attention scores to probabilities.\n-    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n+    if attention_mask is not None:\n+        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n+        attn_weights = attn_weights + attention_mask\n \n-    # This is actually dropping out entire tokens to attend to, which might\n-    # seem a bit unusual, but is taken from the original Transformer paper.\n+    attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n     attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n \n     attn_output = torch.matmul(attn_weights, value)"
        },
        {
            "sha": "24ffa9987c6faeed2a29bc20166a80b5cbd9b6f2",
            "filename": "src/transformers/models/videomae/modeling_videomae.py",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fvideomae%2Fmodeling_videomae.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fvideomae%2Fmodeling_videomae.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvideomae%2Fmodeling_videomae.py?ref=bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
            "patch": "@@ -178,25 +178,28 @@ def forward(self, pixel_values):\n         return embeddings\n \n \n-# Copied from transformers.models.vit.modeling_vit.eager_attention_forward\n+# Copied from transformers.models.bert.modeling_bert.eager_attention_forward\n def eager_attention_forward(\n     module: nn.Module,\n     query: torch.Tensor,\n     key: torch.Tensor,\n     value: torch.Tensor,\n     attention_mask: Optional[torch.Tensor],\n-    scaling: float,\n+    scaling: Optional[float] = None,\n     dropout: float = 0.0,\n-    **kwargs,\n+    **kwargs: Unpack[TransformersKwargs],\n ):\n+    if scaling is None:\n+        scaling = query.size(-1) ** -0.5\n+\n     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n-    attn_weights = torch.matmul(query, key.transpose(-1, -2)) * scaling\n+    attn_weights = torch.matmul(query, key.transpose(2, 3)) * scaling\n \n-    # Normalize the attention scores to probabilities.\n-    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n+    if attention_mask is not None:\n+        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n+        attn_weights = attn_weights + attention_mask\n \n-    # This is actually dropping out entire tokens to attend to, which might\n-    # seem a bit unusual, but is taken from the original Transformer paper.\n+    attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n     attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n \n     attn_output = torch.matmul(attn_weights, value)"
        },
        {
            "sha": "3eed5c888f34460296600a4a2f22f784a4b47794",
            "filename": "src/transformers/models/vit/modeling_vit.py",
            "status": "modified",
            "additions": 11,
            "deletions": 7,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fvit%2Fmodeling_vit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fvit%2Fmodeling_vit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvit%2Fmodeling_vit.py?ref=bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
            "patch": "@@ -167,24 +167,28 @@ def forward(self, pixel_values: torch.Tensor, interpolate_pos_encoding: bool = F\n         return embeddings\n \n \n+# Copied from transformers.models.bert.modeling_bert.eager_attention_forward\n def eager_attention_forward(\n     module: nn.Module,\n     query: torch.Tensor,\n     key: torch.Tensor,\n     value: torch.Tensor,\n     attention_mask: Optional[torch.Tensor],\n-    scaling: float,\n+    scaling: Optional[float] = None,\n     dropout: float = 0.0,\n-    **kwargs,\n+    **kwargs: Unpack[TransformersKwargs],\n ):\n+    if scaling is None:\n+        scaling = query.size(-1) ** -0.5\n+\n     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n-    attn_weights = torch.matmul(query, key.transpose(-1, -2)) * scaling\n+    attn_weights = torch.matmul(query, key.transpose(2, 3)) * scaling\n \n-    # Normalize the attention scores to probabilities.\n-    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n+    if attention_mask is not None:\n+        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n+        attn_weights = attn_weights + attention_mask\n \n-    # This is actually dropping out entire tokens to attend to, which might\n-    # seem a bit unusual, but is taken from the original Transformer paper.\n+    attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n     attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n \n     attn_output = torch.matmul(attn_weights, value)"
        },
        {
            "sha": "435e3cb92c05e7f532a135b9a9a96335cf78e016",
            "filename": "src/transformers/models/vit_mae/modeling_vit_mae.py",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fvit_mae%2Fmodeling_vit_mae.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fvit_mae%2Fmodeling_vit_mae.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvit_mae%2Fmodeling_vit_mae.py?ref=bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
            "patch": "@@ -326,25 +326,28 @@ def forward(self, pixel_values, interpolate_pos_encoding: bool = False):\n         return x\n \n \n-# Copied from transformers.models.vit.modeling_vit.eager_attention_forward\n+# Copied from transformers.models.bert.modeling_bert.eager_attention_forward\n def eager_attention_forward(\n     module: nn.Module,\n     query: torch.Tensor,\n     key: torch.Tensor,\n     value: torch.Tensor,\n     attention_mask: Optional[torch.Tensor],\n-    scaling: float,\n+    scaling: Optional[float] = None,\n     dropout: float = 0.0,\n-    **kwargs,\n+    **kwargs: Unpack[TransformersKwargs],\n ):\n+    if scaling is None:\n+        scaling = query.size(-1) ** -0.5\n+\n     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n-    attn_weights = torch.matmul(query, key.transpose(-1, -2)) * scaling\n+    attn_weights = torch.matmul(query, key.transpose(2, 3)) * scaling\n \n-    # Normalize the attention scores to probabilities.\n-    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n+    if attention_mask is not None:\n+        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n+        attn_weights = attn_weights + attention_mask\n \n-    # This is actually dropping out entire tokens to attend to, which might\n-    # seem a bit unusual, but is taken from the original Transformer paper.\n+    attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n     attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n \n     attn_output = torch.matmul(attn_weights, value)"
        },
        {
            "sha": "42cfa1d23283eb63083cc1f10b56d6f44cc932ef",
            "filename": "src/transformers/models/vit_msn/modeling_vit_msn.py",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fvit_msn%2Fmodeling_vit_msn.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fvit_msn%2Fmodeling_vit_msn.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvit_msn%2Fmodeling_vit_msn.py?ref=bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
            "patch": "@@ -163,25 +163,28 @@ def forward(self, pixel_values: torch.Tensor, interpolate_pos_encoding: bool = F\n         return embeddings\n \n \n-# Copied from transformers.models.vit.modeling_vit.eager_attention_forward\n+# Copied from transformers.models.bert.modeling_bert.eager_attention_forward\n def eager_attention_forward(\n     module: nn.Module,\n     query: torch.Tensor,\n     key: torch.Tensor,\n     value: torch.Tensor,\n     attention_mask: Optional[torch.Tensor],\n-    scaling: float,\n+    scaling: Optional[float] = None,\n     dropout: float = 0.0,\n-    **kwargs,\n+    **kwargs: Unpack[TransformersKwargs],\n ):\n+    if scaling is None:\n+        scaling = query.size(-1) ** -0.5\n+\n     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n-    attn_weights = torch.matmul(query, key.transpose(-1, -2)) * scaling\n+    attn_weights = torch.matmul(query, key.transpose(2, 3)) * scaling\n \n-    # Normalize the attention scores to probabilities.\n-    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n+    if attention_mask is not None:\n+        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n+        attn_weights = attn_weights + attention_mask\n \n-    # This is actually dropping out entire tokens to attend to, which might\n-    # seem a bit unusual, but is taken from the original Transformer paper.\n+    attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n     attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n \n     attn_output = torch.matmul(attn_weights, value)"
        },
        {
            "sha": "6146fec5833c403c19eaee5249d7bf18966369c3",
            "filename": "src/transformers/models/vitpose_backbone/modeling_vitpose_backbone.py",
            "status": "modified",
            "additions": 13,
            "deletions": 9,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fvitpose_backbone%2Fmodeling_vitpose_backbone.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fvitpose_backbone%2Fmodeling_vitpose_backbone.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvitpose_backbone%2Fmodeling_vitpose_backbone.py?ref=bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
            "patch": "@@ -30,7 +30,8 @@\n from ...modeling_layers import GradientCheckpointingLayer\n from ...modeling_outputs import BackboneOutput, BaseModelOutput\n from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n-from ...utils import auto_docstring, logging\n+from ...processing_utils import Unpack\n+from ...utils import TransformersKwargs, auto_docstring, logging\n from ...utils.backbone_utils import BackboneMixin\n from ...utils.generic import check_model_inputs\n from .configuration_vitpose_backbone import VitPoseBackboneConfig\n@@ -95,25 +96,28 @@ def forward(self, pixel_values: torch.Tensor) -> torch.Tensor:\n         return embeddings\n \n \n-# Copied from transformers.models.vit.modeling_vit.eager_attention_forward\n+# Copied from transformers.models.bert.modeling_bert.eager_attention_forward\n def eager_attention_forward(\n     module: nn.Module,\n     query: torch.Tensor,\n     key: torch.Tensor,\n     value: torch.Tensor,\n     attention_mask: Optional[torch.Tensor],\n-    scaling: float,\n+    scaling: Optional[float] = None,\n     dropout: float = 0.0,\n-    **kwargs,\n+    **kwargs: Unpack[TransformersKwargs],\n ):\n+    if scaling is None:\n+        scaling = query.size(-1) ** -0.5\n+\n     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n-    attn_weights = torch.matmul(query, key.transpose(-1, -2)) * scaling\n+    attn_weights = torch.matmul(query, key.transpose(2, 3)) * scaling\n \n-    # Normalize the attention scores to probabilities.\n-    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n+    if attention_mask is not None:\n+        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n+        attn_weights = attn_weights + attention_mask\n \n-    # This is actually dropping out entire tokens to attend to, which might\n-    # seem a bit unusual, but is taken from the original Transformer paper.\n+    attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n     attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n \n     attn_output = torch.matmul(attn_weights, value)"
        },
        {
            "sha": "a3aee1504387d8bcf75291c6ff6f7ceb6e210753",
            "filename": "src/transformers/models/vivit/modeling_vivit.py",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fvivit%2Fmodeling_vivit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fvivit%2Fmodeling_vivit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvivit%2Fmodeling_vivit.py?ref=bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
            "patch": "@@ -156,25 +156,28 @@ def forward(self, pixel_values: torch.Tensor, interpolate_pos_encoding: bool = F\n         return embeddings\n \n \n-# Copied from transformers.models.vit.modeling_vit.eager_attention_forward\n+# Copied from transformers.models.bert.modeling_bert.eager_attention_forward\n def eager_attention_forward(\n     module: nn.Module,\n     query: torch.Tensor,\n     key: torch.Tensor,\n     value: torch.Tensor,\n     attention_mask: Optional[torch.Tensor],\n-    scaling: float,\n+    scaling: Optional[float] = None,\n     dropout: float = 0.0,\n-    **kwargs,\n+    **kwargs: Unpack[TransformersKwargs],\n ):\n+    if scaling is None:\n+        scaling = query.size(-1) ** -0.5\n+\n     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n-    attn_weights = torch.matmul(query, key.transpose(-1, -2)) * scaling\n+    attn_weights = torch.matmul(query, key.transpose(2, 3)) * scaling\n \n-    # Normalize the attention scores to probabilities.\n-    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n+    if attention_mask is not None:\n+        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n+        attn_weights = attn_weights + attention_mask\n \n-    # This is actually dropping out entire tokens to attend to, which might\n-    # seem a bit unusual, but is taken from the original Transformer paper.\n+    attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n     attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n \n     attn_output = torch.matmul(attn_weights, value)"
        },
        {
            "sha": "d4e86035badbe008357cd9f4524072c839d8eeb4",
            "filename": "src/transformers/models/yolos/modeling_yolos.py",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fyolos%2Fmodeling_yolos.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf815e9b5ea076f758cc58f73f2be2d36237f9ec/src%2Ftransformers%2Fmodels%2Fyolos%2Fmodeling_yolos.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fyolos%2Fmodeling_yolos.py?ref=bf815e9b5ea076f758cc58f73f2be2d36237f9ec",
            "patch": "@@ -211,25 +211,28 @@ def forward(self, pixel_values: torch.Tensor) -> torch.Tensor:\n         return embeddings\n \n \n-# Copied from transformers.models.vit.modeling_vit.eager_attention_forward\n+# Copied from transformers.models.bert.modeling_bert.eager_attention_forward\n def eager_attention_forward(\n     module: nn.Module,\n     query: torch.Tensor,\n     key: torch.Tensor,\n     value: torch.Tensor,\n     attention_mask: Optional[torch.Tensor],\n-    scaling: float,\n+    scaling: Optional[float] = None,\n     dropout: float = 0.0,\n-    **kwargs,\n+    **kwargs: Unpack[TransformersKwargs],\n ):\n+    if scaling is None:\n+        scaling = query.size(-1) ** -0.5\n+\n     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n-    attn_weights = torch.matmul(query, key.transpose(-1, -2)) * scaling\n+    attn_weights = torch.matmul(query, key.transpose(2, 3)) * scaling\n \n-    # Normalize the attention scores to probabilities.\n-    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n+    if attention_mask is not None:\n+        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n+        attn_weights = attn_weights + attention_mask\n \n-    # This is actually dropping out entire tokens to attend to, which might\n-    # seem a bit unusual, but is taken from the original Transformer paper.\n+    attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n     attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n \n     attn_output = torch.matmul(attn_weights, value)"
        }
    ],
    "stats": {
        "total": 265,
        "additions": 155,
        "deletions": 110
    }
}