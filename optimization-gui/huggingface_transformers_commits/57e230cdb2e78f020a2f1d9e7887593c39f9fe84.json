{
    "author": "cyyever",
    "message": "Fix more pylint warnings (#40204)\n\nFix pylint warnings\n\nSigned-off-by: cyy <cyyever@outlook.com>",
    "sha": "57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
    "files": [
        {
            "sha": "f0aeae8985b789807b680f5b907010057e757e07",
            "filename": "src/transformers/image_transforms.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fimage_transforms.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fimage_transforms.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fimage_transforms.py?ref=57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
            "patch": "@@ -748,7 +748,7 @@ def _expand_for_data_format(values):\n         elif isinstance(values, tuple) and len(values) == 2 and isinstance(values[0], int):\n             values = (values, values)\n         elif isinstance(values, tuple) and len(values) == 2 and isinstance(values[0], tuple):\n-            values = values\n+            pass\n         else:\n             raise ValueError(f\"Unsupported format: {values}\")\n "
        },
        {
            "sha": "2421b00a7669343d0d1b5be9380afc9f6782772d",
            "filename": "src/transformers/integrations/mxfp4.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fintegrations%2Fmxfp4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fintegrations%2Fmxfp4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Fmxfp4.py?ref=57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
            "patch": "@@ -228,7 +228,7 @@ def routing_torch_dist(\n \n     with torch.cuda.device(logits.device):\n         world_size = torch.distributed.get_world_size()\n-        rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n+        rank = int(os.environ.get(\"LOCAL_RANK\", \"0\"))\n         replace_value = -1\n \n         n_tokens = logits.shape[0]"
        },
        {
            "sha": "fdcf43c46bd47a2d8e3afc1df120b1030c3f8c77",
            "filename": "src/transformers/modeling_flash_attention_utils.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fmodeling_flash_attention_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fmodeling_flash_attention_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_flash_attention_utils.py?ref=57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
            "patch": "@@ -112,7 +112,6 @@ def _lazy_define_process_function(flash_function):\n     NOTE: While all supported kwargs are marked as `True`, everything else is marked as `False`.\n           This might be confusing for kwargs that we use in any case, e.g. `is_causal`.\n     \"\"\"\n-    global _process_flash_kwargs_fn, _hf_api_to_flash_mapping\n \n     flash_parameters = inspect.signature(flash_function).parameters\n     process_parameters = inspect.signature(_process_flash_attention_kwargs).parameters"
        },
        {
            "sha": "99cf0c77339ab5d9e0c041181c3a83f9dfd5bd40",
            "filename": "src/transformers/modeling_rope_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fmodeling_rope_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fmodeling_rope_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_rope_utils.py?ref=57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
            "patch": "@@ -257,7 +257,7 @@ def find_correction_range(low_rot, high_rot, dim, base, max_position_embeddings,\n         low = find_correction_dim(low_rot, dim, base, max_position_embeddings)\n         high = find_correction_dim(high_rot, dim, base, max_position_embeddings)\n         if truncate:\n-            low = low = math.floor(low)\n+            low = math.floor(low)\n             high = math.ceil(high)\n         return max(low, 0), min(high, dim - 1)\n "
        },
        {
            "sha": "8e3e86e8681a02364dc0bec1bbbe122a90d97bc7",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
            "patch": "@@ -409,8 +409,7 @@ def get_state_dict_dtype(state_dict):\n             return t.dtype\n \n     # if no floating dtype was found return whatever the first dtype is\n-    else:\n-        return next(state_dict.values()).dtype\n+    return next(state_dict.values()).dtype\n \n \n def load_sharded_checkpoint(model, folder, strict=True, prefer_safe=True):"
        },
        {
            "sha": "d48585e63f4730793cbdd761aa38254f82957dd1",
            "filename": "src/transformers/pipelines/table_question_answering.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fpipelines%2Ftable_question_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fpipelines%2Ftable_question_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftable_question_answering.py?ref=57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
            "patch": "@@ -267,7 +267,6 @@ def sequential_inference(self, **inputs):\n                 )\n \n                 coords_to_probs = collections.defaultdict(list)\n-                token_type_ids_example = token_type_ids_example\n                 for i, p in enumerate(tf.squeeze(probabilities).numpy().tolist()):\n                     segment_id = token_type_ids_example[:, 0].tolist()[i]\n                     col = token_type_ids_example[:, 1].tolist()[i] - 1"
        },
        {
            "sha": "fb06df9b21ba1359397a3e73686f82a492ca9129",
            "filename": "src/transformers/processing_utils.py",
            "status": "modified",
            "additions": 6,
            "deletions": 7,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fprocessing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fprocessing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fprocessing_utils.py?ref=57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
            "patch": "@@ -1391,12 +1391,11 @@ def get_possibly_dynamic_module(module_name):\n                             return custom_subclass\n                 elif custom_class is not None and custom_class.__name__ == module_name:\n                     return custom_class\n-        else:\n-            raise ValueError(\n-                f\"Could not find module {module_name} in `transformers`. If this is a custom class, \"\n-                f\"it should be registered using the relevant `AutoClass.register()` function so that \"\n-                f\"other functions can find it!\"\n-            )\n+        raise ValueError(\n+            f\"Could not find module {module_name} in `transformers`. If this is a custom class, \"\n+            f\"it should be registered using the relevant `AutoClass.register()` function so that \"\n+            f\"other functions can find it!\"\n+        )\n \n     @property\n     def model_input_names(self):\n@@ -1469,7 +1468,7 @@ def apply_chat_template(\n                 chat_template = self.chat_template[chat_template]\n             else:\n                 # It's a template string, render it directly\n-                chat_template = chat_template\n+                pass\n \n         is_tokenizers_fast = hasattr(self, \"tokenizer\") and self.tokenizer.__class__.__name__.endswith(\"Fast\")\n "
        },
        {
            "sha": "5f1c40ba8e3dee08a007a5fc2b2d0f33c44c523a",
            "filename": "src/transformers/utils/auto_docstring.py",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Futils%2Fauto_docstring.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Futils%2Fauto_docstring.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fauto_docstring.py?ref=57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
            "patch": "@@ -1120,9 +1120,8 @@ def get_model_name(obj):\n         if file_name.startswith(start) and file_name.endswith(end):\n             model_name_lowercase = file_name[len(start) : -len(end)]\n             return model_name_lowercase\n-    else:\n-        print(f\"ðŸš¨ Something went wrong trying to find the model name in the path: {path}\")\n-        return \"model\"\n+    print(f\"ðŸš¨ Something went wrong trying to find the model name in the path: {path}\")\n+    return \"model\"\n \n \n def get_placeholders_dict(placeholders: list, model_name: str) -> dict:"
        },
        {
            "sha": "110d0ae0fe0ca2e8cd0ce853824d6d059e9fa31f",
            "filename": "src/transformers/utils/fx.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Futils%2Ffx.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Futils%2Ffx.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Ffx.py?ref=57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
            "patch": "@@ -815,7 +815,6 @@ def _proxies_to_metas(v):\n \n def create_cache_proxy_factory_fn(orig_cache_cls: type[Cache]) -> Callable[[Node], HFCacheProxy]:\n     def cache_proxy_factory_fn(n: Node) -> HFCacheProxy:\n-        global _CURRENT_TRACER\n         if not isinstance(_CURRENT_TRACER, HFTracer):\n             raise RuntimeError(\"Cannot create HFCacheProxy because there is no HFTracer currently tracing.\")\n         cache_proxy = HFCacheProxy(n, _CURRENT_TRACER)"
        },
        {
            "sha": "74197a3e7ac6e0465a4e8f8baa41b04e1d66103f",
            "filename": "src/transformers/utils/generic.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Futils%2Fgeneric.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Futils%2Fgeneric.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fgeneric.py?ref=57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
            "patch": "@@ -746,8 +746,7 @@ def infer_framework(model_class):\n             return \"pt\"\n         elif module.startswith(\"flax\") or module.startswith(\"jax\") or name == \"FlaxPreTrainedModel\":\n             return \"flax\"\n-    else:\n-        raise TypeError(f\"Could not infer framework from class {model_class}.\")\n+    raise TypeError(f\"Could not infer framework from class {model_class}.\")\n \n \n def torch_int(x):"
        },
        {
            "sha": "ea5a93f97ca7753a45e3055978c4a164f95c6914",
            "filename": "src/transformers/video_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fvideo_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/src%2Ftransformers%2Fvideo_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fvideo_utils.py?ref=57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
            "patch": "@@ -717,7 +717,7 @@ def _expand_for_data_format(values):\n         elif isinstance(values, tuple) and len(values) == 2 and isinstance(values[0], int):\n             values = (values, values)\n         elif isinstance(values, tuple) and len(values) == 2 and isinstance(values[0], tuple):\n-            values = values\n+            pass\n         else:\n             raise ValueError(f\"Unsupported format: {values}\")\n "
        },
        {
            "sha": "a575503c7c9639e7b5de2f88f6fb6e0f86b45561",
            "filename": "tests/models/aimv2/test_modeling_aimv2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/tests%2Fmodels%2Faimv2%2Ftest_modeling_aimv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/tests%2Fmodels%2Faimv2%2Ftest_modeling_aimv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faimv2%2Ftest_modeling_aimv2.py?ref=57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
            "patch": "@@ -667,9 +667,7 @@ def test_inference_for_native_resolution(self):\n         model = Aimv2VisionModel.from_pretrained(model_name, device_map=\"auto\")\n         processor = AutoImageProcessor.from_pretrained(model_name)\n \n-        image = image = Image.open(\n-            requests.get(\"http://images.cocodataset.org/val2017/000000039769.jpg\", stream=True).raw\n-        )\n+        image = Image.open(requests.get(\"http://images.cocodataset.org/val2017/000000039769.jpg\", stream=True).raw)\n         inputs = processor(image, return_tensors=\"pt\").to(model.device)\n \n         with torch.no_grad():"
        },
        {
            "sha": "4f1c86ad01e44e79c04318d28e954b2e61193b5c",
            "filename": "tests/models/blip_2/test_modeling_blip_2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/tests%2Fmodels%2Fblip_2%2Ftest_modeling_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/tests%2Fmodels%2Fblip_2%2Ftest_modeling_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fblip_2%2Ftest_modeling_blip_2.py?ref=57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
            "patch": "@@ -1828,7 +1828,7 @@ def test_inference_opt_multi_accelerator(self):\n     @require_torch_multi_accelerator\n     def test_inference_t5_multi_accelerator(self):\n         processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n-        device_map = device_map = {\n+        device_map = {\n             \"query_tokens\": 0,\n             \"vision_model\": 0,\n             \"language_model\": 1,"
        },
        {
            "sha": "a87dd314d452842cb6e02c78f838f755140e57da",
            "filename": "tests/models/emu3/test_processing_emu3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/tests%2Fmodels%2Femu3%2Ftest_processing_emu3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/57e230cdb2e78f020a2f1d9e7887593c39f9fe84/tests%2Fmodels%2Femu3%2Ftest_processing_emu3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Femu3%2Ftest_processing_emu3.py?ref=57e230cdb2e78f020a2f1d9e7887593c39f9fe84",
            "patch": "@@ -35,7 +35,7 @@ class Emu3ProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     def setUpClass(cls):\n         cls.tmpdirname = tempfile.mkdtemp()\n         image_processor = Emu3ImageProcessor(min_pixels=28 * 28, max_pixels=56 * 56)\n-        extra_special_tokens = extra_special_tokens = {\n+        extra_special_tokens = {\n             \"image_token\": \"<image>\",\n             \"boi_token\": \"<|image start|>\",\n             \"eoi_token\": \"<|image end|>\","
        }
    ],
    "stats": {
        "total": 43,
        "additions": 17,
        "deletions": 26
    }
}