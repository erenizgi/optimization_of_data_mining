{
    "author": "Rocketknight1",
    "message": "Totally rewrite how pipelines load preprocessors (#38947)\n\n* Totally rewrite how pipelines load preprocessors\n\n* Delete more mappings\n\n* Fix conditionals, thanks Cyril!",
    "sha": "3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
    "files": [
        {
            "sha": "bf7abe324ed894dc5cf2ace40493ec36bcf8bb24",
            "filename": "src/transformers/pipelines/__init__.py",
            "status": "modified",
            "additions": 153,
            "deletions": 211,
            "changes": 364,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2F__init__.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -441,28 +441,6 @@\n     },\n }\n \n-NO_FEATURE_EXTRACTOR_TASKS = set()\n-NO_IMAGE_PROCESSOR_TASKS = set()\n-NO_TOKENIZER_TASKS = set()\n-\n-# Those model configs are special, they are generic over their task, meaning\n-# any tokenizer/feature_extractor might be use for a given model so we cannot\n-# use the statically defined TOKENIZER_MAPPING and FEATURE_EXTRACTOR_MAPPING to\n-# see if the model defines such objects or not.\n-MULTI_MODEL_AUDIO_CONFIGS = {\"SpeechEncoderDecoderConfig\"}\n-MULTI_MODEL_VISION_CONFIGS = {\"VisionEncoderDecoderConfig\", \"VisionTextDualEncoderConfig\"}\n-for task, values in SUPPORTED_TASKS.items():\n-    if values[\"type\"] == \"text\":\n-        NO_FEATURE_EXTRACTOR_TASKS.add(task)\n-        NO_IMAGE_PROCESSOR_TASKS.add(task)\n-    elif values[\"type\"] in {\"image\", \"video\"}:\n-        NO_TOKENIZER_TASKS.add(task)\n-    elif values[\"type\"] in {\"audio\"}:\n-        NO_TOKENIZER_TASKS.add(task)\n-        NO_IMAGE_PROCESSOR_TASKS.add(task)\n-    elif values[\"type\"] != \"multimodal\":\n-        raise ValueError(f\"SUPPORTED_TASK {task} contains invalid type {values['type']}\")\n-\n PIPELINE_REGISTRY = PipelineRegistry(supported_tasks=SUPPORTED_TASKS, task_aliases=TASK_ALIASES)\n \n \n@@ -1037,205 +1015,169 @@ def pipeline(\n             **model_kwargs,\n         )\n \n-    model_config = model.config\n     hub_kwargs[\"_commit_hash\"] = model.config._commit_hash\n \n-    load_tokenizer = type(model_config) in TOKENIZER_MAPPING or model_config.tokenizer_class is not None\n-    load_feature_extractor = type(model_config) in FEATURE_EXTRACTOR_MAPPING or feature_extractor is not None\n-    load_image_processor = type(model_config) in IMAGE_PROCESSOR_MAPPING or image_processor is not None\n-    load_processor = type(model_config) in PROCESSOR_MAPPING or processor is not None\n-\n-    # Check that pipeline class required loading\n-    load_tokenizer = load_tokenizer and pipeline_class._load_tokenizer\n-    load_feature_extractor = load_feature_extractor and pipeline_class._load_feature_extractor\n-    load_image_processor = load_image_processor and pipeline_class._load_image_processor\n-    load_processor = load_processor and pipeline_class._load_processor\n-\n-    # If `model` (instance of `PretrainedModel` instead of `str`) is passed (and/or same for config), while\n-    # `image_processor` or `feature_extractor` is `None`, the loading will fail. This happens particularly for some\n-    # vision tasks when calling `pipeline()` with `model` and only one of the `image_processor` and `feature_extractor`.\n-    # TODO: we need to make `NO_IMAGE_PROCESSOR_TASKS` and `NO_FEATURE_EXTRACTOR_TASKS` more robust to avoid such issue.\n-    # This block is only temporarily to make CI green.\n-    if load_image_processor and load_feature_extractor:\n-        load_feature_extractor = False\n-\n-    if (\n-        tokenizer is None\n-        and not load_tokenizer\n-        and normalized_task not in NO_TOKENIZER_TASKS\n-        # Using class name to avoid importing the real class.\n-        and (\n-            model_config.__class__.__name__ in MULTI_MODEL_AUDIO_CONFIGS\n-            or model_config.__class__.__name__ in MULTI_MODEL_VISION_CONFIGS\n-        )\n-    ):\n-        # This is a special category of models, that are fusions of multiple models\n-        # so the model_config might not define a tokenizer, but it seems to be\n-        # necessary for the task, so we're force-trying to load it.\n-        load_tokenizer = True\n-    if (\n-        image_processor is None\n-        and not load_image_processor\n-        and normalized_task not in NO_IMAGE_PROCESSOR_TASKS\n-        # Using class name to avoid importing the real class.\n-        and model_config.__class__.__name__ in MULTI_MODEL_VISION_CONFIGS\n-    ):\n-        # This is a special category of models, that are fusions of multiple models\n-        # so the model_config might not define a tokenizer, but it seems to be\n-        # necessary for the task, so we're force-trying to load it.\n-        load_image_processor = True\n-    if (\n-        feature_extractor is None\n-        and not load_feature_extractor\n-        and normalized_task not in NO_FEATURE_EXTRACTOR_TASKS\n-        # Using class name to avoid importing the real class.\n-        and model_config.__class__.__name__ in MULTI_MODEL_AUDIO_CONFIGS\n-    ):\n-        # This is a special category of models, that are fusions of multiple models\n-        # so the model_config might not define a tokenizer, but it seems to be\n-        # necessary for the task, so we're force-trying to load it.\n-        load_feature_extractor = True\n-\n-    if task in NO_TOKENIZER_TASKS:\n-        # These will never require a tokenizer.\n-        # the model on the other hand might have a tokenizer, but\n-        # the files could be missing from the hub, instead of failing\n-        # on such repos, we just force to not load it.\n-        load_tokenizer = False\n-\n-    if task in NO_FEATURE_EXTRACTOR_TASKS:\n-        load_feature_extractor = False\n-    if task in NO_IMAGE_PROCESSOR_TASKS:\n-        load_image_processor = False\n-\n-    if load_tokenizer:\n-        # Try to infer tokenizer from model or config name (if provided as str)\n-        if tokenizer is None:\n-            if isinstance(model_name, str):\n-                tokenizer = model_name\n-            elif isinstance(config, str):\n-                tokenizer = config\n-            else:\n-                # Impossible to guess what is the right tokenizer here\n-                raise Exception(\n-                    \"Impossible to guess which tokenizer to use. \"\n-                    \"Please provide a PreTrainedTokenizer class or a path/identifier to a pretrained tokenizer.\"\n+    # Check which preprocessing classes the pipeline uses\n+    # None values indicate optional classes that the pipeline can run without, we don't raise errors if loading fails\n+    load_tokenizer = pipeline_class._load_tokenizer\n+    load_feature_extractor = pipeline_class._load_feature_extractor\n+    load_image_processor = pipeline_class._load_image_processor\n+    load_processor = pipeline_class._load_processor\n+\n+    if load_tokenizer or load_tokenizer is None:\n+        try:\n+            # Try to infer tokenizer from model or config name (if provided as str)\n+            if tokenizer is None:\n+                if isinstance(model_name, str):\n+                    tokenizer = model_name\n+                elif isinstance(config, str):\n+                    tokenizer = config\n+                else:\n+                    # Impossible to guess what is the right tokenizer here\n+                    raise Exception(\n+                        \"Impossible to guess which tokenizer to use. \"\n+                        \"Please provide a PreTrainedTokenizer class or a path/identifier to a pretrained tokenizer.\"\n+                    )\n+\n+            # Instantiate tokenizer if needed\n+            if isinstance(tokenizer, (str, tuple)):\n+                if isinstance(tokenizer, tuple):\n+                    # For tuple we have (tokenizer name, {kwargs})\n+                    use_fast = tokenizer[1].pop(\"use_fast\", use_fast)\n+                    tokenizer_identifier = tokenizer[0]\n+                    tokenizer_kwargs = tokenizer[1]\n+                else:\n+                    tokenizer_identifier = tokenizer\n+                    tokenizer_kwargs = model_kwargs.copy()\n+                    tokenizer_kwargs.pop(\"torch_dtype\", None)\n+\n+                tokenizer = AutoTokenizer.from_pretrained(\n+                    tokenizer_identifier, use_fast=use_fast, _from_pipeline=task, **hub_kwargs, **tokenizer_kwargs\n                 )\n-\n-        # Instantiate tokenizer if needed\n-        if isinstance(tokenizer, (str, tuple)):\n-            if isinstance(tokenizer, tuple):\n-                # For tuple we have (tokenizer name, {kwargs})\n-                use_fast = tokenizer[1].pop(\"use_fast\", use_fast)\n-                tokenizer_identifier = tokenizer[0]\n-                tokenizer_kwargs = tokenizer[1]\n+        except Exception as e:\n+            if load_tokenizer:\n+                raise e\n             else:\n-                tokenizer_identifier = tokenizer\n-                tokenizer_kwargs = model_kwargs.copy()\n-                tokenizer_kwargs.pop(\"torch_dtype\", None)\n-\n-            tokenizer = AutoTokenizer.from_pretrained(\n-                tokenizer_identifier, use_fast=use_fast, _from_pipeline=task, **hub_kwargs, **tokenizer_kwargs\n-            )\n-\n-    if load_image_processor:\n-        # Try to infer image processor from model or config name (if provided as str)\n-        if image_processor is None:\n-            if isinstance(model_name, str):\n-                image_processor = model_name\n-            elif isinstance(config, str):\n-                image_processor = config\n-            # Backward compatibility, as `feature_extractor` used to be the name\n-            # for `ImageProcessor`.\n-            elif feature_extractor is not None and isinstance(feature_extractor, BaseImageProcessor):\n-                image_processor = feature_extractor\n-            else:\n-                # Impossible to guess what is the right image_processor here\n-                raise Exception(\n-                    \"Impossible to guess which image processor to use. \"\n-                    \"Please provide a PreTrainedImageProcessor class or a path/identifier \"\n-                    \"to a pretrained image processor.\"\n+                tokenizer = None\n+\n+    if load_image_processor or load_image_processor is None:\n+        try:\n+            # Try to infer image processor from model or config name (if provided as str)\n+            if image_processor is None:\n+                if isinstance(model_name, str):\n+                    image_processor = model_name\n+                elif isinstance(config, str):\n+                    image_processor = config\n+                # Backward compatibility, as `feature_extractor` used to be the name\n+                # for `ImageProcessor`.\n+                elif feature_extractor is not None and isinstance(feature_extractor, BaseImageProcessor):\n+                    image_processor = feature_extractor\n+                else:\n+                    # Impossible to guess what is the right image_processor here\n+                    raise Exception(\n+                        \"Impossible to guess which image processor to use. \"\n+                        \"Please provide a PreTrainedImageProcessor class or a path/identifier \"\n+                        \"to a pretrained image processor.\"\n+                    )\n+\n+            # Instantiate image_processor if needed\n+            if isinstance(image_processor, (str, tuple)):\n+                image_processor = AutoImageProcessor.from_pretrained(\n+                    image_processor, _from_pipeline=task, **hub_kwargs, **model_kwargs\n                 )\n-\n-        # Instantiate image_processor if needed\n-        if isinstance(image_processor, (str, tuple)):\n-            image_processor = AutoImageProcessor.from_pretrained(\n-                image_processor, _from_pipeline=task, **hub_kwargs, **model_kwargs\n-            )\n-\n-    if load_feature_extractor:\n-        # Try to infer feature extractor from model or config name (if provided as str)\n-        if feature_extractor is None:\n-            if isinstance(model_name, str):\n-                feature_extractor = model_name\n-            elif isinstance(config, str):\n-                feature_extractor = config\n+        except Exception as e:\n+            if load_image_processor:\n+                raise e\n             else:\n-                # Impossible to guess what is the right feature_extractor here\n-                raise Exception(\n-                    \"Impossible to guess which feature extractor to use. \"\n-                    \"Please provide a PreTrainedFeatureExtractor class or a path/identifier \"\n-                    \"to a pretrained feature extractor.\"\n+                image_processor = None\n+\n+    if load_feature_extractor or load_feature_extractor is None:\n+        try:\n+            # Try to infer feature extractor from model or config name (if provided as str)\n+            if feature_extractor is None:\n+                if isinstance(model_name, str):\n+                    feature_extractor = model_name\n+                elif isinstance(config, str):\n+                    feature_extractor = config\n+                else:\n+                    # Impossible to guess what is the right feature_extractor here\n+                    raise Exception(\n+                        \"Impossible to guess which feature extractor to use. \"\n+                        \"Please provide a PreTrainedFeatureExtractor class or a path/identifier \"\n+                        \"to a pretrained feature extractor.\"\n+                    )\n+\n+            # Instantiate feature_extractor if needed\n+            if isinstance(feature_extractor, (str, tuple)):\n+                feature_extractor = AutoFeatureExtractor.from_pretrained(\n+                    feature_extractor, _from_pipeline=task, **hub_kwargs, **model_kwargs\n                 )\n \n-        # Instantiate feature_extractor if needed\n-        if isinstance(feature_extractor, (str, tuple)):\n-            feature_extractor = AutoFeatureExtractor.from_pretrained(\n-                feature_extractor, _from_pipeline=task, **hub_kwargs, **model_kwargs\n-            )\n-\n-            if (\n-                feature_extractor._processor_class\n-                and feature_extractor._processor_class.endswith(\"WithLM\")\n-                and isinstance(model_name, str)\n-            ):\n-                try:\n-                    import kenlm  # to trigger `ImportError` if not installed\n-                    from pyctcdecode import BeamSearchDecoderCTC\n-\n-                    if os.path.isdir(model_name) or os.path.isfile(model_name):\n-                        decoder = BeamSearchDecoderCTC.load_from_dir(model_name)\n-                    else:\n-                        language_model_glob = os.path.join(\n-                            BeamSearchDecoderCTC._LANGUAGE_MODEL_SERIALIZED_DIRECTORY, \"*\"\n+                if (\n+                    feature_extractor._processor_class\n+                    and feature_extractor._processor_class.endswith(\"WithLM\")\n+                    and isinstance(model_name, str)\n+                ):\n+                    try:\n+                        import kenlm  # to trigger `ImportError` if not installed\n+                        from pyctcdecode import BeamSearchDecoderCTC\n+\n+                        if os.path.isdir(model_name) or os.path.isfile(model_name):\n+                            decoder = BeamSearchDecoderCTC.load_from_dir(model_name)\n+                        else:\n+                            language_model_glob = os.path.join(\n+                                BeamSearchDecoderCTC._LANGUAGE_MODEL_SERIALIZED_DIRECTORY, \"*\"\n+                            )\n+                            alphabet_filename = BeamSearchDecoderCTC._ALPHABET_SERIALIZED_FILENAME\n+                            allow_patterns = [language_model_glob, alphabet_filename]\n+                            decoder = BeamSearchDecoderCTC.load_from_hf_hub(model_name, allow_patterns=allow_patterns)\n+\n+                        kwargs[\"decoder\"] = decoder\n+                    except ImportError as e:\n+                        logger.warning(\n+                            f\"Could not load the `decoder` for {model_name}. Defaulting to raw CTC. Error: {e}\"\n                         )\n-                        alphabet_filename = BeamSearchDecoderCTC._ALPHABET_SERIALIZED_FILENAME\n-                        allow_patterns = [language_model_glob, alphabet_filename]\n-                        decoder = BeamSearchDecoderCTC.load_from_hf_hub(model_name, allow_patterns=allow_patterns)\n-\n-                    kwargs[\"decoder\"] = decoder\n-                except ImportError as e:\n-                    logger.warning(f\"Could not load the `decoder` for {model_name}. Defaulting to raw CTC. Error: {e}\")\n-                    if not is_kenlm_available():\n-                        logger.warning(\"Try to install `kenlm`: `pip install kenlm\")\n-\n-                    if not is_pyctcdecode_available():\n-                        logger.warning(\"Try to install `pyctcdecode`: `pip install pyctcdecode\")\n-\n-    if load_processor:\n-        # Try to infer processor from model or config name (if provided as str)\n-        if processor is None:\n-            if isinstance(model_name, str):\n-                processor = model_name\n-            elif isinstance(config, str):\n-                processor = config\n+                        if not is_kenlm_available():\n+                            logger.warning(\"Try to install `kenlm`: `pip install kenlm\")\n+\n+                        if not is_pyctcdecode_available():\n+                            logger.warning(\"Try to install `pyctcdecode`: `pip install pyctcdecode\")\n+        except Exception as e:\n+            if load_feature_extractor:\n+                raise e\n             else:\n-                # Impossible to guess what is the right processor here\n-                raise Exception(\n-                    \"Impossible to guess which processor to use. \"\n-                    \"Please provide a processor instance or a path/identifier \"\n-                    \"to a processor.\"\n-                )\n-\n-        # Instantiate processor if needed\n-        if isinstance(processor, (str, tuple)):\n-            processor = AutoProcessor.from_pretrained(processor, _from_pipeline=task, **hub_kwargs, **model_kwargs)\n-            if not isinstance(processor, ProcessorMixin):\n-                raise TypeError(\n-                    \"Processor was loaded, but it is not an instance of `ProcessorMixin`. \"\n-                    f\"Got type `{type(processor)}` instead. Please check that you specified \"\n-                    \"correct pipeline task for the model and model has processor implemented and saved.\"\n-                )\n+                feature_extractor = None\n+\n+    if load_processor or load_processor is None:\n+        try:\n+            # Try to infer processor from model or config name (if provided as str)\n+            if processor is None:\n+                if isinstance(model_name, str):\n+                    processor = model_name\n+                elif isinstance(config, str):\n+                    processor = config\n+                else:\n+                    # Impossible to guess what is the right processor here\n+                    raise Exception(\n+                        \"Impossible to guess which processor to use. \"\n+                        \"Please provide a processor instance or a path/identifier \"\n+                        \"to a processor.\"\n+                    )\n+\n+            # Instantiate processor if needed\n+            if isinstance(processor, (str, tuple)):\n+                processor = AutoProcessor.from_pretrained(processor, _from_pipeline=task, **hub_kwargs, **model_kwargs)\n+                if not isinstance(processor, ProcessorMixin):\n+                    raise TypeError(\n+                        \"Processor was loaded, but it is not an instance of `ProcessorMixin`. \"\n+                        f\"Got type `{type(processor)}` instead. Please check that you specified \"\n+                        \"correct pipeline task for the model and model has processor implemented and saved.\"\n+                    )\n+        except Exception as e:\n+            if load_processor:\n+                raise e\n+            else:\n+                processor = None\n \n     if task == \"translation\" and model.config.task_specific_params:\n         for key in model.config.task_specific_params:"
        },
        {
            "sha": "cf6c6e80b0407694eb77392650ecbf7adb3729d2",
            "filename": "src/transformers/pipelines/audio_classification.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Faudio_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Faudio_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Faudio_classification.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -90,6 +90,11 @@ class AudioClassificationPipeline(Pipeline):\n     [huggingface.co/models](https://huggingface.co/models?filter=audio-classification).\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = False\n+    _load_feature_extractor = True\n+    _load_tokenizer = False\n+\n     def __init__(self, *args, **kwargs):\n         # Only set default top_k if explicitly provided\n         if \"top_k\" in kwargs and kwargs[\"top_k\"] is None:"
        },
        {
            "sha": "16d583bb3e5a6c2bc7b45b90a9834ab1cf6fb1e5",
            "filename": "src/transformers/pipelines/automatic_speech_recognition.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fautomatic_speech_recognition.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fautomatic_speech_recognition.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fautomatic_speech_recognition.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -183,6 +183,10 @@ class AutomaticSpeechRecognitionPipeline(ChunkPipeline):\n     \"\"\"\n \n     _pipeline_calls_generate = True\n+    _load_processor = False\n+    _load_image_processor = False\n+    _load_feature_extractor = True\n+    _load_tokenizer = True\n     # Make sure the docstring is updated when the default generation config is changed\n     _default_generation_config = GenerationConfig(\n         max_new_tokens=256,"
        },
        {
            "sha": "9077467568225d98935e32a31407c76f57515897",
            "filename": "src/transformers/pipelines/base.py",
            "status": "modified",
            "additions": 9,
            "deletions": 15,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fbase.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fbase.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fbase.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -925,21 +925,15 @@ class Pipeline(_ScikitCompat, PushToHubMixin):\n     constructor argument. If set to `True`, the output will be stored in the pickle format.\n     \"\"\"\n \n-    # Historically we have pipelines working with `tokenizer`, `feature_extractor`, and `image_processor`\n-    # as separate processing components. While we have `processor` class that combines them, some pipelines\n-    # might still operate with these components separately.\n-    # With the addition of `processor` to `pipeline`, we want to avoid:\n-    #  - loading `processor` for pipelines that still work with `image_processor` and `tokenizer` separately;\n-    #  - loading `image_processor`/`tokenizer` as a separate component while we operate only with `processor`,\n-    #    because `processor` will load required sub-components by itself.\n-    # Below flags allow granular control over loading components and set to be backward compatible with current\n-    # pipelines logic. You may override these flags when creating your pipeline. For example, for\n-    # `zero-shot-object-detection` pipeline which operates with `processor` you should set `_load_processor=True`\n-    # and all the rest flags to `False` to avoid unnecessary loading of the components.\n-    _load_processor = False\n-    _load_image_processor = True\n-    _load_feature_extractor = True\n-    _load_tokenizer = True\n+    # These flags should be overridden for downstream pipelines. They indicate which preprocessing classes are\n+    # used by each pipeline. The possible values are:\n+    # - True (the class is mandatory, raise an error if it's not present in the repo)\n+    # - None (the class is optional; it should be loaded if present in the repo but the pipeline can work without it)\n+    # - False (the class is never used by the pipeline and should not be loaded even if present)\n+    _load_processor = None\n+    _load_image_processor = None\n+    _load_feature_extractor = None\n+    _load_tokenizer = None\n \n     # Pipelines that call `generate` have shared logic, e.g. preparing the generation config.\n     _pipeline_calls_generate = False"
        },
        {
            "sha": "cd9df1317105f8b52a026485eb085bf0b7c0ca74",
            "filename": "src/transformers/pipelines/depth_estimation.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fdepth_estimation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fdepth_estimation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fdepth_estimation.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -47,6 +47,11 @@ class DepthEstimationPipeline(Pipeline):\n     See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=depth-estimation).\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = True\n+    _load_feature_extractor = False\n+    _load_tokenizer = False\n+\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         requires_backends(self, \"vision\")"
        },
        {
            "sha": "1d3c5f2f73532d053f0c41e10cd732baae5812b5",
            "filename": "src/transformers/pipelines/document_question_answering.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fdocument_question_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fdocument_question_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fdocument_question_answering.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -135,6 +135,10 @@ class DocumentQuestionAnsweringPipeline(ChunkPipeline):\n     \"\"\"\n \n     _pipeline_calls_generate = True\n+    _load_processor = False\n+    _load_image_processor = None\n+    _load_feature_extractor = None\n+    _load_tokenizer = False\n     # Make sure the docstring is updated when the default generation config is changed\n     _default_generation_config = GenerationConfig(\n         max_new_tokens=256,"
        },
        {
            "sha": "9c8005d05f22b3a0ff5e7b933a46c99a02c0ff49",
            "filename": "src/transformers/pipelines/feature_extraction.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ffeature_extraction.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ffeature_extraction.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ffeature_extraction.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -37,6 +37,11 @@ class FeatureExtractionPipeline(Pipeline):\n     [huggingface.co/models](https://huggingface.co/models).\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = False\n+    _load_feature_extractor = False\n+    _load_tokenizer = True\n+\n     def _sanitize_parameters(self, truncation=None, tokenize_kwargs=None, return_tensors=None, **kwargs):\n         if tokenize_kwargs is None:\n             tokenize_kwargs = {}"
        },
        {
            "sha": "f5dbe71dadff879f5516bd7599e81e1efab77dd3",
            "filename": "src/transformers/pipelines/fill_mask.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ffill_mask.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ffill_mask.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ffill_mask.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -32,6 +32,11 @@\n             Additional dictionary of keyword arguments passed along to the tokenizer.\"\"\",\n )\n class FillMaskPipeline(Pipeline):\n+    _load_processor = False\n+    _load_image_processor = False\n+    _load_feature_extractor = False\n+    _load_tokenizer = True\n+\n     \"\"\"\n     Masked language modeling prediction pipeline using any `ModelWithLMHead`. See the [masked language modeling\n     examples](../task_summary#masked-language-modeling) for more information."
        },
        {
            "sha": "95d525776c9a260faf59d7c510b0de4200ddd215",
            "filename": "src/transformers/pipelines/image_classification.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fimage_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fimage_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fimage_classification.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -99,6 +99,10 @@ class ImageClassificationPipeline(Pipeline):\n     \"\"\"\n \n     function_to_apply: ClassificationFunction = ClassificationFunction.NONE\n+    _load_processor = False\n+    _load_image_processor = True\n+    _load_feature_extractor = False\n+    _load_tokenizer = False\n \n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)"
        },
        {
            "sha": "7193a59249a6751cb9c837efe10f525ff80e2812",
            "filename": "src/transformers/pipelines/image_feature_extraction.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fimage_feature_extraction.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fimage_feature_extraction.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fimage_feature_extraction.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -45,6 +45,11 @@ class ImageFeatureExtractionPipeline(Pipeline):\n     [huggingface.co/models](https://huggingface.co/models).\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = True\n+    _load_feature_extractor = False\n+    _load_tokenizer = False\n+\n     def _sanitize_parameters(self, image_processor_kwargs=None, return_tensors=None, pool=None, **kwargs):\n         preprocess_params = {} if image_processor_kwargs is None else image_processor_kwargs\n "
        },
        {
            "sha": "3d113e776810b12cff9dcc08a0d7d5547bebe4e2",
            "filename": "src/transformers/pipelines/image_segmentation.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fimage_segmentation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fimage_segmentation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fimage_segmentation.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -60,6 +60,11 @@ class ImageSegmentationPipeline(Pipeline):\n     [huggingface.co/models](https://huggingface.co/models?filter=image-segmentation).\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = True\n+    _load_feature_extractor = False\n+    _load_tokenizer = None  # Oneformer uses it but no-one else does\n+\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n "
        },
        {
            "sha": "52fc99bd05f14301c2c1607871772e527a9ba717",
            "filename": "src/transformers/pipelines/image_to_image.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fimage_to_image.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fimage_to_image.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fimage_to_image.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -67,6 +67,11 @@ class ImageToImagePipeline(Pipeline):\n     See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=image-to-image).\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = True\n+    _load_feature_extractor = False\n+    _load_tokenizer = False\n+\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         requires_backends(self, \"vision\")"
        },
        {
            "sha": "86adf402cce6f232d9063b70baf012b62ed11fcb",
            "filename": "src/transformers/pipelines/image_to_text.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fimage_to_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fimage_to_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fimage_to_text.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -72,6 +72,10 @@ class ImageToTextPipeline(Pipeline):\n     \"\"\"\n \n     _pipeline_calls_generate = True\n+    _load_processor = False\n+    _load_image_processor = True\n+    _load_feature_extractor = False\n+    _load_tokenizer = True\n     # Make sure the docstring is updated when the default generation config is changed\n     _default_generation_config = GenerationConfig(\n         max_new_tokens=256,"
        },
        {
            "sha": "76d3a5be0e97d3b14101e96b3f538e4ba9f0de45",
            "filename": "src/transformers/pipelines/mask_generation.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fmask_generation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fmask_generation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fmask_generation.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -84,6 +84,11 @@ class MaskGenerationPipeline(ChunkPipeline):\n     See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=mask-generation).\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = True\n+    _load_feature_extractor = False\n+    _load_tokenizer = False\n+\n     def __init__(self, **kwargs):\n         super().__init__(**kwargs)\n         requires_backends(self, \"vision\")"
        },
        {
            "sha": "284c9e19079ea3ce60d8f2bedeeb5aefad3d37a3",
            "filename": "src/transformers/pipelines/object_detection.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fobject_detection.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fobject_detection.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fobject_detection.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -48,6 +48,11 @@ class ObjectDetectionPipeline(Pipeline):\n     See the list of available models on [huggingface.co/models](https://huggingface.co/models?filter=object-detection).\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = True\n+    _load_feature_extractor = False\n+    _load_tokenizer = None\n+\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n "
        },
        {
            "sha": "2fe92d747e81351ce8cdccf637011d869b84807f",
            "filename": "src/transformers/pipelines/question_answering.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fquestion_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fquestion_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fquestion_answering.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -156,6 +156,11 @@ class QuestionAnsweringArgumentHandler(ArgumentHandler):\n     supplied arguments.\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = False\n+    _load_feature_extractor = False\n+    _load_tokenizer = True\n+\n     def normalize(self, item):\n         if isinstance(item, SquadExample):\n             return item"
        },
        {
            "sha": "54a65ad77f7073a6b995094c0cc4900c67b98c26",
            "filename": "src/transformers/pipelines/table_question_answering.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ftable_question_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ftable_question_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftable_question_answering.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -122,6 +122,10 @@ class TableQuestionAnsweringPipeline(Pipeline):\n     default_input_names = \"table,query\"\n \n     _pipeline_calls_generate = True\n+    _load_processor = False\n+    _load_image_processor = False\n+    _load_feature_extractor = False\n+    _load_tokenizer = True\n     # Make sure the docstring is updated when the default generation config is changed\n     _default_generation_config = GenerationConfig(\n         max_new_tokens=256,"
        },
        {
            "sha": "c9333b760da61982d7cac7035378c1e2f953e7ce",
            "filename": "src/transformers/pipelines/text2text_generation.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ftext2text_generation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ftext2text_generation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftext2text_generation.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -68,6 +68,10 @@ class Text2TextGenerationPipeline(Pipeline):\n     ```\"\"\"\n \n     _pipeline_calls_generate = True\n+    _load_processor = False\n+    _load_image_processor = False\n+    _load_feature_extractor = False\n+    _load_tokenizer = True\n     # Make sure the docstring is updated when the default generation config is changed (in all pipelines in this file)\n     _default_generation_config = GenerationConfig(\n         max_new_tokens=256,"
        },
        {
            "sha": "367d867d0e80fb3dcfa4cd3b1b3536c772eaf33e",
            "filename": "src/transformers/pipelines/text_classification.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ftext_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ftext_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftext_classification.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -78,6 +78,11 @@ class TextClassificationPipeline(Pipeline):\n     [huggingface.co/models](https://huggingface.co/models?filter=text-classification).\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = False\n+    _load_feature_extractor = False\n+    _load_tokenizer = True\n+\n     return_all_scores = False\n     function_to_apply = ClassificationFunction.NONE\n "
        },
        {
            "sha": "d7eb3b54f8f4e9d6f2e39ec3d332f30be1e049b2",
            "filename": "src/transformers/pipelines/text_generation.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ftext_generation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ftext_generation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftext_generation.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -105,6 +105,11 @@ class TextGenerationPipeline(Pipeline):\n     \"\"\"\n \n     _pipeline_calls_generate = True\n+    _load_processor = False\n+    _load_image_processor = False\n+    _load_feature_extractor = False\n+    _load_tokenizer = True\n+\n     # Make sure the docstring is updated when the default generation config is changed\n     _default_generation_config = GenerationConfig(\n         max_new_tokens=256,"
        },
        {
            "sha": "a4ef097038d4a84bc26ed9e77292030277319a81",
            "filename": "src/transformers/pipelines/text_to_audio.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftext_to_audio.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -84,6 +84,11 @@ class TextToAudioPipeline(Pipeline):\n     _load_processor = True\n \n     _pipeline_calls_generate = True\n+    _load_processor = False\n+    _load_image_processor = False\n+    _load_feature_extractor = False\n+    _load_tokenizer = True\n+\n     # Make sure the docstring is updated when the default generation config is changed\n     _default_generation_config = GenerationConfig(\n         max_new_tokens=256,"
        },
        {
            "sha": "d7663eb1705cfad81fa03aac741e1ef8c82d73b9",
            "filename": "src/transformers/pipelines/token_classification.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ftoken_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Ftoken_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Ftoken_classification.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -136,6 +136,11 @@ class TokenClassificationPipeline(ChunkPipeline):\n \n     default_input_names = \"sequences\"\n \n+    _load_processor = False\n+    _load_image_processor = False\n+    _load_feature_extractor = False\n+    _load_tokenizer = True\n+\n     def __init__(self, args_parser=TokenClassificationArgumentHandler(), *args, **kwargs):\n         super().__init__(*args, **kwargs)\n "
        },
        {
            "sha": "0d601ca8f1e538c139fbc88c1266fbb1a80835ee",
            "filename": "src/transformers/pipelines/video_classification.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fvideo_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fvideo_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fvideo_classification.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -51,6 +51,11 @@ class VideoClassificationPipeline(Pipeline):\n     [huggingface.co/models](https://huggingface.co/models?filter=video-classification).\n     \"\"\"\n \n+    _load_processor = True\n+    _load_image_processor = False\n+    _load_feature_extractor = False\n+    _load_tokenizer = False\n+\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         requires_backends(self, \"av\")"
        },
        {
            "sha": "9be1b97ccd57a63945ccf6b491ee2b9a8c0ff224",
            "filename": "src/transformers/pipelines/visual_question_answering.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fvisual_question_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fvisual_question_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fvisual_question_answering.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -57,6 +57,11 @@ class VisualQuestionAnsweringPipeline(Pipeline):\n     [huggingface.co/models](https://huggingface.co/models?filter=visual-question-answering).\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = True\n+    _load_feature_extractor = False\n+    _load_tokenizer = True\n+\n     _pipeline_calls_generate = True\n     # Make sure the docstring is updated when the default generation config is changed\n     _default_generation_config = GenerationConfig("
        },
        {
            "sha": "ed988f70b12019cb1afd1816bffdf5678f770c6e",
            "filename": "src/transformers/pipelines/zero_shot_audio_classification.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fzero_shot_audio_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fzero_shot_audio_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fzero_shot_audio_classification.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -60,6 +60,11 @@ class ZeroShotAudioClassificationPipeline(Pipeline):\n     [huggingface.co/models](https://huggingface.co/models?filter=zero-shot-audio-classification).\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = False\n+    _load_feature_extractor = True\n+    _load_tokenizer = True\n+\n     def __init__(self, **kwargs):\n         super().__init__(**kwargs)\n "
        },
        {
            "sha": "b571a7896b726931279a5e1a173a6d6ba8334fff",
            "filename": "src/transformers/pipelines/zero_shot_classification.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fzero_shot_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fzero_shot_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fzero_shot_classification.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -82,6 +82,11 @@ class ZeroShotClassificationPipeline(ChunkPipeline):\n     of available models on [huggingface.co/models](https://huggingface.co/models?search=nli).\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = False\n+    _load_feature_extractor = False\n+    _load_tokenizer = True\n+\n     def __init__(self, args_parser=ZeroShotClassificationArgumentHandler(), *args, **kwargs):\n         self._args_parser = args_parser\n         super().__init__(*args, **kwargs)"
        },
        {
            "sha": "cb3c06fd238fff979ed7b2f22e169749d5b9831e",
            "filename": "src/transformers/pipelines/zero_shot_image_classification.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fzero_shot_image_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fzero_shot_image_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fzero_shot_image_classification.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -64,6 +64,11 @@ class ZeroShotImageClassificationPipeline(Pipeline):\n     [huggingface.co/models](https://huggingface.co/models?filter=zero-shot-image-classification).\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = True\n+    _load_feature_extractor = False\n+    _load_tokenizer = True\n+\n     def __init__(self, **kwargs):\n         super().__init__(**kwargs)\n "
        },
        {
            "sha": "46426fed392336c9b434de31171a00b851b4b074",
            "filename": "src/transformers/pipelines/zero_shot_object_detection.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fzero_shot_object_detection.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3d8be20cd2f76aa03d3f42808f2c9b36c94608b3/src%2Ftransformers%2Fpipelines%2Fzero_shot_object_detection.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fzero_shot_object_detection.py?ref=3d8be20cd2f76aa03d3f42808f2c9b36c94608b3",
            "patch": "@@ -53,6 +53,11 @@ class ZeroShotObjectDetectionPipeline(ChunkPipeline):\n     [huggingface.co/models](https://huggingface.co/models?filter=zero-shot-object-detection).\n     \"\"\"\n \n+    _load_processor = False\n+    _load_image_processor = True\n+    _load_feature_extractor = False\n+    _load_tokenizer = True\n+\n     def __init__(self, **kwargs):\n         super().__init__(**kwargs)\n "
        }
    ],
    "stats": {
        "total": 512,
        "additions": 286,
        "deletions": 226
    }
}