{
    "author": "cyyever",
    "message": "Fix typing of train_args (#41142)\n\n* Fix typing\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>\n\n* Fix fsdp typing\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>\n\n---------\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>",
    "sha": "a61fc6a0b985548c681df89c15f8053dafe322bf",
    "files": [
        {
            "sha": "54ec025f83aa0f69e5dd99d58736b0646bac8f80",
            "filename": "src/transformers/training_args.py",
            "status": "modified",
            "additions": 17,
            "deletions": 18,
            "changes": 35,
            "blob_url": "https://github.com/huggingface/transformers/blob/a61fc6a0b985548c681df89c15f8053dafe322bf/src%2Ftransformers%2Ftraining_args.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a61fc6a0b985548c681df89c15f8053dafe322bf/src%2Ftransformers%2Ftraining_args.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftraining_args.py?ref=a61fc6a0b985548c681df89c15f8053dafe322bf",
            "patch": "@@ -476,7 +476,7 @@ class TrainingArguments:\n             When resuming training, whether or not to skip the epochs and batches to get the data loading at the same\n             stage as in the previous training. If set to `True`, the training will begin faster (as that skipping step\n             can take a long time) but will not yield the same results as the interrupted training would have.\n-        fsdp (`bool`, `str` or list of [`~trainer_utils.FSDPOption`], *optional*, defaults to `''`):\n+        fsdp (`bool`, `str` or list of [`~trainer_utils.FSDPOption`], *optional*, defaults to `[]`):\n             Use PyTorch Distributed Parallel Training (in distributed training only).\n \n             A list of options along the following:\n@@ -738,11 +738,10 @@ class TrainingArguments:\n             Refer to the PyTorch doc for possible values and note that they may change across PyTorch versions.\n \n             This flag is experimental and subject to change in future releases.\n-        include_tokens_per_second (`bool`, *optional*):\n+        include_tokens_per_second (`bool`, *optional*, defaults to `False`):\n             Whether or not to compute the number of tokens per second per device for training speed metrics.\n \n             This will iterate over the entire training dataloader once beforehand,\n-\n             and will slow down the entire process.\n \n         include_num_input_tokens_seen (`bool`, *optional*):\n@@ -761,7 +760,7 @@ class TrainingArguments:\n             See GaLore implementation (https://github.com/jiaweizzhao/GaLore) and APOLLO implementation (https://github.com/zhuhanqing/APOLLO) for more details.\n             You need to make sure to pass a valid GaLore or APOLLO optimizer, e.g., one of: \"apollo_adamw\", \"galore_adamw\", \"galore_adamw_8bit\", \"galore_adafactor\" and make sure that the target modules are `nn.Linear` modules only.\n \n-        batch_eval_metrics (`Optional[bool]`, defaults to `False`):\n+        batch_eval_metrics (`bool`, *optional*, defaults to `False`):\n             If set to `True`, evaluation will call compute_metrics at the end of each batch to accumulate statistics\n             rather than saving all eval logits in memory. When set to `True`, you must pass a compute_metrics function\n             that takes a boolean argument `compute_result`, which when passed `True`, will trigger the final global\n@@ -845,7 +844,7 @@ class TrainingArguments:\n         metadata={\"help\": \"Number of predictions steps to accumulate before moving the tensors to the CPU.\"},\n     )\n \n-    eval_delay: Optional[float] = field(\n+    eval_delay: float = field(\n         default=0,\n         metadata={\n             \"help\": (\n@@ -880,7 +879,7 @@ class TrainingArguments:\n         default=\"linear\",\n         metadata={\"help\": \"The scheduler type to use.\"},\n     )\n-    lr_scheduler_kwargs: Optional[Union[dict[str, Any], str]] = field(\n+    lr_scheduler_kwargs: Union[dict[str, Any], str] = field(\n         default_factory=dict,\n         metadata={\n             \"help\": (\n@@ -963,7 +962,7 @@ class TrainingArguments:\n             )\n         },\n     )\n-    save_safetensors: Optional[bool] = field(\n+    save_safetensors: bool = field(\n         default=True,\n         metadata={\n             \"help\": \"Use safetensors saving and loading for state dicts instead of default torch.load and torch.save.\"\n@@ -1117,13 +1116,13 @@ class TrainingArguments:\n         default=None, metadata={\"help\": \"Whether or not to disable the tqdm progress bars.\"}\n     )\n \n-    remove_unused_columns: Optional[bool] = field(\n+    remove_unused_columns: bool = field(\n         default=True, metadata={\"help\": \"Remove columns not required by the model when using an nlp.Dataset.\"}\n     )\n     label_names: Optional[list[str]] = field(\n         default=None, metadata={\"help\": \"The list of keys in your dictionary of inputs that correspond to the labels.\"}\n     )\n-    load_best_model_at_end: Optional[bool] = field(\n+    load_best_model_at_end: bool = field(\n         default=False,\n         metadata={\n             \"help\": (\n@@ -1147,8 +1146,8 @@ class TrainingArguments:\n             )\n         },\n     )\n-    fsdp: Optional[Union[list[FSDPOption], str]] = field(\n-        default=\"\",\n+    fsdp: Union[list[FSDPOption], str, bool] = field(\n+        default_factory=list,\n         metadata={\n             \"help\": (\n                 \"Whether or not to use PyTorch Fully Sharded Data Parallel (FSDP) training (in distributed training\"\n@@ -1209,7 +1208,7 @@ class TrainingArguments:\n         default=False,\n         metadata={\"help\": \"Whether or not to group samples of roughly the same length together when batching.\"},\n     )\n-    length_column_name: Optional[str] = field(\n+    length_column_name: str = field(\n         default=\"length\",\n         metadata={\"help\": \"Column name with precomputed lengths to use when grouping by length.\"},\n     )\n@@ -1338,7 +1337,7 @@ class TrainingArguments:\n             )\n         },\n     )\n-    ray_scope: Optional[str] = field(\n+    ray_scope: str = field(\n         default=\"last\",\n         metadata={\n             \"help\": (\n@@ -1373,12 +1372,12 @@ class TrainingArguments:\n         },\n     )\n \n-    include_tokens_per_second: Optional[bool] = field(\n+    include_tokens_per_second: bool = field(\n         default=False,\n         metadata={\"help\": \"If set to `True`, the speed metrics will include `tgs` (tokens per second per device).\"},\n     )\n \n-    include_num_input_tokens_seen: Optional[Union[str, bool]] = field(\n+    include_num_input_tokens_seen: Union[str, bool] = field(\n         default=False,\n         metadata={\n             \"help\": (\n@@ -1415,7 +1414,7 @@ class TrainingArguments:\n         },\n     )\n \n-    use_liger_kernel: Optional[bool] = field(\n+    use_liger_kernel: bool = field(\n         default=False,\n         metadata={\"help\": \"Whether or not to enable the Liger Kernel for model training.\"},\n     )\n@@ -1433,14 +1432,14 @@ class TrainingArguments:\n         },\n     )\n \n-    eval_use_gather_object: Optional[bool] = field(\n+    eval_use_gather_object: bool = field(\n         default=False,\n         metadata={\n             \"help\": \"Whether to run recursively gather object in a nested list/tuple/dictionary of objects from all devices.\"\n         },\n     )\n \n-    average_tokens_across_devices: Optional[bool] = field(\n+    average_tokens_across_devices: bool = field(\n         default=True,\n         metadata={\n             \"help\": \"Whether or not to average tokens across devices. If enabled, will use all_reduce to \""
        }
    ],
    "stats": {
        "total": 35,
        "additions": 17,
        "deletions": 18
    }
}