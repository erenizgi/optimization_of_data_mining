{
    "author": "cyyever",
    "message": "Fix unnecessary super calls (#38897)\n\nSigned-off-by: cyy <cyyever@outlook.com>",
    "sha": "0a53df1a77a9978ddf958e1f8f7a257181f180cb",
    "files": [
        {
            "sha": "e6e5f68a98a3777908b48b52be255a727764525e",
            "filename": "src/transformers/models/bit/modeling_bit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fbit%2Fmodeling_bit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fbit%2Fmodeling_bit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbit%2Fmodeling_bit.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -135,7 +135,7 @@ class BitGroupNormActivation(nn.GroupNorm):\n     \"\"\"\n \n     def __init__(self, config, num_channels, eps=1e-5, affine=True, apply_activation=True):\n-        super(BitGroupNormActivation, self).__init__(config.num_groups, num_channels, eps=eps, affine=affine)\n+        super().__init__(config.num_groups, num_channels, eps=eps, affine=affine)\n         if apply_activation:\n             self.activation = ACT2FN[config.hidden_act]\n         else:"
        },
        {
            "sha": "6be0c98869a7420aae07749a039d297095683676",
            "filename": "src/transformers/models/blenderbot/modeling_blenderbot.py",
            "status": "modified",
            "additions": 2,
            "deletions": 4,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_blenderbot.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_blenderbot.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_blenderbot.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -1183,7 +1183,7 @@ def from_pretrained(cls, pretrained_model_name_or_path: Optional[Union[str, os.P\n             )\n             return BlenderbotSmallModel.from_pretrained(pretrained_model_name_or_path)\n \n-        return super(BlenderbotModel, cls).from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n+        return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n \n     def get_input_embeddings(self):\n         return self.shared\n@@ -1344,9 +1344,7 @@ def from_pretrained(cls, pretrained_model_name_or_path: Optional[Union[str, os.P\n             )\n             return BlenderbotSmallForConditionalGeneration.from_pretrained(pretrained_model_name_or_path)\n \n-        return super(BlenderbotForConditionalGeneration, cls).from_pretrained(\n-            pretrained_model_name_or_path, *model_args, **kwargs\n-        )\n+        return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n \n     def get_encoder(self):\n         return self.model.get_encoder()"
        },
        {
            "sha": "33d1a44a2febc9fcbfce5f8ba7a0ef946f1668c5",
            "filename": "src/transformers/models/bros/modeling_bros.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fbros%2Fmodeling_bros.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fbros%2Fmodeling_bros.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbros%2Fmodeling_bros.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -74,7 +74,7 @@ class BrosPositionalEmbedding1D(nn.Module):\n     # Reference: https://github.com/kimiyoung/transformer-xl/blob/master/pytorch/mem_transformer.py#L15\n \n     def __init__(self, config):\n-        super(BrosPositionalEmbedding1D, self).__init__()\n+        super().__init__()\n \n         self.dim_bbox_sinusoid_emb_1d = config.dim_bbox_sinusoid_emb_1d\n \n@@ -93,7 +93,7 @@ def forward(self, pos_seq: torch.Tensor) -> torch.Tensor:\n \n class BrosPositionalEmbedding2D(nn.Module):\n     def __init__(self, config):\n-        super(BrosPositionalEmbedding2D, self).__init__()\n+        super().__init__()\n \n         self.dim_bbox = config.dim_bbox\n         self.x_pos_emb = BrosPositionalEmbedding1D(config)\n@@ -112,7 +112,7 @@ def forward(self, bbox: torch.Tensor) -> torch.Tensor:\n \n class BrosBboxEmbeddings(nn.Module):\n     def __init__(self, config):\n-        super(BrosBboxEmbeddings, self).__init__()\n+        super().__init__()\n         self.bbox_sinusoid_emb = BrosPositionalEmbedding2D(config)\n         self.bbox_projection = nn.Linear(config.dim_bbox_sinusoid_emb_2d, config.dim_bbox_projection, bias=False)\n "
        },
        {
            "sha": "9c62b5fc8c1020a2d70b3f6cd38ffda0dedfaa11",
            "filename": "src/transformers/models/data2vec/modeling_data2vec_audio.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_audio.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -1229,7 +1229,7 @@ def forward(\n \n class AMSoftmaxLoss(nn.Module):\n     def __init__(self, input_dim, num_labels, scale=30.0, margin=0.4):\n-        super(AMSoftmaxLoss, self).__init__()\n+        super().__init__()\n         self.scale = scale\n         self.margin = margin\n         self.num_labels = num_labels"
        },
        {
            "sha": "f57754cc585a1c034c5c8f0cf705cdccfd7f4a69",
            "filename": "src/transformers/models/deprecated/ernie_m/modeling_ernie_m.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fernie_m%2Fmodeling_ernie_m.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fernie_m%2Fmodeling_ernie_m.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fernie_m%2Fmodeling_ernie_m.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -484,7 +484,7 @@ def _init_weights(self, module):\n )\n class ErnieMModel(ErnieMPreTrainedModel):\n     def __init__(self, config, add_pooling_layer=True):\n-        super(ErnieMModel, self).__init__(config)\n+        super().__init__(config)\n         self.initializer_range = config.initializer_range\n         self.embeddings = ErnieMEmbeddings(config)\n         self.encoder = ErnieMEncoder(config)\n@@ -964,7 +964,7 @@ def forward(\n )\n class ErnieMForInformationExtraction(ErnieMPreTrainedModel):\n     def __init__(self, config):\n-        super(ErnieMForInformationExtraction, self).__init__(config)\n+        super().__init__(config)\n         self.ernie_m = ErnieMModel(config)\n         self.linear_start = nn.Linear(config.hidden_size, 1)\n         self.linear_end = nn.Linear(config.hidden_size, 1)"
        },
        {
            "sha": "151057dd997ab9b4f8d618c4fbc5851f1bfdf144",
            "filename": "src/transformers/models/granitemoe/modeling_granitemoe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -324,7 +324,7 @@ class GraniteMoeMoE(nn.Module):\n     \"\"\"\n \n     def __init__(self, config: GraniteMoeConfig):\n-        super(GraniteMoeMoE, self).__init__()\n+        super().__init__()\n \n         self.input_size = config.hidden_size\n         self.hidden_size = config.intermediate_size"
        },
        {
            "sha": "0cd453c6e891a686e070c9e842fe940fc825a88a",
            "filename": "src/transformers/models/granitemoehybrid/modeling_granitemoehybrid.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoehybrid%2Fmodeling_granitemoehybrid.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -856,7 +856,7 @@ class GraniteMoeHybridMLP(nn.Module):\n     \"\"\"\n \n     def __init__(self, config: GraniteMoeHybridConfig):\n-        super(GraniteMoeHybridMLP, self).__init__()\n+        super().__init__()\n \n         self.input_size = config.hidden_size\n         self.hidden_size = config.shared_intermediate_size\n@@ -995,7 +995,7 @@ class GraniteMoeHybridMoE(nn.Module):\n     \"\"\"\n \n     def __init__(self, config: GraniteMoeHybridConfig):\n-        super(GraniteMoeHybridMoE, self).__init__()\n+        super().__init__()\n \n         self.input_size = config.hidden_size\n         self.hidden_size = config.intermediate_size"
        },
        {
            "sha": "82e997d462a52a1cf35a6490dbfa38f76cd354aa",
            "filename": "src/transformers/models/granitemoeshared/modeling_granitemoeshared.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodeling_granitemoeshared.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodeling_granitemoeshared.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodeling_granitemoeshared.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -56,7 +56,7 @@ class GraniteMoeSharedMLP(nn.Module):\n     \"\"\"\n \n     def __init__(self, config: GraniteMoeSharedConfig):\n-        super(GraniteMoeSharedMLP, self).__init__()\n+        super().__init__()\n \n         self.input_size = config.hidden_size\n         self.hidden_size = config.shared_intermediate_size\n@@ -195,7 +195,7 @@ class GraniteMoeSharedMoE(nn.Module):\n     \"\"\"\n \n     def __init__(self, config: GraniteMoeSharedConfig):\n-        super(GraniteMoeSharedMoE, self).__init__()\n+        super().__init__()\n \n         self.input_size = config.hidden_size\n         self.hidden_size = config.intermediate_size"
        },
        {
            "sha": "d8e644b7b982d17d2d4054880c0d661ed38bd4fa",
            "filename": "src/transformers/models/granitemoeshared/modular_granitemoeshared.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodular_granitemoeshared.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodular_granitemoeshared.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoeshared%2Fmodular_granitemoeshared.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -43,7 +43,7 @@ class GraniteMoeSharedMLP(nn.Module):\n     \"\"\"\n \n     def __init__(self, config: GraniteMoeSharedConfig):\n-        super(GraniteMoeSharedMLP, self).__init__()\n+        super().__init__()\n \n         self.input_size = config.hidden_size\n         self.hidden_size = config.shared_intermediate_size"
        },
        {
            "sha": "ccee5f34a5026fe2204db29baf3c62e071dacc18",
            "filename": "src/transformers/models/jetmoe/modeling_jetmoe.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -233,7 +233,7 @@ class JetMoeMoE(nn.Module):\n     \"\"\"\n \n     def __init__(self, config: JetMoeConfig):\n-        super(JetMoeMoE, self).__init__()\n+        super().__init__()\n \n         self.input_size = config.hidden_size\n         self.hidden_size = config.intermediate_size\n@@ -291,7 +291,7 @@ class JetMoeMoA(nn.Module):\n     \"\"\"\n \n     def __init__(self, config: JetMoeConfig):\n-        super(JetMoeMoA, self).__init__()\n+        super().__init__()\n \n         self.num_experts = config.num_local_experts\n         self.input_size = config.hidden_size"
        },
        {
            "sha": "e4fb25523a7eb8714829ed56537cd6b93ce037a4",
            "filename": "src/transformers/models/layoutlm/modeling_layoutlm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Flayoutlm%2Fmodeling_layoutlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Flayoutlm%2Fmodeling_layoutlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flayoutlm%2Fmodeling_layoutlm.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -47,7 +47,7 @@ class LayoutLMEmbeddings(nn.Module):\n     \"\"\"Construct the embeddings from word, position and token_type embeddings.\"\"\"\n \n     def __init__(self, config):\n-        super(LayoutLMEmbeddings, self).__init__()\n+        super().__init__()\n         self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n         self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n         self.x_position_embeddings = nn.Embedding(config.max_2d_position_embeddings, config.hidden_size)\n@@ -635,7 +635,7 @@ def _init_weights(self, module):\n @auto_docstring\n class LayoutLMModel(LayoutLMPreTrainedModel):\n     def __init__(self, config):\n-        super(LayoutLMModel, self).__init__(config)\n+        super().__init__(config)\n         self.config = config\n \n         self.embeddings = LayoutLMEmbeddings(config)"
        },
        {
            "sha": "7a82375d1ff896a59062e693e099410e31783d80",
            "filename": "src/transformers/models/layoutlmv2/modeling_layoutlmv2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fmodeling_layoutlmv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fmodeling_layoutlmv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fmodeling_layoutlmv2.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -52,7 +52,7 @@ class LayoutLMv2Embeddings(nn.Module):\n     \"\"\"Construct the embeddings from word, position and token_type embeddings.\"\"\"\n \n     def __init__(self, config):\n-        super(LayoutLMv2Embeddings, self).__init__()\n+        super().__init__()\n         self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n         self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n "
        },
        {
            "sha": "44e603144038d424c9585049208ce1299fb175cc",
            "filename": "src/transformers/models/lxmert/modeling_lxmert.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Flxmert%2Fmodeling_lxmert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Flxmert%2Fmodeling_lxmert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flxmert%2Fmodeling_lxmert.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -648,7 +648,7 @@ def forward(\n \n class LxmertPooler(nn.Module):\n     def __init__(self, config):\n-        super(LxmertPooler, self).__init__()\n+        super().__init__()\n         self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n         self.activation = nn.Tanh()\n \n@@ -663,7 +663,7 @@ def forward(self, hidden_states):\n \n class LxmertPredictionHeadTransform(nn.Module):\n     def __init__(self, config):\n-        super(LxmertPredictionHeadTransform, self).__init__()\n+        super().__init__()\n         self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n         self.transform_act_fn = ACT2FN[config.hidden_act]\n         self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n@@ -677,7 +677,7 @@ def forward(self, hidden_states):\n \n class LxmertLMPredictionHead(nn.Module):\n     def __init__(self, config, lxmert_model_embedding_weights):\n-        super(LxmertLMPredictionHead, self).__init__()\n+        super().__init__()\n         self.transform = LxmertPredictionHeadTransform(config)\n \n         # The output weights are the same as the input embeddings, but there is\n@@ -744,7 +744,7 @@ def forward(self, hidden_states):\n \n class LxmertPreTrainingHeads(nn.Module):\n     def __init__(self, config, lxmert_model_embedding_weights):\n-        super(LxmertPreTrainingHeads, self).__init__()\n+        super().__init__()\n         self.predictions = LxmertLMPredictionHead(config, lxmert_model_embedding_weights)\n         self.seq_relationship = nn.Linear(config.hidden_size, 2)\n "
        },
        {
            "sha": "47e57b00172914d8666ac881128effe5778b5746",
            "filename": "src/transformers/models/markuplm/modeling_markuplm.py",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fmarkuplm%2Fmodeling_markuplm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fmarkuplm%2Fmodeling_markuplm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmarkuplm%2Fmodeling_markuplm.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -52,7 +52,7 @@ class XPathEmbeddings(nn.Module):\n     \"\"\"\n \n     def __init__(self, config):\n-        super(XPathEmbeddings, self).__init__()\n+        super().__init__()\n         self.max_depth = config.max_depth\n \n         self.xpath_unitseq2_embeddings = nn.Linear(config.xpath_unit_hidden_size * self.max_depth, config.hidden_size)\n@@ -116,7 +116,7 @@ class MarkupLMEmbeddings(nn.Module):\n     \"\"\"Construct the embeddings from word, position and token_type embeddings.\"\"\"\n \n     def __init__(self, config):\n-        super(MarkupLMEmbeddings, self).__init__()\n+        super().__init__()\n         self.config = config\n         self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n         self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n@@ -724,9 +724,7 @@ def _init_weights(self, module):\n \n     @classmethod\n     def from_pretrained(cls, pretrained_model_name_or_path: Optional[Union[str, os.PathLike]], *model_args, **kwargs):\n-        return super(MarkupLMPreTrainedModel, cls).from_pretrained(\n-            pretrained_model_name_or_path, *model_args, **kwargs\n-        )\n+        return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n \n \n @auto_docstring"
        },
        {
            "sha": "00239833cb47c76729c5a476a14e411f29783439",
            "filename": "src/transformers/models/perceiver/modeling_perceiver.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fperceiver%2Fmodeling_perceiver.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fperceiver%2Fmodeling_perceiver.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fperceiver%2Fmodeling_perceiver.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -2533,7 +2533,7 @@ class Conv2dSamePadding(nn.Conv2d):\n     \"\"\"\n \n     def __init__(self, *args, **kwargs):\n-        super(Conv2dSamePadding, self).__init__(*args, **kwargs)\n+        super().__init__(*args, **kwargs)\n         self.zero_pad_2d = nn.ZeroPad2d(\n             reduce(__add__, [(k // 2 + (k - 2 * (k // 2)) - 1, k // 2) for k in self.kernel_size[::-1]])\n         )"
        },
        {
            "sha": "375392077c6755b4a22e6a3eadb3469d5c2104af",
            "filename": "src/transformers/models/speech_to_text/modeling_speech_to_text.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fspeech_to_text%2Fmodeling_speech_to_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fspeech_to_text%2Fmodeling_speech_to_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fspeech_to_text%2Fmodeling_speech_to_text.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -77,7 +77,7 @@ class Conv1dSubsampler(nn.Module):\n     \"\"\"\n \n     def __init__(self, config):\n-        super(Conv1dSubsampler, self).__init__()\n+        super().__init__()\n         self.config = config\n         self.num_layers = config.num_conv_layers\n         self.in_channels = config.input_feat_per_channel * config.input_channels"
        },
        {
            "sha": "b64f0b832ff9a854584ec2c6e57dea0e9e08812e",
            "filename": "src/transformers/models/swin/modeling_tf_swin.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fswin%2Fmodeling_tf_swin.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fswin%2Fmodeling_tf_swin.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fswin%2Fmodeling_tf_swin.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -476,7 +476,7 @@ class TFSwinDropPath(keras.layers.Layer):\n     \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\"\"\"\n \n     def __init__(self, drop_prob: Optional[float] = None, scale_by_keep: bool = True, **kwargs) -> None:\n-        super(TFSwinDropPath, self).__init__(**kwargs)\n+        super().__init__(**kwargs)\n         self.drop_prob = drop_prob\n         self.scale_by_keep = scale_by_keep\n "
        },
        {
            "sha": "74cbfd453d8a25887380c06fbcbaca0c1a1ca520",
            "filename": "src/transformers/models/tapas/modeling_tf_tapas.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Ftapas%2Fmodeling_tf_tapas.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Ftapas%2Fmodeling_tf_tapas.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftapas%2Fmodeling_tf_tapas.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -1871,7 +1871,7 @@ def __init__(self, outer_index, inner_index):\n         if outer_index.batch_dims != inner_index.batch_dims:\n             raise ValueError(\"outer_index.batch_dims and inner_index.batch_dims must be the same.\")\n \n-        super(ProductIndexMap, self).__init__(\n+        super().__init__(\n             indices=(\n                 inner_index.indices\n                 + outer_index.indices * tf.cast(inner_index.num_segments, inner_index.indices.dtype)"
        },
        {
            "sha": "ba3c0080a278f8b41c9376a06fd68766b44f3bfc",
            "filename": "src/transformers/models/udop/modeling_udop.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fudop%2Fmodeling_udop.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fudop%2Fmodeling_udop.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fudop%2Fmodeling_udop.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -847,7 +847,7 @@ def forward(\n \n class UdopCellEmbeddings(nn.Module):\n     def __init__(self, max_2d_position_embeddings=501, hidden_size=1024):\n-        super(UdopCellEmbeddings, self).__init__()\n+        super().__init__()\n         self.max_2d_position_embeddings = max_2d_position_embeddings\n \n         self.x_position_embeddings = nn.Embedding(max_2d_position_embeddings, hidden_size)\n@@ -911,7 +911,7 @@ def __init__(\n         prefix_bucket=False,\n         expand=False,\n     ):\n-        super(RelativePositionBiasBase, self).__init__()\n+        super().__init__()\n         self.prefix_bucket = prefix_bucket\n         self.augmentation = augmentation\n         self.level = level\n@@ -1499,7 +1499,7 @@ class UdopModel(UdopPreTrainedModel):\n     ]\n \n     def __init__(self, config):\n-        super(UdopModel, self).__init__(config)\n+        super().__init__(config)\n \n         # text and image embeddings\n         self.shared = nn.Embedding(config.vocab_size, config.d_model)\n@@ -1695,7 +1695,7 @@ class UdopForConditionalGeneration(UdopPreTrainedModel, GenerationMixin):\n     ]\n \n     def __init__(self, config):\n-        super(UdopForConditionalGeneration, self).__init__(config)\n+        super().__init__(config)\n \n         # text and image embeddings\n         self.shared = nn.Embedding(config.vocab_size, config.d_model)"
        },
        {
            "sha": "1ecb418c140c94fc1643b7a2e6f783f6702a496c",
            "filename": "src/transformers/models/unispeech_sat/modeling_unispeech_sat.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Funispeech_sat%2Fmodeling_unispeech_sat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Funispeech_sat%2Fmodeling_unispeech_sat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Funispeech_sat%2Fmodeling_unispeech_sat.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -1670,7 +1670,7 @@ def forward(\n \n class AMSoftmaxLoss(nn.Module):\n     def __init__(self, input_dim, num_labels, scale=30.0, margin=0.4):\n-        super(AMSoftmaxLoss, self).__init__()\n+        super().__init__()\n         self.scale = scale\n         self.margin = margin\n         self.num_labels = num_labels"
        },
        {
            "sha": "6057e0c9fb22347ba9ff1108de9c3b89ba5d41c6",
            "filename": "src/transformers/models/wav2vec2/modeling_wav2vec2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fmodeling_wav2vec2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fmodeling_wav2vec2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fmodeling_wav2vec2.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -2203,7 +2203,7 @@ def forward(\n \n class AMSoftmaxLoss(nn.Module):\n     def __init__(self, input_dim, num_labels, scale=30.0, margin=0.4):\n-        super(AMSoftmaxLoss, self).__init__()\n+        super().__init__()\n         self.scale = scale\n         self.margin = margin\n         self.num_labels = num_labels"
        },
        {
            "sha": "f938fa20bfd40d1caf7c5af3ac4ad1177002340f",
            "filename": "src/transformers/models/wav2vec2_bert/modeling_wav2vec2_bert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fwav2vec2_bert%2Fmodeling_wav2vec2_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fwav2vec2_bert%2Fmodeling_wav2vec2_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwav2vec2_bert%2Fmodeling_wav2vec2_bert.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -1358,7 +1358,7 @@ def forward(\n \n class AMSoftmaxLoss(nn.Module):\n     def __init__(self, input_dim, num_labels, scale=30.0, margin=0.4):\n-        super(AMSoftmaxLoss, self).__init__()\n+        super().__init__()\n         self.scale = scale\n         self.margin = margin\n         self.num_labels = num_labels"
        },
        {
            "sha": "eb28f7f9554e7e5d3e5f761d6b1a55f96a9f91b3",
            "filename": "src/transformers/models/wav2vec2_conformer/modeling_wav2vec2_conformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fwav2vec2_conformer%2Fmodeling_wav2vec2_conformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fwav2vec2_conformer%2Fmodeling_wav2vec2_conformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwav2vec2_conformer%2Fmodeling_wav2vec2_conformer.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -1751,7 +1751,7 @@ def forward(\n \n class AMSoftmaxLoss(nn.Module):\n     def __init__(self, input_dim, num_labels, scale=30.0, margin=0.4):\n-        super(AMSoftmaxLoss, self).__init__()\n+        super().__init__()\n         self.scale = scale\n         self.margin = margin\n         self.num_labels = num_labels"
        },
        {
            "sha": "bb9c15002b26aa96de603302aa9a9e3842da505d",
            "filename": "src/transformers/models/wavlm/modeling_wavlm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fwavlm%2Fmodeling_wavlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a53df1a77a9978ddf958e1f8f7a257181f180cb/src%2Ftransformers%2Fmodels%2Fwavlm%2Fmodeling_wavlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwavlm%2Fmodeling_wavlm.py?ref=0a53df1a77a9978ddf958e1f8f7a257181f180cb",
            "patch": "@@ -1514,7 +1514,7 @@ def forward(\n \n class AMSoftmaxLoss(nn.Module):\n     def __init__(self, input_dim, num_labels, scale=30.0, margin=0.4):\n-        super(AMSoftmaxLoss, self).__init__()\n+        super().__init__()\n         self.scale = scale\n         self.margin = margin\n         self.num_labels = num_labels"
        }
    ],
    "stats": {
        "total": 84,
        "additions": 40,
        "deletions": 44
    }
}