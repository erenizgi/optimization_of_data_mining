{
    "author": "xspirus",
    "message": "Fix `num_items_in_batch` not being an integer (#35115)\n\nIn method `Trainer#get_batch_samples`, the return values should be a\nlist of batch samples and an integer indicating the number of items that\nexist in the batch. However, this was not actually a case and what was\nreturned instead of an integer, was a tensor with one element. In the\nmulti-GPU setup, this tensor is placed in a different device than the\nloss tensor, causing the loss function to raise a `RuntimeError`.\n\nThe problem arises from\nhttps://github.com/huggingface/transformers/blob/5d7739f15a6e50de416977fe2cc9cb516d67edda/src/transformers/trainer.py#L5139-L5144,\nwhere the outer `sum` operates over a list of tensors which means that\nthe final result is also a tensor. To counter this issue, a new check\n(after the accelerator gathering) has been added in order to convert a\npotential tensor to an integer before returning the\n`num_items_in_batch`.",
    "sha": "dada0fd85f13c68dd7506aba0740083523bcf2df",
    "files": [
        {
            "sha": "be41a415e5a710e1d57698a0c287f1e71e626025",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/dada0fd85f13c68dd7506aba0740083523bcf2df/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dada0fd85f13c68dd7506aba0740083523bcf2df/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=dada0fd85f13c68dd7506aba0740083523bcf2df",
            "patch": "@@ -5138,4 +5138,8 @@ def get_batch_samples(self, epoch_iterator, num_batches):\n \n         if self.args.average_tokens_across_devices:\n             num_items_in_batch = self.accelerator.gather(num_items_in_batch).sum().item()\n+\n+        if torch.is_tensor(num_items_in_batch):\n+            num_items_in_batch = num_items_in_batch.item()\n+\n         return batch_samples, num_items_in_batch"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 4,
        "deletions": 0
    }
}