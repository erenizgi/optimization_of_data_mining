{
    "author": "hsilva664",
    "message": "adding option to save/reload scaler (#34932)\n\n* Adding option to save/reload scaler\n\n* Removing duplicate variable\n\n* Adding save/reload test\n\n* Small fixes on deterministic algorithm call\n\n* Moving LLM test to another file to isolate its environment\n\n* Moving back to old file and using subprocess to run test isolated\n\n* Reverting back accidental change\n\n* Reverting back accidental change",
    "sha": "281c0c8b5b82d5b94e119ee58e7f82871c2653bc",
    "files": [
        {
            "sha": "677daa55ee401e556b9ec2f653f8016bb71523b8",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 44,
            "deletions": 1,
            "changes": 45,
            "blob_url": "https://github.com/huggingface/transformers/blob/281c0c8b5b82d5b94e119ee58e7f82871c2653bc/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/281c0c8b5b82d5b94e119ee58e7f82871c2653bc/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=281c0c8b5b82d5b94e119ee58e7f82871c2653bc",
            "patch": "@@ -305,9 +305,9 @@ def safe_globals():\n TRAINING_ARGS_NAME = \"training_args.bin\"\n TRAINER_STATE_NAME = \"trainer_state.json\"\n OPTIMIZER_NAME = \"optimizer.pt\"\n+SCALER_NAME = \"scaler.pt\"\n OPTIMIZER_NAME_BIN = \"optimizer.bin\"\n SCHEDULER_NAME = \"scheduler.pt\"\n-SCALER_NAME = \"scaler.pt\"\n FSDP_MODEL_NAME = \"pytorch_model_fsdp\"\n \n \n@@ -2394,6 +2394,7 @@ def _inner_training_loop(\n \n         # Check if saved optimizer or scheduler states exist\n         self._load_optimizer_and_scheduler(resume_from_checkpoint)\n+        self._load_scaler(resume_from_checkpoint)\n \n         # important: at this point:\n         # self.model         is the Transformers Model\n@@ -3191,6 +3192,7 @@ def _save_checkpoint(self, model, trial):\n         if not self.args.save_only_model:\n             # Save optimizer and scheduler\n             self._save_optimizer_and_scheduler(output_dir)\n+            self._save_scaler(output_dir)\n             # Save RNG state\n             self._save_rng_state(output_dir)\n \n@@ -3424,6 +3426,47 @@ def opt_load_hook(mod, opt):\n                     self.lr_scheduler.load_state_dict(torch.load(os.path.join(checkpoint, SCHEDULER_NAME)))\n                 reissue_pt_warnings(caught_warnings)\n \n+    def _save_scaler(self, output_dir):\n+        # See if there is a scaler attribute\n+        try:\n+            scaler = self.accelerator.scaler\n+        except AttributeError:\n+            return\n+        if scaler is None:\n+            return\n+        if is_torch_xla_available():\n+            xm.rendezvous(\"saving_scaler_state\")\n+            with warnings.catch_warnings(record=True) as caught_warnings:\n+                xm.save(self.accelerator.scaler.state_dict(), os.path.join(output_dir, SCALER_NAME))\n+                reissue_pt_warnings(caught_warnings)\n+\n+        # Save SCALER\n+        if self.args.should_save and not is_torch_xla_available():\n+            with warnings.catch_warnings(record=True) as caught_warnings:\n+                torch.save(self.accelerator.scaler.state_dict(), os.path.join(output_dir, SCALER_NAME))\n+            reissue_pt_warnings(caught_warnings)\n+\n+    def _load_scaler(self, checkpoint):\n+        \"\"\"If scaler state exists, load it.\"\"\"\n+        if checkpoint is None:\n+            return\n+\n+        checkpoint_file_exists = os.path.isfile(os.path.join(checkpoint, SCALER_NAME))\n+\n+        if checkpoint_file_exists:\n+            # On TPU we have to take some extra precautions to properly load the states on the right device.\n+            # Load in scaler states\n+            if is_torch_xla_available():\n+                with warnings.catch_warnings(record=True) as caught_warnings:\n+                    scaler_state = torch.load(os.path.join(checkpoint, SCALER_NAME), map_location=\"cpu\")\n+                reissue_pt_warnings(caught_warnings)\n+                xm.send_cpu_data_to_device(scaler_state, self.args.device)\n+                self.accelerator.scaler.load_state_dict(scaler_state)\n+            else:\n+                with warnings.catch_warnings(record=True) as caught_warnings:\n+                    self.accelerator.scaler.load_state_dict(torch.load(os.path.join(checkpoint, SCALER_NAME)))\n+                reissue_pt_warnings(caught_warnings)\n+\n     def _load_callback_state(self):\n         \"\"\"If callback states exist and were passed in, restore their states if enabled\"\"\"\n         if not self.args.restore_callback_states_from_checkpoint:"
        },
        {
            "sha": "3abf3eaee67ed24c34ac04f890a2ba91d469eb8c",
            "filename": "tests/trainer/test_trainer.py",
            "status": "modified",
            "additions": 87,
            "deletions": 1,
            "changes": 88,
            "blob_url": "https://github.com/huggingface/transformers/blob/281c0c8b5b82d5b94e119ee58e7f82871c2653bc/tests%2Ftrainer%2Ftest_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/281c0c8b5b82d5b94e119ee58e7f82871c2653bc/tests%2Ftrainer%2Ftest_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_trainer.py?ref=281c0c8b5b82d5b94e119ee58e7f82871c2653bc",
            "patch": "@@ -46,6 +46,7 @@\n     PretrainedConfig,\n     TrainerCallback,\n     TrainingArguments,\n+    enable_full_determinism,\n     get_polynomial_decay_schedule_with_warmup,\n     is_torch_available,\n     logging,\n@@ -97,6 +98,7 @@\n     require_torchdynamo,\n     require_vision,\n     require_wandb,\n+    run_test_using_subprocess,\n     slow,\n     torch_device,\n )\n@@ -576,13 +578,41 @@ def get_regression_trainer(\n             preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n         )\n \n+    def get_language_model_trainer(**kwargs):\n+        import datasets\n+\n+        dataset = datasets.load_dataset(\"fka/awesome-chatgpt-prompts\")\n+        model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n+        tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n+        tokenizer.pad_token = tokenizer.eos_token\n+\n+        def _tokenize_function(examples):\n+            model_inputs = tokenizer(examples[\"prompt\"], padding=\"max_length\", truncation=True)\n+            model_inputs[\"labels\"] = np.array(model_inputs[\"input_ids\"]).astype(np.int64)\n+            return model_inputs\n+\n+        tokenized_datasets = dataset.map(_tokenize_function, batched=True)\n+        training_args = TrainingArguments(**kwargs)\n+\n+        trainer = Trainer(\n+            model=model,\n+            args=training_args,\n+            train_dataset=tokenized_datasets[\"train\"],\n+        )\n+\n+        return trainer\n+\n \n class TrainerIntegrationCommon:\n-    def check_saved_checkpoints(self, output_dir, freq, total, is_pretrained=True, safe_weights=True):\n+    def check_saved_checkpoints(\n+        self, output_dir, freq, total, is_pretrained=True, safe_weights=True, use_scaler=False\n+    ):\n         weights_file = WEIGHTS_NAME if not safe_weights else SAFE_WEIGHTS_NAME\n         file_list = [weights_file, \"training_args.bin\", \"optimizer.pt\", \"scheduler.pt\", \"trainer_state.json\"]\n         if is_pretrained:\n             file_list.append(\"config.json\")\n+        if use_scaler:\n+            file_list.append(\"scaler.pt\")\n         for step in range(freq, total, freq):\n             checkpoint = os.path.join(output_dir, f\"checkpoint-{step}\")\n             self.assertTrue(os.path.isdir(checkpoint))\n@@ -3095,6 +3125,62 @@ def test_can_resume_training(self):\n             trainer.train(resume_from_checkpoint=True)\n         self.assertTrue(\"No valid checkpoint found in output directory\" in str(context.exception))\n \n+    # require_torch_non_multi_accelerator is necessary because this worker blocks runs when using multiple GPUs, making\n+    # the test slower.\n+    @require_torch_non_multi_accelerator\n+    @run_test_using_subprocess\n+    @slow\n+    def test_can_resume_training_lm(self):\n+        # Check if it works for a simple language modeling example\n+        training_steps = 10\n+        resume_from_step = 8\n+        with tempfile.TemporaryDirectory() as tmpdir:\n+            enable_full_determinism(0)\n+            kwargs = {\n+                \"output_dir\": tmpdir,\n+                \"fp16\": True,\n+                \"max_steps\": training_steps,\n+                \"per_device_train_batch_size\": 1,\n+                \"learning_rate\": 1e-5,\n+                \"lr_scheduler_type\": \"cosine\",\n+                \"save_strategy\": \"steps\",\n+                \"save_steps\": 1,\n+                \"logging_strategy\": \"steps\",\n+                \"logging_steps\": 1,\n+                \"report_to\": \"none\",\n+            }\n+\n+            trainer = get_language_model_trainer(**kwargs)\n+            trainer.train(resume_from_checkpoint=False)\n+            # Get the parameter length of the model\n+            model_params = torch.cat([p.cpu().flatten() for p in trainer.model.parameters()])\n+            model_param_len = len(model_params)\n+            # Sample uniform indexes and save the values of the parameters (considering an unrolled vector with\n+            # all of them)\n+            indices = torch.randint(0, model_param_len, (1000,))\n+            # Save the values of the parameters for later comparison\n+            model_params_sample = model_params[indices].detach().clone()\n+            state1 = dataclasses.asdict(trainer.state)\n+            # Delete the reference\n+            del model_params, trainer\n+            # Checks if all checkpoints are there, +1 is necessary because range is 1-indexed\n+            self.check_saved_checkpoints(\n+                tmpdir, freq=1, total=training_steps + 1, is_pretrained=True, safe_weights=True, use_scaler=True\n+            )\n+\n+            # Checkpoint at intermediate step\n+            enable_full_determinism(0)\n+            checkpoint = os.path.join(tmpdir, f\"checkpoint-{resume_from_step+1}\")\n+            trainer = get_language_model_trainer(**kwargs)\n+            trainer.train(resume_from_checkpoint=checkpoint)\n+            model_params = torch.cat([p.cpu().flatten() for p in trainer.model.parameters()])\n+\n+            # Check that the parameters are the same\n+            self.assertTrue(torch.allclose(model_params[indices], model_params_sample))\n+            state2 = dataclasses.asdict(trainer.state)\n+            self.check_trainer_state_are_the_same(state1, state2)\n+            del model_params, trainer\n+\n     @unittest.skip(\n         reason=\"@muellerzr: Fix once Trainer can take an accelerate configuration. Need to set `seedable_sampler=True`.\"\n     )"
        }
    ],
    "stats": {
        "total": 133,
        "additions": 131,
        "deletions": 2
    }
}