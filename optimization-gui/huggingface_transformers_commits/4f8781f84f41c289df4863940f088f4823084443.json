{
    "author": "albertvillanova",
    "message": "Remove invalid `@staticmethod` from module-level get_device_and_memory_breakdown (#41747)\n\nRemove staticmethod decorator from function",
    "sha": "4f8781f84f41c289df4863940f088f4823084443",
    "files": [
        {
            "sha": "28407c550e87a890c0a143138243bac2f31f7b18",
            "filename": "src/transformers/generation/continuous_batching/requests.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/4f8781f84f41c289df4863940f088f4823084443/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching%2Frequests.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4f8781f84f41c289df4863940f088f4823084443/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching%2Frequests.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching%2Frequests.py?ref=4f8781f84f41c289df4863940f088f4823084443",
            "patch": "@@ -27,7 +27,6 @@\n logger = logging.getLogger(\"ContinuousBatchingLogger\")\n \n \n-@staticmethod\n def get_device_and_memory_breakdown() -> tuple[torch.device, int, int, int]:\n     if torch.cuda.is_available():\n         device = torch.device(\"cuda\")"
        }
    ],
    "stats": {
        "total": 1,
        "additions": 0,
        "deletions": 1
    }
}