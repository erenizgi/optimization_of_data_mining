{
    "author": "zucchini-nlp",
    "message": "Blip: fix offloading and MP tests  (#35239)\n\n* fix device map\r\n\r\n* fix offloading + model parallel test",
    "sha": "14910281a7abd033695d0423c7d91f5276295a7f",
    "files": [
        {
            "sha": "27dbbee6c671ee10e7af8b5e3c97bedd1a3bb4f1",
            "filename": "src/transformers/models/blip/modeling_blip.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/14910281a7abd033695d0423c7d91f5276295a7f/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/14910281a7abd033695d0423c7d91f5276295a7f/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py?ref=14910281a7abd033695d0423c7d91f5276295a7f",
            "patch": "@@ -464,7 +464,8 @@ class BlipPreTrainedModel(PreTrainedModel):\n     config_class = BlipConfig\n     base_model_prefix = \"blip\"\n     supports_gradient_checkpointing = True\n-    _no_split_modules = [\"BlipEncoderLayer\"]\n+    _no_split_modules = [\"BlipEncoderLayer\", \"BlipTextEmbeddings\"]\n+    _skip_keys_device_placement = [\"past_key_value\"]\n \n     def _init_weights(self, module):\n         \"\"\"Initialize the weights\"\"\"\n@@ -1010,7 +1011,8 @@ def forward(\n         text_embeds = text_embeds / text_embeds.norm(p=2, dim=-1, keepdim=True)\n \n         # cosine similarity as logits\n-        logit_scale = self.logit_scale.exp()\n+        logit_scale = self.logit_scale.exp().to(device=text_embeds.device)\n+        image_embeds = image_embeds.to(device=text_embeds.device, dtype=text_embeds.dtype)\n         logits_per_text = torch.matmul(text_embeds, image_embeds.t()) * logit_scale\n         logits_per_image = logits_per_text.t()\n "
        },
        {
            "sha": "db8ad939725aca3f3593b6d31ec13863e39cead8",
            "filename": "src/transformers/models/blip/modeling_blip_text.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/14910281a7abd033695d0423c7d91f5276295a7f/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/14910281a7abd033695d0423c7d91f5276295a7f/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip_text.py?ref=14910281a7abd033695d0423c7d91f5276295a7f",
            "patch": "@@ -82,7 +82,6 @@ def forward(\n             position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]\n \n         if inputs_embeds is None:\n-            input_ids = input_ids.to(self.word_embeddings.weight.device)\n             inputs_embeds = self.word_embeddings(input_ids)\n \n         embeddings = inputs_embeds"
        }
    ],
    "stats": {
        "total": 7,
        "additions": 4,
        "deletions": 3
    }
}