{
    "author": "zucchini-nlp",
    "message": "Fix ckpt in docs (#41659)\n\n* fix ckpt in docs\n\n* fix config ckpt",
    "sha": "1eb45cd61dd9068e9ce53a216bd0bfa6f62d0548",
    "files": [
        {
            "sha": "5d66e4e7a8424afa2d2401319c85ae0890f1594d",
            "filename": "docs/source/en/model_doc/florence2.md",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/1eb45cd61dd9068e9ce53a216bd0bfa6f62d0548/docs%2Fsource%2Fen%2Fmodel_doc%2Fflorence2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/1eb45cd61dd9068e9ce53a216bd0bfa6f62d0548/docs%2Fsource%2Fen%2Fmodel_doc%2Fflorence2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fflorence2.md?ref=1eb45cd61dd9068e9ce53a216bd0bfa6f62d0548",
            "patch": "@@ -70,8 +70,8 @@ from transformers import AutoProcessor, Florence2ForConditionalGeneration\n url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg?download=true\"\n image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n \n-model = Florence2ForConditionalGeneration.from_pretrained(\"microsoft/Florence-2-base\", dtype=torch.bfloat16, device_map=\"auto\")\n-processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-base\")\n+model = Florence2ForConditionalGeneration.from_pretrained(\"florence-community/Florence-2-base\", dtype=torch.bfloat16, device_map=\"auto\")\n+processor = AutoProcessor.from_pretrained(\"florence-community/Florence-2-base\")\n \n task_prompt = \"<OD>\"\n inputs = processor(text=task_prompt, images=image, return_tensors=\"pt\").to(model.device)\n@@ -105,12 +105,12 @@ from transformers import AutoProcessor, Florence2ForConditionalGeneration, BitsA\n quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n \n model = Florence2ForConditionalGeneration.from_pretrained(\n-    \"microsoft/Florence-2-large\",\n+    \"florence-community/Florence-2-base\",\n     dtype=torch.bfloat16,\n     device_map=\"auto\",\n     quantization_config=quantization_config\n )\n-processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-large\")\n+processor = AutoProcessor.from_pretrained(\"florence-community/Florence-2-base\")\n \n url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg?download=true\"\n image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")"
        },
        {
            "sha": "c2e6bff992850dc13741003b65d565f86a2bf351",
            "filename": "src/transformers/models/florence2/configuration_florence2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/1eb45cd61dd9068e9ce53a216bd0bfa6f62d0548/src%2Ftransformers%2Fmodels%2Fflorence2%2Fconfiguration_florence2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1eb45cd61dd9068e9ce53a216bd0bfa6f62d0548/src%2Ftransformers%2Fmodels%2Fflorence2%2Fconfiguration_florence2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflorence2%2Fconfiguration_florence2.py?ref=1eb45cd61dd9068e9ce53a216bd0bfa6f62d0548",
            "patch": "@@ -140,7 +140,7 @@ class Florence2Config(PreTrainedConfig):\n     Florence-2 model according to the specified arguments, defining the model architecture.\n \n     Instantiating a configuration with the defaults will yield a similar configuration to that of the Florence-2\n-    [microsoft/Florence-2-base](https://huggingface.co/microsoft/Florence-2-base) architecture.\n+    [florence-community/Florence-2-base](https://huggingface.co/florence-community/Florence-2-base) architecture.\n \n     Configuration objects inherit from [`PreTrainedConfig`] and can be used to control the model outputs. Read the\n     documentation from [`PreTrainedConfig`] for more information."
        },
        {
            "sha": "4e1250231a99b12031a8c7fc5d42c99c733afb42",
            "filename": "src/transformers/models/florence2/modeling_florence2.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/1eb45cd61dd9068e9ce53a216bd0bfa6f62d0548/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodeling_florence2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1eb45cd61dd9068e9ce53a216bd0bfa6f62d0548/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodeling_florence2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodeling_florence2.py?ref=1eb45cd61dd9068e9ce53a216bd0bfa6f62d0548",
            "patch": "@@ -884,8 +884,8 @@ def forward(\n         >>> import requests\n         >>> from transformers import AutoProcessor, Florence2ForConditionalGeneration\n \n-        >>> model = Florence2ForConditionalGeneration.from_pretrained(\"microsoft/Florence-2-large\")\n-        >>> processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-large\")\n+        >>> model = Florence2ForConditionalGeneration.from_pretrained(\"florence-community/Florence-2-large\")\n+        >>> processor = AutoProcessor.from_pretrained(\"florence-community/Florence-2-large\")\n \n         >>> prompt = \"<CAPTION>\"\n         >>> url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg\""
        },
        {
            "sha": "6ae43c0b69a753df608f717d1c2990bc60a7a809",
            "filename": "src/transformers/models/florence2/modular_florence2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/1eb45cd61dd9068e9ce53a216bd0bfa6f62d0548/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodular_florence2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1eb45cd61dd9068e9ce53a216bd0bfa6f62d0548/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodular_florence2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodular_florence2.py?ref=1eb45cd61dd9068e9ce53a216bd0bfa6f62d0548",
            "patch": "@@ -160,7 +160,7 @@ class Florence2Config(PreTrainedConfig):\n     Florence-2 model according to the specified arguments, defining the model architecture.\n \n     Instantiating a configuration with the defaults will yield a similar configuration to that of the Florence-2\n-    [microsoft/Florence-2-base](https://huggingface.co/microsoft/Florence-2-base) architecture.\n+    [florence-community/Florence-2-base](https://huggingface.co/florence-community/Florence-2-base) architecture.\n \n     Configuration objects inherit from [`PreTrainedConfig`] and can be used to control the model outputs. Read the\n     documentation from [`PreTrainedConfig`] for more information.\n@@ -1674,8 +1674,8 @@ def forward(\n         >>> import requests\n         >>> from transformers import AutoProcessor, Florence2ForConditionalGeneration\n \n-        >>> model = Florence2ForConditionalGeneration.from_pretrained(\"microsoft/Florence-2-large\")\n-        >>> processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-large\")\n+        >>> model = Florence2ForConditionalGeneration.from_pretrained(\"florence-community/Florence-2-large\")\n+        >>> processor = AutoProcessor.from_pretrained(\"florence-community/Florence-2-large\")\n \n         >>> prompt = \"<CAPTION>\"\n         >>> url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg\""
        }
    ],
    "stats": {
        "total": 20,
        "additions": 10,
        "deletions": 10
    }
}