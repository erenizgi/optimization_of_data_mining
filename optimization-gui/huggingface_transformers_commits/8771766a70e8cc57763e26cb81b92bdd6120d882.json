{
    "author": "yonigozlan",
    "message": "Fix InternVL interpolate_pos_encoding and add to video_processing_auto (#38092)\n\n* fix InternVL interpolate_pos_encoding\n\n* fix modular and auto_video_processor for internvl",
    "sha": "8771766a70e8cc57763e26cb81b92bdd6120d882",
    "files": [
        {
            "sha": "0382ad65098432fa2592b3b897e41e3eb873e60a",
            "filename": "src/transformers/models/auto/video_processing_auto.py",
            "status": "modified",
            "additions": 2,
            "deletions": 7,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/8771766a70e8cc57763e26cb81b92bdd6120d882/src%2Ftransformers%2Fmodels%2Fauto%2Fvideo_processing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8771766a70e8cc57763e26cb81b92bdd6120d882/src%2Ftransformers%2Fmodels%2Fauto%2Fvideo_processing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fvideo_processing_auto.py?ref=8771766a70e8cc57763e26cb81b92bdd6120d882",
            "patch": "@@ -24,13 +24,7 @@\n # Build the list of all video processors\n from ...configuration_utils import PretrainedConfig\n from ...dynamic_module_utils import get_class_from_dynamic_module, resolve_trust_remote_code\n-from ...utils import (\n-    CONFIG_NAME,\n-    VIDEO_PROCESSOR_NAME,\n-    cached_file,\n-    is_torchvision_available,\n-    logging,\n-)\n+from ...utils import CONFIG_NAME, VIDEO_PROCESSOR_NAME, cached_file, is_torchvision_available, logging\n from ...utils.import_utils import requires\n from ...video_processing_utils import BaseVideoProcessor\n from .auto_factory import _LazyAutoMapping\n@@ -53,6 +47,7 @@\n     VIDEO_PROCESSOR_MAPPING_NAMES = OrderedDict(\n         [\n             (\"instructblipvideo\", \"InstructBlipVideoVideoProcessor\"),\n+            (\"internvl\", \"InternVLVideoProcessor\"),\n             (\"llava_next_video\", \"LlavaNextVideoVideoProcessor\"),\n             (\"llava_onevision\", \"LlavaOnevisionVideoProcessor\"),\n             (\"qwen2_5_vl\", \"Qwen2_5_VLVideoProcessor\"),"
        },
        {
            "sha": "106aaaa3c3611f9099a198dc6a4f9903aa5f673b",
            "filename": "src/transformers/models/internvl/modeling_internvl.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/8771766a70e8cc57763e26cb81b92bdd6120d882/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodeling_internvl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8771766a70e8cc57763e26cb81b92bdd6120d882/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodeling_internvl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodeling_internvl.py?ref=8771766a70e8cc57763e26cb81b92bdd6120d882",
            "patch": "@@ -329,8 +329,8 @@ def interpolate_pos_encoding(self, embeddings: torch.Tensor, height: int, width:\n \n         dim = embeddings.shape[-1]\n \n-        new_height = height // self.patch_size\n-        new_width = width // self.patch_size\n+        new_height = height // self.patch_size[0]\n+        new_width = width // self.patch_size[1]\n \n         sqrt_num_positions = torch_int(num_positions**0.5)\n         patch_pos_embed = patch_pos_embed.reshape(1, sqrt_num_positions, sqrt_num_positions, dim)"
        },
        {
            "sha": "b4e1efe3487af9a0e5ff0a9fc6a328a7d3c432a8",
            "filename": "src/transformers/models/internvl/modular_internvl.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/8771766a70e8cc57763e26cb81b92bdd6120d882/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodular_internvl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8771766a70e8cc57763e26cb81b92bdd6120d882/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodular_internvl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finternvl%2Fmodular_internvl.py?ref=8771766a70e8cc57763e26cb81b92bdd6120d882",
            "patch": "@@ -286,8 +286,8 @@ def interpolate_pos_encoding(self, embeddings: torch.Tensor, height: int, width:\n \n         dim = embeddings.shape[-1]\n \n-        new_height = height // self.patch_size\n-        new_width = width // self.patch_size\n+        new_height = height // self.patch_size[0]\n+        new_width = width // self.patch_size[1]\n \n         sqrt_num_positions = torch_int(num_positions**0.5)\n         patch_pos_embed = patch_pos_embed.reshape(1, sqrt_num_positions, sqrt_num_positions, dim)"
        }
    ],
    "stats": {
        "total": 17,
        "additions": 6,
        "deletions": 11
    }
}