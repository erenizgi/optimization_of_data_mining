{
    "author": "Cyrilvallez",
    "message": "Fix device in rope module when using dynamic updates (#35608)\n\nfix rope device",
    "sha": "cd44bdb4b895b9e442476ee556d53ec71f9efe87",
    "files": [
        {
            "sha": "43bf1c22687fe235dd3c129fb5fe23332563e575",
            "filename": "src/transformers/models/aria/modeling_aria.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faria%2Fmodeling_aria.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -754,6 +754,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "30017181738eeebb9fc548e1dedc372745ca030c",
            "filename": "src/transformers/models/bamba/modeling_bamba.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodeling_bamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodeling_bamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbamba%2Fmodeling_bamba.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -150,6 +150,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "0d0d6ccf9e859c1382bcca10309acebdd58ef316",
            "filename": "src/transformers/models/cohere/modeling_cohere.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fcohere%2Fmodeling_cohere.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fcohere%2Fmodeling_cohere.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere%2Fmodeling_cohere.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -103,6 +103,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "9811c02163aa6712d80d4ce7dfb205ad45cfb81f",
            "filename": "src/transformers/models/cohere2/modeling_cohere2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodeling_cohere2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodeling_cohere2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcohere2%2Fmodeling_cohere2.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -77,6 +77,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "fc1e38549b7e1aaa1daf9c3126fdb759ff1d7057",
            "filename": "src/transformers/models/diffllama/modeling_diffllama.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fdiffllama%2Fmodeling_diffllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fdiffllama%2Fmodeling_diffllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdiffllama%2Fmodeling_diffllama.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -643,6 +643,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "557f63338a1f027dd5d0cfc31024ba9a226b8e5d",
            "filename": "src/transformers/models/emu3/modeling_emu3.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Femu3%2Fmodeling_emu3.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -1227,6 +1227,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "c0fad1ab66d53da6294cafe48a42fb96adbebfd9",
            "filename": "src/transformers/models/falcon/modeling_falcon.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Ffalcon%2Fmodeling_falcon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Ffalcon%2Fmodeling_falcon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffalcon%2Fmodeling_falcon.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -140,6 +140,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "66e975edaa53cb0fb3751d0ce04371df085e2a79",
            "filename": "src/transformers/models/gemma/modeling_gemma.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fgemma%2Fmodeling_gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fgemma%2Fmodeling_gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma%2Fmodeling_gemma.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -122,6 +122,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "116504a7312799d42d0af0bb2eecc656b958441f",
            "filename": "src/transformers/models/gemma2/modeling_gemma2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma2%2Fmodeling_gemma2.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -354,6 +354,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "3e5107c561df092c07ab02a7f645bf541da5414a",
            "filename": "src/transformers/models/glm/modeling_glm.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fglm%2Fmodeling_glm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fglm%2Fmodeling_glm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm%2Fmodeling_glm.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -285,6 +285,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "beed2430b44b5c5f6303c4ca4025632b839af767",
            "filename": "src/transformers/models/gpt_neox/modeling_gpt_neox.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fgpt_neox%2Fmodeling_gpt_neox.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fgpt_neox%2Fmodeling_gpt_neox.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_neox%2Fmodeling_gpt_neox.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -521,6 +521,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "6a9ae6b50f9012c9818f0653ac3e3f15807d6af3",
            "filename": "src/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fgpt_neox_japanese%2Fmodeling_gpt_neox_japanese.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fgpt_neox_japanese%2Fmodeling_gpt_neox_japanese.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_neox_japanese%2Fmodeling_gpt_neox_japanese.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -255,6 +255,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "3c887d3a1b91fcdee553e3f241bb5eb5ccb8a064",
            "filename": "src/transformers/models/granite/modeling_granite.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fgranite%2Fmodeling_granite.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fgranite%2Fmodeling_granite.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranite%2Fmodeling_granite.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -339,6 +339,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "77ab0cece3eacdb505aa02f7275d569a2acad2e0",
            "filename": "src/transformers/models/granitemoe/modeling_granitemoe.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranitemoe%2Fmodeling_granitemoe.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -188,6 +188,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "433ca61fabec781d7df6c2f990727e29470d1547",
            "filename": "src/transformers/models/jetmoe/modeling_jetmoe.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjetmoe%2Fmodeling_jetmoe.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -416,6 +416,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "8cbb12628c0a39acdbd9bd5f28191273c81ba064",
            "filename": "src/transformers/models/llama/modeling_llama.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fllama%2Fmodeling_llama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fllama%2Fmodeling_llama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllama%2Fmodeling_llama.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -110,6 +110,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "8342f83cfc54dd133b7ec4aa1b04fa3c6ec00fac",
            "filename": "src/transformers/models/mimi/modeling_mimi.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fmimi%2Fmodeling_mimi.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fmimi%2Fmodeling_mimi.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmimi%2Fmodeling_mimi.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -395,6 +395,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "635cda9cc8f096693f396d038b7d8db60ddd7b21",
            "filename": "src/transformers/models/mistral/modeling_mistral.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodeling_mistral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodeling_mistral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmistral%2Fmodeling_mistral.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -300,6 +300,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "8cf2d0e8fa8da90fc632349e48bf929135049600",
            "filename": "src/transformers/models/mixtral/modeling_mixtral.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -422,6 +422,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "2fa5a08acc4831d20303b17576c46aa4cf085233",
            "filename": "src/transformers/models/modernbert/modeling_modernbert.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodeling_modernbert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodeling_modernbert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmodernbert%2Fmodeling_modernbert.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -271,6 +271,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "50894e3cff44fbe757cccf3bf7bcfb704c239bd4",
            "filename": "src/transformers/models/moonshine/modeling_moonshine.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodeling_moonshine.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodeling_moonshine.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmoonshine%2Fmodeling_moonshine.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -319,6 +319,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "35e107d7cb7a8c4ea446a30f3c43a04da867023c",
            "filename": "src/transformers/models/moshi/modeling_moshi.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fmoshi%2Fmodeling_moshi.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fmoshi%2Fmodeling_moshi.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmoshi%2Fmodeling_moshi.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -338,6 +338,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "54f774f0b942c58bc803c3911d0fda5d6981cfdd",
            "filename": "src/transformers/models/nemotron/modeling_nemotron.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fnemotron%2Fmodeling_nemotron.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fnemotron%2Fmodeling_nemotron.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fnemotron%2Fmodeling_nemotron.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -117,6 +117,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "34e9f7259cdfff1299f2da9f330779879fde0032",
            "filename": "src/transformers/models/olmo/modeling_olmo.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Folmo%2Fmodeling_olmo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Folmo%2Fmodeling_olmo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmo%2Fmodeling_olmo.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -304,6 +304,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "a6a19265015b6e77848d8e3156f189e9aeb3a894",
            "filename": "src/transformers/models/olmo2/modeling_olmo2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Folmo2%2Fmodeling_olmo2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Folmo2%2Fmodeling_olmo2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmo2%2Fmodeling_olmo2.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -305,6 +305,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "5c78138c1a035155564955fdf33819a19c6de64a",
            "filename": "src/transformers/models/olmoe/modeling_olmoe.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -188,6 +188,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "8336ab5a2cf5298196cd2aef7b9b0d4f86d5b515",
            "filename": "src/transformers/models/persimmon/modeling_persimmon.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fpersimmon%2Fmodeling_persimmon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fpersimmon%2Fmodeling_persimmon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpersimmon%2Fmodeling_persimmon.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -87,6 +87,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "08d9eddd9e2f9dd51a7a417e85dbd4326c0dca8a",
            "filename": "src/transformers/models/phi/modeling_phi.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fphi%2Fmodeling_phi.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fphi%2Fmodeling_phi.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi%2Fmodeling_phi.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -300,6 +300,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "cf905cb62e90008544c9ba952b27b47ca1cde0cc",
            "filename": "src/transformers/models/phi3/modeling_phi3.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodeling_phi3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodeling_phi3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodeling_phi3.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -348,6 +348,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n \n@@ -390,6 +393,9 @@ def _longrope_frequency_update(self, position_ids, device):\n                 )\n             self.register_buffer(\"inv_freq\", self.long_inv_freq, persistent=False)\n         else:\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n \n "
        },
        {
            "sha": "2b1a19be4ae2c96280c6b8422e0819c6edde9955",
            "filename": "src/transformers/models/phi3/modular_phi3.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodular_phi3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodular_phi3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi3%2Fmodular_phi3.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -230,6 +230,9 @@ def _longrope_frequency_update(self, position_ids, device):\n                 )\n             self.register_buffer(\"inv_freq\", self.long_inv_freq, persistent=False)\n         else:\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n \n     @torch.no_grad()"
        },
        {
            "sha": "f8be4e3740f4b138d03f4f4b75aeeaccbec013e7",
            "filename": "src/transformers/models/qwen2/modeling_qwen2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodeling_qwen2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodeling_qwen2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2%2Fmodeling_qwen2.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -313,6 +313,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "0f61323f403083d6f6afbb468fddea8bd8c5d75d",
            "filename": "src/transformers/models/qwen2_moe/modeling_qwen2_moe.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -197,6 +197,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "4cdab6dc4d2db5e0d5001eb10e4781d2fdfb49b6",
            "filename": "src/transformers/models/stablelm/modeling_stablelm.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fstablelm%2Fmodeling_stablelm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fstablelm%2Fmodeling_stablelm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fstablelm%2Fmodeling_stablelm.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -93,6 +93,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        },
        {
            "sha": "8620c7d69d56a2a884adfb4400d7230c5fac8e0d",
            "filename": "src/transformers/models/starcoder2/modeling_starcoder2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodeling_starcoder2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cd44bdb4b895b9e442476ee556d53ec71f9efe87/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodeling_starcoder2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fstarcoder2%2Fmodeling_starcoder2.py?ref=cd44bdb4b895b9e442476ee556d53ec71f9efe87",
            "patch": "@@ -304,6 +304,9 @@ def _dynamic_frequency_update(self, position_ids, device):\n             self.max_seq_len_cached = seq_len\n \n         if seq_len < self.original_max_seq_len and self.max_seq_len_cached > self.original_max_seq_len:  # reset\n+            # This .to() is needed if the model has been moved to a device after being initialized (because\n+            # the buffer is automatically moved, but not the original copy)\n+            self.original_inv_freq = self.original_inv_freq.to(device)\n             self.register_buffer(\"inv_freq\", self.original_inv_freq, persistent=False)\n             self.max_seq_len_cached = self.original_max_seq_len\n "
        }
    ],
    "stats": {
        "total": 105,
        "additions": 105,
        "deletions": 0
    }
}