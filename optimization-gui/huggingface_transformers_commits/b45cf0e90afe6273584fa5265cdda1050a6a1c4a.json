{
    "author": "dmlap",
    "message": "Guard against unset resolved_archive_file (#35628)\n\n* archive_file may not be specified\r\nWhen loading a pre-trained model from a gguf file, resolved_archive_file may not be set. Guard against that case in the safetensors availability check.\r\n\r\n* Remap partial disk offload to cpu for GGUF files\r\nGGUF files don't support disk offload so attempt to remap them to the CPU when device_map is auto. If device_map is anything else but None, raise a NotImplementedError.\r\n\r\n* Don't remap auto device_map and raise RuntimeError\r\nIf device_map=auto and modules are selected for disk offload, don't attempt to map them to any other device. Raise a runtime error when a GGUF model is configured to map any modules to disk.\r\n\r\n---------\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>",
    "sha": "b45cf0e90afe6273584fa5265cdda1050a6a1c4a",
    "files": [
        {
            "sha": "b75151992c58fd65481bbf387d355b8bd85416cd",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/b45cf0e90afe6273584fa5265cdda1050a6a1c4a/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b45cf0e90afe6273584fa5265cdda1050a6a1c4a/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=b45cf0e90afe6273584fa5265cdda1050a6a1c4a",
            "patch": "@@ -4267,6 +4267,12 @@ def from_pretrained(\n             # check if we don't have tied param in different devices\n             check_tied_parameters_on_same_device(tied_params, device_map)\n \n+        if gguf_path and device_map is not None and \"disk\" in device_map.values():\n+            raise RuntimeError(\n+                \"One or more modules is configured to be mapped to disk. Disk offload is not supported for models \"\n+                \"loaded from GGUF files.\"\n+            )\n+\n         if from_tf:\n             if resolved_archive_file.endswith(\".index\"):\n                 # Load from a TensorFlow 1.X checkpoint - provided by original authors\n@@ -4525,7 +4531,7 @@ def _load_pretrained_model(\n             archive_file = (\n                 resolved_archive_file[0] if isinstance(resolved_archive_file, (list, tuple)) else resolved_archive_file\n             )\n-            is_safetensors = archive_file.endswith(\".safetensors\")\n+            is_safetensors = archive_file is not None and archive_file.endswith(\".safetensors\")\n             if offload_folder is None and not is_safetensors:\n                 raise ValueError(\n                     \"The current `device_map` had weights offloaded to the disk. Please provide an `offload_folder`\""
        },
        {
            "sha": "efba55d42b80db82ec126977be4236c60d4631c9",
            "filename": "tests/quantization/ggml/test_ggml.py",
            "status": "modified",
            "additions": 43,
            "deletions": 0,
            "changes": 43,
            "blob_url": "https://github.com/huggingface/transformers/blob/b45cf0e90afe6273584fa5265cdda1050a6a1c4a/tests%2Fquantization%2Fggml%2Ftest_ggml.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b45cf0e90afe6273584fa5265cdda1050a6a1c4a/tests%2Fquantization%2Fggml%2Ftest_ggml.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fquantization%2Fggml%2Ftest_ggml.py?ref=b45cf0e90afe6273584fa5265cdda1050a6a1c4a",
            "patch": "@@ -219,6 +219,49 @@ def test_q6_k_fp16(self):\n         EXPECTED_TEXT = \"Hello, World!\\n\\nStep 3: Add\"\n         self.assertEqual(tokenizer.decode(out[0], skip_special_tokens=True), EXPECTED_TEXT)\n \n+    def test_gguf_errors_disk_offload(self):\n+        from collections import OrderedDict\n+\n+        q2_k_gguf_model_id = self.gguf_filename.format(quant_type=QuantType.Q2_K.name)\n+        with self.assertRaises(RuntimeError):\n+            AutoModelForCausalLM.from_pretrained(\n+                self.gguf_model_id,\n+                device_map=OrderedDict(\n+                    [\n+                        (\"model.embed_tokens\", \"cpu\"),\n+                        (\"lm_head\", \"cpu\"),\n+                        (\"model.layers.0\", \"cpu\"),\n+                        (\"model.layers.1\", \"cpu\"),\n+                        (\"model.layers.2\", \"cpu\"),\n+                        (\"model.layers.3\", \"cpu\"),\n+                        (\"model.layers.4\", \"cpu\"),\n+                        (\"model.layers.5\", \"cpu\"),\n+                        (\"model.layers.6\", \"cpu\"),\n+                        (\"model.layers.7\", \"cpu\"),\n+                        (\"model.layers.8\", \"cpu\"),\n+                        (\"model.layers.9\", \"cpu\"),\n+                        (\"model.layers.10\", \"disk\"),\n+                        (\"model.layers.11\", \"disk\"),\n+                        (\"model.layers.12\", \"disk\"),\n+                        (\"model.layers.13\", \"disk\"),\n+                        (\"model.layers.14\", \"disk\"),\n+                        (\"model.layers.15\", \"disk\"),\n+                        (\"model.layers.16\", \"disk\"),\n+                        (\"model.layers.17\", \"disk\"),\n+                        (\"model.layers.18\", \"disk\"),\n+                        (\"model.layers.19\", \"disk\"),\n+                        (\"model.layers.20\", \"disk\"),\n+                        (\"model.layers.21\", \"disk\"),\n+                        (\"model.layers.22\", \"disk\"),\n+                        (\"model.norm\", \"disk\"),\n+                        (\"model.rotary_emb\", \"disk\"),\n+                    ]\n+                ),\n+                gguf_file=q2_k_gguf_model_id,\n+                offload_folder=\"offload\",\n+                offload_state_dict=True,\n+            )\n+\n \n @require_gguf\n @require_torch_gpu"
        }
    ],
    "stats": {
        "total": 51,
        "additions": 50,
        "deletions": 1
    }
}