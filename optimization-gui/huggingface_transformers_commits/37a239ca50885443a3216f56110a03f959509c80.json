{
    "author": "ydshieh",
    "message": "Update expected values (after switching to A10) - part 3 (#39179)\n\n* fix\n\n* fix\n\n* fix\n\n* fix\n\n* fix\n\n* fix\n\n* fix\n\n* fix\n\n* fix\n\n* fix\n\n* fix\n\n* fix\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "37a239ca50885443a3216f56110a03f959509c80",
    "files": [
        {
            "sha": "eb968ad9f686d0bc3ea1f340d8211f9babec4b03",
            "filename": "tests/models/dpt/test_modeling_dpt.py",
            "status": "modified",
            "additions": 9,
            "deletions": 5,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt.py?ref=37a239ca50885443a3216f56110a03f959509c80",
            "patch": "@@ -18,7 +18,7 @@\n from transformers import DPTConfig\n from transformers.file_utils import is_torch_available, is_vision_available\n from transformers.pytorch_utils import is_torch_greater_or_equal_than_2_4\n-from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n+from transformers.testing_utils import Expectations, require_torch, require_vision, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n@@ -342,11 +342,15 @@ def test_inference_depth_estimation(self):\n         expected_shape = torch.Size((1, 384, 384))\n         self.assertEqual(predicted_depth.shape, expected_shape)\n \n-        expected_slice = torch.tensor(\n-            [[6.3199, 6.3629, 6.4148], [6.3850, 6.3615, 6.4166], [6.3519, 6.3176, 6.3575]]\n-        ).to(torch_device)\n+        expectations = Expectations(\n+            {\n+                (None, None): [[6.3199, 6.3629, 6.4148], [6.3850, 6.3615, 6.4166], [6.3519, 6.3176, 6.3575]],\n+                (\"cuda\", 8): [[6.3215, 6.3635, 6.4155], [6.3863, 6.3622, 6.4174], [6.3530, 6.3184, 6.3583]],\n+            }\n+        )\n+        expected_slice = torch.tensor(expectations.get_expectation()).to(torch_device)\n \n-        torch.testing.assert_close(outputs.predicted_depth[0, :3, :3], expected_slice, rtol=1e-4, atol=1e-4)\n+        torch.testing.assert_close(outputs.predicted_depth[0, :3, :3], expected_slice, rtol=2e-4, atol=2e-4)\n \n     def test_inference_semantic_segmentation(self):\n         image_processor = DPTImageProcessor.from_pretrained(\"Intel/dpt-large-ade\")"
        },
        {
            "sha": "1505be27cf724ec96ea7f51c07a22ecc9beb891d",
            "filename": "tests/models/dpt/test_modeling_dpt_auto_backbone.py",
            "status": "modified",
            "additions": 41,
            "deletions": 13,
            "changes": 54,
            "blob_url": "https://github.com/huggingface/transformers/blob/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_auto_backbone.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_auto_backbone.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_auto_backbone.py?ref=37a239ca50885443a3216f56110a03f959509c80",
            "patch": "@@ -17,7 +17,7 @@\n \n from transformers import Dinov2Config, DPTConfig\n from transformers.file_utils import is_torch_available, is_vision_available\n-from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n+from transformers.testing_utils import Expectations, require_torch, require_vision, slow, torch_device\n from transformers.utils.import_utils import get_torch_major_and_minor_version\n \n from ...test_configuration_common import ConfigTester\n@@ -267,11 +267,15 @@ def test_inference_depth_estimation_dinov2(self):\n         expected_shape = torch.Size((1, 576, 736))\n         self.assertEqual(predicted_depth.shape, expected_shape)\n \n-        expected_slice = torch.tensor(\n-            [[6.0336, 7.1502, 7.4130], [6.8977, 7.2383, 7.2268], [7.9180, 8.0525, 8.0134]]\n-        ).to(torch_device)\n+        expectations = Expectations(\n+            {\n+                (None, None): [[6.0336, 7.1502, 7.4130], [6.8977, 7.2383, 7.2268], [7.9180, 8.0525, 8.0134]],\n+                (\"cuda\", 8): [[6.0350, 7.1518, 7.4144], [6.8992, 7.2396, 7.2280], [7.9194, 8.0538, 8.0145]],\n+            }\n+        )\n+        expected_slice = torch.tensor(expectations.get_expectation()).to(torch_device)\n \n-        torch.testing.assert_close(outputs.predicted_depth[0, :3, :3], expected_slice, rtol=1e-4, atol=1e-4)\n+        torch.testing.assert_close(outputs.predicted_depth[0, :3, :3], expected_slice, rtol=2e-4, atol=2e-4)\n \n     def test_inference_depth_estimation_beit(self):\n         image_processor = DPTImageProcessor.from_pretrained(\"Intel/dpt-beit-base-384\")\n@@ -289,11 +293,23 @@ def test_inference_depth_estimation_beit(self):\n         expected_shape = torch.Size((1, 384, 384))\n         self.assertEqual(predicted_depth.shape, expected_shape)\n \n-        expected_slice = torch.tensor(\n-            [[2669.7061, 2663.7144, 2674.9399], [2633.9326, 2650.9092, 2665.4270], [2621.8271, 2632.0129, 2637.2290]]\n-        ).to(torch_device)\n+        expectations = Expectations(\n+            {\n+                (None, None): [\n+                    [2669.7061, 2663.7144, 2674.9399],\n+                    [2633.9326, 2650.9092, 2665.4270],\n+                    [2621.8271, 2632.0129, 2637.2290],\n+                ],\n+                (\"cuda\", 8): [\n+                    [2669.4292, 2663.4121, 2674.6233],\n+                    [2633.7400, 2650.7026, 2665.2085],\n+                    [2621.6572, 2631.8452, 2637.0525],\n+                ],\n+            }\n+        )\n+        expected_slice = torch.tensor(expectations.get_expectation()).to(torch_device)\n \n-        torch.testing.assert_close(outputs.predicted_depth[0, :3, :3], expected_slice, rtol=1e-4, atol=1e-4)\n+        torch.testing.assert_close(outputs.predicted_depth[0, :3, :3], expected_slice, rtol=2e-4, atol=2e-4)\n \n     def test_inference_depth_estimation_swinv2(self):\n         image_processor = DPTImageProcessor.from_pretrained(\"Intel/dpt-swinv2-tiny-256\")\n@@ -311,8 +327,20 @@ def test_inference_depth_estimation_swinv2(self):\n         expected_shape = torch.Size((1, 256, 256))\n         self.assertEqual(predicted_depth.shape, expected_shape)\n \n-        expected_slice = torch.tensor(\n-            [[1032.7719, 1025.1886, 1030.2661], [1023.7619, 1021.0075, 1024.9121], [1022.5667, 1018.8522, 1021.4145]]\n-        ).to(torch_device)\n+        expectations = Expectations(\n+            {\n+                (None, None): [\n+                    [1032.7719, 1025.1886, 1030.2661],\n+                    [1023.7619, 1021.0075, 1024.9121],\n+                    [1022.5667, 1018.8522, 1021.4145],\n+                ],\n+                (\"cuda\", 8): [\n+                    [1032.7170, 1025.0629, 1030.1941],\n+                    [1023.7309, 1020.9786, 1024.8594],\n+                    [1022.5233, 1018.8235, 1021.3312],\n+                ],\n+            }\n+        )\n+        expected_slice = torch.tensor(expectations.get_expectation()).to(torch_device)\n \n-        torch.testing.assert_close(outputs.predicted_depth[0, :3, :3], expected_slice, rtol=1e-4, atol=1e-4)\n+        torch.testing.assert_close(outputs.predicted_depth[0, :3, :3], expected_slice, rtol=2e-4, atol=2e-4)"
        },
        {
            "sha": "79cad886db4097163de4156fd4d8bd4245daa230",
            "filename": "tests/models/dpt/test_modeling_dpt_hybrid.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_hybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_hybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_hybrid.py?ref=37a239ca50885443a3216f56110a03f959509c80",
            "patch": "@@ -194,6 +194,9 @@ def setUp(self):\n     def test_config(self):\n         self.config_tester.run_common_tests()\n \n+    def test_batching_equivalence(self, atol=2e-5, rtol=2e-5):\n+        super().test_batching_equivalence(atol=atol, rtol=rtol)\n+\n     @unittest.skip(reason=\"DPT does not use inputs_embeds\")\n     def test_inputs_embeds(self):\n         pass"
        },
        {
            "sha": "670756a9bfacee626fdc3b1058a97603f45ca218",
            "filename": "tests/models/oneformer/test_modeling_oneformer.py",
            "status": "modified",
            "additions": 23,
            "deletions": 9,
            "changes": 32,
            "blob_url": "https://github.com/huggingface/transformers/blob/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Foneformer%2Ftest_modeling_oneformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Foneformer%2Ftest_modeling_oneformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Foneformer%2Ftest_modeling_oneformer.py?ref=37a239ca50885443a3216f56110a03f959509c80",
            "patch": "@@ -21,6 +21,7 @@\n from tests.test_modeling_common import floats_tensor\n from transformers import AutoModelForImageClassification, OneFormerConfig, is_torch_available, is_vision_available\n from transformers.testing_utils import (\n+    Expectations,\n     is_flaky,\n     require_timm,\n     require_torch,\n@@ -528,7 +529,7 @@ def test_backbone_selection(self):\n                 self.assertEqual(model.model.pixel_level_module.encoder.out_indices, [1, 2, 3])\n \n \n-TOLERANCE = 1e-4\n+TOLERANCE = 2e-4\n \n \n # We will verify our results on an image of cute cats\n@@ -574,12 +575,15 @@ def test_inference_no_head(self):\n         slice_hidden_state = outputs.pixel_decoder_hidden_states[0][0, 0, :3, :3]\n         torch.testing.assert_close(slice_hidden_state, expected_slice_hidden_state, atol=TOLERANCE, rtol=TOLERANCE)\n \n-        # fmt: off\n-        expected_slice_hidden_state = [[3.0668, -1.1833, -5.1103], [3.344, -3.362, -5.1101], [2.6017, -4.3613, -4.1444]]\n-        expected_slice_hidden_state = torch.tensor(expected_slice_hidden_state).to(torch_device)\n+        expectations = Expectations(\n+            {\n+                (None, None): [[3.0668, -1.1833, -5.1103], [3.344, -3.362, -5.1101], [2.6017, -4.3613, -4.1444]],\n+                (\"cuda\", 8): [[3.0590, -1.1903, -5.1119], [3.3919, -3.3547, -5.1469], [2.6041, -4.3592, -4.1406]],\n+            }\n+        )\n+        expected_slice_hidden_state = torch.tensor(expectations.get_expectation()).to(torch_device)\n         slice_hidden_state = outputs.transformer_decoder_class_predictions[0, :3, :3]\n         torch.testing.assert_close(slice_hidden_state, expected_slice_hidden_state, atol=TOLERANCE, rtol=TOLERANCE)\n-        # fmt: on\n \n     def test_inference_universal_segmentation_head(self):\n         model = OneFormerForUniversalSegmentation.from_pretrained(self.model_checkpoints).to(torch_device).eval()\n@@ -599,8 +603,13 @@ def test_inference_universal_segmentation_head(self):\n             masks_queries_logits.shape,\n             (1, model.config.num_queries, inputs_shape[-2] // 4, (inputs_shape[-1] + 2) // 4),\n         )\n-        expected_slice = [[3.1848, 4.2141, 4.1993], [2.9000, 3.5721, 3.6603], [2.5358, 3.0883, 3.6168]]\n-        expected_slice = torch.tensor(expected_slice).to(torch_device)\n+        expectations = Expectations(\n+            {\n+                (None, None): [[3.1848, 4.2141, 4.1993], [2.9000, 3.5721, 3.6603], [2.5358, 3.0883, 3.6168]],\n+                (\"cuda\", 8): [[3.1687, 4.1893, 4.1742], [2.8768, 3.5380, 3.6257], [2.5121, 3.0552, 3.5822]],\n+            }\n+        )\n+        expected_slice = torch.tensor(expectations.get_expectation()).to(torch_device)\n         torch.testing.assert_close(masks_queries_logits[0, 0, :3, :3], expected_slice, rtol=TOLERANCE, atol=TOLERANCE)\n \n         # class_queries_logits\n@@ -609,8 +618,13 @@ def test_inference_universal_segmentation_head(self):\n             class_queries_logits.shape,\n             (1, model.config.num_queries, model.config.num_labels + 1),\n         )\n-        expected_slice = [[3.0668, -1.1833, -5.1103], [3.3440, -3.3620, -5.1101], [2.6017, -4.3613, -4.1444]]\n-        expected_slice = torch.tensor(expected_slice).to(torch_device)\n+        expectations = Expectations(\n+            {\n+                (None, None): [[3.0668, -1.1833, -5.1103], [3.3440, -3.3620, -5.1101], [2.6017, -4.3613, -4.1444]],\n+                (\"cuda\", 8): [[3.0590, -1.1903, -5.1119], [3.3919, -3.3547, -5.1469], [2.6041, -4.3592, -4.1406]],\n+            }\n+        )\n+        expected_slice = torch.tensor(expectations.get_expectation()).to(torch_device)\n         torch.testing.assert_close(class_queries_logits[0, :3, :3], expected_slice, rtol=TOLERANCE, atol=TOLERANCE)\n \n     @require_torch_accelerator"
        },
        {
            "sha": "56300abbe8cadf96338c29279d8e52a075478ebb",
            "filename": "tests/models/poolformer/test_modeling_poolformer.py",
            "status": "modified",
            "additions": 12,
            "deletions": 3,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fpoolformer%2Ftest_modeling_poolformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fpoolformer%2Ftest_modeling_poolformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpoolformer%2Ftest_modeling_poolformer.py?ref=37a239ca50885443a3216f56110a03f959509c80",
            "patch": "@@ -17,7 +17,7 @@\n \n from transformers import is_torch_available, is_vision_available\n from transformers.models.auto import get_values\n-from transformers.testing_utils import require_torch, slow, torch_device\n+from transformers.testing_utils import Expectations, require_torch, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n@@ -144,6 +144,9 @@ def test_model(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_model(*config_and_inputs)\n \n+    def test_batching_equivalence(self, atol=2e-4, rtol=2e-4):\n+        super().test_batching_equivalence(atol=atol, rtol=rtol)\n+\n     @unittest.skip(reason=\"PoolFormer does not use inputs_embeds\")\n     def test_inputs_embeds(self):\n         pass\n@@ -235,5 +238,11 @@ def test_inference_image_classification_head(self):\n         expected_shape = torch.Size((1, 1000))\n         self.assertEqual(outputs.logits.shape, expected_shape)\n \n-        expected_slice = torch.tensor([-0.6113, 0.1685, -0.0492]).to(torch_device)\n-        torch.testing.assert_close(outputs.logits[0, :3], expected_slice, rtol=1e-4, atol=1e-4)\n+        expectations = Expectations(\n+            {\n+                (None, None): [-0.6113, 0.1685, -0.0492],\n+                (\"cuda\", 8): [-0.6112, 0.1690, -0.0481],\n+            }\n+        )\n+        expected_slice = torch.tensor(expectations.get_expectation()).to(torch_device)\n+        torch.testing.assert_close(outputs.logits[0, :3], expected_slice, rtol=2e-4, atol=2e-4)"
        },
        {
            "sha": "eeaabcbd608e7e823476ffc7609b70fcc113397f",
            "filename": "tests/models/pvt/test_modeling_pvt.py",
            "status": "modified",
            "additions": 20,
            "deletions": 6,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fpvt%2Ftest_modeling_pvt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fpvt%2Ftest_modeling_pvt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpvt%2Ftest_modeling_pvt.py?ref=37a239ca50885443a3216f56110a03f959509c80",
            "patch": "@@ -17,6 +17,7 @@\n \n from transformers import is_torch_available, is_vision_available\n from transformers.testing_utils import (\n+    Expectations,\n     require_accelerate,\n     require_torch,\n     require_torch_accelerator,\n@@ -153,6 +154,9 @@ def setUp(self):\n         self.model_tester = PvtModelTester(self)\n         self.config_tester = PvtConfigTester(self, config_class=PvtConfig)\n \n+    def test_batching_equivalence(self, atol=1e-4, rtol=1e-4):\n+        super().test_batching_equivalence(atol=atol, rtol=rtol)\n+\n     def test_config(self):\n         self.config_tester.run_common_tests()\n \n@@ -257,9 +261,15 @@ def test_inference_image_classification(self):\n         expected_shape = torch.Size((1, model.config.num_labels))\n         self.assertEqual(outputs.logits.shape, expected_shape)\n \n-        expected_slice = torch.tensor([-1.4192, -1.9158, -0.9702]).to(torch_device)\n+        expectations = Expectations(\n+            {\n+                (None, None): [-1.4192, -1.9158, -0.9702],\n+                (\"cuda\", 8): [-1.4194, -1.9161, -0.9705],\n+            }\n+        )\n+        expected_slice = torch.tensor(expectations.get_expectation()).to(torch_device)\n \n-        torch.testing.assert_close(outputs.logits[0, :3], expected_slice, rtol=1e-4, atol=1e-4)\n+        torch.testing.assert_close(outputs.logits[0, :3], expected_slice, rtol=2e-4, atol=2e-4)\n \n     @slow\n     def test_inference_model(self):\n@@ -278,11 +288,15 @@ def test_inference_model(self):\n         expected_shape = torch.Size((1, 50, 512))\n         self.assertEqual(outputs.last_hidden_state.shape, expected_shape)\n \n-        expected_slice = torch.tensor(\n-            [[-0.3086, 1.0402, 1.1816], [-0.2880, 0.5781, 0.6124], [0.1480, 0.6129, -0.0590]]\n-        ).to(torch_device)\n+        expectations = Expectations(\n+            {\n+                (None, None): [[-0.3086, 1.0402, 1.1816], [-0.2880, 0.5781, 0.6124], [0.1480, 0.6129, -0.0590]],\n+                (\"cuda\", 8): [[-0.3084, 1.0402, 1.1816], [-0.2883, 0.5781, 0.6123], [0.1487, 0.6119, -0.0584]],\n+            }\n+        )\n+        expected_slice = torch.tensor(expectations.get_expectation()).to(torch_device)\n \n-        torch.testing.assert_close(outputs.last_hidden_state[0, :3, :3], expected_slice, rtol=1e-4, atol=1e-4)\n+        torch.testing.assert_close(outputs.last_hidden_state[0, :3, :3], expected_slice, rtol=2e-4, atol=2e-4)\n \n     @slow\n     @require_accelerate"
        },
        {
            "sha": "0aca4e6652b4c3f9dbfbfc730d696454ccc55364",
            "filename": "tests/models/pvt_v2/test_modeling_pvt_v2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fpvt_v2%2Ftest_modeling_pvt_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fpvt_v2%2Ftest_modeling_pvt_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpvt_v2%2Ftest_modeling_pvt_v2.py?ref=37a239ca50885443a3216f56110a03f959509c80",
            "patch": "@@ -167,6 +167,9 @@ def test_model(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_model(*config_and_inputs)\n \n+    def test_batching_equivalence(self, atol=5e-4, rtol=5e-4):\n+        super().test_batching_equivalence(atol=atol, rtol=rtol)\n+\n     @unittest.skip(reason=\"Pvt-V2 does not use inputs_embeds\")\n     def test_inputs_embeds(self):\n         pass"
        },
        {
            "sha": "8fc8e452da93e5e6d48ca91a5735f46d6b35a1f5",
            "filename": "tests/models/regnet/test_modeling_regnet.py",
            "status": "modified",
            "additions": 12,
            "deletions": 4,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fregnet%2Ftest_modeling_regnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fregnet%2Ftest_modeling_regnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fregnet%2Ftest_modeling_regnet.py?ref=37a239ca50885443a3216f56110a03f959509c80",
            "patch": "@@ -17,7 +17,7 @@\n \n from transformers import RegNetConfig\n from transformers.file_utils import cached_property, is_torch_available, is_vision_available\n-from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n+from transformers.testing_utils import Expectations, require_torch, require_vision, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n@@ -146,6 +146,9 @@ def setUp(self):\n     def test_config(self):\n         self.config_tester.run_common_tests()\n \n+    def test_batching_equivalence(self, atol=3e-5, rtol=3e-5):\n+        super().test_batching_equivalence(atol=atol, rtol=rtol)\n+\n     @unittest.skip(reason=\"RegNet does not use inputs_embeds\")\n     def test_inputs_embeds(self):\n         pass\n@@ -248,6 +251,11 @@ def test_inference_image_classification_head(self):\n         expected_shape = torch.Size((1, 1000))\n         self.assertEqual(outputs.logits.shape, expected_shape)\n \n-        expected_slice = torch.tensor([-0.4180, -1.5051, -3.4836]).to(torch_device)\n-\n-        torch.testing.assert_close(outputs.logits[0, :3], expected_slice, rtol=1e-4, atol=1e-4)\n+        expectations = Expectations(\n+            {\n+                (None, None): [-0.4180, -1.5051, -3.4836],\n+                (\"cuda\", 8): [-0.4168, -1.5056, -3.4836],\n+            }\n+        )\n+        expected_slice = torch.tensor(expectations.get_expectation()).to(torch_device)\n+        torch.testing.assert_close(outputs.logits[0, :3], expected_slice, rtol=2e-4, atol=2e-4)"
        },
        {
            "sha": "3778bd400544817bdfa1b68d98680645c84cfd34",
            "filename": "tests/models/resnet/test_modeling_resnet.py",
            "status": "modified",
            "additions": 9,
            "deletions": 4,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fresnet%2Ftest_modeling_resnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fresnet%2Ftest_modeling_resnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fresnet%2Ftest_modeling_resnet.py?ref=37a239ca50885443a3216f56110a03f959509c80",
            "patch": "@@ -16,7 +16,7 @@\n import unittest\n \n from transformers import ResNetConfig\n-from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n+from transformers.testing_utils import Expectations, require_torch, require_vision, slow, torch_device\n from transformers.utils import cached_property, is_torch_available, is_vision_available\n \n from ...test_backbone_common import BackboneTesterMixin\n@@ -301,9 +301,14 @@ def test_inference_image_classification_head(self):\n         expected_shape = torch.Size((1, 1000))\n         self.assertEqual(outputs.logits.shape, expected_shape)\n \n-        expected_slice = torch.tensor([-11.1069, -9.7877, -8.3777]).to(torch_device)\n-\n-        torch.testing.assert_close(outputs.logits[0, :3], expected_slice, rtol=1e-4, atol=1e-4)\n+        expectations = Expectations(\n+            {\n+                (None, None): [-11.1069, -9.7877, -8.3777],\n+                (\"cuda\", 8): [-11.1112, -9.7916, -8.3788],\n+            }\n+        )\n+        expected_slice = torch.tensor(expectations.get_expectation()).to(torch_device)\n+        torch.testing.assert_close(outputs.logits[0, :3], expected_slice, rtol=2e-4, atol=2e-4)\n \n \n @require_torch"
        },
        {
            "sha": "4083276e18520ac7e316885e567437242763c8e9",
            "filename": "tests/models/seggpt/test_modeling_seggpt.py",
            "status": "modified",
            "additions": 17,
            "deletions": 8,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fseggpt%2Ftest_modeling_seggpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fseggpt%2Ftest_modeling_seggpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fseggpt%2Ftest_modeling_seggpt.py?ref=37a239ca50885443a3216f56110a03f959509c80",
            "patch": "@@ -21,6 +21,7 @@\n \n from transformers import SegGptConfig\n from transformers.testing_utils import (\n+    Expectations,\n     require_torch,\n     require_vision,\n     slow,\n@@ -379,15 +380,23 @@ def test_one_shot_inference(self):\n         expected_shape = torch.Size((1, 3, 896, 448))\n         self.assertEqual(outputs.pred_masks.shape, expected_shape)\n \n-        expected_slice = torch.tensor(\n-            [\n-                [[-2.1208, -2.1190, -2.1198], [-2.1237, -2.1228, -2.1227], [-2.1232, -2.1226, -2.1228]],\n-                [[-2.0405, -2.0396, -2.0403], [-2.0434, -2.0434, -2.0433], [-2.0428, -2.0432, -2.0434]],\n-                [[-1.8102, -1.8088, -1.8099], [-1.8131, -1.8126, -1.8129], [-1.8130, -1.8128, -1.8131]],\n-            ]\n-        ).to(torch_device)\n+        expectations = Expectations(\n+            {\n+                (None, None): [\n+                    [[-2.1208, -2.1190, -2.1198], [-2.1237, -2.1228, -2.1227], [-2.1232, -2.1226, -2.1228]],\n+                    [[-2.0405, -2.0396, -2.0403], [-2.0434, -2.0434, -2.0433], [-2.0428, -2.0432, -2.0434]],\n+                    [[-1.8102, -1.8088, -1.8099], [-1.8131, -1.8126, -1.8129], [-1.8130, -1.8128, -1.8131]],\n+                ],\n+                (\"cuda\", 8): [\n+                    [[-2.1208, -2.1189, -2.1198], [-2.1236, -2.1229, -2.1230], [-2.1233, -2.1227, -2.1228]],\n+                    [[-2.0408, -2.0398, -2.0405], [-2.0435, -2.0437, -2.0438], [-2.0431, -2.0435, -2.0436]],\n+                    [[-1.8101, -1.8086, -1.8098], [-1.8129, -1.8126, -1.8130], [-1.8128, -1.8128, -1.8130]],\n+                ],\n+            }\n+        )\n+        expected_slice = torch.tensor(expectations.get_expectation()).to(torch_device)\n \n-        torch.testing.assert_close(outputs.pred_masks[0, :, :3, :3], expected_slice, rtol=1e-4, atol=1e-4)\n+        torch.testing.assert_close(outputs.pred_masks[0, :, :3, :3], expected_slice, rtol=2e-4, atol=2e-4)\n \n         result = image_processor.post_process_semantic_segmentation(outputs, [input_image.size[::-1]])[0]\n "
        },
        {
            "sha": "a1767a0ab246609be0147cef38a6a4cd426a16e8",
            "filename": "tests/models/swin2sr/test_modeling_swin2sr.py",
            "status": "modified",
            "additions": 10,
            "deletions": 5,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fswin2sr%2Ftest_modeling_swin2sr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fswin2sr%2Ftest_modeling_swin2sr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fswin2sr%2Ftest_modeling_swin2sr.py?ref=37a239ca50885443a3216f56110a03f959509c80",
            "patch": "@@ -16,7 +16,7 @@\n import unittest\n \n from transformers import Swin2SRConfig\n-from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n+from transformers.testing_utils import Expectations, require_torch, require_vision, slow, torch_device\n from transformers.utils import is_torch_available, is_vision_available\n \n from ...test_configuration_common import ConfigTester\n@@ -360,7 +360,12 @@ def test_inference_fp16(self):\n         # verify the logits\n         expected_shape = torch.Size([1, 3, 976, 1296])\n         self.assertEqual(outputs.reconstruction.shape, expected_shape)\n-        expected_slice = torch.tensor(\n-            [[0.5454, 0.5542, 0.5640], [0.5518, 0.5562, 0.5649], [0.5391, 0.5425, 0.5620]], dtype=model.dtype\n-        ).to(torch_device)\n-        torch.testing.assert_close(outputs.reconstruction[0, 0, :3, :3], expected_slice, rtol=1e-4, atol=1e-4)\n+\n+        expectations = Expectations(\n+            {\n+                (None, None): [[0.5454, 0.5542, 0.5640], [0.5518, 0.5562, 0.5649], [0.5391, 0.5425, 0.5620]],\n+                (\"cuda\", 8): [[0.5454, 0.5547, 0.5640], [0.5522, 0.5562, 0.5649], [0.5391, 0.5425, 0.5620]],\n+            }\n+        )\n+        expected_slice = torch.tensor(expectations.get_expectation()).to(torch_device, dtype=model.dtype)\n+        torch.testing.assert_close(outputs.reconstruction[0, 0, :3, :3], expected_slice, rtol=2e-4, atol=2e-4)"
        },
        {
            "sha": "67b59fef4ffa86d869ff3098a5863b33ac424b4a",
            "filename": "tests/models/switch_transformers/test_modeling_switch_transformers.py",
            "status": "modified",
            "additions": 22,
            "deletions": 11,
            "changes": 33,
            "blob_url": "https://github.com/huggingface/transformers/blob/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fswitch_transformers%2Ftest_modeling_switch_transformers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/37a239ca50885443a3216f56110a03f959509c80/tests%2Fmodels%2Fswitch_transformers%2Ftest_modeling_switch_transformers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fswitch_transformers%2Ftest_modeling_switch_transformers.py?ref=37a239ca50885443a3216f56110a03f959509c80",
            "patch": "@@ -19,6 +19,7 @@\n \n from transformers import SwitchTransformersConfig, is_torch_available\n from transformers.testing_utils import (\n+    Expectations,\n     require_tokenizers,\n     require_torch,\n     require_torch_accelerator,\n@@ -1035,18 +1036,28 @@ def test_small_logits(self):\n         decoder_input_ids = torch.ones((32, 64), dtype=torch.long).to(torch_device)\n \n         # fmt: off\n-        EXPECTED_MEAN_LOGITS = torch.Tensor(\n-            [\n-                -0.204102, -0.193359, 0.523438, -0.296875, 0.108887,\n-                0.0211182, 0.605469, -0.100586, -0.0551758, 0.296875,\n-                0.0090332, 0.174805, 0.139648, -0.170898, -0.0981445,\n-                0.0245361, 0.0373535, 0.050293, -0.212891, 0.129883,\n-                0.390625, -0.203125, -0.122559, -0.180664, 0.0437012,\n-                -0.349609, -0.0250244, -0.104004, -0.15918, -0.133789\n-            ]\n-        ).to(torch.bfloat16)\n+        expectations = Expectations(\n+            {\n+                (None, None): [\n+                    -0.204102, -0.193359, 0.523438, -0.296875, 0.108887,\n+                    0.0211182, 0.605469, -0.100586, -0.0551758, 0.296875,\n+                    0.0090332, 0.174805, 0.139648, -0.170898, -0.0981445,\n+                    0.0245361, 0.0373535, 0.050293, -0.212891, 0.129883,\n+                    0.390625, -0.203125, -0.122559, -0.180664, 0.0437012,\n+                    -0.349609, -0.0250244, -0.104004, -0.15918, -0.133789\n+                ],\n+                (\"cuda\", 8): [\n+                    -0.2051, -0.1914, 0.5352, -0.2988, 0.1108, 0.0200, 0.6094, -0.1025,\n+                    -0.0549, 0.2988, -0.0018, 0.1758, 0.1348, -0.1689, -0.1035, 0.0266,\n+                    0.0383, 0.0493, -0.2119, 0.1328, 0.3906, -0.2041, -0.1240, -0.1836,\n+                    0.0454, -0.3477, -0.0256, -0.1050, -0.1572, -0.1338\n+                ],\n+            }\n+        )\n+        EXPECTED_MEAN_LOGITS = torch.tensor(expectations.get_expectation()).to(torch_device, dtype=torch.bfloat16)\n         # fmt: on\n-        hf_logits = model(input_ids, decoder_input_ids=decoder_input_ids).last_hidden_state.cpu()\n+\n+        hf_logits = model(input_ids, decoder_input_ids=decoder_input_ids).last_hidden_state\n         hf_logits = hf_logits[0, 0, :30]\n \n         torch.testing.assert_close(hf_logits, EXPECTED_MEAN_LOGITS, rtol=6e-3, atol=9e-3)"
        }
    ],
    "stats": {
        "total": 249,
        "additions": 181,
        "deletions": 68
    }
}