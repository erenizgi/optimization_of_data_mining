{
    "author": "SunMarc",
    "message": "Fix trainer for py3.9 (#41359)\n\nfix",
    "sha": "db711210d29cead8ae6b376778ab51f5d3b7c4e5",
    "files": [
        {
            "sha": "9b81a57010146f444ad842e30a0f06e6298bb3df",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/db711210d29cead8ae6b376778ab51f5d3b7c4e5/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/db711210d29cead8ae6b376778ab51f5d3b7c4e5/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=db711210d29cead8ae6b376778ab51f5d3b7c4e5",
            "patch": "@@ -5206,7 +5206,7 @@ def _fsdp_qlora_plugin_updates(self):\n                     self.model.hf_quantizer.quantization_config.bnb_4bit_quant_storage, override=True\n                 )\n \n-    def _get_num_items_in_batch(self, batch_samples: list, device: torch.device) -> int | None:\n+    def _get_num_items_in_batch(self, batch_samples: list, device: torch.device) -> Optional[Union[torch.Tensor, int]]:\n         \"\"\"\n         Counts the number of items in the batches to properly scale the loss.\n         Args:"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}