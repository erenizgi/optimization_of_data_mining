{
    "author": "ydshieh",
    "message": "CI when PR merged to `main` (#40451)\n\n* up\n\n* up\n\n* up\n\n* up\n\n* up\n\n* update\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "80f4c0c6a0f4cf1edd9a812115e41b49cd9be448",
    "files": [
        {
            "sha": "f1b0f6a9554f67c85231223956bd8ff1359bec57",
            "filename": ".github/workflows/push-important-models.yml",
            "status": "modified",
            "additions": 136,
            "deletions": 115,
            "changes": 251,
            "blob_url": "https://github.com/huggingface/transformers/blob/80f4c0c6a0f4cf1edd9a812115e41b49cd9be448/.github%2Fworkflows%2Fpush-important-models.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/80f4c0c6a0f4cf1edd9a812115e41b49cd9be448/.github%2Fworkflows%2Fpush-important-models.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fpush-important-models.yml?ref=80f4c0c6a0f4cf1edd9a812115e41b49cd9be448",
            "patch": "@@ -4,17 +4,6 @@ on:\n   push:\n     branches: [ main ]\n \n-env:\n-  OUTPUT_SLACK_CHANNEL_ID: \"C06L2SGMEEA\"\n-  HF_HUB_READ_TOKEN: ${{ secrets.HF_HUB_READ_TOKEN }}\n-  HF_HOME: /mnt/cache\n-  TRANSFORMERS_IS_CI: yes\n-  OMP_NUM_THREADS: 8\n-  MKL_NUM_THREADS: 8\n-  RUN_SLOW: yes # For gated repositories, we still need to agree to share information on the Hub repo. page in order to get access. # This token is created under the bot `hf-transformers-bot`.\n-  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}\n-  TF_FORCE_GPU_ALLOW_GROWTH: true\n-\n jobs:\n   get_modified_models:\n     name: \"Get all modified files\"\n@@ -25,111 +14,143 @@ jobs:\n       - name: Check out code\n         uses: actions/checkout@v4\n \n-      - name: Get changed files\n-        id: changed-files\n-        uses: tj-actions/changed-files@1c8e6069583811afb28f97afeaf8e7da80c6be5c\n+      - name: Get changed files using `actions/github-script`\n+        id: get-changed-files\n+        uses: actions/github-script@v7\n         with:\n-          files: src/transformers/models/**\n-\n-      - name: Run step if only the files listed above change\n-        if: steps.changed-files.outputs.any_changed == 'true'\n-        id: set-matrix\n+          script: |\n+            let files = [];\n+            \n+            // Only handle push events\n+            if (context.eventName === 'push') {\n+              const afterSha = context.payload.after;\n+              const branchName = context.payload.ref.replace('refs/heads/', '');\n+              \n+              let baseSha;\n+              \n+              if (branchName === 'main') {\n+                console.log('Push to main branch, comparing to parent commit');\n+                // Get the parent commit of the pushed commit\n+                const { data: commit } = await github.rest.repos.getCommit({\n+                  owner: context.repo.owner,\n+                  repo: context.repo.repo,\n+                  ref: afterSha\n+                });\n+                baseSha = commit.parents[0]?.sha;\n+                if (!baseSha) {\n+                  throw new Error('No parent commit found for the pushed commit');\n+                }\n+              } else {\n+                console.log(`Push to branch ${branchName}, comparing to main`);\n+                baseSha = 'main';\n+              }\n+              \n+              const { data: comparison } = await github.rest.repos.compareCommits({\n+                owner: context.repo.owner,\n+                repo: context.repo.repo,\n+                base: baseSha,\n+                head: afterSha\n+              });\n+              \n+              // Include added, modified, and renamed files\n+              files = comparison.files\n+                .filter(file => file.status === 'added' || file.status === 'modified' || file.status === 'renamed')\n+                .map(file => file.filename);\n+            }\n+            \n+            // Include all files under src/transformers/ (not just models subdirectory)\n+            const filteredFiles = files.filter(file => \n+              file.startsWith('src/transformers/')\n+            );\n+            \n+            core.setOutput('changed_files', filteredFiles.join(' '));\n+            core.setOutput('any_changed', filteredFiles.length > 0 ? 'true' : 'false');\n+\n+      - name: Parse changed files with Python\n+        if: steps.get-changed-files.outputs.any_changed == 'true'\n         env:\n-          ALL_CHANGED_FILES: ${{ steps.changed-files.outputs.all_changed_files }}\n+          CHANGED_FILES: ${{ steps.get-changed-files.outputs.changed_files }}\n+        id: set-matrix\n         run: |\n-            model_arrays=()\n-            for file in $ALL_CHANGED_FILES; do\n-                model_path=\"${file#*models/}\"\n-                model_path=\"models/${model_path%%/*}\"\n-                if grep -qFx \"$model_path\" utils/important_models.txt; then\n-                    # Append the file to the matrix string\n-                    model_arrays+=(\"$model_path\")\n-                fi\n-            done\n-            matrix_string=$(printf '\"%s\", ' \"${model_arrays[@]}\" | sed 's/, $//')\n-            echo \"matrix=[$matrix_string]\" >> $GITHUB_OUTPUT\n-  test_modified_files:\n+          python3 - << 'EOF'\n+          import os\n+          import sys\n+          import json\n+          \n+          # Add the utils directory to Python path\n+          sys.path.insert(0, 'utils')\n+          \n+          # Import the important models list\n+          from important_files import IMPORTANT_MODELS\n+          \n+          print(f\"Important models: {IMPORTANT_MODELS}\")\n+          \n+          # Get the changed files from the previous step\n+          changed_files_str = os.environ.get('CHANGED_FILES', '')\n+          changed_files = changed_files_str.split() if changed_files_str else []\n+          \n+          # Filter to only Python files\n+          python_files = [f for f in changed_files if f.endswith('.py')]\n+          print(f\"Python files changed: {python_files}\")\n+          \n+          result_models = set()\n+          \n+          # Specific files that trigger all models\n+          transformers_utils_files = [\n+              'modeling_utils.py',\n+              'modeling_rope_utils.py', \n+              'modeling_flash_attention_utils.py',\n+              'modeling_attn_mask_utils.py',\n+              'cache_utils.py',\n+              'masking_utils.py',\n+              'pytorch_utils.py'\n+          ]\n+          \n+          # Single loop through all Python files\n+          for file in python_files:\n+              # Check for files under src/transformers/models/\n+              if file.startswith('src/transformers/models/'):\n+                  remaining_path = file[len('src/transformers/models/'):]\n+                  if '/' in remaining_path:\n+                      model_dir = remaining_path.split('/')[0]\n+                      if model_dir in IMPORTANT_MODELS:\n+                          result_models.add(model_dir)\n+                          print(f\"Added model directory: {model_dir}\")\n+              \n+              # Check for specific files under src/transformers/ or src/transformers/generation/ files\n+              elif file.startswith('src/transformers/generation/') or \\\n+                   (file.startswith('src/transformers/') and os.path.basename(file) in transformers_utils_files):\n+                  print(f\"Found core file: {file} - including all important models\")\n+                  result_models.update(IMPORTANT_MODELS)\n+                  break  # No need to continue once we include all models\n+          \n+          # Convert to sorted list and create matrix\n+          result_list = sorted(list(result_models))\n+          print(f\"Final model list: {result_list}\")\n+          \n+          if result_list:\n+              matrix_json = json.dumps(result_list)\n+              print(f\"matrix={matrix_json}\")\n+              \n+              # Write to GITHUB_OUTPUT\n+              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:\n+                  f.write(f\"matrix={matrix_json}\\n\")\n+          else:\n+              print(\"matrix=[]\")\n+              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:\n+                  f.write(\"matrix=[]\\n\")\n+          EOF\n+\n+  model-ci:\n+    name: Model CI\n+    uses: ./.github/workflows/self-scheduled.yml\n     needs: get_modified_models\n-    name: Slow & FA2 tests\n-    runs-on:\n-      group: aws-g5-4xlarge-cache\n-    container:\n-      image: huggingface/transformers-all-latest-gpu\n-      options: --gpus all --privileged --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n-    if: ${{ needs.get_modified_models.outputs.matrix != '[]' && needs.get_modified_models.outputs.matrix != '' && fromJson(needs.get_modified_models.outputs.matrix)[0] != null }}\n-    strategy:\n-      fail-fast: false\n-      matrix:\n-        model-name: ${{ fromJson(needs.get_modified_models.outputs.matrix) }}\n-\n-    steps:\n-      - name: Check out code\n-        uses: actions/checkout@v4\n-\n-      - name: Install locally transformers & other libs\n-        run: |\n-          apt install sudo\n-          sudo -H pip install --upgrade pip\n-          sudo -H pip uninstall -y transformers\n-          sudo -H pip install -U -e \".[testing]\"\n-          MAX_JOBS=4 pip install flash-attn --no-build-isolation\n-          pip install bitsandbytes\n-\n-      - name: NVIDIA-SMI\n-        run: |\n-          nvidia-smi\n-\n-      - name: Show installed libraries and their versions\n-        run: pip freeze\n-\n-      - name: Run FA2 tests\n-        id: run_fa2_tests\n-        run:\n-          pytest -rsfE -m \"flash_attn_test\" --make-reports=${{ matrix.model-name }}_fa2_tests/ tests/${{ matrix.model-name }}/test_modeling_*\n-\n-      - name: \"Test suite reports artifacts: ${{ matrix.model-name }}_fa2_tests\"\n-        if: ${{ always() }}\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: ${{ matrix.model-name }}_fa2_tests\n-          path: /transformers/reports/${{ matrix.model-name }}_fa2_tests\n-\n-      - name: Post to Slack\n-        if: always()\n-        uses: huggingface/hf-workflows/.github/actions/post-slack@main\n-        with:\n-          slack_channel: ${{ env.OUTPUT_SLACK_CHANNEL_ID }}\n-          title: ðŸ¤— Results of the FA2 tests - ${{ matrix.model-name }}\n-          status: ${{ steps.run_fa2_tests.conclusion}}\n-          slack_token: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n-\n-      - name: Run integration tests\n-        id: run_integration_tests\n-        if: always()\n-        run:\n-          pytest -rsfE -k \"IntegrationTest\"  --make-reports=tests_integration_${{ matrix.model-name }} tests/${{ matrix.model-name }}/test_modeling_*\n-\n-      - name: \"Test suite reports artifacts: tests_integration_${{ matrix.model-name }}\"\n-        if: ${{ always() }}\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: tests_integration_${{ matrix.model-name }}\n-          path: /transformers/reports/tests_integration_${{ matrix.model-name }}\n-\n-      - name: Post to Slack\n-        if: always()\n-        uses: huggingface/hf-workflows/.github/actions/post-slack@main\n-        with:\n-          slack_channel: ${{ env.OUTPUT_SLACK_CHANNEL_ID }}\n-          title: ðŸ¤— Results of the Integration tests - ${{ matrix.model-name }}\n-          status: ${{ steps.run_integration_tests.conclusion}}\n-          slack_token: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n-\n-      - name: Tailscale # In order to be able to SSH when a test fails\n-        if: ${{ runner.debug == '1'}}\n-        uses: huggingface/tailscale-action@v1\n-        with:\n-          authkey: ${{ secrets.TAILSCALE_SSH_AUTHKEY }}\n-          slackChannel: ${{ secrets.SLACK_CIFEEDBACK_CHANNEL }}\n-          slackToken: ${{ secrets.SLACK_CIFEEDBACK_BOT_TOKEN }}\n-          waitForSSH: true\n+    with:\n+      job: run_models_gpu\n+      slack_report_channel: \"#transformers-ci-push\"\n+      docker: huggingface/transformers-all-latest-gpu\n+      ci_event: push\n+      report_repo_id: hf-internal-testing/transformers_ci_push\n+      commit_sha: ${{ github.sha }}\n+      models: ${{ needs.get_modified_models.outputs.matrix }}\n+    secrets: inherit"
        },
        {
            "sha": "cc44ee904aaa1293d9fd01353e0e02ac778845f0",
            "filename": ".github/workflows/self-scheduled.yml",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/80f4c0c6a0f4cf1edd9a812115e41b49cd9be448/.github%2Fworkflows%2Fself-scheduled.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/80f4c0c6a0f4cf1edd9a812115e41b49cd9be448/.github%2Fworkflows%2Fself-scheduled.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-scheduled.yml?ref=80f4c0c6a0f4cf1edd9a812115e41b49cd9be448",
            "patch": "@@ -31,7 +31,10 @@ on:\n       commit_sha:\n         required: false\n         type: string\n-\n+      models:\n+        default: \"\"\n+        required: false\n+        type: string\n \n env:\n   HF_HOME: /mnt/cache\n@@ -68,7 +71,7 @@ jobs:\n       - name: Update clone\n         working-directory: /transformers\n         run: |\n-          git fetch && git checkout ${{ github.sha }}\n+          git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n \n       - name: Cleanup\n         working-directory: /transformers\n@@ -87,7 +90,7 @@ jobs:\n         working-directory: /transformers/tests\n         run: |\n           if [ \"${{ inputs.job }}\" = \"run_models_gpu\" ]; then\n-            echo \"folder_slices=$(python3 ../utils/split_model_tests.py --num_splits ${{ env.NUM_SLICES }})\" >> $GITHUB_OUTPUT\n+            echo \"folder_slices=$(python3 ../utils/split_model_tests.py --models '${{ inputs.models }}' --num_splits ${{ env.NUM_SLICES }})\" >> $GITHUB_OUTPUT\n             echo \"slice_ids=$(python3 -c 'd = list(range(${{ env.NUM_SLICES }})); print(d)')\" >> $GITHUB_OUTPUT\n             echo \"runner_map=$(python3 ../utils/get_runner_map.py)\" >> $GITHUB_OUTPUT\n           elif [ \"${{ inputs.job }}\" = \"run_trainer_and_fsdp_gpu\" ]; then"
        },
        {
            "sha": "304baf0bebbdebdd677d30569d846647fdf7eab4",
            "filename": ".github/workflows/slack-report.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/80f4c0c6a0f4cf1edd9a812115e41b49cd9be448/.github%2Fworkflows%2Fslack-report.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/80f4c0c6a0f4cf1edd9a812115e41b49cd9be448/.github%2Fworkflows%2Fslack-report.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fslack-report.yml?ref=80f4c0c6a0f4cf1edd9a812115e41b49cd9be448",
            "patch": "@@ -75,6 +75,8 @@ jobs:\n           SLACK_REPORT_CHANNEL: ${{ inputs.slack_report_channel }}\n           ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n           CI_EVENT: ${{ inputs.ci_event }}\n+          # This `CI_TITLE` would be empty for `schedule` or `workflow_run` events.\n+          CI_TITLE: ${{ github.event.head_commit.message }}\n           CI_SHA: ${{ inputs.commit_sha || github.sha }}\n           CI_TEST_JOB: ${{ inputs.job }}\n           SETUP_STATUS: ${{ inputs.setup_status }}"
        },
        {
            "sha": "f932d8d363f68e6476c76bd742e6b91ac36fb1cb",
            "filename": "utils/important_files.py",
            "status": "added",
            "additions": 28,
            "deletions": 0,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/80f4c0c6a0f4cf1edd9a812115e41b49cd9be448/utils%2Fimportant_files.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/80f4c0c6a0f4cf1edd9a812115e41b49cd9be448/utils%2Fimportant_files.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fimportant_files.py?ref=80f4c0c6a0f4cf1edd9a812115e41b49cd9be448",
            "patch": "@@ -0,0 +1,28 @@\n+# List here the models to always test.\n+IMPORTANT_MODELS = [\n+    \"auto\",\n+    \"bert\",\n+    \"gpt2\",\n+    \"t5\",\n+    \"modernbert\",\n+    \"vit,clip\",\n+    \"detr\",\n+    \"table_transformer\",\n+    \"got_ocr2\",\n+    \"whisper\",\n+    \"wav2vec2\",\n+    \"qwen2_audio\",\n+    \"speech_t5\",\n+    \"csm\",\n+    \"llama\",\n+    \"gemma3\",\n+    \"qwen2\",\n+    \"mistral3\",\n+    \"qwen2_5_vl\",\n+    \"llava\",\n+    \"smolvlm\",\n+    \"internvl\",\n+    \"gemma3n\",\n+    \"gpt_oss\",\n+    \"qwen2_5_omni\",\n+]"
        },
        {
            "sha": "410d3ba7850782889b1f7cb7f7035a3ad070a5ed",
            "filename": "utils/notification_service.py",
            "status": "modified",
            "additions": 4,
            "deletions": 8,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/80f4c0c6a0f4cf1edd9a812115e41b49cd9be448/utils%2Fnotification_service.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/80f4c0c6a0f4cf1edd9a812115e41b49cd9be448/utils%2Fnotification_service.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fnotification_service.py?ref=80f4c0c6a0f4cf1edd9a812115e41b49cd9be448",
            "patch": "@@ -1072,18 +1072,14 @@ def pop_default(l: list[Any], i: int, default: Any) -> Any:\n     pr_number_re = re.compile(r\"\\(#(\\d+)\\)$\")\n \n     # Add Commit/PR title with a link for push CI\n-    # (check the title in 2 env. variables - depending on the CI is triggered via `push` or `workflow_run` event)\n-    ci_title_push = os.environ.get(\"CI_TITLE_PUSH\")\n-    ci_title_workflow_run = os.environ.get(\"CI_TITLE_WORKFLOW_RUN\")\n-    ci_title = ci_title_push if ci_title_push else ci_title_workflow_run\n-\n+    ci_title = os.environ.get(\"CI_TITLE\", \"\")\n     ci_sha = os.environ.get(\"CI_SHA\")\n \n     ci_url = None\n     if ci_sha:\n         ci_url = f\"https://github.com/{repository_full_name}/commit/{ci_sha}\"\n \n-    if ci_title is not None:\n+    if ci_title:\n         if ci_url is None:\n             raise ValueError(\n                 \"When a title is found (`ci_title`), it means a `push` event or a `workflow_run` even (triggered by \"\n@@ -1112,9 +1108,9 @@ def pop_default(l: list[Any], i: int, default: Any) -> Any:\n             merged_by = ci_details[\"merged_by\"][\"login\"]\n \n         if merged_by is None:\n-            ci_title = f\"<{ci_url}|{ci_title}>\\nAuthor: {ci_author}\"\n+            ci_title = f\"<{ci_url}|{ci_title}>\\nAuthor: GH_{ci_author}\"\n         else:\n-            ci_title = f\"<{ci_url}|{ci_title}>\\nAuthor: {ci_author} | Merged by: {merged_by}\"\n+            ci_title = f\"<{ci_url}|{ci_title}>\\nAuthor: GH_{ci_author} | Merged by: GH_{merged_by}\"\n \n     elif ci_sha:\n         ci_title = f\"<{ci_url}|commit: {ci_sha}>\""
        },
        {
            "sha": "6a2aefb293a490d512356c810373c55112432549",
            "filename": "utils/split_model_tests.py",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/80f4c0c6a0f4cf1edd9a812115e41b49cd9be448/utils%2Fsplit_model_tests.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/80f4c0c6a0f4cf1edd9a812115e41b49cd9be448/utils%2Fsplit_model_tests.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fsplit_model_tests.py?ref=80f4c0c6a0f4cf1edd9a812115e41b49cd9be448",
            "patch": "@@ -33,11 +33,18 @@\n \"\"\"\n \n import argparse\n+import ast\n import os\n \n \n if __name__ == \"__main__\":\n     parser = argparse.ArgumentParser()\n+    parser.add_argument(\n+        \"--models\",\n+        type=str,\n+        default=\"\",\n+        help=\"the list of pre-computed model names.\",\n+    )\n     parser.add_argument(\n         \"--num_splits\",\n         type=int,\n@@ -53,6 +60,10 @@\n     d1.remove(\"models\")\n     d = d2 + d1\n \n+    if args.models != \"\":\n+        model_tests = ast.literal_eval(args.models)\n+        d = sorted(filter(os.path.isdir, [f\"models/{x}\" for x in model_tests]))\n+\n     num_jobs = len(d)\n     num_jobs_per_splits = num_jobs // args.num_splits\n "
        },
        {
            "sha": "546a14fd982282e4a93f54cd89d9bc96ef0d8fff",
            "filename": "utils/tests_fetcher.py",
            "status": "modified",
            "additions": 3,
            "deletions": 29,
            "changes": 32,
            "blob_url": "https://github.com/huggingface/transformers/blob/80f4c0c6a0f4cf1edd9a812115e41b49cd9be448/utils%2Ftests_fetcher.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/80f4c0c6a0f4cf1edd9a812115e41b49cd9be448/utils%2Ftests_fetcher.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Ftests_fetcher.py?ref=80f4c0c6a0f4cf1edd9a812115e41b49cd9be448",
            "patch": "@@ -61,6 +61,9 @@\n \n from git import Repo\n \n+# List here the models not to be filtered by `filter_tests`.\n+from important_files import IMPORTANT_MODELS\n+\n \n PATH_TO_REPO = Path(__file__).parent.parent.resolve()\n PATH_TO_EXAMPLES = PATH_TO_REPO / \"examples\"\n@@ -71,35 +74,6 @@\n # This variable has effect only if `filter_models=False`.\n NUM_MODELS_TO_TRIGGER_FULL_CI = 30\n \n-# List here the models to always test.\n-IMPORTANT_MODELS = [\n-    \"auto\",\n-    \"bert\",\n-    \"gpt2\",\n-    \"t5\",\n-    \"modernbert\",\n-    \"vit,clip\",\n-    \"detr\",\n-    \"table_transformer\",\n-    \"got_ocr2\",\n-    \"whisper\",\n-    \"wav2vec2\",\n-    \"qwen2_audio\",\n-    \"speech_t5\",\n-    \"csm\",\n-    \"llama\",\n-    \"gemma3\",\n-    \"qwen2\",\n-    \"mistral3\",\n-    \"qwen2_5_vl\",\n-    \"llava\",\n-    \"smolvlm\",\n-    \"internvl\",\n-    \"gemma3n\",\n-    \"gpt_oss\",\n-    \"qwen2_5_omni\",\n-]\n-\n \n @contextmanager\n def checkout_commit(repo: Repo, commit_id: str):"
        }
    ],
    "stats": {
        "total": 345,
        "additions": 190,
        "deletions": 155
    }
}