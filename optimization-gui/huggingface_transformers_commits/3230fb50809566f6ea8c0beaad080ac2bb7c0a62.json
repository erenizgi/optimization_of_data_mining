{
    "author": "hmellor",
    "message": "Only default `rope_parameters` to empty `dict` if there is something to put in it (#42651)\n\n* Only default `rope_parameters` to empty `dict` if there is something to put in it\n\nSigned-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>\n\n* Add warning\n\nSigned-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>\n\n* Also catch explicit `{}`\n\nSigned-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>\n\n* Handle model with layer types and rope theta but not rope parameters\n\nSigned-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>\n\n---------\n\nSigned-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>",
    "sha": "3230fb50809566f6ea8c0beaad080ac2bb7c0a62",
    "files": [
        {
            "sha": "4827441c1ea75f51dac6d01a709856f6563b1c9c",
            "filename": "src/transformers/modeling_rope_utils.py",
            "status": "modified",
            "additions": 9,
            "deletions": 3,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/3230fb50809566f6ea8c0beaad080ac2bb7c0a62/src%2Ftransformers%2Fmodeling_rope_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3230fb50809566f6ea8c0beaad080ac2bb7c0a62/src%2Ftransformers%2Fmodeling_rope_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_rope_utils.py?ref=3230fb50809566f6ea8c0beaad080ac2bb7c0a62",
            "patch": "@@ -654,20 +654,26 @@ def standardize_rope_params(self):\n         Helper to standardize the config's rope params field by ensuring the params are defined for each\n         later type. For old model the fn will duplicate a single rope param in each layer type (backward compatibility)\n         \"\"\"\n-        # Move `rope_theta` and `partial_rotary_factor` to the params dict, if not there yet\n+        # Move `rope_theta` and `partial_rotary_factor` to the `rope_parameters`, if not there yet\n         rope_theta = getattr(self, \"rope_theta\", None)\n         partial_rotary_factor = getattr(self, \"partial_rotary_factor\", None)\n         rope_parameters = getattr(self, \"rope_parameters\", None) or {}\n+        layer_types = getattr(self, \"layer_types\", None)\n \n+        # Case 0: no RoPE params defined\n+        if not (rope_parameters or rope_theta):\n+            # partial_rotary_factor without rope_theta is invalid, so we don't check for it here\n+            logger.warning(\"`standardize_rope_params` was called but no RoPE parameters were found.\")\n+            return\n         # Case 1: RoPE param keys do not intersect with possible `layer_types` -> one global dict\n-        if getattr(self, \"layer_types\", None) is None or not set(rope_parameters.keys()).issubset(self.layer_types):\n+        elif layer_types is None or rope_parameters == {} or not set(rope_parameters.keys()).issubset(layer_types):\n             rope_parameters.setdefault(\"rope_type\", rope_parameters.get(\"type\", \"default\"))\n             rope_parameters.setdefault(\"rope_theta\", rope_theta)\n             if partial_rotary_factor is not None:\n                 rope_parameters[\"partial_rotary_factor\"] = partial_rotary_factor\n         # Case 2: different RoPE for each layer -> several params as nested dict\n         else:\n-            for layer_type in self.layer_types:\n+            for layer_type in layer_types:\n                 rope_parameters[layer_type].setdefault(\"rope_type\", rope_parameters[layer_type].get(\"type\", \"default\"))\n                 rope_parameters[layer_type].setdefault(\"rope_theta\", rope_theta)\n                 if partial_rotary_factor is not None:"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 9,
        "deletions": 3
    }
}