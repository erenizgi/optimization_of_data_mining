{
    "author": "ydshieh",
    "message": "Track the CI (model) jobs that don't produce test output files (process being killed etc.) (#40981)\n\n* fix\n\n* fix\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "5ac3c5171a6b01708e574eaa11fa2a60086d26bc",
    "files": [
        {
            "sha": "121a8687556f19a8d27c3207e472e684151b99c2",
            "filename": ".github/workflows/model_jobs.yml",
            "status": "modified",
            "additions": 13,
            "deletions": 1,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/5ac3c5171a6b01708e574eaa11fa2a60086d26bc/.github%2Fworkflows%2Fmodel_jobs.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/5ac3c5171a6b01708e574eaa11fa2a60086d26bc/.github%2Fworkflows%2Fmodel_jobs.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fmodel_jobs.yml?ref=5ac3c5171a6b01708e574eaa11fa2a60086d26bc",
            "patch": "@@ -138,10 +138,16 @@ jobs:\n       - name: Run all tests on GPU\n         working-directory: /transformers\n         run: |\n-          PATCH_TESTING_METHODS_TO_COLLECT_OUTPUTS=yes _PATCHED_TESTING_METHODS_OUTPUT_DIR=/transformers/reports/${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports python3 -m pytest -rsfE -v --make-reports=${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports tests/${{ matrix.folders }}\n+          script -q -c \"PATCH_TESTING_METHODS_TO_COLLECT_OUTPUTS=yes _PATCHED_TESTING_METHODS_OUTPUT_DIR=/transformers/reports/${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports python3 -m pytest -rsfE -v --make-reports=${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports tests/${{ matrix.folders }}\" test_outputs.txt\n+          ls -la\n+          # Extract the exit code from the output file\n+          PYTEST_EXIT_CODE=$(tail -1 test_outputs.txt | grep \"PYTEST_EXIT_CODE:\" | cut -d: -f2)\n+          exit ${PYTEST_EXIT_CODE:-1}\n \n       - name: Failure short reports\n         if: ${{ failure() }}\n+        # This step is only to show information on Github Actions log.\n+        # Always mark this step as successful, even if the report directory or the file `failures_short.txt` in it doesn't exist\n         continue-on-error: true\n         run: cat /transformers/reports/${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports/failures_short.txt\n \n@@ -151,6 +157,12 @@ jobs:\n         run: |\n           cat /transformers/reports/${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports/captured_info.txt\n \n+      - name: Copy test_outputs.txt\n+        if: ${{ always() }}\n+        continue-on-error: true\n+        run: |\n+          cp /transformers/test_outputs.txt /transformers/reports/${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports\n+\n       - name: \"Test suite reports artifacts: ${{ env.machine_type }}_${{ inputs.report_name_prefix }}_${{ env.matrix_folders }}_test_reports\"\n         if: ${{ always() }}\n         uses: actions/upload-artifact@v4"
        },
        {
            "sha": "ccff52d28df7e4f87adb9d6311a4a961d4eb63c6",
            "filename": "utils/notification_service.py",
            "status": "modified",
            "additions": 11,
            "deletions": 1,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/5ac3c5171a6b01708e574eaa11fa2a60086d26bc/utils%2Fnotification_service.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5ac3c5171a6b01708e574eaa11fa2a60086d26bc/utils%2Fnotification_service.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fnotification_service.py?ref=5ac3c5171a6b01708e574eaa11fa2a60086d26bc",
            "patch": "@@ -158,9 +158,11 @@ def __init__(\n         self.n_model_failures = (\n             self.n_model_single_gpu_failures + self.n_model_multi_gpu_failures + self.n_model_unknown_failures\n         )\n+        self.n_model_jobs_errored_out = sum(r[\"error\"] for r in model_results.values())\n \n         # Failures and success of the additional tests\n         self.n_additional_success = sum(r[\"success\"] for r in additional_results.values())\n+        self.n_additional_jobs_errored_out = sum(r[\"error\"] for r in additional_results.values())\n \n         if len(additional_results) > 0:\n             # `dicts_to_sum` uses `dicts_to_sum` which requires a non empty dictionary. Let's just add an empty entry.\n@@ -183,6 +185,7 @@ def __init__(\n         self.n_failures = self.n_model_failures + self.n_additional_failures\n         self.n_success = self.n_model_success + self.n_additional_success\n         self.n_tests = self.n_failures + self.n_success\n+        self.n_jobs_errored_out = self.n_model_jobs_errored_out + self.n_additional_jobs_errored_out\n \n         self.model_results = model_results\n         self.additional_results = additional_results\n@@ -241,6 +244,7 @@ def failures(self) -> dict:\n                 \"type\": \"plain_text\",\n                 \"text\": (\n                     f\"There were {self.n_failures} failures, out of {self.n_tests} tests.\\n\"\n+                    f\"ðŸš¨ There were {self.n_jobs_errored_out} jobs errored out (not producing test output files).\\n\"\n                     f\"The suite ran in {self.time}.\"\n                 ),\n                 \"emoji\": True,\n@@ -561,7 +565,7 @@ def payload(self) -> str:\n         if self.ci_title:\n             blocks.append(self.ci_title_section)\n \n-        if self.n_model_failures > 0 or self.n_additional_failures > 0:\n+        if self.n_model_failures > 0 or self.n_additional_failures > 0 or self.n_jobs_errored_out > 0:\n             blocks.append(self.failures)\n \n         if self.n_model_failures > 0:\n@@ -1194,6 +1198,7 @@ def pop_default(l: list[Any], i: int, default: Any) -> Any:\n             \"success\": 0,\n             \"skipped\": 0,\n             \"time_spent\": [],\n+            \"error\": False,\n             \"failures\": {},\n             \"job_link\": {},\n             \"captured_info\": {},\n@@ -1222,6 +1227,11 @@ def pop_default(l: list[Any], i: int, default: Any) -> Any:\n                 continue\n \n             artifact = retrieve_artifact(path, artifact_gpu)\n+\n+            if \"summary_short\" not in artifact:\n+                # The process might be killed (for example, CPU OOM), or the job is canceled for some reason), etc.\n+                matrix_job_results[matrix_name][\"error\"] = True\n+\n             if \"stats\" in artifact:\n                 # Link to the GitHub Action job\n                 job = artifact_name_to_job_map[path]"
        }
    ],
    "stats": {
        "total": 26,
        "additions": 24,
        "deletions": 2
    }
}