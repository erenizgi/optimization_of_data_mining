{
    "author": "Cyrilvallez",
    "message": "Fix deepspeed with quantization (#37324)\n\n* Update modeling_utils.py\n\n* Update modeling_utils.py",
    "sha": "9db31ea58579cf441bc0cf978ecf917a289fdc39",
    "files": [
        {
            "sha": "67266d558dda898411d88710ca2147f350c6a62e",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 9,
            "deletions": 10,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/9db31ea58579cf441bc0cf978ecf917a289fdc39/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9db31ea58579cf441bc0cf978ecf917a289fdc39/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=9db31ea58579cf441bc0cf978ecf917a289fdc39",
            "patch": "@@ -3719,19 +3719,14 @@ def float(self, *args):\n \n     @classmethod\n     def get_init_context(cls, is_quantized: bool, _is_ds_init_called: bool):\n-        # With deepspeed, we cannot initialize the model on meta device\n         if is_deepspeed_zero3_enabled():\n             init_contexts = [no_init_weights()]\n+            # We cannot initialize the model on meta device with deepspeed when not quantized\n             if not is_quantized and not _is_ds_init_called:\n                 logger.info(\"Detected DeepSpeed ZeRO-3: activating zero.init() for this model\")\n-                init_contexts.extend(\n-                    [\n-                        deepspeed.zero.Init(config_dict_or_path=deepspeed_config()),\n-                        set_zero3_state(),\n-                    ]\n-                )\n+                init_contexts.extend([deepspeed.zero.Init(config_dict_or_path=deepspeed_config()), set_zero3_state()])\n             elif is_quantized:\n-                init_contexts.append(set_quantized_state())\n+                init_contexts.extend([init_empty_weights(), set_quantized_state()])\n         else:\n             init_contexts = [no_init_weights(), init_empty_weights()]\n \n@@ -4800,7 +4795,11 @@ def _load_pretrained_model(\n                 continue\n \n             map_location = \"cpu\"\n-            if shard_file.endswith(\".safetensors\") and not is_hqq_or_bnb and not is_deepspeed_zero3_enabled():\n+            if (\n+                shard_file.endswith(\".safetensors\")\n+                and not is_hqq_or_bnb\n+                and not (is_deepspeed_zero3_enabled() and not is_quantized)\n+            ):\n                 map_location = \"meta\"\n             elif (\n                 device_map is not None\n@@ -4822,7 +4821,7 @@ def _load_pretrained_model(\n             # Fix the key names\n             state_dict = {key_renaming_mapping[k]: v for k, v in state_dict.items() if k in key_renaming_mapping}\n \n-            if is_deepspeed_zero3_enabled():\n+            if is_deepspeed_zero3_enabled() and not is_quantized:\n                 error_msgs += _load_state_dict_into_zero3_model(model_to_load, state_dict)\n             # Skip it with fsdp on ranks other than 0\n             elif not (is_fsdp_enabled() and not is_local_dist_rank_0() and not is_quantized):"
        }
    ],
    "stats": {
        "total": 19,
        "additions": 9,
        "deletions": 10
    }
}