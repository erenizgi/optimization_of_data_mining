{
    "author": "vasqu",
    "message": "[`Ernie 4.5 VL Moe`] Post merge adjustments (#43117)\n\npost merge fixes",
    "sha": "52e9d05fde10cfccf5368c4403a206c7cbef8e6f",
    "files": [
        {
            "sha": "192a42b891d989cc28234b13825468e3a7990c79",
            "filename": "src/transformers/models/ernie4_5_vl_moe/modeling_ernie4_5_vl_moe.py",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/52e9d05fde10cfccf5368c4403a206c7cbef8e6f/src%2Ftransformers%2Fmodels%2Fernie4_5_vl_moe%2Fmodeling_ernie4_5_vl_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/52e9d05fde10cfccf5368c4403a206c7cbef8e6f/src%2Ftransformers%2Fmodels%2Fernie4_5_vl_moe%2Fmodeling_ernie4_5_vl_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie4_5_vl_moe%2Fmodeling_ernie4_5_vl_moe.py?ref=52e9d05fde10cfccf5368c4403a206c7cbef8e6f",
            "patch": "@@ -1705,6 +1705,8 @@ def prepare_inputs_for_generation(\n         past_key_values=None,\n         image_grid_thw=None,\n         video_grid_thw=None,\n+        use_cache=True,\n+        is_first_iteration=False,\n         # Intentionally ignore position ids to force custom cache logic\n         position_ids=None,\n         **kwargs,\n@@ -1717,6 +1719,8 @@ def prepare_inputs_for_generation(\n             past_key_values=past_key_values,\n             image_grid_thw=image_grid_thw,\n             video_grid_thw=video_grid_thw,\n+            use_cache=use_cache,\n+            is_first_iteration=is_first_iteration,\n             **kwargs,\n         )\n \n@@ -1732,7 +1736,7 @@ def prepare_inputs_for_generation(\n             mm_token_type_ids=model_inputs.get(\"mm_token_type_ids\"),\n         )\n \n-        if model_inputs[\"cache_position\"][0] != 0:\n+        if not is_first_iteration and use_cache:\n             model_inputs[\"pixel_values\"] = None\n             model_inputs[\"pixel_values_videos\"] = None\n             model_inputs[\"mm_token_type_ids\"] = None"
        },
        {
            "sha": "863719409d5ae1751861c67fc8635e1454a64d4c",
            "filename": "src/transformers/models/ernie4_5_vl_moe/modular_ernie4_5_vl_moe.py",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/52e9d05fde10cfccf5368c4403a206c7cbef8e6f/src%2Ftransformers%2Fmodels%2Fernie4_5_vl_moe%2Fmodular_ernie4_5_vl_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/52e9d05fde10cfccf5368c4403a206c7cbef8e6f/src%2Ftransformers%2Fmodels%2Fernie4_5_vl_moe%2Fmodular_ernie4_5_vl_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fernie4_5_vl_moe%2Fmodular_ernie4_5_vl_moe.py?ref=52e9d05fde10cfccf5368c4403a206c7cbef8e6f",
            "patch": "@@ -1393,6 +1393,8 @@ def prepare_inputs_for_generation(\n         past_key_values=None,\n         image_grid_thw=None,\n         video_grid_thw=None,\n+        use_cache=True,\n+        is_first_iteration=False,\n         # Intentionally ignore position ids to force custom cache logic\n         position_ids=None,\n         **kwargs,\n@@ -1405,6 +1407,8 @@ def prepare_inputs_for_generation(\n             past_key_values=past_key_values,\n             image_grid_thw=image_grid_thw,\n             video_grid_thw=video_grid_thw,\n+            use_cache=use_cache,\n+            is_first_iteration=is_first_iteration,\n             **kwargs,\n         )\n \n@@ -1420,7 +1424,7 @@ def prepare_inputs_for_generation(\n             mm_token_type_ids=model_inputs.get(\"mm_token_type_ids\"),\n         )\n \n-        if model_inputs[\"cache_position\"][0] != 0:\n+        if not is_first_iteration and use_cache:\n             model_inputs[\"pixel_values\"] = None\n             model_inputs[\"pixel_values_videos\"] = None\n             model_inputs[\"mm_token_type_ids\"] = None"
        },
        {
            "sha": "dbc41f22064b6a13470e2c1a956ab4bbdf44d9a4",
            "filename": "tests/models/ernie4_5_vl_moe/test_modeling_ernie4_5_vl_moe.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/52e9d05fde10cfccf5368c4403a206c7cbef8e6f/tests%2Fmodels%2Fernie4_5_vl_moe%2Ftest_modeling_ernie4_5_vl_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/52e9d05fde10cfccf5368c4403a206c7cbef8e6f/tests%2Fmodels%2Fernie4_5_vl_moe%2Ftest_modeling_ernie4_5_vl_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fernie4_5_vl_moe%2Ftest_modeling_ernie4_5_vl_moe.py?ref=52e9d05fde10cfccf5368c4403a206c7cbef8e6f",
            "patch": "@@ -313,6 +313,7 @@ def load_model(self, dtype, attn_implementation=\"sdpa\"):\n             device_map=\"auto\",\n             dtype=dtype,\n             attn_implementation=attn_implementation,\n+            experts_implementation=\"eager\",\n             revision=\"refs/pr/10\",\n         )\n \n@@ -549,6 +550,7 @@ def load_model(self, dtype, attn_implementation=\"sdpa\"):\n             device_map=\"auto\",\n             dtype=dtype,\n             attn_implementation=attn_implementation,\n+            experts_implementation=\"eager\",\n         )\n \n     def test_small_model_integration_test(self):"
        }
    ],
    "stats": {
        "total": 14,
        "additions": 12,
        "deletions": 2
    }
}