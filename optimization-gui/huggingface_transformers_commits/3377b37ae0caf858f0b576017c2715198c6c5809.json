{
    "author": "Cyrilvallez",
    "message": "Less verbose library helpers (#43197)\n\n* setup\n\n* less verbose\n\n* modular check less verbose",
    "sha": "3377b37ae0caf858f0b576017c2715198c6c5809",
    "files": [
        {
            "sha": "2984652af06858eddb49b2ce271b012635dc89fb",
            "filename": "setup.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/3377b37ae0caf858f0b576017c2715198c6c5809/setup.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3377b37ae0caf858f0b576017c2715198c6c5809/setup.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/setup.py?ref=3377b37ae0caf858f0b576017c2715198c6c5809",
            "patch": "@@ -219,7 +219,6 @@ def run(self):\n             \"\",\n         ]\n         target = \"src/transformers/dependency_versions_table.py\"\n-        print(f\"updating {target}\")\n         with open(target, \"w\", encoding=\"utf-8\", newline=\"\\n\") as f:\n             f.write(\"\\n\".join(content))\n "
        },
        {
            "sha": "4f66378ad7415f022c0b9cc6ed01fbfda3b4e1e4",
            "filename": "utils/add_dates.py",
            "status": "modified",
            "additions": 0,
            "deletions": 7,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/3377b37ae0caf858f0b576017c2715198c6c5809/utils%2Fadd_dates.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3377b37ae0caf858f0b576017c2715198c6c5809/utils%2Fadd_dates.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fadd_dates.py?ref=3377b37ae0caf858f0b576017c2715198c6c5809",
            "patch": "@@ -343,12 +343,10 @@ def main(all=False, models=None, check_only=False):\n     if check_only:\n         # Check all model cards for missing dates\n         all_model_cards = get_all_model_cards()\n-        print(f\"Checking all {len(all_model_cards)} model cards for missing dates...\")\n         missing_dates = check_missing_dates(all_model_cards)\n \n         # Check modified model cards for incorrect dates\n         modified_cards = get_modified_cards()\n-        print(f\"Checking {len(modified_cards)} modified model cards for incorrect dates...\")\n         incorrect_dates = check_incorrect_dates(modified_cards)\n \n         if missing_dates or incorrect_dates:\n@@ -358,22 +356,17 @@ def main(all=False, models=None, check_only=False):\n                 f\"Missing or incorrect dates in the following model cards: {' '.join(problematic_cards)}\\n\"\n                 f\"Run `python utils/add_dates.py --models {' '.join(model_names)}` to fix them.\"\n             )\n-        print(\"All dates are present and correct!\")\n         return\n \n     # Determine which model cards to process\n     if all:\n         model_cards = get_all_model_cards()\n-        print(f\"Processing all {len(model_cards)} model cards from docs directory\")\n     elif models:\n         model_cards = models\n-        print(f\"Processing specified model cards: {model_cards}\")\n     else:\n         model_cards = get_modified_cards()\n         if not model_cards:\n-            print(\"No modified model cards found.\")\n             return\n-        print(f\"Processing modified model cards: {model_cards}\")\n \n     insert_dates(model_cards)\n "
        },
        {
            "sha": "4a3173a734e02a28ca9143a708aea7d3d4dbc2d8",
            "filename": "utils/check_docstrings.py",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/3377b37ae0caf858f0b576017c2715198c6c5809/utils%2Fcheck_docstrings.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3377b37ae0caf858f0b576017c2715198c6c5809/utils%2Fcheck_docstrings.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_docstrings.py?ref=3377b37ae0caf858f0b576017c2715198c6c5809",
            "patch": "@@ -1012,8 +1012,6 @@ def find_matching_model_files(check_all: bool = False):\n         # intersect with module_diff_files\n         matching_files = sorted([file for file in matching_files if file in module_diff_files])\n \n-    print(\"    Checking auto_docstrings in the following files:\" + \"\\n    - \" + \"\\n    - \".join(matching_files))\n-\n     return matching_files\n \n \n@@ -1942,7 +1940,6 @@ def check_docstrings(overwrite: bool = False, check_all: bool = False):\n         # quick escape route: if there are no module files in the diff, skip this check\n         if len(module_diff_files) == 0:\n             return\n-        print(\"    Checking docstrings in the following files:\" + \"\\n    - \" + \"\\n    - \".join(module_diff_files))\n \n     failures = []\n     hard_failures = []"
        },
        {
            "sha": "80b4368b15bff49182b4e4393cbc4b7fd760054b",
            "filename": "utils/check_modular_conversion.py",
            "status": "modified",
            "additions": 3,
            "deletions": 19,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/3377b37ae0caf858f0b576017c2715198c6c5809/utils%2Fcheck_modular_conversion.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3377b37ae0caf858f0b576017c2715198c6c5809/utils%2Fcheck_modular_conversion.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_modular_conversion.py?ref=3377b37ae0caf858f0b576017c2715198c6c5809",
            "patch": "@@ -50,15 +50,15 @@ def process_file(\n         # we always save the generated content, to be able to update dependant files\n         with open(file_path, \"w\", encoding=\"utf-8\", newline=\"\\n\") as modeling_file:\n             modeling_file.write(generated_modeling_content[file_type])\n-        console.print(f\"[bold blue]Overwritten {file_path} with the generated content.[/bold blue]\")\n+        if not show_diff:\n+            console.print(f\"[bold blue]Overwritten {file_path} with the generated content.[/bold blue]\")\n         if show_diff:\n             console.print(f\"\\n[bold red]Differences found between the generated code and {file_path}:[/bold red]\\n\")\n             diff_text = \"\\n\".join(diff_list)\n             syntax = Syntax(diff_text, \"diff\", theme=\"ansi_dark\", line_numbers=True)\n             console.print(syntax)\n         return 1\n     else:\n-        console.print(f\"[bold green]No differences found for {file_path}.[/bold green]\")\n         return 0\n \n \n@@ -181,12 +181,8 @@ def guaranteed_no_diff(modular_file_path, dependencies, models_in_diff):\n     else:\n         models_in_diff = get_models_in_diff()\n         if not models_in_diff and not args.check_all:\n-            console.print(\n-                \"[bold green]No models files or model tests in the diff, skipping modular checks[/bold green]\"\n-            )\n             exit(0)\n \n-    skipped_models = set()\n     non_matching_files = []\n     ordered_files, dependencies = find_priority_list(args.files)\n     flat_ordered_files = [item for sublist in ordered_files for item in sublist]\n@@ -198,18 +194,12 @@ def guaranteed_no_diff(modular_file_path, dependencies, models_in_diff):\n     #  - ... and so on\n     # files (models) within the same list are *independent* of each other;\n     # we start applying modular conversion to each list in parallel, starting from the first list\n-\n-    console.print(f\"[bold yellow]Number of dependency levels: {len(ordered_files)}[/bold yellow]\")\n-    console.print(f\"[bold yellow]Files per level: {tuple(len(x) for x in ordered_files)}[/bold yellow]\")\n-\n     try:\n         for dependency_level_files in ordered_files:\n             # Filter files guaranteed no diff\n             files_to_check = []\n             for file_path in dependency_level_files:\n-                if not args.check_all and guaranteed_no_diff(file_path, dependencies, models_in_diff):\n-                    skipped_models.add(file_path.split(\"/\")[-2])  # save model folder name\n-                else:\n+                if args.check_all or not guaranteed_no_diff(file_path, dependencies, models_in_diff):\n                     files_to_check.append(file_path)\n \n             if not files_to_check:\n@@ -260,9 +250,3 @@ def guaranteed_no_diff(modular_file_path, dependencies, models_in_diff):\n         diff_models = set(file_path.split(\"/\")[-2] for file_path in non_matching_files)  # noqa\n         models_str = \"\\n - \" + \"\\n - \".join(sorted(diff_models))\n         raise ValueError(f\"Some diff and their modeling code did not match. Models in diff:{models_str}\")\n-\n-    if skipped_models:\n-        console.print(\n-            f\"[bold green]Skipped {len(skipped_models)} models and their dependencies that are not in the diff: \"\n-            f\"{', '.join(sorted(skipped_models))}[/bold green]\"\n-        )"
        }
    ],
    "stats": {
        "total": 33,
        "additions": 3,
        "deletions": 30
    }
}