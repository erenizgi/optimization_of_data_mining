{
    "author": "jiqing-feng",
    "message": "Fix vits low-precision dtype (#35418)\n\n* fix vits dtype\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\r\n\r\n* add tests\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\r\n\r\n* use weight dtype\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>\r\n\r\n---------\r\n\r\nSigned-off-by: jiqing-feng <jiqing.feng@intel.com>",
    "sha": "641238eb766ecac073e985dbfb926fd55a55600f",
    "files": [
        {
            "sha": "7a506d497f9a266e0ac114fee32d542bb88b654f",
            "filename": "src/transformers/models/vits/modeling_vits.py",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/641238eb766ecac073e985dbfb926fd55a55600f/src%2Ftransformers%2Fmodels%2Fvits%2Fmodeling_vits.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/641238eb766ecac073e985dbfb926fd55a55600f/src%2Ftransformers%2Fmodels%2Fvits%2Fmodeling_vits.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvits%2Fmodeling_vits.py?ref=641238eb766ecac073e985dbfb926fd55a55600f",
            "patch": "@@ -1406,10 +1406,11 @@ def forward(\n         if labels is not None:\n             raise NotImplementedError(\"Training of VITS is not supported yet.\")\n \n+        mask_dtype = self.text_encoder.embed_tokens.weight.dtype\n         if attention_mask is not None:\n-            input_padding_mask = attention_mask.unsqueeze(-1).float()\n+            input_padding_mask = attention_mask.unsqueeze(-1).to(mask_dtype)\n         else:\n-            input_padding_mask = torch.ones_like(input_ids).unsqueeze(-1).float()\n+            input_padding_mask = torch.ones_like(input_ids).unsqueeze(-1).to(mask_dtype)\n \n         if self.config.num_speakers > 1 and speaker_id is not None:\n             if not 0 <= speaker_id < self.config.num_speakers:"
        },
        {
            "sha": "9733fb4bce1e65dec77ef79d2e2946e6a2430753",
            "filename": "tests/models/vits/test_modeling_vits.py",
            "status": "modified",
            "additions": 32,
            "deletions": 0,
            "changes": 32,
            "blob_url": "https://github.com/huggingface/transformers/blob/641238eb766ecac073e985dbfb926fd55a55600f/tests%2Fmodels%2Fvits%2Ftest_modeling_vits.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/641238eb766ecac073e985dbfb926fd55a55600f/tests%2Fmodels%2Fvits%2Ftest_modeling_vits.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvits%2Ftest_modeling_vits.py?ref=641238eb766ecac073e985dbfb926fd55a55600f",
            "patch": "@@ -27,6 +27,7 @@\n     is_flaky,\n     is_torch_available,\n     require_torch,\n+    require_torch_fp16,\n     require_torch_multi_gpu,\n     slow,\n     torch_device,\n@@ -434,3 +435,34 @@ def test_forward(self):\n         )\n         # fmt: on\n         self.assertTrue(torch.allclose(outputs.waveform[0, 10000:10030].cpu(), EXPECTED_LOGITS, atol=1e-4))\n+\n+    @require_torch_fp16\n+    def test_forward_fp16(self):\n+        # GPU gives different results than CPU\n+        torch_device = \"cpu\"\n+\n+        model = VitsModel.from_pretrained(\"facebook/mms-tts-eng\", torch_dtype=torch.float16)\n+        model.to(torch_device)\n+\n+        tokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n+\n+        set_seed(555)  # make deterministic\n+\n+        input_text = \"Mister quilter is the apostle of the middle classes and we are glad to welcome his gospel!\"\n+        input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(torch_device)\n+\n+        with torch.no_grad():\n+            outputs = model(input_ids)\n+\n+        self.assertEqual(outputs.waveform.shape, (1, 87040))\n+        # fmt: off\n+        EXPECTED_LOGITS = torch.tensor(\n+            [\n+                0.0101,  0.0318,  0.0489,  0.0627,  0.0728,  0.0865,  0.1053,  0.1279,\n+                0.1514,  0.1703,  0.1827,  0.1829,  0.1694,  0.1509,  0.1332,  0.1188,\n+                0.1066,  0.0978,  0.0936,  0.0867,  0.0724,  0.0493,  0.0197, -0.0141,\n+                -0.0501, -0.0817, -0.1065, -0.1223, -0.1311, -0.1339\n+            ]\n+        ).to(torch.float16)\n+        # fmt: on\n+        self.assertTrue(torch.allclose(outputs.waveform[0, 10000:10030].cpu(), EXPECTED_LOGITS, atol=1e-4))"
        }
    ],
    "stats": {
        "total": 37,
        "additions": 35,
        "deletions": 2
    }
}