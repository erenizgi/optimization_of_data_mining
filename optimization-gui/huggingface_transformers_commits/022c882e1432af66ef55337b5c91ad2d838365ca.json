{
    "author": "Cyrilvallez",
    "message": "Fix Glm4v test (#41011)\n\nfix",
    "sha": "022c882e1432af66ef55337b5c91ad2d838365ca",
    "files": [
        {
            "sha": "1881fffa9dd9171f73b6df856aa89d6a831a6e90",
            "filename": "tests/models/glm4v_moe/test_modeling_glm4v_moe.py",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/022c882e1432af66ef55337b5c91ad2d838365ca/tests%2Fmodels%2Fglm4v_moe%2Ftest_modeling_glm4v_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/022c882e1432af66ef55337b5c91ad2d838365ca/tests%2Fmodels%2Fglm4v_moe%2Ftest_modeling_glm4v_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fglm4v_moe%2Ftest_modeling_glm4v_moe.py?ref=022c882e1432af66ef55337b5c91ad2d838365ca",
            "patch": "@@ -297,6 +297,7 @@ def test_inputs_embeds_matches_input_ids(self):\n \n \n @require_torch\n+@slow\n class Glm4vMoeIntegrationTest(unittest.TestCase):\n     model = None\n \n@@ -310,7 +311,8 @@ def get_model(cls):\n \n     @classmethod\n     def tearDownClass(cls):\n-        del cls.model\n+        if hasattr(cls, \"model\"):\n+            del cls.model\n         cleanup(torch_device, gc_collect=True)\n \n     def setUp(self):\n@@ -364,7 +366,6 @@ def setUp(self):\n     def tearDown(self):\n         cleanup(torch_device, gc_collect=True)\n \n-    @slow\n     def test_small_model_integration_test(self):\n         inputs = self.processor.apply_chat_template(\n             self.message, tokenize=True, add_generation_prompt=True, return_dict=True, return_tensors=\"pt\"\n@@ -386,7 +387,6 @@ def test_small_model_integration_test(self):\n         )\n         torch.testing.assert_close(expected_pixel_slice, inputs.pixel_values[:6, :3], atol=1e-4, rtol=1e-4)\n \n-    @slow\n     def test_small_model_integration_test_batch(self):\n         model = self.get_model()\n         batch_messages = [self.message, self.message2, self.message_wo_image]\n@@ -414,7 +414,6 @@ def test_small_model_integration_test_batch(self):\n             EXPECTED_DECODED_TEXT,\n         )\n \n-    @slow\n     def test_small_model_integration_test_with_video(self):\n         processor = AutoProcessor.from_pretrained(\"zai-org/GLM-4.5V\", max_image_size={\"longest_edge\": 50176})\n         model = self.get_model()\n@@ -437,7 +436,6 @@ def test_small_model_integration_test_with_video(self):\n         )\n \n     @run_first\n-    @slow\n     @require_flash_attn\n     @require_torch_gpu\n     def test_small_model_integration_test_batch_flashatt2(self):"
        }
    ],
    "stats": {
        "total": 8,
        "additions": 3,
        "deletions": 5
    }
}