{
    "author": "cyyever",
    "message": "Change deprecated PT functions (#37041)\n\nChange deprecated functions",
    "sha": "aa3778afc2ad681edcd253837246d5eb8c62291c",
    "files": [
        {
            "sha": "a8feab0b1a5f2a10fef10025b6f70675112a4a74",
            "filename": "src/transformers/models/clvp/modeling_clvp.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/aa3778afc2ad681edcd253837246d5eb8c62291c/src%2Ftransformers%2Fmodels%2Fclvp%2Fmodeling_clvp.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aa3778afc2ad681edcd253837246d5eb8c62291c/src%2Ftransformers%2Fmodels%2Fclvp%2Fmodeling_clvp.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclvp%2Fmodeling_clvp.py?ref=aa3778afc2ad681edcd253837246d5eb8c62291c",
            "patch": "@@ -1346,8 +1346,8 @@ def _prepare_model_inputs(\n             if hasattr(model_kwargs, \"attention_mask\"):\n                 position_ids = model_kwargs[\"attention_mask\"].long().cumsum(-1) - 1\n             else:\n-                position_ids = torch.range(\n-                    0, conditioning_embeds.shape[1] - 1, dtype=torch.long, device=conditioning_embeds.device\n+                position_ids = torch.arange(\n+                    0, conditioning_embeds.shape[1], dtype=torch.long, device=conditioning_embeds.device\n                 )\n             position_ids = position_ids.unsqueeze(0).repeat(conditioning_embeds.shape[0], 1)\n "
        },
        {
            "sha": "b779dfbe415f333956598d7e7716bec19b40a784",
            "filename": "src/transformers/models/convnextv2/modeling_convnextv2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/aa3778afc2ad681edcd253837246d5eb8c62291c/src%2Ftransformers%2Fmodels%2Fconvnextv2%2Fmodeling_convnextv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aa3778afc2ad681edcd253837246d5eb8c62291c/src%2Ftransformers%2Fmodels%2Fconvnextv2%2Fmodeling_convnextv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fconvnextv2%2Fmodeling_convnextv2.py?ref=aa3778afc2ad681edcd253837246d5eb8c62291c",
            "patch": "@@ -100,7 +100,7 @@ def __init__(self, dim: int):\n \n     def forward(self, hidden_states: torch.FloatTensor) -> torch.FloatTensor:\n         # Compute and normalize global spatial feature maps\n-        global_features = torch.norm(hidden_states, p=2, dim=(1, 2), keepdim=True)\n+        global_features = torch.linalg.norm(hidden_states, ord=2, dim=(1, 2), keepdim=True)\n         norm_features = global_features / (global_features.mean(dim=-1, keepdim=True) + 1e-6)\n         hidden_states = self.weight * (hidden_states * norm_features) + self.bias + hidden_states\n "
        },
        {
            "sha": "0fd1bad62662de0a4658f0472f6bf1b38eb562b7",
            "filename": "src/transformers/models/deprecated/jukebox/modeling_jukebox.py",
            "status": "modified",
            "additions": 9,
            "deletions": 5,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/aa3778afc2ad681edcd253837246d5eb8c62291c/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fjukebox%2Fmodeling_jukebox.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/aa3778afc2ad681edcd253837246d5eb8c62291c/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fjukebox%2Fmodeling_jukebox.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fjukebox%2Fmodeling_jukebox.py?ref=aa3778afc2ad681edcd253837246d5eb8c62291c",
            "patch": "@@ -429,19 +429,21 @@ def update_codebook(self, hidden_states, latent_states):\n             entropy = -torch.sum(_codebook_prob * torch.log(_codebook_prob + 1e-8))  # entropy ie how diverse\n             used_curr = (_codebook_elem >= self.threshold).sum()\n             usage = torch.sum(usage)\n-            dk = torch.norm(self.codebook - old_codebook) / np.sqrt(np.prod(old_codebook.shape))\n+            dk = torch.linalg.norm(self.codebook - old_codebook) / np.sqrt(np.prod(old_codebook.shape))\n         return {\"entropy\": entropy, \"used_curr\": used_curr, \"usage\": usage, \"dk\": dk}\n \n     def preprocess(self, hidden_states):\n         hidden_states = hidden_states.permute(0, 2, 1).contiguous()\n         hidden_states = hidden_states.view(-1, hidden_states.shape[-1])\n \n         if hidden_states.shape[-1] == self.codebook_width:\n-            prenorm = torch.norm(hidden_states - torch.mean(hidden_states)) / np.sqrt(np.prod(hidden_states.shape))\n+            prenorm = torch.linalg.norm(hidden_states - torch.mean(hidden_states)) / np.sqrt(\n+                np.prod(hidden_states.shape)\n+            )\n         elif hidden_states.shape[-1] == 2 * self.codebook_width:\n             x1, x2 = hidden_states[..., : self.codebook_width], hidden_states[..., self.codebook_width :]\n-            prenorm = (torch.norm(x1 - torch.mean(x1)) / np.sqrt(np.prod(x1.shape))) + (\n-                torch.norm(x2 - torch.mean(x2)) / np.sqrt(np.prod(x2.shape))\n+            prenorm = (torch.linalg.norm(x1 - torch.mean(x1)) / np.sqrt(np.prod(x1.shape))) + (\n+                torch.linalg.norm(x2 - torch.mean(x2)) / np.sqrt(np.prod(x2.shape))\n             )\n \n             # Normalise\n@@ -517,7 +519,9 @@ def forward(self, hidden_states, update_codebook=True):\n             update_metrics = {}\n \n         # Loss\n-        commit_loss = torch.norm(dequantised_states.detach() - hidden_states) ** 2 / np.prod(hidden_states.shape)\n+        commit_loss = torch.linalg.norm(dequantised_states.detach() - hidden_states) ** 2 / np.prod(\n+            hidden_states.shape\n+        )\n \n         # Passthrough\n         dequantised_states = hidden_states + (dequantised_states - hidden_states).detach()"
        }
    ],
    "stats": {
        "total": 20,
        "additions": 12,
        "deletions": 8
    }
}