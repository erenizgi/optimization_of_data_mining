{
    "author": "ydshieh",
    "message": "disable `test_fast_is_faster_than_slow` (#40909)\n\nfix\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5",
    "files": [
        {
            "sha": "8661d6a8da40ecfa4b0b9227fe74168320a174fb",
            "filename": "tests/models/depth_pro/test_image_processing_depth_pro.py",
            "status": "modified",
            "additions": 1,
            "deletions": 7,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Fdepth_pro%2Ftest_image_processing_depth_pro.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Fdepth_pro%2Ftest_image_processing_depth_pro.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdepth_pro%2Ftest_image_processing_depth_pro.py?ref=88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5",
            "patch": "@@ -15,7 +15,7 @@\n \n import unittest\n \n-from transformers.testing_utils import is_flaky, require_torch, require_vision\n+from transformers.testing_utils import require_torch, require_vision\n from transformers.utils import is_torchvision_available, is_vision_available\n \n from ...test_image_processing_common import ImageProcessingTestMixin, prepare_image_inputs\n@@ -115,9 +115,3 @@ def test_image_processor_from_dict_with_kwargs(self):\n \n         image_processor = self.image_processing_class.from_dict(self.image_processor_dict, size=42)\n         self.assertEqual(image_processor.size, {\"height\": 42, \"width\": 42})\n-\n-    @is_flaky(\n-        description=\"fast and slow, both processors use torch implementation, see: https://github.com/huggingface/transformers/issues/34920\",\n-    )\n-    def test_fast_is_faster_than_slow(self):\n-        super().test_fast_is_faster_than_slow()"
        },
        {
            "sha": "ba142974b78d273905f6927e669e6c1fe1ae38fb",
            "filename": "tests/models/efficientloftr/test_image_processing_efficientloftr.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Fefficientloftr%2Ftest_image_processing_efficientloftr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Fefficientloftr%2Ftest_image_processing_efficientloftr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fefficientloftr%2Ftest_image_processing_efficientloftr.py?ref=88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5",
            "patch": "@@ -143,6 +143,7 @@ def test_slow_fast_equivalence_batched(self):\n \n         self._assert_slow_fast_tensors_equivalence(encoding_slow.pixel_values, encoding_fast.pixel_values)\n \n+    @unittest.skip(reason=\"Many failing cases. This test needs a more deep investigation.\")\n     def test_fast_is_faster_than_slow(self):\n         \"\"\"Override the generic test since EfficientLoFTR requires image pairs.\"\"\"\n         if not self.test_slow_image_processor or not self.test_fast_image_processor:"
        },
        {
            "sha": "05d2813f98ca744684d532393572862f39aca065",
            "filename": "tests/models/kosmos2_5/test_image_processing_kosmos2_5.py",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Fkosmos2_5%2Ftest_image_processing_kosmos2_5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Fkosmos2_5%2Ftest_image_processing_kosmos2_5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fkosmos2_5%2Ftest_image_processing_kosmos2_5.py?ref=88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5",
            "patch": "@@ -177,12 +177,6 @@ def test_can_compile_fast_image_processor(self):\n             output_eager.pixel_values, output_compiled.pixel_values, atol=1e-4, rtol=1e-4, mean_atol=1e-5\n         )\n \n-    @unittest.skip(\n-        reason=\"Kosmos2_5ImageProcessor already uses many torch operations. Fast image processor only works faster with sufficiently large batch size on GPU.\"\n-    )\n-    def test_fast_is_faster_than_slow(self):\n-        super().test_fast_is_faster_than_slow()\n-\n     def test_image_processor_properties(self):\n         image_processor = self.image_processing_class(**self.image_processor_dict)\n         self.assertTrue(hasattr(image_processor, \"do_normalize\"))\n@@ -376,12 +370,6 @@ def test_slow_fast_equivalence_batched(self):\n     def test_can_compile_fast_image_processor(self):\n         return super().test_can_compile_fast_image_processor()\n \n-    @unittest.skip(\n-        reason=\"Kosmos2_5ImageProcessor already uses many torch operations. Fast image processor only works faster with sufficiently large batch size on GPU.\"\n-    )\n-    def test_fast_is_faster_than_slow(self):\n-        super().test_fast_is_faster_than_slow()\n-\n     def test_image_processor_properties(self):\n         image_processor = self.image_processing_class(**self.image_processor_dict)\n         self.assertTrue(hasattr(image_processor, \"do_normalize\"))"
        },
        {
            "sha": "9c2a3eee735d5412510dcdf0b45e08b24ba2289b",
            "filename": "tests/models/layoutlmv2/test_image_processing_layoutlmv2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Flayoutlmv2%2Ftest_image_processing_layoutlmv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Flayoutlmv2%2Ftest_image_processing_layoutlmv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flayoutlmv2%2Ftest_image_processing_layoutlmv2.py?ref=88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5",
            "patch": "@@ -105,10 +105,6 @@ def setUp(self):\n     def image_processor_dict(self):\n         return self.image_processor_tester.prepare_image_processor_dict()\n \n-    @unittest.skip(reason=\"FIXME: @yoni.\")\n-    def test_fast_is_faster_than_slow(self):\n-        pass\n-\n     def test_image_processor_properties(self):\n         for image_processing_class in self.image_processor_list:\n             image_processing = image_processing_class(**self.image_processor_dict)"
        },
        {
            "sha": "8d3577e553717e3d78f42b3792a992652ad7339c",
            "filename": "tests/models/layoutlmv3/test_image_processing_layoutlmv3.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Flayoutlmv3%2Ftest_image_processing_layoutlmv3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Flayoutlmv3%2Ftest_image_processing_layoutlmv3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flayoutlmv3%2Ftest_image_processing_layoutlmv3.py?ref=88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5",
            "patch": "@@ -86,10 +86,6 @@ def setUp(self):\n     def image_processor_dict(self):\n         return self.image_processor_tester.prepare_image_processor_dict()\n \n-    @unittest.skip(reason=\"FIXME: @yoni.\")\n-    def test_fast_is_faster_than_slow(self):\n-        pass\n-\n     def test_image_processor_properties(self):\n         for image_processing_class in self.image_processor_list:\n             image_processing = image_processing_class(**self.image_processor_dict)"
        },
        {
            "sha": "230665087746a7aef7c01fad551ec9f5ef110d04",
            "filename": "tests/models/owlv2/test_image_processing_owlv2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Fowlv2%2Ftest_image_processing_owlv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Fowlv2%2Ftest_image_processing_owlv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fowlv2%2Ftest_image_processing_owlv2.py?ref=88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5",
            "patch": "@@ -99,10 +99,6 @@ def setUp(self):\n     def image_processor_dict(self):\n         return self.image_processor_tester.prepare_image_processor_dict()\n \n-    @unittest.skip(reason=\"FIXME: @yoni. It always fails: `0.12 not less than or equal to 0.03`.\")\n-    def test_fast_is_faster_than_slow(self):\n-        super().test_fast_is_faster_than_slow()\n-\n     def test_image_processor_properties(self):\n         for image_processing_class in self.image_processor_list:\n             image_processing = image_processing_class(**self.image_processor_dict)"
        },
        {
            "sha": "15e07d40e2cb61ee44e90547b1ef2b8986e097d8",
            "filename": "tests/models/rt_detr/test_image_processing_rt_detr.py",
            "status": "modified",
            "additions": 0,
            "deletions": 7,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Frt_detr%2Ftest_image_processing_rt_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Frt_detr%2Ftest_image_processing_rt_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Frt_detr%2Ftest_image_processing_rt_detr.py?ref=88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5",
            "patch": "@@ -16,7 +16,6 @@\n \n from transformers.image_utils import load_image\n from transformers.testing_utils import (\n-    is_flaky,\n     require_torch,\n     require_torch_accelerator,\n     require_torchvision,\n@@ -435,9 +434,3 @@ def test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations(s\n         )\n         # verify size\n         torch.testing.assert_close(encoding_cpu[\"labels\"][0][\"size\"], encoding_gpu[\"labels\"][0][\"size\"].to(\"cpu\"))\n-\n-    @is_flaky(\n-        description=\"Still flaky with a failing ratio of ~0.6% after #36240\",\n-    )\n-    def test_fast_is_faster_than_slow(self):\n-        super().test_fast_is_faster_than_slow()"
        },
        {
            "sha": "eecb023c29a0b6e67f15e872a7c230a154bb7b84",
            "filename": "tests/models/swin2sr/test_image_processing_swin2sr.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Fswin2sr%2Ftest_image_processing_swin2sr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Fswin2sr%2Ftest_image_processing_swin2sr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fswin2sr%2Ftest_image_processing_swin2sr.py?ref=88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5",
            "patch": "@@ -187,10 +187,6 @@ def test_call_pytorch(self):\n         expected_output_image_shape = self.image_processor_tester.expected_output_image_shape([image_inputs[0]])\n         self.assertEqual(tuple(encoded_images.shape), (1, *expected_output_image_shape))\n \n-    @unittest.skip(reason=\"No speed gain on CPU due to minimal processing.\")\n-    def test_fast_is_faster_than_slow(self):\n-        pass\n-\n     def test_slow_fast_equivalence_batched(self):\n         image_inputs = self.image_processor_tester.prepare_image_inputs(equal_resolution=True, torchify=True)\n "
        },
        {
            "sha": "dc5597b1918b50c953653cde0e955637af5e16ad",
            "filename": "tests/models/vitmatte/test_image_processing_vitmatte.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Fvitmatte%2Ftest_image_processing_vitmatte.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Fmodels%2Fvitmatte%2Ftest_image_processing_vitmatte.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvitmatte%2Ftest_image_processing_vitmatte.py?ref=88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5",
            "patch": "@@ -266,7 +266,7 @@ def test_image_processor_preprocess_arguments(self):\n             self.assertGreaterEqual(len(raised_warnings), 1)\n             self.assertIn(\"extra_argument\", messages)\n \n-    @unittest.skip(reason=\"TODO: Yoni\")\n+    @unittest.skip(reason=\"Many failing cases. This test needs a more deep investigation.\")\n     def test_fast_is_faster_than_slow(self):\n         if not self.test_slow_image_processor or not self.test_fast_image_processor:\n             self.skipTest(reason=\"Skipping speed test\")"
        },
        {
            "sha": "b98c94093e2d58df2047525f4706c970a61221b6",
            "filename": "tests/test_image_processing_common.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Ftest_image_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5/tests%2Ftest_image_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_image_processing_common.py?ref=88ba0f107eb8c96b34bbe664f17f07ce0c8c57b5",
            "patch": "@@ -18,6 +18,7 @@\n import pathlib\n import tempfile\n import time\n+import unittest\n import warnings\n from copy import deepcopy\n \n@@ -30,7 +31,6 @@\n from transformers.image_utils import AnnotationFormat, AnnotionFormat\n from transformers.testing_utils import (\n     check_json_file_has_correct_format,\n-    is_flaky,\n     require_torch,\n     require_torch_accelerator,\n     require_vision,\n@@ -216,7 +216,7 @@ def test_slow_fast_equivalence_batched(self):\n \n     @require_vision\n     @require_torch\n-    @is_flaky()\n+    @unittest.skip(reason=\"Many failing cases. This test needs a more deep investigation.\")\n     def test_fast_is_faster_than_slow(self):\n         if not self.test_slow_image_processor or not self.test_fast_image_processor:\n             self.skipTest(reason=\"Skipping speed test\")"
        }
    ],
    "stats": {
        "total": 50,
        "additions": 5,
        "deletions": 45
    }
}