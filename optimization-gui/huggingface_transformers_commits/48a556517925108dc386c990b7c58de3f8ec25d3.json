{
    "author": "ducviet00",
    "message": "Add support for Florence-2 training (#40914)\n\n* Support training florence2\n\n* update doc and testing model to florence-community\n\n* fix florence-2 test, use head dim 16 instead of 8 for fa2\n\n* skip test_sdpa_can_dispatch_on_flash\n\n* Apply style fixes\n\n---------\n\nCo-authored-by: github-actions[bot] <github-actions[bot]@users.noreply.github.com>",
    "sha": "48a556517925108dc386c990b7c58de3f8ec25d3",
    "files": [
        {
            "sha": "14865320206770680ca84a22eaafafabf955e0e1",
            "filename": "docs/source/en/model_doc/florence2.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/48a556517925108dc386c990b7c58de3f8ec25d3/docs%2Fsource%2Fen%2Fmodel_doc%2Fflorence2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/48a556517925108dc386c990b7c58de3f8ec25d3/docs%2Fsource%2Fen%2Fmodel_doc%2Fflorence2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fflorence2.md?ref=48a556517925108dc386c990b7c58de3f8ec25d3",
            "patch": "@@ -44,7 +44,7 @@ from transformers import pipeline\n \n pipeline = pipeline(\n     \"image-text-to-text\",\n-    model=\"ducviet00/Florence-2-base-hf\",\n+    model=\"florence-community/Florence-2-base\",\n     device=0,\n     dtype=torch.bfloat16\n )"
        },
        {
            "sha": "0c1cf26fa4bc2c89243ab4adc014c5a67dc52e78",
            "filename": "src/transformers/models/florence2/modeling_florence2.py",
            "status": "modified",
            "additions": 29,
            "deletions": 0,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/48a556517925108dc386c990b7c58de3f8ec25d3/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodeling_florence2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/48a556517925108dc386c990b7c58de3f8ec25d3/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodeling_florence2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodeling_florence2.py?ref=48a556517925108dc386c990b7c58de3f8ec25d3",
            "patch": "@@ -33,6 +33,7 @@\n     auto_docstring,\n     can_return_tuple,\n     is_torch_available,\n+    logging,\n )\n from ..auto import AutoModel\n from .configuration_florence2 import Florence2Config, Florence2VisionConfig\n@@ -44,6 +45,9 @@\n     import torch.nn.functional as F\n \n \n+logger = logging.get_logger(__name__)\n+\n+\n def drop_path(input: torch.Tensor, drop_prob: float = 0.0, training: bool = False) -> torch.Tensor:\n     \"\"\"\n     Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n@@ -793,6 +797,22 @@ def get_encoder(self):\n         return self.language_model.get_encoder()\n \n \n+def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int):\n+    \"\"\"\n+    Shift input ids one token to the right.\n+    \"\"\"\n+    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n+    shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n+    shifted_input_ids[:, 0] = decoder_start_token_id\n+\n+    if pad_token_id is None:\n+        raise ValueError(\"self.model.config.pad_token_id has to be defined.\")\n+    # replace possible -100 values in labels by `pad_token_id`\n+    shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n+\n+    return shifted_input_ids\n+\n+\n @auto_docstring(\n     custom_intro=\"\"\"\n     Florence-2 is a vision model for captioning, detection, and segmentation.\n@@ -901,6 +921,15 @@ def forward(\n         )\n         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n \n+        if labels is not None:\n+            if use_cache:\n+                logger.warning(\"The `use_cache` argument is changed to `False` since `labels` is provided.\")\n+            use_cache = False\n+            if decoder_input_ids is None and decoder_inputs_embeds is None:\n+                decoder_input_ids = shift_tokens_right(\n+                    labels, self.config.text_config.pad_token_id, self.config.text_config.decoder_start_token_id\n+                )\n+\n         outputs = self.model(\n             input_ids=input_ids,\n             pixel_values=pixel_values,"
        },
        {
            "sha": "d82d9ac5255e70df65bedb7710ee22d9b89553f6",
            "filename": "src/transformers/models/florence2/modular_florence2.py",
            "status": "modified",
            "additions": 10,
            "deletions": 1,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/48a556517925108dc386c990b7c58de3f8ec25d3/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodular_florence2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/48a556517925108dc386c990b7c58de3f8ec25d3/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodular_florence2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflorence2%2Fmodular_florence2.py?ref=48a556517925108dc386c990b7c58de3f8ec25d3",
            "patch": "@@ -36,7 +36,7 @@\n     logging,\n )\n from ..auto import CONFIG_MAPPING, AutoConfig\n-from ..bart.modeling_bart import eager_attention_forward\n+from ..bart.modeling_bart import eager_attention_forward, shift_tokens_right\n from ..beit.modeling_beit import BeitDropPath\n from ..llama4.modeling_llama4 import Llama4VisionMLP\n from ..llava.modeling_llava import LlavaForConditionalGeneration, LlavaModel, LlavaPreTrainedModel\n@@ -1710,6 +1710,15 @@ def forward(\n         )\n         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n \n+        if labels is not None:\n+            if use_cache:\n+                logger.warning(\"The `use_cache` argument is changed to `False` since `labels` is provided.\")\n+            use_cache = False\n+            if decoder_input_ids is None and decoder_inputs_embeds is None:\n+                decoder_input_ids = shift_tokens_right(\n+                    labels, self.config.text_config.pad_token_id, self.config.text_config.decoder_start_token_id\n+                )\n+\n         outputs = self.model(\n             input_ids=input_ids,\n             pixel_values=pixel_values,"
        },
        {
            "sha": "e191bf1032d6107cdaadafafe1b6876b7085dddd",
            "filename": "tests/models/florence2/test_modeling_florence2.py",
            "status": "modified",
            "additions": 17,
            "deletions": 13,
            "changes": 30,
            "blob_url": "https://github.com/huggingface/transformers/blob/48a556517925108dc386c990b7c58de3f8ec25d3/tests%2Fmodels%2Fflorence2%2Ftest_modeling_florence2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/48a556517925108dc386c990b7c58de3f8ec25d3/tests%2Fmodels%2Fflorence2%2Ftest_modeling_florence2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fflorence2%2Ftest_modeling_florence2.py?ref=48a556517925108dc386c990b7c58de3f8ec25d3",
            "patch": "@@ -58,11 +58,11 @@ def __init__(\n         vocab_size=99,\n         max_position_embeddings=64,\n         encoder_layers=1,\n-        encoder_ffn_dim=8,\n+        encoder_ffn_dim=16,\n         decoder_layers=1,\n-        decoder_ffn_dim=8,\n+        decoder_ffn_dim=16,\n         num_attention_heads=1,\n-        d_model=8,\n+        d_model=16,\n         activation_function=\"gelu\",\n         dropout=0.1,\n         eos_token_id=2,\n@@ -74,12 +74,12 @@ def __init__(\n         patch_stride=[4],\n         patch_padding=[3],\n         patch_prenorm=[False],\n-        embed_dim=[8],\n+        embed_dim=[16],\n         num_heads=[1],\n         num_groups=[1],\n         window_size=12,\n         drop_path_rate=0.1,\n-        projection_dim=8,\n+        projection_dim=16,\n     ):\n         self.parent = parent\n         self.batch_size = batch_size\n@@ -215,6 +215,10 @@ def create_and_check_florence2_model_fp16_forward(self, config, input_ids, pixel\n     def test_load_save_without_tied_weights(self):\n         pass\n \n+    @unittest.skip(reason=\"SDPA can't dispatch on flash due to unsupported qkv stride\")\n+    def test_sdpa_can_dispatch_on_flash(self):\n+        pass\n+\n \n @require_torch\n class Florence2ForConditionalGenerationModelTest(ModelTesterMixin, GenerationTesterMixin, unittest.TestCase):\n@@ -271,7 +275,7 @@ def tearDown(self):\n         cleanup(torch_device, gc_collect=True)\n \n     def test_base_model_inference_eager(self):\n-        model_name = \"ducviet00/Florence-2-base-hf\"\n+        model_name = \"florence-community/Florence-2-base\"\n         processor = AutoProcessor.from_pretrained(model_name)\n         model = Florence2ForConditionalGeneration.from_pretrained(model_name, attn_implementation=\"eager\").to(\n             torch_device\n@@ -295,7 +299,7 @@ def test_base_model_inference_eager(self):\n         self.assertEqual(generated_text, EXPECTED_GENERATED_TEXT)\n \n     def test_base_model_batching_inference_eager(self):\n-        model_name = \"ducviet00/Florence-2-base-hf\"\n+        model_name = \"florence-community/Florence-2-base\"\n         processor = AutoProcessor.from_pretrained(model_name)\n         model = Florence2ForConditionalGeneration.from_pretrained(model_name, attn_implementation=\"eager\").to(\n             torch_device\n@@ -343,7 +347,7 @@ def test_base_model_batching_inference_eager(self):\n         self.assertEqual(parsed_answer_1, EXPECTED_PARSED_ANSWER_1)\n \n     def test_base_model_inference_sdpa(self):\n-        model_name = \"ducviet00/Florence-2-base-hf\"\n+        model_name = \"florence-community/Florence-2-base\"\n         processor = AutoProcessor.from_pretrained(model_name)\n         model = Florence2ForConditionalGeneration.from_pretrained(model_name, attn_implementation=\"sdpa\").to(\n             torch_device\n@@ -375,7 +379,7 @@ def test_base_model_inference_sdpa(self):\n         self.assertEqual(parsed_answer, EXPECTED_PARSED_ANSWER)\n \n     def test_base_model_batching_inference_sdpa(self):\n-        model_name = \"ducviet00/Florence-2-base-hf\"\n+        model_name = \"florence-community/Florence-2-base\"\n         processor = AutoProcessor.from_pretrained(model_name)\n         model = Florence2ForConditionalGeneration.from_pretrained(model_name, attn_implementation=\"sdpa\").to(\n             torch_device\n@@ -415,7 +419,7 @@ def test_base_model_batching_inference_sdpa(self):\n         self.assertEqual(parsed_answer, EXPECTED_PARSED_ANSWER)\n \n     def test_large_model_inference_eager(self):\n-        model_name = \"ducviet00/Florence-2-large-hf\"\n+        model_name = \"florence-community/Florence-2-large\"\n         processor = AutoProcessor.from_pretrained(model_name)\n         model = Florence2ForConditionalGeneration.from_pretrained(model_name, attn_implementation=\"eager\").to(\n             torch_device\n@@ -439,7 +443,7 @@ def test_large_model_inference_eager(self):\n         self.assertEqual(generated_text, EXPECTED_GENERATED_TEXT)\n \n     def test_large_model_batching_inference_eager(self):\n-        model_name = \"ducviet00/Florence-2-large-hf\"\n+        model_name = \"florence-community/Florence-2-large\"\n         processor = AutoProcessor.from_pretrained(model_name)\n         model = Florence2ForConditionalGeneration.from_pretrained(model_name, attn_implementation=\"eager\").to(\n             torch_device\n@@ -485,7 +489,7 @@ def test_large_model_batching_inference_eager(self):\n         self.assertEqual(parsed_answer_1, EXPECTED_PARSED_ANSWER_1)\n \n     def test_large_model_inference_sdpa(self):\n-        model_name = \"ducviet00/Florence-2-large-hf\"\n+        model_name = \"florence-community/Florence-2-large\"\n         processor = AutoProcessor.from_pretrained(model_name)\n         model = Florence2ForConditionalGeneration.from_pretrained(model_name, attn_implementation=\"sdpa\").to(\n             torch_device\n@@ -517,7 +521,7 @@ def test_large_model_inference_sdpa(self):\n         self.assertEqual(parsed_answer, EXPECTED_PARSED_ANSWER)\n \n     def test_large_model_batching_inference_sdpa(self):\n-        model_name = \"ducviet00/Florence-2-large-hf\"\n+        model_name = \"florence-community/Florence-2-large\"\n         processor = AutoProcessor.from_pretrained(model_name)\n         model = Florence2ForConditionalGeneration.from_pretrained(model_name, attn_implementation=\"sdpa\").to(\n             torch_device"
        },
        {
            "sha": "351e4768e53d69f66e262a8d00d2eb57f66f385a",
            "filename": "tests/models/florence2/test_processing_florence2.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/48a556517925108dc386c990b7c58de3f8ec25d3/tests%2Fmodels%2Fflorence2%2Ftest_processing_florence2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/48a556517925108dc386c990b7c58de3f8ec25d3/tests%2Fmodels%2Fflorence2%2Ftest_processing_florence2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fflorence2%2Ftest_processing_florence2.py?ref=48a556517925108dc386c990b7c58de3f8ec25d3",
            "patch": "@@ -38,9 +38,9 @@ class Florence2ProcessorTest(ProcessorTesterMixin, unittest.TestCase):\n     def setUpClass(cls):\n         cls.tmpdirname = tempfile.mkdtemp()\n \n-        image_processor = CLIPImageProcessor.from_pretrained(\"ducviet00/Florence-2-base-hf\")\n+        image_processor = CLIPImageProcessor.from_pretrained(\"florence-community/Florence-2-base\")\n         image_processor.image_seq_length = 0\n-        tokenizer = BartTokenizerFast.from_pretrained(\"ducviet00/Florence-2-base-hf\")\n+        tokenizer = BartTokenizerFast.from_pretrained(\"florence-community/Florence-2-base\")\n         tokenizer.image_token = \"<image>\"\n         tokenizer.image_token_id = tokenizer.encode(tokenizer.image_token, add_special_tokens=False)[0]\n         tokenizer.extra_special_tokens = {\"image_token\": \"<image>\"}"
        }
    ],
    "stats": {
        "total": 76,
        "additions": 59,
        "deletions": 17
    }
}