{
    "author": "killight98",
    "message": "fix error vocab_size at Qwen2_5_VLForConditionalGeneration loss_function (#40130)\n\n* fix error vocab_size at Qwen2_5_VLForConditionalGeneration loss_function\n\nSigned-off-by: luoxiaoc <xiaochuan.luo@intel.com>\n\n* fix similar errer at qwen2_vl and do make fix-copies\n\nSigned-off-by: luoxiaoc <xiaochuan.luo@intel.com>\n\n* pass in kwargs for loss_func at qwen2_vl and qwen2_5_vl\n\nSigned-off-by: luoxiaoc <xiaochuan.luo@intel.com>\n\n* Apply style fixes\n\n---------\n\nSigned-off-by: luoxiaoc <xiaochuan.luo@intel.com>\nCo-authored-by: github-actions[bot] <github-actions[bot]@users.noreply.github.com>",
    "sha": "eb2f9da096fc59dd80ed14d4165719887dfeb792",
    "files": [
        {
            "sha": "90d36320b2fd0fa8d2d41fcf81bbb07c48ceb6cb",
            "filename": "src/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/eb2f9da096fc59dd80ed14d4165719887dfeb792/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/eb2f9da096fc59dd80ed14d4165719887dfeb792/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodeling_qwen2_5_vl.py?ref=eb2f9da096fc59dd80ed14d4165719887dfeb792",
            "patch": "@@ -1524,7 +1524,9 @@ def forward(\n \n         loss = None\n         if labels is not None:\n-            loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size)\n+            loss = self.loss_function(\n+                logits=logits, labels=labels, vocab_size=self.config.text_config.vocab_size, **kwargs\n+            )\n \n         return Qwen2_5_VLCausalLMOutputWithPast(\n             loss=loss,"
        },
        {
            "sha": "1e3f4d87359fe445a304c8513559585753ab929e",
            "filename": "src/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/eb2f9da096fc59dd80ed14d4165719887dfeb792/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/eb2f9da096fc59dd80ed14d4165719887dfeb792/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py?ref=eb2f9da096fc59dd80ed14d4165719887dfeb792",
            "patch": "@@ -749,7 +749,9 @@ def forward(\n \n         loss = None\n         if labels is not None:\n-            loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size)\n+            loss = self.loss_function(\n+                logits=logits, labels=labels, vocab_size=self.config.text_config.vocab_size, **kwargs\n+            )\n \n         return Qwen2_5_VLCausalLMOutputWithPast(\n             loss=loss,"
        },
        {
            "sha": "0df3e9215e21b1e17987f023bf89e7a757ecc9aa",
            "filename": "src/transformers/models/qwen2_vl/modeling_qwen2_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/eb2f9da096fc59dd80ed14d4165719887dfeb792/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/eb2f9da096fc59dd80ed14d4165719887dfeb792/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fmodeling_qwen2_vl.py?ref=eb2f9da096fc59dd80ed14d4165719887dfeb792",
            "patch": "@@ -1405,7 +1405,9 @@ def forward(\n \n         loss = None\n         if labels is not None:\n-            loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size)\n+            loss = self.loss_function(\n+                logits=logits, labels=labels, vocab_size=self.config.text_config.vocab_size, **kwargs\n+            )\n \n         return Qwen2VLCausalLMOutputWithPast(\n             loss=loss,"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 9,
        "deletions": 3
    }
}