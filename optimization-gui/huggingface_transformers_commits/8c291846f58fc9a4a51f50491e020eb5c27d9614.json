{
    "author": "yao-matrix",
    "message": "extend 2 blip2 and falcon_h1 test cases to xpu (#41825)\n\n* extend 2 blip2 and falcon_h1 test cases to xpu\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>\n\n* fix style\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>\n\n* xx\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>\n\n---------\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>",
    "sha": "8c291846f58fc9a4a51f50491e020eb5c27d9614",
    "files": [
        {
            "sha": "035236bcd5fcc38ecb1a63b00ae8383399254cef",
            "filename": "tests/models/blip_2/test_modeling_blip_2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/8c291846f58fc9a4a51f50491e020eb5c27d9614/tests%2Fmodels%2Fblip_2%2Ftest_modeling_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8c291846f58fc9a4a51f50491e020eb5c27d9614/tests%2Fmodels%2Fblip_2%2Ftest_modeling_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fblip_2%2Ftest_modeling_blip_2.py?ref=8c291846f58fc9a4a51f50491e020eb5c27d9614",
            "patch": "@@ -28,7 +28,6 @@\n     require_torch,\n     require_torch_accelerator,\n     require_torch_fp16,\n-    require_torch_gpu,\n     require_torch_multi_accelerator,\n     require_vision,\n     slow,\n@@ -1734,7 +1733,7 @@ def test_inference_t5_multi_accelerator(self):\n         self.assertEqual(predictions[0].tolist(), expected_ids_and_text[0])\n         self.assertEqual(generated_text, expected_ids_and_text[1])\n \n-    @require_torch_gpu\n+    @require_torch_accelerator\n     def test_inference_itm(self):\n         model_name = \"Salesforce/blip2-itm-vit-g\"\n         processor = Blip2Processor.from_pretrained(model_name)"
        },
        {
            "sha": "c2d53baa4734c41221ce9a4f50483feeea75f813",
            "filename": "tests/models/falcon_h1/test_modeling_falcon_h1.py",
            "status": "modified",
            "additions": 29,
            "deletions": 4,
            "changes": 33,
            "blob_url": "https://github.com/huggingface/transformers/blob/8c291846f58fc9a4a51f50491e020eb5c27d9614/tests%2Fmodels%2Ffalcon_h1%2Ftest_modeling_falcon_h1.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8c291846f58fc9a4a51f50491e020eb5c27d9614/tests%2Fmodels%2Ffalcon_h1%2Ftest_modeling_falcon_h1.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ffalcon_h1%2Ftest_modeling_falcon_h1.py?ref=8c291846f58fc9a4a51f50491e020eb5c27d9614",
            "patch": "@@ -23,7 +23,7 @@\n     Expectations,\n     get_device_properties,\n     require_torch,\n-    require_torch_gpu,\n+    require_torch_accelerator,\n     slow,\n     torch_device,\n )\n@@ -400,7 +400,7 @@ def test_left_padding_compatibility(self):\n \n @slow\n @require_torch\n-@require_torch_gpu\n+@require_torch_accelerator\n class FalconH1ModelIntegrationTest(unittest.TestCase):\n     @slow\n     def test_falcon_h1_hard(self):\n@@ -448,10 +448,36 @@ def test_falcon_h1_hard(self):\n             6.\n         \"\"\"\n \n+        EXPECTED_TEXT_XPU = \"\"\"\n+            user\n+            Tell me about the french revolution.\n+            assistant\n+            The French Revolution (1789–1799) was a period of radical social and political upheaval in France that fundamentally transformed the nation and had profound effects on the rest of Europe and the world. Here are the key aspects of the revolution:\n+\n+            ### **Causes**\n+            1. **Economic Crisis**: France was in severe financial trouble due to costly wars (particularly the American Revolution), extravagant spending by the monarchy, and inefficient taxation.\n+            2. **Social Inequality**: The rigid class system (the Ancien Régime) favored the nobility and clergy while the majority of the population (the Third Estate) bore the brunt of taxation and had limited rights.\n+            3. **Enlightenment Ideas**: Philosophers like Rousseau, Voltaire, and Montesquieu inspired ideas of liberty, equality, and popular sovereignty.\n+            4. **Settlement of 1789**: The Estates-General convened to address the financial crisis, leading to debates that exposed the weaknesses of the monarchy and the grievances of the common people.\n+\n+            ### **Key Events**\n+            1. **Opening of the Revolution (1789)**:\n+               - **Storming of the Bastille**: A symbol of royal tyranny, marking the start of the revolution.\n+               - **Declaration of the Rights of Man and of the Citizen**: A foundational document proclaiming liberty, equality, and fraternity.\n+\n+            2. **Stages of the Revolution**:\n+               - **Staffords' Reforms (1789–1791)**: Attempts to address grievances, including the abolition of feudal privileges and the introduction of the Civil Constitution of the Church.\n+               - **Reign of Terror (1793–1794)**: Led by Maximilien Robespierre, characterized by mass executions of perceived enemies of the revolution, including King Louis XVI and Queen Marie Antoinette.\n+               - **Thermidorian Reaction (1794)**: The fall of Robespierre and the end of the Reign of Terror.\n+\n+            3. **\n+        \"\"\"\n+\n         expected_texts = Expectations(\n             {\n                 (None, None): EXPECTED_TEXT_DEFAULT,\n                 (\"cuda\", 8): EXPECTED_TEXT_A10,\n+                (\"xpu\", None): EXPECTED_TEXT_XPU,\n             }\n         )\n         EXPECTED_TEXT = expected_texts.get_expectation()\n@@ -466,10 +492,9 @@ def test_falcon_h1_hard(self):\n         model_id = \"tiiuae/Falcon-H1-1.5B-Deep-Instruct\"\n         tokenizer = AutoTokenizer.from_pretrained(model_id)\n         model = FalconH1ForCausalLM.from_pretrained(model_id, dtype=torch.bfloat16, device_map=\"auto\")\n-        device = \"cuda\"\n         messages = [{\"role\": \"user\", \"content\": \"Tell me about the french revolution.\"}]\n         input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n-        inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n+        inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(torch_device)\n \n         with torch.no_grad():\n             outputs = model.generate(inputs, max_new_tokens=512, do_sample=False)"
        },
        {
            "sha": "662fc24cf4acd6051d3b2ab12f3f0d16ad08023a",
            "filename": "tests/models/helium/test_modeling_helium.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/8c291846f58fc9a4a51f50491e020eb5c27d9614/tests%2Fmodels%2Fhelium%2Ftest_modeling_helium.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8c291846f58fc9a4a51f50491e020eb5c27d9614/tests%2Fmodels%2Fhelium%2Ftest_modeling_helium.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fhelium%2Ftest_modeling_helium.py?ref=8c291846f58fc9a4a51f50491e020eb5c27d9614",
            "patch": "@@ -48,7 +48,6 @@ class HeliumModelTest(CausalLMModelTest, unittest.TestCase):\n \n \n @slow\n-# @require_torch_gpu\n class HeliumIntegrationTest(unittest.TestCase):\n     input_text = [\"Hello, today is a great day to\"]\n "
        }
    ],
    "stats": {
        "total": 37,
        "additions": 30,
        "deletions": 7
    }
}