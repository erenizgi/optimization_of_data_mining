{
    "author": "LysandreJik",
    "message": "Num parameters in model.safetensors.index.json (#38531)\n\nNum parameters in index.json",
    "sha": "afb35a10edc6e53d6c7c712808a406addf6948ba",
    "files": [
        {
            "sha": "480e6f3f3f32b10143b499c13166f7fe4b66a122",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/afb35a10edc6e53d6c7c712808a406addf6948ba/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/afb35a10edc6e53d6c7c712808a406addf6948ba/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=afb35a10edc6e53d6c7c712808a406addf6948ba",
            "patch": "@@ -3750,7 +3750,7 @@ def save_pretrained(\n         index = None\n         if state_dict_split.is_sharded:\n             index = {\n-                \"metadata\": state_dict_split.metadata,\n+                \"metadata\": {\"total_parameters\": self.num_parameters(), **state_dict_split.metadata},\n                 \"weight_map\": state_dict_split.tensor_to_filename,\n             }\n "
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}