{
    "author": "ydshieh",
    "message": "Use torch 2.7.1 on daily CI (#38620)\n\n* fix\n\n* fix\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "10627c1a0f6877ce6715b9537afe7fafb2a89edd",
    "files": [
        {
            "sha": "04c82e8776493ac708a55e1619e8041d4a725d2b",
            "filename": "docker/transformers-all-latest-gpu/Dockerfile",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10627c1a0f6877ce6715b9537afe7fafb2a89edd/docker%2Ftransformers-all-latest-gpu%2FDockerfile",
            "raw_url": "https://github.com/huggingface/transformers/raw/10627c1a0f6877ce6715b9537afe7fafb2a89edd/docker%2Ftransformers-all-latest-gpu%2FDockerfile",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docker%2Ftransformers-all-latest-gpu%2FDockerfile?ref=10627c1a0f6877ce6715b9537afe7fafb2a89edd",
            "patch": "@@ -1,4 +1,4 @@\n-FROM nvidia/cuda:12.1.0-cudnn8-devel-ubuntu22.04\n+FROM nvidia/cuda:12.6.0-cudnn-devel-ubuntu22.04\n LABEL maintainer=\"Hugging Face\"\n \n ARG DEBIAN_FRONTEND=noninteractive\n@@ -9,9 +9,9 @@ SHELL [\"sh\", \"-lc\"]\n # The following `ARG` are mainly used to specify the versions explicitly & directly in this docker file, and not meant\n # to be used as arguments for docker build (so far).\n \n-ARG PYTORCH='2.6.0'\n+ARG PYTORCH='2.7.1'\n # Example: `cu102`, `cu113`, etc.\n-ARG CUDA='cu121'\n+ARG CUDA='cu126'\n # Disable kernel mapping for now until all tests pass\n ENV DISABLE_KERNEL_MAPPING=1\n "
        },
        {
            "sha": "46137062842a32035c26220a0daa7e7d26c6e4f8",
            "filename": "docker/transformers-pytorch-deepspeed-latest-gpu/Dockerfile",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/10627c1a0f6877ce6715b9537afe7fafb2a89edd/docker%2Ftransformers-pytorch-deepspeed-latest-gpu%2FDockerfile",
            "raw_url": "https://github.com/huggingface/transformers/raw/10627c1a0f6877ce6715b9537afe7fafb2a89edd/docker%2Ftransformers-pytorch-deepspeed-latest-gpu%2FDockerfile",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docker%2Ftransformers-pytorch-deepspeed-latest-gpu%2FDockerfile?ref=10627c1a0f6877ce6715b9537afe7fafb2a89edd",
            "patch": "@@ -4,7 +4,7 @@ LABEL maintainer=\"Hugging Face\"\n \n ARG DEBIAN_FRONTEND=noninteractive\n \n-ARG PYTORCH='2.6.0'\n+ARG PYTORCH='2.7.1'\n # Example: `cu102`, `cu113`, etc.\n ARG CUDA='cu126'\n "
        },
        {
            "sha": "9891759a1fb60c04f624879be979754ccdf8bd97",
            "filename": "docker/transformers-pytorch-gpu/Dockerfile",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/10627c1a0f6877ce6715b9537afe7fafb2a89edd/docker%2Ftransformers-pytorch-gpu%2FDockerfile",
            "raw_url": "https://github.com/huggingface/transformers/raw/10627c1a0f6877ce6715b9537afe7fafb2a89edd/docker%2Ftransformers-pytorch-gpu%2FDockerfile",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docker%2Ftransformers-pytorch-gpu%2FDockerfile?ref=10627c1a0f6877ce6715b9537afe7fafb2a89edd",
            "patch": "@@ -1,4 +1,4 @@\n-FROM nvidia/cuda:12.1.0-cudnn8-devel-ubuntu22.04\n+FROM nvidia/cuda:12.6.0-cudnn-devel-ubuntu22.04\n LABEL maintainer=\"Hugging Face\"\n \n ARG DEBIAN_FRONTEND=noninteractive\n@@ -11,18 +11,20 @@ ARG REF=main\n RUN git clone https://github.com/huggingface/transformers && cd transformers && git checkout $REF\n \n # If set to nothing, will install the latest version\n-ARG PYTORCH='2.6.0'\n+ARG PYTORCH='2.7.1'\n ARG TORCH_VISION=''\n ARG TORCH_AUDIO=''\n # Example: `cu102`, `cu113`, etc.\n-ARG CUDA='cu121'\n+ARG CUDA='cu126'\n \n+RUN python3 -m pip install --no-cache-dir -e ./transformers[dev-torch,testing,video]\n+\n+# Install torch stuff after ./transformers[dev-torch,testing,video], otherwise torch may be resolved to a previous\n+# version.\n RUN [ ${#PYTORCH} -gt 0 ] && VERSION='torch=='$PYTORCH'.*' ||  VERSION='torch'; python3 -m pip install --no-cache-dir -U $VERSION --extra-index-url https://download.pytorch.org/whl/$CUDA\n RUN [ ${#TORCH_VISION} -gt 0 ] && VERSION='torchvision=='TORCH_VISION'.*' ||  VERSION='torchvision'; python3 -m pip install --no-cache-dir -U $VERSION --extra-index-url https://download.pytorch.org/whl/$CUDA\n RUN [ ${#TORCH_AUDIO} -gt 0 ] && VERSION='torchaudio=='TORCH_AUDIO'.*' ||  VERSION='torchaudio'; python3 -m pip install --no-cache-dir -U $VERSION --extra-index-url https://download.pytorch.org/whl/$CUDA\n \n-RUN python3 -m pip install --no-cache-dir -e ./transformers[dev-torch,testing,video]\n-\n RUN python3 -m pip uninstall -y tensorflow flax\n \n RUN python3 -m pip install --no-cache-dir git+https://github.com/facebookresearch/detectron2.git pytesseract"
        }
    ],
    "stats": {
        "total": 20,
        "additions": 11,
        "deletions": 9
    }
}