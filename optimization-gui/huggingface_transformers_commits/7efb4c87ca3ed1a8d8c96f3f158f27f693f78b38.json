{
    "author": "zucchini-nlp",
    "message": "Flaky CI is annoying (#40543)\n\n* mark flaky\n\n* and the non batch one",
    "sha": "7efb4c87ca3ed1a8d8c96f3f158f27f693f78b38",
    "files": [
        {
            "sha": "0b5d4e3bcb99b6ed7a86ab2cfb8cc3ff1eb15b12",
            "filename": "tests/models/tvp/test_image_processing_tvp.py",
            "status": "modified",
            "additions": 12,
            "deletions": 1,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/7efb4c87ca3ed1a8d8c96f3f158f27f693f78b38/tests%2Fmodels%2Ftvp%2Ftest_image_processing_tvp.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7efb4c87ca3ed1a8d8c96f3f158f27f693f78b38/tests%2Fmodels%2Ftvp%2Ftest_image_processing_tvp.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ftvp%2Ftest_image_processing_tvp.py?ref=7efb4c87ca3ed1a8d8c96f3f158f27f693f78b38",
            "patch": "@@ -19,7 +19,7 @@\n import numpy as np\n \n from transformers.image_transforms import PaddingMode\n-from transformers.testing_utils import require_torch, require_vision\n+from transformers.testing_utils import is_flaky, require_torch, require_vision\n from transformers.utils import is_torch_available, is_torchvision_available, is_vision_available\n \n from ...test_image_processing_common import ImageProcessingTestMixin, prepare_video_inputs\n@@ -349,6 +349,17 @@ def test_call_pytorch(self):\n \n     @require_vision\n     @require_torch\n+    @is_flaky(\n+        description=\"FIXME: @yoni probably because of an extra 'time' dimension and since image processors don't handle it well?\"\n+    )\n+    def test_slow_fast_equivalence(self):\n+        super().test_slow_fast_equivalence()\n+\n+    @require_vision\n+    @require_torch\n+    @is_flaky(\n+        description=\"FIXME: @yoni probably because of an extra 'time' dimension and since image processors don't handle it well?\"\n+    )\n     def test_slow_fast_equivalence_batched(self):\n         if not self.test_slow_image_processor or not self.test_fast_image_processor:\n             self.skipTest(reason=\"Skipping slow/fast equivalence test\")"
        }
    ],
    "stats": {
        "total": 13,
        "additions": 12,
        "deletions": 1
    }
}