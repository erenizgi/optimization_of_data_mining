{
    "author": "akintunero",
    "message": "Fix typo and improve GPU kernel check error message in MXFP4 quantization (#40349) (#40408)\n\nCo-authored-by: Mohamed Mekkouri <93391238+MekkCyber@users.noreply.github.com>\nCo-authored-by: Joao Gante <joaofranciscocardosogante@gmail.com>",
    "sha": "eac4f00bdfb9beb8922af78339a70e167777ad18",
    "files": [
        {
            "sha": "4ef52760fba06514a22aa5fafc1604a421f76ae0",
            "filename": "src/transformers/quantizers/quantizer_mxfp4.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/eac4f00bdfb9beb8922af78339a70e167777ad18/src%2Ftransformers%2Fquantizers%2Fquantizer_mxfp4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/eac4f00bdfb9beb8922af78339a70e167777ad18/src%2Ftransformers%2Fquantizers%2Fquantizer_mxfp4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizer_mxfp4.py?ref=eac4f00bdfb9beb8922af78339a70e167777ad18",
            "patch": "@@ -112,7 +112,7 @@ def validate_environment(self, *args, **kwargs):\n             )\n         elif not kernels_available:\n             # we can't quantize the model in this case so we raise an error\n-            raise ValueError(\"MXFP4 quantization requires triton >= 3.4.0 and triton_kernels installed\")\n+            raise ValueError(\"MXFP4 quantization requires triton >= 3.4.0 and kernels installed\")\n \n         if not self.pre_quantized:\n             self._lazy_import_kernels()"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}