{
    "author": "yonigozlan",
    "message": "Reduce add_dates verbosity (#43184)\n\n* reduce add_dates verbosity\n\n* add file exists check",
    "sha": "83782890ab31e4f1c2d1d289a11b3cfb6eec2a5e",
    "files": [
        {
            "sha": "c9e67027406379e1387c0db6b04cf2ba20875e4d",
            "filename": "docs/source/en/model_doc/audioflamingo3.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/83782890ab31e4f1c2d1d289a11b3cfb6eec2a5e/docs%2Fsource%2Fen%2Fmodel_doc%2Faudioflamingo3.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/83782890ab31e4f1c2d1d289a11b3cfb6eec2a5e/docs%2Fsource%2Fen%2Fmodel_doc%2Faudioflamingo3.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Faudioflamingo3.md?ref=83782890ab31e4f1c2d1d289a11b3cfb6eec2a5e",
            "patch": "@@ -14,7 +14,7 @@ rendered properly in your Markdown viewer.\n \n -->\n \n-*This model was released on 2025-07-10 and added to Hugging Face Transformers on 2025-11-17.*\n+*This model was released on 2025-07-10 and added to Hugging Face Transformers on 2025-11-12.*\n \n # Audio Flamingo 3\n "
        },
        {
            "sha": "6c4d0e3fd84b11f42fd5b164dccdd020bf1b74ee",
            "filename": "utils/add_dates.py",
            "status": "modified",
            "additions": 13,
            "deletions": 46,
            "changes": 59,
            "blob_url": "https://github.com/huggingface/transformers/blob/83782890ab31e4f1c2d1d289a11b3cfb6eec2a5e/utils%2Fadd_dates.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/83782890ab31e4f1c2d1d289a11b3cfb6eec2a5e/utils%2Fadd_dates.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fadd_dates.py?ref=83782890ab31e4f1c2d1d289a11b3cfb6eec2a5e",
            "patch": "@@ -68,19 +68,10 @@ def check_file_exists_on_github(file_path: str) -> bool:\n         if e.code == 404:\n             # File doesn't exist on GitHub\n             return False\n-        # Fall through to generic exception handler for other HTTP errors\n-        print(\n-            f\"Warning: Could not verify file existence on GitHub (HTTP {e.code}): {url}\\n\"\n-            f\"Assuming file exists and continuing with local git history.\"\n-        )\n+        # HTTP error (non-404): assume file exists and continue with local git history\n         return True\n-    except Exception as e:\n-        # Handle all other errors (network issues, timeouts, etc.)\n-        print(\n-            f\"Warning: Could not verify file existence on GitHub: {url}\\n\"\n-            f\"Error: {e}\\n\"\n-            f\"Assuming file exists and continuing with local git history.\"\n-        )\n+    except Exception:\n+        # Network/timeout error: assume file exists and continue with local git history\n         return True\n \n \n@@ -94,9 +85,11 @@ def get_modified_cards() -> list[str]:\n         if line:\n             # Check if the file is in the model_doc directory\n             if line.startswith(\"docs/source/en/model_doc/\") and line.endswith(\".md\"):\n-                model_name = os.path.splitext(os.path.basename(line))[0]\n-                if model_name not in [\"auto\", \"timm_wrapper\"]:\n-                    model_names.append(model_name)\n+                file_path = os.path.join(ROOT, line)\n+                if os.path.exists(file_path):\n+                    model_name = os.path.splitext(os.path.basename(line))[0]\n+                    if model_name not in [\"auto\", \"timm_wrapper\"]:\n+                        model_names.append(model_name)\n \n     return model_names\n \n@@ -116,26 +109,7 @@ def get_paper_link(model_card: str | None, path: str | None) -> str:\n     paper_ids += re.findall(r\"https://arxiv\\.org/abs/\\d+\\.\\d+\", content)\n     paper_ids += re.findall(r\"https://arxiv\\.org/pdf/\\d+\\.\\d+\", content)\n \n-    # If no known paper links are found, look for other potential paper links\n     if len(paper_ids) == 0:\n-        # Find all https links\n-        all_https_links = re.findall(r\"https://[^\\s\\)]+\", content)\n-\n-        # Filter out huggingface.co and github links\n-        other_paper_links = []\n-        for link in all_https_links:\n-            link = link.rstrip(\".,;!?)\")\n-            if \"huggingface.co\" not in link and \"github.com\" not in link:\n-                other_paper_links.append(link)\n-\n-        # Remove duplicates while preserving order\n-        other_paper_links = list(dict.fromkeys(other_paper_links))\n-\n-        if other_paper_links:\n-            print(f\"No Hugging Face or Arxiv papers found. The possible paper links found in {model_card}:\")\n-            for link in other_paper_links:\n-                print(f\"  - {link}\")\n-\n         return \"No_paper\"\n \n     return paper_ids[0]\n@@ -161,7 +135,6 @@ def get_first_commit_date(model_name: str | None) -> str:\n \n     if not file_exists_on_github:\n         # File does not exist on GitHub main branch (new model), use today's date\n-        print(f\"Model {model_name} not found on GitHub main branch, using today's date\")\n         final_date = date.today().isoformat()\n     else:\n         # File exists on GitHub main branch, get the first commit date from local git history\n@@ -178,11 +151,11 @@ def get_release_date(link: str) -> str:\n         try:\n             info = paper_info(link)\n             return info.published_at.date().isoformat()\n-        except Exception as e:\n-            print(f\"Error fetching release date for the paper https://huggingface.co/papers/{link}: {e}\")\n+        except Exception:\n+            # Error fetching release date, function returns None (will use placeholder)\n+            pass\n \n     elif link.startswith(\"https://arxiv.org/abs/\") or link.startswith(\"https://arxiv.org/pdf/\"):\n-        print(f\"This paper {link} is not yet available in Hugging Face papers, skipping the release date attachment.\")\n         return r\"{release_date}\"\n \n \n@@ -192,7 +165,6 @@ def replace_paper_links(file_path: str) -> bool:\n     with open(file_path, \"r\", encoding=\"utf-8\") as f:\n         content = f.read()\n \n-    model_card = os.path.basename(file_path)\n     original_content = content\n \n     # Replace hf.co with huggingface.co\n@@ -212,11 +184,9 @@ def replace_paper_links(file_path: str) -> bool:\n                 old_link = f\"https://arxiv.org/pdf/{paper_id}\"\n             new_link = f\"https://huggingface.co/papers/{paper_id}\"\n             content = content.replace(old_link, new_link)\n-            print(f\"Replaced {old_link} with {new_link}\")\n \n         except Exception:\n             # Paper not available on huggingface, keep arxiv link\n-            print(f\"Paper {paper_id} for {model_card} is not available on huggingface, keeping the arxiv link\")\n             continue\n \n     # Write back only if content changed\n@@ -308,16 +278,14 @@ def insert_dates(model_card_list: list[str]):\n         file_path = os.path.join(DOCS_PATH, model_card)\n \n         # First replace arxiv paper links with hf paper link if possible\n-        links_replaced = replace_paper_links(file_path)\n-        if links_replaced:\n-            print(f\"Updated paper links in {model_card}\")\n+        replace_paper_links(file_path)\n \n         # Read content and ensure copyright disclaimer exists\n         content = _read_model_card_content(model_card)\n         markers = list(re.finditer(r\"-->\", content))\n \n         if len(markers) == 0:\n-            print(f\"No marker found in {model_card}. Adding copyright disclaimer to the top.\")\n+            # No copyright marker found, adding disclaimer to the top\n             content = COPYRIGHT_DISCLAIMER + \"\\n\\n\" + content\n             with open(file_path, \"w\", encoding=\"utf-8\") as f:\n                 f.write(content)\n@@ -356,7 +324,6 @@ def insert_dates(model_card_list: list[str]):\n             content = content[:insert_index] + date_info + content[insert_index:]\n             with open(file_path, \"w\", encoding=\"utf-8\") as f:\n                 f.write(content)\n-            print(f\"Added {model_card} release and commit dates.\")\n \n \n def get_all_model_cards():"
        }
    ],
    "stats": {
        "total": 61,
        "additions": 14,
        "deletions": 47
    }
}