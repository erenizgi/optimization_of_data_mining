{
    "author": "phos-phophy",
    "message": "Pass state dict (#35234)\n\n* Pass state_dict argument to get_peft_model_state_dict\n\n* Style fix\n\n* Change arguments order",
    "sha": "63380b77d46575957d126624db1ac956a4167b9b",
    "files": [
        {
            "sha": "6aa3b137b1914254c1b9ac49d5a8b413e29acb0b",
            "filename": "src/transformers/integrations/peft.py",
            "status": "modified",
            "additions": 6,
            "deletions": 2,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/63380b77d46575957d126624db1ac956a4167b9b/src%2Ftransformers%2Fintegrations%2Fpeft.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/63380b77d46575957d126624db1ac956a4167b9b/src%2Ftransformers%2Fintegrations%2Fpeft.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Fpeft.py?ref=63380b77d46575957d126624db1ac956a4167b9b",
            "patch": "@@ -446,7 +446,7 @@ def active_adapter(self) -> str:\n \n         return self.active_adapters()[0]\n \n-    def get_adapter_state_dict(self, adapter_name: Optional[str] = None) -> dict:\n+    def get_adapter_state_dict(self, adapter_name: Optional[str] = None, state_dict: Optional[dict] = None) -> dict:\n         \"\"\"\n         If you are not familiar with adapters and PEFT methods, we invite you to read more about them on the PEFT\n         official documentation: https://huggingface.co/docs/peft\n@@ -457,6 +457,10 @@ def get_adapter_state_dict(self, adapter_name: Optional[str] = None) -> dict:\n         Args:\n             adapter_name (`str`, *optional*):\n                 The name of the adapter to get the state dict from. If no name is passed, the active adapter is used.\n+            state_dict (nested dictionary of `torch.Tensor`, *optional*)\n+                The state dictionary of the model. Will default to `self.state_dict()`, but can be used if special\n+                precautions need to be taken when recovering the state dictionary of a model (like when using model\n+                parallelism).\n         \"\"\"\n         check_peft_version(min_version=MIN_PEFT_VERSION)\n \n@@ -468,7 +472,7 @@ def get_adapter_state_dict(self, adapter_name: Optional[str] = None) -> dict:\n         if adapter_name is None:\n             adapter_name = self.active_adapters()[0]\n \n-        adapter_state_dict = get_peft_model_state_dict(self, adapter_name=adapter_name)\n+        adapter_state_dict = get_peft_model_state_dict(self, state_dict=state_dict, adapter_name=adapter_name)\n         return adapter_state_dict\n \n     def _dispatch_accelerate_model("
        },
        {
            "sha": "120af2b842dbb742167a5aff0cf4ee3ffd1c33da",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/63380b77d46575957d126624db1ac956a4167b9b/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/63380b77d46575957d126624db1ac956a4167b9b/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=63380b77d46575957d126624db1ac956a4167b9b",
            "patch": "@@ -3359,7 +3359,7 @@ def save_pretrained(\n                 logger.info(\n                     \"Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\"\n                 )\n-                state_dict = model_to_save.get_adapter_state_dict()\n+                state_dict = model_to_save.get_adapter_state_dict(state_dict=state_dict)\n \n                 if save_peft_format:\n                     logger.info("
        }
    ],
    "stats": {
        "total": 10,
        "additions": 7,
        "deletions": 3
    }
}