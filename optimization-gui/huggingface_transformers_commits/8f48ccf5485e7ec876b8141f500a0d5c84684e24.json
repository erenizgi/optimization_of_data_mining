{
    "author": "MekkCyber",
    "message": "Fix : Add PEFT from source to CI docker (#34969)\n\n* Docker fix peft\r\n\r\n* Test new docker\r\n\r\n* uncomment",
    "sha": "8f48ccf5485e7ec876b8141f500a0d5c84684e24",
    "files": [
        {
            "sha": "a8f131164eb4aef396feb7ef008330ac22d58a93",
            "filename": "docker/transformers-quantization-latest-gpu/Dockerfile",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/8f48ccf5485e7ec876b8141f500a0d5c84684e24/docker%2Ftransformers-quantization-latest-gpu%2FDockerfile",
            "raw_url": "https://github.com/huggingface/transformers/raw/8f48ccf5485e7ec876b8141f500a0d5c84684e24/docker%2Ftransformers-quantization-latest-gpu%2FDockerfile",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docker%2Ftransformers-quantization-latest-gpu%2FDockerfile?ref=8f48ccf5485e7ec876b8141f500a0d5c84684e24",
            "patch": "@@ -42,6 +42,9 @@ RUN python3 -m pip install --no-cache-dir auto-gptq --extra-index-url https://hu\n # Add optimum for gptq quantization testing\n RUN python3 -m pip install --no-cache-dir git+https://github.com/huggingface/optimum@main#egg=optimum\n \n+# Add PEFT\n+RUN python3 -m pip install --no-cache-dir git+https://github.com/huggingface/peft@main#egg=peft\n+\n # Add aqlm for quantization testing\n RUN python3 -m pip install --no-cache-dir aqlm[gpu]==1.0.2\n "
        }
    ],
    "stats": {
        "total": 3,
        "additions": 3,
        "deletions": 0
    }
}