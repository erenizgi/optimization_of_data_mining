{
    "author": "SunMarc",
    "message": "Log the correct learning rate (#36973)\n\n* fix learning rate log\n\n* fix lr log\n\n* add lr",
    "sha": "79d6f9fd7006bd6a7860f63f43f0e6e89a0412a4",
    "files": [
        {
            "sha": "189f09d3de23b1ec0623f387ff1bd6b4de92d2c6",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 22,
            "deletions": 4,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/79d6f9fd7006bd6a7860f63f43f0e6e89a0412a4/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/79d6f9fd7006bd6a7860f63f43f0e6e89a0412a4/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=79d6f9fd7006bd6a7860f63f43f0e6e89a0412a4",
            "patch": "@@ -2460,6 +2460,7 @@ def _inner_training_loop(\n         self._globalstep_last_logged = self.state.global_step\n         model.zero_grad()\n         grad_norm: Optional[float] = None\n+        learning_rate = None\n         self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\n \n         if args.eval_on_start:\n@@ -2608,6 +2609,9 @@ def _inner_training_loop(\n \n                         self.control = self.callback_handler.on_optimizer_step(args, self.state, self.control)\n \n+                        # get leaning rate before update\n+                        learning_rate = self._get_learning_rate()\n+\n                         if not self.accelerator.optimizer_step_was_skipped:\n                             # Delay optimizer scheduling until metrics are generated\n                             if not isinstance(self.lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n@@ -2618,7 +2622,14 @@ def _inner_training_loop(\n                         self.state.epoch = epoch + (step + 1 + steps_skipped) / steps_in_epoch\n                         self.control = self.callback_handler.on_step_end(args, self.state, self.control)\n                         self._maybe_log_save_evaluate(\n-                            tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time\n+                            tr_loss,\n+                            grad_norm,\n+                            model,\n+                            trial,\n+                            epoch,\n+                            ignore_keys_for_eval,\n+                            start_time,\n+                            learning_rate=learning_rate,\n                         )\n                     else:\n                         self.control = self.callback_handler.on_substep_end(args, self.state, self.control)\n@@ -2644,7 +2655,9 @@ def _inner_training_loop(\n                 self.control.should_training_stop = True\n \n             self.control = self.callback_handler.on_epoch_end(args, self.state, self.control)\n-            self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\n+            self._maybe_log_save_evaluate(\n+                tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate=learning_rate\n+            )\n \n             if DebugOption.TPU_METRICS_DEBUG in self.args.debug:\n                 if is_torch_xla_available():\n@@ -3064,7 +3077,9 @@ def _evaluate(self, trial, ignore_keys_for_eval, skip_scheduler=False):\n                 ) from exc\n         return metrics\n \n-    def _maybe_log_save_evaluate(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time):\n+    def _maybe_log_save_evaluate(\n+        self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate=None\n+    ):\n         if self.control.should_log and self.state.global_step > self._globalstep_last_logged:\n             if is_torch_xla_available():\n                 xm.mark_step()\n@@ -3080,7 +3095,10 @@ def _maybe_log_save_evaluate(self, tr_loss, grad_norm, model, trial, epoch, igno\n             logs[\"loss\"] = round(tr_loss_scalar / (self.state.global_step - self._globalstep_last_logged), 4)\n             if grad_norm is not None:\n                 logs[\"grad_norm\"] = grad_norm.detach().item() if isinstance(grad_norm, torch.Tensor) else grad_norm\n-            logs[\"learning_rate\"] = self._get_learning_rate()\n+            if learning_rate is not None:\n+                logs[\"learning_rate\"] = learning_rate\n+            else:\n+                logs[\"learning_rate\"] = self._get_learning_rate()\n \n             self._total_loss_scalar += tr_loss_scalar\n             self._globalstep_last_logged = self.state.global_step"
        }
    ],
    "stats": {
        "total": 26,
        "additions": 22,
        "deletions": 4
    }
}