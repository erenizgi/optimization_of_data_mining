{
    "author": "andimarafioti",
    "message": "[run_slow] idefics2 (#32840)",
    "sha": "18199b34e58d06a760929fceef340581152cf55f",
    "files": [
        {
            "sha": "8d48acb9500d2f9a5952c98efb486464cade9e33",
            "filename": "tests/models/idefics2/test_modeling_idefics2.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/18199b34e58d06a760929fceef340581152cf55f/tests%2Fmodels%2Fidefics2%2Ftest_modeling_idefics2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/18199b34e58d06a760929fceef340581152cf55f/tests%2Fmodels%2Fidefics2%2Ftest_modeling_idefics2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fidefics2%2Ftest_modeling_idefics2.py?ref=18199b34e58d06a760929fceef340581152cf55f",
            "patch": "@@ -34,6 +34,7 @@\n     require_flash_attn,\n     require_torch,\n     require_torch_gpu,\n+    require_torch_multi_gpu,\n     slow,\n     torch_device,\n )\n@@ -498,7 +499,7 @@ def tearDown(self):\n         torch.cuda.empty_cache()\n \n     @slow\n-    @unittest.skip(\"Test hits OOM on CI - https://github.com/huggingface/transformers/issues/32288\")\n+    @require_torch_multi_gpu\n     def test_integration_test(self):\n         model = Idefics2ForConditionalGeneration.from_pretrained(\n             \"HuggingFaceM4/idefics2-8b-base\","
        }
    ],
    "stats": {
        "total": 3,
        "additions": 2,
        "deletions": 1
    }
}