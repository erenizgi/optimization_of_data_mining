{
    "author": "yonigozlan",
    "message": "Add compile test for fast image processor (#35184)\n\n* add compile test for fast image processor\r\n\r\n* override pixtral test",
    "sha": "93aafdc620d39b9ec714ffecf015a085ea221282",
    "files": [
        {
            "sha": "5fa23923fe747319b93cbfa3c3eac062afb9eb1b",
            "filename": "src/transformers/models/pixtral/image_processing_pixtral_fast.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/93aafdc620d39b9ec714ffecf015a085ea221282/src%2Ftransformers%2Fmodels%2Fpixtral%2Fimage_processing_pixtral_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93aafdc620d39b9ec714ffecf015a085ea221282/src%2Ftransformers%2Fmodels%2Fpixtral%2Fimage_processing_pixtral_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpixtral%2Fimage_processing_pixtral_fast.py?ref=93aafdc620d39b9ec714ffecf015a085ea221282",
            "patch": "@@ -346,4 +346,7 @@ def preprocess(\n             batch_images.append(images)\n             batch_image_sizes.append(image_sizes)\n \n-        return BatchMixFeature(data={\"pixel_values\": batch_images, \"image_sizes\": batch_image_sizes}, tensor_type=None)\n+        return BatchMixFeature(\n+            data={\"pixel_values\": batch_images, \"image_sizes\": batch_image_sizes},\n+            tensor_type=None,\n+        )"
        },
        {
            "sha": "1377b676917f47ceccf1367c8ccb0cde589c4fb9",
            "filename": "tests/models/pixtral/test_image_processing_pixtral.py",
            "status": "modified",
            "additions": 31,
            "deletions": 2,
            "changes": 33,
            "blob_url": "https://github.com/huggingface/transformers/blob/93aafdc620d39b9ec714ffecf015a085ea221282/tests%2Fmodels%2Fpixtral%2Ftest_image_processing_pixtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93aafdc620d39b9ec714ffecf015a085ea221282/tests%2Fmodels%2Fpixtral%2Ftest_image_processing_pixtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpixtral%2Ftest_image_processing_pixtral.py?ref=93aafdc620d39b9ec714ffecf015a085ea221282",
            "patch": "@@ -19,8 +19,15 @@\n \n import numpy as np\n import requests\n-\n-from transformers.testing_utils import require_torch, require_vision\n+from packaging import version\n+\n+from transformers.testing_utils import (\n+    require_torch,\n+    require_torch_gpu,\n+    require_vision,\n+    slow,\n+    torch_device,\n+)\n from transformers.utils import is_torch_available, is_torchvision_available, is_vision_available\n \n from ...test_image_processing_common import ImageProcessingTestMixin, prepare_image_inputs\n@@ -157,6 +164,9 @@ def test_image_processor_properties(self):\n             self.assertTrue(hasattr(image_processing, \"image_std\"))\n             self.assertTrue(hasattr(image_processing, \"do_convert_rgb\"))\n \n+    # The following tests are overriden as PixtralImageProcessor can return images of different sizes\n+    # and thus doesn't support returning batched tensors\n+\n     def test_call_pil(self):\n         for image_processing_class in self.image_processor_list:\n             # Initialize image_processing\n@@ -273,6 +283,25 @@ def test_slow_fast_equivalence(self):\n \n         self.assertTrue(torch.allclose(encoding_slow.pixel_values[0][0], encoding_fast.pixel_values[0][0], atol=1e-2))\n \n+    @slow\n+    @require_torch_gpu\n+    @require_vision\n+    def test_can_compile_fast_image_processor(self):\n+        if self.fast_image_processing_class is None:\n+            self.skipTest(\"Skipping compilation test as fast image processor is not defined\")\n+        if version.parse(torch.__version__) < version.parse(\"2.3\"):\n+            self.skipTest(reason=\"This test requires torch >= 2.3 to run.\")\n+\n+        torch.compiler.reset()\n+        input_image = torch.randint(0, 255, (3, 224, 224), dtype=torch.uint8)\n+        image_processor = self.fast_image_processing_class(**self.image_processor_dict)\n+        output_eager = image_processor(input_image, device=torch_device, return_tensors=\"pt\")\n+\n+        image_processor = torch.compile(image_processor, mode=\"reduce-overhead\")\n+        output_compiled = image_processor(input_image, device=torch_device, return_tensors=\"pt\")\n+\n+        self.assertTrue(torch.allclose(output_eager.pixel_values[0][0], output_compiled.pixel_values[0][0], atol=1e-4))\n+\n     @unittest.skip(reason=\"PixtralImageProcessor doesn't treat 4 channel PIL and numpy consistently yet\")  # FIXME Amy\n     def test_call_numpy_4_channels(self):\n         pass"
        },
        {
            "sha": "1cb92174df1d8a0628cf55c584305bd3c5412437",
            "filename": "tests/test_image_processing_common.py",
            "status": "modified",
            "additions": 28,
            "deletions": 1,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/93aafdc620d39b9ec714ffecf015a085ea221282/tests%2Ftest_image_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93aafdc620d39b9ec714ffecf015a085ea221282/tests%2Ftest_image_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_image_processing_common.py?ref=93aafdc620d39b9ec714ffecf015a085ea221282",
            "patch": "@@ -23,10 +23,18 @@\n \n import numpy as np\n import requests\n+from packaging import version\n \n from transformers import AutoImageProcessor, BatchFeature\n from transformers.image_utils import AnnotationFormat, AnnotionFormat\n-from transformers.testing_utils import check_json_file_has_correct_format, require_torch, require_vision\n+from transformers.testing_utils import (\n+    check_json_file_has_correct_format,\n+    require_torch,\n+    require_torch_gpu,\n+    require_vision,\n+    slow,\n+    torch_device,\n+)\n from transformers.utils import is_torch_available, is_vision_available\n \n \n@@ -463,6 +471,25 @@ def test_image_processor_preprocess_arguments(self):\n         if not is_tested:\n             self.skipTest(reason=\"No validation found for `preprocess` method\")\n \n+    @slow\n+    @require_torch_gpu\n+    @require_vision\n+    def test_can_compile_fast_image_processor(self):\n+        if self.fast_image_processing_class is None:\n+            self.skipTest(\"Skipping compilation test as fast image processor is not defined\")\n+        if version.parse(torch.__version__) < version.parse(\"2.3\"):\n+            self.skipTest(reason=\"This test requires torch >= 2.3 to run.\")\n+\n+        torch.compiler.reset()\n+        input_image = torch.randint(0, 255, (3, 224, 224), dtype=torch.uint8)\n+        image_processor = self.fast_image_processing_class(**self.image_processor_dict)\n+        output_eager = image_processor(input_image, device=torch_device, return_tensors=\"pt\")\n+\n+        image_processor = torch.compile(image_processor, mode=\"reduce-overhead\")\n+        output_compiled = image_processor(input_image, device=torch_device, return_tensors=\"pt\")\n+\n+        self.assertTrue(torch.allclose(output_eager.pixel_values, output_compiled.pixel_values, atol=1e-4))\n+\n \n class AnnotationFormatTestMixin:\n     # this mixin adds a test to assert that usages of the"
        }
    ],
    "stats": {
        "total": 67,
        "additions": 63,
        "deletions": 4
    }
}