{
    "author": "ydshieh",
    "message": "byebye CircleCI TF jobs (#36998)\n\n* byebye tf jobs\n\n* byebye tf jobs\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "181d45306945be3463ef691765b7184c88f7e433",
    "files": [
        {
            "sha": "b2b42784e482e821e6041a55595620ce41053c2a",
            "filename": ".circleci/create_circleci_config.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/181d45306945be3463ef691765b7184c88f7e433/.circleci%2Fcreate_circleci_config.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/181d45306945be3463ef691765b7184c88f7e433/.circleci%2Fcreate_circleci_config.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.circleci%2Fcreate_circleci_config.py?ref=181d45306945be3463ef691765b7184c88f7e433",
            "patch": "@@ -357,9 +357,9 @@ def job_name(self):\n     pytest_num_workers=1,\n )\n \n-REGULAR_TESTS = [torch_job, tf_job, flax_job, hub_job, onnx_job, tokenization_job, processor_job, generate_job, non_model_job] # fmt: skip\n-EXAMPLES_TESTS = [examples_torch_job, examples_tensorflow_job]\n-PIPELINE_TESTS = [pipelines_torch_job, pipelines_tf_job]\n+REGULAR_TESTS = [torch_job, flax_job, hub_job, onnx_job, tokenization_job, processor_job, generate_job, non_model_job] # fmt: skip\n+EXAMPLES_TESTS = [examples_torch_job]\n+PIPELINE_TESTS = [pipelines_torch_job]\n REPO_UTIL_TESTS = [repo_utils_job]\n DOC_TESTS = [doc_test_job]\n ALL_TESTS = REGULAR_TESTS + EXAMPLES_TESTS + PIPELINE_TESTS + REPO_UTIL_TESTS + DOC_TESTS + [custom_tokenizers_job] + [exotic_models_job]  # fmt: skip"
        },
        {
            "sha": "c4b528eb89907df461e820a50841a6f0cf4153ad",
            "filename": "utils/tests_fetcher.py",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/181d45306945be3463ef691765b7184c88f7e433/utils%2Ftests_fetcher.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/181d45306945be3463ef691765b7184c88f7e433/utils%2Ftests_fetcher.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Ftests_fetcher.py?ref=181d45306945be3463ef691765b7184c88f7e433",
            "patch": "@@ -1154,17 +1154,14 @@ def parse_commit_message(commit_message: str) -> Dict[str, bool]:\n \n \n JOB_TO_TEST_FILE = {\n-    \"tests_tf\": r\"tests/models/.*/test_modeling_tf_.*\",\n     \"tests_torch\": r\"tests/models/.*/test_modeling_(?!(?:flax_|tf_)).*\",\n     \"tests_generate\": r\"tests/models/.*/test_modeling_(?!(?:flax_|tf_)).*\",\n     \"tests_tokenization\": r\"tests/models/.*/test_tokenization.*\",\n     \"tests_processors\": r\"tests/models/.*/test_(?!(?:modeling_|tokenization_)).*\",  # takes feature extractors, image processors, processors\n     \"examples_torch\": r\"examples/pytorch/.*test_.*\",\n-    \"examples_tensorflow\": r\"examples/tensorflow/.*test_.*\",\n     \"tests_exotic_models\": r\"tests/models/.*(?=layoutlmv|nat|deta|udop|nougat).*\",\n     \"tests_custom_tokenizers\": r\"tests/models/.*/test_tokenization_(?=bert_japanese|openai|clip).*\",\n     # \"repo_utils\": r\"tests/[^models].*test.*\", TODO later on we might want to do\n-    \"pipelines_tf\": r\"tests/models/.*/test_modeling_tf_.*\",\n     \"pipelines_torch\": r\"tests/models/.*/test_modeling_(?!(?:flax_|tf_)).*\",\n     \"tests_hub\": r\"tests/.*\",\n     \"tests_onnx\": r\"tests/models/.*/test_modeling_(?:tf_|(?!flax)).*\","
        }
    ],
    "stats": {
        "total": 9,
        "additions": 3,
        "deletions": 6
    }
}