{
    "author": "yao-matrix",
    "message": "fix some ut failures on XPU w/ torch 2.9 (#41923)\n\n* fix 6 ut failures on XPU w/ torch 2.9\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>\n\n* fix UT failures for 4 models on XPU\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>\n\n---------\n\nSigned-off-by: Yao, Matrix <matrix.yao@intel.com>",
    "sha": "a43b36cf802f00616800e0bd4d748679236123ee",
    "files": [
        {
            "sha": "0e5ac22a08195ede31a12332be1945aa8ff18dbd",
            "filename": "tests/models/aria/test_modeling_aria.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/a43b36cf802f00616800e0bd4d748679236123ee/tests%2Fmodels%2Faria%2Ftest_modeling_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a43b36cf802f00616800e0bd4d748679236123ee/tests%2Fmodels%2Faria%2Ftest_modeling_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faria%2Ftest_modeling_aria.py?ref=a43b36cf802f00616800e0bd4d748679236123ee",
            "patch": "@@ -520,7 +520,6 @@ def test_generation_no_images(self):\n             quantization_config=BitsAndBytesConfig(load_in_4bit=True, llm_int8_skip_modules=[\"multihead_attn\"]),\n         )\n         processor = AutoProcessor.from_pretrained(model_id)\n-        assert model.device.type == \"cuda\", \"This test is only supported on CUDA\"  # TODO: remove this\n         # Prepare inputs with no images\n         inputs = processor(text=\"Hello, I am\", return_tensors=\"pt\").to(torch_device)\n "
        },
        {
            "sha": "ce1975cadd8a95a2989beffb4172e7c024efc035",
            "filename": "tests/models/aya_vision/test_modeling_aya_vision.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/a43b36cf802f00616800e0bd4d748679236123ee/tests%2Fmodels%2Faya_vision%2Ftest_modeling_aya_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a43b36cf802f00616800e0bd4d748679236123ee/tests%2Fmodels%2Faya_vision%2Ftest_modeling_aya_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faya_vision%2Ftest_modeling_aya_vision.py?ref=a43b36cf802f00616800e0bd4d748679236123ee",
            "patch": "@@ -267,7 +267,7 @@ def test_small_model_integration_forward(self):\n \n         EXPECTED_LOGITS = Expectations(\n             {\n-                (\"xpu\", 3): [0.4109, 0.1532, 0.8018, 2.1328, 0.5483],\n+                (\"xpu\", 3): [1.6699, 0.6260, 3.2266, 8.5547, 2.209],\n                 # 4-bit\n                 (\"cuda\", 7): [0.1097, 0.3481, 3.8340, 9.7969, 2.0488],\n                 (\"cuda\", 8): [1.6396, 0.6094, 3.1992, 8.5234, 2.1875],\n@@ -308,7 +308,7 @@ def test_small_model_integration_generate_text_only(self):\n \n         expected_outputs = Expectations(\n             {\n-                (\"xpu\", 3): \"Whispers on the breeze,\\nLeaves dance under moonlit skies,\\nNature's quiet song.\",\n+                (\"xpu\", 3): \"Whispers on the breeze,\\nLeaves dance under moonlit sky,\\nNature's quiet song.\",\n                 # 4-bit\n                 (\"cuda\", 7): \"Sure, here's a haiku for you:\\n\\nMorning dew sparkles,\\nPetals unfold in sunlight,\\n\",\n                 (\"cuda\", 8): \"Whispers on the breeze,\\nLeaves dance under moonlit skies,\\nNature's quiet song.\",\n@@ -474,7 +474,7 @@ def test_small_model_integration_batched_generate_multi_image(self):\n         # Batching seems to alter the output slightly, but it is also the case in the original implementation. This seems to be expected: https://github.com/huggingface/transformers/issues/23017#issuecomment-1649630232\n         expected_outputs = Expectations(\n             {\n-                (\"xpu\", 3): \"Wooden path to water,\\nMountains echo in stillness,\\nPeaceful forest lake.\",\n+                (\"xpu\", 3): \"Wooden path to water,\\nMountains echo in stillness,\\nPeaceful forest scene.\",\n                 (\"cuda\", 7): 'Wooden bridge stretches\\nMirrored lake below, mountains rise\\nPeaceful, serene',\n                 (\"cuda\", 8): 'Wooden path to water,\\nMountains echo in stillness,\\nPeaceful forest scene.',\n             }"
        },
        {
            "sha": "9f2d335e172afd2a4130be572ff039b357df63ea",
            "filename": "tests/models/gemma3/test_modeling_gemma3.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/a43b36cf802f00616800e0bd4d748679236123ee/tests%2Fmodels%2Fgemma3%2Ftest_modeling_gemma3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a43b36cf802f00616800e0bd4d748679236123ee/tests%2Fmodels%2Fgemma3%2Ftest_modeling_gemma3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgemma3%2Ftest_modeling_gemma3.py?ref=a43b36cf802f00616800e0bd4d748679236123ee",
            "patch": "@@ -499,7 +499,7 @@ def test_model_4b_bf16(self):\n \n         EXPECTED_TEXTS = Expectations(\n             {\n-                (\"xpu\", 3): ['user\\nYou are a helpful assistant.\\n\\n\\n\\n\\n\\nWhat is shown in this image?\\nmodel\\nCertainly! \\n\\nThe image shows a brown and white cow standing on a sandy beach with turquoise water in the background. It looks like a lovely,'],\n+                (\"xpu\", 3): ['user\\nYou are a helpful assistant.\\n\\n\\n\\n\\n\\nWhat is shown in this image?\\nmodel\\nCertainly! \\n\\nThe image shows a brown cow standing on a sandy beach with turquoise water and a blue sky in the background. It looks like a'],\n                 (\"cuda\", (8, 0)): ['user\\nYou are a helpful assistant.\\n\\n\\n\\n\\n\\nWhat is shown in this image?\\nmodel\\nCertainly! \\n\\nThe image shows a brown cow standing on a sandy beach with clear turquoise water and a blue sky in the background. It looks like'],\n                 (\"cuda\", (8, 6)): ['user\\nYou are a helpful assistant.\\n\\n\\n\\n\\n\\nWhat is shown in this image?\\nmodel\\nCertainly! \\n\\nThe image shows a brown cow standing on a sandy beach with clear blue water and a blue sky in the background. It looks like'],\n                 (\"rocm\", (9, 4)): ['user\\nYou are a helpful assistant.\\n\\n\\n\\n\\n\\nWhat is shown in this image?\\nmodel\\nCertainly! \\n\\nThe image shows a brown cow standing on a sandy beach with turquoise water and a blue sky in the background. It looks like a'],\n@@ -610,7 +610,7 @@ def test_model_4b_crops(self):\n         EXPECTED_NUM_IMAGES = 3  # one for the origin image and two crops of images\n         EXPECTED_TEXTS = Expectations(\n             {\n-                (\"xpu\", 3): ['user\\nYou are a helpful assistant.\\n\\nHere is the original image \\n\\n\\n\\n and here are some crops to help you see better \\n\\n\\n\\n \\n\\n\\n\\nWhat is shown in this image?\\nmodel\\nThe image shows a brown cow standing on a sandy beach next to a turquoise ocean. There are clouds in the blue sky above.'],\n+                (\"xpu\", 3): [\"user\\nYou are a helpful assistant.\\n\\nHere is the original image \\n\\n\\n\\n and here are some crops to help you see better \\n\\n\\n\\n \\n\\n\\n\\nWhat is shown in this image?\\nmodel\\nThe image shows a brown cow standing on a sandy beach next to a turquoise ocean. There's a bright blue sky with some white clouds in the\"],\n                 (\"cuda\", 7): [],\n                 (\"cuda\", (8, 6)): [\"user\\nYou are a helpful assistant.\\n\\nHere is the original image \\n\\n\\n\\n and here are some crops to help you see better \\n\\n\\n\\n \\n\\n\\n\\nWhat is shown in this image?\\nmodel\\nThe image shows a brown cow standing on a sandy beach next to a turquoise ocean. There's a clear blue sky with some white clouds above.\"],\n                 (\"cuda\", (8, 0)): [\"user\\nYou are a helpful assistant.\\n\\nHere is the original image \\n\\n\\n\\n and here are some crops to help you see better \\n\\n\\n\\n \\n\\n\\n\\nWhat is shown in this image?\\nmodel\\nThe image shows a brown cow standing on a sandy beach next to a turquoise ocean. There's a blue sky with some white clouds in the background\"],"
        },
        {
            "sha": "ef1f0d5dc80aae037d675c84b48a7fc76d79b3c8",
            "filename": "tests/models/glm4v/test_modeling_glm4v.py",
            "status": "modified",
            "additions": 19,
            "deletions": 7,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/a43b36cf802f00616800e0bd4d748679236123ee/tests%2Fmodels%2Fglm4v%2Ftest_modeling_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a43b36cf802f00616800e0bd4d748679236123ee/tests%2Fmodels%2Fglm4v%2Ftest_modeling_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fglm4v%2Ftest_modeling_glm4v.py?ref=a43b36cf802f00616800e0bd4d748679236123ee",
            "patch": "@@ -24,7 +24,9 @@\n     is_torch_available,\n )\n from transformers.testing_utils import (\n+    Expectations,\n     cleanup,\n+    require_deterministic_for_xpu,\n     require_flash_attn,\n     require_torch,\n     require_torch_gpu,\n@@ -413,6 +415,7 @@ def test_small_model_integration_test_with_video(self):\n         )\n \n     @slow\n+    @require_deterministic_for_xpu\n     def test_small_model_integration_test_expand(self):\n         model = Glm4vForConditionalGeneration.from_pretrained(\n             \"THUDM/GLM-4.1V-9B-Thinking\", dtype=\"auto\", device_map=\"auto\"\n@@ -426,14 +429,23 @@ def test_small_model_integration_test_expand(self):\n \n         output = model.generate(**inputs, max_new_tokens=30, do_sample=False, num_beams=2, num_return_sequences=2)\n \n-        EXPECTED_DECODED_TEXT = [\n-            \"\\nWhat kind of dog is this?\\n<think>Got it, let's look at the image. The animal in the picture doesn't look like a dog; it's actually a cat. Specifically\",\n-            \"\\nWhat kind of dog is this?\\n<think>Got it, let's look at the image. The animal in the picture doesn't look like a dog; it's actually a cat, specifically\"\n-        ]  # fmt: skip\n-        self.assertEqual(\n-            self.processor.batch_decode(output, skip_special_tokens=True),\n-            EXPECTED_DECODED_TEXT,\n+        # fmt: off\n+        EXPECTED_DECODED_TEXTS = Expectations(\n+            {\n+\n+                (None, None): [\"\\nWhat kind of dog is this?\\n<think>Got it, let's look at the image. The animal in the picture doesn't look like a dog; it's actually a cat. Specifically\",\n+                               \"\\nWhat kind of dog is this?\\n<think>Got it, let's look at the image. The animal in the picture doesn't look like a dog; it's actually a cat, specifically\"\n+                              ],\n+                (\"xpu\", None): [\"\\nWhat kind of dog is this?\\n<think>Got it, let's look at the image. The animal in the picture is not a dog; it's a cat. Specifically, it looks\",\n+                                \"\\nWhat kind of dog is this?\\n<think>Got it, let's look at the image. The animal in the picture is not a dog; it's a cat, specifically a Pallas\"\n+                               ],\n+            }\n         )\n+        # fmt: on\n+        EXPECTED_DECODED_TEXT = EXPECTED_DECODED_TEXTS.get_expectation()\n+\n+        decoded_text = self.processor.batch_decode(output, skip_special_tokens=True)\n+        self.assertEqual(decoded_text, EXPECTED_DECODED_TEXT)\n \n     @slow\n     def test_small_model_integration_test_batch_wo_image(self):"
        },
        {
            "sha": "3a7f51642a7be9fde57e189b5a0c5ff946bc903e",
            "filename": "tests/models/mistral3/test_modeling_mistral3.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/a43b36cf802f00616800e0bd4d748679236123ee/tests%2Fmodels%2Fmistral3%2Ftest_modeling_mistral3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a43b36cf802f00616800e0bd4d748679236123ee/tests%2Fmodels%2Fmistral3%2Ftest_modeling_mistral3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmistral3%2Ftest_modeling_mistral3.py?ref=a43b36cf802f00616800e0bd4d748679236123ee",
            "patch": "@@ -275,6 +275,7 @@ def test_mistral3_integration_generate_text_only(self):\n         self.assertEqual(decoded_output, expected_output)\n \n     @require_read_token\n+    @require_deterministic_for_xpu\n     def test_mistral3_integration_generate(self):\n         processor = AutoProcessor.from_pretrained(self.model_checkpoint)\n         processor.chat_template = processor.chat_template.replace('strftime_now(\"%Y-%m-%d\")', '\"2025-06-20\"')\n@@ -299,7 +300,7 @@ def test_mistral3_integration_generate(self):\n \n         expected_outputs = Expectations(\n             {\n-                (\"xpu\", 3): \"The image features two cats resting on a pink blanket. The cat on the left is a kitten\",\n+                (\"xpu\", 3): \"The image features two tabby cats lying on a pink surface, which appears to be a cushion or\",\n                 (\"cuda\", 8): 'The image features two cats lying on a pink surface, which appears to be a couch or a bed',\n                 (\"rocm\", (9, 4)): \"The image features two cats lying on a pink surface, which appears to be a couch or a bed\",\n                 (\"rocm\", (9, 5)): \"The image features two tabby cats lying on a pink surface, which appears to be a cushion or\""
        },
        {
            "sha": "2f488317d0f346665f7c7bfe9f0cccedc9b50473",
            "filename": "tests/models/mllama/test_modeling_mllama.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/a43b36cf802f00616800e0bd4d748679236123ee/tests%2Fmodels%2Fmllama%2Ftest_modeling_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a43b36cf802f00616800e0bd4d748679236123ee/tests%2Fmodels%2Fmllama%2Ftest_modeling_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmllama%2Ftest_modeling_mllama.py?ref=a43b36cf802f00616800e0bd4d748679236123ee",
            "patch": "@@ -547,7 +547,7 @@ def test_11b_model_integration_generate_text_only(self):\n         decoded_output = processor.decode(output[0], skip_special_tokens=True)\n         expected_outputs = Expectations(\n                 {\n-                    (\"xpu\", 3): \"If I had to write a haiku about my life, I would write:\\nLife is a messy tapestry\\n Threads of joy and sorrow\\nWeft of memories\",\n+                    (\"xpu\", 3): \"If I had to write a haiku about my life, I would write:\\nLife is a messy stream\\nRipples of joy and pain\\nFlowing, ever\",\n                     (\"cuda\", 7): \"If I had to write a haiku about my life, I would write:\\nLife is a messy stream\\nRipples of joy and pain\\nFlowing, ever\",\n                     (\"cuda\", 8): \"If I had to write a haiku about my life, I would write:\\nLife is a messy stream\\nRipples of joy and pain\\nFlowing, ever\",\n                 }"
        },
        {
            "sha": "dbc164701a4cdd9a1bcf4223a6ed40ec00135eb5",
            "filename": "tests/pipelines/test_pipelines_automatic_speech_recognition.py",
            "status": "modified",
            "additions": 8,
            "deletions": 1,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/a43b36cf802f00616800e0bd4d748679236123ee/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a43b36cf802f00616800e0bd4d748679236123ee/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py?ref=a43b36cf802f00616800e0bd4d748679236123ee",
            "patch": "@@ -35,6 +35,7 @@\n from transformers.pipelines.audio_utils import chunk_bytes_iter, ffmpeg_microphone_live\n from transformers.pipelines.automatic_speech_recognition import chunk_iter\n from transformers.testing_utils import (\n+    Expectations,\n     compare_pipeline_output_to_hub_spec,\n     is_pipeline_test,\n     is_torch_available,\n@@ -1443,8 +1444,14 @@ def test_whisper_prompted(self):\n     @slow\n     def test_whisper_longform(self):\n         # fmt: off\n-        EXPECTED_RESULT = \" Folks, if you watch the show, you know, I spent a lot of time right over there. Patiently and astutely scrutinizing the boxwood and mahogany chest set of the day's biggest stories developing the central headline pawns, definitely maneuvering an oso topical night to F6, fainting a classic Sicilian, nade door variation on the news, all the while seeing eight moves deep and patiently marshalling the latest press releases into a fisher's shows in Lip Nitsky attack that culminates in the elegant lethal slow-played, all-passant checkmate that is my nightly monologue. But sometimes, sometimes, folks, I. CHEERING AND APPLAUSE Sometimes I startle away, cubside down in the monkey bars of a condemned playground on a super fun site. Get all hept up on goofballs. Rummage that were discarded tag bag of defective toys. Yank out a fist bowl of disembodied doll limbs, toss them on Saturday, Rusty Cargo, container down by the Wharf, and challenge toothless drifters to the godless bughouse lets of tournament that is my segment. MUSIC Meanwhile!\"\n+        EXPECTED_RESULTS = Expectations(\n+            {\n+                (None, None): \" Folks, if you watch the show, you know, I spent a lot of time right over there. Patiently and astutely scrutinizing the boxwood and mahogany chest set of the day's biggest stories developing the central headline pawns, definitely maneuvering an oso topical night to F6, fainting a classic Sicilian, nade door variation on the news, all the while seeing eight moves deep and patiently marshalling the latest press releases into a fisher's shows in Lip Nitsky attack that culminates in the elegant lethal slow-played, all-passant checkmate that is my nightly monologue. But sometimes, sometimes, folks, I. CHEERING AND APPLAUSE Sometimes I startle away, cubside down in the monkey bars of a condemned playground on a super fun site. Get all hept up on goofballs. Rummage that were discarded tag bag of defective toys. Yank out a fist bowl of disembodied doll limbs, toss them on Saturday, Rusty Cargo, container down by the Wharf, and challenge toothless drifters to the godless bughouse lets of tournament that is my segment. MUSIC Meanwhile!\",\n+                (\"xpu\", None): \" Folks, if you watch the show, you know, I spent a lot of time right over there. Patiently and astutely scrutinizing the boxwood and mahogany chest set of the day's biggest stories developing the central headline pawns, definitely maneuvering an oso topical night to F6, fainting of classics, Sicilian, nade door variation on the news, all the while seeing eight moves deep and patiently marshalling the latest press releases into a Fisher shows in Lip Nitsky attack that culminates in the elegant lethal slow-played, all-passant checkmate that is my nightly monologue. But sometimes, sometimes, folks, I... APPLAUSE Sometimes I... Startle away, upside down on the monkey bars of a condemned playground on a superfund site. Get all heaped up on goofballs, rummaged that would discard a tag bag of defective toys, yank out a fist bowl of disembodied doll limbs, toss them on a stain kid's place mat from a defunct denys, set up a table inside a rusty cargo container down by the Wharf and challenge toothless drifters to the godless bug house blitz of tournament that is my segment.\",\n+            }\n+        )\n         # fmt: on\n+        EXPECTED_RESULT = EXPECTED_RESULTS.get_expectation()\n \n         processor = AutoProcessor.from_pretrained(\"openai/whisper-tiny.en\")\n         model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\")"
        }
    ],
    "stats": {
        "total": 51,
        "additions": 35,
        "deletions": 16
    }
}