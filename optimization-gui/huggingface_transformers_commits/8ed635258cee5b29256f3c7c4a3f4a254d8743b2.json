{
    "author": "hannan72",
    "message": "Fix flax whisper tokenizer bug (#33151)\n\n* Update tokenization_whisper.py\r\n\r\nFix issue with flax whisper model\r\n\r\n* Update tokenization_whisper_fast.py\r\n\r\nFix issue with flax whisper model\r\n\r\n* Update tokenization_whisper.py\r\n\r\njust check len of token_ids\r\n\r\n* Update tokenization_whisper_fast.py\r\n\r\njust use len of token_ids\r\n\r\n* Update tokenization_whisper_fast.py and revert changes in _strip_prompt and add support to jax arrays in _convert_to_list\r\n\r\n* Update tokenization_whisper.py and revert changes in _strip_prompt and add support to jax arrays in _convert_to_list\r\n\r\n* Update test_tokenization_whisper.py to add test for _convert_to_list method\r\n\r\n* Update test_tokenization_whisper.py to fix code style issues\r\n\r\n* Fix code style\r\n\r\n* Fix code check again\r\n\r\n* Update test_tokenization)whisper.py to Improve code style\r\n\r\n* Update test_tokenization_whisper.py to run each of jax, tf and flax modules if available\r\n\r\n* Update tests/models/whisper/test_tokenization_whisper.py\r\n\r\nCo-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>\r\n\r\n* Update test_tokenization_whisper.py and use require_xxx decorators instead of `is_xxx_available()` method\r\n\r\n* Revert the changes automatically applied by formatter and was unrelated to PR\r\n\r\n* Format for minimal changes\r\n\r\n---------\r\n\r\nCo-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>",
    "sha": "8ed635258cee5b29256f3c7c4a3f4a254d8743b2",
    "files": [
        {
            "sha": "0a6eb75c55f66c0d7a9f4e40be6a9df9592f796d",
            "filename": "src/transformers/models/whisper/tokenization_whisper.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8ed635258cee5b29256f3c7c4a3f4a254d8743b2/src%2Ftransformers%2Fmodels%2Fwhisper%2Ftokenization_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8ed635258cee5b29256f3c7c4a3f4a254d8743b2/src%2Ftransformers%2Fmodels%2Fwhisper%2Ftokenization_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Ftokenization_whisper.py?ref=8ed635258cee5b29256f3c7c4a3f4a254d8743b2",
            "patch": "@@ -880,6 +880,8 @@ def _convert_to_list(token_ids):\n                 token_ids = token_ids.cpu().numpy()\n             elif \"tensorflow\" in str(type(token_ids)):\n                 token_ids = token_ids.numpy()\n+        elif \"jaxlib\" in str(type(token_ids)):\n+            token_ids = token_ids.tolist()\n         # now the token ids are either a numpy array, or a list of lists\n         if isinstance(token_ids, np.ndarray):\n             token_ids = token_ids.tolist()"
        },
        {
            "sha": "66cf412cc2a8f7fc934b68c41b2b9863cc251524",
            "filename": "src/transformers/models/whisper/tokenization_whisper_fast.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8ed635258cee5b29256f3c7c4a3f4a254d8743b2/src%2Ftransformers%2Fmodels%2Fwhisper%2Ftokenization_whisper_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8ed635258cee5b29256f3c7c4a3f4a254d8743b2/src%2Ftransformers%2Fmodels%2Fwhisper%2Ftokenization_whisper_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Ftokenization_whisper_fast.py?ref=8ed635258cee5b29256f3c7c4a3f4a254d8743b2",
            "patch": "@@ -613,6 +613,8 @@ def _convert_to_list(token_ids):\n                 token_ids = token_ids.cpu().numpy()\n             elif \"tensorflow\" in str(type(token_ids)):\n                 token_ids = token_ids.numpy()\n+        elif \"jaxlib\" in str(type(token_ids)):\n+            token_ids = token_ids.tolist()\n         # now the token ids are either a numpy array, or a list of lists\n         if isinstance(token_ids, np.ndarray):\n             token_ids = token_ids.tolist()"
        },
        {
            "sha": "27b24448d5a2be2c1d97f2454fc0b51a56668755",
            "filename": "tests/models/whisper/test_tokenization_whisper.py",
            "status": "modified",
            "additions": 40,
            "deletions": 1,
            "changes": 41,
            "blob_url": "https://github.com/huggingface/transformers/blob/8ed635258cee5b29256f3c7c4a3f4a254d8743b2/tests%2Fmodels%2Fwhisper%2Ftest_tokenization_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8ed635258cee5b29256f3c7c4a3f4a254d8743b2/tests%2Fmodels%2Fwhisper%2Ftest_tokenization_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwhisper%2Ftest_tokenization_whisper.py?ref=8ed635258cee5b29256f3c7c4a3f4a254d8743b2",
            "patch": "@@ -18,7 +18,7 @@\n \n from transformers.models.whisper import WhisperTokenizer, WhisperTokenizerFast\n from transformers.models.whisper.tokenization_whisper import _combine_tokens_into_words, _find_longest_common_sequence\n-from transformers.testing_utils import slow\n+from transformers.testing_utils import require_flax, require_tf, require_torch, slow\n \n from ...test_tokenization_common import TokenizerTesterMixin\n \n@@ -574,3 +574,42 @@ def test_offset_decoding(self):\n \n         output = multilingual_tokenizer.decode(INPUT_TOKENS, output_offsets=True)[\"offsets\"]\n         self.assertEqual(output, [])\n+\n+    def test_convert_to_list_np(self):\n+        test_list = [[1, 2, 3], [4, 5, 6]]\n+\n+        # Test with an already converted list\n+        self.assertListEqual(WhisperTokenizer._convert_to_list(test_list), test_list)\n+        self.assertListEqual(WhisperTokenizerFast._convert_to_list(test_list), test_list)\n+\n+        # Test with a numpy array\n+        np_array = np.array(test_list)\n+        self.assertListEqual(WhisperTokenizer._convert_to_list(np_array), test_list)\n+        self.assertListEqual(WhisperTokenizerFast._convert_to_list(np_array), test_list)\n+\n+    @require_tf\n+    def test_convert_to_list_tf(self):\n+        import tensorflow as tf\n+\n+        test_list = [[1, 2, 3], [4, 5, 6]]\n+        tf_tensor = tf.constant(test_list)\n+        self.assertListEqual(WhisperTokenizer._convert_to_list(tf_tensor), test_list)\n+        self.assertListEqual(WhisperTokenizerFast._convert_to_list(tf_tensor), test_list)\n+\n+    @require_flax\n+    def test_convert_to_list_jax(self):\n+        import jax.numpy as jnp\n+\n+        test_list = [[1, 2, 3], [4, 5, 6]]\n+        jax_array = jnp.array(test_list)\n+        self.assertListEqual(WhisperTokenizer._convert_to_list(jax_array), test_list)\n+        self.assertListEqual(WhisperTokenizerFast._convert_to_list(jax_array), test_list)\n+\n+    @require_torch\n+    def test_convert_to_list_pt(self):\n+        import torch\n+\n+        test_list = [[1, 2, 3], [4, 5, 6]]\n+        torch_tensor = torch.tensor(test_list)\n+        self.assertListEqual(WhisperTokenizer._convert_to_list(torch_tensor), test_list)\n+        self.assertListEqual(WhisperTokenizerFast._convert_to_list(torch_tensor), test_list)"
        }
    ],
    "stats": {
        "total": 45,
        "additions": 44,
        "deletions": 1
    }
}