{
    "author": "yonigozlan",
    "message": "[DOC] Add missing dates in model cards (#40922)\n\nadd missing dates",
    "sha": "3853bfe4d50a93880e99afff680c5d9f7beb5f7a",
    "files": [
        {
            "sha": "ba0bdb230bf92e9792b9ed454e36b994c63b8d65",
            "filename": "docs/source/en/model_doc/apertus.md",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3853bfe4d50a93880e99afff680c5d9f7beb5f7a/docs%2Fsource%2Fen%2Fmodel_doc%2Fapertus.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/3853bfe4d50a93880e99afff680c5d9f7beb5f7a/docs%2Fsource%2Fen%2Fmodel_doc%2Fapertus.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fapertus.md?ref=3853bfe4d50a93880e99afff680c5d9f7beb5f7a",
            "patch": "@@ -13,6 +13,9 @@ specific language governing permissions and limitations under the License.\n rendered properly in your Markdown viewer.\n \n -->\n+*This model was released on 2025-09-02 and added to Hugging Face Transformers on 2025-08-28.*\n+\n+# Apertus\n \n <div style=\"float: right;\">\n     <div class=\"flex flex-wrap space-x-1\">\n@@ -23,7 +26,7 @@ rendered properly in your Markdown viewer.\n     </div>\n </div>\n \n-# Apertus\n+## Overview\n \n [Apertus](https://www.swiss-ai.org) is a family of large language models from the Swiss AI Initiative.\n "
        },
        {
            "sha": "77e8de10c31b7c99de6ce276a4da13fdd516659f",
            "filename": "docs/source/en/model_doc/florence2.md",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3853bfe4d50a93880e99afff680c5d9f7beb5f7a/docs%2Fsource%2Fen%2Fmodel_doc%2Fflorence2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/3853bfe4d50a93880e99afff680c5d9f7beb5f7a/docs%2Fsource%2Fen%2Fmodel_doc%2Fflorence2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fflorence2.md?ref=3853bfe4d50a93880e99afff680c5d9f7beb5f7a",
            "patch": "@@ -13,6 +13,9 @@ specific language governing permissions and limitations under the License.\n rendered properly in your Markdown viewer.\n \n -->\n+*This model was released on 2024-06-16 and added to Hugging Face Transformers on 2025-08-20.*\n+\n+# Florence-2\n \n <div style=\"float: right;\">\n     <div class=\"flex flex-wrap space-x-1\">\n@@ -21,7 +24,7 @@ rendered properly in your Markdown viewer.\n     </div>\n </div>\n \n-# Florence-2\n+## Overview\n \n [Florence-2](https://huggingface.co/papers/2311.06242) is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks. Florence-2 can interpret simple text prompts to perform tasks like captioning, object detection, and segmentation. It leverages the FLD-5B dataset, containing 5.4 billion annotations across 126 million images, to master multi-task learning. The model's sequence-to-sequence architecture enables it to excel in both zero-shot and fine-tuned settings, proving to be a competitive vision foundation model.\n "
        },
        {
            "sha": "6f12a3aa746b78f89e20c2b856fa2178eb9f6843",
            "filename": "docs/source/en/model_doc/nllb.md",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/3853bfe4d50a93880e99afff680c5d9f7beb5f7a/docs%2Fsource%2Fen%2Fmodel_doc%2Fnllb.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/3853bfe4d50a93880e99afff680c5d9f7beb5f7a/docs%2Fsource%2Fen%2Fmodel_doc%2Fnllb.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fnllb.md?ref=3853bfe4d50a93880e99afff680c5d9f7beb5f7a",
            "patch": "@@ -13,6 +13,9 @@ specific language governing permissions and limitations under the License.\n rendered properly in your Markdown viewer.\n \n -->\n+*This model was released on 2022-07-11 and added to Hugging Face Transformers on 2022-07-18.*\n+\n+# NLLB\n \n <div style=\"float: right;\">\n     <div class=\"flex flex-wrap space-x-1\">\n@@ -22,18 +25,15 @@ rendered properly in your Markdown viewer.\n     </div>\n </div>\n \n-*This model was released on 2022-07-11 and added to Hugging Face Transformers on 2022-07-18.*\n-\n-\n-# NLLB\n+## Overview\n \n [NLLB: No Language Left Behind](https://huggingface.co/papers/2207.04672) is a multilingual translation model. It's trained on data using data mining techniques tailored for low-resource languages and supports over 200 languages. NLLB features a conditional compute architecture using a Sparsely Gated Mixture of Experts.\n \n \n You can find all the original NLLB checkpoints under the [AI at Meta](https://huggingface.co/facebook/models?search=nllb) organization.\n \n > [!TIP]\n-> This model was contributed by [Lysandre](https://huggingface.co/lysandre).  \n+> This model was contributed by [Lysandre](https://huggingface.co/lysandre).\n > Click on the NLLB models in the right sidebar for more examples of how to apply NLLB to different translation tasks.\n \n The example below demonstrates how to translate text with [`Pipeline`] or the [`AutoModel`] class.\n@@ -120,17 +120,17 @@ visualizer(\"UN Chief says there is no military solution in Syria\")\n    >>> tokenizer(\"How was your day?\").input_ids\n    [256047, 13374, 1398, 4260, 4039, 248130, 2]\n    ```\n-   \n+\n    To revert to the legacy behavior, use the code example below.\n-   \n+\n    ```python\n    >>> from transformers import NllbTokenizer\n \n    >>> tokenizer = NllbTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", legacy_behaviour=True)\n    ```\n-   \n+\n  - For non-English languages, specify the language's [BCP-47](https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200) code with the `src_lang` keyword as shown below.\n- \n+\n  - See example below for a translation from Romanian to German.\n     ```python\n     >>> from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
        },
        {
            "sha": "c2a3fe5acebcedf1e0f7366fa26ca5267762df4d",
            "filename": "docs/source/en/model_doc/sam2.md",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/3853bfe4d50a93880e99afff680c5d9f7beb5f7a/docs%2Fsource%2Fen%2Fmodel_doc%2Fsam2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/3853bfe4d50a93880e99afff680c5d9f7beb5f7a/docs%2Fsource%2Fen%2Fmodel_doc%2Fsam2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fsam2.md?ref=3853bfe4d50a93880e99afff680c5d9f7beb5f7a",
            "patch": "@@ -13,6 +13,10 @@ specific language governing permissions and limitations under the License.\n rendered properly in your Markdown viewer.\n \n -->\n+*This model was released on 2024-07-29 and added to Hugging Face Transformers on 2025-08-14.*\n+\n+# SAM2\n+\n <div style=\"float: right;\">\n     <div class=\"flex flex-wrap space-x-1\">\n         <img alt=\"PyTorch\" src=\"https://img.shields.io/badge/PyTorch-DE3412?style=flat&logo=pytorch&logoColor=white\">\n@@ -21,8 +25,6 @@ rendered properly in your Markdown viewer.\n     </div>\n </div>\n \n-# SAM2\n-\n ## Overview\n \n SAM2 (Segment Anything Model 2) was proposed in [Segment Anything in Images and Videos](https://ai.meta.com/research/publications/sam-2-segment-anything-in-images-and-videos/) by Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman Rädle, Chloe Rolland, Laura Gustafson, Eric Mintun, Junting Pan, Kalyan Vasudev Alwala, Nicolas Carion, Chao-Yuan Wu, Ross Girshick, Piotr Dollár, Christoph Feichtenhofer."
        },
        {
            "sha": "330955592650f7978fd81ac212e28fc087d731d7",
            "filename": "docs/source/en/model_doc/sam2_video.md",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/3853bfe4d50a93880e99afff680c5d9f7beb5f7a/docs%2Fsource%2Fen%2Fmodel_doc%2Fsam2_video.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/3853bfe4d50a93880e99afff680c5d9f7beb5f7a/docs%2Fsource%2Fen%2Fmodel_doc%2Fsam2_video.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fsam2_video.md?ref=3853bfe4d50a93880e99afff680c5d9f7beb5f7a",
            "patch": "@@ -13,6 +13,10 @@ specific language governing permissions and limitations under the License.\n rendered properly in your Markdown viewer.\n \n -->\n+*This model was released on 2024-07-29 and added to Hugging Face Transformers on 2025-08-14.*\n+\n+# SAM2 Video\n+\n <div style=\"float: right;\">\n     <div class=\"flex flex-wrap space-x-1\">\n         <img alt=\"PyTorch\" src=\"https://img.shields.io/badge/PyTorch-DE3412?style=flat&logo=pytorch&logoColor=white\">\n@@ -21,8 +25,6 @@ rendered properly in your Markdown viewer.\n     </div>\n </div>\n \n-# SAM2 Video\n-\n ## Overview\n \n SAM2 (Segment Anything Model 2) was proposed in [Segment Anything in Images and Videos](https://ai.meta.com/research/publications/sam-2-segment-anything-in-images-and-videos/) by Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman Rädle, Chloe Rolland, Laura Gustafson, Eric Mintun, Junting Pan, Kalyan Vasudev Alwala, Nicolas Carion, Chao-Yuan Wu, Ross Girshick, Piotr Dollár, Christoph Feichtenhofer."
        }
    ],
    "stats": {
        "total": 40,
        "additions": 25,
        "deletions": 15
    }
}