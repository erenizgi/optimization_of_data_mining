{
    "author": "fabxoe",
    "message": "ğŸŒ [i18n-KO] Translated `main_classes/quantization.md` to Korean (#33959)\n\n* docs: ko: main_classes/quantization.md\r\n\r\n* feat: nmt draft\r\n\r\n* fix: resolve suggestions\r\n\r\nCo-authored-by: Ahnjj_DEV <ahnjj.dev@gmail.com>\r\n\r\n* fix: resolve suggestions\r\n\r\nCo-authored-by: Ahnjj_DEV <ahnjj.dev@gmail.com>\r\n\r\n* fix: resolve suggestions\r\n\r\n---------\r\n\r\nCo-authored-by: Ahnjj_DEV <ahnjj.dev@gmail.com>",
    "sha": "2e8de976bdd99319451ffdcbc5beda8b6f2808b5",
    "files": [
        {
            "sha": "2bceac04025b12d91f190ed0e9be594b0974dde5",
            "filename": "docs/source/ko/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2e8de976bdd99319451ffdcbc5beda8b6f2808b5/docs%2Fsource%2Fko%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/2e8de976bdd99319451ffdcbc5beda8b6f2808b5/docs%2Fsource%2Fko%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2F_toctree.yml?ref=2e8de976bdd99319451ffdcbc5beda8b6f2808b5",
            "patch": "@@ -298,8 +298,8 @@\n       title: (ë²ˆì—­ì¤‘) Pipelines\n     - local: in_translation\n       title: (ë²ˆì—­ì¤‘) Processors\n-    - local: in_translation\n-      title: (ë²ˆì—­ì¤‘) Quantization\n+    - local: main_classes/quantization\n+      title: ì–‘ìí™”\n     - local: in_translation\n       title: (ë²ˆì—­ì¤‘) Tokenizer\n     - local: main_classes/trainer"
        },
        {
            "sha": "b1d1730d28d00b11dd36d542c3ca74760004e85a",
            "filename": "docs/source/ko/main_classes/quantization.md",
            "status": "added",
            "additions": 71,
            "deletions": 0,
            "changes": 71,
            "blob_url": "https://github.com/huggingface/transformers/blob/2e8de976bdd99319451ffdcbc5beda8b6f2808b5/docs%2Fsource%2Fko%2Fmain_classes%2Fquantization.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/2e8de976bdd99319451ffdcbc5beda8b6f2808b5/docs%2Fsource%2Fko%2Fmain_classes%2Fquantization.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmain_classes%2Fquantization.md?ref=2e8de976bdd99319451ffdcbc5beda8b6f2808b5",
            "patch": "@@ -0,0 +1,71 @@\n+<!--Copyright 2023 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n+\n+âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+\n+# ì–‘ìí™”[[quantization]]\n+\n+\n+\n+ì–‘ìí™” ê¸°ë²•ì€ ê°€ì¤‘ì¹˜ì™€ í™œì„±í™”ë¥¼ 8ë¹„íŠ¸ ì •ìˆ˜(int8)ì™€ ê°™ì€ ë” ë‚®ì€ ì •ë°€ë„ì˜ ë°ì´í„° íƒ€ì…ìœ¼ë¡œ í‘œí˜„í•¨ìœ¼ë¡œì¨ ë©”ëª¨ë¦¬ì™€ ê³„ì‚° ë¹„ìš©ì„ ì¤„ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì¼ë°˜ì ìœ¼ë¡œëŠ” ë©”ëª¨ë¦¬ì— ì˜¬ë¦´ ìˆ˜ ì—†ëŠ” ë” í° ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ìˆê³ , ì¶”ë¡  ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. TransformersëŠ” AWQì™€ GPTQ ì–‘ìí™” ì•Œê³ ë¦¬ì¦˜ì„ ì§€ì›í•˜ë©°, bitsandbytesë¥¼ í†µí•´ 8ë¹„íŠ¸ì™€ 4ë¹„íŠ¸ ì–‘ìí™”ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n+Transformersì—ì„œ ì§€ì›ë˜ì§€ ì•ŠëŠ” ì–‘ìí™” ê¸°ë²•ë“¤ì€ [`HfQuantizer`] í´ë˜ìŠ¤ë¥¼ í†µí•´ ì¶”ê°€ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+<Tip>\n+\n+ëª¨ë¸ì„ ì–‘ìí™”í•˜ëŠ” ë°©ë²•ì€ ì´ [ì–‘ìí™”](../quantization) ê°€ì´ë“œë¥¼ í†µí•´ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+</Tip>\n+\n+## QuantoConfig[[transformers.QuantoConfig]]\n+\n+[[autodoc]] QuantoConfig\n+\n+## AqlmConfig[[transformers.AqlmConfig]]\n+\n+[[autodoc]] AqlmConfig\n+\n+## AwqConfig[[transformers.AwqConfig]]\n+\n+[[autodoc]] AwqConfig\n+\n+## EetqConfig[[transformers.EetqConfig]]\n+[[autodoc]] EetqConfig\n+\n+## GPTQConfig[[transformers.GPTQConfig]]\n+\n+[[autodoc]] GPTQConfig\n+\n+## BitsAndBytesConfig[[#transformers.BitsAndBytesConfig]]\n+\n+[[autodoc]] BitsAndBytesConfig\n+\n+## HfQuantizer[[transformers.quantizers.HfQuantizer]]\n+\n+[[autodoc]] quantizers.base.HfQuantizer\n+\n+## HqqConfig[[transformers.HqqConfig]]\n+\n+[[autodoc]] HqqConfig\n+\n+## FbgemmFp8Config[[transformers.FbgemmFp8Config]]\n+\n+[[autodoc]] FbgemmFp8Config\n+\n+## CompressedTensorsConfig[[transformers.CompressedTensorsConfig]]\n+\n+[[autodoc]] CompressedTensorsConfig\n+\n+## TorchAoConfig[[transformers.TorchAoConfig]]\n+\n+[[autodoc]] TorchAoConfig"
        }
    ],
    "stats": {
        "total": 75,
        "additions": 73,
        "deletions": 2
    }
}