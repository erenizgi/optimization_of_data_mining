{
    "author": "gabe-l-hart",
    "message": "feat: Add granite architectures to auto tokenizer name mappings (#38802)\n\nBranch: GraniteTokenizerMapping\n\nSigned-off-by: Gabe Goodhart <ghart@us.ibm.com>",
    "sha": "9a02e7602d01c98946d755c38b51930bf8b43901",
    "files": [
        {
            "sha": "32f71c3d71f8db2a6db5a9fd671349836925ba5c",
            "filename": "src/transformers/models/auto/tokenization_auto.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9a02e7602d01c98946d755c38b51930bf8b43901/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9a02e7602d01c98946d755c38b51930bf8b43901/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Ftokenization_auto.py?ref=9a02e7602d01c98946d755c38b51930bf8b43901",
            "patch": "@@ -245,6 +245,10 @@\n         (\"gpt_neox_japanese\", (\"GPTNeoXJapaneseTokenizer\", None)),\n         (\"gptj\", (\"GPT2Tokenizer\", \"GPT2TokenizerFast\" if is_tokenizers_available() else None)),\n         (\"gptsan-japanese\", (\"GPTSanJapaneseTokenizer\", None)),\n+        (\"granite\", (\"GPT2Tokenizer\", None)),\n+        (\"granitemoe\", (\"GPT2Tokenizer\", None)),\n+        (\"granitemoehybrid\", (\"GPT2Tokenizer\", None)),\n+        (\"granitemoeshared\", (\"GPT2Tokenizer\", None)),\n         (\"grounding-dino\", (\"BertTokenizer\", \"BertTokenizerFast\" if is_tokenizers_available() else None)),\n         (\"groupvit\", (\"CLIPTokenizer\", \"CLIPTokenizerFast\" if is_tokenizers_available() else None)),\n         (\"helium\", (None, \"PreTrainedTokenizerFast\" if is_tokenizers_available() else None)),"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 4,
        "deletions": 0
    }
}