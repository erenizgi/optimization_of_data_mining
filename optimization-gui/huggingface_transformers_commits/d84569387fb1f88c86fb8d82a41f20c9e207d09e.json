{
    "author": "threewebcode",
    "message": "chore: fix typos in utils module (#36668)\n\n* chore: fix typos in utils module\n\n* chore: fix typos in utils module\n\n* chore: fix typos in utils module\n\n* chore: fix typos in utils module\n\n* chore: fix typos in utils module\n\n* chore: fix typos in utils module",
    "sha": "d84569387fb1f88c86fb8d82a41f20c9e207d09e",
    "files": [
        {
            "sha": "507046ea3c3f3cfb1704a2211598f5925ed26d38",
            "filename": "utils/check_config_attributes.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fcheck_config_attributes.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fcheck_config_attributes.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_config_attributes.py?ref=d84569387fb1f88c86fb8d82a41f20c9e207d09e",
            "patch": "@@ -33,7 +33,7 @@\n \n SPECIAL_CASES_TO_ALLOW = {\n     # 'max_position_embeddings' is not used in modeling file, but needed for eval frameworks like Huggingface's lighteval (https://github.com/huggingface/lighteval/blob/af24080ea4f16eaf1683e353042a2dfc9099f038/src/lighteval/models/base_model.py#L264).\n-    # periods and offsers are not used in modeling file, but used in the configuration file to define `layers_block_type` and `layers_num_experts`.\n+    # periods and offsets are not used in modeling file, but used in the configuration file to define `layers_block_type` and `layers_num_experts`.\n     \"BambaConfig\": [\n         \"attn_layer_indices\",\n     ],"
        },
        {
            "sha": "0dffa79a3275e72a5b08887f7082dd1919656938",
            "filename": "utils/check_copies.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fcheck_copies.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fcheck_copies.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_copies.py?ref=d84569387fb1f88c86fb8d82a41f20c9e207d09e",
            "patch": "@@ -245,7 +245,7 @@ def g(x):\n             [\"block_without_name\", \"block_with_name\"],\n         ]:\n             raise ValueError(\n-                f\"\"\"Class defined in {filename} doesn't have the expected stucture.\n+                f\"\"\"Class defined in {filename} doesn't have the expected structure.\n                 See the docstring of `_sanity_check_splits` in the file `utils/check_copies.py`\"\"\",\n             )\n \n@@ -652,7 +652,7 @@ def is_copy_consistent(filename: str, overwrite: bool = False, buffer: dict = No\n \n     Returns:\n         `Optional[List[Tuple[str, int]]]`: If `overwrite=False`, returns the list of differences as tuples `(str, int)`\n-        with the name of the object having a diff and the line number where theere is the first diff.\n+        with the name of the object having a diff and the line number where there is the first diff.\n     \"\"\"\n     base_path = TRANSFORMERS_PATH if not filename.startswith(\"tests\") else MODEL_TEST_PATH\n "
        },
        {
            "sha": "81ab0dea0d4076015c8e8f85765f35e365192818",
            "filename": "utils/check_docstrings.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fcheck_docstrings.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fcheck_docstrings.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_docstrings.py?ref=d84569387fb1f88c86fb8d82a41f20c9e207d09e",
            "patch": "@@ -683,7 +683,7 @@ def replace_default_in_arg_description(description: str, default: Any) -> str:\n \n     Args:\n         description (`str`): The description of an argument in a docstring to process.\n-        default (`Any`): The default value that whould be in the docstring of that argument.\n+        default (`Any`): The default value that would be in the docstring of that argument.\n \n     Returns:\n        `str`: The description updated with the new default value.\n@@ -906,7 +906,7 @@ def match_docstring_with_signature(obj: Any) -> Optional[Tuple[str, str]]:\n \n def fix_docstring(obj: Any, old_doc_args: str, new_doc_args: str):\n     \"\"\"\n-    Fixes the docstring of an object by replacing its arguments documentaiton by the one matched with the signature.\n+    Fixes the docstring of an object by replacing its arguments documentation by the one matched with the signature.\n \n     Args:\n         obj (`Any`):"
        },
        {
            "sha": "95e5a48a0fb0f88232dc9c8a4a732910db52a132",
            "filename": "utils/check_inits.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fcheck_inits.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fcheck_inits.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_inits.py?ref=d84569387fb1f88c86fb8d82a41f20c9e207d09e",
            "patch": "@@ -16,7 +16,7 @@\n Utility that checks the custom inits of Transformers are well-defined: Transformers uses init files that delay the\n import of an object to when it's actually needed. This is to avoid the main init importing all models, which would\n make the line `import transformers` very slow when the user has all optional dependencies installed. The inits with\n-delayed imports have two halves: one definining a dictionary `_import_structure` which maps modules to the name of the\n+delayed imports have two halves: one defining a dictionary `_import_structure` which maps modules to the name of the\n objects in each module, and one in `TYPE_CHECKING` which looks like a normal init for type-checkers. The goal of this\n script is to check the objects defined in both halves are the same.\n \n@@ -363,7 +363,7 @@ def check_submodules():\n     if len(module_not_registered) > 0:\n         list_of_modules = \"\\n\".join(f\"- {module}\" for module in module_not_registered)\n         raise ValueError(\n-            \"The following submodules are not properly registed in the main init of Transformers:\\n\"\n+            \"The following submodules are not properly registered in the main init of Transformers:\\n\"\n             f\"{list_of_modules}\\n\"\n             \"Make sure they appear somewhere in the keys of `_import_structure` with an empty list as value.\"\n         )"
        },
        {
            "sha": "7d3635c71b53764145478c40a12fa8cc0f3584ed",
            "filename": "utils/custom_init_isort.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fcustom_init_isort.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fcustom_init_isort.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcustom_init_isort.py?ref=d84569387fb1f88c86fb8d82a41f20c9e207d09e",
            "patch": "@@ -16,7 +16,7 @@\n Utility that sorts the imports in the custom inits of Transformers. Transformers uses init files that delay the\n import of an object to when it's actually needed. This is to avoid the main init importing all models, which would\n make the line `import transformers` very slow when the user has all optional dependencies installed. The inits with\n-delayed imports have two halves: one definining a dictionary `_import_structure` which maps modules to the name of the\n+delayed imports have two halves: one defining a dictionary `_import_structure` which maps modules to the name of the\n objects in each module, and one in `TYPE_CHECKING` which looks like a normal init for type-checkers. `isort` or `ruff`\n properly sort the second half which looks like traditionl imports, the goal of this script is to sort the first half.\n "
        },
        {
            "sha": "db449ef00a06efb9840ce3634d660be9f28e7bdd",
            "filename": "utils/deprecate_models.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fdeprecate_models.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fdeprecate_models.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fdeprecate_models.py?ref=d84569387fb1f88c86fb8d82a41f20c9e207d09e",
            "patch": "@@ -344,7 +344,7 @@ def deprecate_models(models):\n         print(\"Removing #Copied from statements from model's files\")\n         remove_copied_from_statements(model)\n \n-        # Move the model file to deprecated: src/transfomers/models/model -> src/transformers/models/deprecated/model\n+        # Move the model file to deprecated: src/transformers/models/model -> src/transformers/models/deprecated/model\n         print(\"Moving model files to deprecated for model\")\n         move_model_files_to_deprecated(model)\n "
        },
        {
            "sha": "0c0e2ac4a0645b2da2a56ae974d86b14a526e619",
            "filename": "utils/modular_model_converter.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fmodular_model_converter.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fmodular_model_converter.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fmodular_model_converter.py?ref=d84569387fb1f88c86fb8d82a41f20c9e207d09e",
            "patch": "@@ -257,7 +257,7 @@ def is_full_docstring(new_docstring: str) -> bool:\n     \"\"\"Check if `new_docstring` is a full docstring, or if it is only part of a docstring that should then\n     be merged with the existing old one.\n     \"\"\"\n-    # libcst returns the docstrinbgs with litteral `r\"\"\"` quotes in front\n+    # libcst returns the docstrinbgs with literal `r\"\"\"` quotes in front\n     new_docstring = new_docstring.split('\"\"\"', 1)[1]\n     # The docstring contains Args definition, so it is self-contained\n     if re.search(r\"\\n\\s*Args:\\n\", new_docstring):\n@@ -1141,7 +1141,7 @@ def append_new_import_node(\n def get_needed_imports(body: dict[str, dict], all_imports: list[cst.CSTNode]) -> list[cst.CSTNode]:\n     \"\"\"Get all the imports needed in the `body`, from the list of `all_imports`.\n     `body` is a dict with the following structure `{str: {\"insert_idx\": int, \"node\": cst.CSTNode}}`.\n-    Note: we need to use `isinstance` on scope assignements, m.matches apparently does not work here yet!\n+    Note: we need to use `isinstance` on scope assignments, m.matches apparently does not work here yet!\n     \"\"\"\n     new_body = [k[1][\"node\"] for k in sorted(body.items(), key=lambda x: x[1][\"insert_idx\"])]\n     wrapper = MetadataWrapper(cst.Module(body=all_imports + new_body))\n@@ -1615,7 +1615,7 @@ class node based on the inherited classes if needed. Also returns any new import\n \n \n def create_modules(modular_mapper: ModularFileMapper) -> dict[str, cst.Module]:\n-    \"\"\"Create all the new modules based on visiting the modular file. It replaces all classes as necesary.\"\"\"\n+    \"\"\"Create all the new modules based on visiting the modular file. It replaces all classes as necessary.\"\"\"\n     files = defaultdict(dict)\n     current_file_indices = defaultdict(lambda: 0)\n "
        },
        {
            "sha": "d8c97f5740191a68c94c3010091f6d68f95928fc",
            "filename": "utils/split_doctest_jobs.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fsplit_doctest_jobs.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fsplit_doctest_jobs.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fsplit_doctest_jobs.py?ref=d84569387fb1f88c86fb8d82a41f20c9e207d09e",
            "patch": "@@ -49,7 +49,7 @@\n         \"--num_splits\",\n         type=int,\n         default=1,\n-        help=\"the number of splits into which the (flat) list of direcotry/file paths will be split. This has effect only if `only_return_keys` is `True`.\",\n+        help=\"the number of splits into which the (flat) list of directory/file paths will be split. This has effect only if `only_return_keys` is `True`.\",\n     )\n     args = parser.parse_args()\n "
        },
        {
            "sha": "f41634d612791eaf571a1fe1e1e419e072d9b8e1",
            "filename": "utils/tests_fetcher.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Ftests_fetcher.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Ftests_fetcher.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Ftests_fetcher.py?ref=d84569387fb1f88c86fb8d82a41f20c9e207d09e",
            "patch": "@@ -185,7 +185,7 @@ def keep_doc_examples_only(content: str) -> str:\n def get_all_tests() -> List[str]:\n     \"\"\"\n     Walks the `tests` folder to return a list of files/subfolders. This is used to split the tests to run when using\n-    paralellism. The split is:\n+    parallelism. The split is:\n \n     - folders under `tests`: (`tokenization`, `pipelines`, etc) except the subfolder `models` is excluded.\n     - folders under `tests/models`: `bert`, `gpt2`, etc.\n@@ -854,7 +854,7 @@ def print_tree_deps_of(module, all_edges=None):\n \n def init_test_examples_dependencies() -> Tuple[Dict[str, List[str]], List[str]]:\n     \"\"\"\n-    The test examples do not import from the examples (which are just scripts, not modules) so we need som extra\n+    The test examples do not import from the examples (which are just scripts, not modules) so we need some extra\n     care initializing the dependency map, which is the goal of this function. It initializes the dependency map for\n     example files by linking each example to the example test file for the example framework.\n "
        },
        {
            "sha": "d2023ff4679f7f1e49b2c41d73bd94aa876b9128",
            "filename": "utils/update_metadata.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fupdate_metadata.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d84569387fb1f88c86fb8d82a41f20c9e207d09e/utils%2Fupdate_metadata.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fupdate_metadata.py?ref=d84569387fb1f88c86fb8d82a41f20c9e207d09e",
            "patch": "@@ -132,7 +132,7 @@ def camel_case_split(identifier: str) -> List[str]:\n         identifier (`str`): The camel-cased name to parse.\n \n     Returns:\n-        `List[str]`: The list of words in the identifier (as seprated by capital letters).\n+        `List[str]`: The list of words in the identifier (as separated by capital letters).\n \n     Example:\n \n@@ -215,7 +215,7 @@ def get_frameworks_table() -> pd.DataFrame:\n \n def update_pipeline_and_auto_class_table(table: Dict[str, Tuple[str, str]]) -> Dict[str, Tuple[str, str]]:\n     \"\"\"\n-    Update the table maping models to pipelines and auto classes without removing old keys if they don't exist anymore.\n+    Update the table mapping models to pipelines and auto classes without removing old keys if they don't exist anymore.\n \n     Args:\n         table (`Dict[str, Tuple[str, str]]`):"
        }
    ],
    "stats": {
        "total": 34,
        "additions": 17,
        "deletions": 17
    }
}