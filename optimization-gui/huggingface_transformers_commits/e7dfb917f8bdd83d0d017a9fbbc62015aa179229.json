{
    "author": "ylacombe",
    "message": "[TESTS] ASR pipeline (#33925)\n\n* fix whisper translation\r\n\r\n* correct slow_unfinished_sequence test\r\n\r\n* make fixup",
    "sha": "e7dfb917f8bdd83d0d017a9fbbc62015aa179229",
    "files": [
        {
            "sha": "391005b0213709a9507a398d5a27dd830b7a5e8c",
            "filename": "tests/pipelines/test_pipelines_automatic_speech_recognition.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7dfb917f8bdd83d0d017a9fbbc62015aa179229/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7dfb917f8bdd83d0d017a9fbbc62015aa179229/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py?ref=e7dfb917f8bdd83d0d017a9fbbc62015aa179229",
            "patch": "@@ -1212,7 +1212,7 @@ def test_simple_whisper_translation(self):\n         speech_recognizer_2 = AutomaticSpeechRecognitionPipeline(\n             model=model, tokenizer=tokenizer, feature_extractor=feature_extractor\n         )\n-        output_2 = speech_recognizer_2(ds[0][\"audio\"])\n+        output_2 = speech_recognizer_2(ds[40][\"audio\"])\n         self.assertEqual(output, output_2)\n \n         # either use generate_kwargs or set the model's generation_config\n@@ -1224,7 +1224,7 @@ def test_simple_whisper_translation(self):\n             feature_extractor=feature_extractor,\n             generate_kwargs={\"task\": \"transcribe\", \"language\": \"<|it|>\"},\n         )\n-        output_3 = speech_translator(ds[0][\"audio\"])\n+        output_3 = speech_translator(ds[40][\"audio\"])\n         self.assertEqual(output_3, {\"text\": \" Un uomo ha detto all'universo, Sir, esiste.\"})\n \n     @slow\n@@ -1896,15 +1896,15 @@ def test_slow_unfinished_sequence(self):\n             model=\"vasista22/whisper-hindi-large-v2\",\n             device=torch_device,\n         )\n-        # Original model wasn't trained with timestamps and has incorrect generation config\n-        pipe.model.generation_config = GenerationConfig.from_pretrained(\"openai/whisper-large-v2\")\n \n         # the audio is 4 seconds long\n         audio = hf_hub_download(\"Narsil/asr_dummy\", filename=\"hindi.ogg\", repo_type=\"dataset\")\n \n+        # Original model wasn't trained with timestamps and has incorrect generation config\n         out = pipe(\n             audio,\n             return_timestamps=True,\n+            generate_kwargs={\"generation_config\": GenerationConfig.from_pretrained(\"openai/whisper-large-v2\")},\n         )\n         self.assertEqual(\n             out,"
        }
    ],
    "stats": {
        "total": 8,
        "additions": 4,
        "deletions": 4
    }
}