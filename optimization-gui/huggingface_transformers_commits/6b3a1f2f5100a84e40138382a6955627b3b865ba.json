{
    "author": "bvantuan",
    "message": "Fix missing initializations for models created in 2023 (#39239)\n\n* fix SwiftFormer\n\n* fix Kosmos2\n\n* fix Owlv2\n\n* fix Sam\n\n* fix Vits\n\n* fix Pvt\n\n* fix MobileViTV2\n\n* fix PatchTST\n\n* fix Bros\n\n* fix Informer\n\n* fix BridgeTower\n\n* fix Mra and Yoso\n\n* fix Rwkv\n\n* fix EfficientNet\n\n* fix NllbMoe\n\n* fix Tvp\n\n* fix Clap\n\n* fix Autoformer\n\n* fix SwiftFormer\n\n* fix Mgpstr\n\n* fix Align\n\n* fix VitMatte\n\n* fix SpeechT5\n\n* add conditional check for parameters\n\n* fix SpeechT5\n\n* fix TimmBackbone and Clvp\n\n* fix SwiftFormer\n\n* fix SeamlessM4T and SeamlessM4Tv2\n\n* fix Align\n\n* fix Owlv2 and OwlViT\n\n* add reviewed changes\n\n* add reviewed changes\n\n* fix typo\n\n---------\n\nCo-authored-by: Cyril Vallez <cyril.vallez@huggingface.co>",
    "sha": "6b3a1f2f5100a84e40138382a6955627b3b865ba",
    "files": [
        {
            "sha": "455cab2f7789806b9012ba6bf7421735cd58e287",
            "filename": "src/transformers/models/align/modeling_align.py",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Falign%2Fmodeling_align.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Falign%2Fmodeling_align.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Falign%2Fmodeling_align.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -885,21 +885,22 @@ class AlignPreTrainedModel(PreTrainedModel):\n     base_model_prefix = \"align\"\n     supports_gradient_checkpointing = True\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n+        std = self.config.initializer_range\n         if isinstance(module, (nn.Linear, nn.Conv2d)):\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, AlignModel):\n             nn.init.xavier_uniform_(module.text_projection.weight)\n             module.text_projection.bias.data.zero_()\n-            module.text_projection._is_hf_initialized = True\n+            module.temperature.data.fill_(self.config.temperature_init_value)\n         elif isinstance(module, nn.Embedding):\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n-        if isinstance(module, nn.LayerNorm):\n+        if isinstance(module, (nn.LayerNorm, nn.BatchNorm2d)):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n "
        },
        {
            "sha": "a3a305e1e775adfd40ca448e2a84d37f0b84125c",
            "filename": "src/transformers/models/autoformer/modeling_autoformer.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fautoformer%2Fmodeling_autoformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fautoformer%2Fmodeling_autoformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fautoformer%2Fmodeling_autoformer.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -852,7 +852,7 @@ class AutoformerPreTrainedModel(PreTrainedModel):\n     main_input_name = \"past_values\"\n     supports_gradient_checkpointing = True\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         std = self.config.init_std\n         if isinstance(module, (nn.Linear, nn.Conv1d)):\n             module.weight.data.normal_(mean=0.0, std=std)\n@@ -864,6 +864,9 @@ def _init_weights(self, module):\n             module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n+        elif isinstance(module, nn.LayerNorm):\n+            module.weight.data.fill_(1.0)\n+            module.bias.data.zero_()\n \n     # Copied from transformers.models.bart.modeling_bart.BartPreTrainedModel._update_full_mask\n     def _update_full_mask("
        },
        {
            "sha": "d82e91329974835a1fc2fa8c28fd407ef1479e63",
            "filename": "src/transformers/models/bridgetower/modeling_bridgetower.py",
            "status": "modified",
            "additions": 19,
            "deletions": 19,
            "changes": 38,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fmodeling_bridgetower.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fmodeling_bridgetower.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fmodeling_bridgetower.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -949,30 +949,30 @@ class BridgeTowerPreTrainedModel(PreTrainedModel):\n     _no_split_modules = [\"BridgeTowerSelfAttention\", \"BridgeTowerResidualAttention\"]\n     _skip_keys_device_placement = \"past_key_values\"\n \n-    def _init_weights(self, module):\n-        if isinstance(module, BridgeTowerVisionModel):\n-            proj_std = (module.visual.transformer.hidden_size**-0.5) * (\n-                (2 * module.visual.transformer.num_hidden_layers) ** -0.5\n-            )\n-            attn_std = module.visual.transformer.hidden_size**-0.5\n-            fc_std = (2 * module.visual.transformer.hidden_size) ** -0.5\n-            for block in module.visual.transformer.resblocks:\n-                nn.init.normal_(block.attn.in_proj_weight, std=attn_std * self.config.initializer_factor)\n-                nn.init.normal_(block.attn.out_proj.weight, std=proj_std * self.config.initializer_factor)\n-                nn.init.normal_(block.mlp.c_fc.weight, std=fc_std * self.config.initializer_factor)\n-                nn.init.normal_(block.mlp.c_proj.weight, std=proj_std * self.config.initializer_factor)\n-\n-            nn.init.normal_(module.visual.embeddings.class_embedding, std=attn_std * self.config.initializer_factor)\n-            nn.init.normal_(\n-                module.visual.embeddings.position_embedding.weight, std=attn_std * self.config.initializer_factor\n-            )\n+    def _init_weights(self, module: nn.Module):\n+        std = self.config.initializer_factor\n+        if isinstance(module, BridgeTowerVisionTransformer):\n+            proj_std = (self.config.hidden_size**-0.5) * ((2 * self.config.num_hidden_layers) ** -0.5)\n+            attn_std = self.config.hidden_size**-0.5\n+            fc_std = (2 * self.config.hidden_size) ** -0.5\n+            for block in module.transformer.resblocks:\n+                nn.init.normal_(block.attn.in_proj_weight, std=attn_std * std)\n+                block.attn.in_proj_bias.data.zero_()\n+                nn.init.normal_(block.attn.out_proj.weight, std=proj_std * std)\n+                nn.init.normal_(block.mlp.c_fc.weight, std=fc_std * std)\n+                nn.init.normal_(block.mlp.c_proj.weight, std=proj_std * std)\n+\n+            nn.init.normal_(module.embeddings.class_embedding, std=attn_std * std)\n+            nn.init.normal_(module.embeddings.position_embedding.weight, std=attn_std * std)\n         elif isinstance(module, (nn.Linear, nn.Conv2d, nn.Embedding)):\n-            module.weight.data.normal_(mean=0.0, std=0.05 * self.config.initializer_factor)\n+            module.weight.data.normal_(mean=0.0, std=0.05 * std)\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, BridgeTowerForContrastiveLearning):\n+            module.logit_scale.data.fill_(self.config.logit_scale_init_value)\n \n-        if isinstance(module, nn.Linear) and module.bias is not None:\n+        if isinstance(module, (nn.Linear, BridgeTowerMLMHead)) and module.bias is not None:\n             module.bias.data.zero_()\n \n "
        },
        {
            "sha": "68fa2185ff16037a2e28a32a3ca86970359fb838",
            "filename": "src/transformers/models/bros/modeling_bros.py",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fbros%2Fmodeling_bros.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fbros%2Fmodeling_bros.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbros%2Fmodeling_bros.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -586,21 +586,24 @@ class BrosPreTrainedModel(PreTrainedModel):\n     config: BrosConfig\n     base_model_prefix = \"bros\"\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n+        std = self.config.initializer_range\n         if isinstance(module, nn.Linear):\n             # Slightly different from the TF version which uses truncated_normal for initialization\n             # cf https://github.com/pytorch/pytorch/pull/5617\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, nn.Embedding):\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, BrosRelationExtractor):\n+            nn.init.normal_(module.dummy_node, std=std)\n \n \n @auto_docstring"
        },
        {
            "sha": "87b45900f4eca944d3d387e0da081b095509a2cc",
            "filename": "src/transformers/models/clap/modeling_clap.py",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fclap%2Fmodeling_clap.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fclap%2Fmodeling_clap.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclap%2Fmodeling_clap.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -1404,27 +1404,28 @@ class ClapPreTrainedModel(PreTrainedModel):\n     base_model_prefix = \"clap\"\n     supports_gradient_checkpointing = False\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n         factor = self.config.initializer_factor\n \n         if isinstance(module, ClapTextEmbeddings):\n             module.position_embeddings.weight.data.normal_(mean=0.0, std=factor * 0.02)\n             module.token_type_embeddings.weight.data.normal_(mean=0.0, std=factor * 0.02)\n         elif isinstance(module, ClapModel):\n-            nn.init.normal_(module.logit_scale_a, std=factor * 0.02)\n-            nn.init.normal_(module.logit_scale_t, std=factor * 0.02)\n+            module.logit_scale_a.data.fill_(math.log(self.config.logit_scale_init_value))\n+            module.logit_scale_t.data.fill_(math.log(self.config.logit_scale_init_value))\n         elif isinstance(module, nn.Embedding):\n             module.weight.data.normal_(mean=0.0, std=factor * 0.02)\n-\n-        elif isinstance(module, nn.LayerNorm):\n+        elif isinstance(module, (nn.LayerNorm, nn.BatchNorm2d)):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n         elif isinstance(module, (nn.Conv2d, nn.Linear)):\n             in_proj_std = (self.config.hidden_size**-0.5) * ((2 * self.config.num_hidden_layers) ** -0.5) * factor\n             nn.init.normal_(module.weight, std=in_proj_std)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n+        elif isinstance(module, ClapAudioSelfAttention):\n+            module.relative_position_bias_table.data.zero_()\n \n \n class ClapAudioModel(ClapPreTrainedModel):"
        },
        {
            "sha": "c705997c20e039f370dbee5e845913dde0dc3e08",
            "filename": "src/transformers/models/clvp/modeling_clvp.py",
            "status": "modified",
            "additions": 7,
            "deletions": 3,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fclvp%2Fmodeling_clvp.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fclvp%2Fmodeling_clvp.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclvp%2Fmodeling_clvp.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -788,7 +788,7 @@ class ClvpPreTrainedModel(PreTrainedModel):\n     supports_gradient_checkpointing = True\n     _skip_keys_device_placement = \"past_key_values\"\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n         factor = self.config.initializer_factor\n         if isinstance(module, nn.Embedding):\n@@ -797,8 +797,9 @@ def _init_weights(self, module):\n             module.weight.data.normal_(mean=0.0, std=factor * 0.02)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n+        elif isinstance(module, ClvpRMSNorm):\n+            module.weight.data.fill_(1.0)\n         elif isinstance(module, ClvpEncoderMLP):\n-            factor = self.config.initializer_factor\n             in_proj_std = (module.config.hidden_size**-0.5) * ((2 * module.config.num_hidden_layers) ** -0.5) * factor\n             fc_std = (2 * module.config.hidden_size) ** -0.5 * factor\n             nn.init.normal_(module.fc1.proj.weight if getattr(module.fc1, \"proj\") else module.fc1.weight, std=fc_std)\n@@ -816,7 +817,10 @@ def _init_weights(self, module):\n                     p.data.normal_(\n                         mean=0.0, std=(self.config.initializer_range / math.sqrt(2 * self.config.num_hidden_layers))\n                     )\n-        if isinstance(module, nn.LayerNorm):\n+        elif isinstance(module, ClvpModelForConditionalGeneration):\n+            module.logit_scale.data.fill_(self.config.logit_scale_init_value)\n+\n+        if isinstance(module, (nn.LayerNorm, nn.GroupNorm)):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n "
        },
        {
            "sha": "8f53227f6974042a235e87469115894edf3b4c79",
            "filename": "src/transformers/models/efficientnet/modeling_efficientnet.py",
            "status": "modified",
            "additions": 2,
            "deletions": 5,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fmodeling_efficientnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fmodeling_efficientnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fefficientnet%2Fmodeling_efficientnet.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -437,17 +437,14 @@ class EfficientNetPreTrainedModel(PreTrainedModel):\n     main_input_name = \"pixel_values\"\n     _no_split_modules = []\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n-        if isinstance(module, (nn.Linear, nn.Conv2d)):\n+        if isinstance(module, (nn.Linear, nn.Conv2d, nn.BatchNorm2d)):\n             # Slightly different from the TF version which uses truncated_normal for initialization\n             # cf https://github.com/pytorch/pytorch/pull/5617\n             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n-        elif isinstance(module, nn.LayerNorm):\n-            module.bias.data.zero_()\n-            module.weight.data.fill_(1.0)\n \n \n @auto_docstring"
        },
        {
            "sha": "286c11b5e933c638d2a5292ef1a9c05ecdb60bca",
            "filename": "src/transformers/models/fastspeech2_conformer/modeling_fastspeech2_conformer.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fmodeling_fastspeech2_conformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fmodeling_fastspeech2_conformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fmodeling_fastspeech2_conformer.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -1372,9 +1372,9 @@ def __init__(self, config: FastSpeech2ConformerHifiGanConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights.\"\"\"\n-        if isinstance(module, (nn.Linear, nn.Conv1d)):\n+        if isinstance(module, (nn.Conv1d, nn.ConvTranspose1d)):\n             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n             if module.bias is not None:\n                 module.bias.data.zero_()"
        },
        {
            "sha": "ed4cda28e47da1a97059be7ca97123fe3f329856",
            "filename": "src/transformers/models/informer/modeling_informer.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Finformer%2Fmodeling_informer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Finformer%2Fmodeling_informer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finformer%2Fmodeling_informer.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -256,7 +256,7 @@ class InformerPreTrainedModel(PreTrainedModel):\n     main_input_name = \"past_values\"\n     supports_gradient_checkpointing = True\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         std = self.config.init_std\n         if isinstance(module, (nn.Linear, nn.Conv1d)):\n             module.weight.data.normal_(mean=0.0, std=std)\n@@ -268,6 +268,9 @@ def _init_weights(self, module):\n             module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n+        elif isinstance(module, nn.LayerNorm):\n+            module.weight.data.fill_(1.0)\n+            module.bias.data.zero_()\n \n     # Copied from transformers.models.bart.modeling_bart.BartPreTrainedModel._update_full_mask\n     def _update_full_mask("
        },
        {
            "sha": "0b3ecb59367e87927a48f90804eb8522135b5942",
            "filename": "src/transformers/models/informer/modular_informer.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Finformer%2Fmodular_informer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Finformer%2Fmodular_informer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finformer%2Fmodular_informer.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -97,7 +97,7 @@ class InformerPreTrainedModel(PreTrainedModel):\n     main_input_name = \"past_values\"\n     supports_gradient_checkpointing = True\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         std = self.config.init_std\n         if isinstance(module, (nn.Linear, nn.Conv1d)):\n             module.weight.data.normal_(mean=0.0, std=std)\n@@ -109,6 +109,9 @@ def _init_weights(self, module):\n             module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n+        elif isinstance(module, nn.LayerNorm):\n+            module.weight.data.fill_(1.0)\n+            module.bias.data.zero_()\n \n     # Copied from transformers.models.bart.modeling_bart.BartPreTrainedModel._update_full_mask\n     def _update_full_mask("
        },
        {
            "sha": "a6cf92bfd095bfe137a6aa622c8c8ddd706e3004",
            "filename": "src/transformers/models/kosmos2/modeling_kosmos2.py",
            "status": "modified",
            "additions": 8,
            "deletions": 39,
            "changes": 47,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fmodeling_kosmos2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fmodeling_kosmos2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fmodeling_kosmos2.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -1156,7 +1156,7 @@ class Kosmos2PreTrainedModel(PreTrainedModel):\n     _supports_flash_attn = True\n     _supports_sdpa = True\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(self, Kosmos2VisionModel):\n             factor = self.config.initializer_factor\n@@ -1179,65 +1179,34 @@ def _init_weights(self, module):\n             nn.init.normal_(module.k_proj.weight, std=in_proj_std)\n             nn.init.normal_(module.v_proj.weight, std=in_proj_std)\n             nn.init.normal_(module.out_proj.weight, std=out_proj_std)\n-            if module.q_proj.bias is not None:\n-                module.q_proj.bias.data.zero_()\n-            if module.k_proj.bias is not None:\n-                module.k_proj.bias.data.zero_()\n-            if module.v_proj.bias is not None:\n-                module.v_proj.bias.data.zero_()\n-            if module.out_proj.bias is not None:\n-                module.out_proj.bias.data.zero_()\n         elif isinstance(module, Kosmos2VisionMLP):\n             in_proj_std = (module.config.hidden_size**-0.5) * ((2 * module.config.num_hidden_layers) ** -0.5) * factor\n             fc_std = (2 * module.config.hidden_size) ** -0.5 * factor\n             nn.init.normal_(module.fc1.weight, std=fc_std)\n             nn.init.normal_(module.fc2.weight, std=in_proj_std)\n-            if module.fc1.bias is not None:\n-                module.fc1.bias.data.zero_()\n-            if module.fc2.bias is not None:\n-                module.fc2.bias.data.zero_()\n-        elif isinstance(module, Kosmos2VisionEncoderLayer):\n-            module.layer_norm1.bias.data.zero_()\n-            module.layer_norm1.weight.data.fill_(1.0)\n-            module.layer_norm2.bias.data.zero_()\n-            module.layer_norm2.weight.data.fill_(1.0)\n-        elif isinstance(module, Kosmos2VisionTransformer):\n-            module.pre_layrnorm.bias.data.zero_()\n-            module.pre_layrnorm.weight.data.fill_(1.0)\n-            module.post_layernorm.bias.data.zero_()\n-            module.post_layernorm.weight.data.fill_(1.0)\n         elif isinstance(module, KosmosTextAttention):\n             nn.init.normal_(module.q_proj.weight, std=std)\n             nn.init.normal_(module.k_proj.weight, std=std)\n             nn.init.normal_(module.v_proj.weight, std=std)\n             nn.init.normal_(module.out_proj.weight, std=std)\n-            if module.q_proj.bias is not None:\n-                module.q_proj.bias.data.zero_()\n-            if module.k_proj.bias is not None:\n-                module.k_proj.bias.data.zero_()\n-            if module.v_proj.bias is not None:\n-                module.v_proj.bias.data.zero_()\n-            if module.out_proj.bias is not None:\n-                module.out_proj.bias.data.zero_()\n         elif isinstance(module, Kosmos2TextFFN):\n             nn.init.normal_(module.fc1.weight, std=std)\n             nn.init.normal_(module.fc2.weight, std=std)\n-            if module.fc1.bias is not None:\n-                module.fc1.bias.data.zero_()\n-            if module.fc2.bias is not None:\n-                module.fc2.bias.data.zero_()\n         elif isinstance(module, Kosmos2TextForCausalLM):\n             nn.init.normal_(module.lm_head.weight, std=std)\n-            if module.lm_head.bias is not None:\n-                module.lm_head.bias.data.zero_()\n         elif isinstance(module, Kosmos2ImageToTextProjection):\n             nn.init.normal_(module.dense.weight, std=std)\n-            if module.dense.bias is not None:\n-                module.dense.bias.data.zero_()\n+            nn.init.normal_(module.latent_query)\n         elif isinstance(module, Kosmos2TextTransformer):\n             module.embed_tokens.weight.data.normal_(mean=0.0, std=std)\n             if module.embed_tokens.padding_idx is not None:\n                 module.embed_tokens.weight.data[module.embed_tokens.padding_idx].zero_()\n+        elif isinstance(module, nn.LayerNorm):\n+            module.weight.data.fill_(1.0)\n+            module.bias.data.zero_()\n+\n+        if isinstance(module, nn.Linear) and module.bias is not None:\n+            module.bias.data.zero_()\n \n \n class Kosmos2VisionModel(Kosmos2PreTrainedModel):"
        },
        {
            "sha": "9e6ab26a4b98434758ff96049fba76631edb418b",
            "filename": "src/transformers/models/mgp_str/modeling_mgp_str.py",
            "status": "modified",
            "additions": 11,
            "deletions": 4,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fmgp_str%2Fmodeling_mgp_str.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fmgp_str%2Fmodeling_mgp_str.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmgp_str%2Fmodeling_mgp_str.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -290,13 +290,14 @@ class MgpstrPreTrainedModel(PreTrainedModel):\n     base_model_prefix = \"mgp_str\"\n     _no_split_modules = []\n \n-    def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> None:\n+    def _init_weights(self, module: nn.Module) -> None:\n         \"\"\"Initialize the weights\"\"\"\n+        std = self.config.initializer_range\n         if isinstance(module, MgpstrEmbeddings):\n-            nn.init.trunc_normal_(module.pos_embed, mean=0.0, std=self.config.initializer_range)\n-            nn.init.trunc_normal_(module.cls_token, mean=0.0, std=self.config.initializer_range)\n+            nn.init.trunc_normal_(module.pos_embed, mean=0.0, std=std)\n+            nn.init.trunc_normal_(module.cls_token, mean=0.0, std=std)\n         elif isinstance(module, (nn.Linear, nn.Conv2d)):\n-            module.weight.data = nn.init.trunc_normal_(module.weight.data, mean=0.0, std=self.config.initializer_range)\n+            nn.init.trunc_normal_(module.weight.data, mean=0.0, std=std)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, nn.LayerNorm):\n@@ -312,6 +313,9 @@ def __init__(self, config: MgpstrConfig):\n         self.embeddings = MgpstrEmbeddings(config)\n         self.encoder = MgpstrEncoder(config)\n \n+        # Initialize weights and apply final processing\n+        self.post_init()\n+\n     def get_input_embeddings(self) -> nn.Module:\n         return self.embeddings.proj\n \n@@ -374,6 +378,9 @@ def __init__(self, config: MgpstrConfig) -> None:\n         self.bpe_head = nn.Linear(config.hidden_size, config.num_bpe_labels)\n         self.wp_head = nn.Linear(config.hidden_size, config.num_wordpiece_labels)\n \n+        # Initialize weights and apply final processing\n+        self.post_init()\n+\n     @auto_docstring\n     def forward(\n         self,"
        },
        {
            "sha": "adfa133c510e0c9ea78cdd0336ca428e3856b79a",
            "filename": "src/transformers/models/mobilevit/modeling_mobilevit.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fmodeling_mobilevit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fmodeling_mobilevit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fmodeling_mobilevit.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -629,9 +629,9 @@ class MobileViTPreTrainedModel(PreTrainedModel):\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"MobileViTLayer\"]\n \n-    def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> None:\n+    def _init_weights(self, module: nn.Module) -> None:\n         \"\"\"Initialize the weights\"\"\"\n-        if isinstance(module, (nn.Linear, nn.Conv2d)):\n+        if isinstance(module, (nn.Linear, nn.Conv2d, nn.BatchNorm2d)):\n             # Slightly different from the TF version which uses truncated_normal for initialization\n             # cf https://github.com/pytorch/pytorch/pull/5617\n             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)"
        },
        {
            "sha": "450c871ca9f04b653032aedf98193d154866fb7a",
            "filename": "src/transformers/models/mobilevitv2/modeling_mobilevitv2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fmobilevitv2%2Fmodeling_mobilevitv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fmobilevitv2%2Fmodeling_mobilevitv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilevitv2%2Fmodeling_mobilevitv2.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -569,23 +569,22 @@ def forward(\n \n \n @auto_docstring\n-# Copied from transformers.models.mobilevit.modeling_mobilevit.MobileViTPreTrainedModel with MobileViT->MobileViTV2,mobilevit->mobilevitv2\n class MobileViTV2PreTrainedModel(PreTrainedModel):\n     config: MobileViTV2Config\n     base_model_prefix = \"mobilevitv2\"\n     main_input_name = \"pixel_values\"\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"MobileViTV2Layer\"]\n \n-    def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> None:\n+    def _init_weights(self, module: nn.Module) -> None:\n         \"\"\"Initialize the weights\"\"\"\n-        if isinstance(module, (nn.Linear, nn.Conv2d)):\n+        if isinstance(module, (nn.Linear, nn.Conv2d, nn.BatchNorm2d)):\n             # Slightly different from the TF version which uses truncated_normal for initialization\n             # cf https://github.com/pytorch/pytorch/pull/5617\n             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n-        elif isinstance(module, nn.LayerNorm):\n+        elif isinstance(module, nn.GroupNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n "
        },
        {
            "sha": "3a37712e858073b10f47f1c5bc65f19aca5fef1e",
            "filename": "src/transformers/models/mra/modeling_mra.py",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fmra%2Fmodeling_mra.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fmra%2Fmodeling_mra.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmra%2Fmodeling_mra.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -821,21 +821,24 @@ class MraPreTrainedModel(PreTrainedModel):\n     base_model_prefix = \"mra\"\n     supports_gradient_checkpointing = True\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n+        std = self.config.initializer_range\n         if isinstance(module, nn.Linear):\n             # Slightly different from the TF version which uses truncated_normal for initialization\n             # cf https://github.com/pytorch/pytorch/pull/5617\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, nn.Embedding):\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, MraLMPredictionHead):\n+            module.bias.data.zero_()\n \n \n @auto_docstring"
        },
        {
            "sha": "c8c927ed5803217c0020ee1085b19332fe19063a",
            "filename": "src/transformers/models/nllb_moe/modeling_nllb_moe.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fmodeling_nllb_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fmodeling_nllb_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fmodeling_nllb_moe.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -850,7 +850,7 @@ class NllbMoePreTrainedModel(PreTrainedModel):\n     _supports_sdpa = False\n     _supports_flex_attn = False\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n         std = self.config.init_std\n         if isinstance(module, nn.Linear):\n@@ -861,6 +861,9 @@ def _init_weights(self, module):\n             module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n+        elif isinstance(module, nn.LayerNorm):\n+            module.weight.data.fill_(1.0)\n+            module.bias.data.zero_()\n \n \n class NllbMoeEncoder(NllbMoePreTrainedModel):"
        },
        {
            "sha": "966be71d700b1e0d5f17279b54d0aee71f6ac16e",
            "filename": "src/transformers/models/omdet_turbo/modeling_omdet_turbo.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fomdet_turbo%2Fmodeling_omdet_turbo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fomdet_turbo%2Fmodeling_omdet_turbo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fomdet_turbo%2Fmodeling_omdet_turbo.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -1012,11 +1012,11 @@ def linear_init_(module_to_init):\n                 nn.init.xavier_uniform_(layer[0].weight)\n         elif isinstance(module, OmDetTurboLanguageBackbone):\n             nn.init.normal_(module.text_projection, std=self.config.text_projection_in_dim**-0.5)\n-        elif isinstance(module, (nn.Linear, nn.Conv2d, nn.BatchNorm2d)):\n+        elif isinstance(module, (nn.Linear, nn.Conv2d)):\n             module.weight.data.normal_(mean=0.0, std=self.config.init_std)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n-        elif isinstance(module, nn.LayerNorm):\n+        elif isinstance(module, (nn.LayerNorm, nn.BatchNorm2d)):\n             module.weight.data.fill_(1.0)\n             module.bias.data.zero_()\n "
        },
        {
            "sha": "e80292d98ce4437600d957b5ec792ceb2eaeb2a3",
            "filename": "src/transformers/models/owlv2/modeling_owlv2.py",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fowlv2%2Fmodeling_owlv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fowlv2%2Fmodeling_owlv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fowlv2%2Fmodeling_owlv2.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -560,45 +560,45 @@ class Owlv2PreTrainedModel(PreTrainedModel):\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"Owlv2EncoderLayer\"]\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n         factor = self.config.initializer_factor\n         if isinstance(module, Owlv2TextEmbeddings):\n             module.token_embedding.weight.data.normal_(mean=0.0, std=factor * 0.02)\n             module.position_embedding.weight.data.normal_(mean=0.0, std=factor * 0.02)\n         elif isinstance(module, Owlv2VisionEmbeddings):\n-            factor = self.config.initializer_factor\n             nn.init.normal_(module.class_embedding, mean=0.0, std=module.embed_dim**-0.5 * factor)\n             nn.init.normal_(module.patch_embedding.weight, std=module.config.initializer_range * factor)\n             nn.init.normal_(module.position_embedding.weight, std=module.config.initializer_range * factor)\n         elif isinstance(module, Owlv2Attention):\n-            factor = self.config.initializer_factor\n             in_proj_std = (module.embed_dim**-0.5) * ((2 * module.config.num_hidden_layers) ** -0.5) * factor\n             out_proj_std = (module.embed_dim**-0.5) * factor\n             nn.init.normal_(module.q_proj.weight, std=in_proj_std)\n             nn.init.normal_(module.k_proj.weight, std=in_proj_std)\n             nn.init.normal_(module.v_proj.weight, std=in_proj_std)\n             nn.init.normal_(module.out_proj.weight, std=out_proj_std)\n         elif isinstance(module, Owlv2MLP):\n-            factor = self.config.initializer_factor\n             in_proj_std = (module.config.hidden_size**-0.5) * ((2 * module.config.num_hidden_layers) ** -0.5) * factor\n             fc_std = (2 * module.config.hidden_size) ** -0.5 * factor\n             nn.init.normal_(module.fc1.weight, std=fc_std)\n             nn.init.normal_(module.fc2.weight, std=in_proj_std)\n         elif isinstance(module, Owlv2Model):\n             nn.init.normal_(\n                 module.text_projection.weight,\n-                std=module.text_embed_dim**-0.5 * self.config.initializer_factor,\n+                std=module.text_embed_dim**-0.5 * factor,\n             )\n             nn.init.normal_(\n                 module.visual_projection.weight,\n-                std=module.vision_embed_dim**-0.5 * self.config.initializer_factor,\n+                std=module.vision_embed_dim**-0.5 * factor,\n             )\n+            module.logit_scale.data.fill_(self.config.logit_scale_init_value)\n         if isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n-        if isinstance(module, nn.Linear) and module.bias is not None:\n-            module.bias.data.zero_()\n+        if isinstance(module, nn.Linear):\n+            module.weight.data.normal_(mean=0.0, std=factor)\n+            if module.bias is not None:\n+                module.bias.data.zero_()\n \n \n # Copied from transformers.models.owlvit.modeling_owlvit.OwlViTEncoder with OwlViT->Owlv2\n@@ -1225,6 +1225,9 @@ def __init__(self, config: Owlv2Config):\n         self.num_patches_width = self.config.vision_config.image_size // self.config.vision_config.patch_size\n         self.box_bias = self.compute_box_bias(self.num_patches_height, self.num_patches_width)\n \n+        # Initialize weights and apply final processing\n+        self.post_init()\n+\n     @staticmethod\n     # Copied from transformers.models.owlvit.modeling_owlvit.OwlViTForObjectDetection.normalize_grid_corner_coordinates\n     def normalize_grid_corner_coordinates(num_patches_height: int, num_patches_width: int) -> torch.Tensor:"
        },
        {
            "sha": "482be48ec1d4c14dd17fd96889e3cfef10901b13",
            "filename": "src/transformers/models/owlvit/modeling_owlvit.py",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fowlvit%2Fmodeling_owlvit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fowlvit%2Fmodeling_owlvit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fowlvit%2Fmodeling_owlvit.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -547,45 +547,45 @@ class OwlViTPreTrainedModel(PreTrainedModel):\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"OwlViTEncoderLayer\"]\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n         factor = self.config.initializer_factor\n         if isinstance(module, OwlViTTextEmbeddings):\n             module.token_embedding.weight.data.normal_(mean=0.0, std=factor * 0.02)\n             module.position_embedding.weight.data.normal_(mean=0.0, std=factor * 0.02)\n         elif isinstance(module, OwlViTVisionEmbeddings):\n-            factor = self.config.initializer_factor\n             nn.init.normal_(module.class_embedding, mean=0.0, std=module.embed_dim**-0.5 * factor)\n             nn.init.normal_(module.patch_embedding.weight, std=module.config.initializer_range * factor)\n             nn.init.normal_(module.position_embedding.weight, std=module.config.initializer_range * factor)\n         elif isinstance(module, OwlViTAttention):\n-            factor = self.config.initializer_factor\n             in_proj_std = (module.embed_dim**-0.5) * ((2 * module.config.num_hidden_layers) ** -0.5) * factor\n             out_proj_std = (module.embed_dim**-0.5) * factor\n             nn.init.normal_(module.q_proj.weight, std=in_proj_std)\n             nn.init.normal_(module.k_proj.weight, std=in_proj_std)\n             nn.init.normal_(module.v_proj.weight, std=in_proj_std)\n             nn.init.normal_(module.out_proj.weight, std=out_proj_std)\n         elif isinstance(module, OwlViTMLP):\n-            factor = self.config.initializer_factor\n             in_proj_std = (module.config.hidden_size**-0.5) * ((2 * module.config.num_hidden_layers) ** -0.5) * factor\n             fc_std = (2 * module.config.hidden_size) ** -0.5 * factor\n             nn.init.normal_(module.fc1.weight, std=fc_std)\n             nn.init.normal_(module.fc2.weight, std=in_proj_std)\n         elif isinstance(module, OwlViTModel):\n             nn.init.normal_(\n                 module.text_projection.weight,\n-                std=module.text_embed_dim**-0.5 * self.config.initializer_factor,\n+                std=module.text_embed_dim**-0.5 * factor,\n             )\n             nn.init.normal_(\n                 module.visual_projection.weight,\n-                std=module.vision_embed_dim**-0.5 * self.config.initializer_factor,\n+                std=module.vision_embed_dim**-0.5 * factor,\n             )\n+            module.logit_scale.data.fill_(self.config.logit_scale_init_value)\n         if isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n-        if isinstance(module, nn.Linear) and module.bias is not None:\n-            module.bias.data.zero_()\n+        if isinstance(module, nn.Linear):\n+            module.weight.data.normal_(mean=0.0, std=factor)\n+            if module.bias is not None:\n+                module.bias.data.zero_()\n \n \n class OwlViTEncoder(nn.Module):"
        },
        {
            "sha": "3f4b0c95e4c906ae3d047888e3eb641092855e3c",
            "filename": "src/transformers/models/patchtst/modeling_patchtst.py",
            "status": "modified",
            "additions": 8,
            "deletions": 4,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fpatchtst%2Fmodeling_patchtst.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fpatchtst%2Fmodeling_patchtst.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpatchtst%2Fmodeling_patchtst.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -558,24 +558,28 @@ class PatchTSTPreTrainedModel(PreTrainedModel):\n     main_input_name = \"past_values\"\n     supports_gradient_checkpointing = False\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"\n         Initialize weights\n         \"\"\"\n         if isinstance(module, PatchTSTPositionalEncoding):\n+            # get the number of patches\n+            num_patches = (\n+                max(self.config.context_length, self.config.patch_length) - self.config.patch_length\n+            ) // self.config.patch_stride + 1\n             # initialize cls_token\n             if self.config.use_cls_token:\n                 nn.init.normal_(module.cls_token, std=0.02)\n+                num_patches += 1\n             # initialize positional encoding\n-            if self.config.positional_encoding_type == \"random\":\n-                nn.init.normal_(module.position_enc, mean=0.0, std=0.1)\n+            module.position_enc = module._init_pe(self.config, num_patches)\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n         elif isinstance(module, PatchTSTBatchNorm):\n             module.batchnorm.bias.data.zero_()\n             module.batchnorm.weight.data.fill_(1.0)\n-        elif isinstance(module, (nn.Linear, nn.Conv1d)):\n+        elif isinstance(module, nn.Linear):\n             module.weight.data.normal_(mean=0.0, std=self.config.init_std)\n             if module.bias is not None:\n                 module.bias.data.zero_()"
        },
        {
            "sha": "9e2c5a69d8defb37cf1f5ac368d1a3be90869ad5",
            "filename": "src/transformers/models/pvt/modeling_pvt.py",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fpvt%2Fmodeling_pvt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fpvt%2Fmodeling_pvt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpvt%2Fmodeling_pvt.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -447,12 +447,13 @@ class PvtPreTrainedModel(PreTrainedModel):\n     main_input_name = \"pixel_values\"\n     _no_split_modules = []\n \n-    def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> None:\n+    def _init_weights(self, module: nn.Module) -> None:\n         \"\"\"Initialize the weights\"\"\"\n-        if isinstance(module, nn.Linear):\n+        std = self.config.initializer_range\n+        if isinstance(module, (nn.Linear, nn.Conv2d)):\n             # Upcast the input in `fp32` and cast it back to desired `dtype` to avoid\n             # `trunc_normal_cpu` not implemented in `half` issues\n-            module.weight.data = nn.init.trunc_normal_(module.weight.data, mean=0.0, std=self.config.initializer_range)\n+            nn.init.trunc_normal_(module.weight.data, mean=0.0, std=std)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, nn.LayerNorm):\n@@ -462,13 +463,13 @@ def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> No\n             module.position_embeddings.data = nn.init.trunc_normal_(\n                 module.position_embeddings.data,\n                 mean=0.0,\n-                std=self.config.initializer_range,\n+                std=std,\n             )\n             if module.cls_token is not None:\n                 module.cls_token.data = nn.init.trunc_normal_(\n                     module.cls_token.data,\n                     mean=0.0,\n-                    std=self.config.initializer_range,\n+                    std=std,\n                 )\n \n "
        },
        {
            "sha": "0b16af278946e3337168591566add5d4ae1f6e9f",
            "filename": "src/transformers/models/rwkv/modeling_rwkv.py",
            "status": "modified",
            "additions": 28,
            "deletions": 10,
            "changes": 38,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Frwkv%2Fmodeling_rwkv.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Frwkv%2Fmodeling_rwkv.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frwkv%2Fmodeling_rwkv.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -388,7 +388,7 @@ class RwkvPreTrainedModel(PreTrainedModel):\n     supports_gradient_checkpointing = True\n     _is_stateful = True\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights.\"\"\"\n         if isinstance(module, RwkvSelfAttention):\n             layer_id = module.layer_id\n@@ -420,13 +420,12 @@ def _init_weights(self, module):\n                 * 0.5\n             )\n \n-            with torch.no_grad():\n-                module.time_decay.data = decay_speed\n-                module.time_first.data = torch.ones_like(module.time_first * math.log(0.3) + zigzag)\n+            module.time_decay.data = decay_speed\n+            module.time_first.data = torch.ones_like(module.time_first * math.log(0.3) + zigzag)\n \n-                module.time_mix_key.data = torch.pow(time_weight, ratio_1_to_almost0)\n-                module.time_mix_value.data = torch.pow(time_weight, ratio_1_to_almost0) + 0.3 * ratio_0_to_1\n-                module.time_mix_receptance.data = torch.pow(time_weight, 0.5 * ratio_1_to_almost0)\n+            module.time_mix_key.data = torch.pow(time_weight, ratio_1_to_almost0)\n+            module.time_mix_value.data = torch.pow(time_weight, ratio_1_to_almost0) + 0.3 * ratio_0_to_1\n+            module.time_mix_receptance.data = torch.pow(time_weight, 0.5 * ratio_1_to_almost0)\n         elif isinstance(module, RwkvFeedForward):\n             layer_id = module.layer_id\n             num_hidden_layers = module.config.num_hidden_layers\n@@ -441,9 +440,28 @@ def _init_weights(self, module):\n             )\n             time_weight = time_weight[None, None, :]\n \n-            with torch.no_grad():\n-                module.time_mix_key.data = torch.pow(time_weight, ratio_1_to_almost0)\n-                module.time_mix_receptance.data = torch.pow(time_weight, ratio_1_to_almost0)\n+            module.time_mix_key.data = torch.pow(time_weight, ratio_1_to_almost0)\n+            module.time_mix_receptance.data = torch.pow(time_weight, ratio_1_to_almost0)\n+        elif isinstance(module, nn.Linear):\n+            shape = module.weight.data.shape\n+            gain = 1.0\n+            scale = 1.0  # extra scale for gain\n+            if module.bias is not None:\n+                module.bias.data.zero_()\n+            if shape[0] > shape[1]:\n+                gain = math.sqrt(shape[0] / shape[1])\n+            if shape[0] == self.config.vocab_size and shape[1] == self.config.hidden_size:  # final projection?\n+                scale = 0.5\n+\n+            gain *= scale\n+            nn.init.orthogonal_(module.weight, gain=gain)\n+        elif isinstance(module, nn.Embedding):\n+            shape = module.weight.data.shape\n+            gain = 1e-4 * math.sqrt(max(shape[0], shape[1]))\n+            nn.init.orthogonal_(module.weight, gain=gain)\n+        elif isinstance(module, nn.LayerNorm):\n+            module.weight.data.fill_(1.0)\n+            module.bias.data.zero_()\n \n \n @dataclass"
        },
        {
            "sha": "474e30c584235263b21eddea48a00f400b60650e",
            "filename": "src/transformers/models/sam/modeling_sam.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -1016,7 +1016,7 @@ class SamPreTrainedModel(PreTrainedModel):\n     supports_gradient_checkpointing = True\n     _supports_sdpa = True\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         std = self.config.initializer_range\n         if isinstance(module, (nn.Linear, nn.Conv2d, nn.ConvTranspose2d)):\n             module.weight.data.normal_(mean=0.0, std=std)\n@@ -1033,6 +1033,9 @@ def _init_weights(self, module):\n             if module.use_rel_pos:\n                 module.rel_pos_h.data.zero_()\n                 module.rel_pos_w.data.zero_()\n+        elif isinstance(module, SamVisionEncoder):\n+            if self.config.use_abs_pos:\n+                module.pos_embed.data.zero_()\n \n \n class SamVisionEncoder(SamPreTrainedModel):"
        },
        {
            "sha": "fac2b15500c69a271689c08399ce662513c5f30e",
            "filename": "src/transformers/models/sam_hq/modeling_sam_hq.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodeling_sam_hq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodeling_sam_hq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodeling_sam_hq.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -499,8 +499,8 @@ def _init_weights(self, module):\n             if module.use_rel_pos:\n                 module.rel_pos_h.data.zero_()\n                 module.rel_pos_w.data.zero_()\n-        if isinstance(module, SamHQVisionEncoder):\n-            if module.pos_embed is not None:\n+        elif isinstance(module, SamHQVisionEncoder):\n+            if self.config.use_abs_pos:\n                 module.pos_embed.data.zero_()\n \n "
        },
        {
            "sha": "2a241fb2c05da43f36f58e9be209600c9e18d7c7",
            "filename": "src/transformers/models/sam_hq/modular_sam_hq.py",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodular_sam_hq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodular_sam_hq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodular_sam_hq.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -188,9 +188,6 @@ class SamHQVisionLayer(SamVisionLayer):\n class SamHQPreTrainedModel(SamPreTrainedModel):\n     def _init_weights(self, module):\n         super()._init_weights(module)\n-        if isinstance(module, SamHQVisionEncoder):\n-            if module.pos_embed is not None:\n-                module.pos_embed.data.zero_()\n \n \n class SamHQVisionEncoder(SamVisionEncoder, SamHQPreTrainedModel):"
        },
        {
            "sha": "6c1b827d8f0f8812cce38c6bf7eb51a1a6d8a580",
            "filename": "src/transformers/models/seamless_m4t/modeling_seamless_m4t.py",
            "status": "modified",
            "additions": 10,
            "deletions": 6,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fseamless_m4t%2Fmodeling_seamless_m4t.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fseamless_m4t%2Fmodeling_seamless_m4t.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fseamless_m4t%2Fmodeling_seamless_m4t.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -1343,7 +1343,7 @@ class SeamlessM4TPreTrainedModel(PreTrainedModel):\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"SeamlessM4TEncoderLayer\", \"SeamlessM4TDecoderLayer\", \"SeamlessM4TConformerEncoderLayer\"]\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n         std = self.config.initializer_range\n         if isinstance(module, nn.Linear):\n@@ -1370,7 +1370,7 @@ def _init_weights(self, module):\n             k = math.sqrt(1 / module.projection.in_features)\n             nn.init.uniform_(module.projection.weight, a=-k, b=k)\n             nn.init.uniform_(module.projection.bias, a=-k, b=k)\n-        elif isinstance(module, (nn.LayerNorm, nn.GroupNorm)):\n+        elif isinstance(module, (nn.LayerNorm, nn.BatchNorm1d)):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n         elif isinstance(module, nn.Conv1d):\n@@ -2426,16 +2426,20 @@ def forward(\n \n         return hidden_states, lengths\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights.\"\"\"\n+        std = self.config.initializer_range\n         if isinstance(module, (nn.Linear, nn.Conv1d, nn.ConvTranspose1d)):\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, nn.Embedding):\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n+        elif isinstance(module, nn.LayerNorm):\n+            module.weight.data.fill_(1.0)\n+            module.bias.data.zero_()\n \n     def apply_weight_norm(self):\n         weight_norm = nn.utils.weight_norm\n@@ -2730,7 +2734,7 @@ def generate(\n     \"\"\"\n )\n class SeamlessM4TForSpeechToText(SeamlessM4TPreTrainedModel, GenerationMixin):\n-    _keys_to_ignore_on_load_missing = [\"text_decoder\", \"t2u_model\", \"vocoder\"]\n+    _keys_to_ignore_on_load_missing = [\"text_encoder\", \"t2u_model\", \"vocoder\"]\n     main_input_name = \"input_features\"\n \n     _tied_weights_keys = ["
        },
        {
            "sha": "38b736d23ebb789c8b3231aa56c9efa271565159",
            "filename": "src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py",
            "status": "modified",
            "additions": 13,
            "deletions": 6,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fseamless_m4t_v2%2Fmodeling_seamless_m4t_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fseamless_m4t_v2%2Fmodeling_seamless_m4t_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fseamless_m4t_v2%2Fmodeling_seamless_m4t_v2.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -1260,7 +1260,7 @@ class SeamlessM4Tv2PreTrainedModel(PreTrainedModel):\n         \"SeamlessM4Tv2TextToUnitDecoderLayer\",\n     ]\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n         std = self.config.initializer_range\n         if isinstance(module, nn.Linear):\n@@ -1280,7 +1280,10 @@ def _init_weights(self, module):\n             k = math.sqrt(1 / module.projection.in_features)\n             nn.init.uniform_(module.projection.weight, a=-k, b=k)\n             nn.init.uniform_(module.projection.bias, a=-k, b=k)\n-        elif isinstance(module, (nn.LayerNorm, nn.GroupNorm)):\n+        elif isinstance(module, SeamlessM4Tv2TextToUnitDecoder):\n+            module.pos_emb_alpha_char.data.fill_(1)\n+            module.pos_emb_alpha.data.fill_(1)\n+        elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n         elif isinstance(module, (nn.Conv1d, nn.ConvTranspose1d)):\n@@ -2636,16 +2639,20 @@ def forward(\n         return hidden_states, lengths\n \n     # Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TCodeHifiGan._init_weights\n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights.\"\"\"\n+        std = self.config.initializer_range\n         if isinstance(module, (nn.Linear, nn.Conv1d, nn.ConvTranspose1d)):\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, nn.Embedding):\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n+        elif isinstance(module, nn.LayerNorm):\n+            module.weight.data.fill_(1.0)\n+            module.bias.data.zero_()\n \n     # Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TCodeHifiGan.apply_weight_norm\n     def apply_weight_norm(self):\n@@ -2943,7 +2950,7 @@ def generate(\n     \"\"\"\n )\n class SeamlessM4Tv2ForSpeechToText(SeamlessM4Tv2PreTrainedModel, GenerationMixin):\n-    _keys_to_ignore_on_load_missing = [\"text_decoder\", \"t2u_model\", \"vocoder\"]\n+    _keys_to_ignore_on_load_missing = [\"text_encoder\", \"t2u_model\", \"vocoder\"]\n     main_input_name = \"input_features\"\n \n     _tied_weights_keys = ["
        },
        {
            "sha": "4d6e5da03edf1cb59e930961b240ee5f99e48488",
            "filename": "src/transformers/models/speecht5/modeling_speecht5.py",
            "status": "modified",
            "additions": 13,
            "deletions": 7,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fmodeling_speecht5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fmodeling_speecht5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fmodeling_speecht5.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -414,7 +414,7 @@ def __init__(self, dropout, dim, max_len=5000):\n         self.register_buffer(\"pe\", pe, persistent=False)\n         self.dropout = nn.Dropout(p=dropout)\n         self.dim = dim\n-        self.alpha = torch.nn.Parameter(torch.tensor(1.0))\n+        self.alpha = nn.Parameter(torch.tensor(1.0))\n \n     def forward(self, emb):\n         emb = emb + self.alpha * self.pe[:, : emb.size(1)]\n@@ -1208,24 +1208,27 @@ class SpeechT5PreTrainedModel(PreTrainedModel):\n     main_input_name = \"input_values\"\n     supports_gradient_checkpointing = True\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n+        std = self.config.initializer_range\n         if isinstance(module, SpeechT5PositionalConvEmbedding):\n             nn.init.normal_(\n                 module.conv.weight,\n                 mean=0,\n                 std=2 * math.sqrt(1 / (module.conv.kernel_size[0] * module.conv.in_channels)),\n             )\n             nn.init.constant_(module.conv.bias, 0)\n+        elif isinstance(module, SpeechT5ScaledPositionalEncoding):\n+            module.alpha.data.fill_(1.0)\n         elif isinstance(module, SpeechT5FeatureProjection):\n             k = math.sqrt(1 / module.projection.in_features)\n             nn.init.uniform_(module.projection.weight, a=-k, b=k)\n             nn.init.uniform_(module.projection.bias, a=-k, b=k)\n         elif isinstance(module, nn.Linear):\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n-        elif isinstance(module, (nn.LayerNorm, nn.GroupNorm)):\n+        elif isinstance(module, (nn.LayerNorm, nn.GroupNorm, nn.BatchNorm1d)):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n         elif isinstance(module, nn.Conv1d):\n@@ -1234,10 +1237,13 @@ def _init_weights(self, module):\n                 k = math.sqrt(module.groups / (module.in_channels * module.kernel_size[0]))\n                 nn.init.uniform_(module.bias, a=-k, b=k)\n         elif isinstance(module, nn.Embedding):\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n \n+        if hasattr(module, \"masked_spec_embed\"):\n+            nn.init.uniform_(module.masked_spec_embed)\n+\n \n class SpeechT5Encoder(SpeechT5PreTrainedModel):\n     \"\"\"\n@@ -3164,9 +3170,9 @@ def __init__(self, config: SpeechT5HifiGanConfig):\n         # Initialize weights and apply final processing\n         self.post_init()\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights.\"\"\"\n-        if isinstance(module, (nn.Linear, nn.Conv1d)):\n+        if isinstance(module, (nn.Conv1d, nn.ConvTranspose1d)):\n             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n             if module.bias is not None:\n                 module.bias.data.zero_()"
        },
        {
            "sha": "4b6fac00a0240fecf59c10f0175f2255552079d3",
            "filename": "src/transformers/models/swiftformer/modeling_swiftformer.py",
            "status": "modified",
            "additions": 10,
            "deletions": 2,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fswiftformer%2Fmodeling_swiftformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fswiftformer%2Fmodeling_swiftformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fswiftformer%2Fmodeling_swiftformer.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -394,15 +394,23 @@ class SwiftFormerPreTrainedModel(PreTrainedModel):\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"SwiftFormerEncoderBlock\"]\n \n-    def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> None:\n+    def _init_weights(self, module: nn.Module) -> None:\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(module, (nn.Conv2d, nn.Linear)):\n             nn.init.trunc_normal_(module.weight, std=0.02)\n             if module.bias is not None:\n                 nn.init.constant_(module.bias, 0)\n-        elif isinstance(module, (nn.LayerNorm)):\n+        elif isinstance(module, (nn.LayerNorm, nn.BatchNorm2d)):\n             nn.init.constant_(module.bias, 0)\n             nn.init.constant_(module.weight, 1.0)\n+        elif isinstance(module, (SwiftFormerConvEncoder, SwiftFormerLocalRepresentation)):\n+            module.layer_scale.data.fill_(1.0)\n+        elif isinstance(module, SwiftFormerEncoderBlock):\n+            if self.config.use_layer_scale:\n+                module.layer_scale_1.data.fill_(self.config.layer_scale_init_value)\n+                module.layer_scale_2.data.fill_(self.config.layer_scale_init_value)\n+        elif isinstance(module, SwiftFormerEfficientAdditiveAttention):\n+            nn.init.normal_(module.w_g)\n \n \n @auto_docstring"
        },
        {
            "sha": "77d74bffe0ee48955deefdfdb36c06cd976373ac",
            "filename": "src/transformers/models/tvp/modeling_tvp.py",
            "status": "modified",
            "additions": 15,
            "deletions": 6,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Ftvp%2Fmodeling_tvp.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Ftvp%2Fmodeling_tvp.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftvp%2Fmodeling_tvp.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -555,7 +555,7 @@ class TvpPreTrainedModel(PreTrainedModel):\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(module, (nn.Linear, nn.Embedding)):\n             # Slightly different from the TF version which uses truncated_normal for initialization\n@@ -564,14 +564,23 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n-\n-        if isinstance(module, nn.Linear) and module.bias is not None:\n-            module.bias.data.zero_()\n-\n-        if isinstance(module, nn.Conv2d):\n+        elif isinstance(module, nn.Conv2d):\n             nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n             if module.bias is not None:\n                 nn.init.constant_(module.bias, 0)\n+        elif isinstance(module, TvpModel):\n+            nn.init.normal_(module.text_prompt)\n+\n+        if isinstance(module, nn.Linear) and module.bias is not None:\n+            module.bias.data.zero_()\n+        if hasattr(module, \"pad_up\"):\n+            nn.init.normal_(module.pad_up)\n+        if hasattr(module, \"pad_down\"):\n+            nn.init.normal_(module.pad_down)\n+        if hasattr(module, \"pad_left\"):\n+            nn.init.normal_(module.pad_left)\n+        if hasattr(module, \"pad_right\"):\n+            nn.init.normal_(module.pad_right)\n \n \n class TvpFrameDownPadPrompter(nn.Module):"
        },
        {
            "sha": "50cec9c153d31b0c4ad3cbce45646896e5ab17ac",
            "filename": "src/transformers/models/vitmatte/modeling_vitmatte.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fvitmatte%2Fmodeling_vitmatte.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fvitmatte%2Fmodeling_vitmatte.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvitmatte%2Fmodeling_vitmatte.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -57,8 +57,8 @@ class VitMattePreTrainedModel(PreTrainedModel):\n     supports_gradient_checkpointing = True\n     _no_split_modules = []\n \n-    def _init_weights(self, module):\n-        if isinstance(module, nn.Conv2d):\n+    def _init_weights(self, module: nn.Module):\n+        if isinstance(module, (nn.Conv2d, nn.BatchNorm2d)):\n             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n             if module.bias is not None:\n                 module.bias.data.zero_()"
        },
        {
            "sha": "6accac596a8815fcfd0bc0ffde793ac6c7b5b5f4",
            "filename": "src/transformers/models/vits/modeling_vits.py",
            "status": "modified",
            "additions": 13,
            "deletions": 4,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fvits%2Fmodeling_vits.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fvits%2Fmodeling_vits.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvits%2Fmodeling_vits.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -1218,24 +1218,33 @@ class VitsPreTrainedModel(PreTrainedModel):\n     main_input_name = \"input_ids\"\n     supports_gradient_checkpointing = True\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n+        std = self.config.initializer_range\n         if isinstance(module, nn.Linear):\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n-        elif isinstance(module, nn.Conv1d):\n+        elif isinstance(module, (nn.Conv1d, nn.ConvTranspose1d)):\n             nn.init.kaiming_normal_(module.weight)\n             if module.bias is not None:\n                 k = math.sqrt(module.groups / (module.in_channels * module.kernel_size[0]))\n                 nn.init.uniform_(module.bias, a=-k, b=k)\n         elif isinstance(module, nn.Embedding):\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n+        elif isinstance(module, VitsAttention):\n+            if self.config.window_size:\n+                head_dim = self.config.hidden_size // self.config.num_attention_heads\n+                nn.init.normal_(module.emb_rel_k, std=head_dim**-0.5)\n+                nn.init.normal_(module.emb_rel_v, std=head_dim**-0.5)\n+        elif isinstance(module, VitsElementwiseAffine):\n+            module.translate.data.zero_()\n+            module.log_scale.data.zero_()\n \n \n @auto_docstring("
        },
        {
            "sha": "221ebaa637feec1e4428085ca11fa204c722c7f6",
            "filename": "src/transformers/models/yoso/modeling_yoso.py",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fyoso%2Fmodeling_yoso.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/src%2Ftransformers%2Fmodels%2Fyoso%2Fmodeling_yoso.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fyoso%2Fmodeling_yoso.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -643,21 +643,24 @@ class YosoPreTrainedModel(PreTrainedModel):\n     base_model_prefix = \"yoso\"\n     supports_gradient_checkpointing = True\n \n-    def _init_weights(self, module):\n+    def _init_weights(self, module: nn.Module):\n         \"\"\"Initialize the weights\"\"\"\n+        std = self.config.initializer_range\n         if isinstance(module, nn.Linear):\n             # Slightly different from the TF version which uses truncated_normal for initialization\n             # cf https://github.com/pytorch/pytorch/pull/5617\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, nn.Embedding):\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, YosoLMPredictionHead):\n+            module.bias.data.zero_()\n \n \n @auto_docstring"
        },
        {
            "sha": "24a28e80bded307b28adb82f9fc66ee987912efc",
            "filename": "tests/models/clap/test_modeling_clap.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/tests%2Fmodels%2Fclap%2Ftest_modeling_clap.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/tests%2Fmodels%2Fclap%2Ftest_modeling_clap.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fclap%2Ftest_modeling_clap.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -536,7 +536,7 @@ def test_initialization(self):\n             for name, param in model.named_parameters():\n                 if param.requires_grad:\n                     # check if `logit_scale` is initialized as per the original implementation\n-                    if name == \"logit_scale\":\n+                    if \"logit_scale\" in name:\n                         self.assertAlmostEqual(\n                             param.data.item(),\n                             np.log(1 / 0.07),"
        },
        {
            "sha": "5b5736f83d76e978f176bd9e4f06f93ffc9f735d",
            "filename": "tests/models/swiftformer/test_modeling_swiftformer.py",
            "status": "modified",
            "additions": 2,
            "deletions": 13,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/tests%2Fmodels%2Fswiftformer%2Ftest_modeling_swiftformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/tests%2Fmodels%2Fswiftformer%2Ftest_modeling_swiftformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fswiftformer%2Ftest_modeling_swiftformer.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -13,10 +13,9 @@\n # limitations under the License.\n \"\"\"Testing suite for the PyTorch SwiftFormer model.\"\"\"\n \n-import copy\n import unittest\n \n-from transformers import PretrainedConfig, SwiftFormerConfig\n+from transformers import SwiftFormerConfig\n from transformers.testing_utils import (\n     require_torch,\n     require_vision,\n@@ -26,7 +25,7 @@\n from transformers.utils import cached_property, is_torch_available, is_vision_available\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -234,16 +233,6 @@ def check_hidden_states_output(inputs_dict, config, model_class):\n             check_hidden_states_output(inputs_dict, config, model_class)\n \n     def test_initialization(self):\n-        def _config_zero_init(config):\n-            configs_no_init = copy.deepcopy(config)\n-            for key in configs_no_init.__dict__.keys():\n-                if \"_range\" in key or \"_std\" in key or \"initializer_factor\" in key or \"layer_scale\" in key:\n-                    setattr(configs_no_init, key, 1e-10)\n-                if isinstance(getattr(configs_no_init, key, None), PretrainedConfig):\n-                    no_init_subconfig = _config_zero_init(getattr(configs_no_init, key))\n-                    setattr(configs_no_init, key, no_init_subconfig)\n-            return configs_no_init\n-\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n \n         configs_no_init = _config_zero_init(config)"
        },
        {
            "sha": "306b9d2b06a31e2e4f737f3d93e355a170b2273b",
            "filename": "tests/models/timm_backbone/test_modeling_timm_backbone.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/tests%2Fmodels%2Ftimm_backbone%2Ftest_modeling_timm_backbone.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/tests%2Fmodels%2Ftimm_backbone%2Ftest_modeling_timm_backbone.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ftimm_backbone%2Ftest_modeling_timm_backbone.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -136,6 +136,10 @@ def test_feed_forward_chunking(self):\n     def test_hidden_states_output(self):\n         pass\n \n+    @unittest.skip(reason=\"TimmBackbone initialization is managed on the timm side\")\n+    def test_can_init_all_missing_weights(self):\n+        pass\n+\n     @unittest.skip(reason=\"TimmBackbone initialization is managed on the timm side\")\n     def test_initialization(self):\n         pass"
        },
        {
            "sha": "5a24bcecee1ec51b181faea5aab2f536841194a3",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/6b3a1f2f5100a84e40138382a6955627b3b865ba/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6b3a1f2f5100a84e40138382a6955627b3b865ba/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=6b3a1f2f5100a84e40138382a6955627b3b865ba",
            "patch": "@@ -854,9 +854,8 @@ def test_can_init_all_missing_weights(self):\n \n         for model_class in self.all_model_classes:\n             # For now, skip everything older than 2024 and \"important models\" (too much models to patch otherwise)\n-            # Use `supports_cache_class` as a proxy to judge \"important\" models in order to prioritize them\n             # TODO: relax this as we patch more and more models\n-            if addition_year < 2024:\n+            if addition_year < 2023:\n                 self.skipTest(reason=f\"{model_class} is not a priorited model for now.\")\n \n             # Monkey patch the method to add a seed (we do it on PreTrainedModel._initialize_weights, which wraps"
        }
    ],
    "stats": {
        "total": 446,
        "additions": 253,
        "deletions": 193
    }
}