{
    "author": "Cyrilvallez",
    "message": "Remove low_cpu_mem_usage and _fast_init (#36963)\n\n* Remove low_cpu_mem_usage and _fast_init\n\n* Update deepspeed.py\n\n* Update modeling_utils.py\n\n* remove the first 2 tests everywhere\n\n* Update test_modeling_common.py\n\n* remove what was remaining about fast_init\n\n* fix logic and simplify\n\n* mismatched keys logic update\n\n* Update modeling_utils.py\n\n* Update modeling_utils.py\n\n* Update modeling_utils.py\n\n* Update modeling_utils.py\n\n* fix 2 models init_weights\n\n* extend to others\n\n* remove grad\n\n* Update modeling_fsmt.py\n\n* init weights in tests\n\n* style\n\n* Update test_modeling_fsmt.py\n\n* more old models\n\n* fix more init_weights\n\n* copies\n\n* fix\n\n* style\n\n* Update modeling_lxmert.py\n\n* fix inits\n\n* more and more\n\n* more\n\n* should finalize\n\n* style\n\n* Update modeling_dinov2_with_registers.py\n\n* fix\n\n* Update modeling_encoder_decoder.py\n\n* fix\n\n* style\n\n* Update modeling_lxmert.py\n\n* post rebase cleanup\n\n* Update modeling_informer.py\n\n* back to start for device\n\n* fix\n\n* add test to detect all failing cases correctly\n\n* Update test_modeling_common.py\n\n* fix\n\n* fix\n\n* sam\n\n* style\n\n* Update modeling_maskformer_swin.py\n\n* CIs\n\n* CIs\n\n* remove test - will add it on separate PR\n\n* fix\n\n* fix\n\n* Update modeling_sam.py\n\n* CIs\n\n* CIs\n\n* CIs\n\n* convnext\n\n* suggestions\n\n* CIs\n\n* fix copies after merge\n\n---------\n\nCo-authored-by: Yih-Dar <2521628+ydshieh@users.noreply.github.com>",
    "sha": "f304318f5ffa530a4948aed552d3405708163b52",
    "files": [
        {
            "sha": "ee012215e0709872beb7627f008496943d0698f2",
            "filename": "conftest.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/conftest.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/conftest.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/conftest.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -46,10 +46,6 @@\n     \"test_keep_in_fp32_modules\",\n     \"test_gradient_checkpointing_backward_compatibility\",\n     \"test_gradient_checkpointing_enable_disable\",\n-    \"test_save_load_fast_init_from_base\",\n-    \"test_fast_init_context_manager\",\n-    \"test_fast_init_tied_embeddings\",\n-    \"test_save_load_fast_init_to_base\",\n     \"test_torch_save_load\",\n     \"test_initialization\",\n     \"test_forward_signature\","
        },
        {
            "sha": "1700301db51fd73bd9023f68170066d88c6971eb",
            "filename": "src/transformers/integrations/deepspeed.py",
            "status": "modified",
            "additions": 2,
            "deletions": 5,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fintegrations%2Fdeepspeed.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fintegrations%2Fdeepspeed.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Fdeepspeed.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -303,7 +303,7 @@ def deepspeed_config():\n         return None\n \n \n-def _load_state_dict_into_zero3_model(model_to_load, state_dict, assign_to_params_buffers=False):\n+def _load_state_dict_into_zero3_model(model_to_load, state_dict):\n     \"\"\"\n     Loads state dict into a model specifically for Zero3, since DeepSpeed does not support the `transformers`\n     tensor parallelism API.\n@@ -346,10 +346,7 @@ def load(module: nn.Module, state_dict, prefix=\"\", assign_to_params_buffers=Fals\n             if child is not None:\n                 load(child, state_dict, prefix + name + \".\", assign_to_params_buffers)\n \n-    load(model_to_load, state_dict, assign_to_params_buffers=assign_to_params_buffers)\n-    # Delete `state_dict` so it could be collected by GC earlier. Note that `state_dict` is a copy of the argument, so\n-    # it's safe to delete it.\n-    del state_dict\n+    load(model_to_load, state_dict, assign_to_params_buffers=False)\n \n     return error_msgs\n "
        },
        {
            "sha": "0d1126ba549f11c5d522d0a962e06cd9480c8436",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 145,
            "deletions": 233,
            "changes": 378,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -73,7 +73,6 @@\n from .quantizers.quantizers_utils import get_module_from_name\n from .safetensors_conversion import auto_conversion\n from .utils import (\n-    ACCELERATE_MIN_VERSION,\n     ADAPTER_SAFE_WEIGHTS_NAME,\n     ADAPTER_WEIGHTS_NAME,\n     CONFIG_NAME,\n@@ -137,7 +136,6 @@\n         load_offloaded_weights,\n         offload_weight,\n         save_offload_index,\n-        set_module_tensor_to_device,\n     )\n \n     accelerate_version = version.parse(importlib.metadata.version(\"accelerate\"))\n@@ -208,32 +206,29 @@ def is_local_dist_rank_0():\n \n \n @contextmanager\n-def no_init_weights(_enable=True):\n+def no_init_weights():\n     \"\"\"\n     Context manager to globally disable weight initialization to speed up loading large models.\n-\n-    TODO(Patrick): Delete safety argument `_enable=True` at next major version. .\n     \"\"\"\n     global _init_weights\n     old_init_weights = _init_weights\n \n-    if _enable:\n-        _init_weights = False\n+    _init_weights = False\n \n-        def _skip_init(*args, **kwargs):\n-            pass\n+    def _skip_init(*args, **kwargs):\n+        pass\n+\n+    # Save the original initialization functions\n+    for name, init_func in TORCH_INIT_FUNCTIONS.items():\n+        setattr(torch.nn.init, name, _skip_init)\n \n-        # # Save the original initialization functions\n-        for name, init_func in TORCH_INIT_FUNCTIONS.items():\n-            setattr(torch.nn.init, name, _skip_init)\n     try:\n         yield\n     finally:\n         _init_weights = old_init_weights\n-        if _enable:\n-            # # Restore the original initialization functions\n-            for name, init_func in TORCH_INIT_FUNCTIONS.items():\n-                setattr(torch.nn.init, name, init_func)\n+        # Restore the original initialization functions\n+        for name, init_func in TORCH_INIT_FUNCTIONS.items():\n+            setattr(torch.nn.init, name, init_func)\n \n \n @contextmanager\n@@ -404,37 +399,6 @@ def dtype_byte_size(dtype):\n     return bit_size // 8\n \n \n-def check_support_param_buffer_assignment(model_to_load, state_dict):\n-    \"\"\"\n-    Checks if `model_to_load` supports param buffer assignment (such\n-    as when loading in empty weights) by first checking\n-    if the model explicitly disables it, then by ensuring that the state dict keys\n-    are a subset of the model's parameters.\n-\n-    Note: We fully disable this if we are using `deepspeed`\n-    \"\"\"\n-    if len(state_dict) == 0:\n-        return False\n-\n-    if is_deepspeed_zero3_enabled():\n-        return False\n-\n-    # Some models explicitly do not support param buffer assignment\n-    if not getattr(model_to_load, \"_supports_param_buffer_assignment\", True):\n-        logger.debug(\n-            f\"{model_to_load.__class__.__name__} does not support param buffer assignment, loading will be slower\"\n-        )\n-        return False\n-\n-    # If the model does, the incoming `state_dict` and the `model_to_load` must be the same dtype\n-    first_key = next(iter(model_to_load.state_dict().keys()))\n-    if first_key in state_dict:\n-        return state_dict[first_key].dtype == model_to_load.state_dict()[first_key].dtype\n-\n-    # For cases when the `state_dict` doesn't contain real weights to the model (`test_model_weights_reload_no_missing_tied_weights`)\n-    return False\n-\n-\n def load_sharded_checkpoint(model, folder, strict=True, prefer_safe=True):\n     \"\"\"\n     This is the same as\n@@ -750,6 +714,13 @@ def _infer_parameter_dtype(\n     return old_param is not None and old_param.is_contiguous(), casting_dtype\n \n \n+def _load_parameter_into_model(model: \"PreTrainedModel\", param_name: str, tensor: torch.Tensor):\n+    \"\"\"Cast a single parameter `param_name` into the `model`, with value `tensor`.\"\"\"\n+    module, param_type = get_module_from_name(model, param_name)\n+    # This will check potential shape mismatch if skipped before\n+    module.load_state_dict({param_type: tensor}, strict=False, assign=True)\n+\n+\n @torch.no_grad()\n def _load_state_dict_into_meta_model(\n     model: \"PreTrainedModel\",\n@@ -857,17 +828,12 @@ def _load_state_dict_into_meta_model(\n             ):\n                 if is_fsdp_enabled():\n                     param_device = \"cpu\" if is_local_dist_rank_0() else \"meta\"\n-                module, param_type = get_module_from_name(model, param_name)\n \n                 # avoid tied weights\n                 if param.data_ptr() in data_ptrs:\n                     param = param.clone()\n \n-                module.load_state_dict(\n-                    {param_type: param.to(param_device)},\n-                    strict=False,\n-                    assign=True,\n-                )\n+                _load_parameter_into_model(model, param_name, param.to(param_device))\n \n                 # Add `data_ptr` of `model.state_dict()[param_name]` to avoid tied weights\n                 data_ptrs.add(model.state_dict()[param_name].data_ptr())\n@@ -1397,18 +1363,7 @@ def _find_missing_and_unexpected_keys(\n     if has_inv_freq_buffers:\n         unexpected_keys = [k for k in unexpected_keys if \"rotary_emb.inv_freq\" not in k]\n \n-    if device_map is None and not is_fsdp_enabled() and not is_deepspeed_zero3_enabled():\n-        ptrs = collections.defaultdict(list)\n-        for name, tensor in model.state_dict().items():\n-            id_tensor = id_tensor_storage(tensor)\n-            ptrs[id_tensor].append(name)\n-\n-        # These are all the pointers of shared tensors.\n-        tied_params = [names for _, names in ptrs.items() if len(names) > 1]\n-    else:\n-        # id function doesn't work for meta tensor so we need this function\n-        tied_params = find_tied_parameters(model)\n-\n+    tied_params = find_tied_parameters(model)\n     for group in tied_params:\n         missing_in_group = [k for k in missing_keys if k in group]\n         if len(missing_in_group) > 0 and len(missing_in_group) < len(group):\n@@ -1430,29 +1385,59 @@ def _find_missing_and_unexpected_keys(\n \n \n def _find_mismatched_keys(\n-    model_to_load: \"PreTrainedModel\",\n-    state_dict: Dict,\n+    model: \"PreTrainedModel\",\n+    state_dict: Optional[Dict],\n+    checkpoint_files: Optional[List[str]],\n     ignore_mismatched_sizes: bool,\n-    prefix: str,\n-) -> List:\n-    \"\"\"Find mismatch of shapes between the model parameters and the loaded state dict, and optionally remove the\n-    problematic keys from `state_dict` if `ignore_mismatched_sizes` is `True`.\"\"\"\n+    keys_to_rename_mapping: Dict[str, str],\n+    is_quantized: bool,\n+    weights_only: bool,\n+) -> Tuple[List[str], List[Tuple[int, int]]]:\n+    \"\"\"\n+    Find potential shape mismatch between the different state dicts and the model parameters, but only if `ignore_mismatched_sizes`\n+    is True. Otherwise, return immediately and any shape mismatch that may exist will be raised later on. This avoids checking\n+    every parameter in advance, as shape mismatch are extremely rare in practice. If we want to ignore them however, we do\n+    need to check in advance as we need to know which parameters we need to move back from meta to cpu, and initialize\n+    correctly. Indeed, as our model initialization takes place at the module level, and not the weight level, in the\n+    case of a sharded checkpoint we cannot correctly initialize the weights according to `model._init_weights()` if we perform\n+    this check on each state dict at loading time (after the first loaded checkpoint, there are no way to initialize only the\n+    mismatched weights if any, without overwriting the previously loaded weights as well because all the module will be\n+    initialized, not only the weights that are mismatched).\n+    \"\"\"\n+\n+    # An error will be raised later on anyway if there is a mismatch - this avoids running the rest of this function\n+    # if there are no mismatch (which is almost always the case)\n+    if not ignore_mismatched_sizes:\n+        return [], []\n+\n+    if state_dict is not None:\n+        checkpoint_files = [\"\"]\n+\n+    model_state_dict = model.state_dict()\n     mismatched_keys = []\n-    if ignore_mismatched_sizes:\n-        model_state_dict = model_to_load.state_dict()\n-        state_dict_keys = list(state_dict.keys())\n-        for key in state_dict_keys:\n-            if key in model_state_dict and state_dict[key].shape != model_state_dict[key].shape:\n-                if state_dict[key].shape[-1] == 1 and state_dict[key].numel() * 2 == model_state_dict[key].numel():\n-                    # This skips size mismatches for 4-bit weights. Two 4-bit values share an 8-bit container, causing size differences.\n-                    # Without matching with module type or paramter type it seems like a practical way to detect valid 4bit weights.\n-                    pass\n-                else:\n-                    # Add prefix if we removed it before, to add the correct state dict key to the warnings\n-                    key_with_prefix = prefix + key\n-                    mismatched_keys.append((key_with_prefix, state_dict[key].shape, model_state_dict[key].shape))\n-                    del state_dict[key]\n-    return mismatched_keys\n+    mismatched_shapes = []\n+    for shard_file in checkpoint_files:\n+        # If shard_file is \"\", we use the existing state_dict instead of loading it\n+        if shard_file != \"\":\n+            state_dict = load_state_dict(\n+                shard_file, is_quantized=is_quantized, map_location=\"meta\", weights_only=weights_only\n+            )\n+\n+        # Fix the key names\n+        new_state_dict = {keys_to_rename_mapping[k]: v for k, v in state_dict.items() if k in keys_to_rename_mapping}\n+\n+        for key in new_state_dict.keys():\n+            if key in model_state_dict and new_state_dict[key].shape != model_state_dict[key].shape:\n+                # This skips size mismatches for 4-bit weights. Two 4-bit values share an 8-bit container, causing size differences.\n+                # Without matching with module type or paramter type it seems like a practical way to detect valid 4bit weights.\n+                if not (\n+                    new_state_dict[key].shape[-1] == 1\n+                    and new_state_dict[key].numel() * 2 == model_state_dict[key].numel()\n+                ):\n+                    mismatched_keys.append(key)\n+                    mismatched_shapes.append((new_state_dict[key].shape, model_state_dict[key].shape))\n+\n+    return mismatched_keys, mismatched_shapes\n \n \n class PipelineParallel(Enum):\n@@ -3773,27 +3758,20 @@ def float(self, *args):\n     @classmethod\n     def get_init_context(\n         cls: Type[SpecificPreTrainedModelType],\n-        _fast_init=True,\n         is_quantized=None,\n         _is_ds_init_called=None,\n-        low_cpu_mem_usage=True,\n     ):\n-        init_contexts = [no_init_weights(_enable=_fast_init)]\n-\n         if is_deepspeed_zero3_enabled() and not is_quantized and not _is_ds_init_called:\n             import deepspeed\n \n             logger.info(\"Detected DeepSpeed ZeRO-3: activating zero.init() for this model\")\n             init_contexts = [\n                 deepspeed.zero.Init(config_dict_or_path=deepspeed_config()),\n                 set_zero3_state(),\n-            ] + init_contexts\n-        elif low_cpu_mem_usage:\n-            if not is_accelerate_available():\n-                raise ImportError(\n-                    f\"Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install 'accelerate>={ACCELERATE_MIN_VERSION}'`\"\n-                )\n-            init_contexts.append(init_empty_weights())\n+                no_init_weights(),\n+            ]\n+        else:\n+            init_contexts = [no_init_weights(), init_empty_weights()]\n \n         if is_deepspeed_zero3_enabled() and is_quantized:\n             init_contexts.append(set_quantized_state())\n@@ -3829,10 +3807,6 @@ def from_pretrained(\n         The warning *Weights from XXX not used in YYY* means that the layer XXX is not used by YYY, therefore those\n         weights are discarded.\n \n-        If model weights are the same precision as the base model (and is a supported model), weights will be lazily loaded\n-        in using the `meta` device and brought into memory once an input is passed through that layer regardless of\n-        `low_cpu_mem_usage`.\n-\n         Parameters:\n             pretrained_model_name_or_path (`str` or `os.PathLike`, *optional*):\n                 Can be either:\n@@ -3910,31 +3884,12 @@ def from_pretrained(\n \n                 To test a pull request you made on the Hub, you can pass `revision=\"refs/pr/<pr_number>\"`.\n \n-                </Tip>\n-            _fast_init(`bool`, *optional*, defaults to `True`):\n-                Whether or not to disable fast initialization.\n-\n-                <Tip warning={true}>\n-\n-                One should only disable *_fast_init* to ensure backwards compatibility with `transformers.__version__ <\n-                4.6.0` for seeded model initialization. This argument will be removed at the next major version. See\n-                [pull request 11471](https://github.com/huggingface/transformers/pull/11471) for more information.\n-\n                 </Tip>\n             attn_implementation (`str`, *optional*):\n                 The attention implementation to use in the model (if relevant). Can be any of `\"eager\"` (manual implementation of the attention), `\"sdpa\"` (using [`F.scaled_dot_product_attention`](https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention.html)), or `\"flash_attention_2\"` (using [Dao-AILab/flash-attention](https://github.com/Dao-AILab/flash-attention)). By default, if available, SDPA will be used for torch>=2.1.1. The default is otherwise the manual `\"eager\"` implementation.\n \n             > Parameters for big model inference\n \n-            low_cpu_mem_usage(`bool`, *optional*):\n-                Tries not to use more than 1x model size in CPU memory (including peak memory) while loading the model.\n-                Generally should be combined with a `device_map` (such as `\"auto\"`) for best results.\n-                This is an experimental feature and a subject to change at any moment.\n-                </Tip>\n-                    If the model weights are in the same precision as the model loaded in, `low_cpu_mem_usage` (without\n-                    `device_map`) is redundant and will not provide any benefit in regards to CPU memory usage. However,\n-                    this should still be enabled if you are passing in a `device_map`.\n-                </Tip>\n             torch_dtype (`str` or `torch.dtype`, *optional*):\n                 Override the default `torch.dtype` and load the model under a specific `dtype`. The different options\n                 are:\n@@ -4045,37 +4000,16 @@ def from_pretrained(\n         >>> # Loading from a Flax checkpoint file instead of a PyTorch model (slower)\n         >>> model = BertModel.from_pretrained(\"google-bert/bert-base-uncased\", from_flax=True)\n         ```\n-\n-        * `low_cpu_mem_usage` algorithm:\n-\n-        This is an experimental function that loads the model using ~1x model size CPU memory\n-\n-        Here is how it works:\n-\n-        1. save which state_dict keys we have\n-        2. drop state_dict before the model is created, since the latter takes 1x model size CPU memory\n-        3. after the model has been instantiated switch to the meta device all params/buffers that\n-        are going to be replaced from the loaded state_dict\n-        4. load state_dict 2nd time\n-        5. replace the params/buffers from the state_dict\n-\n-        Currently, it can't handle deepspeed ZeRO stage 3 and ignores loading errors\n-\n         \"\"\"\n         state_dict = kwargs.pop(\"state_dict\", None)\n         from_tf = kwargs.pop(\"from_tf\", False)\n         from_flax = kwargs.pop(\"from_flax\", False)\n-        _ = kwargs.pop(\"resume_download\", None)\n         proxies = kwargs.pop(\"proxies\", None)\n         output_loading_info = kwargs.pop(\"output_loading_info\", False)\n         use_auth_token = kwargs.pop(\"use_auth_token\", None)\n-        _ = kwargs.pop(\"trust_remote_code\", None)\n-        _ = kwargs.pop(\"mirror\", None)\n         from_pipeline = kwargs.pop(\"_from_pipeline\", None)\n         from_auto_class = kwargs.pop(\"_from_auto\", False)\n-        _fast_init = kwargs.pop(\"_fast_init\", True)\n         torch_dtype = kwargs.pop(\"torch_dtype\", None)\n-        low_cpu_mem_usage = kwargs.pop(\"low_cpu_mem_usage\", None)\n         device_map = kwargs.pop(\"device_map\", None)\n         max_memory = kwargs.pop(\"max_memory\", None)\n         offload_folder = kwargs.pop(\"offload_folder\", None)\n@@ -4094,6 +4028,12 @@ def from_pretrained(\n         gguf_file = kwargs.pop(\"gguf_file\", None)\n         tp_plan = kwargs.pop(\"tp_plan\", None)\n         key_mapping = kwargs.pop(\"key_mapping\", None)\n+        # Not used anymore -- remove them from the kwargs\n+        _ = kwargs.pop(\"resume_download\", None)\n+        _ = kwargs.pop(\"trust_remote_code\", None)\n+        _ = kwargs.pop(\"mirror\", None)\n+        _ = kwargs.pop(\"_fast_init\", True)\n+        _ = kwargs.pop(\"low_cpu_mem_usage\", None)\n \n         if state_dict is not None and (pretrained_model_name_or_path is not None or gguf_file is not None):\n             raise ValueError(\n@@ -4156,9 +4096,6 @@ def from_pretrained(\n             world_size = torch.distributed.get_world_size()\n             device_mesh = torch.distributed.init_device_mesh(tp_device.type, (world_size,))\n \n-        if is_fsdp_enabled():\n-            low_cpu_mem_usage = True\n-\n         if use_auth_token is not None:\n             warnings.warn(\n                 \"The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\",\n@@ -4240,20 +4177,8 @@ def from_pretrained(\n                 device_map = {\"\": device_map}\n \n         if device_map is not None:\n-            if low_cpu_mem_usage is None:\n-                low_cpu_mem_usage = True\n-            elif not low_cpu_mem_usage:\n-                raise ValueError(\"Passing along a `device_map` or a `tp_plan` requires `low_cpu_mem_usage=True`\")\n-\n-        if low_cpu_mem_usage:\n             if is_deepspeed_zero3_enabled():\n-                raise ValueError(\n-                    \"DeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\"\n-                )\n-            elif not is_accelerate_available():\n-                raise ImportError(\n-                    f\"Using `low_cpu_mem_usage=True`, a `device_map` or a `tp_plan` requires Accelerate: `pip install 'accelerate>={ACCELERATE_MIN_VERSION}'`\"\n-                )\n+                raise ValueError(\"DeepSpeed Zero-3 is not compatible with passing a `device_map`.\")\n \n         # handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\n         if load_in_4bit or load_in_8bit:\n@@ -4355,10 +4280,6 @@ def from_pretrained(\n                 user_agent[\"quant\"] = hf_quantizer.quantization_config.quant_method.value\n             else:\n                 user_agent[\"quant\"] = hf_quantizer.quantization_config.quant_method\n-            # Force-set to `True` for more mem efficiency\n-            if low_cpu_mem_usage is None:\n-                low_cpu_mem_usage = True\n-                logger.warning(\"`low_cpu_mem_usage` was None, now default to True since model is quantized.\")\n \n         if gguf_file is not None and hf_quantizer is not None:\n             raise ValueError(\n@@ -4438,8 +4359,6 @@ def from_pretrained(\n                 state_dict = load_gguf_checkpoint(checkpoint_files[0], return_tensors=True, model_to_load=dummy_model)[\n                     \"tensors\"\n                 ]\n-                # Force it if is not already the case\n-                low_cpu_mem_usage = True\n \n             # Find the correct dtype based on current state\n             config, torch_dtype, dtype_orig = _get_torch_dtype(\n@@ -4449,7 +4368,7 @@ def from_pretrained(\n         config.name_or_path = pretrained_model_name_or_path\n \n         # Instantiate model.\n-        model_init_context = cls.get_init_context(_fast_init, is_quantized, _is_ds_init_called, low_cpu_mem_usage)\n+        model_init_context = cls.get_init_context(is_quantized, _is_ds_init_called)\n \n         config = copy.deepcopy(config)  # We do not want to modify the config inplace in from_pretrained.\n         if not getattr(config, \"_attn_implementation_autoset\", False):\n@@ -4480,8 +4399,6 @@ def from_pretrained(\n         if model._keep_in_fp32_modules is not None and (\n             torch_dtype == torch.float16 or getattr(hf_quantizer, \"use_keep_in_fp32_modules\", False)\n         ):\n-            # Only the path with `low_cpu_mem_usage` will check every param for the correct dtype\n-            low_cpu_mem_usage = True\n             # We need to match exact layers, so we add either `.` on each side, or start/end of string\n             keep_in_fp32_regex = re.compile(\n                 \"|\".join([rf\"((^|\\.){module}($|\\.))\" for module in model._keep_in_fp32_modules])\n@@ -4526,7 +4443,6 @@ def from_pretrained(\n                 pretrained_model_name_or_path,\n                 ignore_mismatched_sizes=ignore_mismatched_sizes,\n                 sharded_metadata=sharded_metadata,\n-                low_cpu_mem_usage=low_cpu_mem_usage,\n                 device_map=device_map,\n                 disk_offload_folder=offload_folder,\n                 offload_state_dict=offload_state_dict,\n@@ -4536,7 +4452,6 @@ def from_pretrained(\n                 device_mesh=device_mesh,\n                 key_mapping=key_mapping,\n                 weights_only=weights_only,\n-                _fast_init=_fast_init,\n             )\n \n         # make sure token embedding weights are still tied if needed\n@@ -4735,7 +4650,6 @@ def _load_pretrained_model(\n         pretrained_model_name_or_path: Optional[str],\n         ignore_mismatched_sizes: bool = False,\n         sharded_metadata: Optional[Dict] = None,\n-        low_cpu_mem_usage: bool = False,\n         device_map: Optional[Dict] = None,\n         disk_offload_folder: Optional[str] = None,\n         offload_state_dict: Optional[bool] = None,\n@@ -4745,7 +4659,6 @@ def _load_pretrained_model(\n         device_mesh: Optional[\"torch.distributed.device_mesh.DeviceMesh\"] = None,\n         key_mapping: Optional[Dict[str, str]] = None,\n         weights_only: bool = True,\n-        _fast_init: bool = True,\n     ):\n         # Useful flags\n         is_quantized = hf_quantizer is not None\n@@ -4787,20 +4700,28 @@ def _load_pretrained_model(\n             hf_quantizer,\n             device_map,\n         )\n+        # Find all the keys with shape mismatch (if we ignore the mismatch, the weights need to be newly initialized the\n+        # same way as missing keys)\n+        mismatched_keys, mismatched_shapes = _find_mismatched_keys(\n+            model,\n+            state_dict,\n+            checkpoint_files,\n+            ignore_mismatched_sizes,\n+            key_renaming_mapping,\n+            is_quantized,\n+            weights_only,\n+        )\n+\n+        # We need to update both the mapping and the list of checkpoint keys to remove the mismatched ones\n+        key_renaming_mapping = {k: v for k, v in key_renaming_mapping.items() if v not in mismatched_keys}\n+        checkpoint_keys = list(key_renaming_mapping.values())\n \n-        # Move missing keys back to cpu from meta device (because they won't be moved when loading the weights as\n-        # they are not in the loaded state dict)\n-        if low_cpu_mem_usage:\n-            model._move_missing_keys_from_meta_to_cpu(missing_keys, unexpected_keys, dtype, hf_quantizer)\n-            # In this case we also need to move everything back\n-            if is_fsdp_enabled() and not is_local_dist_rank_0() and not is_quantized:\n-                for key, param in model.state_dict().items():\n-                    if param.device == torch.device(\"meta\"):\n-                        set_module_tensor_to_device(model, key, \"cpu\", torch.empty(*param.size(), dtype=dtype))\n+        # Move missing (and potentially mismatched) keys back to cpu from meta device (because they won't be moved when\n+        # loading the weights as they are not in the loaded state dict)\n+        model._move_missing_keys_from_meta_to_cpu(missing_keys + mismatched_keys, unexpected_keys, dtype, hf_quantizer)\n \n-        # correctly initialize the missing keys if it was skipped before\n-        if _fast_init or low_cpu_mem_usage:\n-            model._initialize_missing_keys(checkpoint_keys, ignore_mismatched_sizes, is_quantized)\n+        # correctly initialize the missing (and potentially mismatched) keys\n+        model._initialize_missing_keys(checkpoint_keys, ignore_mismatched_sizes, is_quantized)\n \n         # Set some modules to fp32 if needed\n         if keep_in_fp32_regex is not None:\n@@ -4907,24 +4828,22 @@ def _load_pretrained_model(\n             caching_allocator_warmup(model_to_load, expanded_device_map, factor=2 if hf_quantizer is None else 4)\n \n         error_msgs = []\n-        mismatched_keys = []\n         # Iterate on all the shards to load the weights\n         for shard_file in checkpoint_files:\n             # Skip the load for shards that only contain disk-offloaded weights\n             if shard_file in disk_only_shard_files:\n                 continue\n \n             map_location = \"cpu\"\n-            if low_cpu_mem_usage:\n-                if shard_file.endswith(\".safetensors\"):\n-                    map_location = \"meta\"\n-                elif (\n-                    device_map is not None\n-                    and hf_quantizer is not None\n-                    and hf_quantizer.quantization_config.quant_method == QuantizationMethod.TORCHAO\n-                    and hf_quantizer.quantization_config.quant_type in [\"int4_weight_only\", \"autoquant\"]\n-                ):\n-                    map_location = torch.device([d for d in device_map.values() if d not in [\"cpu\", \"disk\"]][0])\n+            if shard_file.endswith(\".safetensors\"):\n+                map_location = \"meta\"\n+            elif (\n+                device_map is not None\n+                and hf_quantizer is not None\n+                and hf_quantizer.quantization_config.quant_method == QuantizationMethod.TORCHAO\n+                and hf_quantizer.quantization_config.quant_type in [\"int4_weight_only\", \"autoquant\"]\n+            ):\n+                map_location = torch.device([d for d in device_map.values() if d not in [\"cpu\", \"disk\"]][0])\n \n             # If shard_file is \"\", we use the existing state_dict instead of loading it\n             if shard_file != \"\":\n@@ -4935,41 +4854,27 @@ def _load_pretrained_model(\n             # Fix the key names\n             state_dict = {key_renaming_mapping[k]: v for k, v in state_dict.items() if k in key_renaming_mapping}\n \n-            # Mistmatched keys contains tuples key/shape1/shape2 of weights in the checkpoint that have a shape not\n-            # matching the weights in the model.\n-            mismatched_keys += _find_mismatched_keys(\n-                model_to_load,\n-                state_dict,\n-                ignore_mismatched_sizes,\n-                prefix if loading_base_model_from_task_state_dict else \"\",\n-            )\n-\n-            if low_cpu_mem_usage:\n-                # Skip it with fsdp on ranks other than 0\n-                if not (is_fsdp_enabled() and not is_local_dist_rank_0() and not is_quantized):\n-                    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n-                        model_to_load,\n-                        state_dict,\n-                        shard_file,\n-                        expected_keys,\n-                        reverse_key_renaming_mapping,\n-                        device_map=device_map,\n-                        disk_offload_folder=disk_offload_folder,\n-                        disk_offload_index=disk_offload_index,\n-                        cpu_offload_folder=cpu_offload_folder,\n-                        cpu_offload_index=cpu_offload_index,\n-                        hf_quantizer=hf_quantizer,\n-                        is_safetensors=is_offloaded_safetensors,\n-                        keep_in_fp32_regex=keep_in_fp32_regex,\n-                        unexpected_keys=unexpected_keys,\n-                        device_mesh=device_mesh,\n-                    )\n-            else:\n-                assign_params = check_support_param_buffer_assignment(model_to_load, state_dict)\n-                if is_deepspeed_zero3_enabled():\n-                    error_msgs += _load_state_dict_into_zero3_model(model_to_load, state_dict, assign_params)\n-                else:\n-                    model_to_load.load_state_dict(state_dict, strict=False, assign=assign_params)\n+            if is_deepspeed_zero3_enabled():\n+                error_msgs += _load_state_dict_into_zero3_model(model_to_load, state_dict)\n+            # Skip it with fsdp on ranks other than 0\n+            elif not (is_fsdp_enabled() and not is_local_dist_rank_0() and not is_quantized):\n+                disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n+                    model_to_load,\n+                    state_dict,\n+                    shard_file,\n+                    expected_keys,\n+                    reverse_key_renaming_mapping,\n+                    device_map=device_map,\n+                    disk_offload_folder=disk_offload_folder,\n+                    disk_offload_index=disk_offload_index,\n+                    cpu_offload_folder=cpu_offload_folder,\n+                    cpu_offload_index=cpu_offload_index,\n+                    hf_quantizer=hf_quantizer,\n+                    is_safetensors=is_offloaded_safetensors,\n+                    keep_in_fp32_regex=keep_in_fp32_regex,\n+                    unexpected_keys=unexpected_keys,\n+                    device_mesh=device_mesh,\n+                )\n \n             # force memory release if loading multiple shards, to avoid having 2 state dicts in memory in next loop\n             del state_dict\n@@ -5068,7 +4973,7 @@ def _load_pretrained_model(\n             mismatched_warning = \"\\n\".join(\n                 [\n                     f\"- {key}: found shape {shape1} in the checkpoint and {shape2} in the model instantiated\"\n-                    for key, shape1, shape2 in mismatched_keys\n+                    for key, (shape1, shape2) in zip(mismatched_keys, mismatched_shapes)\n                 ]\n             )\n             logger.warning(\n@@ -5323,19 +5228,26 @@ def _move_missing_keys_from_meta_to_cpu(\n         \"\"\"\n         is_quantized = hf_quantizer is not None\n \n+        # In this case we need to move everything back\n+        if is_fsdp_enabled() and not is_local_dist_rank_0() and not is_quantized:\n+            # We only do it for the parameters, as the buffers are not initialized on the meta device by default\n+            for key, param in self.named_parameters():\n+                value = torch.empty_like(param, dtype=dtype, device=\"cpu\")\n+                _load_parameter_into_model(self, key, value)\n+            return\n+\n         model_state_dict = self.state_dict()\n         for key in missing_keys:\n             param = model_state_dict[key]\n+            # Buffers are not initialized on the meta device, so we still need this check to avoid overwriting them\n             if param.device == torch.device(\"meta\"):\n-                # upcast in fp32 if any\n-                target_dtype = dtype\n-                value = torch.empty(*param.size(), dtype=target_dtype)\n+                value = torch.empty_like(param, dtype=dtype, device=\"cpu\")\n                 if (\n                     not is_quantized\n                     or (getattr(hf_quantizer, \"requires_parameters_quantization\", False))\n                     or not hf_quantizer.check_quantized_param(self, param_value=value, param_name=key, state_dict={})\n                 ):\n-                    set_module_tensor_to_device(self, key, \"cpu\", value)\n+                    _load_parameter_into_model(self, key, value)\n                 else:\n                     hf_quantizer.create_quantized_param(self, value, key, \"cpu\", model_state_dict, unexpected_keys)\n "
        },
        {
            "sha": "1aa24ca08a5aa17763074379f0db904c9e0f0fb1",
            "filename": "src/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faudio_spectrogram_transformer%2Fmodeling_audio_spectrogram_transformer.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -401,7 +401,6 @@ class ASTPreTrainedModel(PreTrainedModel):\n     _supports_sdpa = True\n     _supports_flash_attn_2 = True\n \n-    # Copied from transformers.models.deit.modeling_deit.DeiTPreTrainedModel._init_weights\n     def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> None:\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(module, (nn.Linear, nn.Conv2d)):\n@@ -415,6 +414,10 @@ def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> No\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, ASTEmbeddings):\n+            module.cls_token.data.zero_()\n+            module.position_embeddings.data.zero_()\n+            module.distillation_token.data.zero_()\n \n \n AUDIO_SPECTROGRAM_TRANSFORMER_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "aaca155b0c8cac19e7b8ae7d3e6416040c18d67b",
            "filename": "src/transformers/models/autoformer/modeling_autoformer.py",
            "status": "modified",
            "additions": 5,
            "deletions": 7,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fautoformer%2Fmodeling_autoformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fautoformer%2Fmodeling_autoformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fautoformer%2Fmodeling_autoformer.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -361,22 +361,20 @@ class AutoformerSinusoidalPositionalEmbedding(nn.Embedding):\n     def __init__(self, num_positions: int, embedding_dim: int, padding_idx: Optional[int] = None) -> None:\n         super().__init__(num_positions, embedding_dim)\n \n-    @staticmethod\n-    def _init_weight(out: nn.Parameter) -> nn.Parameter:\n+    def _init_weight(self):\n         \"\"\"\n         Identical to the XLM create_sinusoidal_embeddings except features are not interleaved. The cos features are in\n         the 2nd half of the vector. [dim // 2:]\n         \"\"\"\n-        n_pos, dim = out.shape\n+        n_pos, dim = self.weight.shape\n         position_enc = np.array(\n             [[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)]\n         )\n-        out.requires_grad = False  # set early to avoid an error in pytorch-1.8+\n+        out = torch.empty(n_pos, dim, dtype=self.weight.dtype, requires_grad=False)\n         sentinel = dim // 2 if dim % 2 == 0 else (dim // 2) + 1\n         out[:, 0:sentinel] = torch.FloatTensor(np.sin(position_enc[:, 0::2]))\n         out[:, sentinel:] = torch.FloatTensor(np.cos(position_enc[:, 1::2]))\n-        out.detach_()\n-        return out\n+        self.weight = nn.Parameter(out, requires_grad=False)\n \n     @torch.no_grad()\n     def forward(self, input_ids_shape: torch.Size, past_key_values_length: int = 0) -> torch.Tensor:\n@@ -903,7 +901,7 @@ def _init_weights(self, module):\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, AutoformerSinusoidalPositionalEmbedding):\n-            module.weight = module._init_weight(module.weight)\n+            module._init_weight()\n         elif isinstance(module, nn.Embedding):\n             module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:"
        },
        {
            "sha": "264bce993a341f4989e7d34ab3b1bf147bc40db5",
            "filename": "src/transformers/models/beit/modeling_beit.py",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fbeit%2Fmodeling_beit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fbeit%2Fmodeling_beit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbeit%2Fmodeling_beit.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -770,6 +770,18 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, BeitEmbeddings):\n+            module.cls_token.data.zero_()\n+            if module.mask_token is not None:\n+                module.mask_token.data.zero_()\n+            if module.position_embeddings is not None:\n+                module.position_embeddings.data.zero_()\n+        elif isinstance(module, BeitRelativePositionBias):\n+            module.relative_position_bias_table.data.zero_()\n+        elif isinstance(module, BeitLayer):\n+            if module.lambda_1 is not None:\n+                module.lambda_1.data.fill_(self.config.layer_scale_init_value)\n+                module.lambda_2.data.fill_(self.config.layer_scale_init_value)\n \n \n BEIT_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "d7a26500ccfa096d8f890c65b5947b9e4955c7b0",
            "filename": "src/transformers/models/bert/modeling_bert.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fbert%2Fmodeling_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fbert%2Fmodeling_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbert%2Fmodeling_bert.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -848,6 +848,8 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, BertLMPredictionHead):\n+            module.bias.data.zero_()\n \n \n @dataclass"
        },
        {
            "sha": "b69590ae21a59702c18dd3c69772c65c4994a29c",
            "filename": "src/transformers/models/camembert/modeling_camembert.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -715,7 +715,7 @@ class CamembertPreTrainedModel(PreTrainedModel):\n     supports_gradient_checkpointing = True\n     _supports_sdpa = True\n \n-    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights\n+    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights with BertLMPredictionHead->CamembertLMHead\n     def _init_weights(self, module):\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(module, nn.Linear):\n@@ -731,6 +731,8 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, CamembertLMHead):\n+            module.bias.data.zero_()\n \n \n CAMEMBERT_INPUTS_DOCSTRING = r\"\"\""
        },
        {
            "sha": "8eeb98b089ff30a04a1cfca2e1907f5fe019043a",
            "filename": "src/transformers/models/convnext/modeling_convnext.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fconvnext%2Fmodeling_convnext.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fconvnext%2Fmodeling_convnext.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fconvnext%2Fmodeling_convnext.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -286,9 +286,12 @@ def _init_weights(self, module):\n             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n-        elif isinstance(module, nn.LayerNorm):\n+        elif isinstance(module, (nn.LayerNorm, ConvNextLayerNorm)):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, ConvNextLayer):\n+            if module.layer_scale_parameter is not None:\n+                module.layer_scale_parameter.data.fill_(self.config.layer_scale_init_value)\n \n \n CONVNEXT_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "98e5ba15513ea903c3dd7b1d56eb2ffa0e03778e",
            "filename": "src/transformers/models/convnextv2/modeling_convnextv2.py",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fconvnextv2%2Fmodeling_convnextv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fconvnextv2%2Fmodeling_convnextv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fconvnextv2%2Fmodeling_convnextv2.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -287,7 +287,6 @@ def forward(\n         )\n \n \n-# Copied from transformers.models.convnext.modeling_convnext.ConvNextPreTrainedModel with ConvNext->ConvNextV2, convnext->convnextv2\n class ConvNextV2PreTrainedModel(PreTrainedModel):\n     \"\"\"\n     An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained\n@@ -307,9 +306,12 @@ def _init_weights(self, module):\n             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n             if module.bias is not None:\n                 module.bias.data.zero_()\n-        elif isinstance(module, nn.LayerNorm):\n+        elif isinstance(module, (nn.LayerNorm, ConvNextV2LayerNorm)):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, ConvNextV2GRN):\n+            module.weight.data.zero_()\n+            module.bias.data.zero_()\n \n \n CONVNEXTV2_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "12a407c51ad62278404d5110347a3b79a9cf3916",
            "filename": "src/transformers/models/data2vec/modeling_data2vec_vision.py",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fmodeling_data2vec_vision.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -784,6 +784,18 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, Data2VecVisionEmbeddings):\n+            module.cls_token.data.zero_()\n+            if module.mask_token is not None:\n+                module.mask_token.data.zero_()\n+            if module.position_embeddings is not None:\n+                module.position_embeddings.data.zero_()\n+        elif isinstance(module, Data2VecVisionRelativePositionBias):\n+            module.relative_position_bias_table.data.zero_()\n+        elif isinstance(module, Data2VecVisionLayer):\n+            if module.lambda_1 is not None:\n+                module.lambda_1.data.fill_(self.config.layer_scale_init_value)\n+                module.lambda_2.data.fill_(self.config.layer_scale_init_value)\n \n \n DATA2VEC_VISION_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "007129c5bd6eb83988932fe2b6dec5797b499ae4",
            "filename": "src/transformers/models/deformable_detr/modeling_deformable_detr.py",
            "status": "modified",
            "additions": 0,
            "deletions": 10,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fmodeling_deformable_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fmodeling_deformable_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fmodeling_deformable_detr.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -1850,30 +1850,20 @@ def __init__(self, config: DeformableDetrConfig):\n             num_layers=3,\n         )\n \n-        prior_prob = 0.01\n-        bias_value = -math.log((1 - prior_prob) / prior_prob)\n-        self.class_embed.bias.data = torch.ones(config.num_labels) * bias_value\n-        nn.init.constant_(self.bbox_embed.layers[-1].weight.data, 0)\n-        nn.init.constant_(self.bbox_embed.layers[-1].bias.data, 0)\n-\n         # if two-stage, the last class_embed and bbox_embed is for region proposal generation\n         num_pred = (config.decoder_layers + 1) if config.two_stage else config.decoder_layers\n         if config.with_box_refine:\n             self.class_embed = _get_clones(self.class_embed, num_pred)\n             self.bbox_embed = _get_clones(self.bbox_embed, num_pred)\n-            nn.init.constant_(self.bbox_embed[0].layers[-1].bias.data[2:], -2.0)\n             # hack implementation for iterative bounding box refinement\n             self.model.decoder.bbox_embed = self.bbox_embed\n         else:\n-            nn.init.constant_(self.bbox_embed.layers[-1].bias.data[2:], -2.0)\n             self.class_embed = nn.ModuleList([self.class_embed for _ in range(num_pred)])\n             self.bbox_embed = nn.ModuleList([self.bbox_embed for _ in range(num_pred)])\n             self.model.decoder.bbox_embed = None\n         if config.two_stage:\n             # hack implementation for two-stage\n             self.model.decoder.class_embed = self.class_embed\n-            for box_embed in self.bbox_embed:\n-                nn.init.constant_(box_embed.layers[-1].bias.data[2:], 0.0)\n \n         # Initialize weights and apply final processing\n         self.post_init()"
        },
        {
            "sha": "b8cae05f1ff6994838a165808dc8840b3c3a1657",
            "filename": "src/transformers/models/deit/modeling_deit.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeit%2Fmodeling_deit.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -487,6 +487,12 @@ def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> No\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, DeiTEmbeddings):\n+            module.cls_token.data.zero_()\n+            module.position_embeddings.data.zero_()\n+            module.distillation_token.data.zero_()\n+            if module.mask_token is not None:\n+                module.mask_token.data.zero_()\n \n \n DEIT_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "18ab8db6d05ab0db7a19c1bed29e1b8aa024ca51",
            "filename": "src/transformers/models/deprecated/speech_to_text_2/modeling_speech_to_text_2.py",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fspeech_to_text_2%2Fmodeling_speech_to_text_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fspeech_to_text_2%2Fmodeling_speech_to_text_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fspeech_to_text_2%2Fmodeling_speech_to_text_2.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -44,7 +44,6 @@ def __init__(self, num_positions: int, embedding_dim: int, padding_idx: Optional\n         self.offset = 2\n         self.embedding_dim = embedding_dim\n         self.padding_idx = padding_idx\n-        self.make_weights(num_positions + self.offset, embedding_dim, padding_idx)\n \n     def make_weights(self, num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None):\n         emb_weights = self.get_embedding(num_embeddings, embedding_dim, padding_idx)\n@@ -399,6 +398,11 @@ def _init_weights(self, module):\n             module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n+        elif isinstance(module, Speech2Text2SinusoidalPositionalEmbedding):\n+            weight = module.get_embedding(*module.weight.shape, module.padding_idx)\n+            weight = nn.Parameter(weight, requires_grad=False)\n+            weight.detach_()\n+            module.weight = weight\n \n \n SPEECH_TO_TEXT_2_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "6ad8a14a73290ac7fb19b91719b15ea232a1b851",
            "filename": "src/transformers/models/deprecated/vit_hybrid/modeling_vit_hybrid.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvit_hybrid%2Fmodeling_vit_hybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvit_hybrid%2Fmodeling_vit_hybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvit_hybrid%2Fmodeling_vit_hybrid.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -516,12 +516,12 @@ def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> No\n                 mean=0.0,\n                 std=self.config.initializer_range,\n             ).to(module.position_embeddings.dtype)\n-\n             module.cls_token.data = nn.init.trunc_normal_(\n                 module.cls_token.data.to(torch.float32),\n                 mean=0.0,\n                 std=self.config.initializer_range,\n             ).to(module.cls_token.dtype)\n+            module.mask_token.data.zero_()\n \n \n VIT_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "7ed5a4ec6cb7b180e23c84a8beb1b3a2dc0ed392",
            "filename": "src/transformers/models/dinov2/modeling_dinov2.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov2%2Fmodeling_dinov2.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -548,6 +548,11 @@ def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> No\n                 std=self.config.initializer_range,\n             ).to(module.cls_token.dtype)\n \n+            if self.config.use_mask_token:\n+                module.mask_token.data.zero_()\n+        elif isinstance(module, Dinov2LayerScale):\n+            module.lambda1.data.fill_(self.config.layerscale_value)\n+\n \n DINOV2_START_DOCSTRING = r\"\"\"\n     This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass. Use it"
        },
        {
            "sha": "449bfb9b91cdcaf665c6a3e0ac4cad828d5779eb",
            "filename": "src/transformers/models/dinov2_with_registers/modeling_dinov2_with_registers.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodeling_dinov2_with_registers.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -556,6 +556,11 @@ def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> No\n                 std=self.config.initializer_range,\n             ).to(module.cls_token.dtype)\n \n+            module.mask_token.data.zero_()\n+            module.register_tokens.data.zero_()\n+        elif isinstance(module, Dinov2WithRegistersLayerScale):  # noqa: F821\n+            module.lambda1.data.fill_(self.config.layerscale_value)\n+\n \n _EXPECTED_OUTPUT_SHAPE = [1, 257, 768]\n "
        },
        {
            "sha": "59777e2157894e7641c8512c7ff50febb75aed43",
            "filename": "src/transformers/models/dinov2_with_registers/modular_dinov2_with_registers.py",
            "status": "modified",
            "additions": 31,
            "deletions": 2,
            "changes": 33,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodular_dinov2_with_registers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodular_dinov2_with_registers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdinov2_with_registers%2Fmodular_dinov2_with_registers.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -14,7 +14,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-from typing import Optional\n+from typing import Optional, Union\n \n import torch\n import torch.utils.checkpoint\n@@ -277,7 +277,36 @@ class Dinov2WithRegistersEncoder(Dinov2Encoder):\n \n \n class Dinov2WithRegistersPreTrainedModel(Dinov2PreTrainedModel):\n-    pass\n+    def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> None:\n+        \"\"\"Initialize the weights\"\"\"\n+        if isinstance(module, (nn.Linear, nn.Conv2d)):\n+            # Upcast the input in `fp32` and cast it back to desired `dtype` to avoid\n+            # `trunc_normal_cpu` not implemented in `half` issues\n+            module.weight.data = nn.init.trunc_normal_(\n+                module.weight.data.to(torch.float32), mean=0.0, std=self.config.initializer_range\n+            ).to(module.weight.dtype)\n+            if module.bias is not None:\n+                module.bias.data.zero_()\n+        elif isinstance(module, nn.LayerNorm):\n+            module.bias.data.zero_()\n+            module.weight.data.fill_(1.0)\n+        elif isinstance(module, Dinov2WithRegistersEmbeddings):\n+            module.position_embeddings.data = nn.init.trunc_normal_(\n+                module.position_embeddings.data.to(torch.float32),\n+                mean=0.0,\n+                std=self.config.initializer_range,\n+            ).to(module.position_embeddings.dtype)\n+\n+            module.cls_token.data = nn.init.trunc_normal_(\n+                module.cls_token.data.to(torch.float32),\n+                mean=0.0,\n+                std=self.config.initializer_range,\n+            ).to(module.cls_token.dtype)\n+\n+            module.mask_token.data.zero_()\n+            module.register_tokens.data.zero_()\n+        elif isinstance(module, Dinov2WithRegistersLayerScale):  # noqa: F821\n+            module.lambda1.data.fill_(self.config.layerscale_value)\n \n \n class Dinov2WithRegistersModel(Dinov2Model):"
        },
        {
            "sha": "929d73088475d7257c4eaa96113aba6616d7e2d2",
            "filename": "src/transformers/models/donut/modeling_donut_swin.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdonut%2Fmodeling_donut_swin.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdonut%2Fmodeling_donut_swin.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdonut%2Fmodeling_donut_swin.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -869,6 +869,13 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, DonutSwinEmbeddings):\n+            if module.mask_token is not None:\n+                module.mask_token.data.zero_()\n+            if module.position_embeddings is not None:\n+                module.position_embeddings.data.zero_()\n+        elif isinstance(module, DonutSwinSelfAttention):\n+            module.relative_position_bias_table.data.zero_()\n \n \n SWIN_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "c9bbaa171675ba05a7faf9ea17b994c9c6c4c659",
            "filename": "src/transformers/models/dpt/modeling_dpt.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -855,6 +855,9 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        if isinstance(module, (DPTViTEmbeddings, DPTViTHybridEmbeddings)):\n+            module.cls_token.data.zero_()\n+            module.position_embeddings.data.zero_()\n \n \n DPT_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "3921ca50790f43920355e08176ff5ef61baa35df",
            "filename": "src/transformers/models/electra/modeling_electra.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Felectra%2Fmodeling_electra.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Felectra%2Fmodeling_electra.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Felectra%2Fmodeling_electra.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -670,7 +670,6 @@ class ElectraPreTrainedModel(PreTrainedModel):\n     base_model_prefix = \"electra\"\n     supports_gradient_checkpointing = True\n \n-    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights\n     def _init_weights(self, module):\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(module, nn.Linear):"
        },
        {
            "sha": "415fd058e45d8fe6e44ca30ddfe178ffc717cf19",
            "filename": "src/transformers/models/encoder_decoder/modeling_encoder_decoder.py",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fencoder_decoder%2Fmodeling_encoder_decoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fencoder_decoder%2Fmodeling_encoder_decoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fencoder_decoder%2Fmodeling_encoder_decoder.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -264,6 +264,8 @@ def __init__(\n         self.tie_weights()\n \n     def tie_weights(self):\n+        self.encoder.tie_weights()\n+        self.decoder.tie_weights()\n         # tie encoder & decoder if needed\n         if self.config.tie_encoder_decoder:\n             # tie encoder and decoder base model\n@@ -279,6 +281,12 @@ def tie_weights(self):\n             # Leading to issues on subsequent calls by different tests or subsequent calls.\n             self._dynamic_tied_weights_keys = tied_weights\n \n+    def _init_weights(self, module):\n+        if module in self.encoder.modules():\n+            self.encoder._init_weights(module)\n+        elif module in self.decoder.modules():\n+            self.decoder._init_weights(module)\n+\n     def get_encoder(self):\n         return self.encoder\n \n@@ -385,14 +393,6 @@ def from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs):\n \n                 return model\n \n-        # At the moment fast initialization is not supported for composite models\n-        if kwargs.get(\"_fast_init\", False):\n-            logger.warning(\n-                \"Fast initialization is currently not supported for EncoderDecoderModel. \"\n-                \"Falling back to slow initialization...\"\n-            )\n-        kwargs[\"_fast_init\"] = False\n-\n         return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n \n     @classmethod"
        },
        {
            "sha": "6f90d8d052f9bc9a3f0c5cdeb74aad823b44bf21",
            "filename": "src/transformers/models/esm/modeling_esm.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fesm%2Fmodeling_esm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fesm%2Fmodeling_esm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fesm%2Fmodeling_esm.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -681,7 +681,7 @@ class EsmPreTrainedModel(PreTrainedModel):\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"EsmLayer\", \"EsmFoldTriangularSelfAttentionBlock\", \"EsmEmbeddings\"]\n \n-    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights\n+    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights with BertLMPredictionHead->EsmLMHead\n     def _init_weights(self, module):\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(module, nn.Linear):\n@@ -697,6 +697,8 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, EsmLMHead):\n+            module.bias.data.zero_()\n \n \n ESM_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "330f7c4e7baf6d08d4aeb4e93af0b4a909f9c4e4",
            "filename": "src/transformers/models/flava/modeling_flava.py",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fflava%2Fmodeling_flava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fflava%2Fmodeling_flava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflava%2Fmodeling_flava.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -874,6 +874,18 @@ def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> No\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, FlavaMaskedPredictionHead):\n+            module.bias.data.zero_()\n+        elif isinstance(module, FlavaImageEmbeddings):\n+            module.cls_token.data.zero_()\n+            module.position_embeddings.data.zero_()\n+            if module.mask_token is not None:\n+                module.mask_token.data.zero_()\n+        elif isinstance(module, FlavaMultimodalModel):\n+            if module.use_cls_token:\n+                module.cls_token.data.zero_()\n+        elif isinstance(module, FlavaModel):\n+            module.logit_scale.data.fill_(self.config.logit_scale_init_value)\n \n \n @add_start_docstrings("
        },
        {
            "sha": "a5cf2981b14a152fb172843e791038fc828388f2",
            "filename": "src/transformers/models/focalnet/modeling_focalnet.py",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Ffocalnet%2Fmodeling_focalnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Ffocalnet%2Fmodeling_focalnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffocalnet%2Fmodeling_focalnet.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -621,7 +621,6 @@ def forward(\n         )\n \n \n-# Copied from transformers.models.swin.modeling_swin.SwinPreTrainedModel with Swin->FocalNet,swin->focalnet\n class FocalNetPreTrainedModel(PreTrainedModel):\n     \"\"\"\n     An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained\n@@ -645,6 +644,13 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, FocalNetEmbeddings):\n+            if module.mask_token is not None:\n+                module.mask_token.data.zero_()\n+        elif isinstance(module, FocalNetLayer):\n+            if self.config.use_layerscale:\n+                module.gamma_1.data.fill_(self.config.layerscale_value)\n+                module.gamma_2.data.fill_(self.config.layerscale_value)\n \n \n FOCALNET_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "8bbdf195501b90c89636fb8dafa2bef737c9adc0",
            "filename": "src/transformers/models/fsmt/modeling_fsmt.py",
            "status": "modified",
            "additions": 8,
            "deletions": 9,
            "changes": 17,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Ffsmt%2Fmodeling_fsmt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Ffsmt%2Fmodeling_fsmt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffsmt%2Fmodeling_fsmt.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -351,7 +351,10 @@ def _init_weights(self, module):\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, SinusoidalPositionalEmbedding):\n-            pass\n+            weight = module.get_embedding(*module.weight.shape, module.padding_idx)\n+            weight = nn.Parameter(weight, requires_grad=False)\n+            weight.detach_()\n+            module.weight = weight\n         elif isinstance(module, nn.Embedding):\n             module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n@@ -1302,17 +1305,13 @@ class SinusoidalPositionalEmbedding(nn.Embedding):\n     \"\"\"\n \n     def __init__(self, num_positions, embedding_dim, padding_idx):\n-        self.make_weight(num_positions, embedding_dim, padding_idx)\n+        super().__init__(num_positions, embedding_dim, padding_idx)\n \n     def make_weight(self, num_positions, embedding_dim, padding_idx):\n         weight = self.get_embedding(num_positions, embedding_dim, padding_idx)\n-        if not hasattr(self, \"weight\"):\n-            # in ___init__\n-            super().__init__(num_positions, embedding_dim, padding_idx, _weight=weight)\n-        else:\n-            # in forward put the weights on the correct dtype and device of the param\n-            weight = weight.to(dtype=self.weight.dtype, device=self.weight.device)\n-            self.weight = nn.Parameter(weight)\n+        # in forward put the weights on the correct dtype and device of the param\n+        weight = weight.to(dtype=self.weight.dtype, device=self.weight.device)\n+        self.weight = nn.Parameter(weight)\n         self.weight.detach_()\n         self.weight.requires_grad = False\n "
        },
        {
            "sha": "8842b10cc15b27fed09dafa6257208f06d48088c",
            "filename": "src/transformers/models/glpn/modeling_glpn.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fglpn%2Fmodeling_glpn.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fglpn%2Fmodeling_glpn.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglpn%2Fmodeling_glpn.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -437,7 +437,7 @@ def _init_weights(self, module):\n             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n-        elif isinstance(module, nn.LayerNorm):\n+        elif isinstance(module, (nn.LayerNorm, nn.BatchNorm2d)):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n "
        },
        {
            "sha": "c48310e4256b2a411d840ecbc5b7a9ede0308cde",
            "filename": "src/transformers/models/ijepa/modeling_ijepa.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodeling_ijepa.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -187,6 +187,8 @@ def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> No\n                 mean=0.0,\n                 std=self.config.initializer_range,\n             ).to(module.position_embeddings.dtype)\n+            if module.mask_token is not None:\n+                module.mask_token.data.zero_()\n \n \n def eager_attention_forward("
        },
        {
            "sha": "2cf0fe32bf5ff4e53d3c7ef36563bf78509a9dcb",
            "filename": "src/transformers/models/ijepa/modular_ijepa.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodular_ijepa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodular_ijepa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fijepa%2Fmodular_ijepa.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -129,6 +129,8 @@ def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> No\n                 mean=0.0,\n                 std=self.config.initializer_range,\n             ).to(module.position_embeddings.dtype)\n+            if module.mask_token is not None:\n+                module.mask_token.data.zero_()\n \n \n _EXPECTED_OUTPUT_SHAPE = [1, 256, 1280]"
        },
        {
            "sha": "3f37662459e8545a7d8c2c12a1144dead6dc5192",
            "filename": "src/transformers/models/informer/modeling_informer.py",
            "status": "modified",
            "additions": 5,
            "deletions": 7,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Finformer%2Fmodeling_informer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Finformer%2Fmodeling_informer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finformer%2Fmodeling_informer.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -234,22 +234,20 @@ class InformerSinusoidalPositionalEmbedding(nn.Embedding):\n     def __init__(self, num_positions: int, embedding_dim: int, padding_idx: Optional[int] = None) -> None:\n         super().__init__(num_positions, embedding_dim)\n \n-    @staticmethod\n-    def _init_weight(out: nn.Parameter) -> nn.Parameter:\n+    def _init_weight(self):\n         \"\"\"\n         Identical to the XLM create_sinusoidal_embeddings except features are not interleaved. The cos features are in\n         the 2nd half of the vector. [dim // 2:]\n         \"\"\"\n-        n_pos, dim = out.shape\n+        n_pos, dim = self.weight.shape\n         position_enc = np.array(\n             [[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)]\n         )\n-        out.requires_grad = False  # set early to avoid an error in pytorch-1.8+\n+        out = torch.empty(n_pos, dim, dtype=self.weight.dtype, requires_grad=False)\n         sentinel = dim // 2 if dim % 2 == 0 else (dim // 2) + 1\n         out[:, 0:sentinel] = torch.FloatTensor(np.sin(position_enc[:, 0::2]))\n         out[:, sentinel:] = torch.FloatTensor(np.cos(position_enc[:, 1::2]))\n-        out.detach_()\n-        return out\n+        self.weight = nn.Parameter(out, requires_grad=False)\n \n     @torch.no_grad()\n     def forward(self, input_ids_shape: torch.Size, past_key_values_length: int = 0) -> torch.Tensor:\n@@ -887,7 +885,7 @@ def _init_weights(self, module):\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, InformerSinusoidalPositionalEmbedding):\n-            module.weight = module._init_weight(module.weight)\n+            module._init_weight()\n         elif isinstance(module, nn.Embedding):\n             module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:"
        },
        {
            "sha": "8c31521a3f6d128bec84bd011e353e7818a2af6b",
            "filename": "src/transformers/models/layoutlm/modeling_layoutlm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Flayoutlm%2Fmodeling_layoutlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Flayoutlm%2Fmodeling_layoutlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flayoutlm%2Fmodeling_layoutlm.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -635,6 +635,8 @@ def _init_weights(self, module):\n         elif isinstance(module, LayoutLMLayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, LayoutLMLMPredictionHead):\n+            module.bias.data.zero_()\n \n \n LAYOUTLM_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "8cb9cbdf959d42bea767082accaec9ed587b9496",
            "filename": "src/transformers/models/layoutlmv2/modeling_layoutlmv2.py",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fmodeling_layoutlmv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fmodeling_layoutlmv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flayoutlmv2%2Fmodeling_layoutlmv2.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -48,6 +48,10 @@\n     import detectron2\n     from detectron2.modeling import META_ARCH_REGISTRY\n \n+    # This is needed as otherwise their overload will break sequential loading by overwriting buffer over and over. See\n+    # https://github.com/facebookresearch/detectron2/blob/9604f5995cc628619f0e4fd913453b4d7d61db3f/detectron2/layers/batch_norm.py#L83-L86\n+    detectron2.layers.batch_norm.FrozenBatchNorm2d._load_from_state_dict = torch.nn.Module._load_from_state_dict\n+\n logger = logging.get_logger(__name__)\n \n _CHECKPOINT_FOR_DOC = \"microsoft/layoutlmv2-base-uncased\"\n@@ -510,6 +514,10 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, LayoutLMv2SelfAttention):\n+            if self.config.fast_qkv:\n+                module.q_bias.data.zero_()\n+                module.v_bias.data.zero_()\n         elif isinstance(module, LayoutLMv2Model):\n             if hasattr(module, \"visual_segment_embedding\"):\n                 module.visual_segment_embedding.data.normal_(mean=0.0, std=self.config.initializer_range)"
        },
        {
            "sha": "8c79ae42f0e594925c40c20523894f1306352eee",
            "filename": "src/transformers/models/layoutlmv3/modeling_layoutlmv3.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Flayoutlmv3%2Fmodeling_layoutlmv3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Flayoutlmv3%2Fmodeling_layoutlmv3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flayoutlmv3%2Fmodeling_layoutlmv3.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -374,6 +374,10 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, LayoutLMv3Model):\n+            if self.config.visual_embed:\n+                module.cls_token.data.zero_()\n+                module.pos_embed.data.zero_()\n \n \n class LayoutLMv3SelfAttention(nn.Module):"
        },
        {
            "sha": "b3d057fd648f41972cdf131a31ec651329646a73",
            "filename": "src/transformers/models/lilt/modeling_lilt.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Flilt%2Fmodeling_lilt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Flilt%2Fmodeling_lilt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flilt%2Fmodeling_lilt.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -579,7 +579,6 @@ class LiltPreTrainedModel(PreTrainedModel):\n     supports_gradient_checkpointing = True\n     _no_split_modules = []\n \n-    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights\n     def _init_weights(self, module):\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(module, nn.Linear):"
        },
        {
            "sha": "1b8fb938a2eaa0c0e228cfc7ebc53cbf696349b2",
            "filename": "src/transformers/models/lxmert/modeling_lxmert.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Flxmert%2Fmodeling_lxmert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Flxmert%2Fmodeling_lxmert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flxmert%2Fmodeling_lxmert.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -790,6 +790,8 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, LxmertLMPredictionHead):\n+            module.bias.data.zero_()\n \n \n LXMERT_START_DOCSTRING = r\"\"\"\n@@ -1072,6 +1074,9 @@ def __init__(self, config):\n             }\n         self.visual_losses = visual_losses\n \n+    def _tie_weights(self):\n+        self.cls.predictions.decoder.weight = self.lxmert.embeddings.word_embeddings.weight\n+\n     def resize_token_embeddings(\n         self, new_num_tokens: int, pad_to_multiple_of: Optional[int] = None, mean_resizing: bool = True\n     ) -> nn.Embedding:"
        },
        {
            "sha": "6d69e21213d784787823dad8487e910e167bb49e",
            "filename": "src/transformers/models/marian/modeling_marian.py",
            "status": "modified",
            "additions": 5,
            "deletions": 7,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fmarian%2Fmodeling_marian.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fmarian%2Fmodeling_marian.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmarian%2Fmodeling_marian.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -74,22 +74,20 @@ class MarianSinusoidalPositionalEmbedding(nn.Embedding):\n     def __init__(self, num_positions: int, embedding_dim: int, padding_idx: Optional[int] = None) -> None:\n         super().__init__(num_positions, embedding_dim)\n \n-    @staticmethod\n-    def _init_weight(out: nn.Parameter) -> nn.Parameter:\n+    def _init_weight(self):\n         \"\"\"\n         Identical to the XLM create_sinusoidal_embeddings except features are not interleaved. The cos features are in\n         the 2nd half of the vector. [dim // 2:]\n         \"\"\"\n-        n_pos, dim = out.shape\n+        n_pos, dim = self.weight.shape\n         position_enc = np.array(\n             [[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)]\n         )\n-        out.requires_grad = False  # set early to avoid an error in pytorch-1.8+\n+        out = torch.empty(n_pos, dim, dtype=self.weight.dtype, requires_grad=False)\n         sentinel = dim // 2 if dim % 2 == 0 else (dim // 2) + 1\n         out[:, 0:sentinel] = torch.FloatTensor(np.sin(position_enc[:, 0::2]))\n         out[:, sentinel:] = torch.FloatTensor(np.cos(position_enc[:, 1::2]))\n-        out.detach_()\n-        return out\n+        self.weight = nn.Parameter(out, requires_grad=False)\n \n     @torch.no_grad()\n     def forward(self, input_ids_shape: torch.Size, past_key_values_length: int = 0) -> torch.Tensor:\n@@ -467,7 +465,7 @@ def _init_weights(self, module: Union[nn.Linear, nn.Embedding, MarianSinusoidalP\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, MarianSinusoidalPositionalEmbedding):\n-            module.weight = module._init_weight(module.weight)\n+            module._init_weight()\n         elif isinstance(module, nn.Embedding):\n             module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:"
        },
        {
            "sha": "f47483d9d8611f9392347d0cbc201df9724cd743",
            "filename": "src/transformers/models/markuplm/modeling_markuplm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fmarkuplm%2Fmodeling_markuplm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fmarkuplm%2Fmodeling_markuplm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmarkuplm%2Fmodeling_markuplm.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -731,6 +731,8 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, MarkupLMLMPredictionHead):\n+            module.bias.data.zero_()\n \n     @classmethod\n     def from_pretrained(cls, pretrained_model_name_or_path: Optional[Union[str, os.PathLike]], *model_args, **kwargs):"
        },
        {
            "sha": "4a8d0b002c6bbba2ca8051e168f5b5c9758452db",
            "filename": "src/transformers/models/maskformer/modeling_maskformer_swin.py",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fmodeling_maskformer_swin.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fmodeling_maskformer_swin.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmaskformer%2Fmodeling_maskformer_swin.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -766,7 +766,6 @@ def forward(\n         )\n \n \n-# Copied from transformers.models.swin.modeling_swin.SwinPreTrainedModel with Swin->MaskFormerSwin, swin->model\n class MaskFormerSwinPreTrainedModel(PreTrainedModel):\n     \"\"\"\n     An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained\n@@ -790,6 +789,11 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, MaskFormerSwinEmbeddings):\n+            if module.position_embeddings is not None:\n+                module.position_embeddings.data.zero_()\n+        elif isinstance(module, MaskFormerSwinSelfAttention):\n+            module.relative_position_bias_table.data.zero_()\n \n \n class MaskFormerSwinModel(MaskFormerSwinPreTrainedModel):"
        },
        {
            "sha": "82ac64c9a40f10f5f917ab576ea35080341f89b7",
            "filename": "src/transformers/models/musicgen/modeling_musicgen.py",
            "status": "modified",
            "additions": 5,
            "deletions": 21,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fmusicgen%2Fmodeling_musicgen.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fmusicgen%2Fmodeling_musicgen.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmusicgen%2Fmodeling_musicgen.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -718,6 +718,11 @@ def _init_weights(self, module):\n             module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n+        elif isinstance(module, MusicgenSinusoidalPositionalEmbedding):\n+            weights = module.get_embedding(*module.weights.shape)\n+            weights = nn.Parameter(weights, requires_grad=False)\n+            weights.detach_()\n+            module.weights = weights\n \n \n MUSICGEN_START_DOCSTRING = r\"\"\"\n@@ -1805,27 +1810,6 @@ def get_output_embeddings(self):\n     def set_output_embeddings(self, new_embeddings):\n         return self.decoder.set_output_embeddings(new_embeddings)\n \n-    @classmethod\n-    def from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs):\n-        r\"\"\"\n-        Example:\n-\n-        ```python\n-        >>> from transformers import MusicgenForConditionalGeneration\n-\n-        >>> model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n-        ```\"\"\"\n-\n-        # At the moment fast initialization is not supported for composite models\n-        if kwargs.get(\"_fast_init\", False):\n-            logger.warning(\n-                \"Fast initialization is currently not supported for MusicgenForConditionalGeneration. \"\n-                \"Falling back to slow initialization...\"\n-            )\n-        kwargs[\"_fast_init\"] = False\n-\n-        return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n-\n     @classmethod\n     def from_sub_models_pretrained(\n         cls,"
        },
        {
            "sha": "a43ecaa04c366b6d429ba4d578e91a342473d586",
            "filename": "src/transformers/models/musicgen_melody/modeling_musicgen_melody.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fmusicgen_melody%2Fmodeling_musicgen_melody.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fmusicgen_melody%2Fmodeling_musicgen_melody.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmusicgen_melody%2Fmodeling_musicgen_melody.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -677,6 +677,11 @@ def _init_weights(self, module):\n             module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n+        elif isinstance(module, MusicgenMelodySinusoidalPositionalEmbedding):\n+            weights = module.get_embedding(*module.weights.shape)\n+            weights = nn.Parameter(weights, requires_grad=False)\n+            weights.detach_()\n+            module.weights = weights\n \n \n MUSICGEN_MELODY_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "11bb17cd28ab06de20f6372f7c504b947e51a7e1",
            "filename": "src/transformers/models/pegasus/modeling_pegasus.py",
            "status": "modified",
            "additions": 7,
            "deletions": 9,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fpegasus%2Fmodeling_pegasus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fpegasus%2Fmodeling_pegasus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpegasus%2Fmodeling_pegasus.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -75,22 +75,20 @@ class PegasusSinusoidalPositionalEmbedding(nn.Embedding):\n     def __init__(self, num_positions: int, embedding_dim: int, padding_idx: Optional[int] = None) -> None:\n         super().__init__(num_positions, embedding_dim)\n \n-    @staticmethod\n-    def _init_weight(out: nn.Parameter) -> nn.Parameter:\n+    def _init_weight(self):\n         \"\"\"\n         Identical to the XLM create_sinusoidal_embeddings except features are not interleaved. The cos features are in\n         the 2nd half of the vector. [dim // 2:]\n         \"\"\"\n-        n_pos, dim = out.shape\n+        n_pos, dim = self.weight.shape\n         position_enc = np.array(\n             [[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)]\n         )\n-        out.requires_grad = False  # set early to avoid an error in pytorch-1.8+\n+        out = torch.empty(n_pos, dim, dtype=self.weight.dtype, requires_grad=False)\n         sentinel = dim // 2 if dim % 2 == 0 else (dim // 2) + 1\n         out[:, 0:sentinel] = torch.FloatTensor(np.sin(position_enc[:, 0::2]))\n         out[:, sentinel:] = torch.FloatTensor(np.cos(position_enc[:, 1::2]))\n-        out.detach_()\n-        return out\n+        self.weight = nn.Parameter(out, requires_grad=False)\n \n     @torch.no_grad()\n     def forward(self, input_ids_shape: torch.Size, past_key_values_length: int = 0) -> torch.Tensor:\n@@ -466,7 +464,7 @@ def _init_weights(self, module):\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, PegasusSinusoidalPositionalEmbedding):\n-            module.weight = module._init_weight(module.weight)\n+            module._init_weight()\n         elif isinstance(module, nn.Embedding):\n             module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n@@ -662,7 +660,7 @@ def resize_position_embeddings(self, new_num_position_embeddings: int):\n             self.config.d_model,\n             self.padding_idx,\n         )\n-        self.embed_positions.weight = self.embed_positions._init_weight(self.embed_positions.weight)\n+        self.embed_positions._init_weight()\n         self.embed_positions.to(self.device)\n \n     def get_position_embeddings(self) -> nn.Embedding:\n@@ -866,7 +864,7 @@ def resize_position_embeddings(self, new_num_position_embeddings: int):\n             self.config.d_model,\n             self.padding_idx,\n         )\n-        self.embed_positions.weight = self.embed_positions._init_weight(self.embed_positions.weight)\n+        self.embed_positions._init_weight()\n         self.embed_positions.to(self.device)\n \n     def get_position_embeddings(self) -> nn.Embedding:"
        },
        {
            "sha": "e84cd45453edc52bb0a6412c66ffba42c81aceb0",
            "filename": "src/transformers/models/rag/modeling_rag.py",
            "status": "modified",
            "additions": 0,
            "deletions": 7,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Frag%2Fmodeling_rag.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Frag%2Fmodeling_rag.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frag%2Fmodeling_rag.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -235,13 +235,6 @@ class RagPreTrainedModel(PreTrainedModel):\n     _supports_flash_attn_2 = True\n     _supports_sdpa = True\n \n-    @classmethod\n-    def from_pretrained(cls, *args, **kwargs):\n-        # At the moment fast initialization is not supported\n-        # for composite models\n-        kwargs[\"_fast_init\"] = False\n-        return super().from_pretrained(*args, **kwargs)\n-\n     @classmethod\n     def from_pretrained_question_encoder_generator(\n         cls,"
        },
        {
            "sha": "f2dfa19a6a50957e43825c9c723fe31c53375a37",
            "filename": "src/transformers/models/roberta/modeling_roberta.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Froberta%2Fmodeling_roberta.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Froberta%2Fmodeling_roberta.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froberta%2Fmodeling_roberta.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -698,7 +698,7 @@ class RobertaPreTrainedModel(PreTrainedModel):\n     _no_split_modules = [\"RobertaEmbeddings\", \"RobertaSelfAttention\", \"RobertaSdpaSelfAttention\"]\n     _supports_sdpa = True\n \n-    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights\n+    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights with BertLMPredictionHead->RobertaLMHead\n     def _init_weights(self, module):\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(module, nn.Linear):\n@@ -714,6 +714,8 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, RobertaLMHead):\n+            module.bias.data.zero_()\n \n \n ROBERTA_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "6b0c40b222c19685f269609d44cc5a39fb553696",
            "filename": "src/transformers/models/roberta_prelayernorm/modeling_roberta_prelayernorm.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fmodeling_roberta_prelayernorm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fmodeling_roberta_prelayernorm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fmodeling_roberta_prelayernorm.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -581,7 +581,7 @@ class RobertaPreLayerNormPreTrainedModel(PreTrainedModel):\n     supports_gradient_checkpointing = True\n     _no_split_modules = [\"RobertaPreLayerNormEmbeddings\", \"RobertaPreLayerNormSelfAttention\"]\n \n-    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights\n+    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights with BertLMPredictionHead->RobertaPreLayerNormLMHead\n     def _init_weights(self, module):\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(module, nn.Linear):\n@@ -597,6 +597,8 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, RobertaPreLayerNormLMHead):\n+            module.bias.data.zero_()\n \n \n ROBERTA_PRELAYERNORM_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "445f6edb1c899f7721a5789ea62b26d702e79e71",
            "filename": "src/transformers/models/roformer/modeling_roformer.py",
            "status": "modified",
            "additions": 5,
            "deletions": 7,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Froformer%2Fmodeling_roformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Froformer%2Fmodeling_roformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froformer%2Fmodeling_roformer.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -60,22 +60,20 @@ class RoFormerSinusoidalPositionalEmbedding(nn.Embedding):\n     def __init__(self, num_positions: int, embedding_dim: int, padding_idx: Optional[int] = None) -> None:\n         super().__init__(num_positions, embedding_dim)\n \n-    @staticmethod\n-    def _init_weight(out: nn.Parameter) -> nn.Parameter:\n+    def _init_weight(self):\n         \"\"\"\n         Identical to the XLM create_sinusoidal_embeddings except features are not interleaved. The cos features are in\n         the 2nd half of the vector. [dim // 2:]\n         \"\"\"\n-        n_pos, dim = out.shape\n+        n_pos, dim = self.weight.shape\n         position_enc = np.array(\n             [[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)]\n         )\n-        out.requires_grad = False  # set early to avoid an error in pytorch-1.8+\n+        out = torch.empty(n_pos, dim, dtype=self.weight.dtype, requires_grad=False)\n         sentinel = dim // 2 if dim % 2 == 0 else (dim // 2) + 1\n         out[:, 0:sentinel] = torch.FloatTensor(np.sin(position_enc[:, 0::2]))\n         out[:, sentinel:] = torch.FloatTensor(np.cos(position_enc[:, 1::2]))\n-        out.detach_()\n-        return out\n+        self.weight = nn.Parameter(out, requires_grad=False)\n \n     @torch.no_grad()\n     def forward(self, input_ids_shape: torch.Size, past_key_values_length: int = 0) -> torch.Tensor:\n@@ -693,7 +691,7 @@ def _init_weights(self, module):\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, RoFormerSinusoidalPositionalEmbedding):\n-            module.weight = module._init_weight(module.weight)\n+            module._init_weight()\n         elif isinstance(module, nn.Embedding):\n             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n             if module.padding_idx is not None:"
        },
        {
            "sha": "dd36b23ba66a1d0469818011528432029c5d5184",
            "filename": "src/transformers/models/sam/modeling_sam.py",
            "status": "modified",
            "additions": 18,
            "deletions": 3,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -655,9 +655,10 @@ def forward(self, masks):\n \n \n class SamPromptEncoder(nn.Module):\n-    def __init__(self, config: SamPromptEncoderConfig, shared_patch_embedding):\n+    def __init__(self, config: SamPromptEncoderConfig):\n         super().__init__()\n-        self.shared_embedding = shared_patch_embedding\n+        self.shared_embedding = SamPositionalEmbedding(config.vision_config)\n+        config = config.prompt_encoder_config\n         self.mask_embed = SamMaskEmbedding(config)\n         self.no_mask_embed = nn.Embedding(1, config.hidden_size)\n \n@@ -1198,6 +1199,13 @@ def _init_weights(self, module):\n             module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n+        elif isinstance(module, (SamLayerNorm, nn.LayerNorm)):\n+            module.weight.data.fill_(1.0)\n+            module.bias.data.zero_()\n+        elif isinstance(module, SamVisionAttention):\n+            if module.use_rel_pos:\n+                module.rel_pos_h.data.zero_()\n+                module.rel_pos_w.data.zero_()\n \n \n SAM_START_DOCSTRING = r\"\"\"\n@@ -1348,17 +1356,24 @@ def forward(\n )\n class SamModel(SamPreTrainedModel):\n     _tied_weights_keys = [\"prompt_encoder.shared_embedding.positional_embedding\"]\n+    # need to be ignored, as it's a buffer and will not be correctly detected as tied weight\n+    _keys_to_ignore_on_load_missing = [\"prompt_encoder.shared_embedding.positional_embedding\"]\n \n     def __init__(self, config):\n         super().__init__(config)\n         self.shared_image_embedding = SamPositionalEmbedding(config.vision_config)\n \n         self.vision_encoder = SamVisionEncoder(config.vision_config)\n-        self.prompt_encoder = SamPromptEncoder(config.prompt_encoder_config, self.shared_image_embedding)\n+        self.prompt_encoder = SamPromptEncoder(config)\n         self.mask_decoder = SamMaskDecoder(config.mask_decoder_config)\n \n         self.post_init()\n \n+    def _tie_weights(self):\n+        self.prompt_encoder.shared_embedding.positional_embedding.data = (\n+            self.shared_image_embedding.positional_embedding.data\n+        )\n+\n     def get_input_embeddings(self):\n         return self.vision_encoder.get_input_embeddings()\n "
        },
        {
            "sha": "3e303b1bff0e162c929fdb34cb2ce68a54fae344",
            "filename": "src/transformers/models/segformer/modeling_segformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fsegformer%2Fmodeling_segformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fsegformer%2Fmodeling_segformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsegformer%2Fmodeling_segformer.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -463,7 +463,7 @@ def _init_weights(self, module):\n             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n             if module.padding_idx is not None:\n                 module.weight.data[module.padding_idx].zero_()\n-        elif isinstance(module, nn.LayerNorm):\n+        elif isinstance(module, (nn.LayerNorm, nn.BatchNorm2d)):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n "
        },
        {
            "sha": "425c3f7d5b35e9fbd362386f7b09a85531595299",
            "filename": "src/transformers/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py",
            "status": "modified",
            "additions": 0,
            "deletions": 11,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fspeech_encoder_decoder%2Fmodeling_speech_encoder_decoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fspeech_encoder_decoder%2Fmodeling_speech_encoder_decoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fspeech_encoder_decoder%2Fmodeling_speech_encoder_decoder.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -277,17 +277,6 @@ def freeze_feature_encoder(self):\n         \"\"\"\n         self.encoder.freeze_feature_encoder()\n \n-    @classmethod\n-    def from_pretrained(cls, *args, **kwargs):\n-        # At the moment fast initialization is not supported for composite models\n-        if kwargs.get(\"_fast_init\", False):\n-            logger.warning(\n-                \"Fast initialization is currently not supported for SpeechEncoderDecoderModel. \"\n-                \"Falling back to slow initialization...\"\n-            )\n-        kwargs[\"_fast_init\"] = False\n-        return super().from_pretrained(*args, **kwargs)\n-\n     @classmethod\n     def from_encoder_decoder_pretrained(\n         cls,"
        },
        {
            "sha": "295a427e6a72e0a0dafc36611db0c7a83e91fcb7",
            "filename": "src/transformers/models/splinter/modeling_splinter.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fsplinter%2Fmodeling_splinter.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fsplinter%2Fmodeling_splinter.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsplinter%2Fmodeling_splinter.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -520,7 +520,6 @@ class SplinterPreTrainedModel(PreTrainedModel):\n     base_model_prefix = \"splinter\"\n     supports_gradient_checkpointing = True\n \n-    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights\n     def _init_weights(self, module):\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(module, nn.Linear):"
        },
        {
            "sha": "46dff663d171d155424005cc478dae99a49b1662",
            "filename": "src/transformers/models/swin/modeling_swin.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fswin%2Fmodeling_swin.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fswin%2Fmodeling_swin.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fswin%2Fmodeling_swin.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -943,6 +943,13 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, SwinEmbeddings):\n+            if module.mask_token is not None:\n+                module.mask_token.data.zero_()\n+            if module.position_embeddings is not None:\n+                module.position_embeddings.data.zero_()\n+        elif isinstance(module, SwinSelfAttention):\n+            module.relative_position_bias_table.data.zero_()\n \n \n SWIN_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "46e0a1ca9ad79bf555a4806a17e7218e399b6171",
            "filename": "src/transformers/models/swinv2/modeling_swinv2.py",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fswinv2%2Fmodeling_swinv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fswinv2%2Fmodeling_swinv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fswinv2%2Fmodeling_swinv2.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -976,7 +976,6 @@ def forward(\n         )\n \n \n-# Copied from transformers.models.swin.modeling_swin.SwinPreTrainedModel with Swin->Swinv2,swin->swinv2\n class Swinv2PreTrainedModel(PreTrainedModel):\n     \"\"\"\n     An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained\n@@ -1000,6 +999,13 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, Swinv2Embeddings):\n+            if module.mask_token is not None:\n+                module.mask_token.data.zero_()\n+            if module.position_embeddings is not None:\n+                module.position_embeddings.data.zero_()\n+        elif isinstance(module, Swinv2SelfAttention):\n+            module.logit_scale.data.fill_(math.log(10))\n \n \n SWINV2_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "5a2450b9a86f550b68454710ed35794ef952959f",
            "filename": "src/transformers/models/tapas/modeling_tapas.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Ftapas%2Fmodeling_tapas.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Ftapas%2Fmodeling_tapas.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftapas%2Fmodeling_tapas.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -719,7 +719,7 @@ class TapasPreTrainedModel(PreTrainedModel):\n     supports_gradient_checkpointing = True\n     _supports_param_buffer_assignment = False\n \n-    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights\n+    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights with Bert->Tapas\n     def _init_weights(self, module):\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(module, nn.Linear):\n@@ -735,6 +735,8 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, TapasLMPredictionHead):\n+            module.bias.data.zero_()\n \n \n TAPAS_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "9a87d19d1602476231c6d93f9e55f3c18e5dabce",
            "filename": "src/transformers/models/time_series_transformer/modeling_time_series_transformer.py",
            "status": "modified",
            "additions": 5,
            "deletions": 7,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Ftime_series_transformer%2Fmodeling_time_series_transformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Ftime_series_transformer%2Fmodeling_time_series_transformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftime_series_transformer%2Fmodeling_time_series_transformer.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -234,22 +234,20 @@ class TimeSeriesSinusoidalPositionalEmbedding(nn.Embedding):\n     def __init__(self, num_positions: int, embedding_dim: int, padding_idx: Optional[int] = None) -> None:\n         super().__init__(num_positions, embedding_dim)\n \n-    @staticmethod\n-    def _init_weight(out: nn.Parameter) -> nn.Parameter:\n+    def _init_weight(self):\n         \"\"\"\n         Identical to the XLM create_sinusoidal_embeddings except features are not interleaved. The cos features are in\n         the 2nd half of the vector. [dim // 2:]\n         \"\"\"\n-        n_pos, dim = out.shape\n+        n_pos, dim = self.weight.shape\n         position_enc = np.array(\n             [[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)]\n         )\n-        out.requires_grad = False  # set early to avoid an error in pytorch-1.8+\n+        out = torch.empty(n_pos, dim, dtype=self.weight.dtype, requires_grad=False)\n         sentinel = dim // 2 if dim % 2 == 0 else (dim // 2) + 1\n         out[:, 0:sentinel] = torch.FloatTensor(np.sin(position_enc[:, 0::2]))\n         out[:, sentinel:] = torch.FloatTensor(np.cos(position_enc[:, 1::2]))\n-        out.detach_()\n-        return out\n+        self.weight = nn.Parameter(out, requires_grad=False)\n \n     @torch.no_grad()\n     def forward(self, input_ids_shape: torch.Size, past_key_values_length: int = 0) -> torch.Tensor:\n@@ -640,7 +638,7 @@ def _init_weights(self, module):\n             if module.bias is not None:\n                 module.bias.data.zero_()\n         elif isinstance(module, TimeSeriesSinusoidalPositionalEmbedding):\n-            module.weight = module._init_weight(module.weight)\n+            module._init_weight()\n         elif isinstance(module, nn.Embedding):\n             module.weight.data.normal_(mean=0.0, std=std)\n             if module.padding_idx is not None:"
        },
        {
            "sha": "7451973b5b654d7fdd335569c35edb8c4442ae8c",
            "filename": "src/transformers/models/vision_encoder_decoder/modeling_vision_encoder_decoder.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fvision_encoder_decoder%2Fmodeling_vision_encoder_decoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fvision_encoder_decoder%2Fmodeling_vision_encoder_decoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvision_encoder_decoder%2Fmodeling_vision_encoder_decoder.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -367,14 +367,6 @@ def from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs):\n \n                 return model\n \n-        # At the moment fast initialization is not supported for composite models\n-        if kwargs.get(\"_fast_init\", False):\n-            logger.warning(\n-                \"Fast initialization is currently not supported for VisionEncoderDecoderModel. \"\n-                \"Falling back to slow initialization...\"\n-            )\n-        kwargs[\"_fast_init\"] = False\n-\n         return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)\n \n     @classmethod"
        },
        {
            "sha": "3e770f6935d86e37a1a6b0579940142a411da0da",
            "filename": "src/transformers/models/vision_text_dual_encoder/modeling_vision_text_dual_encoder.py",
            "status": "modified",
            "additions": 0,
            "deletions": 7,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fvision_text_dual_encoder%2Fmodeling_vision_text_dual_encoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fvision_text_dual_encoder%2Fmodeling_vision_text_dual_encoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvision_text_dual_encoder%2Fmodeling_vision_text_dual_encoder.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -407,13 +407,6 @@ def forward(\n             vision_model_output=vision_outputs,\n         )\n \n-    @classmethod\n-    def from_pretrained(cls, *args, **kwargs):\n-        # At the moment fast initialization is not supported\n-        # for composite models\n-        kwargs[\"_fast_init\"] = False\n-        return super().from_pretrained(*args, **kwargs)\n-\n     @classmethod\n     def from_vision_text_pretrained(\n         cls,"
        },
        {
            "sha": "d757aeaf28b1ac0a32f042d98ef4bf929fe7f910",
            "filename": "src/transformers/models/vit/modeling_vit.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fvit%2Fmodeling_vit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fvit%2Fmodeling_vit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvit%2Fmodeling_vit.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -497,6 +497,9 @@ def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> No\n                 std=self.config.initializer_range,\n             ).to(module.cls_token.dtype)\n \n+            if module.mask_token is not None:\n+                module.mask_token.data.zero_()\n+\n \n VIT_START_DOCSTRING = r\"\"\"\n     This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass. Use it"
        },
        {
            "sha": "e4f6a868accaf906c0ddb0060106ac15127c36ed",
            "filename": "src/transformers/models/vit_mae/modeling_vit_mae.py",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fvit_mae%2Fmodeling_vit_mae.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fvit_mae%2Fmodeling_vit_mae.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvit_mae%2Fmodeling_vit_mae.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -208,7 +208,6 @@ def __init__(self, config):\n         )\n         self.patch_size = config.patch_size\n         self.config = config\n-        self.initialize_weights()\n \n     def initialize_weights(self):\n         # initialize (and freeze) position embeddings by sin-cos embedding\n@@ -660,6 +659,11 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, ViTMAEEmbeddings):\n+            module.initialize_weights()\n+        elif isinstance(module, ViTMAEDecoder):\n+            module.mask_token.data.zero_()\n+            module.decoder_pos_embed.data.zero_()\n \n \n VIT_MAE_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "fb5a3d56ba607f2319ca2132e2f6b6ad9341bafd",
            "filename": "src/transformers/models/vit_msn/modeling_vit_msn.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fvit_msn%2Fmodeling_vit_msn.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fvit_msn%2Fmodeling_vit_msn.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvit_msn%2Fmodeling_vit_msn.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -480,6 +480,11 @@ def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> No\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, ViTMSNEmbeddings):\n+            module.cls_token.data.zero_()\n+            module.position_embeddings.data.zero_()\n+            if module.mask_token is not None:\n+                module.mask_token.data.zero_()\n \n \n VIT_MSN_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "669106239a06a83cb1f4737f76eb7a5bed474227",
            "filename": "src/transformers/models/vivit/modeling_vivit.py",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fvivit%2Fmodeling_vivit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fvivit%2Fmodeling_vivit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvivit%2Fmodeling_vivit.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -485,8 +485,9 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n-        elif isinstance(module, nn.Parameter):\n-            module.data.normal_(mean=0.0, std=self.config.initializer_range)\n+        elif isinstance(module, VivitEmbeddings):\n+            module.cls_token.data.zero_()\n+            module.position_embeddings.data.zero_()\n \n \n VIVIT_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "1fe5823c20660b485f1ddc0454e4514971ead2da",
            "filename": "src/transformers/models/xlm_roberta/modeling_xlm_roberta.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fxlm_roberta%2Fmodeling_xlm_roberta.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fxlm_roberta%2Fmodeling_xlm_roberta.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fxlm_roberta%2Fmodeling_xlm_roberta.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -700,7 +700,7 @@ class XLMRobertaPreTrainedModel(PreTrainedModel):\n     _no_split_modules = [\"XLMRobertaEmbeddings\", \"XLMRobertaSelfAttention\", \"XLMRobertaSdpaSelfAttention\"]\n     _supports_sdpa = True\n \n-    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights\n+    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights with BertLMPredictionHead->XLMRobertaLMHead\n     def _init_weights(self, module):\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(module, nn.Linear):\n@@ -716,6 +716,8 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, XLMRobertaLMHead):\n+            module.bias.data.zero_()\n \n \n XLM_ROBERTA_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "ad43c7903f4f1f48e489d9397c1466d16a615fcb",
            "filename": "src/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fxlm_roberta_xl%2Fmodeling_xlm_roberta_xl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fxlm_roberta_xl%2Fmodeling_xlm_roberta_xl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fxlm_roberta_xl%2Fmodeling_xlm_roberta_xl.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -692,7 +692,7 @@ class XLMRobertaXLPreTrainedModel(PreTrainedModel):\n     _no_split_modules = [\"XLMRobertaXLEmbeddings\", \"XLMRobertaXLLayer\"]\n     _supports_sdpa = True\n \n-    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights\n+    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights with BertLMPredictionHead->XLMRobertaXLLMHead\n     def _init_weights(self, module):\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(module, nn.Linear):\n@@ -708,6 +708,8 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, XLMRobertaXLLMHead):\n+            module.bias.data.zero_()\n \n \n XLM_ROBERTA_XL_START_DOCSTRING = r\"\"\""
        },
        {
            "sha": "21aad7188e0e267fb181143187bb90f59525de64",
            "filename": "src/transformers/models/xmod/modeling_xmod.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fxmod%2Fmodeling_xmod.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fmodels%2Fxmod%2Fmodeling_xmod.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fxmod%2Fmodeling_xmod.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -645,7 +645,7 @@ class XmodPreTrainedModel(PreTrainedModel):\n     base_model_prefix = \"roberta\"\n     supports_gradient_checkpointing = True\n \n-    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights\n+    # Copied from transformers.models.bert.modeling_bert.BertPreTrainedModel._init_weights with BertLMPredictionHead->XmodLMHead\n     def _init_weights(self, module):\n         \"\"\"Initialize the weights\"\"\"\n         if isinstance(module, nn.Linear):\n@@ -661,6 +661,8 @@ def _init_weights(self, module):\n         elif isinstance(module, nn.LayerNorm):\n             module.bias.data.zero_()\n             module.weight.data.fill_(1.0)\n+        elif isinstance(module, XmodLMHead):\n+            module.bias.data.zero_()\n \n     def set_default_language(self, language: str):\n         \"\"\""
        },
        {
            "sha": "bbed8317049f9e2530c03dd40730e9c79cb879b2",
            "filename": "src/transformers/quantizers/quantizers_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 7,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fquantizers%2Fquantizers_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/src%2Ftransformers%2Fquantizers%2Fquantizers_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizers_utils.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -16,11 +16,6 @@\n \n def get_module_from_name(module, tensor_name: str) -> Tuple[Any, str]:\n     if \".\" in tensor_name:\n-        splits = tensor_name.split(\".\")\n-        for split in splits[:-1]:\n-            new_module = getattr(module, split)\n-            if new_module is None:\n-                raise ValueError(f\"{module} has no attribute {split}.\")\n-            module = new_module\n-        tensor_name = splits[-1]\n+        module_name, tensor_name = tensor_name.rsplit(\".\", 1)\n+        module = module.get_submodule(module_name)\n     return module, tensor_name"
        },
        {
            "sha": "08d4ea2210507b563d1948f04097e2dc3eda49bc",
            "filename": "tests/models/align/test_modeling_align.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Falign%2Ftest_modeling_align.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Falign%2Ftest_modeling_align.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Falign%2Ftest_modeling_align.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -380,14 +380,6 @@ def test_inputs_embeds(self):\n     def test_inputs_embeds_matches_input_ids(self):\n         pass\n \n-    @unittest.skip(reason=\"AlignTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"AlignTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"kakaobrain/align-base\""
        },
        {
            "sha": "a111181b699d93638a095062610b0c5c7459e65f",
            "filename": "tests/models/altclip/test_modeling_altclip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Faltclip%2Ftest_modeling_altclip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Faltclip%2Ftest_modeling_altclip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Faltclip%2Ftest_modeling_altclip.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -198,14 +198,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"AltCLIPVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"AltCLIPVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"AltCLIPVisionModel use the same cv backbone with CLIP model.\")\n     def test_model_from_pretrained(self):\n         pass\n@@ -357,14 +349,6 @@ def test_hidden_states_output(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"AltCLIPTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"AltCLIPTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"BAAI/AltCLIP\""
        },
        {
            "sha": "50c5cd37d08905eb3f02bdb1dfba6fcc99e7ed30",
            "filename": "tests/models/bart/test_modeling_bart.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fbart%2Ftest_modeling_bart.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fbart%2Ftest_modeling_bart.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbart%2Ftest_modeling_bart.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -1535,7 +1535,3 @@ def test_decoder_model_attn_mask_past(self):\n     @unittest.skip(reason=\"Decoder cannot keep gradients\")\n     def test_retain_grad_hidden_states_attentions(self):\n         return\n-\n-    @unittest.skip\n-    def test_save_load_fast_init_from_base(self):\n-        pass"
        },
        {
            "sha": "1bf594d3c999bce7c07d9bac1a93f3bdd709607d",
            "filename": "tests/models/blip/test_modeling_blip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fblip%2Ftest_modeling_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fblip%2Ftest_modeling_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fblip%2Ftest_modeling_blip.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -213,14 +213,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"BlipVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"BlipVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"Salesforce/blip-vqa-base\"\n@@ -361,14 +353,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"BlipTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"BlipTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"Salesforce/blip-vqa-base\""
        },
        {
            "sha": "d6614c6a2f3fb56132c375dc933fb73b7f120d86",
            "filename": "tests/models/blip/test_modeling_blip_text.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fblip%2Ftest_modeling_blip_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fblip%2Ftest_modeling_blip_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fblip%2Ftest_modeling_blip_text.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -165,14 +165,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"BlipTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"BlipTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"Salesforce/blip-vqa-base\""
        },
        {
            "sha": "ed427af7ee31d4f6f3ebdb5d7934f9a79f9fee57",
            "filename": "tests/models/blip/test_modeling_tf_blip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fblip%2Ftest_modeling_tf_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fblip%2Ftest_modeling_tf_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fblip%2Ftest_modeling_tf_blip.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -179,14 +179,6 @@ def test_model(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    @unittest.skip(reason=\"BlipVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"BlipVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"Salesforce/blip-vqa-base\"\n@@ -307,14 +299,6 @@ def test_model(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"BlipTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"BlipTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"Salesforce/blip-vqa-base\""
        },
        {
            "sha": "082473dfd5074363e5ed9e8f5044c4f86dc5ef48",
            "filename": "tests/models/blip/test_modeling_tf_blip_text.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fblip%2Ftest_modeling_tf_blip_text.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fblip%2Ftest_modeling_tf_blip_text.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fblip%2Ftest_modeling_tf_blip_text.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -163,14 +163,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"BlipTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"BlipTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"Salesforce/blip-vqa-base\""
        },
        {
            "sha": "a360cb98a4bac0efc2854c0a27b70b14231fae91",
            "filename": "tests/models/blip_2/test_modeling_blip_2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 40,
            "changes": 40,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fblip_2%2Ftest_modeling_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fblip_2%2Ftest_modeling_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fblip_2%2Ftest_modeling_blip_2.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -220,14 +220,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"Blip2VisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Blip2VisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"Salesforce/blip2-opt-2.7b\"\n@@ -509,14 +501,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    @unittest.skip(reason=\"There's no base Blip2Model\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"There's no base Blip2Model\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @require_torch_sdpa\n     def test_sdpa_can_dispatch_composite_models(self):\n         \"\"\"\n@@ -954,14 +938,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    @unittest.skip(reason=\"There's no base Blip2Model\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"There's no base Blip2Model\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"Does not work on the tiny model as we keep hitting edge cases.\")\n     def test_cpu_offload(self):\n         pass\n@@ -1245,14 +1221,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_common_attributes(self):\n         pass\n \n-    @unittest.skip(reason=\"Blip2TextModelWithProjection has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Blip2TextModelWithProjection has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     def test_forward_signature(self):\n         config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n \n@@ -1420,14 +1388,6 @@ def test_model_common_attributes(self):\n             x = model.get_output_embeddings()\n             self.assertTrue(x is None or isinstance(x, nn.Linear))\n \n-    @unittest.skip(reason=\"Blip2VisionModelWithProjection has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Blip2VisionModelWithProjection has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     def test_forward_signature(self):\n         config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n "
        },
        {
            "sha": "bc6ff0d6e47eccd70845ab9e3fa25e0e15e78be7",
            "filename": "tests/models/bridgetower/test_modeling_bridgetower.py",
            "status": "modified",
            "additions": 0,
            "deletions": 36,
            "changes": 36,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fbridgetower%2Ftest_modeling_bridgetower.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fbridgetower%2Ftest_modeling_bridgetower.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbridgetower%2Ftest_modeling_bridgetower.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -14,11 +14,8 @@\n # limitations under the License.\n \"\"\"Testing suite for the PyTorch BridgeTower model.\"\"\"\n \n-import tempfile\n import unittest\n \n-import numpy as np\n-\n from transformers import (\n     BridgeTowerConfig,\n     BridgeTowerTextConfig,\n@@ -359,39 +356,6 @@ def test_model_from_pretrained(self):\n         model = BridgeTowerModel.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    @slow\n-    def test_save_load_fast_init_from_base(self):\n-        # Override as it is a slow test on this model\n-        super().test_save_load_fast_init_from_base()\n-\n-    # Override as extracting meaningful tensor from output is different for BridgeTower\n-    def test_save_load(self):\n-        config, input_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-        for model_class in self.all_model_classes:\n-            model = model_class(config)\n-            model.to(torch_device)\n-            model.eval()\n-            with torch.no_grad():\n-                outputs = model(**input_dict)\n-\n-            out_2 = self.extract_output(outputs, model_class.__name__)\n-            out_2 = out_2.cpu().numpy()\n-            out_2[np.isnan(out_2)] = 0\n-\n-            with tempfile.TemporaryDirectory() as tmpdirname:\n-                model.save_pretrained(tmpdirname)\n-                model = model_class.from_pretrained(tmpdirname)\n-                model.to(torch_device)\n-                with torch.no_grad():\n-                    after_outputs = model(**input_dict)\n-\n-                # Make sure we don't have nans\n-                out_1 = self.extract_output(after_outputs, model_class.__name__)\n-                out_1 = out_1.cpu().numpy()\n-                out_1[np.isnan(out_1)] = 0\n-                max_diff = np.amax(np.abs(out_1 - out_2))\n-                self.assertLessEqual(max_diff, 1e-5)\n-\n     # Override this as `hidden states output` is different for BridgeTower\n     def test_hidden_states_output(self):\n         def check_hidden_states_output(inputs_dict, config, model_class):"
        },
        {
            "sha": "9593042883653677241ff00c8ecefcaceae14d81",
            "filename": "tests/models/chinese_clip/test_modeling_chinese_clip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fchinese_clip%2Ftest_modeling_chinese_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fchinese_clip%2Ftest_modeling_chinese_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fchinese_clip%2Ftest_modeling_chinese_clip.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -408,14 +408,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"ChineseCLIPTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"ChineseCLIPTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n \n @require_torch\n class ChineseCLIPVisionModelTest(ModelTesterMixin, unittest.TestCase):\n@@ -488,14 +480,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"ChineseCLIPVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"ChineseCLIPVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"OFA-Sys/chinese-clip-vit-base-patch16\""
        },
        {
            "sha": "21281ced3e8911532da49e67f1f679a1b914f7ec",
            "filename": "tests/models/clap/test_modeling_clap.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fclap%2Ftest_modeling_clap.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fclap%2Ftest_modeling_clap.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fclap%2Ftest_modeling_clap.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -263,14 +263,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"ClapAudioModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"ClapAudioModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"laion/clap-htsat-fused\"\n@@ -432,14 +424,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"ClapTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"ClapTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"laion/clap-htsat-fused\""
        },
        {
            "sha": "5600e67a70ca81e1770c1a528537c225744b0345",
            "filename": "tests/models/clip/test_modeling_clip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fclip%2Ftest_modeling_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fclip%2Ftest_modeling_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fclip%2Ftest_modeling_clip.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -446,14 +446,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"CLIPVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"CLIPVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"openai/clip-vit-base-patch32\"\n@@ -628,14 +620,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"CLIPTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"CLIPTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"openai/clip-vit-base-patch32\""
        },
        {
            "sha": "85115499267c96968cf608309034c1fc7d5011e5",
            "filename": "tests/models/clipseg/test_modeling_clipseg.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fclipseg%2Ftest_modeling_clipseg.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fclipseg%2Ftest_modeling_clipseg.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fclipseg%2Ftest_modeling_clipseg.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -202,14 +202,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"CLIPSegVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"CLIPSegVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"CIDAS/clipseg-rd64-refined\"\n@@ -345,14 +337,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"CLIPSegTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"CLIPSegTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"CIDAS/clipseg-rd64-refined\""
        },
        {
            "sha": "b9d259b1c71230dbfad8464651e1cdc11411c4bb",
            "filename": "tests/models/depth_anything/test_modeling_depth_anything.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fdepth_anything%2Ftest_modeling_depth_anything.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fdepth_anything%2Ftest_modeling_depth_anything.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdepth_anything%2Ftest_modeling_depth_anything.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -181,14 +181,6 @@ def test_training_gradient_checkpointing(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    @unittest.skip(reason=\"Depth Anything with AutoBackbone does not have a base model\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Depth Anything with AutoBackbone does not have a base model\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(\n         reason=\"This architecture seems to not compute gradients properly when using GC, check: https://github.com/huggingface/transformers/pull/27124\"\n     )"
        },
        {
            "sha": "aba1844e3434e101f12502b43846cadb421e9584",
            "filename": "tests/models/diffllama/test_modeling_diffllama.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fdiffllama%2Ftest_modeling_diffllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fdiffllama%2Ftest_modeling_diffllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdiffllama%2Ftest_modeling_diffllama.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -391,10 +391,6 @@ def test_diffllama_token_classification_model(self):\n             (self.model_tester.batch_size, self.model_tester.seq_length, self.model_tester.num_labels),\n         )\n \n-    @unittest.skip(reason=\"DiffLlama buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @parameterized.expand([(\"linear\",), (\"dynamic\",), (\"yarn\",)])\n     def test_model_rope_scaling_from_config(self, scaling_type):\n         config, _ = self.model_tester.prepare_config_and_inputs_for_common()"
        },
        {
            "sha": "e4c40ca80909d6f54584d87619731550632ba576",
            "filename": "tests/models/dpt/test_modeling_dpt_auto_backbone.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_auto_backbone.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_auto_backbone.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt_auto_backbone.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -221,14 +221,6 @@ def test_initialization(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    @unittest.skip(reason=\"DPT with AutoBackbone does not have a base model\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"DPT with AutoBackbone does not have a base model\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(\n         reason=\"This architecture seem to not compute gradients properly when using GC, check: https://github.com/huggingface/transformers/pull/27124\"\n     )"
        },
        {
            "sha": "03b1981dc87dbcd868f8e7a30b7ff49c9f0f43b6",
            "filename": "tests/models/esm/test_modeling_esmfold.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fesm%2Ftest_modeling_esmfold.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fesm%2Ftest_modeling_esmfold.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fesm%2Ftest_modeling_esmfold.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -241,10 +241,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_outputs_equivalence(self):\n         pass\n \n-    @unittest.skip(reason=\"This test doesn't work for ESMFold and doesn't test core functionality\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"ESMFold does not support input chunking.\")\n     def test_feed_forward_chunking(self):\n         pass"
        },
        {
            "sha": "3e3321a3141c4bd388a957ab818e9ec313a2b656",
            "filename": "tests/models/flava/test_modeling_flava.py",
            "status": "modified",
            "additions": 0,
            "deletions": 34,
            "changes": 34,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fflava%2Ftest_modeling_flava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fflava%2Ftest_modeling_flava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fflava%2Ftest_modeling_flava.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -320,16 +320,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"FlavaImageModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    # skip this test as FlavaImageModel has no base class and is\n-    # not available in MODEL_MAPPING\n-    @unittest.skip(reason=\"FlavaImageModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"facebook/flava-full\"\n@@ -486,14 +476,6 @@ def test_inputs_embeds(self):\n         # FLAVA does not use inputs_embeds\n         pass\n \n-    @unittest.skip(reason=\"FlavaTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"FlavaTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"facebook/flava-full\"\n@@ -650,14 +632,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"FlavaMultimodalModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"FlavaMultimodalModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"facebook/flava-full\"\n@@ -785,14 +759,6 @@ def test_inputs_embeds(self):\n     def test_model_outputs_equivalence(self):\n         pass\n \n-    @unittest.skip(reason=\"FlavaImageCodebook has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"FlavaImageCodebook has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"facebook/flava-full\""
        },
        {
            "sha": "4119769676a990fe5e65efec8d00908e31bb2cb6",
            "filename": "tests/models/fsmt/test_modeling_fsmt.py",
            "status": "modified",
            "additions": 10,
            "deletions": 2,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Ffsmt%2Ftest_modeling_fsmt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Ffsmt%2Ftest_modeling_fsmt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ffsmt%2Ftest_modeling_fsmt.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -548,6 +548,7 @@ def test_basic(self):\n         emb1 = SinusoidalPositionalEmbedding(num_positions=6, embedding_dim=6, padding_idx=self.padding_idx).to(\n             torch_device\n         )\n+        emb1.make_weight(*emb1.weight.shape, emb1.padding_idx)\n         emb = emb1(input_ids)\n         desired_weights = torch.tensor(\n             [\n@@ -562,10 +563,16 @@ def test_basic(self):\n \n     def test_odd_embed_dim(self):\n         # odd embedding_dim  is allowed\n-        SinusoidalPositionalEmbedding(num_positions=4, embedding_dim=5, padding_idx=self.padding_idx).to(torch_device)\n+        test = SinusoidalPositionalEmbedding(num_positions=4, embedding_dim=5, padding_idx=self.padding_idx).to(\n+            torch_device\n+        )\n+        test.make_weight(*test.weight.shape, test.padding_idx)\n \n         # odd num_embeddings is allowed\n-        SinusoidalPositionalEmbedding(num_positions=5, embedding_dim=4, padding_idx=self.padding_idx).to(torch_device)\n+        test = SinusoidalPositionalEmbedding(num_positions=5, embedding_dim=4, padding_idx=self.padding_idx).to(\n+            torch_device\n+        )\n+        test.make_weight(*test.weight.shape, test.padding_idx)\n \n     @unittest.skip(reason=\"different from marian (needs more research)\")\n     def test_positional_emb_weights_against_marian(self):\n@@ -579,6 +586,7 @@ def test_positional_emb_weights_against_marian(self):\n         emb1 = SinusoidalPositionalEmbedding(num_positions=512, embedding_dim=512, padding_idx=self.padding_idx).to(\n             torch_device\n         )\n+        emb1.make_weight(*emb1.weight.shape, emb1.padding_idx)\n         weights = emb1.weights.data[:3, :5]\n         # XXX: only the 1st and 3rd lines match - this is testing against\n         # verbatim copy of SinusoidalPositionalEmbedding from fairseq"
        },
        {
            "sha": "20247bd68c0c6ddbbdb7bcc6531ee97bf05f8a1b",
            "filename": "tests/models/gemma/test_modeling_gemma.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fgemma%2Ftest_modeling_gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fgemma%2Ftest_modeling_gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgemma%2Ftest_modeling_gemma.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -406,10 +406,6 @@ def test_Gemma_token_classification_model(self):\n             (self.model_tester.batch_size, self.model_tester.seq_length, self.model_tester.num_labels),\n         )\n \n-    @unittest.skip(reason=\"Gemma buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"Gemma uses GQA on all models so the KV cache is a non standard format\")\n     def test_past_key_values_format(self):\n         pass"
        },
        {
            "sha": "03f7c8285bfc13d54cdcb4f6bd3d8db9a13e1691",
            "filename": "tests/models/git/test_modeling_git.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fgit%2Ftest_modeling_git.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fgit%2Ftest_modeling_git.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgit%2Ftest_modeling_git.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -187,14 +187,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"GitVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"GitVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"microsoft/git-base\""
        },
        {
            "sha": "7819d61025e0a84530b10a8a63b2f165af82d726",
            "filename": "tests/models/granite/test_modeling_granite.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fgranite%2Ftest_modeling_granite.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fgranite%2Ftest_modeling_granite.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgranite%2Ftest_modeling_granite.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -314,10 +314,6 @@ def test_model_various_embeddings(self):\n             config_and_inputs[0].position_embedding_type = type\n             self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    @unittest.skip(\"Granite buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @parameterized.expand([(\"linear\",), (\"dynamic\",)])\n     def test_model_rope_scaling_from_config(self, scaling_type):\n         config, _ = self.model_tester.prepare_config_and_inputs_for_common()"
        },
        {
            "sha": "927cb2d3655e0b9ccfc81b943162480e5a0b3e7a",
            "filename": "tests/models/granitemoe/test_modeling_granitemoe.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fgranitemoe%2Ftest_modeling_granitemoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fgranitemoe%2Ftest_modeling_granitemoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgranitemoe%2Ftest_modeling_granitemoe.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -313,10 +313,6 @@ def test_model_various_embeddings(self):\n             config_and_inputs[0].position_embedding_type = type\n             self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    @unittest.skip(\"GraniteMoe buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @parameterized.expand([(\"linear\",), (\"dynamic\",)])\n     def test_model_rope_scaling_from_config(self, scaling_type):\n         config, _ = self.model_tester.prepare_config_and_inputs_for_common()"
        },
        {
            "sha": "646911f6f79bafedee8dc503165b38f1c18b5936",
            "filename": "tests/models/granitemoeshared/test_modeling_granitemoeshared.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fgranitemoeshared%2Ftest_modeling_granitemoeshared.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fgranitemoeshared%2Ftest_modeling_granitemoeshared.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgranitemoeshared%2Ftest_modeling_granitemoeshared.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -316,10 +316,6 @@ def test_model_various_embeddings(self):\n             config_and_inputs[0].position_embedding_type = type\n             self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    @unittest.skip(\"GraniteMoeShared buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @parameterized.expand([(\"linear\",), (\"dynamic\",)])\n     def test_model_rope_scaling_from_config(self, scaling_type):\n         config, _ = self.model_tester.prepare_config_and_inputs_for_common()"
        },
        {
            "sha": "3c48743a590efc9b346d53a620bb6ab2a5b227f2",
            "filename": "tests/models/groupvit/test_modeling_groupvit.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fgroupvit%2Ftest_modeling_groupvit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fgroupvit%2Ftest_modeling_groupvit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgroupvit%2Ftest_modeling_groupvit.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -274,14 +274,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"GroupViTVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"GroupViTVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     # override since the attention mask from GroupViT is not used to compute loss, thus no grad\n     def test_retain_grad_hidden_states_attentions(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n@@ -476,14 +468,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"GroupViTTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"GroupViTTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"nvidia/groupvit-gcc-yfcc\""
        },
        {
            "sha": "6b5a36e58434f7788fd297426cdd10b7ba501bbd",
            "filename": "tests/models/informer/test_modeling_informer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Finformer%2Ftest_modeling_informer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Finformer%2Ftest_modeling_informer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Finformer%2Ftest_modeling_informer.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -171,7 +171,7 @@ def check_encoder_decoder_model_standalone(self, config, inputs_dict):\n         embed_positions = InformerSinusoidalPositionalEmbedding(\n             config.context_length + config.prediction_length, config.d_model\n         ).to(torch_device)\n-        embed_positions.weight = embed_positions._init_weight(embed_positions.weight)\n+        embed_positions._init_weight()\n         self.parent.assertTrue(torch.equal(model.encoder.embed_positions.weight, embed_positions.weight))\n         self.parent.assertTrue(torch.equal(model.decoder.embed_positions.weight, embed_positions.weight))\n "
        },
        {
            "sha": "f7c13dd09d98c6f197d288a05b10b27a02d4914d",
            "filename": "tests/models/instructblip/test_modeling_instructblip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Finstructblip%2Ftest_modeling_instructblip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Finstructblip%2Ftest_modeling_instructblip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Finstructblip%2Ftest_modeling_instructblip.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -216,14 +216,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"InstructBlipVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"InstructBlipVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"Salesforce/instructblip-flan-t5-xl\"\n@@ -522,14 +514,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    @unittest.skip(reason=\"There's no base InstructBlipModel\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"There's no base InstructBlipModel\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(\n         \"InstructBLIP cannot generate only from input ids, and requires pixel values in all cases to be present\"\n     )"
        },
        {
            "sha": "e5cc00d92c6a107e44bde3db2f368f2b3104b65b",
            "filename": "tests/models/instructblipvideo/test_modeling_instructblipvideo.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Finstructblipvideo%2Ftest_modeling_instructblipvideo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Finstructblipvideo%2Ftest_modeling_instructblipvideo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Finstructblipvideo%2Ftest_modeling_instructblipvideo.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -224,14 +224,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"InstructBlipVideoVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"InstructBlipVideoVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"Salesforce/instructblip-vicuna-7b\"\n@@ -538,14 +530,6 @@ def test_retain_grad_hidden_states_attentions(self):\n     def test_model_common_attributes(self):\n         pass\n \n-    @unittest.skip(reason=\"There's no base InstructBlipVideoModel\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"There's no base InstructBlipVideoModel\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(\n         \"InstructBLIPVideo cannot generate only from input ids, and requires pixel values in all cases to be present\"\n     )"
        },
        {
            "sha": "aab93c553ef878782bb7420220377b51c29345fe",
            "filename": "tests/models/jetmoe/test_modeling_jetmoe.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fjetmoe%2Ftest_modeling_jetmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fjetmoe%2Ftest_modeling_jetmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fjetmoe%2Ftest_modeling_jetmoe.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -362,10 +362,6 @@ def test_jetmoe_sequence_classification_model_for_multi_label(self):\n         result = model(input_ids, attention_mask=attention_mask, labels=sequence_labels)\n         self.assertEqual(result.logits.shape, (self.model_tester.batch_size, self.model_tester.num_labels))\n \n-    @unittest.skip(reason=\"JetMoe buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"JetMoe uses MoA on all models so the KV cache is a non standard format\")\n     def test_past_key_values_format(self):\n         pass"
        },
        {
            "sha": "b072105a3fa9144bd6dfd19e988ccc0ff2c593b5",
            "filename": "tests/models/llama/test_modeling_llama.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fllama%2Ftest_modeling_llama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fllama%2Ftest_modeling_llama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fllama%2Ftest_modeling_llama.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -384,10 +384,6 @@ def test_llama_token_classification_model(self):\n             (self.model_tester.batch_size, self.model_tester.seq_length, self.model_tester.num_labels),\n         )\n \n-    @unittest.skip(reason=\"Llama buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @parameterized.expand([(\"linear\",), (\"dynamic\",), (\"yarn\",)])\n     def test_model_rope_scaling_from_config(self, scaling_type):\n         config, _ = self.model_tester.prepare_config_and_inputs_for_common()"
        },
        {
            "sha": "6125c2854f7926ff7e3d2044e25046b88fe5647a",
            "filename": "tests/models/maskformer/test_modeling_maskformer_swin.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fmaskformer%2Ftest_modeling_maskformer_swin.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fmaskformer%2Ftest_modeling_maskformer_swin.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmaskformer%2Ftest_modeling_maskformer_swin.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -235,10 +235,6 @@ def test_model_get_set_embeddings(self):\n     def test_attention_outputs(self):\n         pass\n \n-    @unittest.skip(reason=\"MaskFormerSwin is only used as an internal backbone\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     def check_hidden_states_output(self, inputs_dict, config, model_class, image_size):\n         model = model_class(config)\n         model.to(torch_device)"
        },
        {
            "sha": "8f8b757bac9636f93e9e9d717438c6588e0f2af6",
            "filename": "tests/models/mistral/test_modeling_mistral.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fmistral%2Ftest_modeling_mistral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fmistral%2Ftest_modeling_mistral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmistral%2Ftest_modeling_mistral.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -406,10 +406,6 @@ def test_Mistral_token_classification_model(self):\n             (self.model_tester.batch_size, self.model_tester.seq_length, self.model_tester.num_labels),\n         )\n \n-    @unittest.skip(reason=\"Mistral buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"Mistral uses GQA on all models so the KV cache is a non standard format\")\n     def test_past_key_values_format(self):\n         pass"
        },
        {
            "sha": "a45935e9784cf4bf7400c05bce7c582cc6fea29d",
            "filename": "tests/models/mistral/test_modeling_tf_mistral.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fmistral%2Ftest_modeling_tf_mistral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fmistral%2Ftest_modeling_tf_mistral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmistral%2Ftest_modeling_tf_mistral.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -325,10 +325,6 @@ def test_Mistral_sequence_classification_model_for_multi_label(self):\n         result = model(input_ids, attention_mask=attention_mask, labels=sequence_labels)\n         self.assertEqual(result.logits.shape, (self.model_tester.batch_size, self.model_tester.num_labels))\n \n-    @unittest.skip(\"Mistral buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(\"Mistral uses GQA on all models so the KV cache is a non standard format\")\n     def test_past_key_values_format(self):\n         pass"
        },
        {
            "sha": "08d44a94710ea8ded5e521a025670f0ff3193bd7",
            "filename": "tests/models/mixtral/test_modeling_mixtral.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fmixtral%2Ftest_modeling_mixtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fmixtral%2Ftest_modeling_mixtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmixtral%2Ftest_modeling_mixtral.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -405,10 +405,6 @@ def test_Mixtral_token_classification_model(self):\n             (self.model_tester.batch_size, self.model_tester.seq_length, self.model_tester.num_labels),\n         )\n \n-    @unittest.skip(reason=\"Mixtral buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"Mixtral uses GQA on all models so the KV cache is a non standard format\")\n     def test_past_key_values_format(self):\n         pass"
        },
        {
            "sha": "9d49e1b6c5b60d2cf29d41122b12d59b8c3b87a3",
            "filename": "tests/models/musicgen/test_modeling_musicgen.py",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fmusicgen%2Ftest_modeling_musicgen.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fmusicgen%2Ftest_modeling_musicgen.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmusicgen%2Ftest_modeling_musicgen.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -970,12 +970,6 @@ def test_greedy_generate_stereo_outputs(self):\n         super().test_greedy_generate_dict_outputs()\n         self.model_tester.audio_channels = original_audio_channels\n \n-    @unittest.skip(\n-        reason=\"MusicgenModel is actually not the base of MusicgenForCausalLM as the latter is a composite model\"\n-    )\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @require_flash_attn\n     @require_torch_gpu\n     @mark.flash_attn_test"
        },
        {
            "sha": "a979fb8f66466383c3d17f0525632695ad55aeb1",
            "filename": "tests/models/musicgen_melody/test_modeling_musicgen_melody.py",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fmusicgen_melody%2Ftest_modeling_musicgen_melody.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fmusicgen_melody%2Ftest_modeling_musicgen_melody.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmusicgen_melody%2Ftest_modeling_musicgen_melody.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -960,12 +960,6 @@ def test_greedy_generate_stereo_outputs(self):\n         super().test_greedy_generate_dict_outputs()\n         self.model_tester.audio_channels = original_audio_channels\n \n-    @unittest.skip(\n-        reason=\"MusicgenMelodyModel is actually not the base of MusicgenMelodyForCausalLM as the latter is a composite model\"\n-    )\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @require_flash_attn\n     @require_torch_gpu\n     @mark.flash_attn_test"
        },
        {
            "sha": "720486968f022618ae8841efb77df82e8962e0b3",
            "filename": "tests/models/olmo/test_modeling_olmo.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Folmo%2Ftest_modeling_olmo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Folmo%2Ftest_modeling_olmo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Folmo%2Ftest_modeling_olmo.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -310,10 +310,6 @@ def test_model_various_embeddings(self):\n             config_and_inputs[0].position_embedding_type = type\n             self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    @unittest.skip(reason=\"OLMo buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @parameterized.expand([(\"linear\",), (\"dynamic\",)])\n     def test_model_rope_scaling(self, scaling_type):\n         config, _ = self.model_tester.prepare_config_and_inputs_for_common()"
        },
        {
            "sha": "9ed55eb387638be6064442daeec1c57a3846ea56",
            "filename": "tests/models/olmo2/test_modeling_olmo2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Folmo2%2Ftest_modeling_olmo2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Folmo2%2Ftest_modeling_olmo2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Folmo2%2Ftest_modeling_olmo2.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -309,10 +309,6 @@ def test_model_various_embeddings(self):\n             config_and_inputs[0].position_embedding_type = type\n             self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    @unittest.skip(reason=\"OLMo2 buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @parameterized.expand([(\"linear\",), (\"dynamic\",)])\n     def test_model_rope_scaling(self, scaling_type):\n         config, _ = self.model_tester.prepare_config_and_inputs_for_common()"
        },
        {
            "sha": "24461a7c40f709f1192ce4d4ea6bac1f3f413901",
            "filename": "tests/models/olmoe/test_modeling_olmoe.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Folmoe%2Ftest_modeling_olmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Folmoe%2Ftest_modeling_olmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Folmoe%2Ftest_modeling_olmoe.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -323,10 +323,6 @@ def test_model_various_embeddings(self):\n             config_and_inputs[0].position_embedding_type = type\n             self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    @unittest.skip(reason=\"OLMoE buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @parameterized.expand([(\"linear\",), (\"dynamic\",)])\n     def test_model_rope_scaling(self, scaling_type):\n         config, _ = self.model_tester.prepare_config_and_inputs_for_common()"
        },
        {
            "sha": "c5446297b99878e4d03b962cef18bde7b757c51e",
            "filename": "tests/models/owlv2/test_modeling_owlv2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fowlv2%2Ftest_modeling_owlv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fowlv2%2Ftest_modeling_owlv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fowlv2%2Ftest_modeling_owlv2.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -207,14 +207,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"Owlv2VisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Owlv2VisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"google/owlv2-base-patch16-ensemble\"\n@@ -355,14 +347,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"Owlv2TextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Owlv2TextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"google/owlv2-base-patch16-ensemble\"\n@@ -689,10 +673,6 @@ def test_initialization(self):\n     def test_forward_signature(self):\n         pass\n \n-    @unittest.skip(reason=\"Test_save_load_fast_init_from_base is tested in individual model tests\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"OwlV2 does not support training yet\")\n     def test_training(self):\n         pass"
        },
        {
            "sha": "aadc8f1f9394a6898c4778daac419afca8e923f3",
            "filename": "tests/models/owlvit/test_modeling_owlvit.py",
            "status": "modified",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fowlvit%2Ftest_modeling_owlvit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fowlvit%2Ftest_modeling_owlvit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fowlvit%2Ftest_modeling_owlvit.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -205,14 +205,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"OwlViTVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"OwlViTVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"google/owlvit-base-patch32\"\n@@ -351,14 +343,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"OwlViTTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"OwlViTTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"google/owlvit-base-patch32\"\n@@ -682,10 +666,6 @@ def test_initialization(self):\n     def test_forward_signature(self):\n         pass\n \n-    @unittest.skip(reason=\"Test_save_load_fast_init_from_base is tested in individual model tests\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"OWL-ViT does not support training yet\")\n     def test_training(self):\n         pass"
        },
        {
            "sha": "2cd4719083c270b149a945d1fca7fe91023eb75d",
            "filename": "tests/models/perceiver/test_modeling_perceiver.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fperceiver%2Ftest_modeling_perceiver.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fperceiver%2Ftest_modeling_perceiver.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fperceiver%2Ftest_modeling_perceiver.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -812,14 +812,6 @@ def test_problem_types(self):\n     def test_multi_gpu_data_parallel_forward(self):\n         pass\n \n-    @unittest.skip(reason=\"Perceiver models don't have a typical head like is the case with BERT\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Perceiver models don't have a typical head like is the case with BERT\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"Perceiver doesn't support resize_token_embeddings\")\n     def test_resize_tokens_embeddings(self):\n         pass"
        },
        {
            "sha": "2fa6f0ca6707b2e0549ddcb26e3e949e842a9a3b",
            "filename": "tests/models/persimmon/test_modeling_persimmon.py",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fpersimmon%2Ftest_modeling_persimmon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fpersimmon%2Ftest_modeling_persimmon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpersimmon%2Ftest_modeling_persimmon.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -379,11 +379,6 @@ def test_persimmon_token_classification_model(self):\n             (self.model_tester.batch_size, self.model_tester.seq_length, self.model_tester.num_labels),\n         )\n \n-    @unittest.skip(reason=\"Persimmon buffers include complex numbers, which breaks this test\")\n-    # Copied from tests.models.llama.test_modeling_llama.LlamaModelTest.test_save_load_fast_init_from_base\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @parameterized.expand([(\"linear\",), (\"dynamic\",)])\n     # Copied from tests.models.llama.test_modeling_llama.LlamaModelTest.test_model_rope_scaling_from_config with Llama->Persimmon\n     def test_model_rope_scaling_from_config(self, scaling_type):"
        },
        {
            "sha": "1517ae9dbd2f909be5c9a1afd693f3fc08f4055b",
            "filename": "tests/models/pix2struct/test_modeling_pix2struct.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fpix2struct%2Ftest_modeling_pix2struct.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fpix2struct%2Ftest_modeling_pix2struct.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpix2struct%2Ftest_modeling_pix2struct.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -212,14 +212,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_retain_grad_hidden_states_attentions(self):\n         pass\n \n-    @unittest.skip(reason=\"Pix2StructVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Pix2StructVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"google/pix2struct-textcaps-base\"\n@@ -361,14 +353,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"Pix2StructTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Pix2StructTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"google/pix2struct-textcaps-base\""
        },
        {
            "sha": "0dc6838a9dfbefb56b50b90512a490e0e12198f8",
            "filename": "tests/models/prompt_depth_anything/test_modeling_prompt_depth_anything.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fprompt_depth_anything%2Ftest_modeling_prompt_depth_anything.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fprompt_depth_anything%2Ftest_modeling_prompt_depth_anything.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fprompt_depth_anything%2Ftest_modeling_prompt_depth_anything.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -184,14 +184,6 @@ def test_training_gradient_checkpointing(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    @unittest.skip(reason=\"Prompt Depth Anything with AutoBackbone does not have a base model\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Prompt Depth Anything with AutoBackbone does not have a base model\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(\n         reason=\"This architecture seems to not compute gradients properly when using GC, check: https://github.com/huggingface/transformers/pull/27124\"\n     )"
        },
        {
            "sha": "3be1aef60fd1d08c562401773e2c160ec00de366",
            "filename": "tests/models/qwen2/test_modeling_qwen2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -417,10 +417,6 @@ def test_Qwen2_token_classification_model(self):\n             (self.model_tester.batch_size, self.model_tester.seq_length, self.model_tester.num_labels),\n         )\n \n-    @unittest.skip(reason=\"Qwen2 buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"Qwen2 uses GQA on all models so the KV cache is a non standard format\")\n     def test_past_key_values_format(self):\n         pass"
        },
        {
            "sha": "bdddb3708f4e9ce93a08815957c5678fe42b0218",
            "filename": "tests/models/qwen2_moe/test_modeling_qwen2_moe.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fqwen2_moe%2Ftest_modeling_qwen2_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fqwen2_moe%2Ftest_modeling_qwen2_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_moe%2Ftest_modeling_qwen2_moe.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -445,10 +445,6 @@ def test_Qwen2Moe_token_classification_model(self):\n             (self.model_tester.batch_size, self.model_tester.seq_length, self.model_tester.num_labels),\n         )\n \n-    @unittest.skip(reason=\"Qwen2Moe buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"Qwen2Moe uses GQA on all models so the KV cache is a non standard format\")\n     def test_past_key_values_format(self):\n         pass"
        },
        {
            "sha": "1f9843f91f17f304027dc9077272018daaf6cfd2",
            "filename": "tests/models/qwen3/test_modeling_qwen3.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fqwen3%2Ftest_modeling_qwen3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fqwen3%2Ftest_modeling_qwen3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen3%2Ftest_modeling_qwen3.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -420,10 +420,6 @@ def test_Qwen3_token_classification_model(self):\n             (self.model_tester.batch_size, self.model_tester.seq_length, self.model_tester.num_labels),\n         )\n \n-    @unittest.skip(reason=\"Qwen3 buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     # Ignore copy\n     def test_past_key_values_format(self):\n         super().test_past_key_values_format()"
        },
        {
            "sha": "9938d20b857ee7b264998acfe06375e6e8af78ee",
            "filename": "tests/models/qwen3_moe/test_modeling_qwen3_moe.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fqwen3_moe%2Ftest_modeling_qwen3_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fqwen3_moe%2Ftest_modeling_qwen3_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen3_moe%2Ftest_modeling_qwen3_moe.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -439,10 +439,6 @@ def test_Qwen3Moe_token_classification_model(self):\n             (self.model_tester.batch_size, self.model_tester.seq_length, self.model_tester.num_labels),\n         )\n \n-    @unittest.skip(reason=\"Qwen3Moe buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     # Ignore copy\n     def test_past_key_values_format(self):\n         super().test_past_key_values_format()"
        },
        {
            "sha": "0ca4a0dd6e8e8cca8e0bcc2525949bd9cc0b6fa4",
            "filename": "tests/models/recurrent_gemma/test_modeling_recurrent_gemma.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Frecurrent_gemma%2Ftest_modeling_recurrent_gemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Frecurrent_gemma%2Ftest_modeling_recurrent_gemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Frecurrent_gemma%2Ftest_modeling_recurrent_gemma.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -337,10 +337,6 @@ def test_model_various_embeddings(self):\n             config_and_inputs[0].position_embedding_type = type\n             self.model_tester.create_and_check_model(*config_and_inputs)\n \n-    @unittest.skip(reason=\"Fast init from base not tested for RecurrentGemma\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"RecurrentGemma does not return pkv\")\n     def test_past_key_values_format(self):\n         pass"
        },
        {
            "sha": "a592ea01caead73706a02526237b8e8e136164c5",
            "filename": "tests/models/roformer/test_modeling_roformer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Froformer%2Ftest_modeling_roformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Froformer%2Ftest_modeling_roformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Froformer%2Ftest_modeling_roformer.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -534,7 +534,7 @@ class RoFormerSinusoidalPositionalEmbeddingTest(unittest.TestCase):\n     def test_basic(self):\n         input_ids = torch.tensor([[4, 10]], dtype=torch.long, device=torch_device)\n         emb1 = RoFormerSinusoidalPositionalEmbedding(num_positions=6, embedding_dim=6).to(torch_device)\n-        emb1.weight = emb1._init_weight(emb1.weight)\n+        emb1._init_weight()\n         emb = emb1(input_ids.shape)\n         desired_weights = torch.tensor(\n             [[0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000], [0.8415, 0.0464, 0.0022, 0.5403, 0.9989, 1.0000]]\n@@ -553,7 +553,7 @@ def test_positional_emb_weights_against_roformer(self):\n             ]\n         ).to(torch_device)\n         emb1 = RoFormerSinusoidalPositionalEmbedding(num_positions=512, embedding_dim=512).to(torch_device)\n-        emb1.weight = emb1._init_weight(emb1.weight)\n+        emb1._init_weight()\n         weights = emb1.weight.data[:3, :5].to(torch_device)\n \n         self.assertTrue(\n@@ -575,7 +575,7 @@ def test_apply_rotary_position_embeddings(self):\n             -torch.arange(2 * 12 * 16 * 64, dtype=torch.float, device=torch_device).reshape(2, 12, 16, 64) / 100\n         ).to(torch_device)\n         embed_positions = RoFormerSinusoidalPositionalEmbedding(num_positions=32, embedding_dim=64).to(torch_device)\n-        embed_positions.weight = embed_positions._init_weight(embed_positions.weight)\n+        embed_positions._init_weight()\n         sinusoidal_pos = embed_positions([2, 16, 768])[None, None, :, :]\n \n         query_layer, key_layer = RoFormerSelfAttention.apply_rotary_position_embeddings("
        },
        {
            "sha": "2a17fad3344756dff454ca28f49283432e29dcd7",
            "filename": "tests/models/sam/test_modeling_sam.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fsam%2Ftest_modeling_sam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fsam%2Ftest_modeling_sam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsam%2Ftest_modeling_sam.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -647,14 +647,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"SamModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"SamModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"SamModel does not support training\")\n     def test_retain_grad_hidden_states_attentions(self):\n         pass"
        },
        {
            "sha": "d7f01580447408c7596ea272aef271b5139996c1",
            "filename": "tests/models/seamless_m4t/test_modeling_seamless_m4t.py",
            "status": "modified",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fseamless_m4t%2Ftest_modeling_seamless_m4t.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fseamless_m4t%2Ftest_modeling_seamless_m4t.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fseamless_m4t%2Ftest_modeling_seamless_m4t.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -429,20 +429,10 @@ def test_inputs_embeds_matches_input_ids(self):\n     def test_model_weights_reload_no_missing_tied_weights(self):\n         pass\n \n-    @unittest.skip(\n-        reason=\"SeamlessM4TModel is base class but has actually a bigger architecture than seamlessM4T task-specific models.\"\n-    )\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"SeamlessM4TModel can takes input_ids or input_features\")\n     def test_forward_signature(self):\n         pass\n \n-    @unittest.skip(reason=\"SeamlessM4T has no base model\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(\n         reason=\"This architecture seem to not compute gradients properly when using GC, check: https://github.com/huggingface/transformers/pull/27124\"\n     )\n@@ -684,16 +674,6 @@ def test_decoder_model_past_with_large_inputs(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs_for_decoder()\n         self.model_tester.create_and_check_decoder_model_past_large_inputs(*config_and_inputs)\n \n-    @unittest.skip(\n-        reason=\"SeamlessM4TModel is base class but has actually a bigger architecture than seamlessM4T task-specific models.\"\n-    )\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"SeamlessM4T has no base model\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(\n         reason=\"This architecture seem to not compute gradients properly when using GC, check: https://github.com/huggingface/transformers/pull/27124\"\n     )"
        },
        {
            "sha": "2342f5502c97f58e08e682be09c17015a3ccfd5b",
            "filename": "tests/models/seamless_m4t_v2/test_modeling_seamless_m4t_v2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fseamless_m4t_v2%2Ftest_modeling_seamless_m4t_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fseamless_m4t_v2%2Ftest_modeling_seamless_m4t_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fseamless_m4t_v2%2Ftest_modeling_seamless_m4t_v2.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -445,20 +445,10 @@ def test_inputs_embeds_matches_input_ids(self):\n     def test_model_weights_reload_no_missing_tied_weights(self):\n         pass\n \n-    @unittest.skip(\n-        reason=\"SeamlessM4Tv2Model is base class but has actually a bigger architecture than seamlessM4T task-specific models.\"\n-    )\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"SeamlessM4Tv2Model can takes input_ids or input_features\")\n     def test_forward_signature(self):\n         pass\n \n-    @unittest.skip(reason=\"SeamlessM4Tv2 has no base model\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(\n         reason=\"This architecture seem to not compute gradients properly when using GC, check: https://github.com/huggingface/transformers/pull/27124\"\n     )\n@@ -687,16 +677,6 @@ def test_decoder_model_past_with_large_inputs(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs_for_decoder()\n         self.model_tester.create_and_check_decoder_model_past_large_inputs(*config_and_inputs)\n \n-    @unittest.skip(\n-        reason=\"SeamlessM4Tv2Model is base class but has actually a bigger architecture than seamlessM4T task-specific models.\"\n-    )\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"SeamlessM4Tv2 has no base model\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(\n         reason=\"This architecture seem to not compute gradients properly when using GC, check: https://github.com/huggingface/transformers/pull/27124\"\n     )"
        },
        {
            "sha": "93268bbc8e43a768d8c4ac8d565d626834f6e203",
            "filename": "tests/models/siglip/test_modeling_siglip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fsiglip%2Ftest_modeling_siglip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fsiglip%2Ftest_modeling_siglip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsiglip%2Ftest_modeling_siglip.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -399,14 +399,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"SiglipVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"SiglipVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"Siglip uses the same initialization scheme as the Flax original implementation\")\n     def test_initialization(self):\n         pass\n@@ -563,16 +555,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"SiglipTextModel has no base class and is not available in MODEL_MAPPING\")\n-    # Copied from tests.models.clip.test_modeling_clip.CLIPTextModelTest.test_save_load_fast_init_from_base\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"SiglipTextModel has no base class and is not available in MODEL_MAPPING\")\n-    # Copied from tests.models.clip.test_modeling_clip.CLIPTextModelTest.test_save_load_fast_init_to_base\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"Siglip uses the same initialization scheme as the Flax original implementation\")\n     def test_initialization(self):\n         pass"
        },
        {
            "sha": "f5959edb5fe27f18b423337dd9924279730ac78c",
            "filename": "tests/models/siglip2/test_modeling_siglip2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fsiglip2%2Ftest_modeling_siglip2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fsiglip2%2Ftest_modeling_siglip2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsiglip2%2Ftest_modeling_siglip2.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -487,14 +487,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"Siglip2VisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Siglip2VisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"Siglip2 uses the same initialization scheme as the Flax original implementation\")\n     def test_initialization(self):\n         pass\n@@ -646,14 +638,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"Siglip2TextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Siglip2TextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"Siglip2 uses the same initialization scheme as the Flax original implementation\")\n     def test_initialization(self):\n         pass"
        },
        {
            "sha": "3b7ae7fa0488a9b964e584de5be0d47318606da2",
            "filename": "tests/models/speecht5/test_modeling_speecht5.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fspeecht5%2Ftest_modeling_speecht5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fspeecht5%2Ftest_modeling_speecht5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fspeecht5%2Ftest_modeling_speecht5.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -1895,14 +1895,6 @@ def test_model_outputs_equivalence(self):\n     def test_retain_grad_hidden_states_attentions(self):\n         pass\n \n-    @unittest.skip(reason=\"Fails on automapping of SpeechT5HifiGanConfig\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Fails on automapping of SpeechT5HifiGanConfig\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     def test_batched_inputs_outputs(self):\n         config, inputs = self.model_tester.prepare_config_and_inputs_for_common()\n "
        },
        {
            "sha": "5b3626a258765a61c3c12ef216b93f4a8fe1ef80",
            "filename": "tests/models/starcoder2/test_modeling_starcoder2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fstarcoder2%2Ftest_modeling_starcoder2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fstarcoder2%2Ftest_modeling_starcoder2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fstarcoder2%2Ftest_modeling_starcoder2.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -395,10 +395,6 @@ def test_Starcoder2_token_classification_model(self):\n             (self.model_tester.batch_size, self.model_tester.seq_length, self.model_tester.num_labels),\n         )\n \n-    @unittest.skip(reason=\"Starcoder2 buffers include complex numbers, which breaks this test\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"Starcoder2 uses GQA on all models so the KV cache is a non standard format\")\n     def test_past_key_values_format(self):\n         pass"
        },
        {
            "sha": "9af22b1d1bf6f6a35912115b38d51f2c566e2604",
            "filename": "tests/models/trocr/test_modeling_trocr.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Ftrocr%2Ftest_modeling_trocr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Ftrocr%2Ftest_modeling_trocr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ftrocr%2Ftest_modeling_trocr.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -173,14 +173,6 @@ def setUp(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"trocr has no base model\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"trocr has no base model\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     def test_config(self):\n         self.config_tester.run_common_tests()\n "
        },
        {
            "sha": "d731ca9588aee8c7f3b534f402301003b7de8601",
            "filename": "tests/models/upernet/test_modeling_upernet.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fupernet%2Ftest_modeling_upernet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fupernet%2Ftest_modeling_upernet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fupernet%2Ftest_modeling_upernet.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -184,14 +184,6 @@ def test_inputs_embeds(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    @unittest.skip(reason=\"UperNet does not have a base model\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"UperNet does not have a base model\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @require_torch_multi_gpu\n     @unittest.skip(reason=\"UperNet has some layers using `add_module` which doesn't work well with `nn.DataParallel`\")\n     def test_multi_gpu_data_parallel_forward(self):"
        },
        {
            "sha": "a66bb44e824860d036a0b9b9d4cf019c5eaa64e5",
            "filename": "tests/models/vit_mae/test_modeling_vit_mae.py",
            "status": "modified",
            "additions": 18,
            "deletions": 15,
            "changes": 33,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fvit_mae%2Ftest_modeling_vit_mae.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fvit_mae%2Ftest_modeling_vit_mae.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvit_mae%2Ftest_modeling_vit_mae.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -34,7 +34,7 @@\n from transformers.utils import cached_property, is_torch_available, is_vision_available\n \n from ...test_configuration_common import ConfigTester\n-from ...test_modeling_common import ModelTesterMixin, floats_tensor, ids_tensor\n+from ...test_modeling_common import ModelTesterMixin, _config_zero_init, floats_tensor, ids_tensor\n from ...test_pipeline_mixin import PipelineTesterMixin\n \n \n@@ -250,20 +250,6 @@ def test_save_load(self):\n     def test_determinism(self):\n         pass\n \n-    @unittest.skip(\n-        reason=\"\"\"ViTMAE returns a random mask + ids_restore in each forward pass. See test_save_load\n-    to get deterministic results.\"\"\"\n-    )\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(\n-        reason=\"\"\"ViTMAE returns a random mask + ids_restore in each forward pass. See test_save_load\n-    to get deterministic results.\"\"\"\n-    )\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"\"\"ViTMAE returns a random mask + ids_restore in each forward pass. See test_save_load\"\"\")\n     def test_model_outputs_equivalence(self):\n         pass\n@@ -335,6 +321,23 @@ def test_flash_attn_2_inference_equivalence(self):\n     def test_flash_attn_2_inference_equivalence_right_padding(self):\n         pass\n \n+    def test_initialization(self):\n+        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n+\n+        configs_no_init = _config_zero_init(config)\n+        for model_class in self.all_model_classes:\n+            model = model_class(config=configs_no_init)\n+            for name, param in model.named_parameters():\n+                # This is an excepton in the module, it's initialized with xavier_uniform without using initializer_range\n+                if name.endswith(\"patch_embeddings.projection.weight\"):\n+                    continue\n+                if param.requires_grad:\n+                    self.assertIn(\n+                        ((param.data.mean() * 1e9).round() / 1e9).item(),\n+                        [0.0, 1.0],\n+                        msg=f\"Parameter {name} of model {model_class} seems not properly initialized\",\n+                    )\n+\n \n # We will verify our results on an image of cute cats\n def prepare_img():"
        },
        {
            "sha": "f4a1f8e5068e9e294aaeda694b27a4925e0b6e77",
            "filename": "tests/models/whisper/test_modeling_whisper.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -3684,10 +3684,6 @@ def test_generate_without_input_ids(self):\n     def test_retain_grad_hidden_states_attentions(self):\n         return\n \n-    @unittest.skip(reason=\"The model doesn't support fast init from base\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n     @unittest.skip(\n         \"Duplicated test with WhisperModelTest + the FA2 testing suite needs to be refactored to be compatible with WhisperDecoder for that test\"\n     )"
        },
        {
            "sha": "5a121d77439cef15471c9c703e8b96f55a49601f",
            "filename": "tests/models/x_clip/test_modeling_x_clip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fx_clip%2Ftest_modeling_x_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fx_clip%2Ftest_modeling_x_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fx_clip%2Ftest_modeling_x_clip.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -206,14 +206,6 @@ def test_training_gradient_checkpointing_use_reentrant(self):\n     def test_training_gradient_checkpointing_use_reentrant_false(self):\n         pass\n \n-    @unittest.skip(reason=\"XCLIPVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"XCLIPVisionModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"microsoft/xclip-base-patch32\"\n@@ -446,14 +438,6 @@ def test_training_gradient_checkpointing_use_reentrant_false(self):\n     def test_inputs_embeds(self):\n         pass\n \n-    @unittest.skip(reason=\"XCLIPTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"XCLIPTextModel has no base class and is not available in MODEL_MAPPING\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"microsoft/xclip-base-patch32\""
        },
        {
            "sha": "e9ffae7f5c60c1d1d4bdd8177df5798b5bf67b4d",
            "filename": "tests/models/zoedepth/test_modeling_zoedepth.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fzoedepth%2Ftest_modeling_zoedepth.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Fmodels%2Fzoedepth%2Ftest_modeling_zoedepth.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fzoedepth%2Ftest_modeling_zoedepth.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -174,14 +174,6 @@ def test_for_depth_estimation(self):\n     def test_model_common_attributes(self):\n         pass\n \n-    @unittest.skip(reason=\"ZoeDepth with AutoBackbone does not have a base model\")\n-    def test_save_load_fast_init_from_base(self):\n-        pass\n-\n-    @unittest.skip(reason=\"ZoeDepth with AutoBackbone does not have a base model\")\n-    def test_save_load_fast_init_to_base(self):\n-        pass\n-\n     @unittest.skip(reason=\"ZoeDepth does not support training yet\")\n     def test_training(self):\n         pass"
        },
        {
            "sha": "e1c64964d3f48bf0f117d55b09d27e2de47c52d6",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 1,
            "deletions": 111,
            "changes": 112,
            "blob_url": "https://github.com/huggingface/transformers/blob/f304318f5ffa530a4948aed552d3405708163b52/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f304318f5ffa530a4948aed552d3405708163b52/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=f304318f5ffa530a4948aed552d3405708163b52",
            "patch": "@@ -505,60 +505,6 @@ def test_peft_gradient_checkpointing_enable_disable(self):\n                         m.gradient_checkpointing, f\"Module {n} does not have gradient_checkpointing set to False\"\n                     )\n \n-    @is_flaky(description=\"low likelihood of failure, reason not yet discovered\")\n-    def test_save_load_fast_init_from_base(self):\n-        for model_class in self.all_model_classes:\n-            config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-            if config.__class__ not in MODEL_MAPPING:\n-                self.skipTest(reason=f\"{config.__class__.__name__} not in MODEL_MAPPING\")\n-\n-            base_class = MODEL_MAPPING[config.__class__]\n-\n-            if isinstance(base_class, tuple):\n-                base_class = base_class[0]\n-\n-            if model_class == base_class:\n-                continue\n-\n-            # make a copy of model class to not break future tests\n-            # from https://stackoverflow.com/questions/9541025/how-to-copy-a-python-class\n-            class CopyClass(model_class):\n-                pass\n-\n-            model_class_copy = CopyClass\n-\n-            # make sure that all keys are expected for test\n-            model_class_copy._keys_to_ignore_on_load_missing = []\n-\n-            # make init deterministic, but make sure that\n-            # non-initialized weights throw errors nevertheless\n-            model_class_copy._init_weights = _mock_init_weights\n-            model_class_copy.init_weights = _mock_all_init_weights\n-\n-            model = base_class(config)\n-            state_dict = model.state_dict()\n-\n-            # this will often delete a single weight of a multi-weight module\n-            # to test an edge case\n-            random_key_to_del = random.choice(list(state_dict.keys()))\n-            del state_dict[random_key_to_del]\n-\n-            # check that certain keys didn't get saved with the model\n-            with tempfile.TemporaryDirectory() as tmpdirname:\n-                model.save_pretrained(tmpdirname)\n-                torch.save(state_dict, os.path.join(tmpdirname, \"pytorch_model.bin\"))\n-\n-                model_fast_init = model_class_copy.from_pretrained(tmpdirname)\n-                model_slow_init = model_class_copy.from_pretrained(tmpdirname, _fast_init=False)\n-                # Before we test anything\n-\n-                for key in model_fast_init.state_dict().keys():\n-                    if isinstance(model_slow_init.state_dict()[key], torch.BoolTensor):\n-                        max_diff = (model_slow_init.state_dict()[key] ^ model_fast_init.state_dict()[key]).sum().item()\n-                    else:\n-                        max_diff = (model_slow_init.state_dict()[key] - model_fast_init.state_dict()[key]).sum().item()\n-                    self.assertLessEqual(max_diff, 1e-3, msg=f\"{key} not identical\")\n-\n     @slow\n     @require_accelerate\n     @mark.accelerate_tests\n@@ -640,62 +586,6 @@ def _check_save_load_low_cpu_mem_usage(self, model_class, saved_model_path):\n \n         self.assertEqual(tied_params1, tied_params2)\n \n-    def test_save_load_fast_init_to_base(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n-        if config.__class__ not in MODEL_MAPPING:\n-            self.skipTest(reason=f\"{config.__class__.__name__} not in MODEL_MAPPING\")\n-\n-        base_class = MODEL_MAPPING[config.__class__]\n-\n-        if isinstance(base_class, tuple):\n-            base_class = base_class[0]\n-\n-        for model_class in self.all_model_classes:\n-            if model_class == base_class:\n-                continue\n-\n-            # make a copy of model class to not break future tests\n-            # from https://stackoverflow.com/questions/9541025/how-to-copy-a-python-class\n-            class CopyClass(base_class):\n-                pass\n-\n-            base_class_copy = CopyClass\n-\n-            # make sure that all keys are expected for test\n-            base_class_copy._keys_to_ignore_on_load_missing = []\n-\n-            # make init deterministic, but make sure that\n-            # non-initialized weights throw errors nevertheless\n-            base_class_copy._init_weights = _mock_init_weights\n-            base_class_copy.init_weights = _mock_all_init_weights\n-\n-            model = model_class(config)\n-            state_dict = model.state_dict()\n-\n-            # this will often delete a single weight of a multi-weight module\n-            # to test an edge case\n-            random_key_to_del = random.choice(list(state_dict.keys()))\n-            del state_dict[random_key_to_del]\n-\n-            # check that certain keys didn't get saved with the model\n-            with tempfile.TemporaryDirectory() as tmpdirname:\n-                model.config.save_pretrained(tmpdirname)\n-                torch.save(state_dict, os.path.join(tmpdirname, \"pytorch_model.bin\"))\n-\n-                model_fast_init = base_class_copy.from_pretrained(tmpdirname)\n-                model_slow_init = base_class_copy.from_pretrained(tmpdirname, _fast_init=False)\n-\n-                for key in model_fast_init.state_dict().keys():\n-                    if isinstance(model_slow_init.state_dict()[key], torch.BoolTensor):\n-                        max_diff = torch.max(\n-                            model_slow_init.state_dict()[key] ^ model_fast_init.state_dict()[key]\n-                        ).item()\n-                    else:\n-                        max_diff = torch.max(\n-                            torch.abs(model_slow_init.state_dict()[key] - model_fast_init.state_dict()[key])\n-                        ).item()\n-                    self.assertLessEqual(max_diff, 1e-3, msg=f\"{key} not identical\")\n-\n     def test_torch_save_load(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n         if config.__class__ not in MODEL_MAPPING:\n@@ -3189,7 +3079,7 @@ def _init_weights(self, module):\n         # not to init. the weights during the creation: to match the logic in `from_pretrained`, so we can keep the\n         # same sequence of random ops in the execution path to allow us to compare `target_model` and `new_model` below\n         # for `linear` part.\n-        with ContextManagers([no_init_weights(True)]):\n+        with ContextManagers([no_init_weights()]):\n             target_model = MyClass(config=config)\n         target_model.apply(target_model._initialize_weights)\n "
        }
    ],
    "stats": {
        "total": 1629,
        "additions": 464,
        "deletions": 1165
    }
}