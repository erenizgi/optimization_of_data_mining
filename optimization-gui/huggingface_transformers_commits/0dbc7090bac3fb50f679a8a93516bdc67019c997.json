{
    "author": "zucchini-nlp",
    "message": "Processors: don't default padding side (#33942)\n\n* don't default padding side\r\n\r\n* fix",
    "sha": "0dbc7090bac3fb50f679a8a93516bdc67019c997",
    "files": [
        {
            "sha": "ceafa26a8b1187e2f48cc7ebdc2b45ad8b185eb1",
            "filename": "src/transformers/models/idefics3/processing_idefics3.py",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/0dbc7090bac3fb50f679a8a93516bdc67019c997/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0dbc7090bac3fb50f679a8a93516bdc67019c997/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py?ref=0dbc7090bac3fb50f679a8a93516bdc67019c997",
            "patch": "@@ -235,9 +235,6 @@ def __call__(\n             **kwargs,\n         )\n \n-        # Temporary fix for \"padding_side\" in init_kwargs\n-        output_kwargs[\"text_kwargs\"].pop(\"padding_side\", None)\n-\n         image_seq_len = image_seq_len if image_seq_len is not None else self.image_seq_len\n \n         n_images_in_text = []"
        },
        {
            "sha": "039e05a7ec19a060c12745c08864517371af1153",
            "filename": "src/transformers/models/llava_onevision/processing_llava_onevision.py",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0dbc7090bac3fb50f679a8a93516bdc67019c997/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fprocessing_llava_onevision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0dbc7090bac3fb50f679a8a93516bdc67019c997/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fprocessing_llava_onevision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fprocessing_llava_onevision.py?ref=0dbc7090bac3fb50f679a8a93516bdc67019c997",
            "patch": "@@ -172,8 +172,6 @@ def __call__(\n             num_video_tokens = (num_frames * pooled_height_width * pooled_height_width) + 1  # +1 for newline token\n             text = [sample.replace(self.video_token, self.video_token * num_video_tokens) for sample in text]\n \n-        # Padding side can be in TextKwargs but is not accepted by the tokenizer\n-        _ = output_kwargs[\"text_kwargs\"].pop(\"padding_side\", None)\n         text_inputs = self.tokenizer(text, **output_kwargs[\"text_kwargs\"])\n         return BatchFeature(data={**text_inputs, **image_inputs, **video_inputs})\n "
        },
        {
            "sha": "6c0e8d98014ededa5e4ce99cec44353813dd4346",
            "filename": "src/transformers/models/qwen2_vl/processing_qwen2_vl.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/0dbc7090bac3fb50f679a8a93516bdc67019c997/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fprocessing_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0dbc7090bac3fb50f679a8a93516bdc67019c997/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fprocessing_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fprocessing_qwen2_vl.py?ref=0dbc7090bac3fb50f679a8a93516bdc67019c997",
            "patch": "@@ -150,7 +150,6 @@ def __call__(\n                     index += 1\n                 text[i] = text[i].replace(\"<|placeholder|>\", \"<|video_pad|>\")\n \n-        _ = output_kwargs[\"text_kwargs\"].pop(\"padding_side\", None)\n         text_inputs = self.tokenizer(text, **output_kwargs[\"text_kwargs\"])\n \n         return BatchFeature(data={**text_inputs, **image_inputs, **videos_inputs})"
        },
        {
            "sha": "cb2327e5c46b0d9fb8102a481dca16ba6a79f0f1",
            "filename": "src/transformers/processing_utils.py",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/0dbc7090bac3fb50f679a8a93516bdc67019c997/src%2Ftransformers%2Fprocessing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0dbc7090bac3fb50f679a8a93516bdc67019c997/src%2Ftransformers%2Fprocessing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fprocessing_utils.py?ref=0dbc7090bac3fb50f679a8a93516bdc67019c997",
            "patch": "@@ -829,7 +829,12 @@ class MyProcessingKwargs(ProcessingKwargs, CommonKwargs, TextKwargs, ImagesKwarg\n             for modality_key in ModelProcessorKwargs.__annotations__[modality].__annotations__.keys():\n                 # init with tokenizer init kwargs if necessary\n                 if modality_key in tokenizer_init_kwargs:\n-                    default_kwargs[modality][modality_key] = tokenizer_init_kwargs[modality_key]\n+                    value = (\n+                        getattr(self.tokenizer, modality_key)\n+                        if hasattr(self.tokenizer, modality_key)\n+                        else tokenizer_init_kwargs[modality_key]\n+                    )\n+                    default_kwargs[modality][modality_key] = value\n         # now defaults kwargs are updated with the tokenizers defaults.\n         # pass defaults to output dictionary\n         output_kwargs.update(default_kwargs)"
        }
    ],
    "stats": {
        "total": 13,
        "additions": 6,
        "deletions": 7
    }
}