{
    "author": "ManuelFay",
    "message": "bugfix: propage weight key_mapping to peft to fix 3.52 VLM renaming  (#38627)\n\n* propage key mapping to peft\n\n* propage key mapping to peft\n\n* make requested changes\n\n* revert",
    "sha": "ce6ac53ac104feeb6202303512c611f773f0d1e7",
    "files": [
        {
            "sha": "7148da3dd12b9311e7aacdf41aad42255bc463db",
            "filename": "src/transformers/integrations/peft.py",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce6ac53ac104feeb6202303512c611f773f0d1e7/src%2Ftransformers%2Fintegrations%2Fpeft.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce6ac53ac104feeb6202303512c611f773f0d1e7/src%2Ftransformers%2Fintegrations%2Fpeft.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fintegrations%2Fpeft.py?ref=ce6ac53ac104feeb6202303512c611f773f0d1e7",
            "patch": "@@ -14,6 +14,7 @@\n \n import importlib\n import inspect\n+import re\n import warnings\n from typing import Any, Dict, List, Optional, Union\n \n@@ -149,6 +150,7 @@ def load_adapter(\n \n         # peft only supports low_cpu_mem_usage starting from v0.13.0\n         peft_load_kwargs = {}\n+        key_mapping = adapter_kwargs.pop(\"key_mapping\", None) if adapter_kwargs is not None else None\n         if low_cpu_mem_usage:\n             min_version_lcmu = \"0.13.0\"\n             if version.parse(importlib.metadata.version(\"peft\")) >= version.parse(min_version_lcmu):\n@@ -233,6 +235,13 @@ def load_adapter(\n                 new_key = key[len(prefix) :]\n             else:\n                 new_key = key\n+\n+            if key_mapping:\n+                for pattern, replacement in key_mapping.items():\n+                    new_key, n_replace = re.subn(pattern, replacement, new_key)\n+                    # Early exit of the loop\n+                    if n_replace > 0:\n+                        break\n             processed_adapter_state_dict[new_key] = value\n \n         # Load state dict"
        },
        {
            "sha": "9e30fbb43a1a5382271d46f0ff7ec06093c881de",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/ce6ac53ac104feeb6202303512c611f773f0d1e7/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ce6ac53ac104feeb6202303512c611f773f0d1e7/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=ce6ac53ac104feeb6202303512c611f773f0d1e7",
            "patch": "@@ -4778,6 +4778,7 @@ def _assign_original_dtype(module):\n             model.hf_quantizer = hf_quantizer\n \n         if _adapter_model_path is not None:\n+            adapter_kwargs[\"key_mapping\"] = key_mapping\n             model.load_adapter(\n                 _adapter_model_path,\n                 adapter_name=adapter_name,"
        }
    ],
    "stats": {
        "total": 10,
        "additions": 10,
        "deletions": 0
    }
}