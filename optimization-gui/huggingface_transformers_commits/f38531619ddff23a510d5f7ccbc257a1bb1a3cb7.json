{
    "author": "jiqing-feng",
    "message": "enable QA bf16 pipeline (#34483)\n\n* enable QA bf16 pipeline\r\n\r\n* add tests",
    "sha": "f38531619ddff23a510d5f7ccbc257a1bb1a3cb7",
    "files": [
        {
            "sha": "7b876eefc492793087871602f51fcd6fb55f5244",
            "filename": "src/transformers/pipelines/question_answering.py",
            "status": "modified",
            "additions": 8,
            "deletions": 2,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/f38531619ddff23a510d5f7ccbc257a1bb1a3cb7/src%2Ftransformers%2Fpipelines%2Fquestion_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f38531619ddff23a510d5f7ccbc257a1bb1a3cb7/src%2Ftransformers%2Fpipelines%2Fquestion_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Fquestion_answering.py?ref=f38531619ddff23a510d5f7ccbc257a1bb1a3cb7",
            "patch": "@@ -540,8 +540,14 @@ def postprocess(\n         min_null_score = 1000000  # large and positive\n         answers = []\n         for output in model_outputs:\n-            start_ = output[\"start\"]\n-            end_ = output[\"end\"]\n+            if self.framework == \"pt\" and output[\"start\"].dtype == torch.bfloat16:\n+                start_ = output[\"start\"].to(torch.float32)\n+            else:\n+                start_ = output[\"start\"]\n+            if self.framework == \"pt\" and output[\"start\"].dtype == torch.bfloat16:\n+                end_ = output[\"end\"].to(torch.float32)\n+            else:\n+                end_ = output[\"end\"]\n             example = output[\"example\"]\n             p_mask = output[\"p_mask\"]\n             attention_mask = ("
        },
        {
            "sha": "bf4fc7db1db6b5a0cf4768df48119b0e4ae2bd80",
            "filename": "tests/pipelines/test_pipelines_question_answering.py",
            "status": "modified",
            "additions": 33,
            "deletions": 0,
            "changes": 33,
            "blob_url": "https://github.com/huggingface/transformers/blob/f38531619ddff23a510d5f7ccbc257a1bb1a3cb7/tests%2Fpipelines%2Ftest_pipelines_question_answering.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f38531619ddff23a510d5f7ccbc257a1bb1a3cb7/tests%2Fpipelines%2Ftest_pipelines_question_answering.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_question_answering.py?ref=f38531619ddff23a510d5f7ccbc257a1bb1a3cb7",
            "patch": "@@ -27,13 +27,18 @@\n from transformers.testing_utils import (\n     compare_pipeline_output_to_hub_spec,\n     is_pipeline_test,\n+    is_torch_available,\n     nested_simplify,\n     require_tf,\n     require_torch,\n     require_torch_or_tf,\n     slow,\n )\n \n+\n+if is_torch_available():\n+    import torch\n+\n from .test_pipelines_common import ANY\n \n \n@@ -165,6 +170,34 @@ def test_small_model_pt(self):\n \n         self.assertEqual(nested_simplify(outputs), {\"score\": 0.01, \"start\": 0, \"end\": 11, \"answer\": \"HuggingFace\"})\n \n+    @require_torch\n+    def test_small_model_pt_fp16(self):\n+        question_answerer = pipeline(\n+            \"question-answering\",\n+            model=\"sshleifer/tiny-distilbert-base-cased-distilled-squad\",\n+            torch_dtype=torch.float16,\n+        )\n+\n+        outputs = question_answerer(\n+            question=\"Where was HuggingFace founded ?\", context=\"HuggingFace was founded in Paris.\"\n+        )\n+\n+        self.assertEqual(nested_simplify(outputs), {\"score\": 0.01, \"start\": 0, \"end\": 11, \"answer\": \"HuggingFace\"})\n+\n+    @require_torch\n+    def test_small_model_pt_bf16(self):\n+        question_answerer = pipeline(\n+            \"question-answering\",\n+            model=\"sshleifer/tiny-distilbert-base-cased-distilled-squad\",\n+            torch_dtype=torch.bfloat16,\n+        )\n+\n+        outputs = question_answerer(\n+            question=\"Where was HuggingFace founded ?\", context=\"HuggingFace was founded in Paris.\"\n+        )\n+\n+        self.assertEqual(nested_simplify(outputs), {\"score\": 0.01, \"start\": 0, \"end\": 11, \"answer\": \"HuggingFace\"})\n+\n     @require_torch\n     def test_small_model_pt_iterator(self):\n         # https://github.com/huggingface/transformers/issues/18510"
        }
    ],
    "stats": {
        "total": 43,
        "additions": 41,
        "deletions": 2
    }
}