{
    "author": "BakerBunker",
    "message": "Modify Qwen3Omni parameter name since VL changed it (#41045)\n\nModify parameter name since VL changed it\n\nCo-authored-by: lvyuanjun.lyj <lvyuanjun.lyj@alibaba-inc.com>",
    "sha": "db802aafa447c056956fd7cd01a5bac6200b3acf",
    "files": [
        {
            "sha": "1172ebf909197f31b5241ebb73bea35178ed9f9e",
            "filename": "src/transformers/models/qwen3_omni_moe/modeling_qwen3_omni_moe.py",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/db802aafa447c056956fd7cd01a5bac6200b3acf/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/db802aafa447c056956fd7cd01a5bac6200b3acf/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py?ref=db802aafa447c056956fd7cd01a5bac6200b3acf",
            "patch": "@@ -1722,9 +1722,8 @@ def forward(\n             past_key_values=past_key_values,\n         )\n \n-    def _deepstack_process(\n-        self, hidden_states: torch.Tensor, visual_pos_masks: torch.Tensor, visual_embeds: torch.Tensor\n-    ):\n+    def _deepstack_process(self, hidden_states, visual_pos_masks, visual_embeds):\n+        visual_pos_masks = visual_pos_masks[..., 0]\n         visual_pos_masks = visual_pos_masks.to(hidden_states.device)\n         visual_embeds = visual_embeds.to(hidden_states.device, hidden_states.dtype)\n         local_this = hidden_states[visual_pos_masks, :].clone() + visual_embeds\n@@ -2151,7 +2150,7 @@ def forward(\n             use_cache=use_cache,\n             output_router_logits=output_router_logits,\n             cache_position=cache_position,\n-            deepstack_visual_embeds_multiscale=visual_embeds_multiscale,\n+            deepstack_visual_embeds=visual_embeds_multiscale,\n             visual_pos_masks=visual_pos_masks,\n             **kwargs,\n         )"
        },
        {
            "sha": "4d1c30f0a4c31d1bb4d52cbf8f15ee89a603e0a7",
            "filename": "src/transformers/models/qwen3_omni_moe/modular_qwen3_omni_moe.py",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/db802aafa447c056956fd7cd01a5bac6200b3acf/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodular_qwen3_omni_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/db802aafa447c056956fd7cd01a5bac6200b3acf/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodular_qwen3_omni_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodular_qwen3_omni_moe.py?ref=db802aafa447c056956fd7cd01a5bac6200b3acf",
            "patch": "@@ -1228,6 +1228,10 @@ def __init__(self, config: Qwen3OmniMoeTextConfig):\n         )\n         self.rotary_emb = Qwen3OmniMoeThinkerTextRotaryEmbedding(config)\n \n+    def _deepstack_process(self, hidden_states, visual_pos_masks, visual_embeds):\n+        visual_pos_masks = visual_pos_masks[..., 0]\n+        return super()._deepstack_process(hidden_states, visual_pos_masks, visual_embeds)\n+\n \n @dataclass\n class Qwen3OmniMoeThinkerCausalLMOutputWithPast(MoeCausalLMOutputWithPast):\n@@ -1408,7 +1412,7 @@ def forward(\n             use_cache=use_cache,\n             output_router_logits=output_router_logits,\n             cache_position=cache_position,\n-            deepstack_visual_embeds_multiscale=visual_embeds_multiscale,\n+            deepstack_visual_embeds=visual_embeds_multiscale,\n             visual_pos_masks=visual_pos_masks,\n             **kwargs,\n         )"
        }
    ],
    "stats": {
        "total": 13,
        "additions": 8,
        "deletions": 5
    }
}