{
    "author": "gante",
    "message": "[tests] remove `test_export_to_onnx` (#36241)",
    "sha": "429f1a682dfa2b4b5672f8c703e8c607857a18db",
    "files": [
        {
            "sha": "f9bec05743ca8a13dfe42bd81a2a22f3d0757240",
            "filename": "tests/models/fsmt/test_modeling_fsmt.py",
            "status": "modified",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/429f1a682dfa2b4b5672f8c703e8c607857a18db/tests%2Fmodels%2Ffsmt%2Ftest_modeling_fsmt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/429f1a682dfa2b4b5672f8c703e8c607857a18db/tests%2Fmodels%2Ffsmt%2Ftest_modeling_fsmt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ffsmt%2Ftest_modeling_fsmt.py?ref=429f1a682dfa2b4b5672f8c703e8c607857a18db",
            "patch": "@@ -262,20 +262,6 @@ def test_save_load_missing_keys(self):\n                 model2, info = model_class.from_pretrained(tmpdirname, output_loading_info=True)\n             self.assertEqual(info[\"missing_keys\"], [])\n \n-    @unittest.skip(reason=\"Test has a segmentation fault on torch 1.8.0\")\n-    def test_export_to_onnx(self):\n-        config, inputs_dict = self.model_tester.prepare_config_and_inputs()\n-        model = FSMTModel(config).to(torch_device)\n-        with tempfile.TemporaryDirectory() as tmpdirname:\n-            torch.onnx.export(\n-                model,\n-                (inputs_dict[\"input_ids\"], inputs_dict[\"attention_mask\"]),\n-                f\"{tmpdirname}/fsmt_test.onnx\",\n-                export_params=True,\n-                opset_version=12,\n-                input_names=[\"input_ids\", \"attention_mask\"],\n-            )\n-\n     def test_ensure_weights_are_shared(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs()\n "
        },
        {
            "sha": "6ec347fe055da6d674dfa9fe59640518839065f2",
            "filename": "tests/models/longt5/test_modeling_longt5.py",
            "status": "modified",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/429f1a682dfa2b4b5672f8c703e8c607857a18db/tests%2Fmodels%2Flongt5%2Ftest_modeling_longt5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/429f1a682dfa2b4b5672f8c703e8c607857a18db/tests%2Fmodels%2Flongt5%2Ftest_modeling_longt5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flongt5%2Ftest_modeling_longt5.py?ref=429f1a682dfa2b4b5672f8c703e8c607857a18db",
            "patch": "@@ -627,20 +627,6 @@ def test_model_from_pretrained(self):\n         model = LongT5Model.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    @slow\n-    def test_export_to_onnx(self):\n-        config_and_inputs = self.model_tester.prepare_config_and_inputs()\n-        model = LongT5Model(config_and_inputs[0]).to(torch_device)\n-        with tempfile.TemporaryDirectory() as tmpdirname:\n-            torch.onnx.export(\n-                model,\n-                (config_and_inputs[1], config_and_inputs[3], config_and_inputs[2]),\n-                f\"{tmpdirname}/longt5_test.onnx\",\n-                export_params=True,\n-                opset_version=14,\n-                input_names=[\"input_ids\", \"decoder_input_ids\"],\n-            )\n-\n     def test_generate_with_head_masking(self):\n         attention_names = [\"encoder_attentions\", \"decoder_attentions\", \"cross_attentions\"]\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()"
        },
        {
            "sha": "185bd149175e8bba23f632cca1ff289dd015bcb5",
            "filename": "tests/models/mt5/test_modeling_mt5.py",
            "status": "modified",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/429f1a682dfa2b4b5672f8c703e8c607857a18db/tests%2Fmodels%2Fmt5%2Ftest_modeling_mt5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/429f1a682dfa2b4b5672f8c703e8c607857a18db/tests%2Fmodels%2Fmt5%2Ftest_modeling_mt5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmt5%2Ftest_modeling_mt5.py?ref=429f1a682dfa2b4b5672f8c703e8c607857a18db",
            "patch": "@@ -871,20 +871,6 @@ def test_model_from_pretrained(self):\n         model = MT5Model.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    @unittest.skip(reason=\"Test has a segmentation fault on torch 1.8.0\")\n-    def test_export_to_onnx(self):\n-        config_and_inputs = self.model_tester.prepare_config_and_inputs()\n-        model = MT5Model(config_and_inputs[0]).to(torch_device)\n-        with tempfile.TemporaryDirectory() as tmpdirname:\n-            torch.onnx.export(\n-                model,\n-                (config_and_inputs[1], config_and_inputs[3], config_and_inputs[2]),\n-                f\"{tmpdirname}/t5_test.onnx\",\n-                export_params=True,\n-                opset_version=9,\n-                input_names=[\"input_ids\", \"decoder_input_ids\"],\n-            )\n-\n     def test_generate_with_head_masking(self):\n         attention_names = [\"encoder_attentions\", \"decoder_attentions\", \"cross_attentions\"]\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()"
        },
        {
            "sha": "e1f52770c0440b5f4ff3741261d062c185adb90f",
            "filename": "tests/models/pop2piano/test_modeling_pop2piano.py",
            "status": "modified",
            "additions": 0,
            "deletions": 15,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/429f1a682dfa2b4b5672f8c703e8c607857a18db/tests%2Fmodels%2Fpop2piano%2Ftest_modeling_pop2piano.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/429f1a682dfa2b4b5672f8c703e8c607857a18db/tests%2Fmodels%2Fpop2piano%2Ftest_modeling_pop2piano.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpop2piano%2Ftest_modeling_pop2piano.py?ref=429f1a682dfa2b4b5672f8c703e8c607857a18db",
            "patch": "@@ -26,7 +26,6 @@\n from transformers.testing_utils import (\n     require_essentia,\n     require_librosa,\n-    require_onnx,\n     require_scipy,\n     require_torch,\n     slow,\n@@ -611,20 +610,6 @@ def test_model_from_pretrained(self):\n         model = Pop2PianoForConditionalGeneration.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    @require_onnx\n-    def test_export_to_onnx(self):\n-        config_and_inputs = self.model_tester.prepare_config_and_inputs()\n-        model = Pop2PianoForConditionalGeneration(config_and_inputs[0]).to(torch_device)\n-        with tempfile.TemporaryDirectory() as tmpdirname:\n-            torch.onnx.export(\n-                model,\n-                (config_and_inputs[1], config_and_inputs[3], config_and_inputs[2]),\n-                f\"{tmpdirname}/Pop2Piano_test.onnx\",\n-                export_params=True,\n-                opset_version=14,\n-                input_names=[\"input_ids\", \"decoder_input_ids\"],\n-            )\n-\n     def test_pass_with_input_features(self):\n         input_features = BatchFeature(\n             {"
        },
        {
            "sha": "cb62d364c158c073eefe640482abfa0f0fbe7d55",
            "filename": "tests/models/switch_transformers/test_modeling_switch_transformers.py",
            "status": "modified",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/429f1a682dfa2b4b5672f8c703e8c607857a18db/tests%2Fmodels%2Fswitch_transformers%2Ftest_modeling_switch_transformers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/429f1a682dfa2b4b5672f8c703e8c607857a18db/tests%2Fmodels%2Fswitch_transformers%2Ftest_modeling_switch_transformers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fswitch_transformers%2Ftest_modeling_switch_transformers.py?ref=429f1a682dfa2b4b5672f8c703e8c607857a18db",
            "patch": "@@ -709,20 +709,6 @@ def test_model_from_pretrained(self):\n         model = SwitchTransformersModel.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    @unittest.skip(reason=\"Test has a segmentation fault on torch 1.8.0\")\n-    def test_export_to_onnx(self):\n-        config_and_inputs = self.model_tester.prepare_config_and_inputs()\n-        model = SwitchTransformersModel(config_and_inputs[0]).to(torch_device)\n-        with tempfile.TemporaryDirectory() as tmpdirname:\n-            torch.onnx.export(\n-                model,\n-                (config_and_inputs[1], config_and_inputs[3], config_and_inputs[2]),\n-                f\"{tmpdirname}/switch_transformers_test.onnx\",\n-                export_params=True,\n-                opset_version=9,\n-                input_names=[\"input_ids\", \"decoder_input_ids\"],\n-            )\n-\n     def test_generate_with_head_masking(self):\n         attention_names = [\"encoder_attentions\", \"decoder_attentions\", \"cross_attentions\"]\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()"
        },
        {
            "sha": "03a6adb1a916700403aab735b8c5bdd8b00d9119",
            "filename": "tests/models/t5/test_modeling_t5.py",
            "status": "modified",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/429f1a682dfa2b4b5672f8c703e8c607857a18db/tests%2Fmodels%2Ft5%2Ftest_modeling_t5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/429f1a682dfa2b4b5672f8c703e8c607857a18db/tests%2Fmodels%2Ft5%2Ftest_modeling_t5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ft5%2Ftest_modeling_t5.py?ref=429f1a682dfa2b4b5672f8c703e8c607857a18db",
            "patch": "@@ -875,20 +875,6 @@ def test_model_from_pretrained(self):\n         model = T5Model.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n-    @unittest.skip(reason=\"Test has a segmentation fault on torch 1.8.0\")\n-    def test_export_to_onnx(self):\n-        config_and_inputs = self.model_tester.prepare_config_and_inputs()\n-        model = T5Model(config_and_inputs[0]).to(torch_device)\n-        with tempfile.TemporaryDirectory() as tmpdirname:\n-            torch.onnx.export(\n-                model,\n-                (config_and_inputs[1], config_and_inputs[3], config_and_inputs[2]),\n-                f\"{tmpdirname}/t5_test.onnx\",\n-                export_params=True,\n-                opset_version=9,\n-                input_names=[\"input_ids\", \"decoder_input_ids\"],\n-            )\n-\n     def test_generate_with_head_masking(self):\n         attention_names = [\"encoder_attentions\", \"decoder_attentions\", \"cross_attentions\"]\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()"
        },
        {
            "sha": "c274efcf938dbd8af79f003a10f3adb9db798de2",
            "filename": "tests/models/umt5/test_modeling_umt5.py",
            "status": "modified",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/huggingface/transformers/blob/429f1a682dfa2b4b5672f8c703e8c607857a18db/tests%2Fmodels%2Fumt5%2Ftest_modeling_umt5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/429f1a682dfa2b4b5672f8c703e8c607857a18db/tests%2Fmodels%2Fumt5%2Ftest_modeling_umt5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fumt5%2Ftest_modeling_umt5.py?ref=429f1a682dfa2b4b5672f8c703e8c607857a18db",
            "patch": "@@ -525,20 +525,6 @@ def test_with_sequence_classification_head(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_with_sequence_classification_head(*config_and_inputs)\n \n-    @unittest.skip(reason=\"Test has a segmentation fault on torch 1.8.0\")\n-    def test_export_to_onnx(self):\n-        config_and_inputs = self.model_tester.prepare_config_and_inputs()\n-        model = UMT5Model(config_and_inputs[0]).to(torch_device)\n-        with tempfile.TemporaryDirectory() as tmpdirname:\n-            torch.onnx.export(\n-                model,\n-                (config_and_inputs[1], config_and_inputs[3], config_and_inputs[2]),\n-                f\"{tmpdirname}/t5_test.onnx\",\n-                export_params=True,\n-                opset_version=9,\n-                input_names=[\"input_ids\", \"decoder_input_ids\"],\n-            )\n-\n     @unittest.skipIf(torch_device == \"cpu\", \"Cant do half precision\")\n     def test_model_fp16_forward(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()"
        }
    ],
    "stats": {
        "total": 99,
        "additions": 0,
        "deletions": 99
    }
}