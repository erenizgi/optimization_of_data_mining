{
    "author": "Xqle",
    "message": "fix: improve video processing fps assignment logic (#42009)\n\n* fix: improve video processing fps and do_sample_frames assignment logic\n\n* fix: set return_metadata=True to get metadata\n\n* reformat the modular file\n\n* fix typo\n\n* revert flag change and fix fps assignment\n\n* Taking 'num_frames' into considered.\n\nAvoid error when 'num_frames' is passed rather than 'fps'.\n\n* fix\n\n* fix: avoid potential reference before assignment error\n\n* fix\n\n* add 'sample_fps' to 'VideoMetadata'\n\n* fix missing comma\n\n* fix trailing whitespace\n\n* Handle different 'sample_indices_fn'\n\n* Cleaning white space\n\n* import callable from collections.abc\n\n* calculate sampled_fps using indices\n\n* correct the order\n\n* fix\n\n* properly check  value in kwargs\n\n* handle sampled_fps as property\n\n* remove duplicated definition\n\n* fix\n\n* fix\n\n* add safety check\n\n---------\n\nCo-authored-by: Raushan Turganbay <raushan@huggingface.co>",
    "sha": "3c0b2b101ec4bd68bf1c0c3edfd81ccd9a422236",
    "files": [
        {
            "sha": "dc88dd02ee73c13c2d133d974041d543b6b5f90d",
            "filename": "src/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/3c0b2b101ec4bd68bf1c0c3edfd81ccd9a422236/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3c0b2b101ec4bd68bf1c0c3edfd81ccd9a422236/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fmodular_qwen2_5_vl.py?ref=3c0b2b101ec4bd68bf1c0c3edfd81ccd9a422236",
            "patch": "@@ -839,6 +839,7 @@ class Qwen2_5_VLProcessorKwargs(ProcessingKwargs, total=False):\n             \"padding\": False,\n             \"return_mm_token_type_ids\": False,\n         },\n+        \"videos_kwargs\": {\"return_metadata\": True},\n     }\n \n \n@@ -922,10 +923,17 @@ def __call__(\n             image_grid_thw = image_inputs[\"image_grid_thw\"]\n \n         if videos is not None:\n-            fps = output_kwargs[\"videos_kwargs\"].get(\"fps\", 2.0)\n             videos_inputs = self.video_processor(videos=videos, **output_kwargs[\"videos_kwargs\"])\n             video_grid_thw = videos_inputs[\"video_grid_thw\"]\n \n+            # Get video metadata\n+            if not kwargs.get(\"return_metadata\"):\n+                video_metadata = videos_inputs.pop(\"video_metadata\")\n+            else:\n+                video_metadata = videos_inputs[\"video_metadata\"]\n+\n+            fps = [metadata.sampled_fps for metadata in video_metadata]\n+\n             if isinstance(fps, (int, float)):\n                 second_per_grid_ts = [self.video_processor.temporal_patch_size / fps] * len(video_grid_thw)\n             elif hasattr(fps, \"__len__\") and len(fps) == len(video_grid_thw):"
        },
        {
            "sha": "b3ec8c9b1cd5c72ec8de252766e07e5d4ae5ae7f",
            "filename": "src/transformers/models/qwen2_5_vl/processing_qwen2_5_vl.py",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/3c0b2b101ec4bd68bf1c0c3edfd81ccd9a422236/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fprocessing_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3c0b2b101ec4bd68bf1c0c3edfd81ccd9a422236/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fprocessing_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fprocessing_qwen2_5_vl.py?ref=3c0b2b101ec4bd68bf1c0c3edfd81ccd9a422236",
            "patch": "@@ -41,6 +41,7 @@ class Qwen2_5_VLProcessorKwargs(ProcessingKwargs, total=False):\n             \"padding\": False,\n             \"return_mm_token_type_ids\": False,\n         },\n+        \"videos_kwargs\": {\"return_metadata\": True},\n     }\n \n \n@@ -129,10 +130,17 @@ def __call__(\n             image_grid_thw = image_inputs[\"image_grid_thw\"]\n \n         if videos is not None:\n-            fps = output_kwargs[\"videos_kwargs\"].get(\"fps\", 2.0)\n             videos_inputs = self.video_processor(videos=videos, **output_kwargs[\"videos_kwargs\"])\n             video_grid_thw = videos_inputs[\"video_grid_thw\"]\n \n+            # Get video metadata\n+            if not kwargs.get(\"return_metadata\"):\n+                video_metadata = videos_inputs.pop(\"video_metadata\")\n+            else:\n+                video_metadata = videos_inputs[\"video_metadata\"]\n+\n+            fps = [metadata.sampled_fps for metadata in video_metadata]\n+\n             if isinstance(fps, (int, float)):\n                 second_per_grid_ts = [self.video_processor.temporal_patch_size / fps] * len(video_grid_thw)\n             elif hasattr(fps, \"__len__\") and len(fps) == len(video_grid_thw):"
        },
        {
            "sha": "49f4d74a62440596512d760ded8a0bbd81a6eedc",
            "filename": "src/transformers/video_utils.py",
            "status": "modified",
            "additions": 14,
            "deletions": 6,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/3c0b2b101ec4bd68bf1c0c3edfd81ccd9a422236/src%2Ftransformers%2Fvideo_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3c0b2b101ec4bd68bf1c0c3edfd81ccd9a422236/src%2Ftransformers%2Fvideo_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fvideo_utils.py?ref=3c0b2b101ec4bd68bf1c0c3edfd81ccd9a422236",
            "patch": "@@ -106,6 +106,13 @@ def timestamps(self) -> list[float]:\n             raise ValueError(\"Cannot infer video `timestamps` when `fps` or `frames_indices` is None.\")\n         return [frame_idx / self.fps for frame_idx in self.frames_indices]\n \n+    @property\n+    def sampled_fps(self) -> float:\n+        \"FPS of the sampled video.\"\n+        if self.frames_indices is None or self.total_num_frames is None or self.fps is None:\n+            return self.fps or 24\n+        return len(self.frames_indices) / self.total_num_frames * self.fps\n+\n     def update(self, dictionary):\n         for key, value in dictionary.items():\n             if hasattr(self, key):\n@@ -372,8 +379,8 @@ def sample_indices_fn(metadata, **kwargs):\n         height=int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n         width=int(video.get(cv2.CAP_PROP_FRAME_WIDTH)),\n     )\n-    indices = sample_indices_fn(metadata=metadata, **kwargs)\n \n+    indices = sample_indices_fn(metadata=metadata, **kwargs)\n     index = 0\n     frames = []\n     while video.isOpened():\n@@ -486,8 +493,8 @@ def sample_indices_fn(metadata, **kwargs):\n         height=container.streams.video[0].height,\n         width=container.streams.video[0].width,\n     )\n-    indices = sample_indices_fn(metadata=metadata, **kwargs)\n \n+    indices = sample_indices_fn(metadata=metadata, **kwargs)\n     frames = []\n     container.seek(0)\n     end_index = indices[-1]\n@@ -548,7 +555,6 @@ def sample_indices_fn(metadata, **kwargs):\n     )\n \n     indices = sample_indices_fn(metadata=metadata, **kwargs)\n-\n     video = video[indices].contiguous()\n     metadata.update(\n         {\n@@ -596,16 +602,18 @@ def sample_indices_fn(metadata, **kwargs):\n         num_ffmpeg_threads=0,\n         device=kwargs.get(\"device\", \"cpu\"),\n     )\n+    total_num_frames = decoder.metadata.num_frames\n+    video_fps = decoder.metadata.average_fps\n     metadata = VideoMetadata(\n-        total_num_frames=decoder.metadata.num_frames,\n-        fps=decoder.metadata.average_fps,\n+        total_num_frames=total_num_frames,\n+        fps=video_fps,\n         duration=decoder.metadata.duration_seconds,\n         video_backend=\"torchcodec\",\n         height=decoder.metadata.height,\n         width=decoder.metadata.width,\n     )\n-    indices = sample_indices_fn(metadata=metadata, **kwargs)\n \n+    indices = sample_indices_fn(metadata=metadata, **kwargs)\n     video = decoder.get_frames_at(indices=indices).data.contiguous()\n     metadata.frames_indices = indices\n     return video, metadata"
        }
    ],
    "stats": {
        "total": 40,
        "additions": 32,
        "deletions": 8
    }
}