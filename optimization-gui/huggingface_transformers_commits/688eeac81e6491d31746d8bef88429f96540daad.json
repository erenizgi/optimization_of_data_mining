{
    "author": "faaany",
    "message": "[docs] fix typo  (#34235)\n\nfix typo",
    "sha": "688eeac81e6491d31746d8bef88429f96540daad",
    "files": [
        {
            "sha": "404b6eac7fe44b8d3b529fad02911dfd5e9c2284",
            "filename": "docs/source/en/quicktour.md",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/688eeac81e6491d31746d8bef88429f96540daad/docs%2Fsource%2Fen%2Fquicktour.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/688eeac81e6491d31746d8bef88429f96540daad/docs%2Fsource%2Fen%2Fquicktour.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fquicktour.md?ref=688eeac81e6491d31746d8bef88429f96540daad",
            "patch": "@@ -360,17 +360,17 @@ One particularly cool ðŸ¤— Transformers feature is the ability to save a model a\n ```py\n >>> from transformers import AutoModel\n \n->>> tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)\n->>> pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)\n+>>> tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n+>>> pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)\n ```\n </pt>\n <tf>\n \n ```py\n >>> from transformers import TFAutoModel\n \n->>> tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n->>> tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)\n+>>> tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)\n+>>> tf_model = TFAutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)\n ```\n </tf>\n </frameworkcontent>"
        }
    ],
    "stats": {
        "total": 8,
        "additions": 4,
        "deletions": 4
    }
}