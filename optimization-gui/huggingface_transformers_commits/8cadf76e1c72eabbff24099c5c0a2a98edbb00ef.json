{
    "author": "philkuz",
    "message": "fix(DPT,Depth-Anything) `torch.export` (#34103)\n\n* Fix torch.export issue in dpt based models\r\n\r\nSigned-off-by: Phillip Kuznetsov <philkuz@gimletlabs.ai>\r\n\r\n* Simplify the if statements\r\n\r\nSigned-off-by: Phillip Kuznetsov <philkuz@gimletlabs.ai>\r\n\r\n* Move activation definitions of zoe_depth to init()\r\n\r\nSigned-off-by: Phillip Kuznetsov <philkuz@gimletlabs.ai>\r\n\r\n* Add test_export for dpt and zoedepth\r\n\r\nSigned-off-by: Phillip Kuznetsov <philkuz@gimletlabs.ai>\r\n\r\n* add depth anything\r\n\r\nSigned-off-by: Phillip Kuznetsov <philkuz@gimletlabs.ai>\r\n\r\n* Remove zoedepth non-automated zoedepth changes and zoedepth test\r\n\r\nSigned-off-by: Phillip Kuznetsov <philkuz@gimletlabs.ai>\r\n\r\n* [run_slow] dpt, depth_anything, zoedepth\r\n\r\nSigned-off-by: Phillip Kuznetsov <philkuz@gimletlabs.ai>\r\n\r\n---------\r\n\r\nSigned-off-by: Phillip Kuznetsov <philkuz@gimletlabs.ai>",
    "sha": "8cadf76e1c72eabbff24099c5c0a2a98edbb00ef",
    "files": [
        {
            "sha": "4667c413457b1970c05689752224806e751a3f6b",
            "filename": "src/transformers/models/depth_anything/modeling_depth_anything.py",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/8cadf76e1c72eabbff24099c5c0a2a98edbb00ef/src%2Ftransformers%2Fmodels%2Fdepth_anything%2Fmodeling_depth_anything.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8cadf76e1c72eabbff24099c5c0a2a98edbb00ef/src%2Ftransformers%2Fmodels%2Fdepth_anything%2Fmodeling_depth_anything.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdepth_anything%2Fmodeling_depth_anything.py?ref=8cadf76e1c72eabbff24099c5c0a2a98edbb00ef",
            "patch": "@@ -224,16 +224,16 @@ def forward(self, hidden_states, size=None):\n         hidden_states = hidden_states[::-1]\n \n         fused_hidden_states = []\n-        # first layer only uses the last hidden_state\n-        size = hidden_states[1].shape[2:]\n-        fused_hidden_state = self.layers[0](hidden_states[0], size=size)\n-        fused_hidden_states.append(fused_hidden_state)\n+        fused_hidden_state = None\n \n-        # looping from the last layer to the second\n-        for idx, (hidden_state, layer) in enumerate(zip(hidden_states[1:], self.layers[1:])):\n-            size = hidden_states[1:][idx + 1].shape[2:] if idx != (len(hidden_states[1:]) - 1) else None\n+        for idx, (hidden_state, layer) in enumerate(zip(hidden_states, self.layers)):\n+            size = hidden_states[idx + 1].shape[2:] if idx != (len(hidden_states) - 1) else None\n \n-            fused_hidden_state = layer(fused_hidden_state, hidden_state, size=size)\n+            if fused_hidden_state is None:\n+                # first layer only uses the last hidden_state\n+                fused_hidden_state = layer(hidden_state, size=size)\n+            else:\n+                fused_hidden_state = layer(fused_hidden_state, hidden_state, size=size)\n \n             fused_hidden_states.append(fused_hidden_state)\n "
        },
        {
            "sha": "5886d288b88271fc45eae502790f5cc37fa1c6af",
            "filename": "src/transformers/models/dpt/modeling_dpt.py",
            "status": "modified",
            "additions": 7,
            "deletions": 6,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/8cadf76e1c72eabbff24099c5c0a2a98edbb00ef/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8cadf76e1c72eabbff24099c5c0a2a98edbb00ef/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdpt%2Fmodeling_dpt.py?ref=8cadf76e1c72eabbff24099c5c0a2a98edbb00ef",
            "patch": "@@ -689,12 +689,13 @@ def forward(self, hidden_states):\n         hidden_states = hidden_states[::-1]\n \n         fused_hidden_states = []\n-        # first layer only uses the last hidden_state\n-        fused_hidden_state = self.layers[0](hidden_states[0])\n-        fused_hidden_states.append(fused_hidden_state)\n-        # looping from the last layer to the second\n-        for hidden_state, layer in zip(hidden_states[1:], self.layers[1:]):\n-            fused_hidden_state = layer(fused_hidden_state, hidden_state)\n+        fused_hidden_state = None\n+        for hidden_state, layer in zip(hidden_states, self.layers):\n+            if fused_hidden_state is None:\n+                # first layer only uses the last hidden_state\n+                fused_hidden_state = layer(hidden_state)\n+            else:\n+                fused_hidden_state = layer(fused_hidden_state, hidden_state)\n             fused_hidden_states.append(fused_hidden_state)\n \n         return fused_hidden_states"
        },
        {
            "sha": "5cbbdcdc04b756db130cf66d554489b6271d8924",
            "filename": "src/transformers/models/zoedepth/modeling_zoedepth.py",
            "status": "modified",
            "additions": 7,
            "deletions": 6,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/8cadf76e1c72eabbff24099c5c0a2a98edbb00ef/src%2Ftransformers%2Fmodels%2Fzoedepth%2Fmodeling_zoedepth.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8cadf76e1c72eabbff24099c5c0a2a98edbb00ef/src%2Ftransformers%2Fmodels%2Fzoedepth%2Fmodeling_zoedepth.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fzoedepth%2Fmodeling_zoedepth.py?ref=8cadf76e1c72eabbff24099c5c0a2a98edbb00ef",
            "patch": "@@ -185,12 +185,13 @@ def forward(self, hidden_states):\n         hidden_states = hidden_states[::-1]\n \n         fused_hidden_states = []\n-        # first layer only uses the last hidden_state\n-        fused_hidden_state = self.layers[0](hidden_states[0])\n-        fused_hidden_states.append(fused_hidden_state)\n-        # looping from the last layer to the second\n-        for hidden_state, layer in zip(hidden_states[1:], self.layers[1:]):\n-            fused_hidden_state = layer(fused_hidden_state, hidden_state)\n+        fused_hidden_state = None\n+        for hidden_state, layer in zip(hidden_states, self.layers):\n+            if fused_hidden_state is None:\n+                # first layer only uses the last hidden_state\n+                fused_hidden_state = layer(hidden_state)\n+            else:\n+                fused_hidden_state = layer(fused_hidden_state, hidden_state)\n             fused_hidden_states.append(fused_hidden_state)\n \n         return fused_hidden_states"
        },
        {
            "sha": "6e7b423e9ec35f2706b381a828eb01a783b6c33b",
            "filename": "tests/models/depth_anything/test_modeling_depth_anything.py",
            "status": "modified",
            "additions": 28,
            "deletions": 0,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/8cadf76e1c72eabbff24099c5c0a2a98edbb00ef/tests%2Fmodels%2Fdepth_anything%2Ftest_modeling_depth_anything.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8cadf76e1c72eabbff24099c5c0a2a98edbb00ef/tests%2Fmodels%2Fdepth_anything%2Ftest_modeling_depth_anything.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdepth_anything%2Ftest_modeling_depth_anything.py?ref=8cadf76e1c72eabbff24099c5c0a2a98edbb00ef",
            "patch": "@@ -18,6 +18,7 @@\n \n from transformers import DepthAnythingConfig, Dinov2Config\n from transformers.file_utils import is_torch_available, is_vision_available\n+from transformers.pytorch_utils import is_torch_greater_or_equal_than_2_4\n from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n@@ -290,3 +291,30 @@ def test_inference(self):\n         ).to(torch_device)\n \n         self.assertTrue(torch.allclose(predicted_depth[0, :3, :3], expected_slice, atol=1e-4))\n+\n+    def test_export(self):\n+        for strict in [True, False]:\n+            with self.subTest(strict=strict):\n+                if not is_torch_greater_or_equal_than_2_4:\n+                    self.skipTest(reason=\"This test requires torch >= 2.4 to run.\")\n+                model = (\n+                    DepthAnythingForDepthEstimation.from_pretrained(\"LiheYoung/depth-anything-small-hf\")\n+                    .to(torch_device)\n+                    .eval()\n+                )\n+                image_processor = DPTImageProcessor.from_pretrained(\"LiheYoung/depth-anything-small-hf\")\n+                image = prepare_img()\n+                inputs = image_processor(images=image, return_tensors=\"pt\").to(torch_device)\n+\n+                exported_program = torch.export.export(\n+                    model,\n+                    args=(inputs[\"pixel_values\"],),\n+                    strict=strict,\n+                )\n+                with torch.no_grad():\n+                    eager_outputs = model(**inputs)\n+                    exported_outputs = exported_program.module().forward(inputs[\"pixel_values\"])\n+                self.assertEqual(eager_outputs.predicted_depth.shape, exported_outputs.predicted_depth.shape)\n+                self.assertTrue(\n+                    torch.allclose(eager_outputs.predicted_depth, exported_outputs.predicted_depth, atol=1e-4)\n+                )"
        },
        {
            "sha": "7f841fbb2efc588e348e1506e0d2bd61d696f522",
            "filename": "tests/models/dpt/test_modeling_dpt.py",
            "status": "modified",
            "additions": 22,
            "deletions": 0,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/8cadf76e1c72eabbff24099c5c0a2a98edbb00ef/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8cadf76e1c72eabbff24099c5c0a2a98edbb00ef/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdpt%2Ftest_modeling_dpt.py?ref=8cadf76e1c72eabbff24099c5c0a2a98edbb00ef",
            "patch": "@@ -18,6 +18,7 @@\n \n from transformers import DPTConfig\n from transformers.file_utils import is_torch_available, is_vision_available\n+from transformers.pytorch_utils import is_torch_greater_or_equal_than_2_4\n from transformers.testing_utils import require_torch, require_vision, slow, torch_device\n \n from ...test_configuration_common import ConfigTester\n@@ -410,3 +411,24 @@ def test_post_processing_depth_estimation(self):\n         ).squeeze()\n         self.assertTrue(output_enlarged.shape == expected_shape)\n         self.assertTrue(torch.allclose(predicted_depth_l, output_enlarged, rtol=1e-3))\n+\n+    def test_export(self):\n+        for strict in [True, False]:\n+            with self.subTest(strict=strict):\n+                if not is_torch_greater_or_equal_than_2_4:\n+                    self.skipTest(reason=\"This test requires torch >= 2.4 to run.\")\n+                model = DPTForSemanticSegmentation.from_pretrained(\"Intel/dpt-large-ade\").to(torch_device).eval()\n+                image_processor = DPTImageProcessor.from_pretrained(\"Intel/dpt-large-ade\")\n+                image = prepare_img()\n+                inputs = image_processor(images=image, return_tensors=\"pt\").to(torch_device)\n+\n+                exported_program = torch.export.export(\n+                    model,\n+                    args=(inputs[\"pixel_values\"],),\n+                    strict=strict,\n+                )\n+                with torch.no_grad():\n+                    eager_outputs = model(**inputs)\n+                    exported_outputs = exported_program.module().forward(inputs[\"pixel_values\"])\n+                self.assertEqual(eager_outputs.logits.shape, exported_outputs.logits.shape)\n+                self.assertTrue(torch.allclose(eager_outputs.logits, exported_outputs.logits, atol=1e-4))"
        }
    ],
    "stats": {
        "total": 92,
        "additions": 72,
        "deletions": 20
    }
}