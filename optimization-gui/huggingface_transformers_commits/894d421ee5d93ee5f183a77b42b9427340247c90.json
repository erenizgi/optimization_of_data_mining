{
    "author": "gante",
    "message": "Test: add higher `atol` in `test_forward_with_num_logits_to_keep` (#33093)",
    "sha": "894d421ee5d93ee5f183a77b42b9427340247c90",
    "files": [
        {
            "sha": "4aad6647aa8b1f819a66b8ecf919a3ef27af696b",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/894d421ee5d93ee5f183a77b42b9427340247c90/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/894d421ee5d93ee5f183a77b42b9427340247c90/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=894d421ee5d93ee5f183a77b42b9427340247c90",
            "patch": "@@ -4842,8 +4842,8 @@ def test_forward_with_num_logits_to_keep(self):\n             self.assertEqual(tuple(all_logits.shape), (batch_size, sequence_length, vocab_size))\n             self.assertEqual(tuple(last_token_logits.shape), (batch_size, 1, vocab_size))\n \n-            # Assert the last tokens are actually the same\n-            self.assertTrue(torch.allclose(all_logits[:, -1:, :], last_token_logits))\n+            # Assert the last tokens are actually the same (except for the natural fluctuation due to order of FP ops)\n+            self.assertTrue(torch.allclose(all_logits[:, -1:, :], last_token_logits, atol=1e-5))\n \n \n global_rng = random.Random()"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}