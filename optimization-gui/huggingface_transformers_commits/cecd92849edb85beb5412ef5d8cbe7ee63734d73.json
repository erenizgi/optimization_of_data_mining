{
    "author": "SunMarc",
    "message": "[v5] Remove train kwargs (#41127)\n\n* rm train kwargs\n\n* fix",
    "sha": "cecd92849edb85beb5412ef5d8cbe7ee63734d73",
    "files": [
        {
            "sha": "240a6e63e6d9676f20a06f31f2a44016d12375b0",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/cecd92849edb85beb5412ef5d8cbe7ee63734d73/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cecd92849edb85beb5412ef5d8cbe7ee63734d73/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=cecd92849edb85beb5412ef5d8cbe7ee63734d73",
            "patch": "@@ -2131,7 +2131,6 @@ def train(\n         resume_from_checkpoint: Optional[Union[str, bool]] = None,\n         trial: Union[\"optuna.Trial\", dict[str, Any], None] = None,\n         ignore_keys_for_eval: Optional[list[str]] = None,\n-        **kwargs: Any,\n     ):\n         \"\"\"\n         Main training entry point.\n@@ -2146,8 +2145,6 @@ def train(\n             ignore_keys_for_eval (`list[str]`, *optional*)\n                 A list of keys in the output of your model (if it is a dictionary) that should be ignored when\n                 gathering predictions for evaluation during the training.\n-            kwargs (`dict[str, Any]`, *optional*):\n-                Additional keyword arguments used to hide deprecated arguments\n         \"\"\"\n         if resume_from_checkpoint is False:\n             resume_from_checkpoint = None\n@@ -2179,15 +2176,6 @@ def train(\n         ):\n             self._move_model_to_device(self.model, args.device)\n \n-        if \"model_path\" in kwargs:\n-            resume_from_checkpoint = kwargs.pop(\"model_path\")\n-            warnings.warn(\n-                \"`model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` \"\n-                \"instead.\",\n-                FutureWarning,\n-            )\n-        if len(kwargs) > 0:\n-            raise TypeError(f\"train() got unexpected keyword arguments: {', '.join(list(kwargs.keys()))}.\")\n         # This might change the seed so needs to run first.\n         self._hp_search_setup(trial)\n         self._train_batch_size = self.args.train_batch_size"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 0,
        "deletions": 12
    }
}