{
    "author": "aymeric-roucher",
    "message": "Agents: turn any Space into a Tool with `Tool.from_space()` (#34561)\n\n* Agents: you can now load a Space as a tool",
    "sha": "3ea3ab62d80d91f9bdd16bd3cacd8133fb0d4566",
    "files": [
        {
            "sha": "1213b35008605b9560748c802a13cce4de9fd7f4",
            "filename": "docs/source/ar/agents.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/3ea3ab62d80d91f9bdd16bd3cacd8133fb0d4566/docs%2Fsource%2Far%2Fagents.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/3ea3ab62d80d91f9bdd16bd3cacd8133fb0d4566/docs%2Fsource%2Far%2Fagents.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fagents.md?ref=3ea3ab62d80d91f9bdd16bd3cacd8133fb0d4566",
            "patch": "@@ -464,7 +464,7 @@ image = image_generator(prompt=improved_prompt)\n \n Ù‚Ø¨Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø© Ø£Ø®ÙŠØ±Ù‹Ø§:\n \n-<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/rabbit.png\" />\n+<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/rabbit_spacesuit_flux.webp\" />\n \n > [!WARNING]\n > ØªØªØ·Ù„Ø¨ gradio-tools Ø¥Ø¯Ø®Ø§Ù„Ø§Øª ÙˆØ¥Ø®Ø±Ø§Ø¬Ø§Øª *Ù†ØµÙŠØ©* Ø­ØªÙ‰ Ø¹Ù†Ø¯ Ø§Ù„Ø¹Ù…Ù„ Ù…Ø¹ Ø·Ø±Ø§Ø¦Ù‚ Ù…Ø®ØªÙ„ÙØ© Ù…Ø«Ù„ ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ØµÙˆØª. Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª ÙˆØ§Ù„Ø¥Ø®Ø±Ø§Ø¬Ø§Øª Ø§Ù„ØµÙˆØ±ÙŠØ© ÙˆØ§Ù„ØµÙˆØªÙŠØ© ØºÙŠØ± Ù…ØªÙˆØ§ÙÙ‚Ø© Ø­Ø§Ù„ÙŠÙ‹Ø§."
        },
        {
            "sha": "e80e402d7374cda888b915d7081b1c98206b80e9",
            "filename": "docs/source/en/agents_advanced.md",
            "status": "modified",
            "additions": 46,
            "deletions": 28,
            "changes": 74,
            "blob_url": "https://github.com/huggingface/transformers/blob/3ea3ab62d80d91f9bdd16bd3cacd8133fb0d4566/docs%2Fsource%2Fen%2Fagents_advanced.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/3ea3ab62d80d91f9bdd16bd3cacd8133fb0d4566/docs%2Fsource%2Fen%2Fagents_advanced.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fagents_advanced.md?ref=3ea3ab62d80d91f9bdd16bd3cacd8133fb0d4566",
            "patch": "@@ -123,52 +123,70 @@ from transformers import load_tool, CodeAgent\n model_download_tool = load_tool(\"m-ric/hf-model-downloads\")\n ```\n \n-### Use gradio-tools\n+### Import a Space as a tool ğŸš€\n \n-[gradio-tools](https://github.com/freddyaboulton/gradio-tools) is a powerful library that allows using Hugging\n-Face Spaces as tools. It supports many existing Spaces as well as custom Spaces.\n+You can directly import a Space from the Hub as a tool using the [`Tool.from_space`] method!\n \n-Transformers supports `gradio_tools` with the [`Tool.from_gradio`] method. For example, let's use the [`StableDiffusionPromptGeneratorTool`](https://github.com/freddyaboulton/gradio-tools/blob/main/gradio_tools/tools/prompt_generator.py) from `gradio-tools` toolkit for improving prompts to generate better images.\n+You only need to provide the id of the Space on the Hub, its name, and a description that will help you agent understand what the tool does. Under the hood, this will use [`gradio-client`](https://pypi.org/project/gradio-client/) library to call the Space.\n \n-Import and instantiate the tool, then pass it to the `Tool.from_gradio` method:\n+For instance, let's import the [FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev) Space from the Hub and use it to generate an image.\n \n-```python\n-from gradio_tools import StableDiffusionPromptGeneratorTool\n-from transformers import Tool, load_tool, CodeAgent\n+```\n+from transformers import Tool\n \n-gradio_prompt_generator_tool = StableDiffusionPromptGeneratorTool()\n-prompt_generator_tool = Tool.from_gradio(gradio_prompt_generator_tool)\n+image_generation_tool = Tool.from_space(\n+    \"black-forest-labs/FLUX.1-dev\",\n+    name=\"image_generator\",\n+    description=\"Generate an image from a prompt\")\n+\n+image_generation_tool(\"A sunny beach\")\n ```\n+And voilÃ , here's your image! ğŸ–ï¸\n \n-Now you can use it just like any other tool. For example, let's improve the prompt  `a rabbit wearing a space suit`.\n+<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/sunny_beach.webp\">\n+\n+Then you can use this tool just like any other tool.  For example, let's improve the prompt  `a rabbit wearing a space suit` and generate an image of it.\n \n ```python\n-image_generation_tool = load_tool('huggingface-tools/text-to-image')\n-agent = CodeAgent(tools=[prompt_generator_tool, image_generation_tool], llm_engine=llm_engine)\n+from transformers import ReactCodeAgent\n+\n+agent = ReactCodeAgent(tools=[image_generation_tool])\n \n agent.run(\n     \"Improve this prompt, then generate an image of it.\", prompt='A rabbit wearing a space suit'\n )\n ```\n \n-The model adequately leverages the tool:\n ```text\n-======== New task ========\n-Improve this prompt, then generate an image of it.\n-You have been provided with these initial arguments: {'prompt': 'A rabbit wearing a space suit'}.\n-==== Agent is executing the code below:\n-improved_prompt = StableDiffusionPromptGenerator(query=prompt)\n-while improved_prompt == \"QUEUE_FULL\":\n-    improved_prompt = StableDiffusionPromptGenerator(query=prompt)\n-print(f\"The improved prompt is {improved_prompt}.\")\n-image = image_generator(prompt=improved_prompt)\n-====\n+=== Agent thoughts:\n+improved_prompt could be \"A bright blue space suit wearing rabbit, on the surface of the moon, under a bright orange sunset, with the Earth visible in the background\"\n+\n+Now that I have improved the prompt, I can use the image generator tool to generate an image based on this prompt.\n+>>> Agent is executing the code below:\n+image = image_generator(prompt=\"A bright blue space suit wearing rabbit, on the surface of the moon, under a bright orange sunset, with the Earth visible in the background\")\n+final_answer(image)\n ```\n \n-Before finally generating the image:\n+<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/rabbit_spacesuit_flux.webp\">\n \n-<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/rabbit.png\">\n+How cool is this? ğŸ¤©\n \n+### Use gradio-tools\n+\n+[gradio-tools](https://github.com/freddyaboulton/gradio-tools) is a powerful library that allows using Hugging\n+Face Spaces as tools. It supports many existing Spaces as well as custom Spaces.\n+\n+Transformers supports `gradio_tools` with the [`Tool.from_gradio`] method. For example, let's use the [`StableDiffusionPromptGeneratorTool`](https://github.com/freddyaboulton/gradio-tools/blob/main/gradio_tools/tools/prompt_generator.py) from `gradio-tools` toolkit for improving prompts to generate better images.\n+\n+Import and instantiate the tool, then pass it to the `Tool.from_gradio` method:\n+\n+```python\n+from gradio_tools import StableDiffusionPromptGeneratorTool\n+from transformers import Tool, load_tool, CodeAgent\n+\n+gradio_prompt_generator_tool = StableDiffusionPromptGeneratorTool()\n+prompt_generator_tool = Tool.from_gradio(gradio_prompt_generator_tool)\n+```\n \n > [!WARNING]\n > gradio-tools require *textual* inputs and outputs even when working with different modalities like image and audio objects. Image and audio inputs and outputs are currently incompatible.\n@@ -179,7 +197,7 @@ We love Langchain and think it has a very compelling suite of tools.\n To import a tool from LangChain, use the `from_langchain()` method.\n \n Here is how you can use it to recreate the intro's search result using a LangChain web search tool.\n-\n+This tool will need `pip install google-search-results` to work properly.\n ```python\n from langchain.agents import load_tools\n from transformers import Tool, ReactCodeAgent\n@@ -188,7 +206,7 @@ search_tool = Tool.from_langchain(load_tools([\"serpapi\"])[0])\n \n agent = ReactCodeAgent(tools=[search_tool])\n \n-agent.run(\"How many more blocks (also denoted as layers) in BERT base encoder than the encoder from the architecture proposed in Attention is All You Need?\")\n+agent.run(\"How many more blocks (also denoted as layers) are in BERT base encoder compared to the encoder from the architecture proposed in Attention is All You Need?\")\n ```\n \n ## Display your agent run in a cool Gradio interface"
        },
        {
            "sha": "994e1bdd817b0cdb07d905d5e26348184c6e7cba",
            "filename": "src/transformers/agents/tools.py",
            "status": "modified",
            "additions": 83,
            "deletions": 30,
            "changes": 113,
            "blob_url": "https://github.com/huggingface/transformers/blob/3ea3ab62d80d91f9bdd16bd3cacd8133fb0d4566/src%2Ftransformers%2Fagents%2Ftools.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3ea3ab62d80d91f9bdd16bd3cacd8133fb0d4566/src%2Ftransformers%2Fagents%2Ftools.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fagents%2Ftools.py?ref=3ea3ab62d80d91f9bdd16bd3cacd8133fb0d4566",
            "patch": "@@ -87,20 +87,22 @@ def get_repo_type(repo_id, repo_type=None, **hub_kwargs):\n \"\"\"\n \n \n-def validate_after_init(cls):\n+def validate_after_init(cls, do_validate_forward: bool = True):\n     original_init = cls.__init__\n \n     @wraps(original_init)\n     def new_init(self, *args, **kwargs):\n         original_init(self, *args, **kwargs)\n         if not isinstance(self, PipelineTool):\n-            self.validate_arguments()\n+            self.validate_arguments(do_validate_forward=do_validate_forward)\n \n     cls.__init__ = new_init\n     return cls\n \n \n-@validate_after_init\n+CONVERSION_DICT = {\"str\": \"string\", \"int\": \"integer\", \"float\": \"number\"}\n+\n+\n class Tool:\n     \"\"\"\n     A base class for the functions used by the agent. Subclass this and implement the `__call__` method as well as the\n@@ -131,7 +133,11 @@ class Tool:\n     def __init__(self, *args, **kwargs):\n         self.is_initialized = False\n \n-    def validate_arguments(self):\n+    def __init_subclass__(cls, **kwargs):\n+        super().__init_subclass__(**kwargs)\n+        validate_after_init(cls, do_validate_forward=False)\n+\n+    def validate_arguments(self, do_validate_forward: bool = True):\n         required_attributes = {\n             \"description\": str,\n             \"name\": str,\n@@ -145,21 +151,23 @@ def validate_arguments(self):\n             if not isinstance(attr_value, expected_type):\n                 raise TypeError(f\"You must set an attribute {attr} of type {expected_type.__name__}.\")\n         for input_name, input_content in self.inputs.items():\n-            assert \"type\" in input_content, f\"Input '{input_name}' should specify a type.\"\n+            assert isinstance(input_content, dict), f\"Input '{input_name}' should be a dictionary.\"\n+            assert (\n+                \"type\" in input_content and \"description\" in input_content\n+            ), f\"Input '{input_name}' should have keys 'type' and 'description', has only {list(input_content.keys())}.\"\n             if input_content[\"type\"] not in authorized_types:\n                 raise Exception(\n                     f\"Input '{input_name}': type '{input_content['type']}' is not an authorized value, should be one of {authorized_types}.\"\n                 )\n-            assert \"description\" in input_content, f\"Input '{input_name}' should have a description.\"\n \n         assert getattr(self, \"output_type\", None) in authorized_types\n-\n-        if not isinstance(self, PipelineTool):\n-            signature = inspect.signature(self.forward)\n-            if not set(signature.parameters.keys()) == set(self.inputs.keys()):\n-                raise Exception(\n-                    \"Tool's 'forward' method should take 'self' as its first argument, then its next arguments should match the keys of tool attribute 'inputs'.\"\n-                )\n+        if do_validate_forward:\n+            if not isinstance(self, PipelineTool):\n+                signature = inspect.signature(self.forward)\n+                if not set(signature.parameters.keys()) == set(self.inputs.keys()):\n+                    raise Exception(\n+                        \"Tool's 'forward' method should take 'self' as its first argument, then its next arguments should match the keys of tool attribute 'inputs'.\"\n+                    )\n \n     def forward(self, *args, **kwargs):\n         return NotImplemented(\"Write this method in your subclass of `Tool`.\")\n@@ -405,6 +413,58 @@ def push_to_hub(\n                 repo_type=\"space\",\n             )\n \n+    @staticmethod\n+    def from_space(space_id, name, description):\n+        \"\"\"\n+        Creates a [`Tool`] from a Space given its id on the Hub.\n+\n+        Args:\n+            space_id (`str`):\n+                The id of the Space on the Hub.\n+            name (`str`):\n+                The name of the tool.\n+            description (`str`):\n+                The description of the tool.\n+\n+        Returns:\n+            [`Tool`]:\n+                The created tool.\n+\n+        Example:\n+        ```\n+        tool = Tool.from_space(\"black-forest-labs/FLUX.1-schnell\", \"image-generator\", \"Generate an image from a prompt\")\n+        ```\n+        \"\"\"\n+        from gradio_client import Client\n+\n+        class SpaceToolWrapper(Tool):\n+            def __init__(self, space_id, name, description):\n+                self.client = Client(space_id)\n+                self.name = name\n+                self.description = description\n+                space_description = self.client.view_api(return_format=\"dict\")[\"named_endpoints\"]\n+                route = list(space_description.keys())[0]\n+                space_description_route = space_description[route]\n+                self.inputs = {}\n+                for parameter in space_description_route[\"parameters\"]:\n+                    if not parameter[\"parameter_has_default\"]:\n+                        self.inputs[parameter[\"parameter_name\"]] = {\n+                            \"type\": parameter[\"type\"][\"type\"],\n+                            \"description\": parameter[\"python_type\"][\"description\"],\n+                        }\n+                output_component = space_description_route[\"returns\"][0][\"component\"]\n+                if output_component == \"Image\":\n+                    self.output_type = \"image\"\n+                elif output_component == \"Audio\":\n+                    self.output_type = \"audio\"\n+                else:\n+                    self.output_type = \"any\"\n+\n+            def forward(self, *args, **kwargs):\n+                return self.client.predict(*args, **kwargs)[0]  # Usually the first output is the result\n+\n+        return SpaceToolWrapper(space_id, name, description)\n+\n     @staticmethod\n     def from_gradio(gradio_tool):\n         \"\"\"\n@@ -414,16 +474,15 @@ def from_gradio(gradio_tool):\n \n         class GradioToolWrapper(Tool):\n             def __init__(self, _gradio_tool):\n-                super().__init__()\n                 self.name = _gradio_tool.name\n                 self.description = _gradio_tool.description\n                 self.output_type = \"string\"\n                 self._gradio_tool = _gradio_tool\n-                func_args = list(inspect.signature(_gradio_tool.run).parameters.keys())\n-                self.inputs = {key: \"\" for key in func_args}\n-\n-            def forward(self, *args, **kwargs):\n-                return self._gradio_tool.run(*args, **kwargs)\n+                func_args = list(inspect.signature(_gradio_tool.run).parameters.items())\n+                self.inputs = {\n+                    key: {\"type\": CONVERSION_DICT[value.annotation], \"description\": \"\"} for key, value in func_args\n+                }\n+                self.forward = self._gradio_tool.run\n \n         return GradioToolWrapper(gradio_tool)\n \n@@ -435,10 +494,13 @@ def from_langchain(langchain_tool):\n \n         class LangChainToolWrapper(Tool):\n             def __init__(self, _langchain_tool):\n-                super().__init__()\n                 self.name = _langchain_tool.name.lower()\n                 self.description = _langchain_tool.description\n-                self.inputs = parse_langchain_args(_langchain_tool.args)\n+                self.inputs = _langchain_tool.args.copy()\n+                for input_content in self.inputs.values():\n+                    if \"title\" in input_content:\n+                        input_content.pop(\"title\")\n+                    input_content[\"description\"] = \"\"\n                 self.output_type = \"string\"\n                 self.langchain_tool = _langchain_tool\n \n@@ -805,15 +867,6 @@ def __call__(\n             return response.json()\n \n \n-def parse_langchain_args(args: Dict[str, str]) -> Dict[str, str]:\n-    \"\"\"Parse the args attribute of a LangChain tool to create a matching inputs dictionary.\"\"\"\n-    inputs = args.copy()\n-    for arg_details in inputs.values():\n-        if \"title\" in arg_details:\n-            arg_details.pop(\"title\")\n-    return inputs\n-\n-\n class ToolCollection:\n     \"\"\"\n     Tool collections enable loading all Spaces from a collection in order to be added to the agent's toolbox."
        }
    ],
    "stats": {
        "total": 189,
        "additions": 130,
        "deletions": 59
    }
}