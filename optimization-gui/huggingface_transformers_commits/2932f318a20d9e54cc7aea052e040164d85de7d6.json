{
    "author": "gante",
    "message": "[docs] logits docstring (#37929)",
    "sha": "2932f318a20d9e54cc7aea052e040164d85de7d6",
    "files": [
        {
            "sha": "ecb98b4085060579a53c6fdef04bf88366c3ed7a",
            "filename": "src/transformers/generation/utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2932f318a20d9e54cc7aea052e040164d85de7d6/src%2Ftransformers%2Fgeneration%2Futils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2932f318a20d9e54cc7aea052e040164d85de7d6/src%2Ftransformers%2Fgeneration%2Futils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Futils.py?ref=2932f318a20d9e54cc7aea052e040164d85de7d6",
            "patch": "@@ -234,7 +234,7 @@ class GenerateBeamDecoderOnlyOutput(ModelOutput):\n         logits (`tuple(torch.FloatTensor)` *optional*, returned when `output_logits=True`):\n             Unprocessed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)\n             at each generation step. Tuple of `torch.FloatTensor` with up to `max_new_tokens` elements (one element for\n-            each generated token), with each tensor of shape `(batch_size, config.vocab_size)`.\n+            each generated token), with each tensor of shape `(batch_size*num_beams, config.vocab_size)`.\n         beam_indices (`torch.LongTensor`, *optional*, returned when `output_scores=True`):\n             Beam indices of generated token id at each generation step. `torch.LongTensor` of shape\n             `(batch_size*num_return_sequences, sequence_length)`.\n@@ -278,7 +278,7 @@ class GenerateBeamEncoderDecoderOutput(ModelOutput):\n         logits (`tuple(torch.FloatTensor)` *optional*, returned when `output_logits=True`):\n             Unprocessed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)\n             at each generation step. Tuple of `torch.FloatTensor` with up to `max_new_tokens` elements (one element for\n-            each generated token), with each tensor of shape `(batch_size, config.vocab_size)`.\n+            each generated token), with each tensor of shape `(batch_size*num_beams, config.vocab_size)`.\n         beam_indices (`torch.LongTensor`, *optional*, returned when `output_scores=True`):\n             Beam indices of generated token id at each generation step. `torch.LongTensor` of shape\n             `(batch_size*num_return_sequences, sequence_length)`."
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}