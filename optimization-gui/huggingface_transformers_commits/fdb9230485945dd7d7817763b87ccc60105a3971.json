{
    "author": "jp1924",
    "message": "Add do_convert_rgb to vit (#34523)\n\n* Add: do_convert_rgb\r\n\r\n* Add: doc string\r\n\r\n* Update src/transformers/models/vit/image_processing_vit.py\r\n\r\nCo-authored-by: Pavel Iakubovskii <qubvel@gmail.com>\r\n\r\n* Update src/transformers/models/vit/image_processing_vit.py\r\n\r\nCo-authored-by: Pavel Iakubovskii <qubvel@gmail.com>\r\n\r\n* Update src/transformers/models/vit/image_processing_vit.py\r\n\r\nCo-authored-by: Pavel Iakubovskii <qubvel@gmail.com>\r\n\r\n* Add: do_convert_rgb to fast\r\n\r\n* Add: convert_to_rgb\r\n\r\n---------\r\n\r\nCo-authored-by: Pavel Iakubovskii <qubvel@gmail.com>",
    "sha": "fdb9230485945dd7d7817763b87ccc60105a3971",
    "files": [
        {
            "sha": "05bb8bae049748acf94e974d7fb6eb3dfa62e292",
            "filename": "src/transformers/models/vit/image_processing_vit.py",
            "status": "modified",
            "additions": 12,
            "deletions": 1,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/fdb9230485945dd7d7817763b87ccc60105a3971/src%2Ftransformers%2Fmodels%2Fvit%2Fimage_processing_vit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fdb9230485945dd7d7817763b87ccc60105a3971/src%2Ftransformers%2Fmodels%2Fvit%2Fimage_processing_vit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvit%2Fimage_processing_vit.py?ref=fdb9230485945dd7d7817763b87ccc60105a3971",
            "patch": "@@ -19,7 +19,7 @@\n import numpy as np\n \n from ...image_processing_utils import BaseImageProcessor, BatchFeature, get_size_dict\n-from ...image_transforms import resize, to_channel_dimension_format\n+from ...image_transforms import convert_to_rgb, resize, to_channel_dimension_format\n from ...image_utils import (\n     IMAGENET_STANDARD_MEAN,\n     IMAGENET_STANDARD_STD,\n@@ -68,6 +68,8 @@ class ViTImageProcessor(BaseImageProcessor):\n         image_std (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_STD`):\n             Standard deviation to use if normalizing the image. This is a float or list of floats the length of the\n             number of channels in the image. Can be overridden by the `image_std` parameter in the `preprocess` method.\n+        do_convert_rgb (`bool`, *optional*):\n+            Whether to convert the image to RGB.\n     \"\"\"\n \n     model_input_names = [\"pixel_values\"]\n@@ -82,6 +84,7 @@ def __init__(\n         do_normalize: bool = True,\n         image_mean: Optional[Union[float, List[float]]] = None,\n         image_std: Optional[Union[float, List[float]]] = None,\n+        do_convert_rgb: Optional[bool] = None,\n         **kwargs,\n     ) -> None:\n         super().__init__(**kwargs)\n@@ -95,6 +98,7 @@ def __init__(\n         self.rescale_factor = rescale_factor\n         self.image_mean = image_mean if image_mean is not None else IMAGENET_STANDARD_MEAN\n         self.image_std = image_std if image_std is not None else IMAGENET_STANDARD_STD\n+        self.do_convert_rgb = do_convert_rgb\n \n     def resize(\n         self,\n@@ -159,6 +163,7 @@ def preprocess(\n         return_tensors: Optional[Union[str, TensorType]] = None,\n         data_format: Union[str, ChannelDimension] = ChannelDimension.FIRST,\n         input_data_format: Optional[Union[str, ChannelDimension]] = None,\n+        do_convert_rgb: Optional[bool] = None,\n     ):\n         \"\"\"\n         Preprocess an image or batch of images.\n@@ -203,6 +208,8 @@ def preprocess(\n                 - `\"channels_first\"` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.\n                 - `\"channels_last\"` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.\n                 - `\"none\"` or `ChannelDimension.NONE`: image in (height, width) format.\n+            do_convert_rgb (`bool`, *optional*, defaults to `self.do_convert_rgb`):\n+                Whether to convert the image to RGB.\n         \"\"\"\n         do_resize = do_resize if do_resize is not None else self.do_resize\n         do_rescale = do_rescale if do_rescale is not None else self.do_rescale\n@@ -211,6 +218,7 @@ def preprocess(\n         rescale_factor = rescale_factor if rescale_factor is not None else self.rescale_factor\n         image_mean = image_mean if image_mean is not None else self.image_mean\n         image_std = image_std if image_std is not None else self.image_std\n+        do_convert_rgb = do_convert_rgb if do_convert_rgb is not None else self.do_convert_rgb\n \n         size = size if size is not None else self.size\n         size_dict = get_size_dict(size)\n@@ -233,6 +241,9 @@ def preprocess(\n             resample=resample,\n         )\n \n+        if do_convert_rgb:\n+            images = [convert_to_rgb(image) for image in images]\n+\n         # All transformations expect numpy arrays.\n         images = [to_numpy_array(image) for image in images]\n "
        },
        {
            "sha": "98ecfb3927a34230d1fd05f8ec3e6e8cb299e29e",
            "filename": "src/transformers/models/vit/image_processing_vit_fast.py",
            "status": "modified",
            "additions": 12,
            "deletions": 1,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/fdb9230485945dd7d7817763b87ccc60105a3971/src%2Ftransformers%2Fmodels%2Fvit%2Fimage_processing_vit_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fdb9230485945dd7d7817763b87ccc60105a3971/src%2Ftransformers%2Fmodels%2Fvit%2Fimage_processing_vit_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvit%2Fimage_processing_vit_fast.py?ref=fdb9230485945dd7d7817763b87ccc60105a3971",
            "patch": "@@ -20,7 +20,7 @@\n from ...image_processing_base import BatchFeature\n from ...image_processing_utils import get_size_dict\n from ...image_processing_utils_fast import BaseImageProcessorFast, SizeDict\n-from ...image_transforms import FusedRescaleNormalize, NumpyToTensor, Rescale\n+from ...image_transforms import FusedRescaleNormalize, NumpyToTensor, Rescale, convert_to_rgb\n from ...image_utils import (\n     IMAGENET_STANDARD_MEAN,\n     IMAGENET_STANDARD_STD,\n@@ -76,6 +76,8 @@ class ViTImageProcessorFast(BaseImageProcessorFast):\n         image_std (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_STD`):\n             Standard deviation to use if normalizing the image. This is a float or list of floats the length of the\n             number of channels in the image. Can be overridden by the `image_std` parameter in the `preprocess` method.\n+        do_convert_rgb (`bool`, *optional*):\n+            Whether to convert the image to RGB.\n     \"\"\"\n \n     model_input_names = [\"pixel_values\"]\n@@ -101,6 +103,7 @@ def __init__(\n         do_normalize: bool = True,\n         image_mean: Optional[Union[float, List[float]]] = None,\n         image_std: Optional[Union[float, List[float]]] = None,\n+        do_convert_rgb: Optional[bool] = None,\n         **kwargs,\n     ) -> None:\n         super().__init__(**kwargs)\n@@ -114,6 +117,7 @@ def __init__(\n         self.rescale_factor = rescale_factor\n         self.image_mean = image_mean if image_mean is not None else IMAGENET_STANDARD_MEAN\n         self.image_std = image_std if image_std is not None else IMAGENET_STANDARD_STD\n+        self.do_convert_rgb = do_convert_rgb\n \n     def _build_transforms(\n         self,\n@@ -199,6 +203,7 @@ def preprocess(\n         return_tensors: Optional[Union[str, TensorType]] = \"pt\",\n         data_format: Union[str, ChannelDimension] = ChannelDimension.FIRST,\n         input_data_format: Optional[Union[str, ChannelDimension]] = None,\n+        do_convert_rgb: Optional[bool] = None,\n         **kwargs,\n     ):\n         \"\"\"\n@@ -237,6 +242,8 @@ def preprocess(\n                 - `\"channels_first\"` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.\n                 - `\"channels_last\"` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.\n                 - `\"none\"` or `ChannelDimension.NONE`: image in (height, width) format.\n+        do_convert_rgb (`bool`, *optional*):\n+            Whether to convert the image to RGB.\n         \"\"\"\n         do_resize = do_resize if do_resize is not None else self.do_resize\n         do_rescale = do_rescale if do_rescale is not None else self.do_rescale\n@@ -246,6 +253,7 @@ def preprocess(\n         image_mean = image_mean if image_mean is not None else self.image_mean\n         image_std = image_std if image_std is not None else self.image_std\n         size = size if size is not None else self.size\n+        do_convert_rgb = do_convert_rgb if do_convert_rgb is not None else self.do_convert_rgb\n         # Make hashable for cache\n         size = SizeDict(**size)\n         image_mean = tuple(image_mean) if isinstance(image_mean, list) else image_mean\n@@ -271,6 +279,9 @@ def preprocess(\n             image_type=image_type,\n         )\n \n+        if do_convert_rgb:\n+            images = [convert_to_rgb(image) for image in images]\n+\n         transforms = self.get_transforms(\n             do_resize=do_resize,\n             do_rescale=do_rescale,"
        }
    ],
    "stats": {
        "total": 26,
        "additions": 24,
        "deletions": 2
    }
}