{
    "author": "Cyrilvallez",
    "message": "Correctly raise error for awq quantization (#38945)\n\nfix warning",
    "sha": "5ee60f970a332b12458b113a18cc74999f8c5880",
    "files": [
        {
            "sha": "a03e9c8e23caee2e50b04d28b64ddb204a771152",
            "filename": "src/transformers/quantizers/quantizer_awq.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/5ee60f970a332b12458b113a18cc74999f8c5880/src%2Ftransformers%2Fquantizers%2Fquantizer_awq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/5ee60f970a332b12458b113a18cc74999f8c5880/src%2Ftransformers%2Fquantizers%2Fquantizer_awq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizer_awq.py?ref=5ee60f970a332b12458b113a18cc74999f8c5880",
            "patch": "@@ -82,7 +82,9 @@ def validate_environment(self, device_map, **kwargs):\n                     \"your model on a GPU device in order to run your model.\"\n                 )\n             elif device_map is not None:\n-                if isinstance(device_map, dict) and (\"cpu\" in device_map.values() or \"disk\" in device_map.values()):\n+                if isinstance(device_map, dict) and any(\n+                    forbidden in device_map.values() for forbidden in (\"cpu\", torch.device(\"cpu\"), \"disk\")\n+                ):\n                     raise ValueError(\n                         \"You are attempting to load an AWQ model with a device_map that contains a CPU or disk device.\"\n                         \" This is not supported. Please remove the CPU or disk device from the device_map.\""
        }
    ],
    "stats": {
        "total": 4,
        "additions": 3,
        "deletions": 1
    }
}