{
    "author": "Cyrilvallez",
    "message": "Some new models added stuff that was already removed (#43179)\n\nremove",
    "sha": "59b9cb06f4a19c6d6601cb3e96c018f170ff6808",
    "files": [
        {
            "sha": "9f103c616c85e8c9910905f70b82bb3eeca329fd",
            "filename": "tests/models/pe_audio/test_modeling_pe_audio.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/59b9cb06f4a19c6d6601cb3e96c018f170ff6808/tests%2Fmodels%2Fpe_audio%2Ftest_modeling_pe_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/59b9cb06f4a19c6d6601cb3e96c018f170ff6808/tests%2Fmodels%2Fpe_audio%2Ftest_modeling_pe_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpe_audio%2Ftest_modeling_pe_audio.py?ref=59b9cb06f4a19c6d6601cb3e96c018f170ff6808",
            "patch": "@@ -133,9 +133,7 @@ def prepare_config_and_inputs_for_common(self):\n @require_torch\n class PeAudioEncoderTest(ModelTesterMixin, unittest.TestCase):\n     all_model_classes = (PeAudioEncoder,)\n-    test_pruning = False\n     test_resize_embeddings = False\n-    test_head_masking = False\n     _is_composite = True\n \n     def setUp(self):\n@@ -284,9 +282,7 @@ class PeAudioModelTest(ModelTesterMixin, unittest.TestCase):\n     # TODO: add PipelineTesterMixin\n     all_model_classes = (PeAudioModel,)\n     additional_model_inputs = [\"input_values\", \"padding_mask\"]\n-    test_pruning = False\n     test_resize_embeddings = False\n-    test_head_masking = False\n     has_attentions = False\n     _is_composite = True\n "
        },
        {
            "sha": "80a310ff1d21d2732dc2eebac7b4f7e76d4cc5a6",
            "filename": "tests/models/pe_audio_video/test_modeling_pe_audio_video.py",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/59b9cb06f4a19c6d6601cb3e96c018f170ff6808/tests%2Fmodels%2Fpe_audio_video%2Ftest_modeling_pe_audio_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/59b9cb06f4a19c6d6601cb3e96c018f170ff6808/tests%2Fmodels%2Fpe_audio_video%2Ftest_modeling_pe_audio_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpe_audio_video%2Ftest_modeling_pe_audio_video.py?ref=59b9cb06f4a19c6d6601cb3e96c018f170ff6808",
            "patch": "@@ -208,9 +208,7 @@ def prepare_config_and_inputs_for_common(self):\n class PeAudioVideoEncoderTest(ModelTesterMixin, unittest.TestCase):\n     all_model_classes = (PeAudioVideoEncoder,)\n     additional_model_inputs = [\"pixel_values_videos\", \"padding_mask_videos\"]\n-    test_pruning = False\n     test_resize_embeddings = False\n-    test_head_masking = False\n     _is_composite = True\n \n     def setUp(self):\n@@ -230,10 +228,6 @@ def test_model(self):\n     def test_model_get_set_embeddings(self):\n         pass\n \n-    @unittest.skip(reason=\"Timm Eva (PE) weights cannot be fully constructed in _init_weights\")\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(\"PeAudioVideoEncoder does not have language_model, vision_tower, multi_modal_projector.\")\n     def test_sdpa_can_dispatch_composite_models(self):\n         pass"
        },
        {
            "sha": "800ed076edef6bb3d29e937a22a70bed96318eed",
            "filename": "tests/models/pe_video/test_modeling_pe_video.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/59b9cb06f4a19c6d6601cb3e96c018f170ff6808/tests%2Fmodels%2Fpe_video%2Ftest_modeling_pe_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/59b9cb06f4a19c6d6601cb3e96c018f170ff6808/tests%2Fmodels%2Fpe_video%2Ftest_modeling_pe_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fpe_video%2Ftest_modeling_pe_video.py?ref=59b9cb06f4a19c6d6601cb3e96c018f170ff6808",
            "patch": "@@ -133,9 +133,7 @@ def prepare_config_and_inputs_for_common(self):\n @require_torch\n class PeVideoEncoderTest(ModelTesterMixin, unittest.TestCase):\n     all_model_classes = (PeVideoEncoder,)\n-    test_pruning = False\n     test_resize_embeddings = False\n-    test_head_masking = False\n     _is_composite = True\n \n     def setUp(self):\n@@ -175,10 +173,6 @@ def test_can_load_with_meta_device_context_manager(self):\n     def test_retain_grad_hidden_states_attentions(self):\n         pass\n \n-    @unittest.skip(reason=\"Timm Eva (PE) weights cannot be fully constructed in _init_weights\")\n-    def test_initialization(self):\n-        pass\n-\n     @unittest.skip(reason=\"PeVideoEncoder does not support feedforward chunking yet\")\n     def test_feed_forward_chunking(self):\n         pass\n@@ -316,9 +310,7 @@ class PeVideoModelTest(ModelTesterMixin, unittest.TestCase):\n     # TODO: add PipelineTesterMixin\n     all_model_classes = (PeVideoModel,)\n     additional_model_inputs = [\"pixel_values_videos\", \"padding_mask_videos\"]\n-    test_pruning = False\n     test_resize_embeddings = False\n-    test_head_masking = False\n     has_attentions = False\n     _is_composite = True\n "
        },
        {
            "sha": "687c260a9992fd71ec58e0b562ac186bb6fda442",
            "filename": "tests/models/switch_transformers/test_modeling_switch_transformers.py",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/59b9cb06f4a19c6d6601cb3e96c018f170ff6808/tests%2Fmodels%2Fswitch_transformers%2Ftest_modeling_switch_transformers.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/59b9cb06f4a19c6d6601cb3e96c018f170ff6808/tests%2Fmodels%2Fswitch_transformers%2Ftest_modeling_switch_transformers.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fswitch_transformers%2Ftest_modeling_switch_transformers.py?ref=59b9cb06f4a19c6d6601cb3e96c018f170ff6808",
            "patch": "@@ -495,7 +495,6 @@ class SwitchTransformersModelTest(ModelTesterMixin, GenerationTesterMixin, Pipel\n     model_split_percents = [0.5, 0.8, 0.9]\n     # `SwitchTransformers` is a MOE in which not all experts will get gradients because they are not all used in a single forward pass\n     test_all_params_have_gradient = False\n-    test_head_masking = False\n \n     def setUp(self):\n         self.model_tester = SwitchTransformersModelTester(self)\n@@ -739,8 +738,6 @@ class SwitchTransformersEncoderOnlyModelTest(ModelTesterMixin, unittest.TestCase\n     all_model_classes = (SwitchTransformersEncoderModel,) if is_torch_available() else ()\n \n     test_resize_embeddings = False\n-    test_model_parallel = False\n-    test_head_masking = False\n \n     def setUp(self):\n         self.model_tester = SwitchTransformersEncoderOnlyModelTester(self)"
        },
        {
            "sha": "9fe37485b7b19bb683a416382fb512833599bc93",
            "filename": "tests/models/video_llama_3/test_modeling_video_llama_3.py",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/59b9cb06f4a19c6d6601cb3e96c018f170ff6808/tests%2Fmodels%2Fvideo_llama_3%2Ftest_modeling_video_llama_3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/59b9cb06f4a19c6d6601cb3e96c018f170ff6808/tests%2Fmodels%2Fvideo_llama_3%2Ftest_modeling_video_llama_3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fvideo_llama_3%2Ftest_modeling_video_llama_3.py?ref=59b9cb06f4a19c6d6601cb3e96c018f170ff6808",
            "patch": "@@ -351,7 +351,6 @@ class VideoLlama3VisionModelTest(ModelTesterMixin, unittest.TestCase):\n     all_model_classes = (VideoLlama3VisionModel,) if is_torch_available() else ()\n     additional_model_inputs = [\"grid_thw\", \"merge_sizes\"]\n     test_resize_embeddings = False\n-    test_head_masking = False\n     test_cpu_offload = False\n     test_disk_offload_safetensors = False\n     test_disk_offload_bin = False\n@@ -653,8 +652,6 @@ class VideoLlama3ModelTest(ModelTesterMixin, GenerationTesterMixin, unittest.Tes\n         else ()\n     )\n     pipeline_model_mapping = {\"image-text-to-text\": VideoLlama3ForConditionalGeneration}\n-    test_pruning = False\n-    test_head_masking = False\n     _is_composite = True\n \n     def setUp(self):"
        }
    ],
    "stats": {
        "total": 24,
        "additions": 0,
        "deletions": 24
    }
}