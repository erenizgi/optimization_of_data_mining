{
    "author": "LysandreJik",
    "message": "Cleanup: continue the init refactor (#35170)\n\n* Round 2\r\n\r\n* Round 3",
    "sha": "7d303efa5f46c23cd5e76ee99e717144d05e8783",
    "files": [
        {
            "sha": "b89712ab5ab49f33f9238553db03b212d009066b",
            "filename": "src/transformers/models/big_bird/__init__.py",
            "status": "modified",
            "additions": 11,
            "deletions": 125,
            "changes": 136,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbig_bird%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbig_bird%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbig_bird%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2021 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,133 +13,19 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import (\n-    OptionalDependencyNotAvailable,\n-    _LazyModule,\n-    is_flax_available,\n-    is_sentencepiece_available,\n-    is_tf_available,\n-    is_tokenizers_available,\n-    is_torch_available,\n-)\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n-_import_structure = {\n-    \"configuration_big_bird\": [\"BigBirdConfig\", \"BigBirdOnnxConfig\"],\n-}\n-\n-try:\n-    if not is_sentencepiece_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"tokenization_big_bird\"] = [\"BigBirdTokenizer\"]\n-\n-try:\n-    if not is_tokenizers_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"tokenization_big_bird_fast\"] = [\"BigBirdTokenizerFast\"]\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_big_bird\"] = [\n-        \"BigBirdForCausalLM\",\n-        \"BigBirdForMaskedLM\",\n-        \"BigBirdForMultipleChoice\",\n-        \"BigBirdForPreTraining\",\n-        \"BigBirdForQuestionAnswering\",\n-        \"BigBirdForSequenceClassification\",\n-        \"BigBirdForTokenClassification\",\n-        \"BigBirdLayer\",\n-        \"BigBirdModel\",\n-        \"BigBirdPreTrainedModel\",\n-        \"load_tf_weights_in_big_bird\",\n-    ]\n-\n-try:\n-    if not is_flax_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_flax_big_bird\"] = [\n-        \"FlaxBigBirdForCausalLM\",\n-        \"FlaxBigBirdForMaskedLM\",\n-        \"FlaxBigBirdForMultipleChoice\",\n-        \"FlaxBigBirdForPreTraining\",\n-        \"FlaxBigBirdForQuestionAnswering\",\n-        \"FlaxBigBirdForSequenceClassification\",\n-        \"FlaxBigBirdForTokenClassification\",\n-        \"FlaxBigBirdModel\",\n-        \"FlaxBigBirdPreTrainedModel\",\n-    ]\n-\n if TYPE_CHECKING:\n-    from .configuration_big_bird import BigBirdConfig, BigBirdOnnxConfig\n-\n-    try:\n-        if not is_sentencepiece_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .tokenization_big_bird import BigBirdTokenizer\n-\n-    try:\n-        if not is_tokenizers_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .tokenization_big_bird_fast import BigBirdTokenizerFast\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_big_bird import (\n-            BigBirdForCausalLM,\n-            BigBirdForMaskedLM,\n-            BigBirdForMultipleChoice,\n-            BigBirdForPreTraining,\n-            BigBirdForQuestionAnswering,\n-            BigBirdForSequenceClassification,\n-            BigBirdForTokenClassification,\n-            BigBirdLayer,\n-            BigBirdModel,\n-            BigBirdPreTrainedModel,\n-            load_tf_weights_in_big_bird,\n-        )\n-\n-    try:\n-        if not is_flax_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_flax_big_bird import (\n-            FlaxBigBirdForCausalLM,\n-            FlaxBigBirdForMaskedLM,\n-            FlaxBigBirdForMultipleChoice,\n-            FlaxBigBirdForPreTraining,\n-            FlaxBigBirdForQuestionAnswering,\n-            FlaxBigBirdForSequenceClassification,\n-            FlaxBigBirdForTokenClassification,\n-            FlaxBigBirdModel,\n-            FlaxBigBirdPreTrainedModel,\n-        )\n-\n+    from .configuration_big_bird import *\n+    from .convert_bigbird_original_tf_checkpoint_to_pytorch import *\n+    from .modeling_big_bird import *\n+    from .modeling_flax_big_bird import *\n+    from .tokenization_big_bird import *\n+    from .tokenization_big_bird_fast import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "1019e008aa3b3820788ee2fd642b48feb35194cd",
            "filename": "src/transformers/models/big_bird/configuration_big_bird.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fconfiguration_big_bird.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fconfiguration_big_bird.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fconfiguration_big_bird.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -171,3 +171,6 @@ def inputs(self) -> Mapping[str, Mapping[int, str]]:\n                 (\"attention_mask\", dynamic_axis),\n             ]\n         )\n+\n+\n+__all__ = [\"BigBirdConfig\", \"BigBirdOnnxConfig\"]"
        },
        {
            "sha": "47c78284b7f29c03602018e78448f0d3ee899682",
            "filename": "src/transformers/models/big_bird/modeling_big_bird.py",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fmodeling_big_bird.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fmodeling_big_bird.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fmodeling_big_bird.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -3126,3 +3126,18 @@ def prepare_question_mask(q_lengths: torch.Tensor, maxlen: int):\n         mask.unsqueeze_(0)  # -> (1, maxlen)\n         mask = torch.where(mask < q_lengths, 1, 0)\n         return mask\n+\n+\n+__all__ = [\n+    \"BigBirdForCausalLM\",\n+    \"BigBirdForMaskedLM\",\n+    \"BigBirdForMultipleChoice\",\n+    \"BigBirdForPreTraining\",\n+    \"BigBirdForQuestionAnswering\",\n+    \"BigBirdForSequenceClassification\",\n+    \"BigBirdForTokenClassification\",\n+    \"BigBirdLayer\",\n+    \"BigBirdModel\",\n+    \"BigBirdPreTrainedModel\",\n+    \"load_tf_weights_in_big_bird\",\n+]"
        },
        {
            "sha": "8d23180a8348cd38c5bf46af5e70ea0615bb64b4",
            "filename": "src/transformers/models/big_bird/modeling_flax_big_bird.py",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fmodeling_flax_big_bird.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fmodeling_flax_big_bird.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbig_bird%2Fmodeling_flax_big_bird.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -2633,3 +2633,16 @@ def update_inputs_for_generation(self, model_outputs, model_kwargs):\n     FlaxCausalLMOutputWithCrossAttentions,\n     _CONFIG_FOR_DOC,\n )\n+\n+\n+__all__ = [\n+    \"FlaxBigBirdForCausalLM\",\n+    \"FlaxBigBirdForMaskedLM\",\n+    \"FlaxBigBirdForMultipleChoice\",\n+    \"FlaxBigBirdForPreTraining\",\n+    \"FlaxBigBirdForQuestionAnswering\",\n+    \"FlaxBigBirdForSequenceClassification\",\n+    \"FlaxBigBirdForTokenClassification\",\n+    \"FlaxBigBirdModel\",\n+    \"FlaxBigBirdPreTrainedModel\",\n+]"
        },
        {
            "sha": "194cbc68cb56ba9f39f50ea8ce35e6fdd61de82e",
            "filename": "src/transformers/models/big_bird/tokenization_big_bird.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbig_bird%2Ftokenization_big_bird.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbig_bird%2Ftokenization_big_bird.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbig_bird%2Ftokenization_big_bird.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -319,3 +319,6 @@ def create_token_type_ids_from_sequences(\n         if token_ids_1 is None:\n             return len(cls + token_ids_0 + sep) * [0]\n         return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n+\n+\n+__all__ = [\"BigBirdTokenizer\"]"
        },
        {
            "sha": "83f2fac07fae72b758f8671458ac0843538eba4b",
            "filename": "src/transformers/models/big_bird/tokenization_big_bird_fast.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbig_bird%2Ftokenization_big_bird_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbig_bird%2Ftokenization_big_bird_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbig_bird%2Ftokenization_big_bird_fast.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -227,3 +227,6 @@ def save_vocabulary(self, save_directory: str, filename_prefix: Optional[str] =\n             copyfile(self.vocab_file, out_vocab_file)\n \n         return (out_vocab_file,)\n+\n+\n+__all__ = [\"BigBirdTokenizerFast\"]"
        },
        {
            "sha": "8684d999d85cb43d8e1f4d6aeb37580e055530f5",
            "filename": "src/transformers/models/bigbird_pegasus/__init__.py",
            "status": "modified",
            "additions": 8,
            "deletions": 47,
            "changes": 55,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2021 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,55 +13,16 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import OptionalDependencyNotAvailable, _LazyModule, is_torch_available\n-\n-\n-_import_structure = {\n-    \"configuration_bigbird_pegasus\": [\n-        \"BigBirdPegasusConfig\",\n-        \"BigBirdPegasusOnnxConfig\",\n-    ],\n-}\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_bigbird_pegasus\"] = [\n-        \"BigBirdPegasusForCausalLM\",\n-        \"BigBirdPegasusForConditionalGeneration\",\n-        \"BigBirdPegasusForQuestionAnswering\",\n-        \"BigBirdPegasusForSequenceClassification\",\n-        \"BigBirdPegasusModel\",\n-        \"BigBirdPegasusPreTrainedModel\",\n-    ]\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n if TYPE_CHECKING:\n-    from .configuration_bigbird_pegasus import (\n-        BigBirdPegasusConfig,\n-        BigBirdPegasusOnnxConfig,\n-    )\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_bigbird_pegasus import (\n-            BigBirdPegasusForCausalLM,\n-            BigBirdPegasusForConditionalGeneration,\n-            BigBirdPegasusForQuestionAnswering,\n-            BigBirdPegasusForSequenceClassification,\n-            BigBirdPegasusModel,\n-            BigBirdPegasusPreTrainedModel,\n-        )\n-\n-\n+    from .configuration_bigbird_pegasus import *\n+    from .convert_bigbird_pegasus_tf_to_pytorch import *\n+    from .modeling_bigbird_pegasus import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "5d9c9bf1a4b0b228f60c90c2c8ffbd4856557a62",
            "filename": "src/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fconfiguration_bigbird_pegasus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fconfiguration_bigbird_pegasus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fconfiguration_bigbird_pegasus.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -407,3 +407,6 @@ def _flatten_past_key_values_(self, flattened_output, name, idx, t):\n             flattened_output = super(OnnxSeq2SeqConfigWithPast, self)._flatten_past_key_values_(\n                 flattened_output, name, idx, t\n             )\n+\n+\n+__all__ = [\"BigBirdPegasusConfig\", \"BigBirdPegasusOnnxConfig\"]"
        },
        {
            "sha": "fd52e4b8bb731c92b1589901312a3361f86afe6c",
            "filename": "src/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fmodeling_bigbird_pegasus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fmodeling_bigbird_pegasus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbigbird_pegasus%2Fmodeling_bigbird_pegasus.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -3028,3 +3028,13 @@ def _reorder_cache(past_key_values, beam_idx):\n                 tuple(past_state.index_select(0, beam_idx.to(past_state.device)) for past_state in layer_past),\n             )\n         return reordered_past\n+\n+\n+__all__ = [\n+    \"BigBirdPegasusForCausalLM\",\n+    \"BigBirdPegasusForConditionalGeneration\",\n+    \"BigBirdPegasusForQuestionAnswering\",\n+    \"BigBirdPegasusForSequenceClassification\",\n+    \"BigBirdPegasusModel\",\n+    \"BigBirdPegasusPreTrainedModel\",\n+]"
        },
        {
            "sha": "27773fb642459c7e1e3805e37f7c4a8e1812da0f",
            "filename": "src/transformers/models/biogpt/__init__.py",
            "status": "modified",
            "additions": 9,
            "deletions": 41,
            "changes": 50,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbiogpt%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbiogpt%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbiogpt%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2022 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,49 +13,17 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import OptionalDependencyNotAvailable, _LazyModule, is_tokenizers_available, is_torch_available\n-\n-\n-_import_structure = {\n-    \"configuration_biogpt\": [\"BioGptConfig\"],\n-    \"tokenization_biogpt\": [\"BioGptTokenizer\"],\n-}\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_biogpt\"] = [\n-        \"BioGptForCausalLM\",\n-        \"BioGptForTokenClassification\",\n-        \"BioGptForSequenceClassification\",\n-        \"BioGptModel\",\n-        \"BioGptPreTrainedModel\",\n-    ]\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n if TYPE_CHECKING:\n-    from .configuration_biogpt import BioGptConfig\n-    from .tokenization_biogpt import BioGptTokenizer\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_biogpt import (\n-            BioGptForCausalLM,\n-            BioGptForSequenceClassification,\n-            BioGptForTokenClassification,\n-            BioGptModel,\n-            BioGptPreTrainedModel,\n-        )\n-\n-\n+    from .configuration_biogpt import *\n+    from .convert_biogpt_original_pytorch_checkpoint_to_pytorch import *\n+    from .modeling_biogpt import *\n+    from .tokenization_biogpt import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "b338092edd1d0b544843276289afe6a58ed0c8de",
            "filename": "src/transformers/models/biogpt/configuration_biogpt.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fconfiguration_biogpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fconfiguration_biogpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fconfiguration_biogpt.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -129,3 +129,6 @@ def __init__(\n         self.layerdrop = layerdrop\n         self.activation_dropout = activation_dropout\n         super().__init__(pad_token_id=pad_token_id, bos_token_id=bos_token_id, eos_token_id=eos_token_id, **kwargs)\n+\n+\n+__all__ = [\"BioGptConfig\"]"
        },
        {
            "sha": "e9d76413600879e99f9f1b09fb62299c9978627c",
            "filename": "src/transformers/models/biogpt/modeling_biogpt.py",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fmodeling_biogpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fmodeling_biogpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fmodeling_biogpt.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1028,3 +1028,12 @@ def get_input_embeddings(self):\n \n     def set_input_embeddings(self, value):\n         self.biogpt.embed_tokens = value\n+\n+\n+__all__ = [\n+    \"BioGptForCausalLM\",\n+    \"BioGptForTokenClassification\",\n+    \"BioGptForSequenceClassification\",\n+    \"BioGptModel\",\n+    \"BioGptPreTrainedModel\",\n+]"
        },
        {
            "sha": "a898976d985f582770602b3a5731081be5f59a0f",
            "filename": "src/transformers/models/biogpt/tokenization_biogpt.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbiogpt%2Ftokenization_biogpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbiogpt%2Ftokenization_biogpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbiogpt%2Ftokenization_biogpt.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -356,3 +356,6 @@ def __setstate__(self, d):\n             )\n \n         self.sm = sacremoses\n+\n+\n+__all__ = [\"BioGptTokenizer\"]"
        },
        {
            "sha": "f46988ca2d8f883e7e72155d460866b5ca764261",
            "filename": "src/transformers/models/bit/__init__.py",
            "status": "modified",
            "additions": 9,
            "deletions": 51,
            "changes": 60,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbit%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbit%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbit%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2022 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,59 +13,17 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import OptionalDependencyNotAvailable, _LazyModule, is_torch_available, is_vision_available\n-\n-\n-_import_structure = {\"configuration_bit\": [\"BitConfig\", \"BitOnnxConfig\"]}\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_bit\"] = [\n-        \"BitForImageClassification\",\n-        \"BitModel\",\n-        \"BitPreTrainedModel\",\n-        \"BitBackbone\",\n-    ]\n-\n-\n-try:\n-    if not is_vision_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"image_processing_bit\"] = [\"BitImageProcessor\"]\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n if TYPE_CHECKING:\n-    from .configuration_bit import BitConfig, BitOnnxConfig\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_bit import (\n-            BitBackbone,\n-            BitForImageClassification,\n-            BitModel,\n-            BitPreTrainedModel,\n-        )\n-\n-    try:\n-        if not is_vision_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .image_processing_bit import BitImageProcessor\n-\n+    from .configuration_bit import *\n+    from .convert_bit_to_pytorch import *\n+    from .image_processing_bit import *\n+    from .modeling_bit import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "238749f1fbe70ff2decedacf7604de603d53f07c",
            "filename": "src/transformers/models/bit/configuration_bit.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbit%2Fconfiguration_bit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbit%2Fconfiguration_bit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbit%2Fconfiguration_bit.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -131,3 +131,6 @@ def __init__(\n         self._out_features, self._out_indices = get_aligned_output_features_output_indices(\n             out_features=out_features, out_indices=out_indices, stage_names=self.stage_names\n         )\n+\n+\n+__all__ = [\"BitConfig\"]"
        },
        {
            "sha": "c32bb934bdc528898b0997cb0655ede517b1a488",
            "filename": "src/transformers/models/bit/image_processing_bit.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbit%2Fimage_processing_bit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbit%2Fimage_processing_bit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbit%2Fimage_processing_bit.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -319,3 +319,6 @@ def preprocess(\n \n         data = {\"pixel_values\": images}\n         return BatchFeature(data=data, tensor_type=return_tensors)\n+\n+\n+__all__ = [\"BitImageProcessor\"]"
        },
        {
            "sha": "3d834671becccdb3bf78f7a23fdf1a0331f38d01",
            "filename": "src/transformers/models/bit/modeling_bit.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbit%2Fmodeling_bit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbit%2Fmodeling_bit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbit%2Fmodeling_bit.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -901,3 +901,6 @@ def forward(\n             hidden_states=outputs.hidden_states if output_hidden_states else None,\n             attentions=None,\n         )\n+\n+\n+__all__ = [\"BitForImageClassification\", \"BitModel\", \"BitPreTrainedModel\", \"BitBackbone\"]"
        },
        {
            "sha": "d1180bd200d45c640b5b22ca33286d3cedb899a8",
            "filename": "src/transformers/models/blenderbot/__init__.py",
            "status": "modified",
            "additions": 12,
            "deletions": 118,
            "changes": 130,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2020 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -11,128 +11,22 @@\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.\n-\n from typing import TYPE_CHECKING\n \n-from ...utils import (\n-    OptionalDependencyNotAvailable,\n-    _LazyModule,\n-    is_flax_available,\n-    is_tf_available,\n-    is_tokenizers_available,\n-    is_torch_available,\n-)\n-\n-\n-_import_structure = {\n-    \"configuration_blenderbot\": [\n-        \"BlenderbotConfig\",\n-        \"BlenderbotOnnxConfig\",\n-    ],\n-    \"tokenization_blenderbot\": [\"BlenderbotTokenizer\"],\n-}\n-\n-try:\n-    if not is_tokenizers_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"tokenization_blenderbot_fast\"] = [\"BlenderbotTokenizerFast\"]\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_blenderbot\"] = [\n-        \"BlenderbotForCausalLM\",\n-        \"BlenderbotForConditionalGeneration\",\n-        \"BlenderbotModel\",\n-        \"BlenderbotPreTrainedModel\",\n-    ]\n-\n-\n-try:\n-    if not is_tf_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_tf_blenderbot\"] = [\n-        \"TFBlenderbotForConditionalGeneration\",\n-        \"TFBlenderbotModel\",\n-        \"TFBlenderbotPreTrainedModel\",\n-    ]\n-\n-\n-try:\n-    if not is_flax_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_flax_blenderbot\"] = [\n-        \"FlaxBlenderbotForConditionalGeneration\",\n-        \"FlaxBlenderbotModel\",\n-        \"FlaxBlenderbotPreTrainedModel\",\n-    ]\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n if TYPE_CHECKING:\n-    from .configuration_blenderbot import (\n-        BlenderbotConfig,\n-        BlenderbotOnnxConfig,\n-    )\n-    from .tokenization_blenderbot import BlenderbotTokenizer\n-\n-    try:\n-        if not is_tokenizers_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .tokenization_blenderbot_fast import BlenderbotTokenizerFast\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_blenderbot import (\n-            BlenderbotForCausalLM,\n-            BlenderbotForConditionalGeneration,\n-            BlenderbotModel,\n-            BlenderbotPreTrainedModel,\n-        )\n-\n-    try:\n-        if not is_tf_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_tf_blenderbot import (\n-            TFBlenderbotForConditionalGeneration,\n-            TFBlenderbotModel,\n-            TFBlenderbotPreTrainedModel,\n-        )\n-\n-    try:\n-        if not is_flax_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_flax_blenderbot import (\n-            FlaxBlenderbotForConditionalGeneration,\n-            FlaxBlenderbotModel,\n-            FlaxBlenderbotPreTrainedModel,\n-        )\n-\n+    from .configuration_blenderbot import *\n+    from .convert_blenderbot_original_pytorch_checkpoint_to_pytorch import *\n+    from .modeling_blenderbot import *\n+    from .modeling_flax_blenderbot import *\n+    from .modeling_tf_blenderbot import *\n+    from .tokenization_blenderbot import *\n+    from .tokenization_blenderbot_fast import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "c9f323210e8c477dad96575c24884295051cbac4",
            "filename": "src/transformers/models/blenderbot/configuration_blenderbot.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fconfiguration_blenderbot.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fconfiguration_blenderbot.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fconfiguration_blenderbot.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -390,3 +390,6 @@ def fill_with_past_key_values_(self, inputs_or_outputs: Mapping[str, Mapping[int\n             inputs_or_outputs[f\"{name}.{i}.decoder.value\"] = {0: \"batch\", 2: decoder_sequence}\n             inputs_or_outputs[f\"{name}.{i}.encoder.key\"] = {0: \"batch\", 2: encoder_sequence}\n             inputs_or_outputs[f\"{name}.{i}.encoder.value\"] = {0: \"batch\", 2: encoder_sequence}\n+\n+\n+__all__ = [\"BlenderbotConfig\", \"BlenderbotOnnxConfig\"]"
        },
        {
            "sha": "ace9470d01e3b21e2eca52555e19f03a824cd8f5",
            "filename": "src/transformers/models/blenderbot/modeling_blenderbot.py",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_blenderbot.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_blenderbot.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_blenderbot.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1547,3 +1547,11 @@ def _reorder_cache(past_key_values, beam_idx):\n                 tuple(past_state.index_select(0, beam_idx.to(past_state.device)) for past_state in layer_past),\n             )\n         return reordered_past\n+\n+\n+__all__ = [\n+    \"BlenderbotForCausalLM\",\n+    \"BlenderbotForConditionalGeneration\",\n+    \"BlenderbotModel\",\n+    \"BlenderbotPreTrainedModel\",\n+]"
        },
        {
            "sha": "fcef08fdeab8deb0842fa57eec2c872365982113",
            "filename": "src/transformers/models/blenderbot/modeling_flax_blenderbot.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_flax_blenderbot.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_flax_blenderbot.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_flax_blenderbot.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1503,3 +1503,6 @@ def update_inputs_for_generation(self, model_outputs, model_kwargs):\n append_replace_return_docstrings(\n     FlaxBlenderbotForConditionalGeneration, output_type=FlaxSeq2SeqLMOutput, config_class=_CONFIG_FOR_DOC\n )\n+\n+\n+__all__ = [\"FlaxBlenderbotForConditionalGeneration\", \"FlaxBlenderbotModel\", \"FlaxBlenderbotPreTrainedModel\"]"
        },
        {
            "sha": "f3476cb925b6b4c056ddcf8470b66c2b6b50e9b3",
            "filename": "src/transformers/models/blenderbot/modeling_tf_blenderbot.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_tf_blenderbot.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_tf_blenderbot.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fmodeling_tf_blenderbot.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1553,3 +1553,6 @@ def build(self, input_shape=None):\n         if getattr(self, \"bias_layer\", None) is not None:\n             with tf.name_scope(self.bias_layer.name):\n                 self.bias_layer.build(None)\n+\n+\n+__all__ = [\"TFBlenderbotForConditionalGeneration\", \"TFBlenderbotModel\", \"TFBlenderbotPreTrainedModel\"]"
        },
        {
            "sha": "08b2a8c1283b6753a25ce0348d1393ca24f32553",
            "filename": "src/transformers/models/blenderbot/tokenization_blenderbot.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot%2Ftokenization_blenderbot.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot%2Ftokenization_blenderbot.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot%2Ftokenization_blenderbot.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -405,3 +405,6 @@ def build_inputs_with_special_tokens(self, token_ids_0: List[int], token_ids_1:\n             `List[int]`: list of [input IDs](../glossary#input-ids) with the appropriate special tokens.\n         \"\"\"\n         return token_ids_0 + [self.eos_token_id]\n+\n+\n+__all__ = [\"BlenderbotTokenizer\"]"
        },
        {
            "sha": "f649246517d271c817e5ecac5cf451fc2f01374f",
            "filename": "src/transformers/models/blenderbot/tokenization_blenderbot_fast.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot%2Ftokenization_blenderbot_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot%2Ftokenization_blenderbot_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot%2Ftokenization_blenderbot_fast.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -287,3 +287,6 @@ def build_inputs_with_special_tokens(self, token_ids_0: List[int], token_ids_1:\n             `List[int]`: list of [input IDs](../glossary#input-ids) with the appropriate special tokens.\n         \"\"\"\n         return token_ids_0 + [self.eos_token_id]\n+\n+\n+__all__ = [\"BlenderbotTokenizerFast\"]"
        },
        {
            "sha": "075d0070e4c4e2b95cce8a3bcaa2818021daee99",
            "filename": "src/transformers/models/blenderbot_small/__init__.py",
            "status": "modified",
            "additions": 11,
            "deletions": 114,
            "changes": 125,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2020 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,122 +13,19 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import (\n-    OptionalDependencyNotAvailable,\n-    _LazyModule,\n-    is_flax_available,\n-    is_tf_available,\n-    is_tokenizers_available,\n-    is_torch_available,\n-)\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n-_import_structure = {\n-    \"configuration_blenderbot_small\": [\n-        \"BlenderbotSmallConfig\",\n-        \"BlenderbotSmallOnnxConfig\",\n-    ],\n-    \"tokenization_blenderbot_small\": [\"BlenderbotSmallTokenizer\"],\n-}\n-\n-try:\n-    if not is_tokenizers_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"tokenization_blenderbot_small_fast\"] = [\"BlenderbotSmallTokenizerFast\"]\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_blenderbot_small\"] = [\n-        \"BlenderbotSmallForCausalLM\",\n-        \"BlenderbotSmallForConditionalGeneration\",\n-        \"BlenderbotSmallModel\",\n-        \"BlenderbotSmallPreTrainedModel\",\n-    ]\n-\n-try:\n-    if not is_tf_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_tf_blenderbot_small\"] = [\n-        \"TFBlenderbotSmallForConditionalGeneration\",\n-        \"TFBlenderbotSmallModel\",\n-        \"TFBlenderbotSmallPreTrainedModel\",\n-    ]\n-\n-try:\n-    if not is_flax_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_flax_blenderbot_small\"] = [\n-        \"FlaxBlenderbotSmallForConditionalGeneration\",\n-        \"FlaxBlenderbotSmallModel\",\n-        \"FlaxBlenderbotSmallPreTrainedModel\",\n-    ]\n-\n if TYPE_CHECKING:\n-    from .configuration_blenderbot_small import (\n-        BlenderbotSmallConfig,\n-        BlenderbotSmallOnnxConfig,\n-    )\n-    from .tokenization_blenderbot_small import BlenderbotSmallTokenizer\n-\n-    try:\n-        if not is_tokenizers_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .tokenization_blenderbot_small_fast import BlenderbotSmallTokenizerFast\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_blenderbot_small import (\n-            BlenderbotSmallForCausalLM,\n-            BlenderbotSmallForConditionalGeneration,\n-            BlenderbotSmallModel,\n-            BlenderbotSmallPreTrainedModel,\n-        )\n-\n-    try:\n-        if not is_tf_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_tf_blenderbot_small import (\n-            TFBlenderbotSmallForConditionalGeneration,\n-            TFBlenderbotSmallModel,\n-            TFBlenderbotSmallPreTrainedModel,\n-        )\n-\n-    try:\n-        if not is_flax_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_flax_blenderbot_small import (\n-            FlaxBlenderbotSmallForConditionalGeneration,\n-            FlaxBlenderbotSmallModel,\n-            FlaxBlenderbotSmallPreTrainedModel,\n-        )\n-\n+    from .configuration_blenderbot_small import *\n+    from .modeling_blenderbot_small import *\n+    from .modeling_flax_blenderbot_small import *\n+    from .modeling_tf_blenderbot_small import *\n+    from .tokenization_blenderbot_small import *\n+    from .tokenization_blenderbot_small_fast import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "5865486370e5b972c07b1b4749ca2dd7778158d9",
            "filename": "src/transformers/models/blenderbot_small/configuration_blenderbot_small.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fconfiguration_blenderbot_small.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fconfiguration_blenderbot_small.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fconfiguration_blenderbot_small.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -385,3 +385,6 @@ def _flatten_past_key_values_(self, flattened_output, name, idx, t):\n             flattened_output = super(OnnxSeq2SeqConfigWithPast, self)._flatten_past_key_values_(\n                 flattened_output, name, idx, t\n             )\n+\n+\n+__all__ = [\"BlenderbotSmallConfig\", \"BlenderbotSmallOnnxConfig\"]"
        },
        {
            "sha": "8564fbf3115d96cb3b53fd2d1a5c4e0c89619f20",
            "filename": "src/transformers/models/blenderbot_small/modeling_blenderbot_small.py",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fmodeling_blenderbot_small.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fmodeling_blenderbot_small.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fmodeling_blenderbot_small.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1499,3 +1499,11 @@ def _reorder_cache(past_key_values, beam_idx):\n                 tuple(past_state.index_select(0, beam_idx.to(past_state.device)) for past_state in layer_past),\n             )\n         return reordered_past\n+\n+\n+__all__ = [\n+    \"BlenderbotSmallForCausalLM\",\n+    \"BlenderbotSmallForConditionalGeneration\",\n+    \"BlenderbotSmallModel\",\n+    \"BlenderbotSmallPreTrainedModel\",\n+]"
        },
        {
            "sha": "236685ac5971f66176f2928a11a567c01fc9f7ce",
            "filename": "src/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fmodeling_flax_blenderbot_small.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fmodeling_flax_blenderbot_small.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fmodeling_flax_blenderbot_small.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1519,3 +1519,10 @@ def update_inputs_for_generation(self, model_outputs, model_kwargs):\n append_replace_return_docstrings(\n     FlaxBlenderbotSmallForConditionalGeneration, output_type=FlaxSeq2SeqLMOutput, config_class=_CONFIG_FOR_DOC\n )\n+\n+\n+__all__ = [\n+    \"FlaxBlenderbotSmallForConditionalGeneration\",\n+    \"FlaxBlenderbotSmallModel\",\n+    \"FlaxBlenderbotSmallPreTrainedModel\",\n+]"
        },
        {
            "sha": "4de98280836d4a21a1abf1cb4cf27b0567ddad2f",
            "filename": "src/transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fmodeling_tf_blenderbot_small.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fmodeling_tf_blenderbot_small.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Fmodeling_tf_blenderbot_small.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1523,3 +1523,6 @@ def build(self, input_shape=None):\n         if getattr(self, \"bias_layer\", None) is not None:\n             with tf.name_scope(self.bias_layer.name):\n                 self.bias_layer.build(None)\n+\n+\n+__all__ = [\"TFBlenderbotSmallForConditionalGeneration\", \"TFBlenderbotSmallModel\", \"TFBlenderbotSmallPreTrainedModel\"]"
        },
        {
            "sha": "be950f0dbe629bb2ec1eef9e85ee1023132afd75",
            "filename": "src/transformers/models/blenderbot_small/tokenization_blenderbot_small.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Ftokenization_blenderbot_small.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Ftokenization_blenderbot_small.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Ftokenization_blenderbot_small.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -217,3 +217,6 @@ def save_vocabulary(self, save_directory: str, filename_prefix: Optional[str] =\n                 index += 1\n \n         return vocab_file, merge_file\n+\n+\n+__all__ = [\"BlenderbotSmallTokenizer\"]"
        },
        {
            "sha": "ac98ce008baad8d425afde9d76e46827cebd423c",
            "filename": "src/transformers/models/blenderbot_small/tokenization_blenderbot_small_fast.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Ftokenization_blenderbot_small_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Ftokenization_blenderbot_small_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot_small%2Ftokenization_blenderbot_small_fast.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -98,3 +98,6 @@ def create_token_type_ids_from_sequences(\n         if token_ids_1 is None:\n             return len(cls + token_ids_0 + sep) * [0]\n         return len(cls + token_ids_0 + sep + sep + token_ids_1 + sep) * [0]\n+\n+\n+__all__ = [\"BlenderbotSmallTokenizerFast\"]"
        },
        {
            "sha": "b3b604b24307ce86dcd422e06b0b836af4a12c32",
            "filename": "src/transformers/models/blip/__init__.py",
            "status": "modified",
            "additions": 13,
            "deletions": 102,
            "changes": 115,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2022 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,110 +13,21 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import (\n-    OptionalDependencyNotAvailable,\n-    _LazyModule,\n-    is_tf_available,\n-    is_torch_available,\n-    is_vision_available,\n-)\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n-_import_structure = {\n-    \"configuration_blip\": [\n-        \"BlipConfig\",\n-        \"BlipTextConfig\",\n-        \"BlipVisionConfig\",\n-    ],\n-    \"processing_blip\": [\"BlipProcessor\"],\n-}\n-\n-try:\n-    if not is_vision_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"image_processing_blip\"] = [\"BlipImageProcessor\"]\n-\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_blip\"] = [\n-        \"BlipModel\",\n-        \"BlipPreTrainedModel\",\n-        \"BlipForConditionalGeneration\",\n-        \"BlipForQuestionAnswering\",\n-        \"BlipVisionModel\",\n-        \"BlipTextModel\",\n-        \"BlipForImageTextRetrieval\",\n-    ]\n-\n-try:\n-    if not is_tf_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_tf_blip\"] = [\n-        \"TFBlipModel\",\n-        \"TFBlipPreTrainedModel\",\n-        \"TFBlipForConditionalGeneration\",\n-        \"TFBlipForQuestionAnswering\",\n-        \"TFBlipVisionModel\",\n-        \"TFBlipTextModel\",\n-        \"TFBlipForImageTextRetrieval\",\n-    ]\n-\n if TYPE_CHECKING:\n-    from .configuration_blip import BlipConfig, BlipTextConfig, BlipVisionConfig\n-    from .processing_blip import BlipProcessor\n-\n-    try:\n-        if not is_vision_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .image_processing_blip import BlipImageProcessor\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_blip import (\n-            BlipForConditionalGeneration,\n-            BlipForImageTextRetrieval,\n-            BlipForQuestionAnswering,\n-            BlipModel,\n-            BlipPreTrainedModel,\n-            BlipTextModel,\n-            BlipVisionModel,\n-        )\n-\n-    try:\n-        if not is_tf_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_tf_blip import (\n-            TFBlipForConditionalGeneration,\n-            TFBlipForImageTextRetrieval,\n-            TFBlipForQuestionAnswering,\n-            TFBlipModel,\n-            TFBlipPreTrainedModel,\n-            TFBlipTextModel,\n-            TFBlipVisionModel,\n-        )\n-\n+    from .configuration_blip import *\n+    from .convert_blip_original_pytorch_to_hf import *\n+    from .image_processing_blip import *\n+    from .modeling_blip import *\n+    from .modeling_blip_text import *\n+    from .modeling_tf_blip import *\n+    from .modeling_tf_blip_text import *\n+    from .processing_blip import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "c46cd2a08be28e9240ccf7d580d0c950b3d318f8",
            "filename": "src/transformers/models/blip/configuration_blip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip%2Fconfiguration_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip%2Fconfiguration_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fconfiguration_blip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -324,3 +324,6 @@ def from_text_vision_configs(cls, text_config: BlipTextConfig, vision_config: Bl\n         \"\"\"\n \n         return cls(text_config=text_config.to_dict(), vision_config=vision_config.to_dict(), **kwargs)\n+\n+\n+__all__ = [\"BlipConfig\", \"BlipTextConfig\", \"BlipVisionConfig\"]"
        },
        {
            "sha": "6bb2dd23733ee3efa5e18ed6735d6c65b2725291",
            "filename": "src/transformers/models/blip/image_processing_blip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip%2Fimage_processing_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip%2Fimage_processing_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fimage_processing_blip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -292,3 +292,6 @@ def preprocess(\n         encoded_outputs = BatchFeature(data={\"pixel_values\": images}, tensor_type=return_tensors)\n \n         return encoded_outputs\n+\n+\n+__all__ = [\"BlipImageProcessor\"]"
        },
        {
            "sha": "90018a8b98218a8d16b745cb13d382ea6e62212d",
            "filename": "src/transformers/models/blip/modeling_blip.py",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_blip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1581,3 +1581,14 @@ def forward(\n             attentions=vision_outputs.attentions,\n             question_embeds=question_embeds,\n         )\n+\n+\n+__all__ = [\n+    \"BlipModel\",\n+    \"BlipPreTrainedModel\",\n+    \"BlipForConditionalGeneration\",\n+    \"BlipForQuestionAnswering\",\n+    \"BlipVisionModel\",\n+    \"BlipTextModel\",\n+    \"BlipForImageTextRetrieval\",\n+]"
        },
        {
            "sha": "92f61bf470d93f53d3aac8b6071d94cacd885dea",
            "filename": "src/transformers/models/blip/modeling_tf_blip.py",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_tf_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_tf_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fmodeling_tf_blip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1696,3 +1696,14 @@ def build(self, input_shape=None):\n         if getattr(self, \"itm_head\", None) is not None:\n             with tf.name_scope(self.itm_head.name):\n                 self.itm_head.build([None, None, self.config.text_config.hidden_size])\n+\n+\n+__all__ = [\n+    \"TFBlipModel\",\n+    \"TFBlipPreTrainedModel\",\n+    \"TFBlipForConditionalGeneration\",\n+    \"TFBlipForQuestionAnswering\",\n+    \"TFBlipVisionModel\",\n+    \"TFBlipTextModel\",\n+    \"TFBlipForImageTextRetrieval\",\n+]"
        },
        {
            "sha": "edef863e4049076372c17d782b3abca360d113be",
            "filename": "src/transformers/models/blip/processing_blip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip%2Fprocessing_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip%2Fprocessing_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fprocessing_blip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -134,3 +134,6 @@ def model_input_names(self):\n         tokenizer_input_names = self.tokenizer.model_input_names\n         image_processor_input_names = self.image_processor.model_input_names\n         return list(dict.fromkeys(tokenizer_input_names + image_processor_input_names))\n+\n+\n+__all__ = [\"BlipProcessor\"]"
        },
        {
            "sha": "1014e8c88102c9b3719616f53a47f506adf29de3",
            "filename": "src/transformers/models/blip_2/__init__.py",
            "status": "modified",
            "additions": 9,
            "deletions": 53,
            "changes": 62,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip_2%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip_2%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip_2%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2023 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,61 +13,17 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import OptionalDependencyNotAvailable, _LazyModule, is_torch_available\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n-_import_structure = {\n-    \"configuration_blip_2\": [\n-        \"Blip2Config\",\n-        \"Blip2QFormerConfig\",\n-        \"Blip2VisionConfig\",\n-    ],\n-    \"processing_blip_2\": [\"Blip2Processor\"],\n-}\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_blip_2\"] = [\n-        \"Blip2Model\",\n-        \"Blip2VisionModelWithProjection\",\n-        \"Blip2QFormerModel\",\n-        \"Blip2PreTrainedModel\",\n-        \"Blip2ForConditionalGeneration\",\n-        \"Blip2ForImageTextRetrieval\",\n-        \"Blip2VisionModel\",\n-        \"Blip2TextModelWithProjection\",\n-    ]\n-\n if TYPE_CHECKING:\n-    from .configuration_blip_2 import (\n-        Blip2Config,\n-        Blip2QFormerConfig,\n-        Blip2VisionConfig,\n-    )\n-    from .processing_blip_2 import Blip2Processor\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_blip_2 import (\n-            Blip2ForConditionalGeneration,\n-            Blip2ForImageTextRetrieval,\n-            Blip2Model,\n-            Blip2PreTrainedModel,\n-            Blip2QFormerModel,\n-            Blip2TextModelWithProjection,\n-            Blip2VisionModel,\n-            Blip2VisionModelWithProjection,\n-        )\n-\n+    from .configuration_blip_2 import *\n+    from .convert_blip_2_original_to_pytorch import *\n+    from .modeling_blip_2 import *\n+    from .processing_blip_2 import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "539a3e365c9883d3ce85c98617a0eed801716fbe",
            "filename": "src/transformers/models/blip_2/configuration_blip_2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip_2%2Fconfiguration_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip_2%2Fconfiguration_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip_2%2Fconfiguration_blip_2.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -343,3 +343,6 @@ def from_vision_qformer_text_configs(\n             text_config=text_config.to_dict() if text_config is not None else None,\n             **kwargs,\n         )\n+\n+\n+__all__ = [\"Blip2Config\", \"Blip2QFormerConfig\", \"Blip2VisionConfig\"]"
        },
        {
            "sha": "99d678b1227be352cd72d65b3a7594339f7defb9",
            "filename": "src/transformers/models/blip_2/modeling_blip_2.py",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip_2%2Fmodeling_blip_2.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -2533,3 +2533,15 @@ def forward(\n             text_model_output=text_outputs,\n             vision_model_output=vision_outputs,\n         )\n+\n+\n+__all__ = [\n+    \"Blip2Model\",\n+    \"Blip2VisionModelWithProjection\",\n+    \"Blip2QFormerModel\",\n+    \"Blip2PreTrainedModel\",\n+    \"Blip2ForConditionalGeneration\",\n+    \"Blip2ForImageTextRetrieval\",\n+    \"Blip2VisionModel\",\n+    \"Blip2TextModelWithProjection\",\n+]"
        },
        {
            "sha": "5d09ea7c07668b4763469a0a8e76e6bed03ce33e",
            "filename": "src/transformers/models/blip_2/processing_blip_2.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip_2%2Fprocessing_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fblip_2%2Fprocessing_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip_2%2Fprocessing_blip_2.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -188,3 +188,6 @@ def model_input_names(self):\n         tokenizer_input_names = self.tokenizer.model_input_names\n         image_processor_input_names = self.image_processor.model_input_names\n         return list(dict.fromkeys(tokenizer_input_names + image_processor_input_names))\n+\n+\n+__all__ = [\"Blip2Processor\"]"
        },
        {
            "sha": "012bbbc15c25d6a3ecce3164caa6e4e8849618ad",
            "filename": "src/transformers/models/bloom/__init__.py",
            "status": "modified",
            "additions": 10,
            "deletions": 81,
            "changes": 91,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbloom%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbloom%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbloom%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2022 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -11,91 +11,20 @@\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.\n-\n from typing import TYPE_CHECKING\n \n-from ...utils import (\n-    OptionalDependencyNotAvailable,\n-    _LazyModule,\n-    is_flax_available,\n-    is_tokenizers_available,\n-    is_torch_available,\n-)\n-\n-\n-_import_structure = {\n-    \"configuration_bloom\": [\"BloomConfig\", \"BloomOnnxConfig\"],\n-}\n-try:\n-    if not is_tokenizers_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"tokenization_bloom_fast\"] = [\"BloomTokenizerFast\"]\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_bloom\"] = [\n-        \"BloomForCausalLM\",\n-        \"BloomModel\",\n-        \"BloomPreTrainedModel\",\n-        \"BloomForSequenceClassification\",\n-        \"BloomForTokenClassification\",\n-        \"BloomForQuestionAnswering\",\n-    ]\n-\n-try:\n-    if not is_flax_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_flax_bloom\"] = [\n-        \"FlaxBloomForCausalLM\",\n-        \"FlaxBloomModel\",\n-        \"FlaxBloomPreTrainedModel\",\n-    ]\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n if TYPE_CHECKING:\n-    from .configuration_bloom import BloomConfig, BloomOnnxConfig\n-\n-    try:\n-        if not is_tokenizers_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .tokenization_bloom_fast import BloomTokenizerFast\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_bloom import (\n-            BloomForCausalLM,\n-            BloomForQuestionAnswering,\n-            BloomForSequenceClassification,\n-            BloomForTokenClassification,\n-            BloomModel,\n-            BloomPreTrainedModel,\n-        )\n-\n-    try:\n-        if not is_flax_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_flax_bloom import FlaxBloomForCausalLM, FlaxBloomModel, FlaxBloomPreTrainedModel\n+    from .configuration_bloom import *\n+    from .convert_bloom_original_checkpoint_to_pytorch import *\n+    from .modeling_bloom import *\n+    from .modeling_flax_bloom import *\n+    from .tokenization_bloom_fast import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "ca10c7ce7ed4ef795f8aefad01bcf93bc88099ee",
            "filename": "src/transformers/models/bloom/configuration_bloom.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbloom%2Fconfiguration_bloom.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbloom%2Fconfiguration_bloom.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbloom%2Fconfiguration_bloom.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -232,3 +232,6 @@ def generate_dummy_inputs(\n     @property\n     def default_onnx_opset(self) -> int:\n         return 13\n+\n+\n+__all__ = [\"BloomConfig\", \"BloomOnnxConfig\"]"
        },
        {
            "sha": "086f8ce03c62fce2c533787065d5005c3521012f",
            "filename": "src/transformers/models/bloom/modeling_bloom.py",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbloom%2Fmodeling_bloom.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbloom%2Fmodeling_bloom.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbloom%2Fmodeling_bloom.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1362,3 +1362,13 @@ def forward(\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n         )\n+\n+\n+__all__ = [\n+    \"BloomForCausalLM\",\n+    \"BloomModel\",\n+    \"BloomPreTrainedModel\",\n+    \"BloomForSequenceClassification\",\n+    \"BloomForTokenClassification\",\n+    \"BloomForQuestionAnswering\",\n+]"
        },
        {
            "sha": "077c2123bf95c4380d1c33269b020d0c721327d1",
            "filename": "src/transformers/models/bloom/modeling_flax_bloom.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbloom%2Fmodeling_flax_bloom.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbloom%2Fmodeling_flax_bloom.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbloom%2Fmodeling_flax_bloom.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -732,3 +732,6 @@ def update_inputs_for_generation(self, model_outputs, model_kwargs):\n \n \n append_call_sample_docstring(FlaxBloomForCausalLM, _CHECKPOINT_FOR_DOC, FlaxCausalLMOutput, _CONFIG_FOR_DOC)\n+\n+\n+__all__ = [\"FlaxBloomForCausalLM\", \"FlaxBloomModel\", \"FlaxBloomPreTrainedModel\"]"
        },
        {
            "sha": "c84322637cb7e879b2cf50fdbd81fdc79b08ed98",
            "filename": "src/transformers/models/bloom/tokenization_bloom_fast.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbloom%2Ftokenization_bloom_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbloom%2Ftokenization_bloom_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbloom%2Ftokenization_bloom_fast.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -147,3 +147,6 @@ def _encode_plus(self, *args, **kwargs) -> BatchEncoding:\n     def save_vocabulary(self, save_directory: str, filename_prefix: Optional[str] = None) -> Tuple[str]:\n         files = self._tokenizer.model.save(save_directory, name=filename_prefix)\n         return tuple(files)\n+\n+\n+__all__ = [\"BloomTokenizerFast\"]"
        },
        {
            "sha": "65613444624fcfed47f79674d1dabf8f6b911baa",
            "filename": "src/transformers/models/bridgetower/__init__.py",
            "status": "modified",
            "additions": 9,
            "deletions": 65,
            "changes": 74,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbridgetower%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbridgetower%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbridgetower%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2023 The Intel Labs Team Authors, The Microsoft Research Team Authors and HuggingFace Inc. team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,73 +13,17 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import OptionalDependencyNotAvailable, _LazyModule, is_torch_available, is_vision_available\n-\n-\n-_import_structure = {\n-    \"configuration_bridgetower\": [\n-        \"BridgeTowerConfig\",\n-        \"BridgeTowerTextConfig\",\n-        \"BridgeTowerVisionConfig\",\n-    ],\n-    \"processing_bridgetower\": [\"BridgeTowerProcessor\"],\n-}\n-\n-try:\n-    if not is_vision_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"image_processing_bridgetower\"] = [\"BridgeTowerImageProcessor\"]\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_bridgetower\"] = [\n-        \"BridgeTowerForContrastiveLearning\",\n-        \"BridgeTowerForImageAndTextRetrieval\",\n-        \"BridgeTowerForMaskedLM\",\n-        \"BridgeTowerModel\",\n-        \"BridgeTowerPreTrainedModel\",\n-    ]\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n if TYPE_CHECKING:\n-    from .configuration_bridgetower import (\n-        BridgeTowerConfig,\n-        BridgeTowerTextConfig,\n-        BridgeTowerVisionConfig,\n-    )\n-    from .processing_bridgetower import BridgeTowerProcessor\n-\n-    try:\n-        if not is_vision_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .image_processing_bridgetower import BridgeTowerImageProcessor\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_bridgetower import (\n-            BridgeTowerForContrastiveLearning,\n-            BridgeTowerForImageAndTextRetrieval,\n-            BridgeTowerForMaskedLM,\n-            BridgeTowerModel,\n-            BridgeTowerPreTrainedModel,\n-        )\n-\n-\n+    from .configuration_bridgetower import *\n+    from .image_processing_bridgetower import *\n+    from .modeling_bridgetower import *\n+    from .processing_bridgetower import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "6a3d9072defadcc329ff8da060945f5945f59ba9",
            "filename": "src/transformers/models/bridgetower/configuration_bridgetower.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fconfiguration_bridgetower.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fconfiguration_bridgetower.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fconfiguration_bridgetower.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -314,3 +314,6 @@ def from_text_vision_configs(\n         \"\"\"\n \n         return cls(text_config=text_config.to_dict(), vision_config=vision_config.to_dict(), **kwargs)\n+\n+\n+__all__ = [\"BridgeTowerConfig\", \"BridgeTowerTextConfig\", \"BridgeTowerVisionConfig\"]"
        },
        {
            "sha": "a8b94e7c9709dc2c7cba349d3cd32ea81a04479c",
            "filename": "src/transformers/models/bridgetower/image_processing_bridgetower.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fimage_processing_bridgetower.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fimage_processing_bridgetower.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fimage_processing_bridgetower.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -538,3 +538,6 @@ def preprocess(\n             encoded_outputs = BatchFeature(data={\"pixel_values\": images}, tensor_type=return_tensors)\n \n         return encoded_outputs\n+\n+\n+__all__ = [\"BridgeTowerImageProcessor\"]"
        },
        {
            "sha": "0d4338261eec4bef95692a23f966c2fe6bb04d9e",
            "filename": "src/transformers/models/bridgetower/modeling_bridgetower.py",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fmodeling_bridgetower.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fmodeling_bridgetower.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fmodeling_bridgetower.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1973,3 +1973,12 @@ def forward(\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n         )\n+\n+\n+__all__ = [\n+    \"BridgeTowerForContrastiveLearning\",\n+    \"BridgeTowerForImageAndTextRetrieval\",\n+    \"BridgeTowerForMaskedLM\",\n+    \"BridgeTowerModel\",\n+    \"BridgeTowerPreTrainedModel\",\n+]"
        },
        {
            "sha": "5519d0a34ce911b26f48b76399bc68cba798bdbd",
            "filename": "src/transformers/models/bridgetower/processing_bridgetower.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fprocessing_bridgetower.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fprocessing_bridgetower.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbridgetower%2Fprocessing_bridgetower.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -109,3 +109,6 @@ def model_input_names(self):\n         tokenizer_input_names = self.tokenizer.model_input_names\n         image_processor_input_names = self.image_processor.model_input_names\n         return list(dict.fromkeys(tokenizer_input_names + image_processor_input_names))\n+\n+\n+__all__ = [\"BridgeTowerProcessor\"]"
        },
        {
            "sha": "54e429863ec85b872f611eea1f8ac11fe2bef594",
            "filename": "src/transformers/models/bros/__init__.py",
            "status": "modified",
            "additions": 9,
            "deletions": 55,
            "changes": 64,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbros%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbros%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbros%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2023-present NAVER Corp, The Microsoft Research Asia LayoutLM Team Authors and the HuggingFace Inc. team.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,63 +13,17 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import OptionalDependencyNotAvailable, _LazyModule, is_tokenizers_available, is_torch_available\n-\n-\n-_import_structure = {\n-    \"configuration_bros\": [\"BrosConfig\"],\n-}\n-\n-try:\n-    if not is_tokenizers_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"processing_bros\"] = [\"BrosProcessor\"]\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_bros\"] = [\n-        \"BrosPreTrainedModel\",\n-        \"BrosModel\",\n-        \"BrosForTokenClassification\",\n-        \"BrosSpadeEEForTokenClassification\",\n-        \"BrosSpadeELForTokenClassification\",\n-    ]\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n if TYPE_CHECKING:\n-    from .configuration_bros import BrosConfig\n-\n-    try:\n-        if not is_tokenizers_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .processing_bros import BrosProcessor\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_bros import (\n-            BrosForTokenClassification,\n-            BrosModel,\n-            BrosPreTrainedModel,\n-            BrosSpadeEEForTokenClassification,\n-            BrosSpadeELForTokenClassification,\n-        )\n-\n-\n+    from .configuration_bros import *\n+    from .convert_bros_to_pytorch import *\n+    from .modeling_bros import *\n+    from .processing_bros import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "84c9989f309fb782b47aed37f9728dd7a26ba6b8",
            "filename": "src/transformers/models/bros/configuration_bros.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbros%2Fconfiguration_bros.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbros%2Fconfiguration_bros.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbros%2Fconfiguration_bros.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -133,3 +133,6 @@ def __init__(\n         self.dim_bbox_sinusoid_emb_1d = self.dim_bbox_sinusoid_emb_2d // self.dim_bbox\n         self.dim_bbox_projection = self.hidden_size // self.num_attention_heads\n         self.classifier_dropout_prob = classifier_dropout_prob\n+\n+\n+__all__ = [\"BrosConfig\"]"
        },
        {
            "sha": "0e1e86c0b39f7e427374dc7ef3f6eb3c63f4dd48",
            "filename": "src/transformers/models/bros/modeling_bros.py",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbros%2Fmodeling_bros.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbros%2Fmodeling_bros.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbros%2Fmodeling_bros.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1312,3 +1312,12 @@ def forward(\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n         )\n+\n+\n+__all__ = [\n+    \"BrosPreTrainedModel\",\n+    \"BrosModel\",\n+    \"BrosForTokenClassification\",\n+    \"BrosSpadeEEForTokenClassification\",\n+    \"BrosSpadeELForTokenClassification\",\n+]"
        },
        {
            "sha": "4687e7f8a86ae5ab4d1339517622f52023c57499",
            "filename": "src/transformers/models/bros/processing_bros.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbros%2Fprocessing_bros.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbros%2Fprocessing_bros.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbros%2Fprocessing_bros.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -107,3 +107,6 @@ def decode(self, *args, **kwargs):\n     def model_input_names(self):\n         tokenizer_input_names = self.tokenizer.model_input_names\n         return list(dict.fromkeys(tokenizer_input_names))\n+\n+\n+__all__ = [\"BrosProcessor\"]"
        },
        {
            "sha": "c4243d1970d31dffe9f48e2e5ec51e677f28ec77",
            "filename": "src/transformers/models/byt5/__init__.py",
            "status": "modified",
            "additions": 6,
            "deletions": 7,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbyt5%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbyt5%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbyt5%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2021 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -11,18 +11,17 @@\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.\n-\n from typing import TYPE_CHECKING\n \n from ...utils import _LazyModule\n-\n-\n-_import_structure = {\"tokenization_byt5\": [\"ByT5Tokenizer\"]}\n+from ...utils.import_utils import define_import_structure\n \n \n if TYPE_CHECKING:\n-    from .tokenization_byt5 import ByT5Tokenizer\n+    from .convert_byt5_original_tf_checkpoint_to_pytorch import *\n+    from .tokenization_byt5 import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "b39ba254b38170e47dcbe0b8da0926fb2e849450",
            "filename": "src/transformers/models/byt5/tokenization_byt5.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbyt5%2Ftokenization_byt5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fbyt5%2Ftokenization_byt5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbyt5%2Ftokenization_byt5.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -231,3 +231,6 @@ def convert_tokens_to_string(self, tokens):\n     # ByT5Tokenizer has no vocab file\n     def save_vocabulary(self, save_directory: str, filename_prefix: Optional[str] = None) -> Tuple[str]:\n         return ()\n+\n+\n+__all__ = [\"ByT5Tokenizer\"]"
        },
        {
            "sha": "9d90f64de97f78ccaf1592c3c5cad40a9b2d5dcb",
            "filename": "src/transformers/models/camembert/__init__.py",
            "status": "modified",
            "additions": 10,
            "deletions": 118,
            "changes": 128,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcamembert%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcamembert%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcamembert%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2020 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -11,128 +11,20 @@\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.\n-\n from typing import TYPE_CHECKING\n \n-from ...utils import (\n-    OptionalDependencyNotAvailable,\n-    _LazyModule,\n-    is_sentencepiece_available,\n-    is_tf_available,\n-    is_tokenizers_available,\n-    is_torch_available,\n-)\n-\n-\n-_import_structure = {\n-    \"configuration_camembert\": [\"CamembertConfig\", \"CamembertOnnxConfig\"],\n-}\n-\n-try:\n-    if not is_sentencepiece_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"tokenization_camembert\"] = [\"CamembertTokenizer\"]\n-\n-try:\n-    if not is_tokenizers_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"tokenization_camembert_fast\"] = [\"CamembertTokenizerFast\"]\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_camembert\"] = [\n-        \"CamembertForCausalLM\",\n-        \"CamembertForMaskedLM\",\n-        \"CamembertForMultipleChoice\",\n-        \"CamembertForQuestionAnswering\",\n-        \"CamembertForSequenceClassification\",\n-        \"CamembertForTokenClassification\",\n-        \"CamembertModel\",\n-        \"CamembertPreTrainedModel\",\n-    ]\n-\n-try:\n-    if not is_tf_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_tf_camembert\"] = [\n-        \"TFCamembertForCausalLM\",\n-        \"TFCamembertForMaskedLM\",\n-        \"TFCamembertForMultipleChoice\",\n-        \"TFCamembertForQuestionAnswering\",\n-        \"TFCamembertForSequenceClassification\",\n-        \"TFCamembertForTokenClassification\",\n-        \"TFCamembertModel\",\n-        \"TFCamembertPreTrainedModel\",\n-    ]\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n if TYPE_CHECKING:\n-    from .configuration_camembert import CamembertConfig, CamembertOnnxConfig\n-\n-    try:\n-        if not is_sentencepiece_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .tokenization_camembert import CamembertTokenizer\n-\n-    try:\n-        if not is_tokenizers_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .tokenization_camembert_fast import CamembertTokenizerFast\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_camembert import (\n-            CamembertForCausalLM,\n-            CamembertForMaskedLM,\n-            CamembertForMultipleChoice,\n-            CamembertForQuestionAnswering,\n-            CamembertForSequenceClassification,\n-            CamembertForTokenClassification,\n-            CamembertModel,\n-            CamembertPreTrainedModel,\n-        )\n-\n-    try:\n-        if not is_tf_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_tf_camembert import (\n-            TFCamembertForCausalLM,\n-            TFCamembertForMaskedLM,\n-            TFCamembertForMultipleChoice,\n-            TFCamembertForQuestionAnswering,\n-            TFCamembertForSequenceClassification,\n-            TFCamembertForTokenClassification,\n-            TFCamembertModel,\n-            TFCamembertPreTrainedModel,\n-        )\n-\n+    from .configuration_camembert import *\n+    from .modeling_camembert import *\n+    from .modeling_tf_camembert import *\n+    from .tokenization_camembert import *\n+    from .tokenization_camembert_fast import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "eaf8c94b8914811e35210b6ebcf3fcdece6281c7",
            "filename": "src/transformers/models/camembert/configuration_camembert.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcamembert%2Fconfiguration_camembert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcamembert%2Fconfiguration_camembert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcamembert%2Fconfiguration_camembert.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -150,3 +150,6 @@ def inputs(self) -> Mapping[str, Mapping[int, str]]:\n                 (\"attention_mask\", dynamic_axis),\n             ]\n         )\n+\n+\n+__all__ = [\"CamembertConfig\", \"CamembertOnnxConfig\"]"
        },
        {
            "sha": "e94e4a0a8948c53598c9064f1942cdd9fc1c26f8",
            "filename": "src/transformers/models/camembert/modeling_camembert.py",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_camembert.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1698,3 +1698,15 @@ def create_position_ids_from_input_ids(input_ids, padding_idx, past_key_values_l\n     mask = input_ids.ne(padding_idx).int()\n     incremental_indices = (torch.cumsum(mask, dim=1).type_as(mask) + past_key_values_length) * mask\n     return incremental_indices.long() + padding_idx\n+\n+\n+__all__ = [\n+    \"CamembertForCausalLM\",\n+    \"CamembertForMaskedLM\",\n+    \"CamembertForMultipleChoice\",\n+    \"CamembertForQuestionAnswering\",\n+    \"CamembertForSequenceClassification\",\n+    \"CamembertForTokenClassification\",\n+    \"CamembertModel\",\n+    \"CamembertPreTrainedModel\",\n+]"
        },
        {
            "sha": "6f456723dea54aafe13a545ea85273835e9605b4",
            "filename": "src/transformers/models/camembert/modeling_tf_camembert.py",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_tf_camembert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_tf_camembert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcamembert%2Fmodeling_tf_camembert.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1787,3 +1787,15 @@ def build(self, input_shape=None):\n         if getattr(self, \"lm_head\", None) is not None:\n             with tf.name_scope(self.lm_head.name):\n                 self.lm_head.build(None)\n+\n+\n+__all__ = [\n+    \"TFCamembertForCausalLM\",\n+    \"TFCamembertForMaskedLM\",\n+    \"TFCamembertForMultipleChoice\",\n+    \"TFCamembertForQuestionAnswering\",\n+    \"TFCamembertForSequenceClassification\",\n+    \"TFCamembertForTokenClassification\",\n+    \"TFCamembertModel\",\n+    \"TFCamembertPreTrainedModel\",\n+]"
        },
        {
            "sha": "3353bf3433c7e13032a06157652ca109986a2968",
            "filename": "src/transformers/models/camembert/tokenization_camembert.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcamembert%2Ftokenization_camembert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcamembert%2Ftokenization_camembert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcamembert%2Ftokenization_camembert.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -316,3 +316,6 @@ def create_token_type_ids_from_sequences(\n         if token_ids_1 is None:\n             return len(cls + token_ids_0 + sep) * [0]\n         return len(cls + token_ids_0 + sep + sep + token_ids_1 + sep) * [0]\n+\n+\n+__all__ = [\"CamembertTokenizer\"]"
        },
        {
            "sha": "c04b5618390234f71a4d0f5890974ec1fd6916d0",
            "filename": "src/transformers/models/camembert/tokenization_camembert_fast.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcamembert%2Ftokenization_camembert_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcamembert%2Ftokenization_camembert_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcamembert%2Ftokenization_camembert_fast.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -196,3 +196,6 @@ def save_vocabulary(self, save_directory: str, filename_prefix: Optional[str] =\n             copyfile(self.vocab_file, out_vocab_file)\n \n         return (out_vocab_file,)\n+\n+\n+__all__ = [\"CamembertTokenizerFast\"]"
        },
        {
            "sha": "5f9611153bbd40dcca0d51f83358d580a5d3ed4f",
            "filename": "src/transformers/models/canine/__init__.py",
            "status": "modified",
            "additions": 9,
            "deletions": 47,
            "changes": 56,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcanine%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcanine%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcanine%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2020 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,55 +13,17 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import OptionalDependencyNotAvailable, _LazyModule, is_tokenizers_available, is_torch_available\n-\n-\n-_import_structure = {\n-    \"configuration_canine\": [\"CanineConfig\"],\n-    \"tokenization_canine\": [\"CanineTokenizer\"],\n-}\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_canine\"] = [\n-        \"CanineForMultipleChoice\",\n-        \"CanineForQuestionAnswering\",\n-        \"CanineForSequenceClassification\",\n-        \"CanineForTokenClassification\",\n-        \"CanineLayer\",\n-        \"CanineModel\",\n-        \"CaninePreTrainedModel\",\n-        \"load_tf_weights_in_canine\",\n-    ]\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n if TYPE_CHECKING:\n-    from .configuration_canine import CanineConfig\n-    from .tokenization_canine import CanineTokenizer\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_canine import (\n-            CanineForMultipleChoice,\n-            CanineForQuestionAnswering,\n-            CanineForSequenceClassification,\n-            CanineForTokenClassification,\n-            CanineLayer,\n-            CanineModel,\n-            CaninePreTrainedModel,\n-            load_tf_weights_in_canine,\n-        )\n-\n-\n+    from .configuration_canine import *\n+    from .convert_canine_original_tf_checkpoint_to_pytorch import *\n+    from .modeling_canine import *\n+    from .tokenization_canine import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "29e90327d08f02d490006a464cb566adbca52007",
            "filename": "src/transformers/models/canine/configuration_canine.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcanine%2Fconfiguration_canine.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcanine%2Fconfiguration_canine.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcanine%2Fconfiguration_canine.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -136,3 +136,6 @@ def __init__(\n         self.num_hash_functions = num_hash_functions\n         self.num_hash_buckets = num_hash_buckets\n         self.local_transformer_stride = local_transformer_stride\n+\n+\n+__all__ = [\"CanineConfig\"]"
        },
        {
            "sha": "9f18fc9ac3df1919be90a1fc8489ded249eeccdc",
            "filename": "src/transformers/models/canine/modeling_canine.py",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcanine%2Fmodeling_canine.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcanine%2Fmodeling_canine.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcanine%2Fmodeling_canine.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1639,3 +1639,15 @@ def forward(\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n         )\n+\n+\n+__all__ = [\n+    \"CanineForMultipleChoice\",\n+    \"CanineForQuestionAnswering\",\n+    \"CanineForSequenceClassification\",\n+    \"CanineForTokenClassification\",\n+    \"CanineLayer\",\n+    \"CanineModel\",\n+    \"CaninePreTrainedModel\",\n+    \"load_tf_weights_in_canine\",\n+]"
        },
        {
            "sha": "fe2734712dca5b79170738993767977df2f79105",
            "filename": "src/transformers/models/canine/tokenization_canine.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcanine%2Ftokenization_canine.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fcanine%2Ftokenization_canine.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcanine%2Ftokenization_canine.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -239,3 +239,6 @@ def create_token_type_ids_from_sequences(\n     # CanineTokenizer has no vocab file\n     def save_vocabulary(self, save_directory: str, filename_prefix: Optional[str] = None):\n         return ()\n+\n+\n+__all__ = [\"CanineTokenizer\"]"
        },
        {
            "sha": "ad00f5cd3dab3dd16f56f1fb56b9f8128949025a",
            "filename": "src/transformers/models/chameleon/__init__.py",
            "status": "modified",
            "additions": 10,
            "deletions": 63,
            "changes": 73,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchameleon%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchameleon%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchameleon%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2024 Meta Inc. and The HuggingFace Inc. team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,71 +13,18 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import (\n-    OptionalDependencyNotAvailable,\n-    _LazyModule,\n-    is_sentencepiece_available,\n-    is_tokenizers_available,\n-    is_torch_available,\n-    is_vision_available,\n-)\n-\n-\n-_import_structure = {\n-    \"configuration_chameleon\": [\"ChameleonConfig\", \"ChameleonVQVAEConfig\"],\n-    \"processing_chameleon\": [\"ChameleonProcessor\"],\n-}\n-\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_chameleon\"] = [\n-        \"ChameleonForConditionalGeneration\",\n-        \"ChameleonModel\",\n-        \"ChameleonPreTrainedModel\",\n-        \"ChameleonVQVAE\",\n-    ]\n-\n-try:\n-    if not is_vision_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"image_processing_chameleon\"] = [\"ChameleonImageProcessor\"]\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n if TYPE_CHECKING:\n-    from .configuration_chameleon import ChameleonConfig, ChameleonVQVAEConfig\n-    from .processing_chameleon import ChameleonProcessor\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_chameleon import (\n-            ChameleonForConditionalGeneration,\n-            ChameleonModel,\n-            ChameleonPreTrainedModel,\n-            ChameleonVQVAE,\n-        )\n-\n-    try:\n-        if not is_vision_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .image_processing_chameleon import ChameleonImageProcessor\n-\n-\n+    from .configuration_chameleon import *\n+    from .convert_chameleon_weights_to_hf import *\n+    from .image_processing_chameleon import *\n+    from .modeling_chameleon import *\n+    from .processing_chameleon import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "2cc9cdb29d46c513d61fe8931c35f45daf4ba555",
            "filename": "src/transformers/models/chameleon/configuration_chameleon.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchameleon%2Fconfiguration_chameleon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchameleon%2Fconfiguration_chameleon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchameleon%2Fconfiguration_chameleon.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -276,3 +276,6 @@ def _rope_scaling_validation(self):\n             )\n         if rope_scaling_factor is None or not isinstance(rope_scaling_factor, float) or rope_scaling_factor <= 1.0:\n             raise ValueError(f\"`rope_scaling`'s factor field must be a float > 1, got {rope_scaling_factor}\")\n+\n+\n+__all__ = [\"ChameleonConfig\", \"ChameleonVQVAEConfig\"]"
        },
        {
            "sha": "cadaeb2e09a624a0d913ca04ea0960c31784ce27",
            "filename": "src/transformers/models/chameleon/image_processing_chameleon.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchameleon%2Fimage_processing_chameleon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchameleon%2Fimage_processing_chameleon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchameleon%2Fimage_processing_chameleon.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -362,3 +362,6 @@ def blend_rgba(self, image: ImageInput) -> ImageInput:\n         alpha = img_rgba[:, :, 3] / 255.0\n         img_rgb = (1 - alpha[:, :, np.newaxis]) * 255 + alpha[:, :, np.newaxis] * img_rgba[:, :, :3]\n         return PIL.Image.fromarray(img_rgb.astype(\"uint8\"), \"RGB\")\n+\n+\n+__all__ = [\"ChameleonImageProcessor\"]"
        },
        {
            "sha": "f01665201bfa2139b3eb083496d573d85ff50875",
            "filename": "src/transformers/models/chameleon/modeling_chameleon.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchameleon%2Fmodeling_chameleon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchameleon%2Fmodeling_chameleon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchameleon%2Fmodeling_chameleon.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1685,3 +1685,6 @@ def prepare_inputs_for_generation(\n             }\n         )\n         return model_inputs\n+\n+\n+__all__ = [\"ChameleonForConditionalGeneration\", \"ChameleonModel\", \"ChameleonPreTrainedModel\", \"ChameleonVQVAE\"]"
        },
        {
            "sha": "9f4bc2904c861c11bddd040fc782fa78fbf96903",
            "filename": "src/transformers/models/chameleon/processing_chameleon.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchameleon%2Fprocessing_chameleon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchameleon%2Fprocessing_chameleon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchameleon%2Fprocessing_chameleon.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -168,3 +168,6 @@ def model_input_names(self):\n         tokenizer_input_names = self.tokenizer.model_input_names\n         image_processor_input_names = self.image_processor.model_input_names\n         return list(dict.fromkeys(tokenizer_input_names + image_processor_input_names))\n+\n+\n+__all__ = [\"ChameleonProcessor\"]"
        },
        {
            "sha": "8770bde94ecf3ad75123b2e022f00a5e575a2303",
            "filename": "src/transformers/models/chinese_clip/__init__.py",
            "status": "modified",
            "additions": 11,
            "deletions": 64,
            "changes": 75,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchinese_clip%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchinese_clip%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchinese_clip%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2022 The OFA-Sys Team Authors and The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,72 +13,19 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import OptionalDependencyNotAvailable, _LazyModule, is_torch_available, is_vision_available\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n-_import_structure = {\n-    \"configuration_chinese_clip\": [\n-        \"ChineseCLIPConfig\",\n-        \"ChineseCLIPOnnxConfig\",\n-        \"ChineseCLIPTextConfig\",\n-        \"ChineseCLIPVisionConfig\",\n-    ],\n-    \"processing_chinese_clip\": [\"ChineseCLIPProcessor\"],\n-}\n-\n-try:\n-    if not is_vision_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"feature_extraction_chinese_clip\"] = [\"ChineseCLIPFeatureExtractor\"]\n-    _import_structure[\"image_processing_chinese_clip\"] = [\"ChineseCLIPImageProcessor\"]\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_chinese_clip\"] = [\n-        \"ChineseCLIPModel\",\n-        \"ChineseCLIPPreTrainedModel\",\n-        \"ChineseCLIPTextModel\",\n-        \"ChineseCLIPVisionModel\",\n-    ]\n-\n if TYPE_CHECKING:\n-    from .configuration_chinese_clip import (\n-        ChineseCLIPConfig,\n-        ChineseCLIPOnnxConfig,\n-        ChineseCLIPTextConfig,\n-        ChineseCLIPVisionConfig,\n-    )\n-    from .processing_chinese_clip import ChineseCLIPProcessor\n-\n-    try:\n-        if not is_vision_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .feature_extraction_chinese_clip import ChineseCLIPFeatureExtractor, ChineseCLIPImageProcessor\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_chinese_clip import (\n-            ChineseCLIPModel,\n-            ChineseCLIPPreTrainedModel,\n-            ChineseCLIPTextModel,\n-            ChineseCLIPVisionModel,\n-        )\n-\n+    from .configuration_chinese_clip import *\n+    from .convert_chinese_clip_original_pytorch_to_hf import *\n+    from .feature_extraction_chinese_clip import *\n+    from .image_processing_chinese_clip import *\n+    from .modeling_chinese_clip import *\n+    from .processing_chinese_clip import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "c52b563cb2df9a63591c85d45b0aad99d53f4675",
            "filename": "src/transformers/models/chinese_clip/configuration_chinese_clip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fconfiguration_chinese_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fconfiguration_chinese_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fconfiguration_chinese_clip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -429,3 +429,6 @@ def generate_dummy_inputs(\n     @property\n     def default_onnx_opset(self) -> int:\n         return 14\n+\n+\n+__all__ = [\"ChineseCLIPConfig\", \"ChineseCLIPOnnxConfig\", \"ChineseCLIPTextConfig\", \"ChineseCLIPVisionConfig\"]"
        },
        {
            "sha": "fd416ca93b9ff389a6768f781ea57a25752aa554",
            "filename": "src/transformers/models/chinese_clip/feature_extraction_chinese_clip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Ffeature_extraction_chinese_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Ffeature_extraction_chinese_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Ffeature_extraction_chinese_clip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -31,3 +31,6 @@ def __init__(self, *args, **kwargs) -> None:\n             FutureWarning,\n         )\n         super().__init__(*args, **kwargs)\n+\n+\n+__all__ = [\"ChineseCLIPFeatureExtractor\"]"
        },
        {
            "sha": "2c338f5a71b9db433c61fc7d129bb0d593bcc32f",
            "filename": "src/transformers/models/chinese_clip/image_processing_chinese_clip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fimage_processing_chinese_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fimage_processing_chinese_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fimage_processing_chinese_clip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -305,3 +305,6 @@ def preprocess(\n \n         data = {\"pixel_values\": images}\n         return BatchFeature(data=data, tensor_type=return_tensors)\n+\n+\n+__all__ = [\"ChineseCLIPImageProcessor\"]"
        },
        {
            "sha": "c9c19073b0e77a54edf69027e1eb702ecebb4c4b",
            "filename": "src/transformers/models/chinese_clip/modeling_chinese_clip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fmodeling_chinese_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fmodeling_chinese_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fmodeling_chinese_clip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1625,3 +1625,6 @@ def forward(\n             text_model_output=text_outputs,\n             vision_model_output=vision_outputs,\n         )\n+\n+\n+__all__ = [\"ChineseCLIPModel\", \"ChineseCLIPPreTrainedModel\", \"ChineseCLIPTextModel\", \"ChineseCLIPVisionModel\"]"
        },
        {
            "sha": "53ba3d31259be9db2defc4f10d1338dafd89c65e",
            "filename": "src/transformers/models/chinese_clip/processing_chinese_clip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fprocessing_chinese_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fprocessing_chinese_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fprocessing_chinese_clip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -158,3 +158,6 @@ def feature_extractor_class(self):\n             FutureWarning,\n         )\n         return self.image_processor_class\n+\n+\n+__all__ = [\"ChineseCLIPProcessor\"]"
        },
        {
            "sha": "aa2a04536f5d9e01f2c5da5fb8f706725a6405ae",
            "filename": "src/transformers/models/clap/__init__.py",
            "status": "modified",
            "additions": 10,
            "deletions": 52,
            "changes": 62,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclap%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclap%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclap%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2023 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,60 +13,18 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import OptionalDependencyNotAvailable, _LazyModule, is_torch_available\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n-_import_structure = {\n-    \"configuration_clap\": [\n-        \"ClapAudioConfig\",\n-        \"ClapConfig\",\n-        \"ClapTextConfig\",\n-    ],\n-    \"processing_clap\": [\"ClapProcessor\"],\n-}\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_clap\"] = [\n-        \"ClapModel\",\n-        \"ClapPreTrainedModel\",\n-        \"ClapTextModel\",\n-        \"ClapTextModelWithProjection\",\n-        \"ClapAudioModel\",\n-        \"ClapAudioModelWithProjection\",\n-    ]\n-    _import_structure[\"feature_extraction_clap\"] = [\"ClapFeatureExtractor\"]\n-\n if TYPE_CHECKING:\n-    from .configuration_clap import (\n-        ClapAudioConfig,\n-        ClapConfig,\n-        ClapTextConfig,\n-    )\n-    from .processing_clap import ClapProcessor\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .feature_extraction_clap import ClapFeatureExtractor\n-        from .modeling_clap import (\n-            ClapAudioModel,\n-            ClapAudioModelWithProjection,\n-            ClapModel,\n-            ClapPreTrainedModel,\n-            ClapTextModel,\n-            ClapTextModelWithProjection,\n-        )\n-\n-\n+    from .configuration_clap import *\n+    from .convert_clap_original_pytorch_to_hf import *\n+    from .feature_extraction_clap import *\n+    from .modeling_clap import *\n+    from .processing_clap import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "c5b7d3b7a21a96ca93707e64858edc5584ae9303",
            "filename": "src/transformers/models/clap/configuration_clap.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclap%2Fconfiguration_clap.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclap%2Fconfiguration_clap.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclap%2Fconfiguration_clap.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -389,3 +389,6 @@ def from_text_audio_configs(cls, text_config: ClapTextConfig, audio_config: Clap\n         \"\"\"\n \n         return cls(text_config=text_config.to_dict(), audio_config=audio_config.to_dict(), **kwargs)\n+\n+\n+__all__ = [\"ClapAudioConfig\", \"ClapConfig\", \"ClapTextConfig\"]"
        },
        {
            "sha": "42d3646065ece72e25be6359875ce84d91f9d5f6",
            "filename": "src/transformers/models/clap/feature_extraction_clap.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclap%2Ffeature_extraction_clap.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclap%2Ffeature_extraction_clap.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclap%2Ffeature_extraction_clap.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -360,3 +360,6 @@ def __call__(\n             input_features = input_features.convert_to_tensors(return_tensors)\n \n         return input_features\n+\n+\n+__all__ = [\"ClapFeatureExtractor\"]"
        },
        {
            "sha": "5792257e026d7dfad72d783a242482771155a441",
            "filename": "src/transformers/models/clap/modeling_clap.py",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclap%2Fmodeling_clap.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclap%2Fmodeling_clap.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclap%2Fmodeling_clap.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -2302,3 +2302,13 @@ def forward(\n             attentions=audio_outputs.attentions,\n             hidden_states=audio_outputs.hidden_states,\n         )\n+\n+\n+__all__ = [\n+    \"ClapModel\",\n+    \"ClapPreTrainedModel\",\n+    \"ClapTextModel\",\n+    \"ClapTextModelWithProjection\",\n+    \"ClapAudioModel\",\n+    \"ClapAudioModelWithProjection\",\n+]"
        },
        {
            "sha": "6df9d4aa3961d0899f1b3de85dd0fee1d23397bc",
            "filename": "src/transformers/models/clap/processing_clap.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclap%2Fprocessing_clap.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclap%2Fprocessing_clap.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclap%2Fprocessing_clap.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -115,3 +115,6 @@ def model_input_names(self):\n         tokenizer_input_names = self.tokenizer.model_input_names\n         feature_extractor_input_names = self.feature_extractor.model_input_names\n         return list(dict.fromkeys(tokenizer_input_names + feature_extractor_input_names))\n+\n+\n+__all__ = [\"ClapProcessor\"]"
        },
        {
            "sha": "3bc3eff946f60fb0f9684a7c2821fda160724ee1",
            "filename": "src/transformers/models/clip/__init__.py",
            "status": "modified",
            "additions": 15,
            "deletions": 157,
            "changes": 172,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclip%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2021 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,165 +13,23 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import (\n-    OptionalDependencyNotAvailable,\n-    _LazyModule,\n-    is_flax_available,\n-    is_tf_available,\n-    is_tokenizers_available,\n-    is_torch_available,\n-    is_vision_available,\n-)\n-\n-\n-_import_structure = {\n-    \"configuration_clip\": [\n-        \"CLIPConfig\",\n-        \"CLIPOnnxConfig\",\n-        \"CLIPTextConfig\",\n-        \"CLIPVisionConfig\",\n-    ],\n-    \"processing_clip\": [\"CLIPProcessor\"],\n-    \"tokenization_clip\": [\"CLIPTokenizer\"],\n-}\n-\n-try:\n-    if not is_tokenizers_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"tokenization_clip_fast\"] = [\"CLIPTokenizerFast\"]\n-\n-try:\n-    if not is_vision_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"feature_extraction_clip\"] = [\"CLIPFeatureExtractor\"]\n-    _import_structure[\"image_processing_clip\"] = [\"CLIPImageProcessor\"]\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_clip\"] = [\n-        \"CLIPModel\",\n-        \"CLIPPreTrainedModel\",\n-        \"CLIPTextModel\",\n-        \"CLIPTextModelWithProjection\",\n-        \"CLIPVisionModel\",\n-        \"CLIPVisionModelWithProjection\",\n-        \"CLIPForImageClassification\",\n-    ]\n-\n-try:\n-    if not is_tf_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_tf_clip\"] = [\n-        \"TFCLIPModel\",\n-        \"TFCLIPPreTrainedModel\",\n-        \"TFCLIPTextModel\",\n-        \"TFCLIPVisionModel\",\n-    ]\n-\n-try:\n-    if not is_flax_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_flax_clip\"] = [\n-        \"FlaxCLIPModel\",\n-        \"FlaxCLIPPreTrainedModel\",\n-        \"FlaxCLIPTextModel\",\n-        \"FlaxCLIPTextPreTrainedModel\",\n-        \"FlaxCLIPTextModelWithProjection\",\n-        \"FlaxCLIPVisionModel\",\n-        \"FlaxCLIPVisionPreTrainedModel\",\n-    ]\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n if TYPE_CHECKING:\n-    from .configuration_clip import (\n-        CLIPConfig,\n-        CLIPOnnxConfig,\n-        CLIPTextConfig,\n-        CLIPVisionConfig,\n-    )\n-    from .processing_clip import CLIPProcessor\n-    from .tokenization_clip import CLIPTokenizer\n-\n-    try:\n-        if not is_tokenizers_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .tokenization_clip_fast import CLIPTokenizerFast\n-\n-    try:\n-        if not is_vision_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .feature_extraction_clip import CLIPFeatureExtractor\n-        from .image_processing_clip import CLIPImageProcessor\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_clip import (\n-            CLIPForImageClassification,\n-            CLIPModel,\n-            CLIPPreTrainedModel,\n-            CLIPTextModel,\n-            CLIPTextModelWithProjection,\n-            CLIPVisionModel,\n-            CLIPVisionModelWithProjection,\n-        )\n-\n-    try:\n-        if not is_tf_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_tf_clip import (\n-            TFCLIPModel,\n-            TFCLIPPreTrainedModel,\n-            TFCLIPTextModel,\n-            TFCLIPVisionModel,\n-        )\n-\n-    try:\n-        if not is_flax_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_flax_clip import (\n-            FlaxCLIPModel,\n-            FlaxCLIPPreTrainedModel,\n-            FlaxCLIPTextModel,\n-            FlaxCLIPTextModelWithProjection,\n-            FlaxCLIPTextPreTrainedModel,\n-            FlaxCLIPVisionModel,\n-            FlaxCLIPVisionPreTrainedModel,\n-        )\n-\n-\n+    from .configuration_clip import *\n+    from .convert_clip_original_pytorch_to_hf import *\n+    from .feature_extraction_clip import *\n+    from .image_processing_clip import *\n+    from .modeling_clip import *\n+    from .modeling_flax_clip import *\n+    from .modeling_tf_clip import *\n+    from .processing_clip import *\n+    from .tokenization_clip import *\n+    from .tokenization_clip_fast import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "3f5cb47cdd121c97418ed52af9c10fb5afed0d7b",
            "filename": "src/transformers/models/clip/configuration_clip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Fconfiguration_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Fconfiguration_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclip%2Fconfiguration_clip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -417,3 +417,6 @@ def generate_dummy_inputs(\n     @property\n     def default_onnx_opset(self) -> int:\n         return 14\n+\n+\n+__all__ = [\"CLIPConfig\", \"CLIPOnnxConfig\", \"CLIPTextConfig\", \"CLIPVisionConfig\"]"
        },
        {
            "sha": "1984d8838757401e1388cb0f844a489852c773da",
            "filename": "src/transformers/models/clip/feature_extraction_clip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Ffeature_extraction_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Ffeature_extraction_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclip%2Ffeature_extraction_clip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -31,3 +31,6 @@ def __init__(self, *args, **kwargs) -> None:\n             FutureWarning,\n         )\n         super().__init__(*args, **kwargs)\n+\n+\n+__all__ = [\"CLIPFeatureExtractor\"]"
        },
        {
            "sha": "a5d12bd7ba29872d0dbdc2b92f74a9f27ee4cdc0",
            "filename": "src/transformers/models/clip/image_processing_clip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Fimage_processing_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Fimage_processing_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclip%2Fimage_processing_clip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -343,3 +343,6 @@ def preprocess(\n \n         data = {\"pixel_values\": images}\n         return BatchFeature(data=data, tensor_type=return_tensors)\n+\n+\n+__all__ = [\"CLIPImageProcessor\"]"
        },
        {
            "sha": "4751bb91aace29006230548d68e49f3c0a9f5e7a",
            "filename": "src/transformers/models/clip/modeling_clip.py",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Fmodeling_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Fmodeling_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclip%2Fmodeling_clip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1677,3 +1677,14 @@ def forward(\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n         )\n+\n+\n+__all__ = [\n+    \"CLIPModel\",\n+    \"CLIPPreTrainedModel\",\n+    \"CLIPTextModel\",\n+    \"CLIPTextModelWithProjection\",\n+    \"CLIPVisionModel\",\n+    \"CLIPVisionModelWithProjection\",\n+    \"CLIPForImageClassification\",\n+]"
        },
        {
            "sha": "c674d35e3daf4131ddd04eb3bb7e12c0d3ed069a",
            "filename": "src/transformers/models/clip/modeling_flax_clip.py",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Fmodeling_flax_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Fmodeling_flax_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclip%2Fmodeling_flax_clip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1293,3 +1293,14 @@ class FlaxCLIPModel(FlaxCLIPPreTrainedModel):\n \n overwrite_call_docstring(FlaxCLIPModel, CLIP_INPUTS_DOCSTRING + FLAX_CLIP_MODEL_DOCSTRING)\n append_replace_return_docstrings(FlaxCLIPModel, output_type=FlaxCLIPOutput, config_class=CLIPConfig)\n+\n+\n+__all__ = [\n+    \"FlaxCLIPModel\",\n+    \"FlaxCLIPPreTrainedModel\",\n+    \"FlaxCLIPTextModel\",\n+    \"FlaxCLIPTextPreTrainedModel\",\n+    \"FlaxCLIPTextModelWithProjection\",\n+    \"FlaxCLIPVisionModel\",\n+    \"FlaxCLIPVisionPreTrainedModel\",\n+]"
        },
        {
            "sha": "aedea502e88645c36bcb0732941981fcfd3a8bb5",
            "filename": "src/transformers/models/clip/modeling_tf_clip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Fmodeling_tf_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Fmodeling_tf_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclip%2Fmodeling_tf_clip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1455,3 +1455,6 @@ def build(self, input_shape=None):\n         if getattr(self, \"clip\", None) is not None:\n             with tf.name_scope(self.clip.name):\n                 self.clip.build(None)\n+\n+\n+__all__ = [\"TFCLIPModel\", \"TFCLIPPreTrainedModel\", \"TFCLIPTextModel\", \"TFCLIPVisionModel\"]"
        },
        {
            "sha": "e69e65dec68d9b88243f5e2b966de241f4924abb",
            "filename": "src/transformers/models/clip/processing_clip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Fprocessing_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Fprocessing_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclip%2Fprocessing_clip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -151,3 +151,6 @@ def feature_extractor(self):\n             FutureWarning,\n         )\n         return self.image_processor\n+\n+\n+__all__ = [\"CLIPProcessor\"]"
        },
        {
            "sha": "41a73db8c1ecb23737f6fea23eb71b789936c177",
            "filename": "src/transformers/models/clip/tokenization_clip.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Ftokenization_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Ftokenization_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclip%2Ftokenization_clip.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -514,3 +514,6 @@ def save_vocabulary(self, save_directory: str, filename_prefix: Optional[str] =\n                 index += 1\n \n         return vocab_file, merge_file\n+\n+\n+__all__ = [\"CLIPTokenizer\"]"
        },
        {
            "sha": "89e7c8360310ee950c6686d9193f6c2c217ac573",
            "filename": "src/transformers/models/clip/tokenization_clip_fast.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Ftokenization_clip_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclip%2Ftokenization_clip_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclip%2Ftokenization_clip_fast.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -159,3 +159,6 @@ def create_token_type_ids_from_sequences(\n     def save_vocabulary(self, save_directory: str, filename_prefix: Optional[str] = None) -> Tuple[str]:\n         files = self._tokenizer.model.save(save_directory, name=filename_prefix)\n         return tuple(files)\n+\n+\n+__all__ = [\"CLIPTokenizerFast\"]"
        },
        {
            "sha": "77b338e8fea31c65613d97da9c98782b82079043",
            "filename": "src/transformers/models/clipseg/__init__.py",
            "status": "modified",
            "additions": 9,
            "deletions": 47,
            "changes": 56,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclipseg%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclipseg%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclipseg%2F__init__.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1,4 +1,4 @@\n-# Copyright 2022 The HuggingFace Team. All rights reserved.\n+# Copyright 2024 The HuggingFace Team. All rights reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n@@ -13,55 +13,17 @@\n # limitations under the License.\n from typing import TYPE_CHECKING\n \n-from ...utils import OptionalDependencyNotAvailable, _LazyModule, is_torch_available\n+from ...utils import _LazyModule\n+from ...utils.import_utils import define_import_structure\n \n \n-_import_structure = {\n-    \"configuration_clipseg\": [\n-        \"CLIPSegConfig\",\n-        \"CLIPSegTextConfig\",\n-        \"CLIPSegVisionConfig\",\n-    ],\n-    \"processing_clipseg\": [\"CLIPSegProcessor\"],\n-}\n-\n-try:\n-    if not is_torch_available():\n-        raise OptionalDependencyNotAvailable()\n-except OptionalDependencyNotAvailable:\n-    pass\n-else:\n-    _import_structure[\"modeling_clipseg\"] = [\n-        \"CLIPSegModel\",\n-        \"CLIPSegPreTrainedModel\",\n-        \"CLIPSegTextModel\",\n-        \"CLIPSegVisionModel\",\n-        \"CLIPSegForImageSegmentation\",\n-    ]\n-\n if TYPE_CHECKING:\n-    from .configuration_clipseg import (\n-        CLIPSegConfig,\n-        CLIPSegTextConfig,\n-        CLIPSegVisionConfig,\n-    )\n-    from .processing_clipseg import CLIPSegProcessor\n-\n-    try:\n-        if not is_torch_available():\n-            raise OptionalDependencyNotAvailable()\n-    except OptionalDependencyNotAvailable:\n-        pass\n-    else:\n-        from .modeling_clipseg import (\n-            CLIPSegForImageSegmentation,\n-            CLIPSegModel,\n-            CLIPSegPreTrainedModel,\n-            CLIPSegTextModel,\n-            CLIPSegVisionModel,\n-        )\n-\n+    from .configuration_clipseg import *\n+    from .convert_clipseg_original_pytorch_to_hf import *\n+    from .modeling_clipseg import *\n+    from .processing_clipseg import *\n else:\n     import sys\n \n-    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n+    _file = globals()[\"__file__\"]\n+    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)"
        },
        {
            "sha": "7be9bd4d55eb0ef02a2933dbb06daeb031c477b6",
            "filename": "src/transformers/models/clipseg/configuration_clipseg.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclipseg%2Fconfiguration_clipseg.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclipseg%2Fconfiguration_clipseg.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclipseg%2Fconfiguration_clipseg.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -391,3 +391,6 @@ def from_text_vision_configs(cls, text_config: CLIPSegTextConfig, vision_config:\n         \"\"\"\n \n         return cls(text_config=text_config.to_dict(), vision_config=vision_config.to_dict(), **kwargs)\n+\n+\n+__all__ = [\"CLIPSegConfig\", \"CLIPSegTextConfig\", \"CLIPSegVisionConfig\"]"
        },
        {
            "sha": "f3b963070dfb29a52c19d278d6e65f36e4f4f85d",
            "filename": "src/transformers/models/clipseg/modeling_clipseg.py",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclipseg%2Fmodeling_clipseg.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclipseg%2Fmodeling_clipseg.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclipseg%2Fmodeling_clipseg.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -1504,3 +1504,12 @@ def forward(\n             vision_model_output=vision_outputs,\n             decoder_output=decoder_outputs,\n         )\n+\n+\n+__all__ = [\n+    \"CLIPSegModel\",\n+    \"CLIPSegPreTrainedModel\",\n+    \"CLIPSegTextModel\",\n+    \"CLIPSegVisionModel\",\n+    \"CLIPSegForImageSegmentation\",\n+]"
        },
        {
            "sha": "bd817ae786550d17a0da38d6dbc6bbc19d37fbcf",
            "filename": "src/transformers/models/clipseg/processing_clipseg.py",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclipseg%2Fprocessing_clipseg.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d303efa5f46c23cd5e76ee99e717144d05e8783/src%2Ftransformers%2Fmodels%2Fclipseg%2Fprocessing_clipseg.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclipseg%2Fprocessing_clipseg.py?ref=7d303efa5f46c23cd5e76ee99e717144d05e8783",
            "patch": "@@ -159,3 +159,6 @@ def feature_extractor(self):\n             FutureWarning,\n         )\n         return self.image_processor\n+\n+\n+__all__ = [\"CLIPSegProcessor\"]"
        }
    ],
    "stats": {
        "total": 1980,
        "additions": 573,
        "deletions": 1407
    }
}