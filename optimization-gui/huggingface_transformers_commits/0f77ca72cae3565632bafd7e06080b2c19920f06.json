{
    "author": "pavelgein",
    "message": "[FIX] Save speed metrics to logs (#38136)\n\nPreviously, we calculated speed metrics and did not do anything with the result.",
    "sha": "0f77ca72cae3565632bafd7e06080b2c19920f06",
    "files": [
        {
            "sha": "586a5335c0b7901cda1faf3a6cb0d996ea560960",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/0f77ca72cae3565632bafd7e06080b2c19920f06/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0f77ca72cae3565632bafd7e06080b2c19920f06/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=0f77ca72cae3565632bafd7e06080b2c19920f06",
            "patch": "@@ -3653,7 +3653,7 @@ def log(self, logs: dict[str, float], start_time: Optional[float] = None) -> Non\n         if self.args.include_num_input_tokens_seen:\n             logs[\"num_input_tokens_seen\"] = self.state.num_input_tokens_seen\n             if start_time is not None:\n-                speed_metrics(\"train\", start_time, num_tokens=self.state.num_input_tokens_seen)\n+                logs.update(speed_metrics(\"train\", start_time, num_tokens=self.state.num_input_tokens_seen))\n \n         output = {**logs, **{\"step\": self.state.global_step}}\n         self.state.log_history.append(output)"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}