{
    "author": "RyanMullins",
    "message": "Adding links to ShieldGemma 2 technical report (#37247)",
    "sha": "3f6af9673203e14bdae39f42dbb7dc9a8407801a",
    "files": [
        {
            "sha": "ed25f57eb7254bb958745f24fb3962f9db0cf70e",
            "filename": "docs/source/en/model_doc/shieldgemma2.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/3f6af9673203e14bdae39f42dbb7dc9a8407801a/docs%2Fsource%2Fen%2Fmodel_doc%2Fshieldgemma2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/3f6af9673203e14bdae39f42dbb7dc9a8407801a/docs%2Fsource%2Fen%2Fmodel_doc%2Fshieldgemma2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fshieldgemma2.md?ref=3f6af9673203e14bdae39f42dbb7dc9a8407801a",
            "patch": "@@ -19,7 +19,7 @@ rendered properly in your Markdown viewer.\n \n ## Overview\n \n-The ShieldGemma 2 model was proposed in a forthcoming technical report by Google. ShieldGemma 2 is built on [Gemma 3](https://ai.google.dev/gemma/docs/core/model_card_3), is a 4 billion (4B) parameter model that checks the safety of both synthetic and natural images against key categories to help you build robust datasets and models. With this addition to the Gemma family of models, researchers and developers can now easily minimize the risk of harmful content in their models across key areas of harm as defined below:\n+The ShieldGemma 2 model was proposed in a [technical report](https://arxiv.org/abs/2504.01081) by Google. ShieldGemma 2, built on [Gemma 3](https://ai.google.dev/gemma/docs/core/model_card_3), is a 4 billion (4B) parameter model that checks the safety of both synthetic and natural images against key categories to help you build robust datasets and models. With this addition to the Gemma family of models, researchers and developers can now easily minimize the risk of harmful content in their models across key areas of harm as defined below:\n \n -   No Sexually Explicit content: The image shall not contain content that depicts explicit or graphic sexual acts (e.g., pornography, erotic nudity, depictions of rape or sexual assault).\n -   No Dangerous Content: The image shall not contain content that facilitates or encourages activities that could cause real-world harm (e.g., building firearms and explosive devices, promotion of terrorism, instructions for suicide)."
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}