{
    "author": "fabxoe",
    "message": "ğŸŒ [i18n-KO] Translated `model_doc/mamba2.md` to Korean (#33629)\n\n* docs: ko: model_doc/mamba2.md\r\n\r\n* fix: resolve suggestions\r\n\r\nCo-authored-by: HyeokJun SHIN <96534680+jun048098@users.noreply.github.com>\r\nCo-authored-by: Chaewon Song <chaewon1019@ewhain.net>\r\nCo-authored-by: Ahnjj_DEV <ahnjj.dev@gmail.com>\r\n\r\n* fix: resolve suggestion\r\n\r\n* fix: resolve suggestions\r\n\r\nCo-authored-by: Ahnjj_DEV <ahnjj.dev@gmail.com>\r\n\r\n* fix: resolve suggestions\r\n\r\n---------\r\n\r\nCo-authored-by: HyeokJun SHIN <96534680+jun048098@users.noreply.github.com>\r\nCo-authored-by: Chaewon Song <chaewon1019@ewhain.net>\r\nCo-authored-by: Ahnjj_DEV <ahnjj.dev@gmail.com>",
    "sha": "48b54205d0a15ba79e5965a34caf5d13ac22697e",
    "files": [
        {
            "sha": "53776781a73657567de0c93a135a45ba7d5d1c5d",
            "filename": "docs/source/ko/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/48b54205d0a15ba79e5965a34caf5d13ac22697e/docs%2Fsource%2Fko%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/48b54205d0a15ba79e5965a34caf5d13ac22697e/docs%2Fsource%2Fko%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2F_toctree.yml?ref=48b54205d0a15ba79e5965a34caf5d13ac22697e",
            "patch": "@@ -442,6 +442,8 @@\n         title: (ë²ˆì—­ì¤‘) M2M100\n       - local: model_doc/mamba\n         title: Mamba\n+      - local: model_doc/mamba2\n+        title: Mamba2\n       - local: in_translation\n         title: (ë²ˆì—­ì¤‘) MarianMT\n       - local: in_translation"
        },
        {
            "sha": "b023914bc1276ab99a3aafb693f97b068d055e82",
            "filename": "docs/source/ko/model_doc/mamba2.md",
            "status": "added",
            "additions": 111,
            "deletions": 0,
            "changes": 111,
            "blob_url": "https://github.com/huggingface/transformers/blob/48b54205d0a15ba79e5965a34caf5d13ac22697e/docs%2Fsource%2Fko%2Fmodel_doc%2Fmamba2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/48b54205d0a15ba79e5965a34caf5d13ac22697e/docs%2Fsource%2Fko%2Fmodel_doc%2Fmamba2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fmamba2.md?ref=48b54205d0a15ba79e5965a34caf5d13ac22697e",
            "patch": "@@ -0,0 +1,111 @@\n+<!--Copyright 2024 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n+\n+âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+\n+# ë§˜ë°”2[[mamba-2]]\n+\n+## ê°œìš”[[overview]]\n+\n+ë§˜ë°”2 ëª¨ë¸ì€ Tri Dao, Albert Guê°€ ì œì•ˆí•œ [íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” SSMì´ë‹¤: êµ¬ì¡°í™”ëœ ìƒíƒœ ê³µê°„ ì´ì¤‘ì„±ì„ í†µí•œ ì¼ë°˜í™”ëœ ëª¨ë¸ê³¼ íš¨ìœ¨ì ì¸ ì•Œê³ ë¦¬ì¦˜](https://arxiv.org/abs/2405.21060)ë¼ëŠ” ë…¼ë¬¸ì—ì„œ ì†Œê°œë˜ì—ˆìŠµë‹ˆë‹¤. ë§˜ë°”2ëŠ” ë§˜ë°”1ê³¼ ìœ ì‚¬í•œ ìƒíƒœ ê³µê°„ ëª¨ë¸ë¡œ, ë‹¨ìˆœí™”ëœ ì•„í‚¤í…ì²˜ì—ì„œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.\n+\n+í•´ë‹¹ ë…¼ë¬¸ì˜ ì´ˆë¡ì…ë‹ˆë‹¤:\n+\n+*íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ì–¸ì–´ ëª¨ë¸ë§ì—ì„œ ë”¥ëŸ¬ë‹ ì„±ê³µì˜ ì£¼ìš” ì•„í‚¤í…ì²˜ì˜€ì§€ë§Œ, ë§˜ë°”ì™€ ê°™ì€ ìƒíƒœ ê³µê°„ ëª¨ë¸(SSM)ì´ ìµœê·¼ ì†Œê·œëª¨ í˜¹ì€ ì¤‘ê°„ ê·œëª¨ì—ì„œ íŠ¸ëœìŠ¤í¬ë¨¸ì™€ ëŒ€ë“±í•˜ê±°ë‚˜ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ëª¨ë¸ ê³„ì—´ë“¤ì´ ì‹¤ì œë¡œ ë§¤ìš° ë°€ì ‘í•˜ê²Œ ì—°ê´€ë˜ì–´ ìˆìŒì„ íŒŒì•…í–ˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  êµ¬ì¡°í™”ëœ ì¤€ë¶„ë¦¬(semiseparable) í–‰ë ¬ ì¤‘ ì—°êµ¬ê°€ ì˜ ì´ë£¨ì–´ì§„ í´ë˜ìŠ¤ì˜ ë‹¤ì–‘í•œ ë¶„í•´ë¥¼ í†µí•´ ì—°ê²°ëœ SSMê³¼ ì–´í…ì…˜ ë³€í˜• ì‚¬ì´ì˜ í’ë¶€í•œ ì´ë¡ ì  ì—°ê²° í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ìƒíƒœ ê³µê°„ ì´ì¤‘ì„±(SSD) í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ë§˜ë°”1ì˜ ì„ íƒì  SSMì„ ê°œì„ í•œ ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í•  ìˆ˜ ìˆì—ˆê³ , íŠ¸ëœìŠ¤í¬ë¨¸ì™€ ê²½ìŸë ¥ì„ ìœ ì§€í•˜ë©´ì„œë„ ì†ë„ëŠ” 2~8ë°° ë” ë¹ ë¥¸ ì„±ëŠ¥ì„ ëƒ…ë‹ˆë‹¤.*\n+\n+íŒ:\n+\n+ì´ ë²„ì „ì€ ë§˜ë°”2 êµ¬í˜„ì„ ì§€ì›í•´ì•¼ í•˜ë©°, íŠ¹íˆ Mistral AIì˜ [Mamba-2 codestral](https://huggingface.co/mistralai/Mamba-Codestral-7B-v0.1)ì„ ì§€ì›í•©ë‹ˆë‹¤. íŠ¹íˆ, mamba 2 codestralì€ 8ê°œì˜ `groups`ë¡œ ì¶œì‹œë˜ì—ˆëŠ”ë°, ì´ëŠ” ì–´í…ì…˜ ê¸°ë°˜ ëª¨ë¸ì˜ KV í—¤ë“œ ìˆ˜ì™€ ìœ ì‚¬í•˜ë‹¤ê³  íŒë‹¨ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n+\n+ì´ ëª¨ë¸ì€ `torch_forward`ì™€ `cuda_kernels_forward`ë¼ëŠ” ë‘ ê°€ì§€ ë‹¤ë¥¸ ì „ë°© íŒ¨ìŠ¤ë¥¼ ê°€ì§‘ë‹ˆë‹¤. `cuda_kernels_forward`ëŠ” í™˜ê²½ì—ì„œ cuda ì»¤ë„ì„ ì°¾ìœ¼ë©´ ì´ë¥¼ ì‚¬ìš©í•˜ë©°, prefillì—ì„œëŠ” ë” ëŠë¦½ë‹ˆë‹¤. ì¦‰, ë†’ì€ CPU ì˜¤ë²„í—¤ë“œë¡œ ì¸í•´ \"ì›œì—… ì‹¤í–‰\"ì´ í•„ìš”í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ê´€ë ¨ ë‚´ìš©ì€ [ì´ê³³](https://github.com/state-spaces/mamba/issues/389#issuecomment-2171755306)ê³¼ [ì´ê³³](https://github.com/state-spaces/mamba/issues/355#issuecomment-2147597457)ì„ ì°¸ê³ í•˜ì„¸ìš”. \n+\n+ì»´íŒŒì¼ ì—†ì´ëŠ” `torch_forward` êµ¬í˜„ì´ 3~4ë°° ë¹ ë¦…ë‹ˆë‹¤. ë˜í•œ, ì´ ëª¨ë¸ì—ëŠ” ìœ„ì¹˜ ì„ë² ë”©ì´ ì—†ì§€ë§Œ `attention_mask`ì™€ ë°°ì¹˜ ìƒì„±ì˜ ê²½ìš° ë‘ ê³³ì—ì„œ ì€ë‹‰ ìƒíƒœ(hidden state)ë¥¼ ë§ˆìŠ¤í‚¹í•˜ëŠ” íŠ¹ì • ë¡œì§ì´ ìˆìŠµë‹ˆë‹¤. ê´€ë ¨ ë‚´ìš©ì€ [ì´ê³³](https://github.com/state-spaces/mamba/issues/66#issuecomment-1863563829)ì„ ì°¸ê³ í•˜ì„¸ìš”. \n+\n+ì´ë¡œì¸í•´ ë§˜ë°”2 ì»¤ë„ì˜ ì¬êµ¬í˜„ê³¼ í•¨ê»˜ ë°°ì¹˜ ìƒì„± ë° ìºì‹œëœ ìƒì„±ì—ì„œ ì•½ê°„ì˜ ì°¨ì´ê°€ ì˜ˆìƒë©ë‹ˆë‹¤. ë˜í•œ cuda ì»¤ë„ ë˜ëŠ” torch forwardê°€ ì œê³µí•˜ëŠ” ê²°ê³¼ê°€ ì•½ê°„ ë‹¤ë¥¼ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. SSM ì•Œê³ ë¦¬ì¦˜ì€ í…ì„œ ìˆ˜ì¶•ì— í¬ê²Œ ì˜ì¡´í•˜ëŠ”ë°, ì´ëŠ” matmulê³¼ ë™ë“±í•˜ì§€ë§Œ ì—°ì‚° ìˆœì„œê°€ ì•½ê°„ ë‹¤ë¥´ë©°, ì´ë¡œ ì¸í•´ ë” ì‘ì€ ì •ë°€ë„ì—ì„œ ì°¨ì´ê°€ ë” ì»¤ì§‘ë‹ˆë‹¤.\n+\n+ë˜ ë‹¤ë¥¸ ì°¸ê³ ì‚¬í•­ìœ¼ë¡œ, íŒ¨ë”© í† í°ì— í•´ë‹¹í•˜ëŠ” ì€ë‹‰ ìƒíƒœ(hidden state)ì˜ ì¢…ë£ŒëŠ” ë‘ ê³³ì—ì„œ ì´ë£¨ì–´ì§€ë©° ì£¼ë¡œ ì™¼ìª½ íŒ¨ë”©ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜¤ë¥¸ìª½ íŒ¨ë”©ì€ ë…¸ì´ì¦ˆë¥¼ ì „íŒŒí•˜ë¯€ë¡œ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¥¼ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. `tokenizer.padding_side = \"left\"`ë¥¼ ì‚¬ìš©í•˜ë©´ ì˜¬ë°”ë¥¸ íŒ¨ë”© ë°©í–¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+ì´ ëª¨ë¸ì€ [Molbap](https://huggingface.co/Molbap)ì´ ê¸°ì—¬í–ˆìœ¼ë©°, [Anton Vlasjuk](https://github.com/vasqu)ì˜ í° ë„ì›€ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.\n+ì›ë³¸ ì½”ë“œëŠ” [ì´ê³³](https://github.com/state-spaces/mamba)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+\n+# ì‚¬ìš©\n+\n+### ê°„ë‹¨í•œ ìƒì„± ì˜ˆ: \n+```python \n+from transformers import Mamba2Config, Mamba2ForCausalLM, AutoTokenizer\n+import torch\n+model_id = 'mistralai/Mamba-Codestral-7B-v0.1'\n+tokenizer = AutoTokenizer.from_pretrained(model_id, revision='refs/pr/9', from_slow=True, legacy=False)\n+model = Mamba2ForCausalLM.from_pretrained(model_id, revision='refs/pr/9')\n+input_ids = tokenizer(\"Hey how are you doing?\", return_tensors= \"pt\")[\"input_ids\"]\n+\n+out = model.generate(input_ids, max_new_tokens=10)\n+print(tokenizer.batch_decode(out))\n+```\n+\n+ì´ê³³ì€ ë¯¸ì„¸ì¡°ì •ì„ ìœ„í•œ ì´ˆì•ˆ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤: \n+```python \n+from trl import SFTTrainer\n+from peft import LoraConfig\n+from transformers import AutoTokenizer, Mamba2ForCausalLM, TrainingArguments\n+model_id = 'mistralai/Mamba-Codestral-7B-v0.1'\n+tokenizer = AutoTokenizer.from_pretrained(model_id, revision='refs/pr/9', from_slow=True, legacy=False)\n+tokenizer.pad_token = tokenizer.eos_token\n+tokenizer.padding_side = \"left\" #ì™¼ìª½ íŒ¨ë”©ìœ¼ë¡œ ì„¤ì •\n+\n+model = Mamba2ForCausalLM.from_pretrained(model_id, revision='refs/pr/9')\n+dataset = load_dataset(\"Abirate/english_quotes\", split=\"train\")\n+# CUDA ì»¤ë„ì—†ì´ëŠ”, ë°°ì¹˜í¬ê¸° 2ê°€ 80GB ì¥ì¹˜ë¥¼ í•˜ë‚˜ ì°¨ì§€í•©ë‹ˆë‹¤.\n+# í•˜ì§€ë§Œ ì •í™•ë„ëŠ” ê°ì†Œí•©ë‹ˆë‹¤.\n+# ì‹¤í—˜ê³¼ ì‹œë„ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤!\n+training_args = TrainingArguments(\n+    output_dir=\"./results\",\n+    num_train_epochs=3,\n+    per_device_train_batch_size=2,\n+    logging_dir='./logs',\n+    logging_steps=10,\n+    learning_rate=2e-3\n+)\n+lora_config =  LoraConfig(\n+        r=8,\n+        target_modules=[\"embeddings\", \"in_proj\", \"out_proj\"],\n+        task_type=\"CAUSAL_LM\",\n+        bias=\"none\"\n+)\n+trainer = SFTTrainer(\n+    model=model,\n+    tokenizer=tokenizer,\n+    args=training_args,\n+    peft_config=lora_config,\n+    train_dataset=dataset,\n+    dataset_text_field=\"quote\",\n+)\n+trainer.train()\n+```\n+\n+\n+## Mamba2Config\n+\n+[[autodoc]] Mamba2Config\n+\n+## Mamba2Model\n+\n+[[autodoc]] Mamba2Model\n+    - forward\n+\n+## Mamba2LMHeadModel\n+\n+[[autodoc]] Mamba2ForCausalLM\n+    - forward"
        }
    ],
    "stats": {
        "total": 113,
        "additions": 113,
        "deletions": 0
    }
}