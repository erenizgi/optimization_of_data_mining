{
    "author": "qubvel",
    "message": "Fix `Optional` typing (#38018)\n\n* Fix\n\n* trigger",
    "sha": "9f8fffed3cbe6c322d6d15735d06d4a2c27ae16f",
    "files": [
        {
            "sha": "e9471c62c9d8cb6a4c21a4603bf139bbdf5e71c5",
            "filename": "src/transformers/models/beit/image_processing_beit_fast.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9f8fffed3cbe6c322d6d15735d06d4a2c27ae16f/src%2Ftransformers%2Fmodels%2Fbeit%2Fimage_processing_beit_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9f8fffed3cbe6c322d6d15735d06d4a2c27ae16f/src%2Ftransformers%2Fmodels%2Fbeit%2Fimage_processing_beit_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbeit%2Fimage_processing_beit_fast.py?ref=9f8fffed3cbe6c322d6d15735d06d4a2c27ae16f",
            "patch": "@@ -237,7 +237,7 @@ def preprocess(\n \n         return BatchFeature(data=data)\n \n-    def post_process_semantic_segmentation(self, outputs, target_sizes: List[Tuple] = None):\n+    def post_process_semantic_segmentation(self, outputs, target_sizes: Optional[List[Tuple]] = None):\n         \"\"\"\n         Converts the output of [`BeitForSemanticSegmentation`] into semantic segmentation maps. Only supports PyTorch.\n "
        },
        {
            "sha": "2a4dc3ef62df8658e11a008b38cbe3eebae384aa",
            "filename": "src/transformers/models/paligemma/modeling_paligemma.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/9f8fffed3cbe6c322d6d15735d06d4a2c27ae16f/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fmodeling_paligemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9f8fffed3cbe6c322d6d15735d06d4a2c27ae16f/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fmodeling_paligemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fmodeling_paligemma.py?ref=9f8fffed3cbe6c322d6d15735d06d4a2c27ae16f",
            "patch": "@@ -275,7 +275,7 @@ def _update_causal_mask(\n         past_key_values=None,\n         cache_position=None,\n         input_tensor=None,\n-        is_training: bool = None,\n+        is_training: Optional[bool] = None,\n     ):\n         if self.config.text_config._attn_implementation == \"flash_attention_2\":\n             if attention_mask is not None and 0.0 in attention_mask:"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}