{
    "author": "MekkCyber",
    "message": "Add tearDown method to Quark to solve OOM issues (#38234)\n\nfix",
    "sha": "9a962dd9ed3ee9b8be3f36da9bf8dd05f076d123",
    "files": [
        {
            "sha": "d77a8c686317666e4cad41af2c20ae9d710d37fa",
            "filename": "tests/quantization/quark_integration/test_quark.py",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/9a962dd9ed3ee9b8be3f36da9bf8dd05f076d123/tests%2Fquantization%2Fquark_integration%2Ftest_quark.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9a962dd9ed3ee9b8be3f36da9bf8dd05f076d123/tests%2Fquantization%2Fquark_integration%2Ftest_quark.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fquantization%2Fquark_integration%2Ftest_quark.py?ref=9a962dd9ed3ee9b8be3f36da9bf8dd05f076d123",
            "patch": "@@ -11,7 +11,7 @@\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.\n-\n+import gc\n import unittest\n \n from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, QuarkConfig\n@@ -77,6 +77,14 @@ def setUpClass(cls):\n             device_map=cls.device_map,\n         )\n \n+    def tearDown(self):\n+        r\"\"\"\n+        TearDown function needs to be called at the end of each test to free the GPU memory and cache, also to\n+        avoid unexpected behaviors. Please see: https://discuss.pytorch.org/t/how-can-we-release-gpu-memory-cache/14530/27\n+        \"\"\"\n+        gc.collect()\n+        torch.cuda.empty_cache()\n+\n     def test_memory_footprint(self):\n         mem_quantized = self.quantized_model.get_memory_footprint()\n "
        }
    ],
    "stats": {
        "total": 10,
        "additions": 9,
        "deletions": 1
    }
}