{
    "author": "gante",
    "message": "MPS: `isin_mps_friendly` can support 0D tensors (#34538)\n\n* apply fix\r\n\r\n* tested\r\n\r\n* make fixup",
    "sha": "34927b0f73c1a9d73746a74b543b8207f4b632fa",
    "files": [
        {
            "sha": "a808f2cb63e861fbdbc89fda6fa058cb9b813c35",
            "filename": "src/transformers/pytorch_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/34927b0f73c1a9d73746a74b543b8207f4b632fa/src%2Ftransformers%2Fpytorch_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/34927b0f73c1a9d73746a74b543b8207f4b632fa/src%2Ftransformers%2Fpytorch_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpytorch_utils.py?ref=34927b0f73c1a9d73746a74b543b8207f4b632fa",
            "patch": "@@ -314,14 +314,17 @@ def isin_mps_friendly(elements: torch.Tensor, test_elements: torch.Tensor | int)\n \n     Args:\n         elements (`torch.Tensor`): Input elements\n-        test_elements (`torch.Tensor`): The elements to check against.\n+        test_elements (`torch.Tensor` or `int`): The elements to check against.\n \n     Returns:\n         `torch.Tensor`: A boolean tensor of the same shape as `elements` that is True for `elements` in `test_elements`\n         and False otherwise\n     \"\"\"\n \n     if elements.device.type == \"mps\" and not is_torch_greater_or_equal_than_2_4:\n+        test_elements = torch.tensor(test_elements)\n+        if test_elements.ndim == 0:\n+            test_elements = test_elements.unsqueeze(0)\n         return elements.tile(test_elements.shape[0], 1).eq(test_elements.unsqueeze(1)).sum(dim=0).bool().squeeze()\n     else:\n         # Note: don't use named arguments in `torch.isin`, see https://github.com/pytorch/pytorch/issues/126045"
        },
        {
            "sha": "5fd6251224c3ed57e13b71c860696b36e2887521",
            "filename": "tests/utils/test_modeling_utils.py",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/34927b0f73c1a9d73746a74b543b8207f4b632fa/tests%2Futils%2Ftest_modeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/34927b0f73c1a9d73746a74b543b8207f4b632fa/tests%2Futils%2Ftest_modeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_modeling_utils.py?ref=34927b0f73c1a9d73746a74b543b8207f4b632fa",
            "patch": "@@ -1711,7 +1711,12 @@ def test_isin_mps_friendly(self):\n                 torch.isin(random_ids, random_test_integer), isin_mps_friendly(random_ids, random_test_integer)\n             )\n         )\n-        # We can match against an tensor of integers\n+        # We can match against an 0D tensor\n+        random_test_tensor = torch.randint(0, 100, (1,)).squeeze()\n+        self.assertTrue(\n+            torch.equal(torch.isin(random_ids, random_test_tensor), isin_mps_friendly(random_ids, random_test_tensor))\n+        )\n+        # We can match against an 1D tensor (with many items)\n         random_test_tensor = torch.randint(0, 100, (10,))\n         self.assertTrue(\n             torch.equal(torch.isin(random_ids, random_test_tensor), isin_mps_friendly(random_ids, random_test_tensor))"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 10,
        "deletions": 2
    }
}