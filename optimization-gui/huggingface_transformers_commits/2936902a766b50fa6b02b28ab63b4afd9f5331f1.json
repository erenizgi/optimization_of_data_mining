{
    "author": "kashif",
    "message": "[Paged-Attention] Handle continuous batching for repetition penalty (#39457)\n\n* Handle continuous batching for repetition penalty\n\n* fix last scores and with token mask creation\n\n* add test\n\n* Update src/transformers/generation/continuous_batching.py\n\nCo-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>\n\n* Update src/transformers/generation/logits_process.py\n\nCo-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>\n\n* fix formatting\n\n* remove unneeded cast\n\n---------\n\nCo-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>",
    "sha": "2936902a766b50fa6b02b28ab63b4afd9f5331f1",
    "files": [
        {
            "sha": "9fc57b11d7d821a52a520285cd020ed752806ee7",
            "filename": "src/transformers/generation/continuous_batching.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/2936902a766b50fa6b02b28ab63b4afd9f5331f1/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2936902a766b50fa6b02b28ab63b4afd9f5331f1/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching.py?ref=2936902a766b50fa6b02b28ab63b4afd9f5331f1",
            "patch": "@@ -1272,6 +1272,11 @@ def _model_forward(self, batch_data):\n \n     @traced(span_name=\"logit_processing\")\n     def _process_logit(self, batch_data, logits):\n+        # Pass continuous batching context to logits processor if it supports it. TODO we should find a way to make this a little bit cleaner!\n+        if hasattr(self.logit_processor, \"set_continuous_batching_context\"):\n+            self.logit_processor.set_continuous_batching_context(\n+                batch_data[\"logits_indices\"], batch_data[\"cumulative_seqlens_q\"]\n+            )\n         return self.logit_processor(batch_data[\"input_ids\"], logits)\n \n     @traced(span_name=\"sampling\")"
        },
        {
            "sha": "d001fe1a946634f7b5022fa441d2436869c7385a",
            "filename": "src/transformers/generation/logits_process.py",
            "status": "modified",
            "additions": 42,
            "deletions": 5,
            "changes": 47,
            "blob_url": "https://github.com/huggingface/transformers/blob/2936902a766b50fa6b02b28ab63b4afd9f5331f1/src%2Ftransformers%2Fgeneration%2Flogits_process.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2936902a766b50fa6b02b28ab63b4afd9f5331f1/src%2Ftransformers%2Fgeneration%2Flogits_process.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Flogits_process.py?ref=2936902a766b50fa6b02b28ab63b4afd9f5331f1",
            "patch": "@@ -355,17 +355,54 @@ def __init__(self, penalty: float, prompt_ignore_length: Optional[int] = None):\n \n         self.penalty = penalty\n         self.prompt_ignore_length = prompt_ignore_length\n+        self.logits_indices = None\n+        self.cumulative_seqlens_q = None\n+\n+    def set_continuous_batching_context(self, logits_indices: torch.Tensor, cumulative_seqlens_q: torch.Tensor):\n+        self.logits_indices = logits_indices\n+        self.cumulative_seqlens_q = cumulative_seqlens_q\n \n     @add_start_docstrings(LOGITS_PROCESSOR_INPUTS_DOCSTRING)\n     def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n         if self.prompt_ignore_length:\n             input_ids = input_ids[:, self.prompt_ignore_length :]\n \n-        score = torch.gather(scores, 1, input_ids)\n+        if scores.dim() == 3:\n+            if self.logits_indices is not None and self.cumulative_seqlens_q is not None:\n+                batch_size, seq_len, vocab_size = scores.shape\n+                last_positions = self.logits_indices\n+                last_scores = scores[0, last_positions, :]\n+\n+                # Prepare token mask\n+                token_mask = torch.zeros_like(last_scores, dtype=torch.bool)\n+                cu_seq_lens = self.cumulative_seqlens_q\n+                lengths = cu_seq_lens[1:] - cu_seq_lens[:-1]\n+                seq_indices = torch.repeat_interleave(torch.arange(len(lengths), device=input_ids.device), lengths)\n+                token_mask[seq_indices, input_ids] = True\n+\n+                # Apply penalty\n+                penalty_scores = torch.where(last_scores < 0, last_scores * self.penalty, last_scores / self.penalty)\n+                scores[0, last_positions, :] = torch.where(token_mask, penalty_scores, last_scores)\n+            else:\n+                batch_size, seq_len, vocab_size = scores.shape\n+                last_scores = scores[:, -1, :]\n+                token_mask = torch.zeros_like(last_scores, dtype=torch.bool)\n+                if input_ids.dim() == 1:\n+                    unique_tokens = torch.unique(input_ids)\n+                    token_mask.scatter_(1, unique_tokens.unsqueeze(0), True)\n+                else:\n+                    token_mask.scatter_(1, input_ids, True)\n+                # if last_scores < 0 then repetition penalty has to be multiplied to reduce the token probabilities\n+                penalty_scores = torch.where(last_scores < 0, last_scores * self.penalty, last_scores / self.penalty)\n+                scores[:, -1, :] = torch.where(token_mask, penalty_scores, last_scores)\n+            return scores\n+\n+        if input_ids.dim() == 1:\n+            input_ids = input_ids.unsqueeze(1)\n \n+        score = torch.gather(scores, 1, input_ids)\n         # if score < 0 then repetition penalty has to be multiplied to reduce the token probabilities\n         score = torch.where(score < 0, score * self.penalty, score / self.penalty)\n-\n         scores_processed = scores.scatter(1, input_ids, score)\n         return scores_processed\n \n@@ -963,12 +1000,12 @@ class NoRepeatNGramLogitsProcessor(LogitsProcessor):\n \n     >>> output = model.generate(**inputs)\n     >>> print(tokenizer.decode(output[0], skip_special_tokens=True))\n-    Today I’m not sure if I’m going to be able to do it.\n+    Today I'm not sure if I'm going to be able to do it.\n \n-    >>> # Now let's add ngram size using `no_repeat_ngram_size`. This stops the repetitions (\"I’m\") in the output.\n+    >>> # Now let's add ngram size using `no_repeat_ngram_size`. This stops the repetitions (\"I'm\") in the output.\n     >>> output = model.generate(**inputs, no_repeat_ngram_size=2)\n     >>> print(tokenizer.decode(output[0], skip_special_tokens=True))\n-    Today I’m not sure if I can get a better understanding of the nature of this issue\n+    Today I'm not sure if I can get a better understanding of the nature of this issue\n     ```\n     \"\"\"\n "
        },
        {
            "sha": "df68f9c621000dd13018c8b2e9f86de50f32e0c4",
            "filename": "tests/generation/test_logits_process.py",
            "status": "modified",
            "additions": 33,
            "deletions": 0,
            "changes": 33,
            "blob_url": "https://github.com/huggingface/transformers/blob/2936902a766b50fa6b02b28ab63b4afd9f5331f1/tests%2Fgeneration%2Ftest_logits_process.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2936902a766b50fa6b02b28ab63b4afd9f5331f1/tests%2Fgeneration%2Ftest_logits_process.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fgeneration%2Ftest_logits_process.py?ref=2936902a766b50fa6b02b28ab63b4afd9f5331f1",
            "patch": "@@ -286,6 +286,39 @@ def test_encoder_repetition_penalty_dist_process(self):\n         # processor should not change logits in-place\n         self.assertFalse(torch.all(scores == processed_scores))\n \n+    def test_repetition_penalty_continuous_batching(self):\n+        vocab_size = 10\n+\n+        input_ids = torch.tensor([1, 2, 3, 4, 5, 6], device=torch_device, dtype=torch.long)\n+        scores = torch.ones((1, 6, vocab_size), device=torch_device, dtype=torch.float) / vocab_size\n+\n+        scores[0, 2, 1] = -2.0\n+        scores[0, 2, 2] = 3.0\n+        scores[0, 2, 3] = 4.0\n+        scores[0, 5, 4] = -5.0\n+        scores[0, 5, 5] = 6.0\n+        scores[0, 5, 6] = 7.0\n+\n+        logits_indices = torch.tensor([2, 5], device=torch_device, dtype=torch.long)\n+        cumulative_seqlens_q = torch.tensor([0, 3, 6], device=torch_device, dtype=torch.long)\n+\n+        rep_penalty_proc = RepetitionPenaltyLogitsProcessor(penalty=2.0)\n+        rep_penalty_proc.set_continuous_batching_context(logits_indices, cumulative_seqlens_q)\n+\n+        original_scores = scores.clone()\n+        processed_scores = rep_penalty_proc(input_ids, scores)\n+\n+        self.assertAlmostEqual(processed_scores[0, 2, 1].item(), -2.0 * 2.0)\n+        self.assertAlmostEqual(processed_scores[0, 2, 2].item(), 3.0 / 2.0)\n+        self.assertAlmostEqual(processed_scores[0, 2, 3].item(), 4.0 / 2.0)\n+        self.assertAlmostEqual(processed_scores[0, 5, 4].item(), -5.0 * 2.0)\n+        self.assertAlmostEqual(processed_scores[0, 5, 5].item(), 6.0 / 2.0)\n+        self.assertAlmostEqual(processed_scores[0, 5, 6].item(), 7.0 / 2.0)\n+        self.assertAlmostEqual(processed_scores[0, 2, 0].item(), 1.0 / vocab_size)\n+        self.assertAlmostEqual(processed_scores[0, 5, 0].item(), 1.0 / vocab_size)\n+\n+        self.assertFalse(torch.all(original_scores == processed_scores))\n+\n     def test_top_k_dist_warper(self):\n         input_ids = None\n         vocab_size = 10"
        }
    ],
    "stats": {
        "total": 85,
        "additions": 80,
        "deletions": 5
    }
}