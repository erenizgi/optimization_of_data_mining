{
    "author": "ydshieh",
    "message": "Fix some GPU OOM after #37553 (#37591)\n\n* fix\n\n* trigger CI\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "f9742143538cfeb65c3a25632b83276266819c41",
    "files": [
        {
            "sha": "c9b86c128cae799247fa9798332c2435fc2909fe",
            "filename": "tests/models/llama/test_modeling_llama.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/f9742143538cfeb65c3a25632b83276266819c41/tests%2Fmodels%2Fllama%2Ftest_modeling_llama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f9742143538cfeb65c3a25632b83276266819c41/tests%2Fmodels%2Fllama%2Ftest_modeling_llama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fllama%2Ftest_modeling_llama.py?ref=f9742143538cfeb65c3a25632b83276266819c41",
            "patch": "@@ -699,6 +699,7 @@ def tearDown(self):\n         cleanup(torch_device, gc_collect=True)\n \n     def setUp(self):\n+        cleanup(torch_device, gc_collect=True)\n         model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n         self.model_dtype = torch.float32\n         self.tokenizer = LlamaTokenizer.from_pretrained(model_name)"
        }
    ],
    "stats": {
        "total": 1,
        "additions": 1,
        "deletions": 0
    }
}