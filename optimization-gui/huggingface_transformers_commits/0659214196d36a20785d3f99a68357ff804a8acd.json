{
    "author": "geetu040",
    "message": "fix: remove CHAT_TEMPLATE import in tests for deepseek-vl (#40003)\n\n* remove CHAT_TEMPLATE import in tests\n\n* update and use prepare_processor_dict",
    "sha": "0659214196d36a20785d3f99a68357ff804a8acd",
    "files": [
        {
            "sha": "e96acfd80eb4dfd36d89e83df84562eff703e035",
            "filename": "tests/models/deepseek_vl/test_processing_deepseek_vl.py",
            "status": "modified",
            "additions": 8,
            "deletions": 4,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/0659214196d36a20785d3f99a68357ff804a8acd/tests%2Fmodels%2Fdeepseek_vl%2Ftest_processing_deepseek_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0659214196d36a20785d3f99a68357ff804a8acd/tests%2Fmodels%2Fdeepseek_vl%2Ftest_processing_deepseek_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdeepseek_vl%2Ftest_processing_deepseek_vl.py?ref=0659214196d36a20785d3f99a68357ff804a8acd",
            "patch": "@@ -16,7 +16,6 @@\n import unittest\n \n from transformers import DeepseekVLProcessor, LlamaTokenizer\n-from transformers.models.deepseek_vl.convert_deepseek_vl_weights_to_hf import CHAT_TEMPLATE\n from transformers.testing_utils import get_tests_dir\n from transformers.utils import is_vision_available\n \n@@ -43,12 +42,17 @@ def setUp(self):\n                 \"image_token\": \"<image_placeholder>\",\n             },\n         )\n+        processor_kwargs = self.prepare_processor_dict()\n         processor = self.processor_class(\n             image_processor=image_processor,\n             tokenizer=tokenizer,\n-            chat_template=CHAT_TEMPLATE,\n+            **processor_kwargs,\n         )\n         processor.save_pretrained(self.tmpdirname)\n \n-    def prepare_processor_dict(self):\n-        return {\"chat_template\": CHAT_TEMPLATE, \"num_image_tokens\": 576}\n+    @staticmethod\n+    def prepare_processor_dict():\n+        return {\n+            \"chat_template\": \"{% set seps = ['\\n\\n', '<\\uff5cend\\u2581of\\u2581sentence\\uff5c>'] %}{% set i = 0 %}You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.\\n\\n{% for message in messages %}{% if message['role']|lower == 'user' %}User: {% elif message['role']|lower == 'assistant' %}Assistant:{% if not (loop.last and not add_generation_prompt and message['content'][0]['type']=='text' and message['content'][0]['text']=='') %} {% endif %}{% else %}{{ message['role'].capitalize() }}: {% endif %}{% for content in message['content'] %}{% if content['type'] == 'image' %}<image_placeholder>{% elif content['type'] == 'text' %}{% set text = content['text'] %}{% if loop.first %}{% set text = text.lstrip() %}{% endif %}{% if loop.last %}{% set text = text.rstrip() %}{% endif %}{% if not loop.first and message['content'][loop.index0-1]['type'] == 'text' %}{{ ' ' + text }}{% else %}{{ text }}{% endif %}{% endif %}{% endfor %}{% if not loop.last or add_generation_prompt %}{% if message['role']|lower == 'user' %}{{ seps[0] }}{% else %}{{ seps[1] }}{% endif %}{% endif %}{% endfor %}{% if add_generation_prompt %}Assistant:{% endif %}\",\n+            \"num_image_tokens\": 576,\n+        }  # fmt: skip"
        },
        {
            "sha": "46178e30f6710361ffd6b77909b4179eec47647b",
            "filename": "tests/models/deepseek_vl_hybrid/test_processing_deepseek_vl_hybrid.py",
            "status": "modified",
            "additions": 8,
            "deletions": 4,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/0659214196d36a20785d3f99a68357ff804a8acd/tests%2Fmodels%2Fdeepseek_vl_hybrid%2Ftest_processing_deepseek_vl_hybrid.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0659214196d36a20785d3f99a68357ff804a8acd/tests%2Fmodels%2Fdeepseek_vl_hybrid%2Ftest_processing_deepseek_vl_hybrid.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdeepseek_vl_hybrid%2Ftest_processing_deepseek_vl_hybrid.py?ref=0659214196d36a20785d3f99a68357ff804a8acd",
            "patch": "@@ -16,7 +16,6 @@\n import unittest\n \n from transformers import DeepseekVLHybridProcessor, LlamaTokenizer\n-from transformers.models.deepseek_vl.convert_deepseek_vl_weights_to_hf import CHAT_TEMPLATE\n from transformers.testing_utils import get_tests_dir\n from transformers.utils import is_vision_available\n \n@@ -43,12 +42,17 @@ def setUp(self):\n                 \"image_token\": \"<image_placeholder>\",\n             },\n         )\n+        processor_kwargs = self.prepare_processor_dict()\n         processor = self.processor_class(\n             image_processor=image_processor,\n             tokenizer=tokenizer,\n-            chat_template=CHAT_TEMPLATE,\n+            **processor_kwargs,\n         )\n         processor.save_pretrained(self.tmpdirname)\n \n-    def prepare_processor_dict(self):\n-        return {\"chat_template\": CHAT_TEMPLATE, \"num_image_tokens\": 576}\n+    @staticmethod\n+    def prepare_processor_dict():\n+        return {\n+            \"chat_template\": \"{% set seps = ['\\n\\n', '<\\uff5cend\\u2581of\\u2581sentence\\uff5c>'] %}{% set i = 0 %}You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.\\n\\n{% for message in messages %}{% if message['role']|lower == 'user' %}User: {% elif message['role']|lower == 'assistant' %}Assistant:{% if not (loop.last and not add_generation_prompt and message['content'][0]['type']=='text' and message['content'][0]['text']=='') %} {% endif %}{% else %}{{ message['role'].capitalize() }}: {% endif %}{% for content in message['content'] %}{% if content['type'] == 'image' %}<image_placeholder>{% elif content['type'] == 'text' %}{% set text = content['text'] %}{% if loop.first %}{% set text = text.lstrip() %}{% endif %}{% if loop.last %}{% set text = text.rstrip() %}{% endif %}{% if not loop.first and message['content'][loop.index0-1]['type'] == 'text' %}{{ ' ' + text }}{% else %}{{ text }}{% endif %}{% endif %}{% endfor %}{% if not loop.last or add_generation_prompt %}{% if message['role']|lower == 'user' %}{{ seps[0] }}{% else %}{{ seps[1] }}{% endif %}{% endif %}{% endfor %}{% if add_generation_prompt %}Assistant:{% endif %}\",\n+            \"num_image_tokens\": 576,\n+        }  # fmt: skip"
        }
    ],
    "stats": {
        "total": 24,
        "additions": 16,
        "deletions": 8
    }
}