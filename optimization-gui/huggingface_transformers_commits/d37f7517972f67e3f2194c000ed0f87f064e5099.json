{
    "author": "Rocketknight1",
    "message": "Two ReDOS fixes (#39013)\n\n* two_redos_fixes\n\n* Fix two redos issues\n\n* Just don't use RE at all",
    "sha": "d37f7517972f67e3f2194c000ed0f87f064e5099",
    "files": [
        {
            "sha": "ef8e1537b99dd46e890c5200699cf82f20c5cff0",
            "filename": "src/transformers/models/marian/tokenization_marian.py",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/d37f7517972f67e3f2194c000ed0f87f064e5099/src%2Ftransformers%2Fmodels%2Fmarian%2Ftokenization_marian.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d37f7517972f67e3f2194c000ed0f87f064e5099/src%2Ftransformers%2Fmodels%2Fmarian%2Ftokenization_marian.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmarian%2Ftokenization_marian.py?ref=d37f7517972f67e3f2194c000ed0f87f064e5099",
            "patch": "@@ -13,7 +13,6 @@\n # limitations under the License.\n import json\n import os\n-import re\n import warnings\n from pathlib import Path\n from shutil import copyfile\n@@ -104,7 +103,6 @@ class MarianTokenizer(PreTrainedTokenizer):\n \n     vocab_files_names = VOCAB_FILES_NAMES\n     model_input_names = [\"input_ids\", \"attention_mask\"]\n-    language_code_re = re.compile(\">>.+<<\")  # type: re.Pattern\n \n     def __init__(\n         self,\n@@ -186,9 +184,11 @@ def _convert_token_to_id(self, token):\n \n     def remove_language_code(self, text: str):\n         \"\"\"Remove language codes like >>fr<< before sentencepiece\"\"\"\n-        match = self.language_code_re.match(text)\n-        code: list = [match.group(0)] if match else []\n-        return code, self.language_code_re.sub(\"\", text)\n+        code = []\n+        if text.startswith(\">>\") and (end_loc := text.find(\"<<\")) != -1:\n+            code.append(text[: end_loc + 2])\n+            text = text[end_loc + 2 :]\n+        return code, text\n \n     def _tokenize(self, text: str) -> list[str]:\n         code, text = self.remove_language_code(text)"
        },
        {
            "sha": "71a77251f2bf9431a08295b8daabbcbe576de71b",
            "filename": "src/transformers/optimization_tf.py",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/d37f7517972f67e3f2194c000ed0f87f064e5099/src%2Ftransformers%2Foptimization_tf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d37f7517972f67e3f2194c000ed0f87f064e5099/src%2Ftransformers%2Foptimization_tf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Foptimization_tf.py?ref=d37f7517972f67e3f2194c000ed0f87f064e5099",
            "patch": "@@ -14,7 +14,6 @@\n # ==============================================================================\n \"\"\"Functions and classes related to optimization (weight updates).\"\"\"\n \n-import re\n from typing import Callable, Optional, Union\n \n import tensorflow as tf\n@@ -296,12 +295,12 @@ def _do_use_weight_decay(self, param_name):\n \n         if self._include_in_weight_decay:\n             for r in self._include_in_weight_decay:\n-                if re.search(r, param_name) is not None:\n+                if r in param_name:\n                     return True\n \n         if self._exclude_from_weight_decay:\n             for r in self._exclude_from_weight_decay:\n-                if re.search(r, param_name) is not None:\n+                if r in param_name:\n                     return False\n         return True\n "
        }
    ],
    "stats": {
        "total": 15,
        "additions": 7,
        "deletions": 8
    }
}