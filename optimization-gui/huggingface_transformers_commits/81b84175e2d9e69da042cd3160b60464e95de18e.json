{
    "author": "Abdennacer-Badaoui",
    "message": "update and add Expectations for mistral3/internvl tests (#42616)",
    "sha": "81b84175e2d9e69da042cd3160b60464e95de18e",
    "files": [
        {
            "sha": "9f51aa3fc325c1c3e687177331af614c4d993e92",
            "filename": "tests/models/internvl/test_modeling_internvl.py",
            "status": "modified",
            "additions": 21,
            "deletions": 6,
            "changes": 27,
            "blob_url": "https://github.com/huggingface/transformers/blob/81b84175e2d9e69da042cd3160b60464e95de18e/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/81b84175e2d9e69da042cd3160b60464e95de18e/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Finternvl%2Ftest_modeling_internvl.py?ref=81b84175e2d9e69da042cd3160b60464e95de18e",
            "patch": "@@ -430,7 +430,14 @@ def test_qwen2_small_model_integration_batched_generate_multi_image(self):\n         # Check first output\n         decoded_output = processor.decode(output[0], skip_special_tokens=True)\n         # Batching seems to alter the output slightly, but it is also the case in the original implementation. This seems to be expected: https://github.com/huggingface/transformers/issues/23017#issuecomment-1649630232\n-        expected_output = \"user\\n\\nWrite a haiku for this image\\nassistant\\nSilky lake,  \\nWooden pier,  \\nNature's peace.\"  # fmt: skip\n+        expected_outputs = Expectations(\n+            {\n+                (\"xpu\", 3): 'user\\n\\nWrite a haiku for this image\\nassistant\\nSilky lake,  \\nWooden pier,  \\nNature\\'s peace.',\n+                (\"cuda\", 7): 'user\\n\\nWrite a haiku for this image\\nassistant\\nSilky lake,  \\nWooden pier,  \\nNature\\'s peace.',\n+                (\"rocm\", (9, 4)): 'user\\n\\nWrite a haiku for this image\\nassistant\\nSilky lake,  \\nWooden pier,  \\nNature\\'s embrace.',\n+            }\n+        )  # fmt: skip\n+        expected_output = expected_outputs.get_expectation()\n         self.assertEqual(\n             decoded_output,\n             expected_output,\n@@ -443,6 +450,7 @@ def test_qwen2_small_model_integration_batched_generate_multi_image(self):\n             {\n                 (\"xpu\", 3): \"user\\n\\nWhat are the differences between these two images?\\nassistant\\nThe images show the Statue of Liberty and the Golden Gate Bridge from different angles. Here are the differences:\\n\\n1. **Foreground\",\n                 (\"cuda\", 7): \"user\\n\\nWhat are the differences between these two images?\\nassistant\\nThe images show the Statue of Liberty and the Golden Gate Bridge from different angles. Here are the differences:\\n\\n1. **Foreground\",\n+                (\"rocm\", (9, 4)): \"user\\n\\nWhat are the differences between these two images?\\nassistant\\nThe images show the Statue of Liberty and the Golden Gate Bridge from different angles. Here are the main differences:\\n\\n1. **\",\n             }\n         )  # fmt: skip\n         expected_output = expected_outputs.get_expectation()\n@@ -567,6 +575,7 @@ def test_qwen2_small_model_integration_interleaved_images_videos(self):\n             {\n                 (\"xpu\", 3): \"user\\n\\n\\nWhat are the differences between these two images?\\nassistant\\nThe images depict two distinct scenes:\\n\\n1. **Left Image:**\\n   - The Statue of Liberty is prominently featured on an\",\n                 (\"cuda\", 7): 'user\\n\\n\\nWhat are the differences between these two images?\\nassistant\\nThe images depict two distinct scenes:\\n\\n1. **Left Image:**\\n   - The Statue of Liberty is prominently featured on an',\n+                (\"rocm\", (9, 4)): 'user\\n\\n\\nWhat are the differences between these two images?\\nassistant\\nThe images depict two distinct scenes:\\n\\n1. **Left Image:**\\n   - This image features the Statue of Liberty on Liberty',\n             }\n         )  # fmt: skip\n         expected_output = expected_outputs.get_expectation()\n@@ -582,6 +591,7 @@ def test_qwen2_small_model_integration_interleaved_images_videos(self):\n             {\n                 (\"xpu\", 3): \"user\\nFrame1: \\nFrame2: \\nFrame3: \\nFrame4: \\nFrame5: \\nFrame6: \\nFrame7: \\nFrame8: \\nWhat type of shot is the man performing?\\nassistant\\nA forehand shot\",\n                 (\"cuda\", 7): 'user\\nFrame1: \\nFrame2: \\nFrame3: \\nFrame4: \\nFrame5: \\nFrame6: \\nFrame7: \\nFrame8: \\nWhat type of shot is the man performing?\\nassistant\\nA forehand shot',\n+                (\"rocm\", (9, 4)): 'user\\nFrame1: \\nFrame2: \\nFrame3: \\nFrame4: \\nFrame5: \\nFrame6: \\nFrame7: \\nFrame8: \\nWhat type of shot is the man performing?\\nassistant\\nA forehand shot',\n             }\n         )  # fmt: skip\n         expected_output = expected_outputs.get_expectation()\n@@ -593,9 +603,14 @@ def test_qwen2_small_model_integration_interleaved_images_videos(self):\n \n         # Check third output\n         decoded_output = processor.decode(output[2], skip_special_tokens=True)\n-        expected_output = (\n-            \"user\\n\\nWrite a haiku for this image\\nassistant\\nSilky lake,  \\nWooden pier,  \\nNature's peace.\"\n-        )\n+        expected_outputs = Expectations(\n+            {\n+                (\"xpu\", 3): 'user\\n\\nWrite a haiku for this image\\nassistant\\nSilky lake,  \\nWooden pier,  \\nNature\\'s peace.',\n+                (\"cuda\", 7): 'user\\n\\nWrite a haiku for this image\\nassistant\\nSilky lake,  \\nWooden pier,  \\nNature\\'s peace.',\n+                (\"rocm\", (9, 4)): 'user\\n\\nWrite a haiku for this image\\nassistant\\nSilky lake,  \\nWooden pier,  \\nNature\\'s embrace.',\n+            }\n+        )  # fmt: skip\n+        expected_output = expected_outputs.get_expectation()\n         self.assertEqual(\n             decoded_output,\n             expected_output,\n@@ -658,7 +673,7 @@ def test_llama_small_model_integration_forward(self):\n                 (\"xpu\", 3): [-9.8828,  -0.4954,   1.4561, -10.3438, -10.3438],\n                 (\"cuda\", 7): [-9.8750,  -0.4861,   1.4648, -10.3359, -10.3359],\n                 (\"cuda\", 8): [-9.8906,  -0.4995,   1.4473, -10.3359, -10.3438],\n-                (\"rocm\", (9, 4)): [ -9.8828,  -0.5005,   1.4697, -10.3438, -10.3438],\n+                (\"rocm\", (9, 4)): [ -9.8672,  -0.4888,   1.4648, -10.3281, -10.3281],\n                 (\"rocm\", (9, 5)): [ -9.8906,  -0.4976,   1.4502, -10.3359, -10.3438],\n             }\n         )  # fmt: skip\n@@ -934,7 +949,7 @@ def test_llama_small_model_integration_interleaved_images_videos(self):\n                 (\"xpu\", 3): \"user\\n\\n\\nWhat are the difference between these two images?\\nassistant\\nI apologize for the confusion in my previous response. Upon closer inspection, the differences between the two images are:\\n\\n1. **\",\n                 (\"cuda\", 7): 'user\\n\\n\\nWhat are the difference between these two images?\\nassistant\\nI apologize for the confusion in my previous response. Upon closer inspection, the differences between the two images are:\\n\\n1. **',\n                 (\"cuda\", 8): 'user\\n\\n\\nWhat are the difference between these two images?\\nassistant\\nI apologize for the confusion in my previous response. After re-examining the images, I can see that there are no',\n-                (\"rocm\", (9, 4)): 'user\\n\\n\\nWhat are the difference between these two images?\\nassistant\\nI apologize for the confusion in my previous response. Upon closer inspection, the differences between the two images are:\\n\\n1. **',\n+                (\"rocm\", (9, 4)): 'user\\n\\n\\nWhat are the difference between these two images?\\nassistant\\nI apologize for the confusion in my previous response. After re-examining the images, I can see that there are no',\n                 (\"rocm\", (9, 5)): 'user\\n\\n\\nWhat are the difference between these two images?\\nassistant\\nI apologize for the confusion in my previous response. After re-examining the images, I can see that there are no',\n             }\n         )  # fmt: skip"
        },
        {
            "sha": "15109b2aec8c644ab79885fcacb194392d480a94",
            "filename": "tests/models/mistral3/test_modeling_mistral3.py",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/81b84175e2d9e69da042cd3160b60464e95de18e/tests%2Fmodels%2Fmistral3%2Ftest_modeling_mistral3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/81b84175e2d9e69da042cd3160b60464e95de18e/tests%2Fmodels%2Fmistral3%2Ftest_modeling_mistral3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmistral3%2Ftest_modeling_mistral3.py?ref=81b84175e2d9e69da042cd3160b60464e95de18e",
            "patch": "@@ -355,7 +355,8 @@ def test_mistral3_integration_batched_generate(self):\n         expected_outputs = Expectations(\n             {\n                 (\"xpu\", 3): \"Calm lake's mirror gleams,\\nWhispering pines stand in silence,\\nPath to peace begins.\",\n-                (\"cuda\", 8): \"Wooden path to calm,\\nReflections whisper secrets,\\nNature's peace unfolds.\",\n+                (\"cuda\", (8, 0)): \"Wooden path to calm,\\nReflections whisper secrets,\\nNature's peace unfolds.\",\n+                (\"cuda\", (8, 6)): \"Calm waters reflect\\nWooden path to distant shore\\nSilence in the woods\",\n                 (\"rocm\", (9, 5)): \"Calm waters reflect\\nWooden path to distant shore\\nSilence in the scene\"\n             }\n         )  # fmt: skip\n@@ -432,7 +433,8 @@ def test_mistral3_integration_batched_generate_multi_image(self):\n         decoded_output = processor.decode(gen_tokens[0], skip_special_tokens=True)\n         expected_outputs = Expectations(\n             {\n-                (\"cuda\", 8): 'Calm waters reflect\\nWooden path to distant shore\\nSilence in the scene',\n+                (\"cuda\", 8): \"Calm waters reflect\\nWooden path to distant shore\\nPeace in nature's hold\",\n+                (\"rocm\", (9, 4)): \"Calm waters reflect\\nWooden path to distant shore\\nSilence in the pines\"\n             }\n         )  # fmt: skip\n         expected_output = expected_outputs.get_expectation()\n@@ -448,6 +450,7 @@ def test_mistral3_integration_batched_generate_multi_image(self):\n             {\n                 (\"xpu\", 3): \"Certainly! The images depict two iconic landmarks:\\n\\n1. The first image shows the Statue of Liberty in New York City.\",\n                 (\"cuda\", 8): 'Certainly! The images depict two famous landmarks in the United States:\\n\\n1. The first image shows the Statue of Liberty,',\n+                (\"rocm\", (9, 4)): 'Certainly! The images depict two famous landmarks in the United States:\\n\\n1. The first image shows the Statue of Liberty,',\n             }\n         )  # fmt: skip\n         expected_output = expected_outputs.get_expectation()"
        }
    ],
    "stats": {
        "total": 34,
        "additions": 26,
        "deletions": 8
    }
}