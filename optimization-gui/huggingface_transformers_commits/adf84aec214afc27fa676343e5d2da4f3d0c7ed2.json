{
    "author": "abdokaseb",
    "message": "Add DeepseekV3ForSequenceClassification for Deepseek V3 models (#40200)\n\n* Add Sequence Classification Support for Deepseek v3 model DeepseekV3ForSequenceClassification\n\n* After run make fixup",
    "sha": "adf84aec214afc27fa676343e5d2da4f3d0c7ed2",
    "files": [
        {
            "sha": "d121f8fb556813041fac7972030be87a88072e07",
            "filename": "docs/source/en/model_doc/deepseek_v3.md",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/adf84aec214afc27fa676343e5d2da4f3d0c7ed2/docs%2Fsource%2Fen%2Fmodel_doc%2Fdeepseek_v3.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/adf84aec214afc27fa676343e5d2da4f3d0c7ed2/docs%2Fsource%2Fen%2Fmodel_doc%2Fdeepseek_v3.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fdeepseek_v3.md?ref=adf84aec214afc27fa676343e5d2da4f3d0c7ed2",
            "patch": "@@ -183,3 +183,8 @@ error, it means NCCL was probably not loaded.\n \n [[autodoc]] DeepseekV3ForCausalLM\n     - forward\n+\n+## DeepseekV3ForSequenceClassification\n+\n+[[autodoc]] DeepseekV3ForSequenceClassification\n+    - forward"
        },
        {
            "sha": "630d66926c9c12bf24df5977e73323176475d4a4",
            "filename": "src/transformers/models/auto/modeling_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/adf84aec214afc27fa676343e5d2da4f3d0c7ed2/src%2Ftransformers%2Fmodels%2Fauto%2Fmodeling_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/adf84aec214afc27fa676343e5d2da4f3d0c7ed2/src%2Ftransformers%2Fmodels%2Fauto%2Fmodeling_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fmodeling_auto.py?ref=adf84aec214afc27fa676343e5d2da4f3d0c7ed2",
            "patch": "@@ -1183,6 +1183,7 @@ class _BaseModelWithGenerate(PreTrainedModel, GenerationMixin):\n         (\"deberta\", \"DebertaForSequenceClassification\"),\n         (\"deberta-v2\", \"DebertaV2ForSequenceClassification\"),\n         (\"deepseek_v2\", \"DeepseekV2ForSequenceClassification\"),\n+        (\"deepseek_v3\", \"DeepseekV3ForSequenceClassification\"),\n         (\"diffllama\", \"DiffLlamaForSequenceClassification\"),\n         (\"distilbert\", \"DistilBertForSequenceClassification\"),\n         (\"doge\", \"DogeForSequenceClassification\"),"
        },
        {
            "sha": "da14e20687eb28a0cb5b7133533e63e9635f724d",
            "filename": "src/transformers/models/deepseek_v3/modeling_deepseek_v3.py",
            "status": "modified",
            "additions": 11,
            "deletions": 2,
            "changes": 13,
            "blob_url": "https://github.com/huggingface/transformers/blob/adf84aec214afc27fa676343e5d2da4f3d0c7ed2/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/adf84aec214afc27fa676343e5d2da4f3d0c7ed2/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py?ref=adf84aec214afc27fa676343e5d2da4f3d0c7ed2",
            "patch": "@@ -17,7 +17,7 @@\n from ...integrations import use_kernel_forward_from_hub\n from ...masking_utils import create_causal_mask\n from ...modeling_flash_attention_utils import FlashAttentionKwargs\n-from ...modeling_layers import GradientCheckpointingLayer\n+from ...modeling_layers import GenericForSequenceClassification, GradientCheckpointingLayer\n from ...modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast\n from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update\n from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n@@ -678,4 +678,13 @@ def forward(\n         )\n \n \n-__all__ = [\"DeepseekV3PreTrainedModel\", \"DeepseekV3Model\", \"DeepseekV3ForCausalLM\"]\n+class DeepseekV3ForSequenceClassification(GenericForSequenceClassification, DeepseekV3PreTrainedModel):\n+    pass\n+\n+\n+__all__ = [\n+    \"DeepseekV3PreTrainedModel\",\n+    \"DeepseekV3Model\",\n+    \"DeepseekV3ForCausalLM\",\n+    \"DeepseekV3ForSequenceClassification\",\n+]"
        },
        {
            "sha": "c0e65d63345768948448cd9582ab2b044c0cd520",
            "filename": "src/transformers/models/deepseek_v3/modular_deepseek_v3.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/adf84aec214afc27fa676343e5d2da4f3d0c7ed2/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodular_deepseek_v3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/adf84aec214afc27fa676343e5d2da4f3d0c7ed2/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodular_deepseek_v3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodular_deepseek_v3.py?ref=adf84aec214afc27fa676343e5d2da4f3d0c7ed2",
            "patch": "@@ -9,6 +9,7 @@\n from ...activations import ACT2FN\n from ...cache_utils import Cache\n from ...modeling_flash_attention_utils import FlashAttentionKwargs\n+from ...modeling_layers import GenericForSequenceClassification\n from ...modeling_utils import ALL_ATTENTION_FUNCTIONS\n from ...processing_utils import Unpack\n from ...utils import logging\n@@ -356,8 +357,13 @@ class DeepseekV3ForCausalLM(LlamaForCausalLM):\n     pass\n \n \n+class DeepseekV3ForSequenceClassification(GenericForSequenceClassification, DeepseekV3PreTrainedModel):\n+    pass\n+\n+\n __all__ = [\n     \"DeepseekV3PreTrainedModel\",\n     \"DeepseekV3Model\",\n     \"DeepseekV3ForCausalLM\",\n+    \"DeepseekV3ForSequenceClassification\",\n ]"
        },
        {
            "sha": "3a45a27751b7287b259cdd09ee4ec4d186bd5733",
            "filename": "tests/models/deepseek_v3/test_modeling_deepseek_v3.py",
            "status": "modified",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/adf84aec214afc27fa676343e5d2da4f3d0c7ed2/tests%2Fmodels%2Fdeepseek_v3%2Ftest_modeling_deepseek_v3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/adf84aec214afc27fa676343e5d2da4f3d0c7ed2/tests%2Fmodels%2Fdeepseek_v3%2Ftest_modeling_deepseek_v3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdeepseek_v3%2Ftest_modeling_deepseek_v3.py?ref=adf84aec214afc27fa676343e5d2da4f3d0c7ed2",
            "patch": "@@ -42,6 +42,7 @@\n \n     from transformers import (\n         DeepseekV3ForCausalLM,\n+        DeepseekV3ForSequenceClassification,\n         DeepseekV3Model,\n     )\n     from transformers.models.deepseek_v3.modeling_deepseek_v3 import (\n@@ -215,6 +216,7 @@ class DeepseekV3ModelTest(ModelTesterMixin, GenerationTesterMixin, PipelineTeste\n         (\n             DeepseekV3Model,\n             DeepseekV3ForCausalLM,\n+            DeepseekV3ForSequenceClassification,\n         )\n         if is_torch_available()\n         else ()\n@@ -223,7 +225,9 @@ class DeepseekV3ModelTest(ModelTesterMixin, GenerationTesterMixin, PipelineTeste\n     pipeline_model_mapping = (\n         {\n             \"feature-extraction\": DeepseekV3Model,\n+            \"text-classification\": DeepseekV3ForSequenceClassification,\n             \"text-generation\": DeepseekV3ForCausalLM,\n+            \"zero-shot\": DeepseekV3ForSequenceClassification,\n         }\n         if is_torch_available()\n         else {}\n@@ -503,6 +507,18 @@ def test_flex_attention_with_grads(self):\n             # If this does not raise an error, the test passes (see https://github.com/huggingface/transformers/pull/35605)\n             _ = model(**dummy_inputs)\n \n+    def test_deepseek_v3_sequence_classification_model(self):\n+        config, input_dict = self.model_tester.prepare_config_and_inputs_for_common()\n+        config.num_labels = 3\n+        input_ids = input_dict[\"input_ids\"]\n+        attention_mask = input_ids.ne(1).to(torch_device)\n+        sequence_labels = ids_tensor([self.model_tester.batch_size], self.model_tester.num_labels)\n+        model = DeepseekV3ForSequenceClassification(config)\n+        model.to(torch_device)\n+        model.eval()\n+        result = model(input_ids, attention_mask=attention_mask, labels=sequence_labels)\n+        self.assertEqual(result.logits.shape, (self.model_tester.batch_size, self.model_tester.num_labels))\n+\n \n @require_torch_accelerator\n class DeepseekV3IntegrationTest(unittest.TestCase):"
        }
    ],
    "stats": {
        "total": 41,
        "additions": 39,
        "deletions": 2
    }
}