{
    "author": "blueingman",
    "message": "[i18n-zh]Translated perf_train_special.md into Chinese (#34948)\n\n* Add translation for perf_train_special documentation\r\n\r\n* Update docs/source/zh/perf_train_special.md\r\n\r\nCo-authored-by: Isotr0py <2037008807@qq.com>\r\n\r\n* Update docs/source/zh/perf_train_special.md\r\n\r\nCo-authored-by: Isotr0py <2037008807@qq.com>\r\n\r\n* Update _toctree.yml\r\n\r\n* Update _toctree.yml\r\n\r\n* Update perf_train_special.md\r\n\r\n* Update perf_train_special.md\r\n\r\n---------\r\n\r\nCo-authored-by: Isotr0py <2037008807@qq.com>",
    "sha": "2910015d6deffb4e3a016a0a316a4fa7cbb4ac1e",
    "files": [
        {
            "sha": "61b74b0d7ca99d3226ff46b1120c3e3d19b680e0",
            "filename": "docs/source/zh/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2910015d6deffb4e3a016a0a316a4fa7cbb4ac1e/docs%2Fsource%2Fzh%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/2910015d6deffb4e3a016a0a316a4fa7cbb4ac1e/docs%2Fsource%2Fzh%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2F_toctree.yml?ref=2910015d6deffb4e3a016a0a316a4fa7cbb4ac1e",
            "patch": "@@ -61,6 +61,8 @@\n   - sections:\n     - local: fsdp\n       title: 完全分片数据并行\n+    - local: perf_train_special\n+      title: 在 Apple silicon 芯片上进行 PyTorch 训练\n     - local: perf_hardware\n       title: 用于训练的定制硬件\n     - local: hpo_train"
        },
        {
            "sha": "ee8553475679ee19d3c04fecb71f60924e11e731",
            "filename": "docs/source/zh/perf_train_special.md",
            "status": "added",
            "additions": 58,
            "deletions": 0,
            "changes": 58,
            "blob_url": "https://github.com/huggingface/transformers/blob/2910015d6deffb4e3a016a0a316a4fa7cbb4ac1e/docs%2Fsource%2Fzh%2Fperf_train_special.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/2910015d6deffb4e3a016a0a316a4fa7cbb4ac1e/docs%2Fsource%2Fzh%2Fperf_train_special.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fperf_train_special.md?ref=2910015d6deffb4e3a016a0a316a4fa7cbb4ac1e",
            "patch": "@@ -0,0 +1,58 @@\n+<!--Copyright 2022 The HuggingFace Team. All rights reserved.\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+http://www.apache.org/licenses/LICENSE-2.0\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+-->\n+\n+# 在 Apple Silicon 芯片上进行 PyTorch 训练\n+\n+之前，在 Mac 上训练模型仅限于使用 CPU 训练。不过随着PyTorch v1.12的发布，您可以通过在 Apple Silicon 芯片的 GPU 上训练模型来显著提高性能和训练速度。这是通过将 Apple 的 Metal 性能着色器 (Metal Performance Shaders, MPS) 作为后端集成到PyTorch中实现的。[MPS后端](https://pytorch.org/docs/stable/notes/mps.html) 将 PyTorch 操作视为自定义的 Metal 着色器来实现，并将对应模块部署到`mps`设备上。\n+\n+<Tip warning={true}>\n+\n+某些 PyTorch 操作目前还未在 MPS 上实现，可能会抛出错误提示。可以通过设置环境变量`PYTORCH_ENABLE_MPS_FALLBACK=1`来使用CPU内核以避免这种情况发生（您仍然会看到一个`UserWarning`）。\n+\n+<br>\n+\n+如果您遇到任何其他错误，请在[PyTorch库](https://github.com/pytorch/pytorch/issues)中创建一个 issue，因为[`Trainer`]类中只集成了 MPS 后端.\n+\n+</Tip>\n+\n+配置好`mps`设备后，您可以：\n+\n+* 在本地训练更大的网络或更大的批量大小\n+* 降低数据获取延迟，因为 GPU 的统一内存架构允许直接访问整个内存存储\n+* 降低成本，因为您不需要再在云端 GPU 上训练或增加额外的本地 GPU\n+\n+在确保已安装PyTorch后就可以开始使用了。 MPS 加速支持macOS 12.3及以上版本。\n+\n+```bash\n+pip install torch torchvision torchaudio\n+```\n+\n+[`TrainingArguments`]类默认使用`mps`设备(如果可用)因此无需显式设置设备。例如，您可以直接运行[run_glue.py](https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py)脚本，在无需进行任何修改的情况下自动启用 MPS 后端。\n+\n+```diff\n+export TASK_NAME=mrpc\n+\n+python examples/pytorch/text-classification/run_glue.py \\\n+  --model_name_or_path google-bert/bert-base-cased \\\n+  --task_name $TASK_NAME \\\n+- --use_mps_device \\\n+  --do_train \\\n+  --do_eval \\\n+  --max_seq_length 128 \\\n+  --per_device_train_batch_size 32 \\\n+  --learning_rate 2e-5 \\\n+  --num_train_epochs 3 \\\n+  --output_dir /tmp/$TASK_NAME/ \\\n+  --overwrite_output_dir\n+```\n+\n+用于[分布式设置](https://pytorch.org/docs/stable/distributed.html#backends)的后端(如`gloo`和`nccl`)不支持`mps`设备，这也意味着使用 MPS 后端时只能在单个 GPU 上进行训练。\n+\n+您可以在[Introducing Accelerated PyTorch Training on Mac](https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/)博客文章中了解有关 MPS 后端的更多信息。"
        }
    ],
    "stats": {
        "total": 60,
        "additions": 60,
        "deletions": 0
    }
}