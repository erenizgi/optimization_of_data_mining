{
    "author": "cyyever",
    "message": "Remove use_ipex option from Trainer (#40784)\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>",
    "sha": "7d57b31e16d5a08fda29578c31fc1924fefc50b2",
    "files": [
        {
            "sha": "1b793e614eb261e74746975fd02923f8e4d8dea3",
            "filename": "src/transformers/training_args.py",
            "status": "modified",
            "additions": 1,
            "deletions": 19,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/7d57b31e16d5a08fda29578c31fc1924fefc50b2/src%2Ftransformers%2Ftraining_args.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7d57b31e16d5a08fda29578c31fc1924fefc50b2/src%2Ftransformers%2Ftraining_args.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftraining_args.py?ref=7d57b31e16d5a08fda29578c31fc1924fefc50b2",
            "patch": "@@ -391,9 +391,6 @@ class TrainingArguments:\n             seed.\n         jit_mode_eval (`bool`, *optional*, defaults to `False`):\n             Whether or not to use PyTorch jit trace for inference.\n-        use_ipex (`bool`, *optional*, defaults to `False`):\n-            Use Intel extension for PyTorch when it is available. [IPEX\n-            installation](https://github.com/intel/intel-extension-for-pytorch).\n         bf16 (`bool`, *optional*, defaults to `False`):\n             Whether to use bf16 16-bit (mixed) precision training instead of 32-bit training. Requires Ampere or higher\n             NVIDIA architecture or Intel XPU or using CPU (use_cpu) or Ascend NPU. This is an experimental API and it may change.\n@@ -1060,15 +1057,6 @@ class TrainingArguments:\n     jit_mode_eval: bool = field(\n         default=False, metadata={\"help\": \"Whether or not to use PyTorch jit trace for inference\"}\n     )\n-    use_ipex: bool = field(\n-        default=False,\n-        metadata={\n-            \"help\": (\n-                \"Use Intel extension for PyTorch when it is available, installation:\"\n-                \" 'https://github.com/intel/intel-extension-for-pytorch'\"\n-            )\n-        },\n-    )\n     bf16: bool = field(\n         default=False,\n         metadata={\n@@ -1622,12 +1610,6 @@ def __post_init__(self):\n                 FutureWarning,\n             )\n             self.use_cpu = self.no_cuda\n-        if self.use_ipex:\n-            warnings.warn(\n-                \"using `use_ipex` is deprecated and will be removed in version 4.54 of ðŸ¤— Transformers. \"\n-                \"You only need PyTorch for the needed optimizations on Intel CPU and XPU.\",\n-                FutureWarning,\n-            )\n \n         self.eval_strategy = IntervalStrategy(self.eval_strategy)\n         self.logging_strategy = IntervalStrategy(self.logging_strategy)\n@@ -2236,7 +2218,7 @@ def _setup_devices(self) -> \"torch.device\":\n         else:\n             AcceleratorState._reset_state(reset_partial_state=True)\n             self.distributed_state = None\n-        if not self.use_ipex and \"ACCELERATE_USE_IPEX\" not in os.environ:\n+        if \"ACCELERATE_USE_IPEX\" not in os.environ:\n             os.environ[\"ACCELERATE_USE_IPEX\"] = \"false\"\n \n         self._n_gpu = 1"
        }
    ],
    "stats": {
        "total": 20,
        "additions": 1,
        "deletions": 19
    }
}