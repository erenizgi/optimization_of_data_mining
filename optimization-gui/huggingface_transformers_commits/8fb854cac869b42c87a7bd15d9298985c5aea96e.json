{
    "author": "ydshieh",
    "message": "Run slow v2 (#41914)\n\n* Super\n\n* Super\n\n* Super\n\n* Super\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "8fb854cac869b42c87a7bd15d9298985c5aea96e",
    "files": [
        {
            "sha": "5f37e7f9541e6a8d26488e562ec274d9916a3ff7",
            "filename": ".github/workflows/check_failed_tests.yml",
            "status": "modified",
            "additions": 75,
            "deletions": 28,
            "changes": 103,
            "blob_url": "https://github.com/huggingface/transformers/blob/8fb854cac869b42c87a7bd15d9298985c5aea96e/.github%2Fworkflows%2Fcheck_failed_tests.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/8fb854cac869b42c87a7bd15d9298985c5aea96e/.github%2Fworkflows%2Fcheck_failed_tests.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fcheck_failed_tests.yml?ref=8fb854cac869b42c87a7bd15d9298985c5aea96e",
            "patch": "@@ -6,9 +6,6 @@ on:\n       docker:\n         required: true\n         type: string\n-      start_sha:\n-        required: true\n-        type: string\n       job:\n         required: true\n         type: string\n@@ -24,7 +21,13 @@ on:\n       commit_sha:\n         required: false\n         type: string\n-\n+      pr_number:\n+        required: false\n+        type: string\n+    outputs:\n+      report:\n+        description: \"Content of the report of new failures\"\n+        value: ${{ jobs.process_new_failures_with_commit_info.outputs.report }}\n \n env:\n   HF_HOME: /mnt/cache\n@@ -88,27 +91,55 @@ jobs:\n             echo \"PREV_WORKFLOW_RUN_ID=\" >> $GITHUB_ENV\n           fi\n \n-          if [ -f setup_values/other_workflow_run_id.txt ]; then\n-            echo \"OTHER_WORKFLOW_RUN_ID=$(cat setup_values/other_workflow_run_id.txt)\" >> $GITHUB_ENV\n-          else\n-            echo \"OTHER_WORKFLOW_RUN_ID=\" >> $GITHUB_ENV\n-          fi\n-\n       - name: Update clone\n         working-directory: /transformers\n         if: ${{ env.process == 'true' }}\n-        run: git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n+        run: |\n+          git fetch origin ${{ inputs.commit_sha || github.sha }}\n+          git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n \n-      - name: Get target commit\n+      - name: Get `START_SHA`\n         working-directory: /transformers/utils\n         if: ${{ env.process == 'true' }}\n+        run: |\n+          echo \"START_SHA=${{ inputs.commit_sha || github.sha }}\" >> $GITHUB_ENV\n+\n+      # This is used if the CI is triggered from a pull request `self-comment-ci.yml` (after security check is verified)\n+      - name: Extract the base commit on `main` (of the merge commit created by Github) if it is a PR\n+        id: pr_info\n+        if: ${{ env.process == 'true' && inputs.pr_number != '' }}\n+        uses: actions/github-script@v6\n+        with:\n+          script: |            \n+            const { data: pr } = await github.rest.pulls.get({\n+              owner: context.repo.owner,\n+              repo: context.repo.repo,\n+              pull_number: ${{ inputs.pr_number }}\n+            });\n+\n+            const { data: merge_commit }  = await github.rest.repos.getCommit({\n+              owner: pr.base.repo.owner.login,\n+              repo: pr.base.repo.name,\n+              ref: pr.merge_commit_sha,\n+            });\n+\n+            core.setOutput('merge_commit_base_sha', merge_commit.parents[0].sha);\n+\n+      # Usually, `END_SHA` should be the commit of the last previous workflow run of the **SAME** (scheduled) workflow.\n+      # (This is why we don't need to specify `workflow_id` which would be fetched automatically in the python script.)\n+      - name: Get `END_SHA` from previous CI runs of the same workflow\n+        working-directory: /transformers/utils\n+        if: ${{ env.process == 'true' && inputs.pr_number == '' }}\n         run: |\n           echo \"END_SHA=$(TOKEN=${{ secrets.ACCESS_REPO_INFO_TOKEN }} python3 -c 'import os; from get_previous_daily_ci import get_last_daily_ci_run_commit; commit=get_last_daily_ci_run_commit(token=os.environ[\"TOKEN\"], workflow_run_id=os.environ[\"PREV_WORKFLOW_RUN_ID\"]); print(commit)')\" >> $GITHUB_ENV\n \n-      - name: Checkout to `start_sha`\n-        working-directory: /transformers\n-        if: ${{ env.process == 'true' }}\n-        run: git fetch && git checkout ${{ inputs.start_sha }}\n+      # However, for workflow runs triggered by `issue_comment` (for pull requests), we want to check against the\n+      # parent commit (on `main`) of the `merge_commit` (dynamically created by GitHub). In this case, the goal is to\n+      # see if a reported failing test is actually ONLY failing on the `merge_commit`.\n+      - name: Set `END_SHA`\n+        if: ${{ env.process == 'true' && inputs.pr_number != '' }}\n+        run: |\n+          echo \"END_SHA=${{ steps.pr_info.outputs.merge_commit_base_sha }}\" >> $GITHUB_ENV\n \n       - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n         working-directory: /transformers\n@@ -138,7 +169,7 @@ jobs:\n       - name: Check failed tests\n         working-directory: /transformers\n         if: ${{ env.process == 'true' }}\n-        run: python3 utils/check_bad_commit.py --start_commit ${{ inputs.start_sha }} --end_commit ${{ env.END_SHA }} --file ci_results_${{ inputs.job }}/new_failures.json --output_file new_failures_with_bad_commit_${{ inputs.job }}_${{ matrix.run_idx }}.json\n+        run: python3 utils/check_bad_commit.py --start_commit ${{ env.START_SHA }} --end_commit ${{ env.END_SHA }} --file ci_results_${{ inputs.job }}/new_failures.json --output_file new_failures_with_bad_commit_${{ inputs.job }}_${{ matrix.run_idx }}.json\n \n       - name: Show results\n         working-directory: /transformers\n@@ -159,6 +190,8 @@ jobs:\n     if: needs.check_new_failures.outputs.process == 'true'\n     runs-on:\n       group: aws-g5-4xlarge-cache\n+    outputs:\n+      report: ${{ steps.set_output.outputs.report }}\n     container:\n       image: ${{ inputs.docker }}\n       options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n@@ -190,18 +223,9 @@ jobs:\n \n       - name: Update clone\n         working-directory: /transformers\n-        run: git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n-\n-      - name: Process report\n-        shell: bash\n-        working-directory: /transformers\n-        env:\n-          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n-          TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN: ${{ secrets.TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN }}\n-          JOB_NAME: ${{ inputs.job }}\n-          REPORT_REPO_ID: ${{ inputs.report_repo_id }}\n         run: |\n-          python3 utils/process_bad_commit_report.py\n+          git fetch origin ${{ inputs.commit_sha || github.sha }}\n+          git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n \n       - name: Process report\n         shell: bash\n@@ -218,6 +242,29 @@ jobs:\n             echo EOF\n           } >> \"$GITHUB_ENV\"\n \n+      # The output is useful if a caller needs more processing, for example, we have a chain\n+      # self-comment-ci.yml -> self-scheduled.yml -> this one (check_failed_tests.yml),\n+      # and `self-comment-ci.yml` needs further processing before sending a GitHub comment to the pull request page.\n+      - name: Show results & Set outputs\n+        id: set_output\n+        working-directory: /transformers\n+        run: |\n+          ls -l new_failures_with_bad_commit.json\n+          cat new_failures_with_bad_commit.json\n+\n+          {\n+            echo 'report<<EOF'\n+            cat new_failures_with_bad_commit.json\n+            echo ''  # Force a newline\n+            echo EOF\n+          } >> \"$GITHUB_OUTPUT\"\n+\n+      - name: Upload artifacts\n+        uses: actions/upload-artifact@v4\n+        with:\n+          name: new_failures_with_bad_commit_${{ inputs.job }}\n+          path: /transformers/new_failures_with_bad_commit.json\n+\n       - name: Prepare Slack report title\n         working-directory: /transformers\n         run: |"
        },
        {
            "sha": "0f60c039349ff48c2449a3c2c92d2e72a1c48a89",
            "filename": ".github/workflows/get-pr-info.yml",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/8fb854cac869b42c87a7bd15d9298985c5aea96e/.github%2Fworkflows%2Fget-pr-info.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/8fb854cac869b42c87a7bd15d9298985c5aea96e/.github%2Fworkflows%2Fget-pr-info.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fget-pr-info.yml?ref=8fb854cac869b42c87a7bd15d9298985c5aea96e",
            "patch": "@@ -39,6 +39,9 @@ on:\n       PR_MERGE_COMMIT_SHA:\n         description: \"The sha of the merge commit for the pull request (created by GitHub) in the base repository\"\n         value: ${{ jobs.get-pr-info.outputs.PR_MERGE_COMMIT_SHA }}\n+      PR_MERGE_COMMIT_BASE_SHA:\n+        description: \"The sha of the parent commit of the the merge commit on the target branch in the base repository\"\n+        value: ${{ jobs.get-pr-info.outputs.PR_MERGE_COMMIT_BASE_SHA }}\n       PR_HEAD_COMMIT_DATE:\n         description: \"The date of the head sha of the pull request branch in the head repository\"\n         value: ${{ jobs.get-pr-info.outputs.PR_HEAD_COMMIT_DATE }}\n@@ -74,6 +77,7 @@ jobs:\n       PR_BASE_REF: ${{ steps.pr_info.outputs.base_ref }}\n       PR_HEAD_SHA: ${{ steps.pr_info.outputs.head_sha }}\n       PR_BASE_SHA: ${{ steps.pr_info.outputs.base_sha }}\n+      PR_MERGE_COMMIT_BASE_SHA: ${{ steps.pr_info.outputs.merge_commit_base_sha }}\n       PR_MERGE_COMMIT_SHA: ${{ steps.pr_info.outputs.merge_commit_sha }}\n       PR_HEAD_COMMIT_DATE: ${{ steps.pr_info.outputs.head_commit_date }}\n       PR_MERGE_COMMIT_DATE: ${{ steps.pr_info.outputs.merge_commit_date }}\n@@ -122,6 +126,7 @@ jobs:\n             core.setOutput('base_ref', pr.base.ref);\n             core.setOutput('head_sha', pr.head.sha);\n             core.setOutput('base_sha', pr.base.sha);\n+            core.setOutput('merge_commit_base_sha', merge_commit.parents[0].sha);\n             core.setOutput('merge_commit_sha', pr.merge_commit_sha);\n             core.setOutput('pr', pr);\n \n@@ -142,6 +147,10 @@ jobs:\n               date: merge_commit.commit.committer.date\n             });\n \n+            console.log('PR Info:', {\n+              pr_info: pr\n+            });\n+\n       - name: Convert dates to timestamps\n         id: get_timestamps\n         run: |"
        },
        {
            "sha": "69c84f22fe8de5e5425aca4d586e73af3c876c80",
            "filename": ".github/workflows/model_jobs.yml",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/8fb854cac869b42c87a7bd15d9298985c5aea96e/.github%2Fworkflows%2Fmodel_jobs.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/8fb854cac869b42c87a7bd15d9298985c5aea96e/.github%2Fworkflows%2Fmodel_jobs.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fmodel_jobs.yml?ref=8fb854cac869b42c87a7bd15d9298985c5aea96e",
            "patch": "@@ -80,7 +80,9 @@ jobs:\n \n       - name: Update clone\n         working-directory: /transformers\n-        run: git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n+        run: |\n+          git fetch origin ${{ inputs.commit_sha || github.sha }}\n+          git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n \n       - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n         working-directory: /transformers\n@@ -174,7 +176,7 @@ jobs:\n \n   collated_reports:\n     name: Collated Reports\n-    if: ${{ always() }}\n+    if: ${{ always() && inputs.runner_type != '' }}\n     needs: run_models_gpu\n     uses: huggingface/transformers/.github/workflows/collated-reports.yml@main\n     with:"
        },
        {
            "sha": "60d63851da1826ca5fdcd1e7b0a992cf0cc2de48",
            "filename": ".github/workflows/push-important-models.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8fb854cac869b42c87a7bd15d9298985c5aea96e/.github%2Fworkflows%2Fpush-important-models.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/8fb854cac869b42c87a7bd15d9298985c5aea96e/.github%2Fworkflows%2Fpush-important-models.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fpush-important-models.yml?ref=8fb854cac869b42c87a7bd15d9298985c5aea96e",
            "patch": "@@ -153,5 +153,5 @@ jobs:\n       ci_event: push\n       report_repo_id: hf-internal-testing/transformers_ci_push\n       commit_sha: ${{ github.sha }}\n-      models: ${{ needs.get_modified_models.outputs.matrix }}\n+      subdirs: ${{ needs.get_modified_models.outputs.matrix }}\n     secrets: inherit"
        },
        {
            "sha": "ab0ab412bb590d2e3c8f21835dec5c8082331990",
            "filename": ".github/workflows/self-comment-ci.yml",
            "status": "modified",
            "additions": 203,
            "deletions": 280,
            "changes": 483,
            "blob_url": "https://github.com/huggingface/transformers/blob/8fb854cac869b42c87a7bd15d9298985c5aea96e/.github%2Fworkflows%2Fself-comment-ci.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/8fb854cac869b42c87a7bd15d9298985c5aea96e/.github%2Fworkflows%2Fself-comment-ci.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-comment-ci.yml?ref=8fb854cac869b42c87a7bd15d9298985c5aea96e",
            "patch": "@@ -23,62 +23,34 @@ env:\n   TF_FORCE_GPU_ALLOW_GROWTH: true\n   CUDA_VISIBLE_DEVICES: 0,1\n \n+\n jobs:\n   get-pr-number:\n-    runs-on: ubuntu-22.04\n     name: Get PR number\n-    # For security: only allow team members to run\n     if: ${{ github.event.issue.state == 'open' && contains(fromJSON('[\"ydshieh\", \"ArthurZucker\", \"zucchini-nlp\", \"molbap\", \"gante\", \"LysandreJik\", \"Cyrilvallez\", \"Rocketknight1\", \"SunMarc\", \"eustlb\", \"MekkCyber\", \"vasqu\", \"ivarflakstad\", \"stevhliu\", \"ebezzam\", \"remi-or\", \"itazap\"]'), github.actor) && (startsWith(github.event.comment.body, 'run-slow') || startsWith(github.event.comment.body, 'run slow') || startsWith(github.event.comment.body, 'run_slow')) }}\n-    outputs:\n-      PR_NUMBER: ${{ steps.set_pr_number.outputs.PR_NUMBER }}\n-    steps:\n-      - name: Get PR number\n-        shell: bash\n-        run: |\n-          if [[ \"${{ github.event.issue.number }}\" != \"\" && \"${{ github.event.issue.pull_request }}\" != \"\" ]]; then\n-            echo \"PR_NUMBER=${{ github.event.issue.number }}\" >> $GITHUB_ENV\n-          else\n-            echo \"PR_NUMBER=\" >> $GITHUB_ENV\n-          fi\n-\n-      - name: Check PR number\n-        shell: bash\n-        run: |\n-          echo \"${{ env.PR_NUMBER }}\"\n-\n-      - name: Set PR number\n-        id: set_pr_number\n-        run: echo \"PR_NUMBER=${{ env.PR_NUMBER }}\" >> \"$GITHUB_OUTPUT\"\n+    uses: ./.github/workflows/get-pr-number.yml\n \n-  get-sha:\n-    runs-on: ubuntu-22.04\n+  get-pr-info:\n+    name: Get PR commit SHA\n     needs: get-pr-number\n     if: ${{ needs.get-pr-number.outputs.PR_NUMBER != ''}}\n+    uses: ./.github/workflows/get-pr-info.yml\n+    with:\n+      pr_number: ${{ needs.get-pr-number.outputs.PR_NUMBER }}\n+\n+  check-timestamps:\n+    name: Check timestamps (security check)\n+    runs-on: ubuntu-22.04\n+    needs: get-pr-info\n     outputs:\n-      PR_HEAD_SHA: ${{ steps.get_sha.outputs.PR_HEAD_SHA }}\n-      PR_MERGE_SHA: ${{ steps.get_sha.outputs.PR_MERGE_SHA }}\n+      PR_HEAD_SHA: ${{ needs.get-pr-info.outputs.PR_HEAD_SHA }}\n+      PR_MERGE_SHA: ${{ needs.get-pr-info.outputs.PR_MERGE_COMMIT_SHA }}\n     steps:\n-      - uses: actions/checkout@v4\n-        with:\n-          fetch-depth: \"0\"\n-          ref: \"refs/pull/${{needs.get-pr-number.outputs.PR_NUMBER}}/merge\"\n-\n-      - name: Get SHA (and verify timestamps against the issue comment date)\n-        id: get_sha\n+      - name: Verify `merge_commit` timestamp is older than the issue comment timestamp\n         env:\n-          PR_NUMBER: ${{ needs.get-pr-number.outputs.PR_NUMBER }}\n           COMMENT_DATE: ${{ github.event.comment.created_at }}\n+          PR_MERGE_COMMIT_TIMESTAMP: ${{ needs.get-pr-info.outputs.PR_MERGE_COMMIT_TIMESTAMP }}\n         run: |\n-            git fetch origin refs/pull/$PR_NUMBER/head:refs/remotes/pull/$PR_NUMBER/head\n-            git checkout refs/remotes/pull/$PR_NUMBER/head\n-            echo \"PR_HEAD_SHA: $(git log -1 --format=%H)\"\n-            echo \"PR_HEAD_SHA=$(git log -1 --format=%H)\" >> \"$GITHUB_OUTPUT\"\n-            git fetch origin refs/pull/$PR_NUMBER/merge:refs/remotes/pull/$PR_NUMBER/merge\n-            git checkout refs/remotes/pull/$PR_NUMBER/merge\n-            echo \"PR_MERGE_SHA: $(git log -1 --format=%H)\"\n-            echo \"PR_MERGE_SHA=$(git log -1 --format=%H)\" >> \"$GITHUB_OUTPUT\"\n-            PR_MERGE_COMMIT_TIMESTAMP=$(git log -1 --date=unix --format=%cd)\n-            echo \"PR_MERGE_COMMIT_TIMESTAMP: $PR_MERGE_COMMIT_TIMESTAMP\"\n             COMMENT_TIMESTAMP=$(date -d \"${COMMENT_DATE}\" +\"%s\")\n             echo \"COMMENT_DATE: $COMMENT_DATE\"\n             echo \"COMMENT_TIMESTAMP: $COMMENT_TIMESTAMP\"\n@@ -87,25 +59,22 @@ jobs:\n               exit -1;\n             fi\n \n-  # use a python script to handle this complex logic\n-  # case 1: `run-slow` (auto. infer with limited number of models, but in particular, new model)\n-  # case 2: `run-slow model_1, model_2`\n+  # use a python script to handle this complex logic.\n   get-tests:\n     runs-on: ubuntu-22.04\n-    needs: [get-pr-number, get-sha]\n-    if: ${{ needs.get-pr-number.outputs.PR_NUMBER != ''}}\n+    needs: [get-pr-number, check-timestamps]\n     outputs:\n       models: ${{ steps.models_to_run.outputs.models }}\n       quantizations: ${{ steps.models_to_run.outputs.quantizations }}\n     steps:\n       - uses: actions/checkout@v4\n         with:\n           fetch-depth: \"0\"\n-          ref: \"refs/pull/${{needs.get-pr-number.outputs.PR_NUMBER}}/merge\"\n+          ref: \"refs/pull/${{ needs.get-pr-number.outputs.PR_NUMBER }}/merge\"\n \n       - name: Verify merge commit SHA\n         env:\n-          VERIFIED_PR_MERGE_SHA: ${{ needs.get-sha.outputs.PR_MERGE_SHA }}\n+          VERIFIED_PR_MERGE_SHA: ${{ needs.check-timestamps.outputs.PR_MERGE_SHA }}\n         run: |\n             PR_MERGE_SHA=$(git log -1 --format=%H)\n             if [ $PR_MERGE_SHA != $VERIFIED_PR_MERGE_SHA ]; then\n@@ -119,19 +88,39 @@ jobs:\n         run: |\n           python -m pip install GitPython\n           python utils/pr_slow_ci_models.py --message \"$PR_COMMENT\" | tee output.txt\n-          echo \"models=$(tail -n 1 output.txt)\" >> $GITHUB_ENV\n+          echo 'models=$(tail -n 1 output.txt)' >> $GITHUB_ENV\n           python utils/pr_slow_ci_models.py --message \"$PR_COMMENT\" --quantization | tee output2.txt\n-          echo \"quantizations=$(tail -n 1 output2.txt)\" >> $GITHUB_ENV\n+          echo 'quantizations=$(tail -n 1 output2.txt)' >> $GITHUB_ENV\n \n       - name: Show models to test\n         id: models_to_run\n         run: |\n           echo \"${{ env.models }}\"\n-          echo \"models=${{ env.models }}\" >> $GITHUB_ENV\n           echo \"models=${{ env.models }}\" >> $GITHUB_OUTPUT\n           echo \"${{ env.quantizations }}\"\n           echo \"quantizations=${{ env.quantizations }}\" >> $GITHUB_OUTPUT\n \n+  # Report back if we are not able to get the tests (for example, security check is failing)\n+  report_error_earlier:\n+    name: Report error earlier\n+    if: ${{ always() && needs.get-pr-info.result == 'success' && needs.get-tests.result != 'success' }}\n+    needs: [get-pr-number, get-pr-info, get-tests]\n+    permissions:\n+      pull-requests: write\n+    runs-on: ubuntu-22.04\n+    steps:\n+      - name: Reply to the comment\n+        env:\n+          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n+          GITHUB_RUN_URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\n+        run: |\n+          gh api \\\n+            --method POST \\\n+            -H \"Accept: application/vnd.github+json\" \\\n+            -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n+            repos/${{ github.repository }}/issues/${{ needs.get-pr-number.outputs.PR_NUMBER }}/comments \\\n+            -f body=\"ðŸ’” This comment contains \\`run-slow\\`, but unknown error occurred and [the workflow run]($GITHUB_RUN_URL) aborted!\"\n+\n   reply_to_comment:\n     name: Reply to the comment\n     if: ${{ needs.get-tests.outputs.models != '[]'  || needs.get-tests.outputs.quantizations != '[]' }}\n@@ -143,20 +132,18 @@ jobs:\n       - name: Reply to the comment\n         env:\n           GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n-          MODELS: ${{ needs.get-tests.outputs.models }}\n-          BODY: \"\\n\\nmodels: ${{ needs.get-tests.outputs.models }}\\nquantizations: ${{ needs.get-tests.outputs.quantizations }}\"\n+          BODY: '\\n\\nmodels: ${{ needs.get-tests.outputs.models }}\\nquantizations: ${{ needs.get-tests.outputs.quantizations }}'\n         run: |\n           gh api \\\n             --method POST \\\n             -H \"Accept: application/vnd.github+json\" \\\n             -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n             repos/${{ github.repository }}/issues/${{ needs.get-pr-number.outputs.PR_NUMBER }}/comments \\\n-            -f \"body=This comment contains run-slow, running the specified jobs: ${{ env.BODY }} ...\"\n+            -f body=\"This comment contains \\`run-slow\\`, running the specified jobs: $(echo -e '${{ env.BODY }}')\"\n \n   create_run:\n     name: Create run\n-    if: ${{ needs.get-tests.outputs.models != '[]' || needs.get-tests.outputs.quantizations != '[]' }}\n-    needs: [get-sha, get-tests, reply_to_comment]\n+    needs: [check-timestamps, reply_to_comment]\n     permissions:\n       statuses: write\n     runs-on: ubuntu-22.04\n@@ -173,243 +160,179 @@ jobs:\n             --method POST \\\n             -H \"Accept: application/vnd.github+json\" \\\n             -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n-            repos/${{ github.repository }}/statuses/${{ needs.get-sha.outputs.PR_HEAD_SHA }} \\\n+            repos/${{ github.repository }}/statuses/${{ needs.check-timestamps.outputs.PR_HEAD_SHA }} \\\n             -f \"target_url=$GITHUB_RUN_URL\" -f \"state=pending\" -f \"description=Slow CI job\" -f \"context=pytest/custom-tests\"\n \n-  run_models_gpu:\n-    name: Run all tests for the model\n+  model-ci:\n+    name: Model CI\n     if: ${{ needs.get-tests.outputs.models != '[]' }}\n-    needs: [get-pr-number, get-sha, get-tests, create_run]\n-    strategy:\n-      fail-fast: false\n-      matrix:\n-        folders: ${{ fromJson(needs.get-tests.outputs.models) }}\n-        machine_type: [aws-g5-4xlarge-cache, aws-g5-12xlarge-cache]\n-    runs-on:\n-       group: '${{ matrix.machine_type }}'\n-    container:\n-      image: huggingface/transformers-all-latest-gpu\n-      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n-    steps:\n-      - name: Echo input and matrix info\n-        shell: bash\n-        run: |\n-          echo \"${{ matrix.folders }}\"\n-\n-      - name: Echo folder ${{ matrix.folders }}\n-        shell: bash\n-        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n-        # set the artifact folder names (because the character `/` is not allowed).\n-        run: |\n-          echo \"${{ matrix.folders }}\"\n-          matrix_folders=${{ matrix.folders }}\n-          matrix_folders=${matrix_folders/'models/'/'models_'}\n-          echo \"$matrix_folders\"\n-          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n-\n-      - name: Checkout to PR merge commit\n-        working-directory: /transformers\n-        run: |\n-          git fetch origin refs/pull/${{ needs.get-pr-number.outputs.PR_NUMBER }}/merge:refs/remotes/pull/${{ needs.get-pr-number.outputs.PR_NUMBER }}/merge\n-          git checkout refs/remotes/pull/${{ needs.get-pr-number.outputs.PR_NUMBER }}/merge\n-          git log -1 --format=%H\n-\n-      - name: Verify merge commit SHA\n-        env:\n-          VERIFIED_PR_MERGE_SHA: ${{ needs.get-sha.outputs.PR_MERGE_SHA }}\n-        working-directory: /transformers\n-        run: |\n-          PR_MERGE_SHA=$(git log -1 --format=%H)\n-          if [ $PR_MERGE_SHA != $VERIFIED_PR_MERGE_SHA ]; then\n-            echo \"The merged commit SHA is not the same as the verified one! Security issue detected, abort the workflow!\";\n-            exit -1;\n-          fi\n-\n-      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n-        working-directory: /transformers\n-        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n-\n-      - name: NVIDIA-SMI\n-        run: |\n-          nvidia-smi\n-\n-      - name: Set `machine_type` for report and artifact names\n-        working-directory: /transformers\n-        shell: bash\n-        run: |\n-          echo \"${{ matrix.machine_type }}\"\n-          if [ \"${{ matrix.machine_type }}\" = \"aws-g5-4xlarge-cache\" ]; then\n-            machine_type=single-gpu\n-          elif [ \"${{ matrix.machine_type }}\" = \"aws-g5-12xlarge-cache\" ]; then\n-            machine_type=multi-gpu\n-          else\n-            machine_type=${{ matrix.machine_type }}\n-          fi\n-          echo \"$machine_type\"\n-          echo \"machine_type=$machine_type\" >> $GITHUB_ENV\n-\n-      - name: Environment\n-        working-directory: /transformers\n-        run: |\n-          python3 utils/print_env.py\n-\n-      - name: Show installed libraries and their versions\n-        working-directory: /transformers\n-        run: pip freeze\n-\n-      - name: Run all tests on GPU\n-        working-directory: /transformers\n-        run: |\n-          export CUDA_VISIBLE_DEVICES=\"$(python3 utils/set_cuda_devices_for_ci.py --test_folder ${{ matrix.folders }})\"\n-          echo $CUDA_VISIBLE_DEVICES\n-          python3 -m pytest -v -rsfE --make-reports=${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports tests/${{ matrix.folders }}\n-\n-      - name: Failure short reports\n-        if: ${{ failure() }}\n-        continue-on-error: true\n-        run: cat /transformers/reports/${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports/failures_short.txt\n-\n-      - name: Make sure report directory exists\n-        shell: bash\n-        run: |\n-          mkdir -p /transformers/reports/${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports\n-          echo \"hello\" > /transformers/reports/${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports/hello.txt\n-          echo \"${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports\"\n-\n-      - name: \"Test suite reports artifacts: ${{ env.machine_type }}_run_models_gpu_${{ env.matrix_folders }}_test_reports\"\n-        if: ${{ always() }}\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: ${{ env.machine_type }}_run_models_gpu_${{ env.matrix_folders }}_test_reports\n-          path: /transformers/reports/${{ env.machine_type }}_run_models_gpu_${{ matrix.folders }}_test_reports\n-\n-  run_quantization_torch_gpu:\n-    name: Run all tests for a quantization\n+    uses: ./.github/workflows/self-scheduled.yml\n+    needs: [get-pr-number, check-timestamps, get-tests, create_run]\n+    with:\n+      job: run_models_gpu\n+      slack_report_channel: \"#transformers-ci-pr\"\n+      docker: huggingface/transformers-all-latest-gpu\n+      ci_event: PR Comment CI\n+      report_repo_id: hf-internal-testing/transformers_pr_ci\n+      commit_sha: ${{ needs.check-timestamps.outputs.PR_MERGE_SHA }}\n+      subdirs: ${{ needs.get-tests.outputs.models }}\n+      pr_number: ${{ needs.get-pr-number.outputs.PR_NUMBER }}\n+    secrets: inherit\n+\n+  quantization-ci:\n+    name: Quantization CI\n     if: ${{ needs.get-tests.outputs.quantizations != '[]' }}\n-    needs: [get-pr-number, get-sha, get-tests, create_run]\n-    strategy:\n-      fail-fast: false\n-      matrix:\n-        folders: ${{ fromJson(needs.get-tests.outputs.quantizations) }}\n-        machine_type: [aws-g5-4xlarge-cache, aws-g5-12xlarge-cache]\n-    runs-on:\n-      group: '${{ matrix.machine_type }}'\n-    container:\n-      image: huggingface/transformers-quantization-latest-gpu\n-      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n+    uses: ./.github/workflows/self-scheduled.yml\n+    needs: [get-pr-number, check-timestamps, get-tests, create_run]\n+    with:\n+      job: run_quantization_torch_gpu\n+      slack_report_channel: \"#transformers-ci-pr\"\n+      docker: huggingface/transformers-quantization-latest-gpu\n+      ci_event: PR Comment CI\n+      report_repo_id: hf-internal-testing/transformers_pr_ci\n+      commit_sha: ${{ needs.check-timestamps.outputs.PR_MERGE_SHA }}\n+      subdirs: ${{ needs.get-tests.outputs.quantizations }}\n+      pr_number: ${{ needs.get-pr-number.outputs.PR_NUMBER }}\n+    secrets: inherit\n+\n+  report:\n+    name: Check & Report\n+    needs: [get-pr-number, check-timestamps, create_run, model-ci, quantization-ci]\n+    permissions:\n+      pull-requests: write\n+      statuses: write\n+    if: ${{ always() && needs.create_run.result == 'success' }}\n+    runs-on: ubuntu-22.04\n     steps:\n-      - name: Echo folder ${{ matrix.folders }}\n-        shell: bash\n-        run: |\n-          echo \"${{ matrix.folders }}\"\n-          matrix_folders=${{ matrix.folders }}\n-          matrix_folders=${matrix_folders/'quantization/'/'quantization_'}\n-          echo \"$matrix_folders\"\n-          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n-\n-      - name: Checkout to PR merge commit\n-        working-directory: /transformers\n+      - name: Show reports from jobs\n         run: |\n-          git fetch origin refs/pull/${{ needs.get-pr-number.outputs.PR_NUMBER }}/merge:refs/remotes/pull/${{ needs.get-pr-number.outputs.PR_NUMBER }}/merge\n-          git checkout refs/remotes/pull/${{ needs.get-pr-number.outputs.PR_NUMBER }}/merge\n-          git log -1 --format=%H\n+          echo \"${{ needs.model-ci.outputs.report }}\"\n+          echo \"${{ needs.quantization-ci.outputs.report }}\"\n \n-      - name: Verify merge commit SHA\n+      - name: Process and filter reports\n         env:\n-          VERIFIED_PR_MERGE_SHA: ${{ needs.get-sha.outputs.PR_MERGE_SHA }}\n-        working-directory: /transformers\n-        run: |\n-          PR_MERGE_SHA=$(git log -1 --format=%H)\n-          if [ $PR_MERGE_SHA != $VERIFIED_PR_MERGE_SHA ]; then\n-            echo \"The merged commit SHA is not the same as the verified one! Security issue detected, abort the workflow!\";\n-            exit -1;\n-          fi\n-\n-      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n-        working-directory: /transformers\n-        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n-      - name: NVIDIA-SMI\n-        run: |\n-          nvidia-smi\n-\n-      - name: Set `machine_type` for report and artifact names\n-        working-directory: /transformers\n-        shell: bash\n-        run: |\n-          echo \"${{ matrix.machine_type }}\"\n-          if [ \"${{ matrix.machine_type }}\" = \"aws-g5-4xlarge-cache\" ]; then\n-            machine_type=single-gpu\n-          elif [ \"${{ matrix.machine_type }}\" = \"aws-g5-12xlarge-cache\" ]; then\n-            machine_type=multi-gpu\n-          else\n-            machine_type=${{ matrix.machine_type }}\n-          fi\n-          echo \"$machine_type\"\n-          echo \"machine_type=$machine_type\" >> $GITHUB_ENV\n-\n-      - name: Environment\n-        working-directory: /transformers\n-        run: |\n-          python3 utils/print_env.py\n-\n-      - name: Show installed libraries and their versions\n-        working-directory: /transformers\n-        run: pip freeze\n-\n-      - name: Run quantization tests on GPU\n-        working-directory: /transformers\n+          MODEL_REPORT: ${{ needs.model-ci.outputs.report }}\n+          QUANT_REPORT: ${{ needs.quantization-ci.outputs.report }}\n         run: |\n-          python3 -m pytest -v --make-reports=${{ env.machine_type }}_run_quantization_torch_gpu_${{ matrix.folders }}_test_reports tests/${{ matrix.folders }}\n-\n-      - name: Failure short reports\n-        if: ${{ failure() }}\n-        continue-on-error: true\n-        run: cat /transformers/reports/${{ env.machine_type }}_run_quantization_torch_gpu_${{ matrix.folders }}_test_reports/failures_short.txt\n-\n-      - name: Make sure report directory exists\n-        shell: bash\n+          # Preprocess with Python\n+          python3 << 'PYTHON_SCRIPT'\n+          import json\n+          import os\n+          \n+          def filter_and_format_report(data):\n+            \"\"\"\n+            Filter out entries where commit is `None` (failing tests who status is not certain) and format as text\n+            \"\"\"\n+            lines = []\n+            \n+            for model, model_result in data.items():\n+                model_lines = []\n+                for device, failures in model_result.items():\n+                    \n+                    # Filter out None commits and extract just the test names\n+                    test_names = [\n+                        failure['test'] \n+                        for failure in failures \n+                        if isinstance(failure, dict) and failure.get('commit') is not None\n+                    ]\n+\n+                    # Add tests to model lines\n+                    for idx, test_name in enumerate(test_names):\n+                        if idx == 0:\n+                            job_link = failures[idx]['job_link']\n+                            model_lines.append(f\"- [{model}]({job_link}):\")\n+          \n+                        model_lines.append(f\"    {test_name}\")\n+\n+                # Only add model section if it has tests\n+                if len(model_lines) > 0:\n+                    lines.extend(model_lines)\n+                    lines.append(\"\")  # Empty line between models\n+            \n+            return \"\\n\".join(lines).strip()\n+          \n+          # Load and filter reports\n+          model_report_str = os.environ.get('MODEL_REPORT', '{}')\n+          quant_report_str = os.environ.get('QUANT_REPORT', '{}')\n+          \n+          model_report = json.loads(model_report_str) if model_report_str else {}\n+          quant_report = json.loads(quant_report_str) if quant_report_str else {}\n+          \n+          formatted_model = filter_and_format_report(model_report)\n+          formatted_quant = filter_and_format_report(quant_report)\n+          \n+          # Write to files\n+          with open('model_ci.txt', 'w') as f:\n+              f.write(formatted_model)\n+              if formatted_model:\n+                  f.write('\\n')\n+          \n+          with open('quantization_ci.txt', 'w') as f:\n+              f.write(formatted_quant)\n+              if formatted_quant:\n+                  f.write('\\n')\n+          PYTHON_SCRIPT\n+\n+      - name: Post results as PR comment\n+        env:\n+          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n+          GITHUB_RUN_URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\n         run: |\n-          mkdir -p /transformers/reports/${{ env.machine_type }}_run_quantization_gpu_${{ matrix.folders }}_test_reports\n-          echo \"hello\" > /transformers/reports/${{ env.machine_type }}_run_quantization_gpu_${{ matrix.folders }}_test_reports/hello.txt\n-          echo \"${{ env.machine_type }}_run_quantization_gpu_${{ matrix.folders }}_test_reports\"\n-\n-      - name: \"Test suite reports artifacts: ${{ env.machine_type }}_run_quantization_torch_gpu_${{ env.matrix_folders }}_test_reports\"\n-        if: ${{ always() }}\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: ${{ env.machine_type }}_run_quantization_torch_gpu_${{ env.matrix_folders }}_test_reports\n-          path: /transformers/reports/${{ env.machine_type }}_run_quantization_torch_gpu_${{ matrix.folders }}_test_reports\n+          {\n+            echo '## CI Results'\n+            echo \"[Workflow Run âš™ï¸]($GITHUB_RUN_URL)\"\n+            echo ''\n+\n+            # Check if both jobs were skipped or cancelled\n+            if [[ \"${{ needs.model-ci.result }}\" == \"skipped\" || \"${{ needs.model-ci.result }}\" == \"cancelled\" ]] && \\\n+               [[ \"${{ needs.quantization-ci.result }}\" == \"skipped\" || \"${{ needs.quantization-ci.result }}\" == \"cancelled\" ]]; then\n+              echo 'âš ï¸ No test being reported (jobs are skipped or cancelled)!'\n+              echo \"STATUS=error\" >> $GITHUB_ENV\n+\n+            # Check if either file has content\n+            elif [ -s model_ci.txt ] || [ -s quantization_ci.txt ]; then\n+              echo \"STATUS=failure\" >> $GITHUB_ENV\n+\n+              # Check if model_ci.txt has content\n+              if [ -s model_ci.txt ]; then\n+                echo '### Model CI Report'\n+                echo ''\n+                echo '#### âŒ Failed tests'\n+                echo ''\n+                cat model_ci.txt\n+                echo ''\n+              fi\n+              \n+              # Check if quantization_ci.txt has content\n+              if [ -s quantization_ci.txt ]; then\n+                echo '### Quantization CI Report'\n+                echo ''\n+                echo '#### âŒ Failed tests'\n+                echo ''\n+                cat quantization_ci.txt\n+                echo ''\n+              fi\n+            else\n+              echo \"STATUS=success\" >> $GITHUB_ENV\n+              echo 'âœ… No failing test specific to this PR ðŸŽ‰ !'\n+            fi\n+          } > comment_body.txt\n \n-  update_run_status:\n-    name: Update Check Run Status\n-    needs: [get-sha, create_run, run_models_gpu, run_quantization_torch_gpu]\n-    permissions:\n-      statuses: write\n-    if: ${{ always() && needs.create_run.result == 'success' }}\n-    runs-on: ubuntu-22.04\n-    env:\n-      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n-      GITHUB_RUN_URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\n-      STATUS_OK: ${{ contains(fromJSON('[\"skipped\", \"success\"]'), needs.run_models_gpu.result) && contains(fromJSON('[\"skipped\", \"success\"]'), needs.run_quantization_torch_gpu.result) }}\n-    steps:\n-      - name: Get `run_models_gpu` job status\n-        run: |\n-          echo \"${{ needs.run_models_gpu.result }}\"\n-          echo \"${{ needs.run_quantization_torch_gpu.result }}\"\n-          echo $STATUS_OK\n-          if [ \"$STATUS_OK\" = \"true\" ]; then\n-            echo \"STATUS=success\" >> $GITHUB_ENV\n-          else\n-            echo \"STATUS=failure\" >> $GITHUB_ENV\n-          fi\n+          gh api \\\n+            --method POST \\\n+            -H \"Accept: application/vnd.github+json\" \\\n+            -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n+            repos/${{ github.repository }}/issues/${{ needs.get-pr-number.outputs.PR_NUMBER }}/comments \\\n+            -F body=@comment_body.txt\n \n       - name: Update PR commit statuses\n+        env:\n+          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n+          GITHUB_RUN_URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\n         run: |\n-          echo \"${{ needs.run_models_gpu.result }}\"\n-          echo \"${{ env.STATUS }}\"\n           gh api \\\n             --method POST \\\n             -H \"Accept: application/vnd.github+json\" \\\n             -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n-            repos/${{ github.repository }}/statuses/${{ needs.get-sha.outputs.PR_HEAD_SHA }} \\\n+            repos/${{ github.repository }}/statuses/${{ needs.check-timestamps.outputs.PR_HEAD_SHA }} \\\n             -f \"target_url=$GITHUB_RUN_URL\" -f \"state=${{ env.STATUS }}\" -f \"description=Slow CI job\" -f \"context=pytest/custom-tests\""
        },
        {
            "sha": "d58d927bb59b1b60d12b9125cb5a3d6b026f237b",
            "filename": ".github/workflows/self-nightly-caller.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/8fb854cac869b42c87a7bd15d9298985c5aea96e/.github%2Fworkflows%2Fself-nightly-caller.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/8fb854cac869b42c87a7bd15d9298985c5aea96e/.github%2Fworkflows%2Fself-nightly-caller.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-nightly-caller.yml?ref=8fb854cac869b42c87a7bd15d9298985c5aea96e",
            "patch": "@@ -51,6 +51,7 @@ jobs:\n       slack_report_channel: \"#transformers-ci-past-future\"\n       docker: huggingface/transformers-all-latest-torch-nightly-gpu\n       ci_event: Nightly CI\n+      runner_type: \"a10\"\n       report_repo_id: hf-internal-testing/transformers_daily_ci_with_torch_nightly\n       commit_sha: ${{ github.event.workflow_run.head_sha || github.sha }}\n     secrets: inherit"
        },
        {
            "sha": "d3de9b70e87c12d8c70e293df0f433c4a05c2362",
            "filename": ".github/workflows/self-scheduled.yml",
            "status": "modified",
            "additions": 14,
            "deletions": 6,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/8fb854cac869b42c87a7bd15d9298985c5aea96e/.github%2Fworkflows%2Fself-scheduled.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/8fb854cac869b42c87a7bd15d9298985c5aea96e/.github%2Fworkflows%2Fself-scheduled.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fself-scheduled.yml?ref=8fb854cac869b42c87a7bd15d9298985c5aea96e",
            "patch": "@@ -34,14 +34,20 @@ on:\n       runner_type:\n         required: false\n         type: string\n-      models:\n+      subdirs:\n         default: \"\"\n         required: false\n         type: string\n       pytest_marker:\n         required: false\n         type: string\n-\n+      pr_number:\n+        required: false\n+        type: string\n+    outputs:\n+      report:\n+        description: \"Content of the report of new failures\"\n+        value: ${{ jobs.check_new_failures.outputs.report }}\n \n env:\n   HF_HOME: /mnt/cache\n@@ -76,6 +82,7 @@ jobs:\n       - name: Update clone\n         working-directory: /transformers\n         run: |\n+          git fetch origin ${{ inputs.commit_sha || github.sha }}\n           git fetch && git checkout ${{ inputs.commit_sha || github.sha }}\n \n       - name: Cleanup\n@@ -95,7 +102,7 @@ jobs:\n         working-directory: /transformers/tests\n         run: |\n           if [ \"${{ inputs.job }}\" = \"run_models_gpu\" ]; then\n-            echo \"folder_slices=$(python3 ../utils/split_model_tests.py --models '${{ inputs.models }}' --num_splits ${{ env.NUM_SLICES }})\" >> $GITHUB_OUTPUT\n+            echo \"folder_slices=$(python3 ../utils/split_model_tests.py --subdirs '${{ inputs.subdirs }}' --num_splits ${{ env.NUM_SLICES }})\" >> $GITHUB_OUTPUT\n             echo \"slice_ids=$(python3 -c 'd = list(range(${{ env.NUM_SLICES }})); print(d)')\" >> $GITHUB_OUTPUT\n           elif [ \"${{ inputs.job }}\" = \"run_trainer_and_fsdp_gpu\" ]; then\n             echo \"folder_slices=[['trainer'], ['fsdp']]\" >> $GITHUB_OUTPUT\n@@ -107,7 +114,7 @@ jobs:\n         name: Identify quantization method to test\n         working-directory: /transformers/tests\n         run: |\n-          echo \"quantization_matrix=$(python3 -c 'import os; tests = os.getcwd(); quantization_tests = os.listdir(os.path.join(tests, \"quantization\")); d = sorted(list(filter(os.path.isdir, [f\"quantization/{x}\" for x in quantization_tests]))) ;  print(d)')\" >> $GITHUB_OUTPUT\n+          echo \"quantization_matrix=$(python3 -c 'import ast; import os; tests = os.getcwd(); quantization_tests = os.listdir(os.path.join(tests, \"quantization\")); subdirs = ast.literal_eval(${{ inputs.subdirs || '\"None\"' }}); quantization_tests = [x.removeprefix(\"quantization/\") for x in subdirs] if subdirs is not None else quantization_tests; d = sorted(list(filter(os.path.isdir, [f\"quantization/{x}\" for x in quantization_tests]))) ;  print(d)')\" >> $GITHUB_OUTPUT\n \n       - name: NVIDIA-SMI\n         run: |\n@@ -539,16 +546,17 @@ jobs:\n     secrets: inherit\n \n   check_new_failures:\n-    if: ${{ always() && inputs.ci_event == 'Daily CI' && needs.send_results.result == 'success' }}\n+    if: ${{ always() && needs.send_results.result == 'success' }}\n     name: Check new failures\n     needs: send_results\n     uses: ./.github/workflows/check_failed_tests.yml\n     with:\n       docker: ${{ inputs.docker }}\n-      start_sha: ${{ inputs.commit_sha || github.sha }}\n+      commit_sha: ${{ inputs.commit_sha || github.sha }}\n       job: ${{ inputs.job }}\n       slack_report_channel: ${{ inputs.slack_report_channel }}\n       ci_event: ${{ inputs.ci_event }}\n       report_repo_id: ${{ inputs.report_repo_id }}\n+      pr_number: ${{ inputs.pr_number }}\n \n     secrets: inherit"
        },
        {
            "sha": "48bbec64819df4be5639854d7870cd0ff9490437",
            "filename": "utils/check_bad_commit.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8fb854cac869b42c87a7bd15d9298985c5aea96e/utils%2Fcheck_bad_commit.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8fb854cac869b42c87a7bd15d9298985c5aea96e/utils%2Fcheck_bad_commit.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_bad_commit.py?ref=8fb854cac869b42c87a7bd15d9298985c5aea96e",
            "patch": "@@ -151,7 +151,7 @@ def find_bad_commit(target_test, start_commit, end_commit):\n \n     bash = f\"\"\"\n git bisect reset\n-git bisect start {start_commit} {end_commit}\n+git bisect start --first-parent {start_commit} {end_commit}\n git bisect run python3 target_script.py\n \"\"\"\n "
        },
        {
            "sha": "be6f488165c4b9b196e2a70b6984b699a09586e0",
            "filename": "utils/notification_service.py",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/8fb854cac869b42c87a7bd15d9298985c5aea96e/utils%2Fnotification_service.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8fb854cac869b42c87a7bd15d9298985c5aea96e/utils%2Fnotification_service.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fnotification_service.py?ref=8fb854cac869b42c87a7bd15d9298985c5aea96e",
            "patch": "@@ -1521,6 +1521,16 @@ def pop_default(l: list[Any], i: int, default: Any) -> Any:\n                 token=os.environ[\"ACCESS_REPO_INFO_TOKEN\"], workflow_id=other_workflow_id, commit_sha=ci_sha\n             )\n             other_workflow_run_ids.append(other_workflow_run_id)\n+    # triggered via `issue_comment` for CI on pull requests (e.g. using the comment `run-slow:`)\n+    elif os.environ.get(\"GITHUB_EVENT_NAME\") in [\"issue_comment\"]:\n+        # TODO (ydshieh): Make this flexible once we implement `run-slow` for AMD CI and others.\n+        # The id of the workflow `.github/workflows/self-scheduled-caller.yml` (not of a workflow run of it).\n+        prev_workflow_id = \"90575235\"\n+        # TODO (ydshieh): It's better to make sure using the last completed scheduled workflow run with the commit being a parent\n+        #  of the PR's `merge_commit`.\n+        prev_workflow_run_id = get_last_daily_ci_workflow_run_id(\n+            token=os.environ[\"ACCESS_REPO_INFO_TOKEN\"], workflow_id=prev_workflow_id\n+        )\n     else:\n         prev_workflow_run_id = os.environ[\"PREV_WORKFLOW_RUN_ID\"]\n         other_workflow_run_id = os.environ[\"OTHER_WORKFLOW_RUN_ID\"]"
        },
        {
            "sha": "0ac7ceeb70de87047bf40ad31bfae1932f4334b5",
            "filename": "utils/pr_slow_ci_models.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/8fb854cac869b42c87a7bd15d9298985c5aea96e/utils%2Fpr_slow_ci_models.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8fb854cac869b42c87a7bd15d9298985c5aea96e/utils%2Fpr_slow_ci_models.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fpr_slow_ci_models.py?ref=8fb854cac869b42c87a7bd15d9298985c5aea96e",
            "patch": "@@ -27,6 +27,7 @@\n \"\"\"\n \n import argparse\n+import json\n import os.path\n import re\n import string\n@@ -169,4 +170,6 @@ def check_model_names(model_name: str):\n         elif os.path.isdir(f\"tests/quantization/{model}\"):\n             final_list.append(f\"quantization/{model}\")\n \n-    print(sorted(set(final_list)))\n+    # Use `json.dumps` to get the double quotes instead of single quote, e.g. `[\"model/vit\"]`.\n+    # (to avoid some shell expansion issues when this script is called from a Github Actions workflow)\n+    print(json.dumps(sorted(set(final_list))))"
        },
        {
            "sha": "43bcecadc0828a1796540816cf55d02240082806",
            "filename": "utils/process_bad_commit_report.py",
            "status": "modified",
            "additions": 19,
            "deletions": 15,
            "changes": 34,
            "blob_url": "https://github.com/huggingface/transformers/blob/8fb854cac869b42c87a7bd15d9298985c5aea96e/utils%2Fprocess_bad_commit_report.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8fb854cac869b42c87a7bd15d9298985c5aea96e/utils%2Fprocess_bad_commit_report.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fprocess_bad_commit_report.py?ref=8fb854cac869b42c87a7bd15d9298985c5aea96e",
            "patch": "@@ -45,6 +45,25 @@\n \n     report_repo_id = os.getenv(\"REPORT_REPO_ID\")\n \n+    with open(\"new_failures_with_bad_commit.json\") as fp:\n+        data = json.load(fp)\n+\n+    with open(f\"ci_results_{job_name}/job_links.json\") as fp:\n+        job_links = json.load(fp)\n+\n+    # Update `new_failures_with_bad_commit.json` with job links information before uploading to Hub repository\n+    #   - need to change `single-gpu` to `single` and same for `multi-gpu` to match the keys in `job_link`.\n+    for model, model_result in data.items():\n+        for device, failed_tests in model_result.items():\n+            for failed_test in failed_tests:\n+                key = model\n+                if list(job_links.keys()) == [job_name]:\n+                    key = job_name\n+                failed_test[\"job_link\"] = job_links[key][device.replace(\"-gpu\", \"\")]\n+\n+    with open(\"new_failures_with_bad_commit.json\", \"w\") as fp:\n+        json.dump(data, fp, indent=4, ensure_ascii=False)\n+\n     commit_info = api.upload_file(\n         path_or_fileobj=\"new_failures_with_bad_commit.json\",\n         path_in_repo=f\"{report_repo_folder}/ci_results_{job_name}/new_failures_with_bad_commit.json\",\n@@ -53,12 +72,6 @@\n         token=os.environ.get(\"TRANSFORMERS_CI_RESULTS_UPLOAD_TOKEN\", None),\n     )\n \n-    with open(\"new_failures_with_bad_commit.json\") as fp:\n-        data = json.load(fp)\n-\n-    with open(f\"ci_results_{job_name}/job_links.json\") as fp:\n-        job_links = json.load(fp)\n-\n     # TODO: extend\n     team_members = [\n         \"ArthurZucker\",\n@@ -101,16 +114,7 @@\n     for author, _data in new_data_full.items():\n         for model, model_result in _data.items():\n             for device, failed_tests in model_result.items():\n-                # prepare job_link and add it to each entry of new failed test information.\n-                # need to change from `single-gpu` to `single` and same for `multi-gpu` to match `job_link`.\n-                key = model\n-                if list(job_links.keys()) == [job_name]:\n-                    key = job_name\n-                job_link = job_links[key][device.replace(\"-gpu\", \"\")]\n-\n                 failed_tests = [x for x in failed_tests if x[\"author\"] == author or x[\"merged_by\"] == author]\n-                for x in failed_tests:\n-                    x.update({\"job_link\": job_link})\n                 model_result[device] = failed_tests\n             _data[model] = {k: v for k, v in model_result.items() if len(v) > 0}\n         new_data_full[author] = {k: v for k, v in _data.items() if len(v) > 0}"
        },
        {
            "sha": "344dc5449f3569db9252178602c14922776f371b",
            "filename": "utils/split_model_tests.py",
            "status": "modified",
            "additions": 14,
            "deletions": 5,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/8fb854cac869b42c87a7bd15d9298985c5aea96e/utils%2Fsplit_model_tests.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8fb854cac869b42c87a7bd15d9298985c5aea96e/utils%2Fsplit_model_tests.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fsplit_model_tests.py?ref=8fb854cac869b42c87a7bd15d9298985c5aea96e",
            "patch": "@@ -40,10 +40,10 @@\n if __name__ == \"__main__\":\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\n-        \"--models\",\n+        \"--subdirs\",\n         type=str,\n         default=\"\",\n-        help=\"the list of pre-computed model names.\",\n+        help=\"the list of pre-computed model names (directory names under `tests/models`) or directory names under `tests` (except `models`).\",\n     )\n     parser.add_argument(\n         \"--num_splits\",\n@@ -60,9 +60,18 @@\n     d1.remove(\"models\")\n     d = d2 + d1\n \n-    if args.models != \"\":\n-        model_tests = ast.literal_eval(args.models)\n-        d = sorted(filter(os.path.isdir, [f\"models/{x}\" for x in model_tests]))\n+    if args.subdirs != \"\":\n+        model_tests = ast.literal_eval(args.subdirs)\n+        # We handle both cases with and without prefix because `push-important-models.yml` returns the list without\n+        # the prefix (i.e. `models`) but `utils/pr_slow_ci_models.py` (called by `self-comment-ci.yml`) returns the\n+        # list with the prefix (`models`) and some directory names under `tests`.\n+        d = []\n+        for x in model_tests:\n+            if os.path.isdir(x):\n+                d.append(x)\n+            if os.path.isdir(f\"models/{x}\"):\n+                d.append(f\"models/{x}\")\n+        d = sorted(d)\n \n     num_jobs = len(d)\n     num_jobs_per_splits = num_jobs // args.num_splits"
        }
    ],
    "stats": {
        "total": 694,
        "additions": 355,
        "deletions": 339
    }
}