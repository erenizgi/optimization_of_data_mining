{
    "author": "vrnvu",
    "message": "removes decord  (#33987)\n\n* removes decord dependency\r\n\r\noptimize\r\n\r\nnp\r\n\r\nRevert \"optimize\"\r\n\r\nThis reverts commit faa136b51ec4ec5858e5b0ae40eb7ef89a88b475.\r\n\r\nhelpers as documentation\r\n\r\npydoc\r\n\r\nmissing keys\r\n\r\n* make fixup\r\n\r\n* require_av\r\n\r\n---------\r\n\r\nCo-authored-by: ad <hi@arnaudiaz.com>",
    "sha": "7f5088503fb440cb3bb2d610f892e2ee547982b3",
    "files": [
        {
            "sha": "08e37ea6e1292f624dacdb525489469bad30fe8e",
            "filename": "docker/transformers-all-latest-gpu/Dockerfile",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/7f5088503fb440cb3bb2d610f892e2ee547982b3/docker%2Ftransformers-all-latest-gpu%2FDockerfile",
            "raw_url": "https://github.com/huggingface/transformers/raw/7f5088503fb440cb3bb2d610f892e2ee547982b3/docker%2Ftransformers-all-latest-gpu%2FDockerfile",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docker%2Ftransformers-all-latest-gpu%2FDockerfile?ref=7f5088503fb440cb3bb2d610f892e2ee547982b3",
            "patch": "@@ -43,7 +43,7 @@ RUN python3 -m pip install --no-cache-dir git+https://github.com/huggingface/pef\n RUN python3 -m pip install --no-cache-dir git+https://github.com/huggingface/optimum@main#egg=optimum\n \n # For video model testing\n-RUN python3 -m pip install --no-cache-dir decord av==9.2.0\n+RUN python3 -m pip install --no-cache-dir av==9.2.0\n \n # Some slow tests require bnb\n RUN python3 -m pip install --no-cache-dir bitsandbytes"
        },
        {
            "sha": "1846f7bf97b5d40e59ee308f3bc082ef8e205140",
            "filename": "setup.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/7f5088503fb440cb3bb2d610f892e2ee547982b3/setup.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7f5088503fb440cb3bb2d610f892e2ee547982b3/setup.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/setup.py?ref=7f5088503fb440cb3bb2d610f892e2ee547982b3",
            "patch": "@@ -104,7 +104,6 @@\n     \"cookiecutter==1.7.3\",\n     \"dataclasses\",\n     \"datasets!=2.5.0\",\n-    \"decord==0.6.0\",\n     \"deepspeed>=0.9.3\",\n     \"diffusers\",\n     \"dill<0.3.5\",\n@@ -313,7 +312,7 @@ def run(self):\n extras[\"torch-vision\"] = deps_list(\"torchvision\") + extras[\"vision\"]\n extras[\"natten\"] = deps_list(\"natten\")\n extras[\"codecarbon\"] = deps_list(\"codecarbon\")\n-extras[\"video\"] = deps_list(\"decord\", \"av\")\n+extras[\"video\"] = deps_list(\"av\")\n \n extras[\"sentencepiece\"] = deps_list(\"sentencepiece\", \"protobuf\")\n extras[\"tiktoken\"] = deps_list(\"tiktoken\", \"blobfile\")"
        },
        {
            "sha": "50400ed6c4e9444c46d4fb9195f1ab4474741167",
            "filename": "src/transformers/__init__.py",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/7f5088503fb440cb3bb2d610f892e2ee547982b3/src%2Ftransformers%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7f5088503fb440cb3bb2d610f892e2ee547982b3/src%2Ftransformers%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2F__init__.py?ref=7f5088503fb440cb3bb2d610f892e2ee547982b3",
            "patch": "@@ -939,7 +939,6 @@\n         \"is_av_available\",\n         \"is_bitsandbytes_available\",\n         \"is_datasets_available\",\n-        \"is_decord_available\",\n         \"is_faiss_available\",\n         \"is_flax_available\",\n         \"is_keras_nlp_available\",\n@@ -5855,7 +5854,6 @@\n         is_av_available,\n         is_bitsandbytes_available,\n         is_datasets_available,\n-        is_decord_available,\n         is_faiss_available,\n         is_flax_available,\n         is_keras_nlp_available,"
        },
        {
            "sha": "5ce23f4b7647d576046811f312a90bd1cc888adf",
            "filename": "src/transformers/dependency_versions_table.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/7f5088503fb440cb3bb2d610f892e2ee547982b3/src%2Ftransformers%2Fdependency_versions_table.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7f5088503fb440cb3bb2d610f892e2ee547982b3/src%2Ftransformers%2Fdependency_versions_table.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdependency_versions_table.py?ref=7f5088503fb440cb3bb2d610f892e2ee547982b3",
            "patch": "@@ -11,7 +11,6 @@\n     \"cookiecutter\": \"cookiecutter==1.7.3\",\n     \"dataclasses\": \"dataclasses\",\n     \"datasets\": \"datasets!=2.5.0\",\n-    \"decord\": \"decord==0.6.0\",\n     \"deepspeed\": \"deepspeed>=0.9.3\",\n     \"diffusers\": \"diffusers\",\n     \"dill\": \"dill<0.3.5\","
        },
        {
            "sha": "2f93a6b03a65d9c7421ddf779834605073888a91",
            "filename": "src/transformers/models/git/convert_git_to_pytorch.py",
            "status": "modified",
            "additions": 32,
            "deletions": 11,
            "changes": 43,
            "blob_url": "https://github.com/huggingface/transformers/blob/7f5088503fb440cb3bb2d610f892e2ee547982b3/src%2Ftransformers%2Fmodels%2Fgit%2Fconvert_git_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7f5088503fb440cb3bb2d610f892e2ee547982b3/src%2Ftransformers%2Fmodels%2Fgit%2Fconvert_git_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgit%2Fconvert_git_to_pytorch.py?ref=7f5088503fb440cb3bb2d610f892e2ee547982b3",
            "patch": "@@ -19,6 +19,7 @@\n import argparse\n from pathlib import Path\n \n+import av\n import numpy as np\n import requests\n import torch\n@@ -193,10 +194,27 @@ def prepare_img(model_name):\n \n \n def prepare_video():\n-    from decord import VideoReader, cpu\n+    def read_video_pyav(container, indices):\n+        \"\"\"\n+        Decode the video with PyAV decoder.\n \n-    # set seed for reproducability\n-    np.random.seed(0)\n+        Args:\n+            container (`av.container.input.InputContainer`): PyAV container.\n+            indices (`List[int]`): List of frame indices to decode.\n+\n+        Returns:\n+            result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n+        \"\"\"\n+        frames = []\n+        container.seek(0)\n+        start_index = indices[0]\n+        end_index = indices[-1]\n+        for i, frame in enumerate(container.decode(video=0)):\n+            if i > end_index:\n+                break\n+            if i >= start_index and i in indices:\n+                frames.append(frame)\n+        return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n \n     def sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n         \"\"\"\n@@ -217,16 +235,19 @@ def sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n         indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n         return indices\n \n-    # video clip consists of 300 frames (10 seconds at 30 FPS)\n-    file_path = hf_hub_download(repo_id=\"nielsr/video-demo\", filename=\"eating_spaghetti.mp4\", repo_type=\"dataset\")\n-    videoreader = VideoReader(file_path, num_threads=1, ctx=cpu(0))\n+    # set seed for reproducibility\n+    np.random.seed(0)\n \n-    # sample 6 frames\n-    videoreader.seek(0)\n-    indices = sample_frame_indices(clip_len=6, frame_sample_rate=4, seg_len=len(videoreader))\n-    video = videoreader.get_batch(indices).asnumpy()\n+    file_path = hf_hub_download(repo_id=\"nielsr/video-demo\", filename=\"eating_spaghetti.mp4\", repo_type=\"dataset\")\n+    with av.open(file_path) as container:\n+        # sample 6 frames\n+        num_frames = 6\n+        indices = sample_frame_indices(\n+            clip_len=num_frames, frame_sample_rate=4, seg_len=container.streams.video[0].frames\n+        )\n+        frames = read_video_pyav(container, indices)\n \n-    return video\n+        return frames\n \n \n @torch.no_grad()"
        },
        {
            "sha": "2fc22551d37f1b164f0b882d4f5762ac0b789662",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/7f5088503fb440cb3bb2d610f892e2ee547982b3/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7f5088503fb440cb3bb2d610f892e2ee547982b3/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=7f5088503fb440cb3bb2d610f892e2ee547982b3",
            "patch": "@@ -67,7 +67,6 @@\n     is_compressed_tensors_available,\n     is_cv2_available,\n     is_cython_available,\n-    is_decord_available,\n     is_detectron2_available,\n     is_eetq_available,\n     is_essentia_available,\n@@ -758,13 +757,6 @@ def require_spacy(test_case):\n     return unittest.skipUnless(is_spacy_available(), \"test requires spacy\")(test_case)\n \n \n-def require_decord(test_case):\n-    \"\"\"\n-    Decorator marking a test that requires decord. These tests are skipped when decord isn't installed.\n-    \"\"\"\n-    return unittest.skipUnless(is_decord_available(), \"test requires decord\")(test_case)\n-\n-\n def require_torch_multi_gpu(test_case):\n     \"\"\"\n     Decorator marking a test that requires a multi-GPU setup (in PyTorch). These tests are skipped on a machine without"
        },
        {
            "sha": "2876eef9ea02dff735f9be20d83b4a39e43ab3f1",
            "filename": "src/transformers/utils/__init__.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/7f5088503fb440cb3bb2d610f892e2ee547982b3/src%2Ftransformers%2Futils%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7f5088503fb440cb3bb2d610f892e2ee547982b3/src%2Ftransformers%2Futils%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2F__init__.py?ref=7f5088503fb440cb3bb2d610f892e2ee547982b3",
            "patch": "@@ -128,7 +128,6 @@\n     is_cv2_available,\n     is_cython_available,\n     is_datasets_available,\n-    is_decord_available,\n     is_detectron2_available,\n     is_eetq_available,\n     is_essentia_available,"
        },
        {
            "sha": "2f0cfe1d6dcec8e11026414512e6d136d810b38f",
            "filename": "src/transformers/utils/import_utils.py",
            "status": "modified",
            "additions": 0,
            "deletions": 10,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/7f5088503fb440cb3bb2d610f892e2ee547982b3/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7f5088503fb440cb3bb2d610f892e2ee547982b3/src%2Ftransformers%2Futils%2Fimport_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fimport_utils.py?ref=7f5088503fb440cb3bb2d610f892e2ee547982b3",
            "patch": "@@ -112,7 +112,6 @@ def _is_package_available(pkg_name: str, return_version: bool = False) -> Union[\n # `importlib.metadata.util` doesn't work with `opencv-python-headless`.\n _cv2_available = importlib.util.find_spec(\"cv2\") is not None\n _datasets_available = _is_package_available(\"datasets\")\n-_decord_available = importlib.util.find_spec(\"decord\") is not None\n _detectron2_available = _is_package_available(\"detectron2\")\n # We need to check both `faiss` and `faiss-cpu`.\n _faiss_available = importlib.util.find_spec(\"faiss\") is not None\n@@ -1173,10 +1172,6 @@ def is_ccl_available():\n     return _is_ccl_available\n \n \n-def is_decord_available():\n-    return _decord_available\n-\n-\n def is_sudachi_available():\n     return _sudachipy_available\n \n@@ -1547,10 +1542,6 @@ def is_liger_kernel_available():\n Please note that you may need to restart your runtime after installation.\n \"\"\"\n \n-DECORD_IMPORT_ERROR = \"\"\"\n-{0} requires the decord library but it was not found in your environment. You can install it with pip: `pip install\n-decord`. Please note that you may need to restart your runtime after installation.\n-\"\"\"\n \n CYTHON_IMPORT_ERROR = \"\"\"\n {0} requires the Cython library but it was not found in your environment. You can install it with pip: `pip install\n@@ -1612,7 +1603,6 @@ def is_liger_kernel_available():\n         (\"scipy\", (is_scipy_available, SCIPY_IMPORT_ERROR)),\n         (\"accelerate\", (is_accelerate_available, ACCELERATE_IMPORT_ERROR)),\n         (\"oneccl_bind_pt\", (is_ccl_available, CCL_IMPORT_ERROR)),\n-        (\"decord\", (is_decord_available, DECORD_IMPORT_ERROR)),\n         (\"cython\", (is_cython_available, CYTHON_IMPORT_ERROR)),\n         (\"jieba\", (is_jieba_available, JIEBA_IMPORT_ERROR)),\n         (\"peft\", (is_peft_available, PEFT_IMPORT_ERROR)),"
        },
        {
            "sha": "74bc1b8669a702a36ab0730161d96e4bd16f770d",
            "filename": "tests/test_pipeline_mixin.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/7f5088503fb440cb3bb2d610f892e2ee547982b3/tests%2Ftest_pipeline_mixin.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/7f5088503fb440cb3bb2d610f892e2ee547982b3/tests%2Ftest_pipeline_mixin.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_pipeline_mixin.py?ref=7f5088503fb440cb3bb2d610f892e2ee547982b3",
            "patch": "@@ -51,7 +51,7 @@\n )\n from transformers.testing_utils import (\n     is_pipeline_test,\n-    require_decord,\n+    require_av,\n     require_pytesseract,\n     require_timm,\n     require_torch,\n@@ -722,14 +722,14 @@ def test_pipeline_translation_fp16(self):\n     @is_pipeline_test\n     @require_torch_or_tf\n     @require_vision\n-    @require_decord\n+    @require_av\n     def test_pipeline_video_classification(self):\n         self.run_task_tests(task=\"video-classification\")\n \n     @is_pipeline_test\n     @require_vision\n-    @require_decord\n     @require_torch\n+    @require_av\n     def test_pipeline_video_classification_fp16(self):\n         self.run_task_tests(task=\"video-classification\", torch_dtype=\"float16\")\n "
        }
    ],
    "stats": {
        "total": 76,
        "additions": 37,
        "deletions": 39
    }
}