{
    "author": "ArthurZucker",
    "message": "[`ModularChecker`] QOL for the modular checker (#41361)\n\n* update\n\n* fancy table fancy prints\n\n* download to cache folder, never need it everagain\n\n* stule\n\n* update based on review",
    "sha": "0452f28544f3626273d25f07f83c0e5f7da2d47a",
    "files": [
        {
            "sha": "caf8c4dfba64a12c34b6264645939626b1eb320b",
            "filename": "utils/modular_model_detector.py",
            "status": "modified",
            "additions": 385,
            "deletions": 56,
            "changes": 441,
            "blob_url": "https://github.com/huggingface/transformers/blob/0452f28544f3626273d25f07f83c0e5f7da2d47a/utils%2Fmodular_model_detector.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0452f28544f3626273d25f07f83c0e5f7da2d47a/utils%2Fmodular_model_detector.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fmodular_model_detector.py?ref=0452f28544f3626273d25f07f83c0e5f7da2d47a",
            "patch": "@@ -103,20 +103,34 @@\n import logging\n import os\n import re\n+from datetime import datetime\n+from functools import cache\n from pathlib import Path\n \n import numpy as np\n import torch\n-from huggingface_hub import HfApi, hf_hub_download\n+from huggingface_hub import HfApi, snapshot_download\n from huggingface_hub import logging as huggingface_hub_logging\n from safetensors.numpy import load_file as safetensors_load\n from safetensors.numpy import save_file as safetensors_save\n from tqdm import tqdm\n \n+import transformers\n from transformers import AutoModel, AutoTokenizer\n from transformers.utils import logging as transformers_logging\n \n \n+# ANSI color codes for CLI output styling\n+ANSI_RESET = \"\\033[0m\"\n+ANSI_BOLD = \"\\033[1m\"\n+ANSI_HEADER = \"\\033[1;36m\"\n+ANSI_SECTION = \"\\033[1;35m\"\n+ANSI_ROW = \"\\033[0;37m\"\n+ANSI_HIGHLIGHT_TOP = \"\\033[1;32m\"\n+ANSI_HIGHLIGHT_OLD = \"\\033[1;33m\"\n+ANSI_HIGHLIGHT_CANDIDATE = \"\\033[1;34m\"\n+\n+\n os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n \n@@ -238,34 +252,40 @@ def __init__(self, hub_dataset: str):\n \n         self.models_root = MODELS_ROOT\n         self.hub_dataset = hub_dataset\n-        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n-        self.dtype = \"auto\"\n         self.tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL)\n-        self.model = (\n-            AutoModel.from_pretrained(\n-                EMBEDDING_MODEL,\n-                torch_dtype=self.dtype if self.device.type == \"cuda\" else torch.float32,\n-            )\n-            .eval()\n-            .to(self.device)\n-        )\n+        self.model = AutoModel.from_pretrained(EMBEDDING_MODEL, torch_dtype=\"auto\", device_map=\"auto\").eval()\n+\n+        self.device = self.model.device\n+        self.index_dir: Path | None = None\n \n     # ---------- HUB IO ----------\n \n+    def _resolve_index_path(self, filename: str) -> Path:\n+        if self.index_dir is None:\n+            return Path(filename)\n+        return self.index_dir / filename\n+\n     def ensure_local_index(self) -> None:\n-        \"\"\"Download index files from Hub if they don't exist locally.\"\"\"\n-        have_all = Path(EMBEDDINGS_PATH).exists() and Path(INDEX_MAP_PATH).exists() and Path(TOKENS_PATH).exists()\n-        if have_all:\n+        \"\"\"Ensure index files are available locally, preferring Hub cache snapshots.\"\"\"\n+        if self.index_dir is not None and all(\n+            (self.index_dir / fname).exists() for fname in (EMBEDDINGS_PATH, INDEX_MAP_PATH, TOKENS_PATH)\n+        ):\n+            return\n+\n+        workspace_dir = Path.cwd()\n+        if all((workspace_dir / fname).exists() for fname in (EMBEDDINGS_PATH, INDEX_MAP_PATH, TOKENS_PATH)):\n+            self.index_dir = workspace_dir\n             return\n-        logging.info(f\"downloading index from hub: {self.hub_dataset}\")\n-        for fname in (EMBEDDINGS_PATH, INDEX_MAP_PATH, TOKENS_PATH):\n-            hf_hub_download(\n-                repo_id=self.hub_dataset,\n-                filename=fname,\n-                repo_type=\"dataset\",\n-                local_dir=\".\",\n-                local_dir_use_symlinks=False,\n-            )\n+\n+        logging.info(f\"downloading index from hub cache: {self.hub_dataset}\")\n+        snapshot_path = snapshot_download(repo_id=self.hub_dataset, repo_type=\"dataset\")\n+        snapshot_dir = Path(snapshot_path)\n+        missing = [\n+            fname for fname in (EMBEDDINGS_PATH, INDEX_MAP_PATH, TOKENS_PATH) if not (snapshot_dir / fname).exists()\n+        ]\n+        if missing:\n+            raise FileNotFoundError(\"Missing expected files in Hub snapshot: \" + \", \".join(missing))\n+        self.index_dir = snapshot_dir\n \n     def push_index_to_hub(self) -> None:\n         \"\"\"Upload index files to the Hub dataset repository.\"\"\"\n@@ -284,7 +304,7 @@ def push_index_to_hub(self) -> None:\n \n     def _extract_definitions(\n         self, file_path: Path, relative_to: Path | None = None, model_hint: str | None = None\n-    ) -> tuple[dict[str, str], dict[str, str], dict[str, list[str]]]:\n+    ) -> tuple[dict[str, str], dict[str, str], dict[str, list[str]], dict[str, str]]:\n         \"\"\"\n         Extract class and function definitions from a Python file.\n \n@@ -294,14 +314,16 @@ def _extract_definitions(\n             model_hint (`str` or `None`): Model name hint for sanitization.\n \n         Returns:\n-            `tuple[dict[str, str], dict[str, str], dict[str, list[str]]]`: A tuple containing:\n+            `tuple[dict[str, str], dict[str, str], dict[str, list[str]], dict[str, str]]`: A tuple containing:\n                 - definitions_raw: Mapping of identifiers to raw source code\n                 - definitions_sanitized: Mapping of identifiers to sanitized source code\n                 - definitions_tokens: Mapping of identifiers to sorted token lists\n+                - definitions_kind: Mapping of identifiers to either \"class\" or \"function\"\n         \"\"\"\n         definitions_raw = {}\n         definitions_sanitized = {}\n         definitions_tokens = {}\n+        definitions_kind = {}\n         source = file_path.read_text(encoding=\"utf-8\")\n         lines = source.splitlines()\n         tree = ast.parse(source)\n@@ -322,7 +344,11 @@ def _extract_definitions(\n                     sanitized = _sanitize_for_embedding(segment, model_hint, node.name)\n                     definitions_sanitized[identifier] = sanitized\n                     definitions_tokens[identifier] = sorted(_tokenize(sanitized))\n-        return definitions_raw, definitions_sanitized, definitions_tokens\n+                    if isinstance(node, ast.ClassDef):\n+                        definitions_kind[identifier] = \"class\"\n+                    else:\n+                        definitions_kind[identifier] = \"function\"\n+        return definitions_raw, definitions_sanitized, definitions_tokens, definitions_kind\n \n     def _infer_model_from_relative_path(self, relative_path: Path) -> str | None:\n         try:\n@@ -400,9 +426,12 @@ def build_index(self) -> None:\n \n         for file_path in tqdm(files, desc=\"parse\", leave=False):\n             model_hint = self._infer_model_from_relative_path(file_path)\n-            definitions_raw, definitions_sanitized, definitions_tokens = self._extract_definitions(\n-                file_path, self.models_root, model_hint\n-            )\n+            (\n+                _,\n+                definitions_sanitized,\n+                definitions_tokens,\n+                _,\n+            ) = self._extract_definitions(file_path, self.models_root, model_hint)\n             for identifier in definitions_sanitized.keys():\n                 identifiers.append(identifier)\n                 sanitized_sources.append(definitions_sanitized[identifier])\n@@ -418,6 +447,8 @@ def build_index(self) -> None:\n         with open(TOKENS_PATH, \"w\", encoding=\"utf-8\") as file:\n             json.dump(tokens_map, file)\n \n+        self.index_dir = Path.cwd()\n+\n     def _topk_embedding(\n         self,\n         query_embedding_row: np.ndarray,\n@@ -439,7 +470,7 @@ def _topk_embedding(\n                 continue\n             if self_model_normalized and _normalize(parent_model) == self_model_normalized:\n                 continue\n-            output.append((f\"{parent_model}::{match_name}\", float(similarities[match_id])))\n+            output.append((identifier, float(similarities[match_id])))\n             if len(output) >= k:\n                 break\n         return output\n@@ -480,12 +511,12 @@ def _topk_jaccard(\n                 continue\n             score = len(query_tokens & tokens) / len(query_tokens | tokens)\n             if score > 0:\n-                scores.append((f\"{parent_model}::{match_name}\", score))\n+                scores.append((identifier, score))\n         scores.sort(key=lambda x: x[1], reverse=True)\n         return scores[:k]\n \n     def analyze_file(\n-        self, modeling_file: Path, top_k_per_item: int = 5, allow_hub_fallback: bool = True\n+        self, modeling_file: Path, top_k_per_item: int = 5, allow_hub_fallback: bool = True, use_jaccard=False\n     ) -> dict[str, dict[str, list]]:\n         \"\"\"\n         Analyze a modeling file and find similar code definitions in the index.\n@@ -502,16 +533,18 @@ def analyze_file(\n         if allow_hub_fallback:\n             self.ensure_local_index()\n \n-        base = safetensors_load(EMBEDDINGS_PATH)\n+        base = safetensors_load(str(self._resolve_index_path(EMBEDDINGS_PATH)))\n         base_embeddings = base[\"embeddings\"]\n-        with open(INDEX_MAP_PATH, \"r\", encoding=\"utf-8\") as file:\n+        with open(self._resolve_index_path(INDEX_MAP_PATH), \"r\", encoding=\"utf-8\") as file:\n             identifier_map = {int(key): value for key, value in json.load(file).items()}\n         identifiers = [identifier_map[i] for i in range(len(identifier_map))]\n-        with open(TOKENS_PATH, \"r\", encoding=\"utf-8\") as file:\n+        with open(self._resolve_index_path(TOKENS_PATH), \"r\", encoding=\"utf-8\") as file:\n             tokens_map = json.load(file)\n \n         self_model = self._infer_query_model_name(modeling_file)\n-        definitions_raw, definitions_sanitized, _ = self._extract_definitions(modeling_file, None, self_model)\n+        definitions_raw, definitions_sanitized, _, definitions_kind = self._extract_definitions(\n+            modeling_file, None, self_model\n+        )\n         query_identifiers = list(definitions_raw.keys())\n         query_sources_sanitized = [definitions_sanitized[key] for key in query_identifiers]\n         query_tokens_list = [set(_tokenize(source)) for source in query_sources_sanitized]\n@@ -528,28 +561,146 @@ def analyze_file(\n             embedding_top = self._topk_embedding(\n                 query_embeddings[i], base_embeddings, identifier_map, self_model_normalized, query_name, top_k_per_item\n             )\n-            jaccard_top = self._topk_jaccard(\n-                query_tokens_list[i], identifiers, tokens_map, self_model_normalized, query_name, top_k_per_item\n-            )\n             embedding_set = {identifier for identifier, _ in embedding_top}\n-            jaccard_set = {identifier for identifier, _ in jaccard_top}\n-            intersection = list(embedding_set & jaccard_set)\n-            output[query_name] = {\"embedding\": embedding_top, \"jaccard\": jaccard_top, \"intersection\": intersection}\n+            kind = definitions_kind.get(query_identifier, \"function\")\n+            entry = {\"kind\": kind, \"embedding\": embedding_top}\n+            if use_jaccard:\n+                jaccard_top = self._topk_jaccard(\n+                    query_tokens_list[i], identifiers, tokens_map, self_model_normalized, query_name, top_k_per_item\n+                )\n+                jaccard_set = {identifier for identifier, _ in jaccard_top}\n+                intersection = set(embedding_set & jaccard_set)\n+\n+                entry.update({\"jaccard\": jaccard_top, \"intersection\": intersection})\n+            output[query_name] = entry\n         return output\n \n \n+_RELEASE_RE = re.compile(\n+    r\"(?:^|[\\*_`\\s>])(?:this|the)\\s+model\\s+was\\s+released\\s+on\\s+(\\d{4}-\\d{2}-\\d{2})\\b\", re.IGNORECASE\n+)\n+\n+\n+def build_date_data() -> dict[str, str]:\n+    \"\"\"\n+    Scan Markdown files in `root_dir` and build {model_id: date_released}.\n+\n+    - model_id is the filename without extension (e.g., \"llama\" for \"llama.md\")\n+    - date_released is the first YYYY-MM-DD matched after \"...was released on ...\"\n+    - Ignores non-*.md files and directories.\n+\n+    Returns:\n+        dict[str, str]: mapping of model_id -> ISO date string (YYYY-MM-DD).\n+                        Files without a match are simply omitted.\n+    \"\"\"\n+\n+    root_dir = transformers.__file__.split(\"src/transformers\")[0]\n+    root = Path(root_dir).joinpath(\"docs/source/en/model_doc\")\n+    result: dict[str, str] = {}\n+\n+    for md_path in root.glob(\"*.md\"):\n+        try:\n+            text = md_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n+        except Exception:\n+            # Skip unreadable files quietly\n+            logging.info(f\"Failed to read md for {md_path}\")\n+\n+        m = _RELEASE_RE.search(text)\n+        if m:\n+            model_id = md_path.stem  # e.g., \"llama\" from \"llama.md\"\n+            result[model_id] = m.group(1)\n+\n+    return result\n+\n+\n+def _format_table(headers: list[str], rows: list[tuple[str, ...] | None], row_styles: list[str] | None = None) -> str:\n+    if not rows:\n+        return f\"{ANSI_ROW}(no matches){ANSI_RESET}\"\n+\n+    widths = [len(header) for header in headers]\n+    for row in rows:\n+        if row is None:\n+            continue\n+        for idx, cell in enumerate(row):\n+            widths[idx] = max(widths[idx], len(cell))\n+\n+    header_line = \" | \".join(header.ljust(widths[idx]) for idx, header in enumerate(headers))\n+    divider = \"-+-\".join(\"-\" * widths[idx] for idx in range(len(headers)))\n+    total_width = sum(widths) + 3 * (len(headers) - 1)\n+\n+    styled_rows = []\n+    style_idx = 0\n+    for row in rows:\n+        if row is None:\n+            styled_rows.append(f\"{ANSI_SECTION}{'-' * total_width}{ANSI_RESET}\")\n+            continue\n+\n+        line = \" | \".join(cell.ljust(widths[col_idx]) for col_idx, cell in enumerate(row))\n+        style = ANSI_ROW\n+        if row_styles and style_idx < len(row_styles) and row_styles[style_idx]:\n+            style = row_styles[style_idx]\n+        styled_rows.append(f\"{style}{line}{ANSI_RESET}\")\n+        style_idx += 1\n+\n+    return \"\\n\".join([f\"{ANSI_SECTION}{header_line}{ANSI_RESET}\", divider] + styled_rows)\n+\n+\n+def _parse_release_date(value: str) -> datetime | None:\n+    \"\"\"Return a datetime parsed from YYYY-MM-DD strings, otherwise None.\"\"\"\n+    try:\n+        return datetime.strptime(value, \"%Y-%m-%d\")\n+    except (TypeError, ValueError):\n+        return None\n+\n+\n+@cache\n+def _load_definition_line_map(relative_path: str) -> dict[str, int]:\n+    \"\"\"Return {definition_name: line_number} for top-level definitions in the given file.\"\"\"\n+    file_path = MODELS_ROOT / relative_path\n+    try:\n+        source = file_path.read_text(encoding=\"utf-8\")\n+    except (FileNotFoundError, OSError):\n+        return {}  # gracefully keep going\n+\n+    try:\n+        tree = ast.parse(source)\n+    except SyntaxError:\n+        return {}\n+\n+    line_map: dict[str, int] = {}\n+    for node in ast.iter_child_nodes(tree):\n+        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n+            line_map[node.name] = getattr(node, \"lineno\", None) or 1\n+        elif isinstance(node, ast.Assign):\n+            continue\n+    return line_map\n+\n+\n+def _resolve_definition_location(relative_path: str, definition: str) -> tuple[str, str]:\n+    \"\"\"Return full path and formatted line number string for the given definition.\"\"\"\n+    full_path = MODELS_ROOT / relative_path\n+    line = _load_definition_line_map(relative_path).get(definition)\n+    line_str = str(line) if line is not None else \"?\"\n+    return str(full_path), line_str\n+\n+\n+def _colorize_heading(text: str) -> str:\n+    return f\"{ANSI_HEADER}{ANSI_BOLD}{text}{ANSI_RESET}\"\n+\n+\n def main():\n     \"\"\"CLI entry point for the modular model detector.\"\"\"\n     logging.basicConfig(level=logging.INFO, format=\"%(message)s\")\n     parser = argparse.ArgumentParser(prog=\"hf-code-sim\")\n     parser.add_argument(\"--build\", action=\"store_true\")\n-    parser.add_argument(\"--modeling-file\", type=str)\n+    parser.add_argument(\"--modeling-file\", type=str, help='You can just specify \"vits\" if you are lazy like me.')\n     parser.add_argument(\n         \"--push-new-index\", action=\"store_true\", help=\"After --build, push index files to a Hub dataset.\"\n     )\n     parser.add_argument(\n         \"--hub-dataset\", type=str, default=HUB_DATASET_DEFAULT, help=\"Hub dataset repo id to pull/push the index.\"\n     )\n+    parser.add_argument(\"--use_jaccard\", type=bool, default=False, help=\"Whether or not to use jaccard index\")\n     args = parser.parse_args()\n \n     analyzer = CodeSimilarityAnalyzer(hub_dataset=args.hub_dataset)\n@@ -563,20 +714,198 @@ def main():\n     if not args.modeling_file:\n         raise SystemExit(\"Provide --modeling-file or use --build\")\n \n-    results = analyzer.analyze_file(Path(args.modeling_file), top_k_per_item=5, allow_hub_fallback=True)\n-    modeling_filename = Path(args.modeling_file).name\n+    dates = build_date_data()\n+    modeling_file = args.modeling_file\n+    if os.sep not in modeling_file:\n+        modeling_file = os.path.join(\"src\", \"transformers\", \"models\", modeling_file, f\"modeling_{modeling_file}.py\")\n+\n+    results = analyzer.analyze_file(\n+        Path(modeling_file), top_k_per_item=5, allow_hub_fallback=True, use_jaccard=args.use_jaccard\n+    )\n+    modeling_filename = Path(modeling_file).name\n+    release_key = modeling_filename.split(\"modeling_\")[-1][:-3]\n+    release_date = dates.get(release_key, \"unknown release date\")\n+\n+    aggregate_scores: dict[str, float] = {}\n+    for data in results.values():\n+        for identifier, score in data.get(\"embedding\", []):\n+            try:\n+                relative_path, _ = identifier.split(\":\", 1)\n+            except ValueError:\n+                continue\n+            aggregate_scores[relative_path] = aggregate_scores.get(relative_path, 0.0) + score\n+\n+    best_candidate_path: str | None = None\n+    if aggregate_scores:\n+        best_candidate_path = max(aggregate_scores.items(), key=lambda item: item[1])[0]\n+        best_model = Path(best_candidate_path).parts[0] if Path(best_candidate_path).parts else \"?\"\n+        best_release = dates.get(best_model, \"unknown release date\")\n+        logging.info(\n+            f\"{ANSI_HIGHLIGHT_CANDIDATE}Closest overall candidate: {MODELS_ROOT / best_candidate_path}\"\n+            f\" (release: {best_release}, total score: {aggregate_scores[best_candidate_path]:.4f}){ANSI_RESET}\"\n+        )\n+\n+    grouped: dict[str, list[tuple[str, dict]]] = {\"class\": [], \"function\": []}\n     for query_name, data in results.items():\n-        logging.info(f\"{modeling_filename}::{query_name}:\")\n-        logging.info(\"  embedding:\")\n-        for identifier, score in data[\"embedding\"]:\n-            logging.info(f\"    {identifier} ({score:.4f})\")\n-        logging.info(\"  jaccard:\")\n-        for identifier, score in data[\"jaccard\"]:\n-            logging.info(f\"    {identifier} ({score:.4f})\")\n-        logging.info(\"  intersection:\")\n-        for identifier in data[\"intersection\"]:\n-            logging.info(f\"    {identifier}\")\n-        logging.info(\"\")\n+        kind = data.get(\"kind\", \"function\")\n+        grouped.setdefault(kind, []).append((query_name, data))\n+\n+    section_titles = [(\"class\", \"Classes\"), (\"function\", \"Functions\")]\n+    legend_shown = False\n+    for kind, title in section_titles:\n+        entries = grouped.get(kind, [])\n+        if not entries:\n+            continue\n+\n+        metrics_present: set[str] = set()\n+        for _, data in entries:\n+            if data.get(\"embedding\"):\n+                metrics_present.add(\"embedding\")\n+            if args.use_jaccard:\n+                if data.get(\"jaccard\"):\n+                    metrics_present.add(\"jaccard\")\n+                if data.get(\"intersection\"):\n+                    metrics_present.add(\"intersection\")\n+\n+        include_metric_column = bool(metrics_present - {\"embedding\"})\n+        headers = [\"Symbol\", \"Path\", \"Score\", \"Release\"]\n+        if include_metric_column:\n+            headers = [\"Symbol\", \"Metric\", \"Path\", \"Score\", \"Release\"]\n+\n+        table_rows: list[tuple[str, ...] | None] = []\n+        row_styles: list[str] = []\n+        has_metric_rows = False\n+\n+        logging.info(_colorize_heading(title))\n+\n+        for query_name, data in entries:\n+            if table_rows:\n+                table_rows.append(None)\n+\n+            symbol_label = query_name\n+            if release_date:\n+                symbol_label = f\"{symbol_label}\"\n+\n+            symbol_row = (symbol_label,) + (\"\",) * (len(headers) - 1)\n+            table_rows.append(symbol_row)\n+            row_styles.append(ANSI_BOLD)\n+\n+            embedding_details: list[tuple[str, str, str, float, str]] = []\n+            embedding_style_indices: list[int] = []\n+\n+            for identifier, score in data.get(\"embedding\", []):\n+                try:\n+                    relative_path, match_name = identifier.split(\":\", 1)\n+                except ValueError:\n+                    continue\n+                model_id = Path(relative_path).parts[0] if Path(relative_path).parts else \"?\"\n+                match_release = dates.get(model_id, \"unknown release date\")\n+                full_path, line = _resolve_definition_location(relative_path, match_name)\n+                display_path = f\"{full_path}:{line} ({match_name})\"\n+\n+                if include_metric_column:\n+                    row = (\"\", \"embedding\", display_path, f\"{score:.4f}\", match_release)\n+                else:\n+                    row = (\"\", display_path, f\"{score:.4f}\", match_release)\n+\n+                table_rows.append(row)\n+                row_styles.append(ANSI_ROW)\n+                embedding_style_indices.append(len(row_styles) - 1)\n+                embedding_details.append((relative_path, model_id, match_name, score, match_release))\n+                has_metric_rows = True\n+\n+            if embedding_details:\n+                highest_score = None\n+                highest_idx = None\n+                for idx, (_, _, _, score, _) in enumerate(embedding_details):\n+                    if highest_score is None or score > highest_score:\n+                        highest_score = score\n+                        highest_idx = idx\n+\n+                if highest_idx is not None:\n+                    row_styles[embedding_style_indices[highest_idx]] = ANSI_HIGHLIGHT_TOP\n+\n+                if highest_score is not None:\n+                    oldest_idx = None\n+                    oldest_date = None\n+                    for idx, (_, model_id, _, score, release_value) in enumerate(embedding_details):\n+                        if highest_score - score > 0.1:\n+                            continue\n+                        parsed = _parse_release_date(release_value)\n+                        if parsed is None:\n+                            continue\n+                        if oldest_date is None or parsed < oldest_date:\n+                            oldest_date = parsed\n+                            oldest_idx = idx\n+                    if (\n+                        oldest_idx is not None\n+                        and row_styles[embedding_style_indices[oldest_idx]] != ANSI_HIGHLIGHT_TOP\n+                    ):\n+                        row_styles[embedding_style_indices[oldest_idx]] = ANSI_HIGHLIGHT_OLD\n+\n+                if best_candidate_path is not None:\n+                    for idx, (relative_path, _, _, _, _) in enumerate(embedding_details):\n+                        style_position = embedding_style_indices[idx]\n+                        if row_styles[style_position] != ANSI_ROW:\n+                            continue\n+                        if relative_path == best_candidate_path:\n+                            row_styles[style_position] = ANSI_HIGHLIGHT_CANDIDATE\n+\n+            if args.use_jaccard:\n+                for identifier, score in data.get(\"jaccard\", []):\n+                    try:\n+                        relative_path, match_name = identifier.split(\":\", 1)\n+                    except ValueError:\n+                        continue\n+                    model_id = Path(relative_path).parts[0] if Path(relative_path).parts else \"?\"\n+                    match_release = dates.get(model_id, \"unknown release date\")\n+                    full_path, line = _resolve_definition_location(relative_path, match_name)\n+                    display_path = f\"{full_path}:{line} ({match_name})\"\n+\n+                    if include_metric_column:\n+                        row = (\"\", \"jaccard\", display_path, f\"{score:.4f}\", match_release)\n+                    else:\n+                        row = (\"\", display_path, f\"{score:.4f}\", match_release)\n+\n+                    table_rows.append(row)\n+                    row_styles.append(ANSI_ROW)\n+                    has_metric_rows = True\n+                    if best_candidate_path == relative_path:\n+                        row_styles[-1] = ANSI_HIGHLIGHT_CANDIDATE\n+\n+                for identifier in sorted(data.get(\"intersection\", [])):\n+                    try:\n+                        relative_path, match_name = identifier.split(\":\", 1)\n+                    except ValueError:\n+                        continue\n+                    model_id = Path(relative_path).parts[0] if Path(relative_path).parts else \"?\"\n+                    match_release = dates.get(model_id, \"unknown release date\")\n+                    full_path, line = _resolve_definition_location(relative_path, match_name)\n+                    display_path = f\"{full_path}:{line} ({match_name})\"\n+\n+                    if include_metric_column:\n+                        row = (\"\", \"intersection\", display_path, \"--\", match_release)\n+                    else:\n+                        row = (\"\", display_path, \"--\", match_release)\n+\n+                    table_rows.append(row)\n+                    row_styles.append(ANSI_ROW)\n+                    has_metric_rows = True\n+                    if best_candidate_path == relative_path:\n+                        row_styles[-1] = ANSI_HIGHLIGHT_CANDIDATE\n+\n+        if table_rows:\n+            if not legend_shown and has_metric_rows:\n+                logging.info(\n+                    \"Legend: \"\n+                    f\"{ANSI_HIGHLIGHT_TOP}highest match{ANSI_RESET}, \"\n+                    f\"{ANSI_HIGHLIGHT_OLD}oldest within 0.1{ANSI_RESET}, \"\n+                    f\"{ANSI_HIGHLIGHT_CANDIDATE}closest overall candidate{ANSI_RESET}\"\n+                )\n+                legend_shown = True\n+\n+            logging.info(_format_table(headers, table_rows, row_styles))\n+            logging.info(\"\")\n \n \n if __name__ == \"__main__\":"
        }
    ],
    "stats": {
        "total": 441,
        "additions": 385,
        "deletions": 56
    }
}