{
    "author": "ydshieh",
    "message": "Fix flaky `test_batching_equivalence` (#35564)\n\n* yes!\r\n\r\n* oh no!!!\r\n\r\n* oh no!!!\r\n\r\n* style\r\n\r\n* oh no!!!\r\n\r\n* oh no!!!\r\n\r\n* oh no!!!\r\n\r\n* oh no!!!\r\n\r\n---------\r\n\r\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "1b2f942af7c36777064fb9297459e2c003899f4d",
    "files": [
        {
            "sha": "7876b22a2bb9070828f76c2cc229ab8a7c264825",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 30,
            "deletions": 5,
            "changes": 35,
            "blob_url": "https://github.com/huggingface/transformers/blob/1b2f942af7c36777064fb9297459e2c003899f4d/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1b2f942af7c36777064fb9297459e2c003899f4d/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=1b2f942af7c36777064fb9297459e2c003899f4d",
            "patch": "@@ -1409,17 +1409,42 @@ def assert_screenout(out, what):\n \n \n def set_model_tester_for_less_flaky_test(test_case):\n-    if hasattr(test_case.model_tester, \"num_hidden_layers\"):\n-        test_case.model_tester.num_hidden_layers = 1\n+    target_num_hidden_layers = 1\n+    # TODO (if possible): Avoid exceptional cases\n+    exceptional_classes = [\n+        \"ZambaModelTester\",\n+        \"RwkvModelTester\",\n+        \"AriaVisionText2TextModelTester\",\n+        \"GPTNeoModelTester\",\n+        \"DPTModelTester\",\n+    ]\n+    if test_case.model_tester.__class__.__name__ in exceptional_classes:\n+        target_num_hidden_layers = None\n+    if hasattr(test_case.model_tester, \"out_features\") or hasattr(test_case.model_tester, \"out_indices\"):\n+        target_num_hidden_layers = None\n+\n+    if hasattr(test_case.model_tester, \"num_hidden_layers\") and target_num_hidden_layers is not None:\n+        test_case.model_tester.num_hidden_layers = target_num_hidden_layers\n     if (\n         hasattr(test_case.model_tester, \"vision_config\")\n         and \"num_hidden_layers\" in test_case.model_tester.vision_config\n+        and target_num_hidden_layers is not None\n     ):\n         test_case.model_tester.vision_config = copy.deepcopy(test_case.model_tester.vision_config)\n-        test_case.model_tester.vision_config[\"num_hidden_layers\"] = 1\n-    if hasattr(test_case.model_tester, \"text_config\") and \"num_hidden_layers\" in test_case.model_tester.text_config:\n+        test_case.model_tester.vision_config[\"num_hidden_layers\"] = target_num_hidden_layers\n+    if (\n+        hasattr(test_case.model_tester, \"text_config\")\n+        and \"num_hidden_layers\" in test_case.model_tester.text_config\n+        and target_num_hidden_layers is not None\n+    ):\n         test_case.model_tester.text_config = copy.deepcopy(test_case.model_tester.text_config)\n-        test_case.model_tester.text_config[\"num_hidden_layers\"] = 1\n+        test_case.model_tester.text_config[\"num_hidden_layers\"] = target_num_hidden_layers\n+\n+    # A few model class specific handling\n+\n+    # For Albert\n+    if hasattr(test_case.model_tester, \"num_hidden_groups\"):\n+        test_case.model_tester.num_hidden_groups = test_case.model_tester.num_hidden_layers\n \n \n def set_config_for_less_flaky_test(config):"
        },
        {
            "sha": "43146a4779310defc9000e6493a28b4eefc6def8",
            "filename": "tests/models/upernet/test_modeling_upernet.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/1b2f942af7c36777064fb9297459e2c003899f4d/tests%2Fmodels%2Fupernet%2Ftest_modeling_upernet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1b2f942af7c36777064fb9297459e2c003899f4d/tests%2Fmodels%2Fupernet%2Ftest_modeling_upernet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fupernet%2Ftest_modeling_upernet.py?ref=1b2f942af7c36777064fb9297459e2c003899f4d",
            "patch": "@@ -82,7 +82,6 @@ def __init__(\n         self.out_features = out_features\n         self.num_labels = num_labels\n         self.scope = scope\n-        self.num_hidden_layers = num_stages\n \n     def prepare_config_and_inputs(self):\n         pixel_values = floats_tensor([self.batch_size, self.num_channels, self.image_size, self.image_size])"
        },
        {
            "sha": "1fe8f043dc0b38837792e686c54616902f8e7134",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/1b2f942af7c36777064fb9297459e2c003899f4d/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1b2f942af7c36777064fb9297459e2c003899f4d/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=1b2f942af7c36777064fb9297459e2c003899f4d",
            "patch": "@@ -816,7 +816,10 @@ def recursive_check(batched_object, single_row_object, model_name, key):\n                     ),\n                 )\n \n+        set_model_tester_for_less_flaky_test(self)\n+\n         config, batched_input = self.model_tester.prepare_config_and_inputs_for_common()\n+        set_config_for_less_flaky_test(config)\n         equivalence = get_tensor_equivalence_function(batched_input)\n \n         for model_class in self.all_model_classes:\n@@ -827,6 +830,7 @@ def recursive_check(batched_object, single_row_object, model_name, key):\n                 config, batched_input = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)\n             batched_input_prepared = self._prepare_for_class(batched_input, model_class)\n             model = model_class(config).to(torch_device).eval()\n+            set_model_for_less_flaky_test(model)\n \n             batch_size = self.model_tester.batch_size\n             single_row_input = {}"
        }
    ],
    "stats": {
        "total": 40,
        "additions": 34,
        "deletions": 6
    }
}