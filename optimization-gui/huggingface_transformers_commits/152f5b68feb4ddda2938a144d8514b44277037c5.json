{
    "author": "AnMakc",
    "message": "Fix TimesFM patch normalization instability (#42099)\n\n* Fix TimesFM potential numerical instability in masked mean/std calculation.\n\n* Fix sigma clamping to 1 instead of config.tolerance in TimesFM.",
    "sha": "152f5b68feb4ddda2938a144d8514b44277037c5",
    "files": [
        {
            "sha": "0ec1b90f89da4bfa8b95d95c2727228f430e64c1",
            "filename": "src/transformers/models/timesfm/modeling_timesfm.py",
            "status": "modified",
            "additions": 9,
            "deletions": 21,
            "changes": 30,
            "blob_url": "https://github.com/huggingface/transformers/blob/152f5b68feb4ddda2938a144d8514b44277037c5/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fmodeling_timesfm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/152f5b68feb4ddda2938a144d8514b44277037c5/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fmodeling_timesfm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fmodeling_timesfm.py?ref=152f5b68feb4ddda2938a144d8514b44277037c5",
            "patch": "@@ -341,11 +341,7 @@ def _forward_transform(\n     ) -> tuple[torch.Tensor, tuple[torch.Tensor, torch.Tensor]]:\n         \"\"\"Input is of shape [B, N, P].\"\"\"\n         mu, sigma = self._timesfm_masked_mean_std(inputs, patched_pads)\n-        sigma = torch.where(\n-            sigma < self.config.tolerance,\n-            torch.tensor(1.0, dtype=sigma.dtype, device=sigma.device),\n-            sigma,\n-        )\n+        sigma = torch.clamp(sigma, min=self.config.tolerance)\n \n         # Normalize each patch\n         outputs = (inputs - mu[:, None, None]) / sigma[:, None, None]\n@@ -524,24 +520,16 @@ def _get_patch_index(arr: torch.Tensor):\n \n         # Calculate the number of valid elements\n         num_valid_elements = torch.sum(mask, dim=1)\n-        num_valid_elements = torch.where(\n-            num_valid_elements == 0,\n-            torch.tensor(1, dtype=num_valid_elements.dtype, device=num_valid_elements.device),\n-            num_valid_elements,\n-        )\n+        num_valid_elements = torch.clamp(num_valid_elements, min=1.0)\n \n-        # Calculate the masked sum and squared sum\n+        # Calculate the masked sum and mean\n         masked_sum = torch.sum(arr * mask, dim=1)\n-        masked_squared_sum = torch.sum((arr * mask) ** 2, dim=1)\n-\n-        # Calculate the masked mean and standard deviation\n-        masked_mean = masked_sum / num_valid_elements\n-        masked_var = masked_squared_sum / num_valid_elements - masked_mean**2\n-        masked_var = torch.where(\n-            masked_var < 0.0,\n-            torch.tensor(0.0, dtype=masked_var.dtype, device=masked_var.device),\n-            masked_var,\n-        )\n+        masked_mean = masked_sum / num_valid_elements  # [b]\n+\n+        # Calculate the masked variance using centered values\n+        masked_centered_arr = (arr - masked_mean.unsqueeze(-1)) * mask\n+        masked_var = torch.sum(masked_centered_arr**2, dim=1) / num_valid_elements\n+        masked_var = torch.clamp(masked_var, min=0.0)\n         masked_std = torch.sqrt(masked_var)\n \n         return masked_mean, masked_std"
        },
        {
            "sha": "bc2ba05add70b8f9864b122fec372757c7f634bd",
            "filename": "src/transformers/models/timesfm/modular_timesfm.py",
            "status": "modified",
            "additions": 9,
            "deletions": 21,
            "changes": 30,
            "blob_url": "https://github.com/huggingface/transformers/blob/152f5b68feb4ddda2938a144d8514b44277037c5/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fmodular_timesfm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/152f5b68feb4ddda2938a144d8514b44277037c5/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fmodular_timesfm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftimesfm%2Fmodular_timesfm.py?ref=152f5b68feb4ddda2938a144d8514b44277037c5",
            "patch": "@@ -297,11 +297,7 @@ def _forward_transform(\n     ) -> tuple[torch.Tensor, tuple[torch.Tensor, torch.Tensor]]:\n         \"\"\"Input is of shape [B, N, P].\"\"\"\n         mu, sigma = self._timesfm_masked_mean_std(inputs, patched_pads)\n-        sigma = torch.where(\n-            sigma < self.config.tolerance,\n-            torch.tensor(1.0, dtype=sigma.dtype, device=sigma.device),\n-            sigma,\n-        )\n+        sigma = torch.clamp(sigma, min=self.config.tolerance)\n \n         # Normalize each patch\n         outputs = (inputs - mu[:, None, None]) / sigma[:, None, None]\n@@ -480,24 +476,16 @@ def _get_patch_index(arr: torch.Tensor):\n \n         # Calculate the number of valid elements\n         num_valid_elements = torch.sum(mask, dim=1)\n-        num_valid_elements = torch.where(\n-            num_valid_elements == 0,\n-            torch.tensor(1, dtype=num_valid_elements.dtype, device=num_valid_elements.device),\n-            num_valid_elements,\n-        )\n+        num_valid_elements = torch.clamp(num_valid_elements, min=1.0)\n \n-        # Calculate the masked sum and squared sum\n+        # Calculate the masked sum and mean\n         masked_sum = torch.sum(arr * mask, dim=1)\n-        masked_squared_sum = torch.sum((arr * mask) ** 2, dim=1)\n-\n-        # Calculate the masked mean and standard deviation\n-        masked_mean = masked_sum / num_valid_elements\n-        masked_var = masked_squared_sum / num_valid_elements - masked_mean**2\n-        masked_var = torch.where(\n-            masked_var < 0.0,\n-            torch.tensor(0.0, dtype=masked_var.dtype, device=masked_var.device),\n-            masked_var,\n-        )\n+        masked_mean = masked_sum / num_valid_elements  # [b]\n+\n+        # Calculate the masked variance using centered values\n+        masked_centered_arr = (arr - masked_mean.unsqueeze(-1)) * mask\n+        masked_var = torch.sum(masked_centered_arr**2, dim=1) / num_valid_elements\n+        masked_var = torch.clamp(masked_var, min=0.0)\n         masked_std = torch.sqrt(masked_var)\n \n         return masked_mean, masked_std"
        }
    ],
    "stats": {
        "total": 60,
        "additions": 18,
        "deletions": 42
    }
}