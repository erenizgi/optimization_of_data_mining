{
    "author": "yukiman76",
    "message": "Update _get_eval_sampler to reflect Trainer.tokenizer is deprecation  self.tokenizer -> self.processing_class (#36315)\n\n* fix warning self.tokenizer -> self.processing_class\n\n* formating change",
    "sha": "92abc0dae848d1853d04b9e8b4672da2374d3cd4",
    "files": [
        {
            "sha": "791b6988609c7449c2dda1aa42602bdca8c98979",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/92abc0dae848d1853d04b9e8b4672da2374d3cd4/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/92abc0dae848d1853d04b9e8b4672da2374d3cd4/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=92abc0dae848d1853d04b9e8b4672da2374d3cd4",
            "patch": "@@ -1060,7 +1060,9 @@ def _get_eval_sampler(self, eval_dataset: Dataset) -> Optional[torch.utils.data.\n                 )\n             else:\n                 lengths = None\n-            model_input_name = self.tokenizer.model_input_names[0] if self.tokenizer is not None else None\n+            model_input_name = (\n+                self.processing_class.model_input_names[0] if self.processing_class is not None else None\n+            )\n             return LengthGroupedSampler(\n                 self.args.eval_batch_size,\n                 dataset=eval_dataset,"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 3,
        "deletions": 1
    }
}