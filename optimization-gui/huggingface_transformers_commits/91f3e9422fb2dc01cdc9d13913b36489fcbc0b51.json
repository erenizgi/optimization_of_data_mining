{
    "author": "regisss",
    "message": "Add Intel Gaudi doc (#37855)\n\n* Add Intel Gaudi doc\n\n* Use \"TIP\" instead of \"NOTE\"\n\n* Address comments from reviews",
    "sha": "91f3e9422fb2dc01cdc9d13913b36489fcbc0b51",
    "files": [
        {
            "sha": "14cf7340ea7ef4b7a48095a058b04a265101453b",
            "filename": "docs/source/en/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/91f3e9422fb2dc01cdc9d13913b36489fcbc0b51/docs%2Fsource%2Fen%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/91f3e9422fb2dc01cdc9d13913b36489fcbc0b51/docs%2Fsource%2Fen%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2F_toctree.yml?ref=91f3e9422fb2dc01cdc9d13913b36489fcbc0b51",
            "patch": "@@ -149,6 +149,8 @@\n       title: TPU\n     - local: perf_train_special\n       title: Apple Silicon\n+    - local: perf_train_gaudi\n+      title: Intel Gaudi\n     - local: perf_hardware\n       title: Build your own machine\n     title: Hardware"
        },
        {
            "sha": "2ba792d484a3e26d8315384573eaddd9aa04c863",
            "filename": "docs/source/en/perf_train_gaudi.md",
            "status": "added",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/huggingface/transformers/blob/91f3e9422fb2dc01cdc9d13913b36489fcbc0b51/docs%2Fsource%2Fen%2Fperf_train_gaudi.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/91f3e9422fb2dc01cdc9d13913b36489fcbc0b51/docs%2Fsource%2Fen%2Fperf_train_gaudi.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fperf_train_gaudi.md?ref=91f3e9422fb2dc01cdc9d13913b36489fcbc0b51",
            "patch": "@@ -0,0 +1,34 @@\n+<!--Copyright 2025 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+\n+⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+\n+# Intel Gaudi\n+\n+The Intel Gaudi AI accelerator family includes [Intel Gaudi 1](https://habana.ai/products/gaudi/), [Intel Gaudi 2](https://habana.ai/products/gaudi2/), and [Intel Gaudi 3](https://habana.ai/products/gaudi3/). Each server is equipped with 8 devices, known as Habana Processing Units (HPUs), providing 128GB of memory on Gaudi 3, 96GB on Gaudi 2, and 32GB on the first-gen Gaudi. For more details on the underlying hardware architecture, check out the [Gaudi Architecture](https://docs.habana.ai/en/latest/Gaudi_Overview/Gaudi_Architecture.html) overview.\n+\n+[`TrainingArguments`], [`Trainer`] and [`Pipeline`] detect and set the backend device to `hpu` if an Intel Gaudi device is available. No additional changes are required to enable training and inference on your device.\n+\n+Some modeling code in Transformers is not optimized for HPU lazy mode. If you encounter any errors, set the environment variable below to use eager mode:\n+```\n+PT_HPU_LAZY_MODE=0\n+```\n+\n+In some cases, you'll also need to enable int64 support to avoid casting issues with long integers:\n+```\n+PT_ENABLE_INT64_SUPPORT=1\n+```\n+Refer to the [Gaudi docs](https://docs.habana.ai/en/latest/index.html) for more details.\n+\n+> [!TIP]\n+> For training and inference with Gaudi-optimized model implementations, we recommend using [Optimum for Intel Gaudi](https://huggingface.co/docs/optimum/main/en/habana/index)."
        }
    ],
    "stats": {
        "total": 36,
        "additions": 36,
        "deletions": 0
    }
}