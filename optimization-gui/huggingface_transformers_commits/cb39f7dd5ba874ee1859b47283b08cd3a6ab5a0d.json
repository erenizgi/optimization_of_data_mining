{
    "author": "zucchini-nlp",
    "message": "[qwen-omni] fix processor (#37493)\n\n* fix\n\n* delete print\n\n* accept kwargs in overriden models as well\n\n* remove duplicate",
    "sha": "cb39f7dd5ba874ee1859b47283b08cd3a6ab5a0d",
    "files": [
        {
            "sha": "d607b8b95e800ba51ee273f05679f694b06bcea2",
            "filename": "src/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py",
            "status": "modified",
            "additions": 5,
            "deletions": 3,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/cb39f7dd5ba874ee1859b47283b08cd3a6ab5a0d/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cb39f7dd5ba874ee1859b47283b08cd3a6ab5a0d/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py?ref=cb39f7dd5ba874ee1859b47283b08cd3a6ab5a0d",
            "patch": "@@ -244,11 +244,13 @@ def replace_multimodal_special_tokens(\n                         curr_video_grid_thw = next(video_grid_thw)\n                         height = curr_video_grid_thw[1] // self.image_processor.merge_size\n                         width = curr_video_grid_thw[2] // self.image_processor.merge_size\n-                        video_token_indices = np.arange(curr_video_grid_thw[0]).view(-1, 1, 1)\n-                        video_token_indices = video_token_indices.expand(-1, height, width).flatten()\n+                        video_token_indices = np.arange(curr_video_grid_thw[0]).reshape(-1, 1, 1)\n+                        video_token_indices = np.broadcast_to(\n+                            video_token_indices, (video_token_indices.shape[0], height, width)\n+                        ).reshape(-1)\n                         video_token_indices = (\n                             video_token_indices * next(video_second_per_grid) * position_id_per_seconds\n-                        ).long()\n+                        )\n \n                         tokens_per_chunk = int(position_id_per_seconds * seconds_per_chunk)\n                         video_chunk_indexes = self.get_chunked_index(video_token_indices, tokens_per_chunk)"
        },
        {
            "sha": "615e3104d6c4b76a919ac08eac5c37cb8ebb0ad5",
            "filename": "src/transformers/models/smolvlm/processing_smolvlm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/cb39f7dd5ba874ee1859b47283b08cd3a6ab5a0d/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fprocessing_smolvlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cb39f7dd5ba874ee1859b47283b08cd3a6ab5a0d/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fprocessing_smolvlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fprocessing_smolvlm.py?ref=cb39f7dd5ba874ee1859b47283b08cd3a6ab5a0d",
            "patch": "@@ -436,6 +436,7 @@ def _load_video_for_model(\n         fps: Optional[int] = None,\n         backend: str = \"opencv\",\n         skip_secs: int = 0.0,\n+        **kwargs,\n     ) -> np.array:\n         \"\"\"\n         Loads `video` to a numpy array."
        },
        {
            "sha": "b650972fb4f0dd010a90d2ea1b015250e8c63e80",
            "filename": "src/transformers/processing_utils.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/cb39f7dd5ba874ee1859b47283b08cd3a6ab5a0d/src%2Ftransformers%2Fprocessing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cb39f7dd5ba874ee1859b47283b08cd3a6ab5a0d/src%2Ftransformers%2Fprocessing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fprocessing_utils.py?ref=cb39f7dd5ba874ee1859b47283b08cd3a6ab5a0d",
            "patch": "@@ -1427,7 +1427,6 @@ def apply_chat_template(\n \n         # Fill sets of kwargs that should be used by different parts of template\n         processed_kwargs = {\n-            \"processor_kwargs\": {},\n             \"mm_load_kwargs\": {},\n             \"template_kwargs\": {},\n         }\n@@ -1551,14 +1550,14 @@ def apply_chat_template(\n             # without actionable solution for users\n             single_prompt = prompt[0] if is_batched else prompt\n             if self.tokenizer.bos_token is not None and single_prompt.startswith(self.tokenizer.bos_token):\n-                processed_kwargs[\"processor_kwargs\"][\"add_special_tokens\"] = False\n+                kwargs[\"add_special_tokens\"] = False\n \n             out = self(\n                 text=prompt,\n                 images=batch_images if batch_images else None,\n                 videos=batch_videos if batch_videos else None,\n                 audio=batch_audios if batch_audios else None,\n-                **processed_kwargs[\"processor_kwargs\"],\n+                **kwargs,\n             )\n             if return_dict:\n                 return out\n@@ -1574,6 +1573,7 @@ def _load_video_for_model(\n         num_frames: Optional[int] = None,\n         fps: Optional[int] = None,\n         backend: str = \"opencv\",\n+        **kwargs,\n     ) -> np.array:\n         \"\"\"\n         Loads `video` to a numpy array."
        },
        {
            "sha": "5cda62c39740fb3e61a508a90471f4d287a75f78",
            "filename": "tests/generation/test_utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/cb39f7dd5ba874ee1859b47283b08cd3a6ab5a0d/tests%2Fgeneration%2Ftest_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/cb39f7dd5ba874ee1859b47283b08cd3a6ab5a0d/tests%2Fgeneration%2Ftest_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fgeneration%2Ftest_utils.py?ref=cb39f7dd5ba874ee1859b47283b08cd3a6ab5a0d",
            "patch": "@@ -228,6 +228,10 @@ def _get_logits_processor_kwargs(self, do_sample=False, config=None):\n                 \"video_token_index\",\n                 \"video_token_id\",\n                 \"vision_start_token_id\",\n+                \"audio_token_index\",\n+                \"audio_start_token_id\",\n+                \"audio_end_token_id\",\n+                \"vision_end_token_id\",\n             ]:\n                 token_index = getattr(config, key, None)\n                 if token_index is None and hasattr(self, \"model_tester\"):"
        }
    ],
    "stats": {
        "total": 19,
        "additions": 13,
        "deletions": 6
    }
}