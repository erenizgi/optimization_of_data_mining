{
    "author": "mikamerath",
    "message": "Add option for running ffmpeg_microphone_live as a background process (#32838)\n\n* Add option for running ffmpeg_microphone_live as a background process\r\n\r\n* Code quality checks for audio_utils\r\n\r\n* Code clean up for audio_utils\r\n\r\n* Fixing logic in ffmpeg_microphone calls in audio_utils\r\n\r\n* Allowing any arbitrary arguments to be passed to ffmpeg_microphone_live\r\n\r\n* Formatting\r\n\r\n* Fixing last problems with adding ffmpeg_additional_args\r\n\r\n* Fixing default arguments and formatting issues\r\n\r\n* Fixing comments for ffmpeg_additional_args\r\n\r\n* Adding two shorts tests for ffmpeg_microphone_live\r\n\r\n* Fixing test bug",
    "sha": "eef6b0ba42c062eb8b2180327045c89199ea93f8",
    "files": [
        {
            "sha": "4a8a93c9683a825b05c46d113db7ee5cb424e882",
            "filename": "src/transformers/pipelines/audio_utils.py",
            "status": "modified",
            "additions": 23,
            "deletions": 1,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/eef6b0ba42c062eb8b2180327045c89199ea93f8/src%2Ftransformers%2Fpipelines%2Faudio_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/eef6b0ba42c062eb8b2180327045c89199ea93f8/src%2Ftransformers%2Fpipelines%2Faudio_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fpipelines%2Faudio_utils.py?ref=eef6b0ba42c062eb8b2180327045c89199ea93f8",
            "patch": "@@ -51,6 +51,7 @@ def ffmpeg_microphone(\n     chunk_length_s: float,\n     format_for_conversion: str = \"f32le\",\n     ffmpeg_input_device: Optional[str] = None,\n+    ffmpeg_additional_args: Optional[list[str]] = None,\n ):\n     \"\"\"\n     Helper function to read audio from a microphone using ffmpeg. The default input device will be used unless another\n@@ -70,6 +71,11 @@ def ffmpeg_microphone(\n             The indentifier of the input device to be used by ffmpeg (i.e. ffmpeg's '-i' argument). If unset,\n             the default input device will be used. See `https://www.ffmpeg.org/ffmpeg-devices.html#Input-Devices`\n             for how to specify and list input devices.\n+        ffmpeg_additional_args (`list[str]`, *optional*):\n+            Additional arguments to pass to ffmpeg, can include arguments like -nostdin for running as a background\n+            process. For example, to pass -nostdin to the ffmpeg process, pass in [\"-nostdin\"]. If passing in flags\n+            with multiple arguments, use the following convention (eg [\"flag\", \"arg1\", \"arg2]).\n+\n     Returns:\n         A generator yielding audio chunks of `chunk_length_s` seconds as `bytes` objects of length\n         `int(round(sampling_rate * chunk_length_s)) * size_of_sample`.\n@@ -95,6 +101,8 @@ def ffmpeg_microphone(\n         format_ = \"dshow\"\n         input_ = ffmpeg_input_device or _get_microphone_name()\n \n+    ffmpeg_additional_args = [] if ffmpeg_additional_args is None else ffmpeg_additional_args\n+\n     ffmpeg_command = [\n         \"ffmpeg\",\n         \"-f\",\n@@ -114,6 +122,9 @@ def ffmpeg_microphone(\n         \"quiet\",\n         \"pipe:1\",\n     ]\n+\n+    ffmpeg_command.extend(ffmpeg_additional_args)\n+\n     chunk_len = int(round(sampling_rate * chunk_length_s)) * size_of_sample\n     iterator = _ffmpeg_stream(ffmpeg_command, chunk_len)\n     for item in iterator:\n@@ -127,6 +138,7 @@ def ffmpeg_microphone_live(\n     stride_length_s: Optional[Union[Tuple[float, float], float]] = None,\n     format_for_conversion: str = \"f32le\",\n     ffmpeg_input_device: Optional[str] = None,\n+    ffmpeg_additional_args: Optional[list[str]] = None,\n ):\n     \"\"\"\n     Helper function to read audio from a microphone using ffmpeg. This will output `partial` overlapping chunks starting\n@@ -153,6 +165,11 @@ def ffmpeg_microphone_live(\n             The identifier of the input device to be used by ffmpeg (i.e. ffmpeg's '-i' argument). If unset,\n             the default input device will be used. See `https://www.ffmpeg.org/ffmpeg-devices.html#Input-Devices`\n             for how to specify and list input devices.\n+        ffmpeg_additional_args (`list[str]`, *optional*):\n+            Additional arguments to pass to ffmpeg, can include arguments like -nostdin for running as a background\n+            process. For example, to pass -nostdin to the ffmpeg process, pass in [\"-nostdin\"]. If passing in flags\n+            with multiple arguments, use the following convention (eg [\"flag\", \"arg1\", \"arg2]).\n+\n     Return:\n         A generator yielding dictionaries of the following form\n \n@@ -168,8 +185,13 @@ def ffmpeg_microphone_live(\n         chunk_s = chunk_length_s\n \n     microphone = ffmpeg_microphone(\n-        sampling_rate, chunk_s, format_for_conversion=format_for_conversion, ffmpeg_input_device=ffmpeg_input_device\n+        sampling_rate,\n+        chunk_s,\n+        format_for_conversion=format_for_conversion,\n+        ffmpeg_input_device=ffmpeg_input_device,\n+        ffmpeg_additional_args=[] if ffmpeg_additional_args is None else ffmpeg_additional_args,\n     )\n+\n     if format_for_conversion == \"s16le\":\n         dtype = np.int16\n         size_of_sample = 2"
        },
        {
            "sha": "b21e8cd25f240891cf627681fefc330d30555ebc",
            "filename": "tests/pipelines/test_pipelines_automatic_speech_recognition.py",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/eef6b0ba42c062eb8b2180327045c89199ea93f8/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/eef6b0ba42c062eb8b2180327045c89199ea93f8/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fpipelines%2Ftest_pipelines_automatic_speech_recognition.py?ref=eef6b0ba42c062eb8b2180327045c89199ea93f8",
            "patch": "@@ -33,7 +33,7 @@\n     WhisperForConditionalGeneration,\n )\n from transformers.pipelines import AutomaticSpeechRecognitionPipeline, pipeline\n-from transformers.pipelines.audio_utils import chunk_bytes_iter\n+from transformers.pipelines.audio_utils import chunk_bytes_iter, ffmpeg_microphone_live\n from transformers.pipelines.automatic_speech_recognition import _find_timestamp_sequence, chunk_iter\n from transformers.testing_utils import (\n     compare_pipeline_output_to_hub_spec,\n@@ -1989,3 +1989,11 @@ def test_chunk_bytes_iter_stride_stream(self):\n         )\n         with self.assertRaises(StopIteration):\n             next(iter_)\n+\n+    def test_ffmpeg_no_additional_args(self):\n+        mic = ffmpeg_microphone_live(16000, 2.0)\n+        mic.close()\n+\n+    def test_ffmpeg_additional_args(self):\n+        mic = ffmpeg_microphone_live(16000, 2.0, ffmpeg_additional_args=[\"-nostdin\"])\n+        mic.close()"
        }
    ],
    "stats": {
        "total": 34,
        "additions": 32,
        "deletions": 2
    }
}