{
    "author": "cyyever",
    "message": "Add weights_only=True to torch.load (#37062)",
    "sha": "28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
    "files": [
        {
            "sha": "43a1b75e51891bcbbe4e2bb94a19ecf40d9f8ab5",
            "filename": "src/transformers/data/datasets/glue.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fdata%2Fdatasets%2Fglue.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fdata%2Fdatasets%2Fglue.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdata%2Fdatasets%2Fglue.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -122,7 +122,7 @@ def __init__(\n         with FileLock(lock_path):\n             if os.path.exists(cached_features_file) and not args.overwrite_cache:\n                 start = time.time()\n-                self.features = torch.load(cached_features_file)\n+                self.features = torch.load(cached_features_file, weights_only=True)\n                 logger.info(\n                     f\"Loading features from cached file {cached_features_file} [took %.3f s]\", time.time() - start\n                 )"
        },
        {
            "sha": "803656b623edbffbfef01bb2d9644cfc6f983a93",
            "filename": "src/transformers/models/bark/convert_suno_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fbark%2Fconvert_suno_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fbark%2Fconvert_suno_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbark%2Fconvert_suno_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -109,7 +109,7 @@ def _load_model(ckpt_path, device, use_small=False, model_type=\"text\"):\n     if not os.path.exists(ckpt_path):\n         logger.info(f\"{model_type} model not found, downloading into `{CACHE_DIR}`.\")\n         _download(model_info[\"repo_id\"], model_info[\"file_name\"])\n-    checkpoint = torch.load(ckpt_path, map_location=device)\n+    checkpoint = torch.load(ckpt_path, map_location=device, weights_only=True)\n     # this is a hack\n     model_args = checkpoint[\"model_args\"]\n     if \"input_vocab_size\" not in model_args:"
        },
        {
            "sha": "84dc415443f0e81a43a528a9942142639bfae28e",
            "filename": "src/transformers/models/bart/convert_bart_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fbart%2Fconvert_bart_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fbart%2Fconvert_bart_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbart%2Fconvert_bart_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -71,7 +71,7 @@ def rename_key(dct, old, new):\n \n def load_xsum_checkpoint(checkpoint_path):\n     \"\"\"Checkpoint path should end in model.pt\"\"\"\n-    sd = torch.load(checkpoint_path, map_location=\"cpu\")\n+    sd = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n     hub_interface = torch.hub.load(\"pytorch/fairseq\", \"bart.large.cnn\").eval()\n     hub_interface.model.load_state_dict(sd[\"model\"])\n     return hub_interface"
        },
        {
            "sha": "8e1e85d5c04e51041822bbfc1843e14a820a1f0b",
            "filename": "src/transformers/models/bert/convert_bert_pytorch_checkpoint_to_original_tf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fbert%2Fconvert_bert_pytorch_checkpoint_to_original_tf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fbert%2Fconvert_bert_pytorch_checkpoint_to_original_tf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbert%2Fconvert_bert_pytorch_checkpoint_to_original_tf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -101,7 +101,7 @@ def main(raw_args=None):\n \n     model = BertModel.from_pretrained(\n         pretrained_model_name_or_path=args.model_name,\n-        state_dict=torch.load(args.pytorch_model_path),\n+        state_dict=torch.load(args.pytorch_model_path, weights_only=True),\n         cache_dir=args.cache_dir,\n     )\n "
        },
        {
            "sha": "c390d2e39f6e7056da4cceda5dcdd9e0c6caf8fd",
            "filename": "src/transformers/models/biogpt/convert_biogpt_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fconvert_biogpt_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fconvert_biogpt_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbiogpt%2Fconvert_biogpt_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -168,7 +168,7 @@ def convert_biogpt_checkpoint_to_pytorch(biogpt_checkpoint_path, pytorch_dump_fo\n     checkpoint_file = os.path.join(biogpt_checkpoint_path, \"checkpoint.pt\")\n     if not os.path.isfile(checkpoint_file):\n         raise ValueError(f\"path to the file {checkpoint_file} does not exist!\")\n-    chkpt = torch.load(checkpoint_file, map_location=\"cpu\")\n+    chkpt = torch.load(checkpoint_file, map_location=\"cpu\", weights_only=True)\n \n     args = chkpt[\"cfg\"][\"model\"]\n "
        },
        {
            "sha": "d8ce9b056c3da15911b90810f2ed1d7de7d078af",
            "filename": "src/transformers/models/blenderbot/convert_blenderbot_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fconvert_blenderbot_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fconvert_blenderbot_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblenderbot%2Fconvert_blenderbot_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -79,7 +79,7 @@ def convert_parlai_checkpoint(checkpoint_path, pytorch_dump_folder_path, config_\n     \"\"\"\n     Copy/paste/tweak model's weights to our BERT structure.\n     \"\"\"\n-    model = torch.load(checkpoint_path, map_location=\"cpu\")\n+    model = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n     sd = model[\"model\"]\n     cfg = BlenderbotConfig.from_json_file(config_json_path)\n     m = BlenderbotForConditionalGeneration(cfg)"
        },
        {
            "sha": "73d251875dc2efc6bc31603aa472f3831b8a2f15",
            "filename": "src/transformers/models/bloom/convert_bloom_original_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fbloom%2Fconvert_bloom_original_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fbloom%2Fconvert_bloom_original_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fbloom%2Fconvert_bloom_original_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -104,7 +104,7 @@ def convert_bloom_checkpoint_to_pytorch(\n             for i in range(pretraining_tp):\n                 # load all TP files\n                 f_name = file.replace(\"model_00\", f\"model_0{i}\")\n-                temp = torch.load(os.path.join(bloom_checkpoint_path, f_name), map_location=\"cpu\")\n+                temp = torch.load(os.path.join(bloom_checkpoint_path, f_name), map_location=\"cpu\", weights_only=True)\n \n                 # Rename keys in the transformers names\n                 keys = list(temp.keys())\n@@ -164,7 +164,7 @@ def convert_bloom_checkpoint_to_pytorch(\n             for i in range(pretraining_tp):\n                 # load all TP files\n                 f_name = file.replace(\"model_00\", f\"model_0{i}\")\n-                temp = torch.load(os.path.join(bloom_checkpoint_path, f_name), map_location=\"cpu\")\n+                temp = torch.load(os.path.join(bloom_checkpoint_path, f_name), map_location=\"cpu\", weights_only=True)\n \n                 # Rename keys in the transformers names\n                 keys = list(temp.keys())"
        },
        {
            "sha": "f74607f7b3c04cd9114847ff482d25aa7890e4ae",
            "filename": "src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py",
            "status": "modified",
            "additions": 5,
            "deletions": 3,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fchameleon%2Fconvert_chameleon_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fchameleon%2Fconvert_chameleon_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchameleon%2Fconvert_chameleon_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -130,13 +130,15 @@ def write_model(model_path, input_base_path, model_size, chameleon_version=1):\n         for possible_name in [\"consolidated.pth\", \"consolidated.00.pth\"]:\n             possible_path = os.path.join(input_model_path, possible_name)\n             if os.path.exists(possible_path):\n-                loaded = torch.load(possible_path, map_location=\"cpu\")\n+                loaded = torch.load(possible_path, map_location=\"cpu\", weights_only=True)\n                 break\n         assert loaded is not None\n     else:\n         # Sharded\n         loaded = [\n-            torch.load(os.path.join(input_model_path, f\"consolidated.{i:02d}.pth\"), map_location=\"cpu\")\n+            torch.load(\n+                os.path.join(input_model_path, f\"consolidated.{i:02d}.pth\"), map_location=\"cpu\", weights_only=True\n+            )\n             for i in range(num_shards)\n         ]\n \n@@ -314,7 +316,7 @@ def permute(w, n_heads, dim1=dim, dim2=dim):\n \n     # Load VQGAN weights\n     vqgan_path = os.path.join(input_base_path, \"tokenizer/vqgan.ckpt\")\n-    vqgan_state_dict = torch.load(vqgan_path, map_location=\"cpu\")[\"state_dict\"]\n+    vqgan_state_dict = torch.load(vqgan_path, map_location=\"cpu\", weights_only=True)[\"state_dict\"]\n     for k, v in vqgan_state_dict.items():\n         if \"decoder\" in k:\n             continue  # we dont do image generation yet"
        },
        {
            "sha": "adc9300ef512507a9cf30d1c5cf79aef006a2f3f",
            "filename": "src/transformers/models/chinese_clip/convert_chinese_clip_original_pytorch_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fconvert_chinese_clip_original_pytorch_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fconvert_chinese_clip_original_pytorch_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fconvert_chinese_clip_original_pytorch_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -104,7 +104,7 @@ def convert_chinese_clip_checkpoint(checkpoint_path, pytorch_dump_folder_path, c\n \n     hf_model = ChineseCLIPModel(config).eval()\n \n-    pt_weights = torch.load(checkpoint_path, map_location=\"cpu\")[\"state_dict\"]\n+    pt_weights = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"state_dict\"]\n     pt_weights = {(name[7:] if name.startswith(\"module.\") else name): value for name, value in pt_weights.items()}\n \n     copy_text_model_and_projection(hf_model, pt_weights)"
        },
        {
            "sha": "be2cfdee87de0bc7c79074fe2692eca1b31b5861",
            "filename": "src/transformers/models/clipseg/convert_clipseg_original_pytorch_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fclipseg%2Fconvert_clipseg_original_pytorch_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fclipseg%2Fconvert_clipseg_original_pytorch_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclipseg%2Fconvert_clipseg_original_pytorch_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -169,7 +169,7 @@ def convert_clipseg_checkpoint(model_name, checkpoint_path, pytorch_dump_folder_\n     model = CLIPSegForImageSegmentation(config)\n     model.eval()\n \n-    state_dict = torch.load(checkpoint_path, map_location=\"cpu\")\n+    state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n \n     # remove some keys\n     for key in state_dict.copy().keys():"
        },
        {
            "sha": "89babb3c4caf67d63a926e0217ccc2a9f4b77032",
            "filename": "src/transformers/models/clvp/convert_clvp_to_hf.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fclvp%2Fconvert_clvp_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fclvp%2Fconvert_clvp_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fclvp%2Fconvert_clvp_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -201,9 +201,9 @@ def convert_clvp_weights(checkpoint_path, pytorch_dump_folder_path):\n             _download(url=each_model_url, root=each_model_path)\n \n         if each_model_name == \"clvp\":\n-            clvp_checkpoint = torch.load(each_model_path, map_location=\"cpu\")\n+            clvp_checkpoint = torch.load(each_model_path, map_location=\"cpu\", weights_only=True)\n         else:\n-            decoder_checkpoint = torch.load(each_model_path, map_location=\"cpu\")\n+            decoder_checkpoint = torch.load(each_model_path, map_location=\"cpu\", weights_only=True)\n \n     # Converting the weights\n     converted_checkpoint.update(**convert_encoder_weights(clvp_checkpoint))"
        },
        {
            "sha": "d39777680b149c55f7512cc428027e2539b98eb1",
            "filename": "src/transformers/models/cvt/convert_cvt_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fcvt%2Fconvert_cvt_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fcvt%2Fconvert_cvt_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcvt%2Fconvert_cvt_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -309,7 +309,7 @@ def convert_cvt_checkpoint(cvt_model, image_size, cvt_file_name, pytorch_dump_fo\n     model = CvtForImageClassification(config)\n     image_processor = AutoImageProcessor.from_pretrained(\"facebook/convnext-base-224-22k-1k\")\n     image_processor.size[\"shortest_edge\"] = image_size\n-    original_weights = torch.load(cvt_file_name, map_location=torch.device(\"cpu\"))\n+    original_weights = torch.load(cvt_file_name, map_location=torch.device(\"cpu\"), weights_only=True)\n \n     huggingface_weights = OrderedDict()\n     list_of_state_dict = []"
        },
        {
            "sha": "ae3a67710150c2cce79c719e6534bdbd9eaa0260",
            "filename": "src/transformers/models/dab_detr/convert_dab_detr_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdab_detr%2Fconvert_dab_detr_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdab_detr%2Fconvert_dab_detr_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdab_detr%2Fconvert_dab_detr_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -143,7 +143,7 @@ def write_model(model_name, pretrained_model_weights_path, pytorch_dump_folder_p\n     config.id2label = id2label\n     config.label2id = {v: k for k, v in id2label.items()}\n     # load original model from local path\n-    loaded = torch.load(pretrained_model_weights_path, map_location=torch.device(\"cpu\"))[\"model\"]\n+    loaded = torch.load(pretrained_model_weights_path, map_location=torch.device(\"cpu\"), weights_only=True)[\"model\"]\n     # Renaming the original model state dictionary to HF compatibile\n     all_keys = list(loaded.keys())\n     new_keys = convert_old_keys_to_new_keys(all_keys)"
        },
        {
            "sha": "b1728a7da11a50e08625ff74d78b4c119d44601a",
            "filename": "src/transformers/models/dac/convert_dac_checkpoint.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdac%2Fconvert_dac_checkpoint.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdac%2Fconvert_dac_checkpoint.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdac%2Fconvert_dac_checkpoint.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -205,7 +205,7 @@ def convert_checkpoint(\n     sample_rate=16000,\n     repo_id=None,\n ):\n-    model_dict = torch.load(checkpoint_path, \"cpu\")\n+    model_dict = torch.load(checkpoint_path, \"cpu\", weights_only=True)\n \n     config = DacConfig()\n "
        },
        {
            "sha": "3f9d7773516aa68c4d0b789062a3e9bd6abd411a",
            "filename": "src/transformers/models/data2vec/convert_data2vec_vision_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fconvert_data2vec_vision_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fconvert_data2vec_vision_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdata2vec%2Fconvert_data2vec_vision_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -224,7 +224,7 @@ def load(module, prefix=\"\"):\n     )\n     patch_size = model.patch_embed.patch_size\n     args.window_size = (args.input_size // patch_size[0], args.input_size // patch_size[1])\n-    checkpoint = torch.load(args.beit_checkpoint, map_location=\"cpu\")\n+    checkpoint = torch.load(args.beit_checkpoint, map_location=\"cpu\", weights_only=True)\n \n     print(f\"Load ckpt from {args.beit_checkpoint}\")\n     checkpoint_model = None"
        },
        {
            "sha": "c88582eaccfd1ce64ef24341497f247434b9b562",
            "filename": "src/transformers/models/deformable_detr/convert_deformable_detr_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fconvert_deformable_detr_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fconvert_deformable_detr_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeformable_detr%2Fconvert_deformable_detr_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -125,7 +125,7 @@ def convert_deformable_detr_checkpoint(\n     logger.info(\"Converting model...\")\n \n     # load original state dict\n-    state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"model\"]\n+    state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"model\"]\n     # rename keys\n     for key in state_dict.copy().keys():\n         val = state_dict.pop(key)"
        },
        {
            "sha": "6436451190a842d20709f28a126a680fb81995ed",
            "filename": "src/transformers/models/deprecated/deta/convert_deta_resnet_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fdeta%2Fconvert_deta_resnet_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fdeta%2Fconvert_deta_resnet_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fdeta%2Fconvert_deta_resnet_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -229,7 +229,7 @@ def convert_deta_checkpoint(model_name, pytorch_dump_folder_path, push_to_hub):\n     else:\n         raise ValueError(f\"Model name {model_name} not supported\")\n     checkpoint_path = hf_hub_download(repo_id=\"nielsr/deta-checkpoints\", filename=filename)\n-    state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"model\"]\n+    state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"model\"]\n \n     # rename keys\n     rename_keys = create_rename_keys(config)"
        },
        {
            "sha": "c2e1ae6001d63f670b8001e28d6bfb188f3c42f2",
            "filename": "src/transformers/models/deprecated/deta/convert_deta_swin_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fdeta%2Fconvert_deta_swin_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fdeta%2Fconvert_deta_swin_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fdeta%2Fconvert_deta_swin_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -230,7 +230,7 @@ def convert_deta_checkpoint(model_name, pytorch_dump_folder_path, push_to_hub):\n     else:\n         raise ValueError(f\"Model name {model_name} not supported\")\n \n-    state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"model\"]\n+    state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"model\"]\n \n     # original state dict\n     for name, param in state_dict.items():"
        },
        {
            "sha": "8ac9a13f5c560995c03b81bc6405511e701de171",
            "filename": "src/transformers/models/deprecated/efficientformer/convert_efficientformer_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fefficientformer%2Fconvert_efficientformer_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fefficientformer%2Fconvert_efficientformer_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fefficientformer%2Fconvert_efficientformer_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -123,7 +123,7 @@ def prepare_img():\n def convert_efficientformer_checkpoint(\n     checkpoint_path: Path, efficientformer_config_file: Path, pytorch_dump_path: Path, push_to_hub: bool\n ):\n-    orig_state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"model\"]\n+    orig_state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"model\"]\n     config = EfficientFormerConfig.from_json_file(efficientformer_config_file)\n     model = EfficientFormerForImageClassificationWithTeacher(config)\n     model_name = \"_\".join(checkpoint_path.split(\"/\")[-1].split(\".\")[0].split(\"_\")[:-1])"
        },
        {
            "sha": "aac3b2efe733bd9f0c4eefb2d5442e15427c9347",
            "filename": "src/transformers/models/deprecated/jukebox/convert_jukebox.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fjukebox%2Fconvert_jukebox.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fjukebox%2Fconvert_jukebox.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fjukebox%2Fconvert_jukebox.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -228,7 +228,7 @@ def convert_openai_checkpoint(model_name=None, pytorch_dump_folder_path=None):\n     weight_dict = []\n     mapping = {}\n     for i, dict_name in enumerate(model_to_convert):\n-        old_dic = torch.load(f\"{pytorch_dump_folder_path}/{dict_name.split('/')[-1]}\")[\"model\"]\n+        old_dic = torch.load(f\"{pytorch_dump_folder_path}/{dict_name.split('/')[-1]}\", weights_only=True)[\"model\"]\n \n         new_dic = {}\n         for k in old_dic.keys():"
        },
        {
            "sha": "c6dbb12890e55fd26c39794aa28018265e98e164",
            "filename": "src/transformers/models/deprecated/mega/convert_mega_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 9,
            "deletions": 3,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fmega%2Fconvert_mega_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fmega%2Fconvert_mega_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fmega%2Fconvert_mega_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -132,13 +132,17 @@ def convert_checkpoint_to_huggingface(pretrained_checkpoint_path, output_path, i\n     print(\n         \"Original Mega encoder:\",\n         original_mlm.mega.load_state_dict(\n-            torch.load(os.path.join(pretrained_checkpoint_path, \"encoder_weights.pt\"), map_location=\"cpu\")\n+            torch.load(\n+                os.path.join(pretrained_checkpoint_path, \"encoder_weights.pt\"), map_location=\"cpu\", weights_only=True\n+            )\n         ),\n     )\n     print(\n         \"Original Mega MLM layer:\",\n         original_mlm.mlm_head.load_state_dict(\n-            torch.load(os.path.join(pretrained_checkpoint_path, \"mlm_head_weights.pt\"), map_location=\"cpu\")\n+            torch.load(\n+                os.path.join(pretrained_checkpoint_path, \"mlm_head_weights.pt\"), map_location=\"cpu\", weights_only=True\n+            )\n         ),\n     )\n \n@@ -234,7 +238,9 @@ def convert_checkpoint_to_huggingface(pretrained_checkpoint_path, output_path, i\n     print(\n         \"HF Mega MLM layer:\",\n         hf_mlm.mlm_head.load_state_dict(\n-            torch.load(os.path.join(pretrained_checkpoint_path, \"mlm_head_weights.pt\"), map_location=\"cpu\")\n+            torch.load(\n+                os.path.join(pretrained_checkpoint_path, \"mlm_head_weights.pt\"), map_location=\"cpu\", weights_only=True\n+            )\n         ),\n     )\n "
        },
        {
            "sha": "cd87217f051a04a6a339e93e6d77cfc85c701832",
            "filename": "src/transformers/models/deprecated/van/convert_van_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvan%2Fconvert_van_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvan%2Fconvert_van_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeprecated%2Fvan%2Fconvert_van_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -129,7 +129,7 @@ def convert_weight_and_push(\n     print(f\"Downloading weights for {name}...\")\n     checkpoint_path = cached_download(checkpoint)\n     print(f\"Converting {name}...\")\n-    from_state_dict = torch.load(checkpoint_path)[\"state_dict\"]\n+    from_state_dict = torch.load(checkpoint_path, weights_only=True)[\"state_dict\"]\n     from_model.load_state_dict(from_state_dict)\n     from_model.eval()\n     with torch.no_grad():"
        },
        {
            "sha": "d43ff7f40dddafe60d19db6630ee3eb9ef08da9c",
            "filename": "src/transformers/models/depth_anything/convert_depth_anything_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdepth_anything%2Fconvert_depth_anything_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdepth_anything%2Fconvert_depth_anything_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdepth_anything%2Fconvert_depth_anything_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -229,7 +229,7 @@ def convert_dpt_checkpoint(model_name, pytorch_dump_folder_path, push_to_hub, ve\n         filename=f\"{filename}\",\n     )\n \n-    state_dict = torch.load(filepath, map_location=\"cpu\")\n+    state_dict = torch.load(filepath, map_location=\"cpu\", weights_only=True)\n     # rename keys\n     rename_keys = create_rename_keys(config)\n     for src, dest in rename_keys:"
        },
        {
            "sha": "03f38084cfbf7428678e0ec7b25d0fe2ae9dace1",
            "filename": "src/transformers/models/dialogpt/convert_dialogpt_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdialogpt%2Fconvert_dialogpt_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdialogpt%2Fconvert_dialogpt_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdialogpt%2Fconvert_dialogpt_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -27,7 +27,7 @@\n \n \n def convert_dialogpt_checkpoint(checkpoint_path: str, pytorch_dump_folder_path: str):\n-    d = torch.load(checkpoint_path)\n+    d = torch.load(checkpoint_path, weights_only=True)\n     d[NEW_KEY] = d.pop(OLD_KEY)\n     os.makedirs(pytorch_dump_folder_path, exist_ok=True)\n     torch.save(d, os.path.join(pytorch_dump_folder_path, WEIGHTS_NAME))"
        },
        {
            "sha": "5151c0972a7ed72c47d125400b918aba3a0d3c0d",
            "filename": "src/transformers/models/dpr/convert_dpr_original_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdpr%2Fconvert_dpr_original_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdpr%2Fconvert_dpr_original_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdpr%2Fconvert_dpr_original_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -29,7 +29,9 @@\n \n def load_states_from_checkpoint(model_file: str) -> CheckpointState:\n     print(f\"Reading saved model from {model_file}\")\n-    state_dict = torch.load(model_file, map_location=lambda s, l: default_restore_location(s, \"cpu\"))\n+    state_dict = torch.load(\n+        model_file, map_location=lambda s, l: default_restore_location(s, \"cpu\"), weights_only=True\n+    )\n     return CheckpointState(**state_dict)\n \n "
        },
        {
            "sha": "ceae9b84711463261f20e70b7cd174437a1666cd",
            "filename": "src/transformers/models/dpt/convert_dpt_hybrid_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdpt%2Fconvert_dpt_hybrid_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fdpt%2Fconvert_dpt_hybrid_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdpt%2Fconvert_dpt_hybrid_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -226,7 +226,7 @@ def convert_dpt_checkpoint(checkpoint_url, pytorch_dump_folder_path, push_to_hub\n     config, expected_shape = get_dpt_config(checkpoint_url)\n     # load original state_dict from URL\n     # state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location=\"cpu\")\n-    state_dict = torch.load(checkpoint_url, map_location=\"cpu\")\n+    state_dict = torch.load(checkpoint_url, map_location=\"cpu\", weights_only=True)\n     # remove certain keys\n     remove_ignore_keys_(state_dict)\n     # rename keys"
        },
        {
            "sha": "f1fb0168705f42b943cb5d9bd40aa904c294cfb6",
            "filename": "src/transformers/models/encodec/convert_encodec_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fencodec%2Fconvert_encodec_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fencodec%2Fconvert_encodec_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fencodec%2Fconvert_encodec_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -325,7 +325,7 @@ def convert_checkpoint(\n     )\n     feature_extractor.save_pretrained(pytorch_dump_folder_path)\n \n-    original_checkpoint = torch.load(checkpoint_path)\n+    original_checkpoint = torch.load(checkpoint_path, weights_only=True)\n     if \"best_state\" in original_checkpoint:\n         # we might have a training state saved, in which case discard the yaml results and just retain the weights\n         original_checkpoint = original_checkpoint[\"best_state\"]"
        },
        {
            "sha": "3a5bb2d2e2e92481739184d30846c5ee1c987f40",
            "filename": "src/transformers/models/fastspeech2_conformer/convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fconvert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fconvert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fconvert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -164,7 +164,7 @@ def convert_FastSpeech2ConformerModel_checkpoint(\n     # Prepare the model\n     model = FastSpeech2ConformerModel(config)\n \n-    espnet_checkpoint = torch.load(checkpoint_path)\n+    espnet_checkpoint = torch.load(checkpoint_path, weights_only=True)\n     hf_compatible_state_dict = convert_espnet_state_dict_to_hf(espnet_checkpoint)\n \n     model.load_state_dict(hf_compatible_state_dict)"
        },
        {
            "sha": "70aada84bd5b49a28bbdcee605dfa035a20a20b9",
            "filename": "src/transformers/models/fastspeech2_conformer/convert_hifigan.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fconvert_hifigan.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fconvert_hifigan.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fconvert_hifigan.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -104,7 +104,7 @@ def convert_hifigan_checkpoint(\n \n     model = FastSpeech2ConformerHifiGan(config)\n \n-    orig_checkpoint = torch.load(checkpoint_path)\n+    orig_checkpoint = torch.load(checkpoint_path, weights_only=True)\n     load_weights(orig_checkpoint, model, config)\n \n     model.save_pretrained(pytorch_dump_folder_path)"
        },
        {
            "sha": "6f840438dcaea99ab9ac51e8373bb1b5f753169c",
            "filename": "src/transformers/models/fastspeech2_conformer/convert_model_with_hifigan.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fconvert_model_with_hifigan.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fconvert_model_with_hifigan.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Fconvert_model_with_hifigan.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -51,7 +51,7 @@ def convert_FastSpeech2ConformerWithHifiGan_checkpoint(\n \n     model = FastSpeech2ConformerModel(model_config)\n \n-    espnet_checkpoint = torch.load(checkpoint_path)\n+    espnet_checkpoint = torch.load(checkpoint_path, weights_only=True)\n     hf_compatible_state_dict = convert_espnet_state_dict_to_hf(espnet_checkpoint)\n     model.load_state_dict(hf_compatible_state_dict)\n "
        },
        {
            "sha": "6408d0e1df04cca9c06f5ee1eba2d30f0cb5163e",
            "filename": "src/transformers/models/flava/convert_dalle_to_flava_codebook.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fflava%2Fconvert_dalle_to_flava_codebook.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fflava%2Fconvert_dalle_to_flava_codebook.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflava%2Fconvert_dalle_to_flava_codebook.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -62,7 +62,7 @@ def convert_dalle_checkpoint(checkpoint_path, pytorch_dump_folder_path, config_p\n \n     encoder = Encoder()\n     if os.path.exists(checkpoint_path):\n-        ckpt = torch.load(checkpoint_path)\n+        ckpt = torch.load(checkpoint_path, weights_only=True)\n     else:\n         ckpt = torch.hub.load_state_dict_from_url(checkpoint_path)\n "
        },
        {
            "sha": "8b6e536a3ab59f6d35e9759971c1410d00dc0c3e",
            "filename": "src/transformers/models/flava/convert_flava_original_pytorch_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fflava%2Fconvert_flava_original_pytorch_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fflava%2Fconvert_flava_original_pytorch_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflava%2Fconvert_flava_original_pytorch_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -73,7 +73,7 @@ def convert_flava_checkpoint(checkpoint_path, codebook_path, pytorch_dump_folder\n     codebook_state_dict = convert_dalle_checkpoint(codebook_path, None, save_checkpoint=False)\n \n     if os.path.exists(checkpoint_path):\n-        state_dict = torch.load(checkpoint_path, map_location=\"cpu\")\n+        state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n     else:\n         state_dict = torch.hub.load_state_dict_from_url(checkpoint_path, map_location=\"cpu\")\n "
        },
        {
            "sha": "29ef7859c9a089d9e74cf486fd480a227a4727c1",
            "filename": "src/transformers/models/fuyu/convert_fuyu_model_weights_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Ffuyu%2Fconvert_fuyu_model_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Ffuyu%2Fconvert_fuyu_model_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffuyu%2Fconvert_fuyu_model_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -87,7 +87,7 @@ def rename_state_dict(state_dict):\n \n def convert_fuyu_checkpoint(pytorch_dump_folder_path, ada_lib_path, pt_model_path, safe_serialization=False):\n     sys.path.insert(0, ada_lib_path)\n-    model_state_dict_base = torch.load(pt_model_path, map_location=\"cpu\")\n+    model_state_dict_base = torch.load(pt_model_path, map_location=\"cpu\", weights_only=True)\n     state_dict = flatdict.FlatDict(model_state_dict_base[\"model\"], \".\")\n     state_dict = rename_state_dict(state_dict)\n "
        },
        {
            "sha": "fd275c157f37c38e0e982d040f2bf2fd76240836",
            "filename": "src/transformers/models/gemma/convert_gemma_weights_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fgemma%2Fconvert_gemma_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fgemma%2Fconvert_gemma_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma%2Fconvert_gemma_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -72,7 +72,7 @@ def write_model(save_path, input_base_path, config, safe_serialization=True, pus\n     head_dim = config.head_dim\n \n     print(f\"Fetching all parameters from the checkpoint at '{input_base_path}'\")\n-    model_state_dict = torch.load(input_base_path, map_location=\"cpu\")[\"model_state_dict\"]\n+    model_state_dict = torch.load(input_base_path, map_location=\"cpu\", weights_only=True)[\"model_state_dict\"]\n     model_state_dict.pop(\"freqs_cis\")\n \n     state_dict = {}"
        },
        {
            "sha": "c41f9a2fdbb2f0e760f19cf76a0ffa8c2caeb21e",
            "filename": "src/transformers/models/gemma2/convert_gemma2_weights_to_hf.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fgemma2%2Fconvert_gemma2_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fgemma2%2Fconvert_gemma2_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma2%2Fconvert_gemma2_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -97,11 +97,11 @@ def write_model(save_path, input_base_path, config, safe_serialization=True, pus\n \n         for file in files:\n             print(file)\n-            loaded_state_dict = torch.load(os.path.join(input_base_path, file), map_location=\"cpu\")\n+            loaded_state_dict = torch.load(os.path.join(input_base_path, file), map_location=\"cpu\", weights_only=True)\n             model_state_dict.update(loaded_state_dict)\n     else:\n         print(\"Model does not seem to be sharded\")\n-        model_state_dict = torch.load(input_base_path, map_location=\"cpu\")[\"model_state_dict\"]\n+        model_state_dict = torch.load(input_base_path, map_location=\"cpu\", weights_only=True)[\"model_state_dict\"]\n         model_state_dict.pop(\"freqs_cis\")\n \n     state_dict = {}"
        },
        {
            "sha": "4a9d8a0159991d5a1a5ff6116e8292d876b53cb5",
            "filename": "src/transformers/models/git/convert_git_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fgit%2Fconvert_git_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fgit%2Fconvert_git_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgit%2Fconvert_git_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -297,7 +297,7 @@ def convert_git_checkpoint(model_name, pytorch_dump_folder_path, push_to_hub=Fal\n     if \"large\" in model_name and not is_video and \"large-r\" not in model_name:\n         # large checkpoints take way too long to download\n         checkpoint_path = model_name_to_path[model_name]\n-        state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"model\"]\n+        state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"model\"]\n     else:\n         checkpoint_url = model_name_to_url[model_name]\n         state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location=\"cpu\", file_name=model_name)["
        },
        {
            "sha": "df1fd7537f4c2ed2dd3077efdb5ded0dd3e3974f",
            "filename": "src/transformers/models/glm/convert_glm_weights_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fglm%2Fconvert_glm_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fglm%2Fconvert_glm_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm%2Fconvert_glm_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -53,7 +53,7 @@ def load_weights(input_dir: str):\n     elif bin_files:\n         bin_files = sorted(bin_files, key=lambda x: int(x.rsplit(\"-\", 3)[1]))\n         for file in bin_files:\n-            tensors = torch.load(file, map_location=\"cpu\")\n+            tensors = torch.load(file, map_location=\"cpu\", weights_only=True)\n             all_weights.update(tensors)\n         return all_weights\n "
        },
        {
            "sha": "51088fb724433188a401eacf7289d8b3ff160a26",
            "filename": "src/transformers/models/glpn/convert_glpn_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fglpn%2Fconvert_glpn_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fglpn%2Fconvert_glpn_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglpn%2Fconvert_glpn_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -140,7 +140,7 @@ def convert_glpn_checkpoint(checkpoint_path, pytorch_dump_folder_path, push_to_h\n     logger.info(\"Converting model...\")\n \n     # load original state dict\n-    state_dict = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n+    state_dict = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"), weights_only=True)\n \n     # rename keys\n     state_dict = rename_keys(state_dict)"
        },
        {
            "sha": "c4e2ff67c5c8786d7665f12d1b61993411a12ddb",
            "filename": "src/transformers/models/gpt_sw3/convert_megatron_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fgpt_sw3%2Fconvert_megatron_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fgpt_sw3%2Fconvert_megatron_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_sw3%2Fconvert_megatron_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -153,7 +153,7 @@ def main(args):\n         raise FileNotFoundError(f\"ERROR! could not find file {checkpoint_path}\")\n \n     # Load the model.\n-    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n+    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n \n     # Load the config.\n     config_megatron = checkpoint[\"hyper_parameters\"][\"cfg\"]"
        },
        {
            "sha": "6bc28184985064c9336e3a168d1542f5245efbe2",
            "filename": "src/transformers/models/groupvit/convert_groupvit_nvlab_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fgroupvit%2Fconvert_groupvit_nvlab_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fgroupvit%2Fconvert_groupvit_nvlab_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgroupvit%2Fconvert_groupvit_nvlab_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -163,7 +163,7 @@ def convert_groupvit_checkpoint(\n     config = GroupViTConfig()\n     model = GroupViTModel(config).eval()\n \n-    state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"model\"]\n+    state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"model\"]\n     new_state_dict = convert_state_dict(state_dict, config)\n     missing_keys, unexpected_keys = model.load_state_dict(new_state_dict, strict=False)\n     assert missing_keys == [\"text_model.embeddings.position_ids\"]"
        },
        {
            "sha": "c66c41ce36b576659ad682cebc6accc2aabc4f84",
            "filename": "src/transformers/models/hubert/convert_hubert_original_s3prl_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fhubert%2Fconvert_hubert_original_s3prl_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fhubert%2Fconvert_hubert_original_s3prl_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhubert%2Fconvert_hubert_original_s3prl_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -32,7 +32,7 @@ def convert_s3prl_checkpoint(base_model_name, config_path, checkpoint_path, mode\n     \"\"\"\n     Copy/paste/tweak model's weights to transformers design.\n     \"\"\"\n-    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n+    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n     if checkpoint[\"Config\"][\"downstream_expert\"][\"modelrc\"][\"select\"] not in SUPPORTED_MODELS:\n         raise NotImplementedError(f\"The supported s3prl models are {SUPPORTED_MODELS}\")\n "
        },
        {
            "sha": "84b5c53a916ffc27c88927cc71c63b749a0583df",
            "filename": "src/transformers/models/llama/convert_llama_weights_to_hf.py",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fllama%2Fconvert_llama_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fllama%2Fconvert_llama_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllama%2Fconvert_llama_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -228,12 +228,17 @@ def permute(w, n_heads, dim1=dim, dim2=dim):\n         if num_shards == 1:\n             # Not sharded\n             # (The sharded implementation would also work, but this is simpler.)\n-            loaded = torch.load(os.path.join(input_base_path, \"consolidated.00.pth\"), map_location=\"cpu\")\n+            loaded = torch.load(\n+                os.path.join(input_base_path, \"consolidated.00.pth\"), map_location=\"cpu\", weights_only=True\n+            )\n         else:\n             # Sharded\n             checkpoint_list = sorted([file for file in os.listdir(input_base_path) if file.endswith(\".pth\")])\n             print(\"Loading in order:\", checkpoint_list)\n-            loaded = [torch.load(os.path.join(input_base_path, file), map_location=\"cpu\") for file in checkpoint_list]\n+            loaded = [\n+                torch.load(os.path.join(input_base_path, file), map_location=\"cpu\", weights_only=True)\n+                for file in checkpoint_list\n+            ]\n         param_count = 0\n         index_dict = {\"weight_map\": {}}\n         for layer_i in range(n_layers):"
        },
        {
            "sha": "85f21d4a5be13b63c1500713fe6e7cb9605b02a7",
            "filename": "src/transformers/models/llava_next/convert_llava_next_weights_to_hf.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fllava_next%2Fconvert_llava_next_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fllava_next%2Fconvert_llava_next_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_next%2Fconvert_llava_next_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -219,12 +219,12 @@ def convert_llava_to_hf(model_id, pytorch_dump_folder_path, push_to_hub=False):\n \n     # verify inputs\n     filepath = hf_hub_download(repo_id=\"nielsr/test-image\", filename=\"llava_1_6_pixel_values.pt\", repo_type=\"dataset\")\n-    original_pixel_values = torch.load(filepath, map_location=\"cpu\")\n+    original_pixel_values = torch.load(filepath, map_location=\"cpu\", weights_only=True)\n     assert torch.allclose(original_pixel_values, inputs.pixel_values.half())\n \n     if model_id == \"liuhaotian/llava-v1.6-mistral-7b\":\n         filepath = hf_hub_download(repo_id=\"nielsr/test-image\", filename=\"llava_1_6_input_ids.pt\", repo_type=\"dataset\")\n-        original_input_ids = torch.load(filepath, map_location=\"cpu\")\n+        original_input_ids = torch.load(filepath, map_location=\"cpu\", weights_only=True)\n         # replace -200 by image_token_index (since we use token ID = 32000 for the image token)\n         original_input_ids[original_input_ids == -200] = image_token_index\n         assert original_input_ids[0].tolist() == inputs.input_ids[0].tolist()\n@@ -233,7 +233,7 @@ def convert_llava_to_hf(model_id, pytorch_dump_folder_path, push_to_hub=False):\n         filepath = hf_hub_download(\n             repo_id=\"nielsr/test-image\", filename=\"llava_1_6_34b_input_ids.pt\", repo_type=\"dataset\"\n         )\n-        original_input_ids = torch.load(filepath, map_location=\"cpu\")\n+        original_input_ids = torch.load(filepath, map_location=\"cpu\", weights_only=True)\n         # replace -200 by image_token_index\n         original_input_ids[original_input_ids == -200] = image_token_index\n "
        },
        {
            "sha": "bd8b9e3c4c9f9f7028a5179d7e0f6a031aeec8ba",
            "filename": "src/transformers/models/llava_onevision/convert_llava_onevision_weights_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fconvert_llava_onevision_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fconvert_llava_onevision_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fconvert_llava_onevision_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -212,7 +212,7 @@ def convert_llava_to_hf(model_id, pytorch_dump_folder_path, push_to_hub=False):\n     filepath = hf_hub_download(\n         repo_id=\"RaushanTurganbay/test-image\", filename=\"llava_onevision_pixel_values.pt\", repo_type=\"dataset\"\n     )\n-    original_pixel_values = torch.load(filepath, map_location=\"cpu\")\n+    original_pixel_values = torch.load(filepath, map_location=\"cpu\", weights_only=True)\n     assert torch.allclose(original_pixel_values, inputs.pixel_values.half())\n \n     image_sizes = torch.tensor([[899, 1024]])"
        },
        {
            "sha": "cbd7600e96398a5d595f7df318506edd11db3376",
            "filename": "src/transformers/models/longformer/convert_longformer_original_pytorch_lightning_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Flongformer%2Fconvert_longformer_original_pytorch_lightning_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Flongformer%2Fconvert_longformer_original_pytorch_lightning_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flongformer%2Fconvert_longformer_original_pytorch_lightning_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -42,7 +42,7 @@ def convert_longformer_qa_checkpoint_to_pytorch(\n     longformer = LongformerModel.from_pretrained(longformer_model)\n     lightning_model = LightningModel(longformer)\n \n-    ckpt = torch.load(longformer_question_answering_ckpt_path, map_location=torch.device(\"cpu\"))\n+    ckpt = torch.load(longformer_question_answering_ckpt_path, map_location=torch.device(\"cpu\"), weights_only=True)\n     lightning_model.load_state_dict(ckpt[\"state_dict\"])\n \n     # init longformer question answering model"
        },
        {
            "sha": "aae550e8d096006952255f3a4804d59fde0ca3b3",
            "filename": "src/transformers/models/luke/convert_luke_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fluke%2Fconvert_luke_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fluke%2Fconvert_luke_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fluke%2Fconvert_luke_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -32,7 +32,7 @@ def convert_luke_checkpoint(checkpoint_path, metadata_path, entity_vocab_path, p\n     config = LukeConfig(use_entity_aware_attention=True, **metadata[\"model_config\"])\n \n     # Load in the weights from the checkpoint_path\n-    state_dict = torch.load(checkpoint_path, map_location=\"cpu\")\n+    state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n \n     # Load the entity vocab file\n     entity_vocab = load_entity_vocab(entity_vocab_path)"
        },
        {
            "sha": "02e7ef23a085177b7689383c1dbda41002c91a36",
            "filename": "src/transformers/models/m2m_100/convert_m2m100_original_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fm2m_100%2Fconvert_m2m100_original_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fm2m_100%2Fconvert_m2m100_original_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fm2m_100%2Fconvert_m2m100_original_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -43,7 +43,7 @@ def make_linear_from_emb(emb):\n \n \n def convert_fairseq_m2m100_checkpoint_from_disk(checkpoint_path):\n-    m2m_100 = torch.load(checkpoint_path, map_location=\"cpu\")\n+    m2m_100 = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n     args = m2m_100[\"args\"] or m2m_100[\"cfg\"][\"model\"]\n     state_dict = m2m_100[\"model\"]\n     remove_ignore_keys_(state_dict)"
        },
        {
            "sha": "f55b032207c01362b4025a36d139e8b54a3e296e",
            "filename": "src/transformers/models/mamba/convert_mamba_ssm_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmamba%2Fconvert_mamba_ssm_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmamba%2Fconvert_mamba_ssm_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmamba%2Fconvert_mamba_ssm_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -108,7 +108,7 @@ def convert_mamba_checkpoint_file_to_huggingface_model_file(\n         )\n     logger.info(f\"Loading model from {mamba_checkpoint_path} based on config from {config_json_file}\")\n     # Load weights and config from paths\n-    original_state_dict = torch.load(mamba_checkpoint_path, map_location=\"cpu\")\n+    original_state_dict = torch.load(mamba_checkpoint_path, map_location=\"cpu\", weights_only=True)\n     with open(config_json_file, \"r\", encoding=\"utf-8\") as json_file:\n         original_ssm_config_dict = json.load(json_file)\n "
        },
        {
            "sha": "bd1d413f40a8367018f5f939d815a208160f414a",
            "filename": "src/transformers/models/mamba2/convert_mamba2_ssm_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmamba2%2Fconvert_mamba2_ssm_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmamba2%2Fconvert_mamba2_ssm_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmamba2%2Fconvert_mamba2_ssm_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -38,7 +38,7 @@ def load_state_dict_from_safetensors(mamba2_checkpoint_path: str, ckpt_name: str\n \n \n def load_state_dict_from_torch(mamba2_checkpoint_path: str, ckpt_name: str) -> Dict[str, torch.Tensor]:\n-    return torch.load(path.join(mamba2_checkpoint_path, ckpt_name), map_location=\"cpu\")\n+    return torch.load(path.join(mamba2_checkpoint_path, ckpt_name), map_location=\"cpu\", weights_only=True)\n \n \n def convert_ssm_config_to_hf_config(config_ssm: Dict, mamba2_model_dict: Dict) -> Mamba2Config:"
        },
        {
            "sha": "909b7b41284c93a60694f8c64c77ded62dfb9346",
            "filename": "src/transformers/models/mbart/convert_mbart_original_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmbart%2Fconvert_mbart_original_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmbart%2Fconvert_mbart_original_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmbart%2Fconvert_mbart_original_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -43,7 +43,7 @@ def make_linear_from_emb(emb):\n def convert_fairseq_mbart_checkpoint_from_disk(\n     checkpoint_path, hf_config_path=\"facebook/mbart-large-en-ro\", finetuned=False, mbart_50=False\n ):\n-    state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"model\"]\n+    state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"model\"]\n     remove_ignore_keys_(state_dict)\n     vocab_size = state_dict[\"encoder.embed_tokens.weight\"].shape[0]\n "
        },
        {
            "sha": "cd29b7ad78cc29686ef2486a5f2620b2051b4a4e",
            "filename": "src/transformers/models/megatron_bert/convert_megatron_bert_checkpoint.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmegatron_bert%2Fconvert_megatron_bert_checkpoint.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmegatron_bert%2Fconvert_megatron_bert_checkpoint.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmegatron_bert%2Fconvert_megatron_bert_checkpoint.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -294,9 +294,9 @@ def main():\n     if args.path_to_checkpoint.endswith(\".zip\"):\n         with zipfile.ZipFile(args.path_to_checkpoint, \"r\") as checkpoint:\n             with checkpoint.open(\"release/mp_rank_00/model_optim_rng.pt\") as pytorch_dict:\n-                input_state_dict = torch.load(pytorch_dict, map_location=\"cpu\")\n+                input_state_dict = torch.load(pytorch_dict, map_location=\"cpu\", weights_only=True)\n     else:\n-        input_state_dict = torch.load(args.path_to_checkpoint, map_location=\"cpu\")\n+        input_state_dict = torch.load(args.path_to_checkpoint, map_location=\"cpu\", weights_only=True)\n \n     if args.config_file == \"\":\n         # Default config of megatron-bert 345m"
        },
        {
            "sha": "548e2d1aeb3647bb6c1790d5c24c24b0c969ae8d",
            "filename": "src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmegatron_gpt2%2Fcheckpoint_reshaping_and_interoperability.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmegatron_gpt2%2Fcheckpoint_reshaping_and_interoperability.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmegatron_gpt2%2Fcheckpoint_reshaping_and_interoperability.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -275,7 +275,7 @@ def merge_transformers_sharded_states(path, num_checkpoints):\n     state_dict = {}\n     for i in range(1, num_checkpoints + 1):\n         checkpoint_path = os.path.join(path, f\"pytorch_model-{i:05d}-of-{num_checkpoints:05d}.bin\")\n-        current_chunk = torch.load(checkpoint_path, map_location=\"cpu\")\n+        current_chunk = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n         state_dict.update(current_chunk)\n     return state_dict\n \n@@ -298,7 +298,7 @@ def get_megatron_sharded_states(args, tp_size, pp_size, pp_rank):\n             checkpoint_path = os.path.join(args.load_path, sub_dir_name, checkpoint_name)\n             if os.path.isfile(checkpoint_path):\n                 break\n-        state_dict = torch.load(checkpoint_path, map_location=\"cpu\")\n+        state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n         tp_state_dicts.append(state_dict)\n     return tp_state_dicts\n \n@@ -338,7 +338,7 @@ def convert_checkpoint_from_megatron_to_transformers(args):\n             rank0_checkpoint_path = os.path.join(args.load_path, sub_dir, rank0_checkpoint_name)\n             break\n     print(f\"Loading Megatron-LM checkpoint arguments from: {rank0_checkpoint_path}\")\n-    state_dict = torch.load(rank0_checkpoint_path, map_location=\"cpu\")\n+    state_dict = torch.load(rank0_checkpoint_path, map_location=\"cpu\", weights_only=True)\n     megatron_args = state_dict.get(\"args\", None)\n     if megatron_args is None:\n         raise ValueError(\n@@ -634,7 +634,7 @@ def convert_checkpoint_from_transformers_to_megatron(args):\n     sub_dirs = [x for x in os.listdir(args.load_path) if x.startswith(\"pytorch_model\")]\n     if len(sub_dirs) == 1:\n         checkpoint_name = \"pytorch_model.bin\"\n-        state_dict = torch.load(os.path.join(args.load_path, checkpoint_name), map_location=\"cpu\")\n+        state_dict = torch.load(os.path.join(args.load_path, checkpoint_name), map_location=\"cpu\", weights_only=True)\n     else:\n         num_checkpoints = len(sub_dirs) - 1\n         state_dict = merge_transformers_sharded_states(args.load_path, num_checkpoints)"
        },
        {
            "sha": "5515b6d6155542d5b2f8e6b54d7d957dc0742380",
            "filename": "src/transformers/models/megatron_gpt2/convert_megatron_gpt2_checkpoint.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmegatron_gpt2%2Fconvert_megatron_gpt2_checkpoint.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmegatron_gpt2%2Fconvert_megatron_gpt2_checkpoint.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmegatron_gpt2%2Fconvert_megatron_gpt2_checkpoint.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -263,9 +263,9 @@ def main():\n     if args.path_to_checkpoint.endswith(\".zip\"):\n         with zipfile.ZipFile(args.path_to_checkpoint, \"r\") as checkpoint:\n             with checkpoint.open(\"release/mp_rank_00/model_optim_rng.pt\") as pytorch_dict:\n-                input_state_dict = torch.load(pytorch_dict, map_location=\"cpu\")\n+                input_state_dict = torch.load(pytorch_dict, map_location=\"cpu\", weights_only=True)\n     else:\n-        input_state_dict = torch.load(args.path_to_checkpoint, map_location=\"cpu\")\n+        input_state_dict = torch.load(args.path_to_checkpoint, map_location=\"cpu\", weights_only=True)\n \n     ds_args = input_state_dict.get(\"args\", None)\n "
        },
        {
            "sha": "0f9cf597d5cce56564b64d0314996eaa4a252b89",
            "filename": "src/transformers/models/mistral/convert_mistral_weights_to_hf.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmistral%2Fconvert_mistral_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmistral%2Fconvert_mistral_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmistral%2Fconvert_mistral_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -208,7 +208,9 @@ def convert_and_write_model(input_dir: str, output_dir: str, max_position_embedd\n     else:\n         shards = [file for file in os.listdir(input_dir) if re.match(r\"consolidated.\\d+.pth\", file)]\n         shards = sorted(shards, key=lambda x: int(x.split(\".\")[1]))\n-        loaded_shards = [torch.load(os.path.join(input_dir, file), map_location=\"cpu\") for file in shards]\n+        loaded_shards = [\n+            torch.load(os.path.join(input_dir, file), map_location=\"cpu\", weights_only=True) for file in shards\n+        ]\n         full_state_dict = convert_state_dict_sharded(loaded_shards, config)\n \n     # Load weights into model and resave them"
        },
        {
            "sha": "7e9f25d37f4bbf164c5260b48709f939b350152a",
            "filename": "src/transformers/models/mixtral/convert_mixtral_weights_to_hf.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmixtral%2Fconvert_mixtral_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmixtral%2Fconvert_mixtral_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmixtral%2Fconvert_mixtral_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -94,7 +94,8 @@ def permute(w, n_heads=n_heads, dim1=dim, dim2=dim):\n     print(f\"Fetching all parameters from the checkpoint at {input_base_path}.\")\n     # Load weights\n     loaded = [\n-        torch.load(os.path.join(input_base_path, f\"consolidated.{i:02d}.pt\"), map_location=\"cpu\") for i in range(8)\n+        torch.load(os.path.join(input_base_path, f\"consolidated.{i:02d}.pt\"), map_location=\"cpu\", weights_only=True)\n+        for i in range(8)\n     ]\n \n     merged_state_dict = {}"
        },
        {
            "sha": "2d361af61e6ad39c3ed4d0de8c7315e7c804f419",
            "filename": "src/transformers/models/mllama/convert_mllama_weights_to_hf.py",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmllama%2Fconvert_mllama_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmllama%2Fconvert_mllama_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmllama%2Fconvert_mllama_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -342,10 +342,15 @@ def write_model(\n             path = os.path.join(input_base_path, \"consolidated.00.pth\")\n         else:\n             path = os.path.join(input_base_path, \"consolidated.pth\")\n-        loaded = [torch.load(path, map_location=\"cpu\", mmap=True)]\n+        loaded = [torch.load(path, map_location=\"cpu\", mmap=True, weights_only=True)]\n     else:\n         loaded = [\n-            torch.load(os.path.join(input_base_path, f\"consolidated.{i:02d}.pth\"), map_location=\"cpu\", mmap=True)\n+            torch.load(\n+                os.path.join(input_base_path, f\"consolidated.{i:02d}.pth\"),\n+                map_location=\"cpu\",\n+                mmap=True,\n+                weights_only=True,\n+            )\n             for i in range(num_shards)\n         ]\n "
        },
        {
            "sha": "5a74d4114acba14ccaa968c615814996363c3879",
            "filename": "src/transformers/models/mluke/convert_mluke_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmluke%2Fconvert_mluke_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmluke%2Fconvert_mluke_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmluke%2Fconvert_mluke_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -33,7 +33,7 @@ def convert_luke_checkpoint(checkpoint_path, metadata_path, entity_vocab_path, p\n     config = LukeConfig(use_entity_aware_attention=True, **metadata[\"model_config\"])\n \n     # Load in the weights from the checkpoint_path\n-    state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"module\"]\n+    state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"module\"]\n \n     # Load the entity vocab file\n     entity_vocab = load_original_entity_vocab(entity_vocab_path)"
        },
        {
            "sha": "7dc6dfa288b3a08134f0c5f7a852cc75470e9d04",
            "filename": "src/transformers/models/mobilevit/convert_mlcvnets_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fconvert_mlcvnets_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fconvert_mlcvnets_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilevit%2Fconvert_mlcvnets_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -199,7 +199,7 @@ def convert_movilevit_checkpoint(mobilevit_name, checkpoint_path, pytorch_dump_f\n     config = get_mobilevit_config(mobilevit_name)\n \n     # load original state_dict\n-    state_dict = torch.load(checkpoint_path, map_location=\"cpu\")\n+    state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n \n     # load  model\n     if mobilevit_name.startswith(\"deeplabv3_\"):"
        },
        {
            "sha": "485cbf5aa09def0fe9049582afca3598a2d96338",
            "filename": "src/transformers/models/mobilevitv2/convert_mlcvnets_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmobilevitv2%2Fconvert_mlcvnets_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmobilevitv2%2Fconvert_mlcvnets_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmobilevitv2%2Fconvert_mlcvnets_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -239,7 +239,7 @@ def convert_mobilevitv2_checkpoint(task_name, checkpoint_path, orig_config_path,\n     config = get_mobilevitv2_config(task_name, orig_config_path)\n \n     # load original state_dict\n-    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n+    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n \n     # load huggingface model\n     if task_name.startswith(\"ade20k_\") or task_name.startswith(\"voc_\"):"
        },
        {
            "sha": "b35cd7662db22d19e45d38c84ab27ad0d473061e",
            "filename": "src/transformers/models/mra/convert_mra_pytorch_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmra%2Fconvert_mra_pytorch_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fmra%2Fconvert_mra_pytorch_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmra%2Fconvert_mra_pytorch_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -77,7 +77,7 @@ def convert_checkpoint_helper(max_position_embeddings, orig_state_dict):\n \n \n def convert_mra_checkpoint(checkpoint_path, mra_config_file, pytorch_dump_path):\n-    orig_state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"model_state_dict\"]\n+    orig_state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"model_state_dict\"]\n     config = MraConfig.from_json_file(mra_config_file)\n     model = MraForMaskedLM(config)\n "
        },
        {
            "sha": "317c5c713c7f50c4641bf2b1efb233c2d521a160",
            "filename": "src/transformers/models/nllb_moe/convert_nllb_moe_sharded_original_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fconvert_nllb_moe_sharded_original_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fconvert_nllb_moe_sharded_original_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fnllb_moe%2Fconvert_nllb_moe_sharded_original_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -77,7 +77,7 @@ def shard_on_the_fly(switch_checkpoint_path, dump_path, num_experts, dtype, weig\n     for expert in range(num_experts):\n         expert_path = switch_checkpoint_path + f\"-rank-{expert}.pt\"\n         if os.path.isfile(expert_path):\n-            expert_state = torch.load(expert_path)[\"model\"]\n+            expert_state = torch.load(expert_path, weights_only=True)[\"model\"]\n             remove_ignore_keys_(expert_state)\n             expert_state = rename_fairseq_keys(expert_state, expert)\n             save_path = os.path.join(\n@@ -93,7 +93,7 @@ def shard_on_the_fly(switch_checkpoint_path, dump_path, num_experts, dtype, weig\n     save_path = os.path.join(\n         dump_path, weights_name.replace(\".bin\", f\"-{len(sharded_state_dicts) + 1:05d}-of-???.bin\")\n     )\n-    shared_weights = torch.load(switch_checkpoint_path + \"-shared.pt\")[\"model\"]\n+    shared_weights = torch.load(switch_checkpoint_path + \"-shared.pt\", weights_only=True)[\"model\"]\n     remove_ignore_keys_(shared_weights)\n     shared_weights = rename_fairseq_keys(shared_weights, None)\n     shared_weights[\"shared.weight\"] = shared_weights[\"decoder.embed_tokens.weight\"]"
        },
        {
            "sha": "6664a7d8ad019a2779b164ed4b8783ea3a6f7e12",
            "filename": "src/transformers/models/nystromformer/convert_nystromformer_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fnystromformer%2Fconvert_nystromformer_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fnystromformer%2Fconvert_nystromformer_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fnystromformer%2Fconvert_nystromformer_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -78,7 +78,7 @@ def convert_checkpoint_helper(config, orig_state_dict):\n \n \n def convert_nystromformer_checkpoint(checkpoint_path, nystromformer_config_file, pytorch_dump_path):\n-    orig_state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"model_state_dict\"]\n+    orig_state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"model_state_dict\"]\n     config = NystromformerConfig.from_json_file(nystromformer_config_file)\n     model = NystromformerForMaskedLM(config)\n "
        },
        {
            "sha": "b3a2ad80b01f18145072ebb64d978e6c5d534601",
            "filename": "src/transformers/models/olmo/convert_olmo_weights_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Folmo%2Fconvert_olmo_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Folmo%2Fconvert_olmo_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmo%2Fconvert_olmo_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -91,7 +91,7 @@ def write_model(model_path, input_base_path, tokenizer_path=None, safe_serializa\n \n     # Not sharded\n     # (The sharded implementation would also work, but this is simpler.)\n-    loaded = torch.load(os.path.join(input_base_path, \"model.pt\"), map_location=\"cpu\")\n+    loaded = torch.load(os.path.join(input_base_path, \"model.pt\"), map_location=\"cpu\", weights_only=True)\n \n     param_count = 0\n     index_dict = {\"weight_map\": {}}"
        },
        {
            "sha": "1e8fb54ddb654899c63733f74a4e18aa66813983",
            "filename": "src/transformers/models/olmo2/convert_olmo2_weights_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Folmo2%2Fconvert_olmo2_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Folmo2%2Fconvert_olmo2_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmo2%2Fconvert_olmo2_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -107,7 +107,7 @@ def write_model(\n \n     # Not sharded\n     # (The sharded implementation would also work, but this is simpler.)\n-    loaded = torch.load(os.path.join(input_base_path, \"model.pt\"), map_location=\"cpu\")\n+    loaded = torch.load(os.path.join(input_base_path, \"model.pt\"), map_location=\"cpu\", weights_only=True)\n \n     param_count = 0\n     index_dict: Dict[str, Any] = {\"weight_map\": {}}"
        },
        {
            "sha": "3fc5a49c7e5e47c0a4f14b2fe1fc316a6426679d",
            "filename": "src/transformers/models/olmoe/convert_olmoe_weights_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Folmoe%2Fconvert_olmoe_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Folmoe%2Fconvert_olmoe_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmoe%2Fconvert_olmoe_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -119,7 +119,7 @@ def write_model(model_path, input_base_path, tokenizer_path=None, safe_serializa\n     print(f\"Fetching all parameters from the checkpoint at {input_base_path}.\")\n \n     # Not sharded\n-    loaded = torch.load(os.path.join(input_base_path, \"model.pt\"), map_location=\"cpu\")\n+    loaded = torch.load(os.path.join(input_base_path, \"model.pt\"), map_location=\"cpu\", weights_only=True)\n \n     param_count = 0\n     index_dict = {\"weight_map\": {}}"
        },
        {
            "sha": "9a9b0c306cbe1cff685853a079017701f8af86e4",
            "filename": "src/transformers/models/opt/convert_opt_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fopt%2Fconvert_opt_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fopt%2Fconvert_opt_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fopt%2Fconvert_opt_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -29,9 +29,9 @@\n \n def load_checkpoint(checkpoint_path):\n     \"\"\"Checkpoint path should end in model.pt\"\"\"\n-    sd = torch.load(checkpoint_path, map_location=\"cpu\")\n+    sd = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n     if \"model\" in sd.keys():\n-        sd = torch.load(checkpoint_path, map_location=\"cpu\")[\"model\"]\n+        sd = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"model\"]\n \n     # pop unnecessary weights\n     keys_to_delete = ["
        },
        {
            "sha": "69665bab1d51a60a9cc2fc50cbf20621af3f87ff",
            "filename": "src/transformers/models/owlv2/convert_owlv2_to_hf.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fowlv2%2Fconvert_owlv2_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fowlv2%2Fconvert_owlv2_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fowlv2%2Fconvert_owlv2_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -268,10 +268,10 @@ def convert_owlv2_checkpoint(model_name, checkpoint_path, pytorch_dump_folder_pa\n \n     # Verify pixel_values and input_ids\n     filepath = hf_hub_download(repo_id=\"nielsr/test-image\", filename=\"owlvit_pixel_values_960.pt\", repo_type=\"dataset\")\n-    original_pixel_values = torch.load(filepath).permute(0, 3, 1, 2)\n+    original_pixel_values = torch.load(filepath, weights_only=True).permute(0, 3, 1, 2)\n \n     filepath = hf_hub_download(repo_id=\"nielsr/test-image\", filename=\"owlv2_input_ids.pt\", repo_type=\"dataset\")\n-    original_input_ids = torch.load(filepath).squeeze()\n+    original_input_ids = torch.load(filepath, weights_only=True).squeeze()\n \n     filepath = hf_hub_download(repo_id=\"adirik/OWL-ViT\", repo_type=\"space\", filename=\"assets/astronaut.png\")\n     image = Image.open(filepath)"
        },
        {
            "sha": "c4b410fd3bbf8104ff62e7de381f0b9398d43c01",
            "filename": "src/transformers/models/persimmon/convert_persimmon_weights_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fpersimmon%2Fconvert_persimmon_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fpersimmon%2Fconvert_persimmon_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpersimmon%2Fconvert_persimmon_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -82,7 +82,7 @@ def convert_persimmon_checkpoint(pytorch_dump_folder_path, ada_lib_path, pt_mode\n     import sys\n \n     sys.path.insert(0, ada_lib_path)\n-    model_state_dict_base = torch.load(pt_model_path, map_location=\"cpu\")\n+    model_state_dict_base = torch.load(pt_model_path, map_location=\"cpu\", weights_only=True)\n     state_dict = flatdict.FlatDict(model_state_dict_base[\"model\"], \".\")\n     state_dict = rename_state_dict(state_dict)\n "
        },
        {
            "sha": "0a2bb9553e0b97f8894f77900835b31bf6d38b33",
            "filename": "src/transformers/models/plbart/convert_plbart_original_checkpoint_to_torch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fplbart%2Fconvert_plbart_original_checkpoint_to_torch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fplbart%2Fconvert_plbart_original_checkpoint_to_torch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fplbart%2Fconvert_plbart_original_checkpoint_to_torch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -43,7 +43,7 @@ def make_linear_from_emb(emb):\n def convert_fairseq_plbart_checkpoint_from_disk(\n     checkpoint_path, hf_config_path=\"uclanlp/plbart-base\", finetuned=False, classification=False\n ):\n-    state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"model\"]\n+    state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"model\"]\n     remove_ignore_keys_(state_dict)\n     vocab_size = state_dict[\"encoder.embed_tokens.weight\"].shape[0]\n "
        },
        {
            "sha": "ddcfb9cd24193714929c9be4759dcea198457bb3",
            "filename": "src/transformers/models/poolformer/convert_poolformer_original_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fpoolformer%2Fconvert_poolformer_original_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fpoolformer%2Fconvert_poolformer_original_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpoolformer%2Fconvert_poolformer_original_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -151,7 +151,7 @@ def convert_poolformer_checkpoint(model_name, checkpoint_path, pytorch_dump_fold\n     logger.info(f\"Converting model {model_name}...\")\n \n     # load original state dict\n-    state_dict = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n+    state_dict = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"), weights_only=True)\n \n     # rename keys\n     state_dict = rename_keys(state_dict)"
        },
        {
            "sha": "84788ac6aecf63d58becc522502ec99c720dce5d",
            "filename": "src/transformers/models/pop2piano/convert_pop2piano_weights_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fpop2piano%2Fconvert_pop2piano_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fpop2piano%2Fconvert_pop2piano_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpop2piano%2Fconvert_pop2piano_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -26,7 +26,7 @@\n \n # This weights were downloaded from the official pop2piano repository\n # https://huggingface.co/sweetcocoa/pop2piano/blob/main/model-1999-val_0.67311615.ckpt\n-official_weights = torch.load(\"./model-1999-val_0.67311615.ckpt\")\n+official_weights = torch.load(\"./model-1999-val_0.67311615.ckpt\", weights_only=True)\n state_dict = {}\n \n "
        },
        {
            "sha": "237be38fff3ed051cbe3795012cb1245d520df37",
            "filename": "src/transformers/models/prompt_depth_anything/convert_prompt_depth_anything_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fprompt_depth_anything%2Fconvert_prompt_depth_anything_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fprompt_depth_anything%2Fconvert_prompt_depth_anything_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fprompt_depth_anything%2Fconvert_prompt_depth_anything_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -173,7 +173,7 @@ def convert_dpt_checkpoint(model_name, pytorch_dump_folder_path, push_to_hub, ve\n         filename=f\"{filename}\",\n     )\n \n-    state_dict = torch.load(filepath, map_location=\"cpu\")[\"state_dict\"]\n+    state_dict = torch.load(filepath, map_location=\"cpu\", weights_only=True)[\"state_dict\"]\n     state_dict = {key[9:]: state_dict[key] for key in state_dict}\n \n     # Convert state dict using mappings"
        },
        {
            "sha": "633d759123f4cfed554e128b87aaa4b4e9eafcf4",
            "filename": "src/transformers/models/pvt/convert_pvt_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fpvt%2Fconvert_pvt_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fpvt%2Fconvert_pvt_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpvt%2Fconvert_pvt_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -165,7 +165,7 @@ def convert_pvt_checkpoint(pvt_size, pvt_checkpoint, pytorch_dump_folder_path):\n         raise ValueError(f\"Available model's size: 'tiny', 'small', 'medium', 'large', but '{pvt_size}' was given\")\n     config = PvtConfig(name_or_path=config_path)\n     # load original model from https://github.com/whai362/PVT\n-    state_dict = torch.load(pvt_checkpoint, map_location=\"cpu\")\n+    state_dict = torch.load(pvt_checkpoint, map_location=\"cpu\", weights_only=True)\n \n     rename_keys = create_rename_keys(config)\n     for src, dest in rename_keys:"
        },
        {
            "sha": "b315d540dab3af2a332ef5ccc080405ce5812e86",
            "filename": "src/transformers/models/pvt_v2/convert_pvt_v2_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fpvt_v2%2Fconvert_pvt_v2_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fpvt_v2%2Fconvert_pvt_v2_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpvt_v2%2Fconvert_pvt_v2_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -207,7 +207,7 @@ def convert_pvt_v2_checkpoint(pvt_v2_size, pvt_v2_checkpoint, pytorch_dump_folde\n         )\n     config = PvtV2Config.from_pretrained(config_path)\n     # load original model from https://github.com/whai362/PVT\n-    state_dict = torch.load(pvt_v2_checkpoint, map_location=\"cpu\")\n+    state_dict = torch.load(pvt_v2_checkpoint, map_location=\"cpu\", weights_only=True)\n \n     rename_keys = create_rename_keys(config)\n     for src, dest in rename_keys:"
        },
        {
            "sha": "ea1cdd58ec9ce6ee80c89841c3dace20f5d6819e",
            "filename": "src/transformers/models/recurrent_gemma/convert_recurrent_gemma_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Frecurrent_gemma%2Fconvert_recurrent_gemma_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Frecurrent_gemma%2Fconvert_recurrent_gemma_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frecurrent_gemma%2Fconvert_recurrent_gemma_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -71,7 +71,7 @@\n \n def write_model(save_path, input_base_path, config, safe_serialization=True, push_to_hub=False, dtype=torch.float32):\n     print(f\"Fetching all parameters from the checkpoint at '{input_base_path}'\")\n-    model_state_dict = torch.load(input_base_path, map_location=\"cpu\")\n+    model_state_dict = torch.load(input_base_path, map_location=\"cpu\", weights_only=True)\n \n     REPLACEMENT = {\n         \"blocks.\": \"layers.\","
        },
        {
            "sha": "c4a6b03162f60bafc2231df547f1c5ee77714fe5",
            "filename": "src/transformers/models/roberta_prelayernorm/convert_roberta_prelayernorm_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fconvert_roberta_prelayernorm_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fconvert_roberta_prelayernorm_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Froberta_prelayernorm%2Fconvert_roberta_prelayernorm_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -37,7 +37,9 @@ def convert_roberta_prelayernorm_checkpoint_to_pytorch(checkpoint_repo: str, pyt\n     )\n \n     # convert state_dict\n-    original_state_dict = torch.load(hf_hub_download(repo_id=checkpoint_repo, filename=\"pytorch_model.bin\"))\n+    original_state_dict = torch.load(\n+        hf_hub_download(repo_id=checkpoint_repo, filename=\"pytorch_model.bin\"), weights_only=True\n+    )\n     state_dict = {}\n     for tensor_key, tensor_value in original_state_dict.items():\n         # The transformer implementation gives the model a unique name, rather than overwiriting 'roberta'"
        },
        {
            "sha": "87d35db223632d868ef3727fc6db7d5bb192ae2d",
            "filename": "src/transformers/models/rwkv/convert_rwkv_checkpoint_to_hf.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Frwkv%2Fconvert_rwkv_checkpoint_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Frwkv%2Fconvert_rwkv_checkpoint_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frwkv%2Fconvert_rwkv_checkpoint_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -112,7 +112,7 @@ def convert_rmkv_checkpoint_to_hf_format(\n \n     # 3. Download model file then convert state_dict\n     model_file = hf_hub_download(repo_id, checkpoint_file)\n-    state_dict = torch.load(model_file, map_location=\"cpu\")\n+    state_dict = torch.load(model_file, map_location=\"cpu\", weights_only=True)\n     state_dict = convert_state_dict(state_dict)\n \n     # 4. Split in shards and save\n@@ -147,7 +147,7 @@ def convert_rmkv_checkpoint_to_hf_format(\n         gc.collect()\n \n         for shard_file in shard_files:\n-            state_dict = torch.load(os.path.join(output_dir, shard_file))\n+            state_dict = torch.load(os.path.join(output_dir, shard_file), weights_only=True)\n             torch.save({k: v.cpu().clone() for k, v in state_dict.items()}, os.path.join(output_dir, shard_file))\n \n     del state_dict"
        },
        {
            "sha": "76d8884d951521062ea9f969a1407fa0f0e649ef",
            "filename": "src/transformers/models/sam/convert_sam_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fsam%2Fconvert_sam_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fsam%2Fconvert_sam_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam%2Fconvert_sam_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -137,7 +137,7 @@ def replace_keys(state_dict):\n def convert_sam_checkpoint(model_name, checkpoint_path, pytorch_dump_folder, push_to_hub):\n     config = get_config(model_name)\n \n-    state_dict = torch.load(checkpoint_path, map_location=\"cpu\")\n+    state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n     state_dict = replace_keys(state_dict)\n \n     image_processor = SamImageProcessor()"
        },
        {
            "sha": "c84e006ad6480a130e9e642f0924f052da9e0419",
            "filename": "src/transformers/models/segformer/convert_segformer_original_to_pytorch.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fsegformer%2Fconvert_segformer_original_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fsegformer%2Fconvert_segformer_original_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsegformer%2Fconvert_segformer_original_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -191,9 +191,9 @@ def convert_segformer_checkpoint(model_name, checkpoint_path, pytorch_dump_folde\n \n     # load original state dict\n     if encoder_only:\n-        state_dict = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n+        state_dict = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"), weights_only=True)\n     else:\n-        state_dict = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))[\"state_dict\"]\n+        state_dict = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"), weights_only=True)[\"state_dict\"]\n \n     # rename keys\n     state_dict = rename_keys(state_dict, encoder_only=encoder_only)"
        },
        {
            "sha": "b61bd7ffb70edaf0674bb3312e047d0b50ff2524",
            "filename": "src/transformers/models/siglip/convert_siglip_to_hf.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fsiglip%2Fconvert_siglip_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fsiglip%2Fconvert_siglip_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsiglip%2Fconvert_siglip_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -441,9 +441,9 @@ def convert_siglip_checkpoint(model_name, pytorch_dump_folder_path, verify_logit\n             raise ValueError(\"Image size not supported\")\n \n         filepath = hf_hub_download(repo_id=\"nielsr/test-image\", filename=filename, repo_type=\"dataset\")\n-        original_pixel_values = torch.load(filepath)\n+        original_pixel_values = torch.load(filepath, weights_only=True)\n         filepath = hf_hub_download(repo_id=\"nielsr/test-image\", filename=\"siglip_input_ids.pt\", repo_type=\"dataset\")\n-        original_input_ids = torch.load(filepath)\n+        original_input_ids = torch.load(filepath, weights_only=True)\n \n         if \"i18n\" not in model_name:\n             assert inputs.input_ids.tolist() == original_input_ids.tolist()"
        },
        {
            "sha": "9286fae776fd857e4f45b77e7c24f55f5e05ac3b",
            "filename": "src/transformers/models/speech_to_text/convert_s2t_fairseq_to_tfms.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fspeech_to_text%2Fconvert_s2t_fairseq_to_tfms.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fspeech_to_text%2Fconvert_s2t_fairseq_to_tfms.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fspeech_to_text%2Fconvert_s2t_fairseq_to_tfms.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -52,7 +52,7 @@ def make_linear_from_emb(emb):\n \n \n def convert_fairseq_s2t_checkpoint_to_tfms(checkpoint_path, pytorch_dump_folder_path):\n-    m2m_100 = torch.load(checkpoint_path, map_location=\"cpu\")\n+    m2m_100 = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n     args = m2m_100[\"args\"]\n     state_dict = m2m_100[\"model\"]\n     lm_head_weights = state_dict[\"decoder.output_projection.weight\"]"
        },
        {
            "sha": "b39012f8e251cef0e164629dcbca1cecac26ac9e",
            "filename": "src/transformers/models/speecht5/convert_hifigan.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fconvert_hifigan.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fconvert_hifigan.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fconvert_hifigan.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -70,7 +70,7 @@ def convert_hifigan_checkpoint(\n \n     model = SpeechT5HifiGan(config)\n \n-    orig_checkpoint = torch.load(checkpoint_path)\n+    orig_checkpoint = torch.load(checkpoint_path, weights_only=True)\n     load_weights(orig_checkpoint[\"model\"][\"generator\"], model, config)\n \n     stats = np.load(stats_path)"
        },
        {
            "sha": "c16e11d2b250f041f6cf36b0ea71d77632e97e5c",
            "filename": "src/transformers/models/speecht5/convert_speecht5_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fconvert_speecht5_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fconvert_speecht5_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fspeecht5%2Fconvert_speecht5_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -361,7 +361,7 @@ def convert_speecht5_checkpoint(\n     processor = SpeechT5Processor(tokenizer=tokenizer, feature_extractor=feature_extractor)\n     processor.save_pretrained(pytorch_dump_folder_path)\n \n-    fairseq_checkpoint = torch.load(checkpoint_path)\n+    fairseq_checkpoint = torch.load(checkpoint_path, weights_only=True)\n     recursively_load_weights(fairseq_checkpoint[\"model\"], model, task)\n \n     model.save_pretrained(pytorch_dump_folder_path)"
        },
        {
            "sha": "3567bb674e950bc7015043647672f6dc3dc0fee2",
            "filename": "src/transformers/models/swiftformer/convert_swiftformer_original_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fswiftformer%2Fconvert_swiftformer_original_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fswiftformer%2Fconvert_swiftformer_original_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fswiftformer%2Fconvert_swiftformer_original_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -125,7 +125,7 @@ def convert_swiftformer_checkpoint(swiftformer_name, pytorch_dump_folder_path, o\n         if original_ckpt.startswith(\"https\"):\n             checkpoint = torch.hub.load_state_dict_from_url(original_ckpt, map_location=\"cpu\", check_hash=True)\n         else:\n-            checkpoint = torch.load(original_ckpt, map_location=\"cpu\")\n+            checkpoint = torch.load(original_ckpt, map_location=\"cpu\", weights_only=True)\n     state_dict = checkpoint\n \n     rename_keys = create_rename_keys(state_dict)"
        },
        {
            "sha": "9a87ff693af209656ccf0e53a0ea4c2e26e5ba51",
            "filename": "src/transformers/models/swin/convert_swin_simmim_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fswin%2Fconvert_swin_simmim_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fswin%2Fconvert_swin_simmim_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fswin%2Fconvert_swin_simmim_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -121,7 +121,7 @@ def convert_state_dict(orig_state_dict, model):\n \n \n def convert_swin_checkpoint(model_name, checkpoint_path, pytorch_dump_folder_path, push_to_hub):\n-    state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"model\"]\n+    state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"model\"]\n \n     config = get_swin_config(model_name)\n     model = SwinForMaskedImageModeling(config)"
        },
        {
            "sha": "cda9b0c182726781f25eb7d983dd36c93517e98a",
            "filename": "src/transformers/models/timesformer/convert_timesformer_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Ftimesformer%2Fconvert_timesformer_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Ftimesformer%2Fconvert_timesformer_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftimesformer%2Fconvert_timesformer_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -143,7 +143,7 @@ def convert_timesformer_checkpoint(checkpoint_url, pytorch_dump_folder_path, mod\n     # download original checkpoint, hosted on Google Drive\n     output = \"pytorch_model.bin\"\n     gdown.cached_download(checkpoint_url, output, quiet=False)\n-    files = torch.load(output, map_location=\"cpu\")\n+    files = torch.load(output, map_location=\"cpu\", weights_only=True)\n     if \"model\" in files:\n         state_dict = files[\"model\"]\n     elif \"module\" in files:"
        },
        {
            "sha": "8ba0de55df78f45808131d6eb538a96006fddf4d",
            "filename": "src/transformers/models/udop/convert_udop_to_hf.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fudop%2Fconvert_udop_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fudop%2Fconvert_udop_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fudop%2Fconvert_udop_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -98,7 +98,7 @@ def convert_udop_checkpoint(model_name, pytorch_dump_folder_path=None, push_to_h\n \n     # load original state dict\n     checkpoint_path = name_to_checkpoint_path[model_name]\n-    state_dict = torch.load(checkpoint_path, map_location=\"cpu\")\n+    state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n \n     print(\"Checkpoint path:\", checkpoint_path)\n \n@@ -177,12 +177,12 @@ def convert_udop_checkpoint(model_name, pytorch_dump_folder_path=None, push_to_h\n     # autoregressive decoding with original input data\n     print(\"Testing generation with original inputs...\")\n     filepath = hf_hub_download(repo_id=\"nielsr/test-image\", filename=\"input_ids_udop.pt\", repo_type=\"dataset\")\n-    input_ids = torch.load(filepath)\n+    input_ids = torch.load(filepath, weights_only=True)\n     filepath = hf_hub_download(repo_id=\"nielsr/test-image\", filename=\"bbox_udop.pt\", repo_type=\"dataset\")\n-    bbox = torch.load(filepath)\n+    bbox = torch.load(filepath, weights_only=True)\n     pixel_values_filename = \"pixel_values_udop_512.pt\" if \"512\" in model_name else \"pixel_values_udop_224.pt\"\n     filepath = hf_hub_download(repo_id=\"nielsr/test-image\", filename=pixel_values_filename, repo_type=\"dataset\")\n-    pixel_values = torch.load(filepath)\n+    pixel_values = torch.load(filepath, weights_only=True)\n \n     print(\"Decoded input ids:\", tokenizer.decode(input_ids[0], skip_special_tokens=True))\n     print(\"Bbox shape:\", bbox.shape)"
        },
        {
            "sha": "0f1256e0ca3ee6f82839ba3c0c3f94d1b0c70256",
            "filename": "src/transformers/models/unispeech_sat/convert_unispeech_original_s3prl_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Funispeech_sat%2Fconvert_unispeech_original_s3prl_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Funispeech_sat%2Fconvert_unispeech_original_s3prl_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Funispeech_sat%2Fconvert_unispeech_original_s3prl_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -71,7 +71,7 @@ def convert_s3prl_checkpoint(base_model_name, config_path, checkpoint_path, mode\n     \"\"\"\n     Copy/paste/tweak model's weights to transformers design.\n     \"\"\"\n-    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n+    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n \n     downstream_dict = checkpoint[\"Downstream\"]\n "
        },
        {
            "sha": "f790efab22f80db2545c8bc41a9df22f9efb22f1",
            "filename": "src/transformers/models/univnet/convert_univnet.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Funivnet%2Fconvert_univnet.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Funivnet%2Fconvert_univnet.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Funivnet%2Fconvert_univnet.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -106,7 +106,7 @@ def convert_univnet_checkpoint(\n     repo_id=None,\n     safe_serialization=False,\n ):\n-    model_state_dict_base = torch.load(checkpoint_path, map_location=\"cpu\")\n+    model_state_dict_base = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n     # Get the generator's state dict\n     state_dict = model_state_dict_base[\"model_g\"]\n "
        },
        {
            "sha": "fff886f8a833564fd1389c60ef92477565785852",
            "filename": "src/transformers/models/video_llava/convert_video_llava_weights_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fconvert_video_llava_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fconvert_video_llava_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fconvert_video_llava_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -99,7 +99,7 @@ def convert_video_llava_llama_to_hf(text_model_id, vision_model_id, output_hub_p\n     state_dict_temp = \"pytorch_model-0000{i}-of-00002.bin\"\n     for shard in range(1, 3):\n         state_dict_path = hf_hub_download(old_state_dict_id, state_dict_temp.format(i=shard))\n-        state_dict = torch.load(state_dict_path, map_location=\"cpu\")\n+        state_dict = torch.load(state_dict_path, map_location=\"cpu\", weights_only=True)\n         state_dict = convert_state_dict_to_hf(state_dict)\n         model.load_state_dict(state_dict, strict=False, assign=True)\n         model_state_dict -= set(state_dict.keys())"
        },
        {
            "sha": "011c1862eb61328c7f7a98433b079cc3a474b36b",
            "filename": "src/transformers/models/videomae/convert_videomae_to_pytorch.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fvideomae%2Fconvert_videomae_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fvideomae%2Fconvert_videomae_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvideomae%2Fconvert_videomae_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -187,7 +187,7 @@ def convert_videomae_checkpoint(checkpoint_url, pytorch_dump_folder_path, model_\n     # download original checkpoint, hosted on Google Drive\n     output = \"pytorch_model.bin\"\n     gdown.cached_download(checkpoint_url, output, quiet=False)\n-    files = torch.load(output, map_location=\"cpu\")\n+    files = torch.load(output, map_location=\"cpu\", weights_only=True)\n     if \"model\" in files:\n         state_dict = files[\"model\"]\n     else:\n@@ -204,7 +204,7 @@ def convert_videomae_checkpoint(checkpoint_url, pytorch_dump_folder_path, model_\n \n     if \"finetuned\" not in model_name:\n         local_path = hf_hub_download(repo_id=\"hf-internal-testing/bool-masked-pos\", filename=\"bool_masked_pos.pt\")\n-        inputs[\"bool_masked_pos\"] = torch.load(local_path)\n+        inputs[\"bool_masked_pos\"] = torch.load(local_path, weights_only=True)\n \n     outputs = model(**inputs)\n     logits = outputs.logits"
        },
        {
            "sha": "f0fa69ab872e6e83c034d99407e835e73dd39709",
            "filename": "src/transformers/models/vipllava/convert_vipllava_weights_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fvipllava%2Fconvert_vipllava_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fvipllava%2Fconvert_vipllava_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvipllava%2Fconvert_vipllava_weights_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -78,7 +78,7 @@ def convert_vipllava_llama_to_hf(text_model_id, vision_model_id, output_hub_path\n \n     state_dict_path = hf_hub_download(old_state_dict_id, \"model_state_dict_7b.bin\")\n \n-    state_dict = torch.load(state_dict_path, map_location=\"cpu\")\n+    state_dict = torch.load(state_dict_path, map_location=\"cpu\", weights_only=True)\n     state_dict = convert_state_dict_to_hf(state_dict)\n \n     model.load_state_dict(state_dict, strict=True, assign=True)"
        },
        {
            "sha": "ae5af9a343db22422fa76a54bdd0c908605a1dc1",
            "filename": "src/transformers/models/visual_bert/convert_visual_bert_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fvisual_bert%2Fconvert_visual_bert_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fvisual_bert%2Fconvert_visual_bert_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvisual_bert%2Fconvert_visual_bert_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -56,7 +56,7 @@\n \n \n def load_state_dict(checkpoint_path):\n-    sd = torch.load(checkpoint_path, map_location=\"cpu\")\n+    sd = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n     return sd\n \n "
        },
        {
            "sha": "5153e1faf525ea767e81e120a341acdfc60e5373",
            "filename": "src/transformers/models/vitmatte/convert_vitmatte_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fvitmatte%2Fconvert_vitmatte_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fvitmatte%2Fconvert_vitmatte_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvitmatte%2Fconvert_vitmatte_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -82,7 +82,7 @@ def convert_vitmatte_checkpoint(model_name, pytorch_dump_folder_path, push_to_hu\n \n     filename = model_name_to_filename[model_name]\n     filepath = hf_hub_download(repo_id=\"nielsr/vitmatte-checkpoints\", filename=filename, repo_type=\"model\")\n-    state_dict = torch.load(filepath, map_location=\"cpu\")\n+    state_dict = torch.load(filepath, map_location=\"cpu\", weights_only=True)\n \n     # rename keys\n     for key in state_dict.copy().keys():"
        },
        {
            "sha": "e4666751a1078d487756f9681cd9fd21fbc58212",
            "filename": "src/transformers/models/vitpose/convert_vitpose_to_hf.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fvitpose%2Fconvert_vitpose_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fvitpose%2Fconvert_vitpose_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvitpose%2Fconvert_vitpose_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -207,7 +207,7 @@ def write_model(model_name, model_path, push_to_hub, check_logits=True):\n     )\n \n     print(\"Converting model...\")\n-    original_state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"state_dict\"]\n+    original_state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"state_dict\"]\n     all_keys = list(original_state_dict.keys())\n     new_keys = convert_old_keys_to_new_keys(all_keys)\n \n@@ -264,7 +264,7 @@ def write_model(model_name, model_path, push_to_hub, check_logits=True):\n     pixel_values = image_processor(images=image, boxes=boxes, return_tensors=\"pt\").pixel_values\n \n     filepath = hf_hub_download(repo_id=\"nielsr/test-image\", filename=\"vitpose_batch_data.pt\", repo_type=\"dataset\")\n-    original_pixel_values = torch.load(filepath, map_location=\"cpu\")[\"img\"]\n+    original_pixel_values = torch.load(filepath, map_location=\"cpu\", weights_only=True)[\"img\"]\n     # we allow for a small difference in the pixel values due to the original repository using cv2\n     assert torch.allclose(pixel_values, original_pixel_values, atol=1e-1)\n "
        },
        {
            "sha": "7f122e86fa54ac75b8051ef13836e38924f57d1a",
            "filename": "src/transformers/models/vits/convert_original_checkpoint.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fvits%2Fconvert_original_checkpoint.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fvits%2Fconvert_original_checkpoint.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvits%2Fconvert_original_checkpoint.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -346,7 +346,7 @@ def convert_checkpoint(\n \n     model.decoder.apply_weight_norm()\n \n-    orig_checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n+    orig_checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"), weights_only=True)\n     recursively_load_weights(orig_checkpoint[\"model\"], model)\n \n     model.decoder.remove_weight_norm()"
        },
        {
            "sha": "fa33416c8bdc6d0a82c50c364438861626d26879",
            "filename": "src/transformers/models/wav2vec2/convert_wav2vec2_original_s3prl_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fconvert_wav2vec2_original_s3prl_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fconvert_wav2vec2_original_s3prl_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwav2vec2%2Fconvert_wav2vec2_original_s3prl_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -71,7 +71,7 @@ def convert_s3prl_checkpoint(base_model_name, config_path, checkpoint_path, mode\n     \"\"\"\n     Copy/paste/tweak model's weights to transformers design.\n     \"\"\"\n-    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n+    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n \n     downstream_dict = checkpoint[\"Downstream\"]\n "
        },
        {
            "sha": "91d4853bade1f2c4ed06205c12478fcb0929a0c2",
            "filename": "src/transformers/models/wavlm/convert_wavlm_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fwavlm%2Fconvert_wavlm_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fwavlm%2Fconvert_wavlm_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwavlm%2Fconvert_wavlm_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -179,7 +179,7 @@ def load_conv_layer(full_name, value, feature_extractor, unused_weights, use_gro\n @torch.no_grad()\n def convert_wavlm_checkpoint(checkpoint_path, pytorch_dump_folder_path, config_path=None):\n     # load the pre-trained checkpoints\n-    checkpoint = torch.load(checkpoint_path)\n+    checkpoint = torch.load(checkpoint_path, weights_only=True)\n     cfg = WavLMConfigOrig(checkpoint[\"cfg\"])\n     model = WavLMOrig(cfg)\n     model.load_state_dict(checkpoint[\"model\"])"
        },
        {
            "sha": "b8c4c33767979c5931a0b262ae54e47eda9fb83d",
            "filename": "src/transformers/models/wavlm/convert_wavlm_original_s3prl_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fwavlm%2Fconvert_wavlm_original_s3prl_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fwavlm%2Fconvert_wavlm_original_s3prl_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwavlm%2Fconvert_wavlm_original_s3prl_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -71,7 +71,7 @@ def convert_s3prl_checkpoint(base_model_name, config_path, checkpoint_path, mode\n     \"\"\"\n     Copy/paste/tweak model's weights to transformers design.\n     \"\"\"\n-    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n+    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n \n     downstream_dict = checkpoint[\"Downstream\"]\n "
        },
        {
            "sha": "343fb5513b5176ac6221b9a1f84c503b5e064eec",
            "filename": "src/transformers/models/whisper/convert_openai_to_hf.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fwhisper%2Fconvert_openai_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fwhisper%2Fconvert_openai_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Fconvert_openai_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -157,7 +157,7 @@ def _download(url: str, root: str) -> Any:\n     if os.path.isfile(download_target):\n         model_bytes = open(download_target, \"rb\").read()\n         if insecure_hashlib.sha256(model_bytes).hexdigest() == expected_sha256:\n-            return torch.load(io.BytesIO(model_bytes))\n+            return torch.load(io.BytesIO(model_bytes), weights_only=True)\n         else:\n             warnings.warn(f\"{download_target} exists, but the SHA256 checksum does not match; re-downloading the file\")\n \n@@ -179,7 +179,7 @@ def _download(url: str, root: str) -> Any:\n             \"Model has been downloaded but the SHA256 checksum does not match. Please retry loading the model.\"\n         )\n \n-    return torch.load(io.BytesIO(model_bytes))\n+    return torch.load(io.BytesIO(model_bytes), weights_only=True)\n \n \n def convert_openai_whisper_to_tfms(\n@@ -190,7 +190,7 @@ def convert_openai_whisper_to_tfms(\n         original_checkpoint = _download(_MODELS[checkpoint_path], root)\n         openai_version = checkpoint_path\n     else:\n-        original_checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n+        original_checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n         openai_version = None\n \n     dimensions = original_checkpoint[\"dims\"]"
        },
        {
            "sha": "6f36b1905586efdfa18217f976aa42357f31835f",
            "filename": "src/transformers/models/x_clip/convert_x_clip_original_pytorch_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fx_clip%2Fconvert_x_clip_original_pytorch_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fx_clip%2Fconvert_x_clip_original_pytorch_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fx_clip%2Fconvert_x_clip_original_pytorch_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -279,7 +279,7 @@ def convert_xclip_checkpoint(model_name, pytorch_dump_folder_path=None, push_to_\n     if \"drive\" in checkpoint_url:\n         output = \"pytorch_model.bin\"\n         gdown.cached_download(checkpoint_url, output, quiet=False)\n-        state_dict = torch.load(output, map_location=\"cpu\")[\"model\"]\n+        state_dict = torch.load(output, map_location=\"cpu\", weights_only=True)[\"model\"]\n     else:\n         state_dict = torch.hub.load_state_dict_from_url(checkpoint_url)[\"model\"]\n "
        },
        {
            "sha": "dc898196260e601b55cb197dd7082c0c19f1ae2f",
            "filename": "src/transformers/models/xglm/convert_xglm_original_ckpt_to_trfms.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fxglm%2Fconvert_xglm_original_ckpt_to_trfms.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fxglm%2Fconvert_xglm_original_ckpt_to_trfms.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fxglm%2Fconvert_xglm_original_ckpt_to_trfms.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -26,7 +26,7 @@ def make_linear_from_emb(emb):\n \n \n def convert_fairseq_xglm_checkpoint_from_disk(checkpoint_path):\n-    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n+    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)\n     args = Namespace(**checkpoint[\"cfg\"][\"model\"])\n     state_dict = checkpoint[\"model\"]\n     remove_ignore_keys_(state_dict)"
        },
        {
            "sha": "2e5a17921d01ca1d1fdea67bcc5e84dcae5e1171",
            "filename": "src/transformers/models/xlm/convert_xlm_original_pytorch_checkpoint_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fxlm%2Fconvert_xlm_original_pytorch_checkpoint_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fxlm%2Fconvert_xlm_original_pytorch_checkpoint_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fxlm%2Fconvert_xlm_original_pytorch_checkpoint_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -29,7 +29,7 @@\n \n def convert_xlm_checkpoint_to_pytorch(xlm_checkpoint_path, pytorch_dump_folder_path):\n     # Load checkpoint\n-    chkpt = torch.load(xlm_checkpoint_path, map_location=\"cpu\")\n+    chkpt = torch.load(xlm_checkpoint_path, map_location=\"cpu\", weights_only=True)\n \n     state_dict = chkpt[\"model\"]\n "
        },
        {
            "sha": "907a11d067bff58ac27de97be316c83d263f433f",
            "filename": "src/transformers/models/yolos/convert_yolos_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fyolos%2Fconvert_yolos_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fyolos%2Fconvert_yolos_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fyolos%2Fconvert_yolos_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -163,7 +163,7 @@ def convert_yolos_checkpoint(\n     config = get_yolos_config(yolos_name)\n \n     # load original state_dict\n-    state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"model\"]\n+    state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"model\"]\n \n     # load  model\n     model = YolosForObjectDetection(config)"
        },
        {
            "sha": "950769ae1e08e37936792e5599d54328835391d0",
            "filename": "src/transformers/models/yoso/convert_yoso_pytorch_to_pytorch.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fyoso%2Fconvert_yoso_pytorch_to_pytorch.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fyoso%2Fconvert_yoso_pytorch_to_pytorch.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fyoso%2Fconvert_yoso_pytorch_to_pytorch.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -75,7 +75,7 @@ def convert_checkpoint_helper(max_position_embeddings, orig_state_dict):\n \n \n def convert_yoso_checkpoint(checkpoint_path, yoso_config_file, pytorch_dump_path):\n-    orig_state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"model_state_dict\"]\n+    orig_state_dict = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"model_state_dict\"]\n     config = YosoConfig.from_json_file(yoso_config_file)\n     model = YosoForMaskedLM(config)\n "
        },
        {
            "sha": "cbf47a636b7d89740549072bb54cf52e37deeabb",
            "filename": "src/transformers/models/zoedepth/convert_zoedepth_to_hf.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fzoedepth%2Fconvert_zoedepth_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/28eae8b4bdc66c0e841ce817f7faab5ef203ea68/src%2Ftransformers%2Fmodels%2Fzoedepth%2Fconvert_zoedepth_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fzoedepth%2Fconvert_zoedepth_to_hf.py?ref=28eae8b4bdc66c0e841ce817f7faab5ef203ea68",
            "patch": "@@ -347,7 +347,7 @@ def convert_zoedepth_checkpoint(model_name, pytorch_dump_folder_path, push_to_hu\n         filename=\"zoedepth_pixel_values.pt\",\n         repo_type=\"dataset\",\n     )\n-    original_pixel_values = torch.load(filepath, map_location=\"cpu\")\n+    original_pixel_values = torch.load(filepath, map_location=\"cpu\", weights_only=True)\n     assert torch.allclose(pixel_values, original_pixel_values)\n \n     # verify logits\n@@ -358,7 +358,7 @@ def convert_zoedepth_checkpoint(model_name, pytorch_dump_folder_path, push_to_hu\n         repo_type=\"dataset\",\n         revision=\"1865dbb81984f01c89e83eec10f8d07efd10743d\",\n     )\n-    cats_pixel_values = torch.load(filepath, map_location=\"cpu\")\n+    cats_pixel_values = torch.load(filepath, map_location=\"cpu\", weights_only=True)\n     depth = model(cats_pixel_values).predicted_depth\n \n     # Verify logits"
        }
    ],
    "stats": {
        "total": 297,
        "additions": 161,
        "deletions": 136
    }
}