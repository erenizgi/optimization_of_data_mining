{
    "author": "akaariai",
    "message": "Refactored qs.add_q() and utils/tree.py\n\nThe sql/query.py add_q method did a lot of where/having tree hacking to\nget complex queries to work correctly. The logic was refactored so that\nit should be simpler to understand. The new logic should also produce\nleaner WHERE conditions.\n\nThe changes cascade somewhat, as some other parts of Django (like\nadd_filter() and WhereNode) expect boolean trees in certain format or\nthey fail to work. So to fix the add_q() one must fix utils/tree.py,\nsome things in add_filter(), WhereNode and so on.\n\nThis commit also fixed add_filter to see negate clauses up the path.\nA query like .exclude(Q(reversefk__in=a_list)) didn't work similarly to\n.filter(~Q(reversefk__in=a_list)). The reason for this is that only\nthe immediate parent negate clauses were seen by add_filter, and thus a\ntree like AND: (NOT AND: (AND: condition)) will not be handled\ncorrectly, as there is one intermediary AND node in the tree. The\nexample tree is generated by .exclude(~Q(reversefk__in=a_list)).\n\nStill, aggregation lost connectors in OR cases, and F() objects and\naggregates in same filter clause caused GROUP BY problems on some\ndatabases.\n\nFixed #17600, fixed #13198, fixed #17025, fixed #17000, fixed #11293.",
    "sha": "d3f00bd5706b35961390d3814dd7e322ead3a9a3",
    "files": [
        {
            "sha": "c29533bf8409b87dae195fb402afac51f5a41c74",
            "filename": "django/contrib/gis/db/models/sql/where.py",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/django/django/blob/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fcontrib%2Fgis%2Fdb%2Fmodels%2Fsql%2Fwhere.py",
            "raw_url": "https://github.com/django/django/raw/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fcontrib%2Fgis%2Fdb%2Fmodels%2Fsql%2Fwhere.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fcontrib%2Fgis%2Fdb%2Fmodels%2Fsql%2Fwhere.py?ref=d3f00bd5706b35961390d3814dd7e322ead3a9a3",
            "patch": "@@ -32,13 +32,14 @@ class GeoWhereNode(WhereNode):\n     Used to represent the SQL where-clause for spatial databases --\n     these are tied to the GeoQuery class that created it.\n     \"\"\"\n-    def add(self, data, connector):\n+\n+    def _prepare_data(self, data):\n         if isinstance(data, (list, tuple)):\n             obj, lookup_type, value = data\n             if ( isinstance(obj, Constraint) and\n                  isinstance(obj.field, GeometryField) ):\n                 data = (GeoConstraint(obj), lookup_type, value)\n-        super(GeoWhereNode, self).add(data, connector)\n+        return super(GeoWhereNode, self)._prepare_data(data)\n \n     def make_atom(self, child, qn, connection):\n         lvalue, lookup_type, value_annot, params_or_value = child"
        },
        {
            "sha": "b89db1c5632e6b8dc758c0c9784b9330eb04edca",
            "filename": "django/db/models/aggregates.py",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/django/django/blob/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Faggregates.py",
            "raw_url": "https://github.com/django/django/raw/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Faggregates.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fdb%2Fmodels%2Faggregates.py?ref=d3f00bd5706b35961390d3814dd7e322ead3a9a3",
            "patch": "@@ -1,6 +1,19 @@\n \"\"\"\n Classes to represent the definitions of aggregate functions.\n \"\"\"\n+from django.db.models.constants import LOOKUP_SEP\n+\n+def refs_aggregate(lookup_parts, aggregates):\n+    \"\"\"\n+    A little helper method to check if the lookup_parts contains references\n+    to the given aggregates set. Because the LOOKUP_SEP is contained in the\n+    default annotation names we must check each prefix of the lookup_parts\n+    for match.\n+    \"\"\"\n+    for i in range(len(lookup_parts) + 1):\n+        if LOOKUP_SEP.join(lookup_parts[0:i]) in aggregates:\n+            return True\n+    return False\n \n class Aggregate(object):\n     \"\"\""
        },
        {
            "sha": "a7e6c252d93b70fe2c2c846b12bd6de0c569bf20",
            "filename": "django/db/models/constants.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/django/django/blob/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fconstants.py",
            "raw_url": "https://github.com/django/django/raw/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fconstants.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fdb%2Fmodels%2Fconstants.py?ref=d3f00bd5706b35961390d3814dd7e322ead3a9a3",
            "patch": "@@ -4,4 +4,3 @@\n \n # Separator used to split filter strings apart.\n LOOKUP_SEP = '__'\n-"
        },
        {
            "sha": "6e0f3c434e05c2522f5c25f8240366b8c4b266d8",
            "filename": "django/db/models/expressions.py",
            "status": "modified",
            "additions": 15,
            "deletions": 3,
            "changes": 18,
            "blob_url": "https://github.com/django/django/blob/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fexpressions.py",
            "raw_url": "https://github.com/django/django/raw/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fexpressions.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fdb%2Fmodels%2Fexpressions.py?ref=d3f00bd5706b35961390d3814dd7e322ead3a9a3",
            "patch": "@@ -1,4 +1,7 @@\n import datetime\n+\n+from django.db.models.aggregates import refs_aggregate\n+from django.db.models.constants import LOOKUP_SEP\n from django.utils import tree\n \n class ExpressionNode(tree.Node):\n@@ -37,6 +40,18 @@ def _combine(self, other, connector, reversed, node=None):\n             obj.add(other, connector)\n         return obj\n \n+    def contains_aggregate(self, existing_aggregates):\n+        if self.children:\n+            return any(child.contains_aggregate(existing_aggregates)\n+                       for child in self.children\n+                       if hasattr(child, 'contains_aggregate'))\n+        else:\n+            return refs_aggregate(self.name.split(LOOKUP_SEP),\n+                                  existing_aggregates)\n+\n+    def prepare_database_save(self, unused):\n+        return self\n+\n     ###################\n     # VISITOR METHODS #\n     ###################\n@@ -113,9 +128,6 @@ def __ror__(self, other):\n             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n         )\n \n-    def prepare_database_save(self, unused):\n-        return self\n-\n class F(ExpressionNode):\n     \"\"\"\n     An expression representing the value of the given field."
        },
        {
            "sha": "a33c44833c8551301cb1abc3cc7d80f19fda1b4e",
            "filename": "django/db/models/query_utils.py",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/django/django/blob/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fquery_utils.py",
            "raw_url": "https://github.com/django/django/raw/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fquery_utils.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fdb%2Fmodels%2Fquery_utils.py?ref=d3f00bd5706b35961390d3814dd7e322ead3a9a3",
            "patch": "@@ -47,6 +47,7 @@ def _combine(self, other, conn):\n         if not isinstance(other, Q):\n             raise TypeError(other)\n         obj = type(self)()\n+        obj.connector = conn\n         obj.add(self, conn)\n         obj.add(other, conn)\n         return obj\n@@ -63,6 +64,16 @@ def __invert__(self):\n         obj.negate()\n         return obj\n \n+    def clone(self):\n+        clone = self.__class__._new_instance(\n+            children=[], connector=self.connector, negated=self.negated)\n+        for child in self.children:\n+            if hasattr(child, 'clone'):\n+                clone.children.append(child.clone())\n+            else:\n+                clone.children.append(child)\n+        return clone\n+\n class DeferredAttribute(object):\n     \"\"\"\n     A wrapper for a deferred-loading field. When the value is read from this"
        },
        {
            "sha": "4711ea6e19200050f28a3c09cb51393281c8c0db",
            "filename": "django/db/models/sql/compiler.py",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/django/django/blob/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fsql%2Fcompiler.py",
            "raw_url": "https://github.com/django/django/raw/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fsql%2Fcompiler.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fdb%2Fmodels%2Fsql%2Fcompiler.py?ref=d3f00bd5706b35961390d3814dd7e322ead3a9a3",
            "patch": "@@ -87,6 +87,7 @@ def as_sql(self, with_limits=True, with_col_aliases=False):\n \n         where, w_params = self.query.where.as_sql(qn=qn, connection=self.connection)\n         having, h_params = self.query.having.as_sql(qn=qn, connection=self.connection)\n+        having_group_by = self.query.having.get_cols()\n         params = []\n         for val in six.itervalues(self.query.extra_select):\n             params.extend(val[1])\n@@ -107,7 +108,7 @@ def as_sql(self, with_limits=True, with_col_aliases=False):\n             result.append('WHERE %s' % where)\n             params.extend(w_params)\n \n-        grouping, gb_params = self.get_grouping(ordering_group_by)\n+        grouping, gb_params = self.get_grouping(having_group_by, ordering_group_by)\n         if grouping:\n             if distinct_fields:\n                 raise NotImplementedError(\n@@ -534,7 +535,7 @@ def get_from_clause(self):\n                 first = False\n         return result, from_params\n \n-    def get_grouping(self, ordering_group_by):\n+    def get_grouping(self, having_group_by, ordering_group_by):\n         \"\"\"\n         Returns a tuple representing the SQL elements in the \"group by\" clause.\n         \"\"\"\n@@ -551,7 +552,7 @@ def get_grouping(self, ordering_group_by):\n                 ]\n                 select_cols = []\n             seen = set()\n-            cols = self.query.group_by + select_cols\n+            cols = self.query.group_by + having_group_by + select_cols\n             for col in cols:\n                 col_params = ()\n                 if isinstance(col, (list, tuple)):"
        },
        {
            "sha": "389099161a6f0c49b5839906a16d26d4ac60a225",
            "filename": "django/db/models/sql/expressions.py",
            "status": "modified",
            "additions": 12,
            "deletions": 7,
            "changes": 19,
            "blob_url": "https://github.com/django/django/blob/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fsql%2Fexpressions.py",
            "raw_url": "https://github.com/django/django/raw/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fsql%2Fexpressions.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fdb%2Fmodels%2Fsql%2Fexpressions.py?ref=d3f00bd5706b35961390d3814dd7e322ead3a9a3",
            "patch": "@@ -7,23 +7,30 @@ class SQLEvaluator(object):\n     def __init__(self, expression, query, allow_joins=True, reuse=None):\n         self.expression = expression\n         self.opts = query.get_meta()\n-        self.cols = []\n-\n-        self.contains_aggregate = False\n         self.reuse = reuse\n+        self.cols = []\n         self.expression.prepare(self, query, allow_joins)\n \n     def relabeled_clone(self, change_map):\n         clone = copy.copy(self)\n         clone.cols = []\n-        for node, col in self.cols[:]:\n+        for node, col in self.cols:\n             if hasattr(col, 'relabeled_clone'):\n                 clone.cols.append((node, col.relabeled_clone(change_map)))\n             else:\n                 clone.cols.append((node,\n                                    (change_map.get(col[0], col[0]), col[1])))\n         return clone\n \n+    def get_cols(self):\n+        cols = []\n+        for node, col in self.cols:\n+            if hasattr(node, 'get_cols'):\n+                cols.extend(node.get_cols())\n+            elif isinstance(col, tuple):\n+                cols.append(col)\n+        return cols\n+\n     def prepare(self):\n         return self\n \n@@ -44,9 +51,7 @@ def prepare_leaf(self, node, query, allow_joins):\n             raise FieldError(\"Joined field references are not permitted in this query\")\n \n         field_list = node.name.split(LOOKUP_SEP)\n-        if (len(field_list) == 1 and\n-            node.name in query.aggregate_select.keys()):\n-            self.contains_aggregate = True\n+        if node.name in query.aggregates:\n             self.cols.append((node, query.aggregate_select[node.name]))\n         else:\n             try:"
        },
        {
            "sha": "2fd67ff0ca3d7a5835197342688c2ebaf3061693",
            "filename": "django/db/models/sql/query.py",
            "status": "modified",
            "additions": 137,
            "deletions": 109,
            "changes": 246,
            "blob_url": "https://github.com/django/django/blob/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fsql%2Fquery.py",
            "raw_url": "https://github.com/django/django/raw/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fsql%2Fquery.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fdb%2Fmodels%2Fsql%2Fquery.py?ref=d3f00bd5706b35961390d3814dd7e322ead3a9a3",
            "patch": "@@ -15,6 +15,7 @@\n from django.utils import six\n from django.db import connections, DEFAULT_DB_ALIAS\n from django.db.models.constants import LOOKUP_SEP\n+from django.db.models.aggregates import refs_aggregate\n from django.db.models.expressions import ExpressionNode\n from django.db.models.fields import FieldDoesNotExist\n from django.db.models.loading import get_model\n@@ -1004,19 +1005,6 @@ def remove_inherited_models(self):\n                 self.unref_alias(alias)\n         self.included_inherited_models = {}\n \n-    def need_force_having(self, q_object):\n-        \"\"\"\n-        Returns whether or not all elements of this q_object need to be put\n-        together in the HAVING clause.\n-        \"\"\"\n-        for child in q_object.children:\n-            if isinstance(child, Node):\n-                if self.need_force_having(child):\n-                    return True\n-            else:\n-                if child[0].split(LOOKUP_SEP)[0] in self.aggregates:\n-                    return True\n-        return False\n \n     def add_aggregate(self, aggregate, model, alias, is_summary):\n         \"\"\"\n@@ -1065,24 +1053,32 @@ def add_aggregate(self, aggregate, model, alias, is_summary):\n         # Add the aggregate to the query\n         aggregate.add_to_query(self, alias, col=col, source=source, is_summary=is_summary)\n \n-    def add_filter(self, filter_expr, connector=AND, negate=False,\n-                   can_reuse=None, force_having=False):\n+    def build_filter(self, filter_expr, branch_negated=False, current_negated=False,\n+                     can_reuse=None):\n         \"\"\"\n-        Add a single filter to the query. The 'filter_expr' is a pair:\n-        (filter_string, value). E.g. ('name__contains', 'fred')\n+        Builds a WhereNode for a single filter clause, but doesn't add it\n+        to this Query. Query.add_q() will then add this filter to the where\n+        or having Node.\n+\n+        The 'branch_negated' tells us if the current branch contains any\n+        negations. This will be used to determine if subqueries are needed.\n+\n+        The 'current_negated' is used to determine if the current filter is\n+        negated or not and this will be used to determine if IS NULL filtering\n+        is needed.\n+\n+        The difference between current_netageted and branch_negated is that\n+        branch_negated is set on first negation, but current_negated is\n+        flipped for each negation.\n \n-        If 'negate' is True, this is an exclude() filter. It's important to\n-        note that this method does not negate anything in the where-clause\n-        object when inserting the filter constraints. This is because negated\n-        filters often require multiple calls to add_filter() and the negation\n-        should only happen once. So the caller is responsible for this (the\n-        caller will normally be add_q(), so that as an example).\n+        Note that add_filter will not do any negating itself, that is done\n+        upper in the code by add_q().\n \n-        If 'can_reuse' is a set, we are processing a component of a\n-        multi-component filter (e.g. filter(Q1, Q2)). In this case, 'can_reuse'\n-        will be a set of table aliases that can be reused in this filter, even\n-        if we would otherwise force the creation of new aliases for a join\n-        (needed for nested Q-filters). The set is updated by this method.\n+        The 'can_reuse' is a set of reusable joins for multijoins.\n+\n+        The method will create a filter clause that can be added to the current\n+        query. However, if the filter isn't added to the query then the caller\n+        is responsible for unreffing the joins used.\n         \"\"\"\n         arg, value = filter_expr\n         parts = arg.split(LOOKUP_SEP)\n@@ -1091,10 +1087,10 @@ def add_filter(self, filter_expr, connector=AND, negate=False,\n \n         # Work out the lookup type and remove it from the end of 'parts',\n         # if necessary.\n-        lookup_type = 'exact' # Default lookup type\n+        lookup_type = 'exact'  # Default lookup type\n         num_parts = len(parts)\n         if (len(parts) > 1 and parts[-1] in self.query_terms\n-            and arg not in self.aggregates):\n+                and arg not in self.aggregates):\n             # Traverse the lookup query to distinguish related fields from\n             # lookup types.\n             lookup_model = self.model\n@@ -1115,10 +1111,7 @@ def add_filter(self, filter_expr, connector=AND, negate=False,\n                         lookup_type = parts.pop()\n                         break\n \n-        # By default, this is a WHERE clause. If an aggregate is referenced\n-        # in the value, the filter will be promoted to a HAVING\n-        having_clause = False\n-\n+        clause = self.where_class()\n         # Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all\n         # uses of None as a query value.\n         if value is None:\n@@ -1131,20 +1124,15 @@ def add_filter(self, filter_expr, connector=AND, negate=False,\n         elif isinstance(value, ExpressionNode):\n             # If value is a query expression, evaluate it\n             value = SQLEvaluator(value, self, reuse=can_reuse)\n-            having_clause = value.contains_aggregate\n \n         for alias, aggregate in self.aggregates.items():\n             if alias in (parts[0], LOOKUP_SEP.join(parts)):\n-                entry = self.where_class()\n-                entry.add((aggregate, lookup_type, value), AND)\n-                if negate:\n-                    entry.negate()\n-                self.having.add(entry, connector)\n-                return\n+                clause.add((aggregate, lookup_type, value), AND)\n+                return clause\n \n         opts = self.get_meta()\n         alias = self.get_initial_alias()\n-        allow_many = not negate\n+        allow_many = not branch_negated\n \n         try:\n             field, target, opts, join_list, path = self.setup_joins(\n@@ -1153,11 +1141,10 @@ def add_filter(self, filter_expr, connector=AND, negate=False,\n             if can_reuse is not None:\n                 can_reuse.update(join_list)\n         except MultiJoin as e:\n-            self.split_exclude(filter_expr, LOOKUP_SEP.join(parts[:e.level]),\n-                               can_reuse, e.names_with_path)\n-            return\n+            return self.split_exclude(filter_expr, LOOKUP_SEP.join(parts[:e.level]),\n+                                      can_reuse, e.names_with_path)\n \n-        if (lookup_type == 'isnull' and value is True and not negate and\n+        if (lookup_type == 'isnull' and value is True and not current_negated and\n                 len(join_list) > 1):\n             # If the comparison is against NULL, we may need to use some left\n             # outer joins when creating the join chain. This is only done when\n@@ -1169,17 +1156,9 @@ def add_filter(self, filter_expr, connector=AND, negate=False,\n         # promotion must happen before join trimming to have the join type\n         # information available when reusing joins.\n         target, alias, join_list = self.trim_joins(target, join_list, path)\n-\n-        if having_clause or force_having:\n-            if (alias, target.column) not in self.group_by:\n-                self.group_by.append((alias, target.column))\n-            self.having.add((Constraint(alias, target.column, field), lookup_type, value),\n-                connector)\n-        else:\n-            self.where.add((Constraint(alias, target.column, field), lookup_type, value),\n-                connector)\n-\n-        if negate:\n+        clause.add((Constraint(alias, target.column, field), lookup_type, value),\n+                   AND)\n+        if current_negated and (lookup_type != 'isnull' or value is False):\n             self.promote_joins(join_list)\n             if (lookup_type != 'isnull' and (\n                     self.is_nullable(target) or self.alias_map[join_list[-1]].join_type == self.LOUTER)):\n@@ -1192,64 +1171,112 @@ def add_filter(self, filter_expr, connector=AND, negate=False,\n                 # (col IS NULL OR col != someval)\n                 #   <=>\n                 # NOT (col IS NOT NULL AND col = someval).\n-                self.where.add((Constraint(alias, target.column, None), 'isnull', False), AND)\n+                clause.add((Constraint(alias, target.column, None), 'isnull', False), AND)\n+        return clause\n+\n+    def add_filter(self, filter_clause):\n+        self.where.add(self.build_filter(filter_clause), 'AND')\n+\n+    def need_having(self, obj):\n+        \"\"\"\n+        Returns whether or not all elements of this q_object need to be put\n+        together in the HAVING clause.\n+        \"\"\"\n+        if not isinstance(obj, Node):\n+            return (refs_aggregate(obj[0].split(LOOKUP_SEP), self.aggregates)\n+                    or (hasattr(obj[1], 'contains_aggregate')\n+                        and obj[1].contains_aggregate(self.aggregates)))\n+        return any(self.need_having(c) for c in obj.children)\n+\n+    def split_having_parts(self, q_object, negated=False):\n+        \"\"\"\n+        Returns a list of q_objects which need to go into the having clause\n+        instead of the where clause. Removes the splitted out nodes from the\n+        given q_object. Note that the q_object is altered, so cloning it is\n+        needed.\n+        \"\"\"\n+        having_parts = []\n+        for c in q_object.children[:]:\n+            # When constucting the having nodes we need to take care to\n+            # preserve the negation status from the upper parts of the tree\n+            if isinstance(c, Node):\n+                # For each negated child, flip the in_negated flag.\n+                in_negated = c.negated ^ negated\n+                if c.connector == OR and self.need_having(c):\n+                    # A subtree starting from OR clause must go into having in\n+                    # whole if any part of that tree references an aggregate.\n+                    q_object.children.remove(c)\n+                    having_parts.append(c)\n+                    c.negated = in_negated\n+                else:\n+                    having_parts.extend(\n+                        self.split_having_parts(c, in_negated)[1])\n+            elif self.need_having(c):\n+                q_object.children.remove(c)\n+                new_q = self.where_class(children=[c], negated=negated)\n+                having_parts.append(new_q)\n+        return q_object, having_parts\n+\n+    def add_q(self, q_object):\n+        \"\"\"\n+        A preprocessor for the internal _add_q(). Responsible for\n+        splitting the given q_object into where and having parts and\n+        setting up some internal variables.\n+        \"\"\"\n+        if not self.need_having(q_object):\n+            where_part, having_parts = q_object, []\n+        else:\n+            where_part, having_parts = self.split_having_parts(\n+                q_object.clone(), q_object.negated)\n+        used_aliases = self.used_aliases\n+        clause = self._add_q(where_part, used_aliases)\n+        self.where.add(clause, AND)\n+        for hp in having_parts:\n+            clause = self._add_q(hp, used_aliases)\n+            self.having.add(clause, AND)\n+        if self.filter_is_sticky:\n+            self.used_aliases = used_aliases\n \n-    def add_q(self, q_object, used_aliases=None, force_having=False):\n+    def _add_q(self, q_object, used_aliases, branch_negated=False,\n+               current_negated=False):\n         \"\"\"\n         Adds a Q-object to the current filter.\n \n         Can also be used to add anything that has an 'add_to_query()' method.\n         \"\"\"\n-        if used_aliases is None:\n-            used_aliases = self.used_aliases\n-        if hasattr(q_object, 'add_to_query'):\n-            # Complex custom objects are responsible for adding themselves.\n-            q_object.add_to_query(self, used_aliases)\n-        else:\n-            if self.where and q_object.connector != AND and len(q_object) > 1:\n-                self.where.start_subtree(AND)\n-                subtree = True\n-            else:\n-                subtree = False\n-            connector = q_object.connector\n-            if connector == OR:\n-                alias_usage_counts = dict()\n-                aliases_before = set(self.tables)\n-            if q_object.connector == OR and not force_having:\n-                force_having = self.need_force_having(q_object)\n-            for child in q_object.children:\n-                if force_having:\n-                    self.having.start_subtree(connector)\n-                else:\n-                    self.where.start_subtree(connector)\n-                if connector == OR:\n-                    refcounts_before = self.alias_refcount.copy()\n-                if isinstance(child, Node):\n-                    self.add_q(child, used_aliases, force_having=force_having)\n-                else:\n-                    self.add_filter(child, connector, q_object.negated,\n-                            can_reuse=used_aliases, force_having=force_having)\n-                if connector == OR:\n-                    used = alias_diff(refcounts_before, self.alias_refcount)\n-                    for alias in used:\n-                        alias_usage_counts[alias] = alias_usage_counts.get(alias, 0) + 1\n-                if force_having:\n-                    self.having.end_subtree()\n-                else:\n-                    self.where.end_subtree()\n+        connector = q_object.connector\n+        current_negated = current_negated ^ q_object.negated\n+        branch_negated = branch_negated or q_object.negated\n+        # Note that if the connector happens to match what we have already in\n+        # the tree, the add will be a no-op.\n+        target_clause = self.where_class(connector=connector,\n+                                         negated=q_object.negated)\n \n+        if connector == OR:\n+            alias_usage_counts = dict()\n+            aliases_before = set(self.tables)\n+        for child in q_object.children:\n             if connector == OR:\n-                self.promote_disjunction(aliases_before, alias_usage_counts,\n-                                         len(q_object.children))\n-            if q_object.negated:\n-                self.where.negate()\n-            if subtree:\n-                self.where.end_subtree()\n-        if self.filter_is_sticky:\n-            self.used_aliases = used_aliases\n+                refcounts_before = self.alias_refcount.copy()\n+            if isinstance(child, Node):\n+                child_clause = self._add_q(\n+                    child, used_aliases, branch_negated,\n+                    current_negated)\n+            else:\n+                child_clause = self.build_filter(\n+                    child, can_reuse=used_aliases, branch_negated=branch_negated,\n+                    current_negated=current_negated)\n+            target_clause.add(child_clause, connector)\n+            if connector == OR:\n+                used = alias_diff(refcounts_before, self.alias_refcount)\n+                for alias in used:\n+                    alias_usage_counts[alias] = alias_usage_counts.get(alias, 0) + 1\n+        if connector == OR:\n+            self.promote_disjunction(aliases_before, alias_usage_counts,\n+                                     len(q_object.children))\n+        return target_clause\n \n-    def names_to_path(self, names, opts, allow_many=False,\n-                      allow_explicit_fk=True):\n+    def names_to_path(self, names, opts, allow_many, allow_explicit_fk):\n         \"\"\"\n         Walks the names path and turns them PathInfo tuples. Note that a\n         single name in 'names' can generate multiple PathInfos (m2m for\n@@ -1413,7 +1440,7 @@ def split_exclude(self, filter_expr, prefix, can_reuse, names_with_path):\n         \"\"\"\n         # Generate the inner query.\n         query = Query(self.model)\n-        query.add_filter(filter_expr)\n+        query.where.add(query.build_filter(filter_expr), AND)\n         query.bump_prefix()\n         query.clear_ordering(True)\n         # Try to have as simple as possible subquery -> trim leading joins from\n@@ -1443,8 +1470,9 @@ def split_exclude(self, filter_expr, prefix, can_reuse, names_with_path):\n                     path[paths_in_prefix - len(path)].from_field.name)\n                 break\n         trimmed_prefix = LOOKUP_SEP.join(trimmed_prefix)\n-        self.add_filter(('%s__in' % trimmed_prefix, query), negate=True,\n-                        can_reuse=can_reuse)\n+        return self.build_filter(\n+            ('%s__in' % trimmed_prefix, query),\n+            current_negated=True, branch_negated=True, can_reuse=can_reuse)\n \n     def set_empty(self):\n         self.where = EmptyWhere()"
        },
        {
            "sha": "78727e394a0a852764c623182c19d86455812581",
            "filename": "django/db/models/sql/subqueries.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/django/django/blob/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fsql%2Fsubqueries.py",
            "raw_url": "https://github.com/django/django/raw/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fsql%2Fsubqueries.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fdb%2Fmodels%2Fsql%2Fsubqueries.py?ref=d3f00bd5706b35961390d3814dd7e322ead3a9a3",
            "patch": "@@ -45,7 +45,7 @@ def delete_batch(self, pk_list, using, field=None):\n         for offset in range(0, len(pk_list), GET_ITERATOR_CHUNK_SIZE):\n             where = self.where_class()\n             where.add((Constraint(None, field.column, field), 'in',\n-                    pk_list[offset:offset + GET_ITERATOR_CHUNK_SIZE]), AND)\n+                       pk_list[offset:offset + GET_ITERATOR_CHUNK_SIZE]), AND)\n             self.do_query(self.model._meta.db_table, where, using=using)\n \n     def delete_qs(self, query, using):\n@@ -117,8 +117,8 @@ def update_batch(self, pk_list, values, using):\n         for offset in range(0, len(pk_list), GET_ITERATOR_CHUNK_SIZE):\n             self.where = self.where_class()\n             self.where.add((Constraint(None, pk_field.column, pk_field), 'in',\n-                    pk_list[offset:offset + GET_ITERATOR_CHUNK_SIZE]),\n-                    AND)\n+                            pk_list[offset:offset + GET_ITERATOR_CHUNK_SIZE]),\n+                           AND)\n             self.get_compiler(using).execute_sql(None)\n \n     def add_update_values(self, values):"
        },
        {
            "sha": "ced5325754ad943b4aa4ea076346f71d4216ad47",
            "filename": "django/db/models/sql/where.py",
            "status": "modified",
            "additions": 21,
            "deletions": 13,
            "changes": 34,
            "blob_url": "https://github.com/django/django/blob/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fsql%2Fwhere.py",
            "raw_url": "https://github.com/django/django/raw/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Fdb%2Fmodels%2Fsql%2Fwhere.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fdb%2Fmodels%2Fsql%2Fwhere.py?ref=d3f00bd5706b35961390d3814dd7e322ead3a9a3",
            "patch": "@@ -46,18 +46,17 @@ class WhereNode(tree.Node):\n     \"\"\"\n     default = AND\n \n-    def add(self, data, connector):\n+    def _prepare_data(self, data):\n         \"\"\"\n-        Add a node to the where-tree. If the data is a list or tuple, it is\n-        expected to be of the form (obj, lookup_type, value), where obj is\n-        a Constraint object, and is then slightly munged before being stored\n-        (to avoid storing any reference to field objects). Otherwise, the 'data'\n-        is stored unchanged and can be any class with an 'as_sql()' method.\n+        Prepare data for addition to the tree. If the data is a list or tuple,\n+        it is expected to be of the form (obj, lookup_type, value), where obj\n+        is a Constraint object, and is then slightly munged before being\n+        stored (to avoid storing any reference to field objects). Otherwise,\n+        the 'data' is stored unchanged and can be any class with an 'as_sql()'\n+        method.\n         \"\"\"\n         if not isinstance(data, (list, tuple)):\n-            super(WhereNode, self).add(data, connector)\n-            return\n-\n+            return data\n         obj, lookup_type, value = data\n         if isinstance(value, collections.Iterator):\n             # Consume any generators immediately, so that we can determine\n@@ -78,9 +77,7 @@ def add(self, data, connector):\n \n         if hasattr(obj, \"prepare\"):\n             value = obj.prepare(lookup_type, value)\n-\n-        super(WhereNode, self).add(\n-                (obj, lookup_type, value_annotation, value), connector)\n+        return (obj, lookup_type, value_annotation, value)\n \n     def as_sql(self, qn, connection):\n         \"\"\"\n@@ -154,6 +151,18 @@ def as_sql(self, qn, connection):\n                 sql_string = '(%s)' % sql_string\n         return sql_string, result_params\n \n+    def get_cols(self):\n+        cols = []\n+        for child in self.children:\n+            if hasattr(child, 'get_cols'):\n+                cols.extend(child.get_cols())\n+            else:\n+                if isinstance(child[0], Constraint):\n+                    cols.append((child[0].alias, child[0].col))\n+                if hasattr(child[3], 'get_cols'):\n+                    cols.extend(child[3].get_cols())\n+        return cols\n+\n     def make_atom(self, child, qn, connection):\n         \"\"\"\n         Turn a tuple (Constraint(table_alias, column_name, db_type),\n@@ -284,7 +293,6 @@ def clone(self):\n         with empty subtree_parents). Childs must be either (Contraint, lookup,\n         value) tuples, or objects supporting .clone().\n         \"\"\"\n-        assert not self.subtree_parents\n         clone = self.__class__._new_instance(\n             children=[], connector=self.connector, negated=self.negated)\n         for child in self.children:"
        },
        {
            "sha": "4152b4600b5d60c6c8471417f8818a1c9e9a1a31",
            "filename": "django/utils/tree.py",
            "status": "modified",
            "additions": 46,
            "deletions": 66,
            "changes": 112,
            "blob_url": "https://github.com/django/django/blob/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Futils%2Ftree.py",
            "raw_url": "https://github.com/django/django/raw/d3f00bd5706b35961390d3814dd7e322ead3a9a3/django%2Futils%2Ftree.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Futils%2Ftree.py?ref=d3f00bd5706b35961390d3814dd7e322ead3a9a3",
            "patch": "@@ -19,14 +19,9 @@ def __init__(self, children=None, connector=None, negated=False):\n         \"\"\"\n         Constructs a new Node. If no connector is given, the default will be\n         used.\n-\n-        Warning: You probably don't want to pass in the 'negated' parameter. It\n-        is NOT the same as constructing a node and calling negate() on the\n-        result.\n         \"\"\"\n         self.children = children and children[:] or []\n         self.connector = connector or self.default\n-        self.subtree_parents = []\n         self.negated = negated\n \n     # We need this because of django.db.models.query_utils.Q. Q. __init__() is\n@@ -59,7 +54,6 @@ def __deepcopy__(self, memodict):\n         obj = Node(connector=self.connector, negated=self.negated)\n         obj.__class__ = self.__class__\n         obj.children = copy.deepcopy(self.children, memodict)\n-        obj.subtree_parents = copy.deepcopy(self.subtree_parents, memodict)\n         return obj\n \n     def __len__(self):\n@@ -83,74 +77,60 @@ def __contains__(self, other):\n         \"\"\"\n         return other in self.children\n \n-    def add(self, node, conn_type):\n+    def _prepare_data(self, data):\n         \"\"\"\n-        Adds a new node to the tree. If the conn_type is the same as the root's\n-        current connector type, the node is added to the first level.\n-        Otherwise, the whole tree is pushed down one level and a new root\n-        connector is created, connecting the existing tree and the new node.\n+        A subclass hook for doing subclass specific transformations of the\n+        given data on combine() or add().\n         \"\"\"\n-        if node in self.children and conn_type == self.connector:\n-            return\n-        if len(self.children) < 2:\n-            self.connector = conn_type\n-        if self.connector == conn_type:\n-            if isinstance(node, Node) and (node.connector == conn_type or\n-                    len(node) == 1):\n-                self.children.extend(node.children)\n-            else:\n-                self.children.append(node)\n-        else:\n-            obj = self._new_instance(self.children, self.connector,\n-                    self.negated)\n-            self.connector = conn_type\n-            self.children = [obj, node]\n+        return data\n \n-    def negate(self):\n+    def add(self, data, conn_type, squash=True):\n         \"\"\"\n-        Negate the sense of the root connector. This reorganises the children\n-        so that the current node has a single child: a negated node containing\n-        all the previous children. This slightly odd construction makes adding\n-        new children behave more intuitively.\n+        Combines this tree and the data represented by data using the\n+        connector conn_type. The combine is done by squashing the node other\n+        away if possible.\n \n-        Interpreting the meaning of this negate is up to client code. This\n-        method is useful for implementing \"not\" arrangements.\n-        \"\"\"\n-        self.children = [self._new_instance(self.children, self.connector,\n-                not self.negated)]\n-        self.connector = self.default\n+        This tree (self) will never be pushed to a child node of the\n+        combined tree, nor will the connector or negated properties change.\n \n-    def start_subtree(self, conn_type):\n-        \"\"\"\n-        Sets up internal state so that new nodes are added to a subtree of the\n-        current node. The conn_type specifies how the sub-tree is joined to the\n-        existing children.\n+        The function returns a node which can be used in place of data\n+        regardless if the node other got squashed or not.\n+\n+        If `squash` is False the data is prepared and added as a child to\n+        this tree without further logic.\n         \"\"\"\n-        if len(self.children) == 1:\n-            self.connector = conn_type\n-        elif self.connector != conn_type:\n-            self.children = [self._new_instance(self.children, self.connector,\n-                    self.negated)]\n+        if data in self.children:\n+            return data\n+        data = self._prepare_data(data)\n+        if not squash:\n+            self.children.append(data)\n+            return data\n+        if self.connector == conn_type:\n+            # We can reuse self.children to append or squash the node other.\n+            if (isinstance(data, Node) and not data.negated\n+                    and (data.connector == conn_type or len(data) == 1)):\n+                # We can squash the other node's children directly into this\n+                # node. We are just doing (AB)(CD) == (ABCD) here, with the\n+                # addition that if the length of the other node is 1 the\n+                # connector doesn't matter. However, for the len(self) == 1\n+                # case we don't want to do the squashing, as it would alter\n+                # self.connector.\n+                self.children.extend(data.children)\n+                return self\n+            else:\n+                # We could use perhaps additional logic here to see if some\n+                # children could be used for pushdown here.\n+                self.children.append(data)\n+                return data\n+        else:\n+            obj = self._new_instance(self.children, self.connector,\n+                                     self.negated)\n             self.connector = conn_type\n-            self.negated = False\n-\n-        self.subtree_parents.append(self.__class__(self.children,\n-                self.connector, self.negated))\n-        self.connector = self.default\n-        self.negated = False\n-        self.children = []\n+            self.children = [obj, data]\n+            return data\n \n-    def end_subtree(self):\n+    def negate(self):\n         \"\"\"\n-        Closes off the most recently unmatched start_subtree() call.\n-\n-        This puts the current state into a node of the parent tree and returns\n-        the current instances state to be the parent.\n+        Negate the sense of the root connector.\n         \"\"\"\n-        obj = self.subtree_parents.pop()\n-        node = self.__class__(self.children, self.connector)\n-        self.connector = obj.connector\n-        self.negated = obj.negated\n-        self.children = obj.children\n-        self.children.append(node)\n-\n+        self.negated = not self.negated"
        },
        {
            "sha": "20677270f5c81104aae1bee62b1c76f730f7828c",
            "filename": "tests/aggregation_regress/tests.py",
            "status": "modified",
            "additions": 85,
            "deletions": 4,
            "changes": 89,
            "blob_url": "https://github.com/django/django/blob/d3f00bd5706b35961390d3814dd7e322ead3a9a3/tests%2Faggregation_regress%2Ftests.py",
            "raw_url": "https://github.com/django/django/raw/d3f00bd5706b35961390d3814dd7e322ead3a9a3/tests%2Faggregation_regress%2Ftests.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/tests%2Faggregation_regress%2Ftests.py?ref=d3f00bd5706b35961390d3814dd7e322ead3a9a3",
            "patch": "@@ -10,6 +10,7 @@\n from django.db.models import Count, Max, Avg, Sum, StdDev, Variance, F, Q\n from django.test import TestCase, Approximate, skipUnlessDBFeature\n from django.utils import six\n+from django.utils.unittest import expectedFailure\n \n from .models import (Author, Book, Publisher, Clues, Entries, HardbackBook,\n         ItemTag, WithManualPK)\n@@ -472,7 +473,7 @@ def test_more_more(self):\n         # Regression for #15709 - Ensure each group_by field only exists once\n         # per query\n         qs = Book.objects.values('publisher').annotate(max_pages=Max('pages')).order_by()\n-        grouping, gb_params = qs.query.get_compiler(qs.db).get_grouping([])\n+        grouping, gb_params = qs.query.get_compiler(qs.db).get_grouping([], [])\n         self.assertEqual(len(grouping), 1)\n \n     def test_duplicate_alias(self):\n@@ -847,22 +848,22 @@ def test_filtering_by_annotation_name(self):\n \n         # The name of the explicitly provided annotation name in this case\n         # poses no problem\n-        qs = Author.objects.annotate(book_cnt=Count('book')).filter(book_cnt=2)\n+        qs = Author.objects.annotate(book_cnt=Count('book')).filter(book_cnt=2).order_by('name')\n         self.assertQuerysetEqual(\n             qs,\n             ['Peter Norvig'],\n             lambda b: b.name\n         )\n         # Neither in this case\n-        qs = Author.objects.annotate(book_count=Count('book')).filter(book_count=2)\n+        qs = Author.objects.annotate(book_count=Count('book')).filter(book_count=2).order_by('name')\n         self.assertQuerysetEqual(\n             qs,\n             ['Peter Norvig'],\n             lambda b: b.name\n         )\n         # This case used to fail because the ORM couldn't resolve the\n         # automatically generated annotation name `book__count`\n-        qs = Author.objects.annotate(Count('book')).filter(book__count=2)\n+        qs = Author.objects.annotate(Count('book')).filter(book__count=2).order_by('name')\n         self.assertQuerysetEqual(\n             qs,\n             ['Peter Norvig'],\n@@ -1020,3 +1021,83 @@ def test_aggregation_with_generic_reverse_relation(self):\n                 ('The Definitive Guide to Django: Web Development Done Right', 0)\n             ]\n         )\n+\n+    def test_negated_aggregation(self):\n+        expected_results = Author.objects.exclude(\n+            pk__in=Author.objects.annotate(book_cnt=Count('book')).filter(book_cnt=2)\n+        ).order_by('name')\n+        expected_results = [a.name for a in expected_results]\n+        qs = Author.objects.annotate(book_cnt=Count('book')).exclude(\n+            Q(book_cnt=2), Q(book_cnt=2)).order_by('name')\n+        self.assertQuerysetEqual(\n+            qs,\n+            expected_results,\n+            lambda b: b.name\n+        )\n+        expected_results = Author.objects.exclude(\n+            pk__in=Author.objects.annotate(book_cnt=Count('book')).filter(book_cnt=2)\n+        ).order_by('name')\n+        expected_results = [a.name for a in expected_results]\n+        qs = Author.objects.annotate(book_cnt=Count('book')).exclude(Q(book_cnt=2)|Q(book_cnt=2)).order_by('name')\n+        self.assertQuerysetEqual(\n+            qs,\n+            expected_results,\n+            lambda b: b.name\n+        )\n+\n+    def test_name_filters(self):\n+        qs = Author.objects.annotate(Count('book')).filter(\n+            Q(book__count__exact=2)|Q(name='Adrian Holovaty')\n+        ).order_by('name')\n+        self.assertQuerysetEqual(\n+            qs,\n+            ['Adrian Holovaty', 'Peter Norvig'],\n+            lambda b: b.name\n+        )\n+\n+    def test_name_expressions(self):\n+        # Test that aggregates are spotted corretly from F objects.\n+        # Note that Adrian's age is 34 in the fixtures, and he has one book\n+        # so both conditions match one author.\n+        qs = Author.objects.annotate(Count('book')).filter(\n+            Q(name='Peter Norvig')|Q(age=F('book__count') + 33)\n+        ).order_by('name')\n+        self.assertQuerysetEqual(\n+            qs,\n+            ['Adrian Holovaty', 'Peter Norvig'],\n+            lambda b: b.name\n+        )\n+\n+    def test_ticket_11293(self):\n+        q1 = Q(price__gt=50)\n+        q2 = Q(authors__count__gt=1)\n+        query = Book.objects.annotate(Count('authors')).filter(\n+            q1 | q2).order_by('pk')\n+        self.assertQuerysetEqual(\n+            query, [1, 4, 5, 6],\n+            lambda b: b.pk)\n+\n+    def test_ticket_11293_q_immutable(self):\n+        \"\"\"\n+        Check that splitting a q object to parts for where/having doesn't alter\n+        the original q-object.\n+        \"\"\"\n+        q1 = Q(isbn='')\n+        q2 = Q(authors__count__gt=1)\n+        query = Book.objects.annotate(Count('authors'))\n+        query.filter(q1 | q2)\n+        self.assertEqual(len(q2.children), 1)\n+\n+    def test_fobj_group_by(self):\n+        \"\"\"\n+        Check that an F() object referring to related column works correctly\n+        in group by.\n+        \"\"\"\n+        qs = Book.objects.annotate(\n+            acount=Count('authors')\n+        ).filter(\n+            acount=F('publisher__num_awards')\n+        )\n+        self.assertQuerysetEqual(\n+            qs, ['Sams Teach Yourself Django in 24 Hours'],\n+            lambda b: b.name)"
        },
        {
            "sha": "71346d8be93d54211cb6f4f7a3f7fce0620e1c3c",
            "filename": "tests/queries/models.py",
            "status": "modified",
            "additions": 22,
            "deletions": 0,
            "changes": 22,
            "blob_url": "https://github.com/django/django/blob/d3f00bd5706b35961390d3814dd7e322ead3a9a3/tests%2Fqueries%2Fmodels.py",
            "raw_url": "https://github.com/django/django/raw/d3f00bd5706b35961390d3814dd7e322ead3a9a3/tests%2Fqueries%2Fmodels.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/tests%2Fqueries%2Fmodels.py?ref=d3f00bd5706b35961390d3814dd7e322ead3a9a3",
            "patch": "@@ -475,3 +475,25 @@ class MyObject(models.Model):\n     parent = models.ForeignKey('self', null=True, blank=True, related_name='children')\n     data = models.CharField(max_length=100)\n     created_at = models.DateTimeField(auto_now_add=True)\n+\n+# Models for #17600 regressions\n+@python_2_unicode_compatible\n+class Order(models.Model):\n+    id = models.IntegerField(primary_key=True)\n+\n+    class Meta:\n+        ordering = ('pk', )\n+\n+    def __str__(self):\n+        return '%s' % self.pk\n+\n+@python_2_unicode_compatible\n+class OrderItem(models.Model):\n+    order = models.ForeignKey(Order, related_name='items')\n+    status = models.IntegerField()\n+\n+    class Meta:\n+        ordering = ('pk', )\n+\n+    def __str__(self):\n+        return '%s' % self.pk"
        },
        {
            "sha": "31d4b4e1a49186966be1ecc16234246f83ace42e",
            "filename": "tests/queries/tests.py",
            "status": "modified",
            "additions": 141,
            "deletions": 8,
            "changes": 149,
            "blob_url": "https://github.com/django/django/blob/d3f00bd5706b35961390d3814dd7e322ead3a9a3/tests%2Fqueries%2Ftests.py",
            "raw_url": "https://github.com/django/django/raw/d3f00bd5706b35961390d3814dd7e322ead3a9a3/tests%2Fqueries%2Ftests.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/tests%2Fqueries%2Ftests.py?ref=d3f00bd5706b35961390d3814dd7e322ead3a9a3",
            "patch": "@@ -23,9 +23,9 @@\n     Ranking, Related, Report, ReservedName, Tag, TvChef, Valid, X, Food, Eaten,\n     Node, ObjectA, ObjectB, ObjectC, CategoryItem, SimpleCategory,\n     SpecialCategory, OneToOneCategory, NullableName, ProxyCategory,\n-    SingleObject, RelatedObject, ModelA, ModelD, Responsibility, Job,\n-    JobResponsibilities, BaseA, Identifier, Program, Channel, Page, Paragraph,\n-    Chapter, Book, MyObject)\n+    SingleObject, RelatedObject, ModelA, ModelB, ModelC, ModelD, Responsibility,\n+    Job, JobResponsibilities, BaseA, Identifier, Program, Channel, Page,\n+    Paragraph, Chapter, Book, MyObject, Order, OrderItem)\n \n \n class BaseQuerysetTest(TestCase):\n@@ -834,7 +834,6 @@ def test_ticket8439(self):\n             Note.objects.filter(Q(extrainfo__author=self.a1)|Q(extrainfo=xx)),\n             ['<Note: n1>', '<Note: n3>']\n         )\n-        xx.delete()\n         q = Note.objects.filter(Q(extrainfo__author=self.a1)|Q(extrainfo=xx)).query\n         self.assertEqual(\n             len([x[2] for x in q.alias_map.values() if x[2] == q.LOUTER and q.alias_refcount[x[1]]]),\n@@ -880,7 +879,6 @@ def test_double_exclude(self):\n             Item.objects.filter(Q(tags__name='t4')),\n             [repr(i) for i in Item.objects.filter(~Q(~Q(tags__name='t4')))])\n \n-    @unittest.expectedFailure\n     def test_exclude_in(self):\n         self.assertQuerysetEqual(\n             Item.objects.exclude(Q(tags__name__in=['t4', 't3'])),\n@@ -2291,6 +2289,103 @@ def test_to_field(self):\n             Responsibility.objects.exclude(jobs__name='Manager'),\n             ['<Responsibility: Programming>'])\n \n+class ExcludeTest17600(TestCase):\n+    \"\"\"\n+    Some regressiontests for ticket #17600. Some of these likely duplicate\n+    other existing tests.\n+    \"\"\"\n+\n+    def setUp(self):\n+        # Create a few Orders.\n+        self.o1 = Order.objects.create(pk=1)\n+        self.o2 = Order.objects.create(pk=2)\n+        self.o3 = Order.objects.create(pk=3)\n+\n+        # Create some OrderItems for the first order with homogeneous\n+        # status_id values\n+        self.oi1 = OrderItem.objects.create(order=self.o1, status=1)\n+        self.oi2 = OrderItem.objects.create(order=self.o1, status=1)\n+        self.oi3 = OrderItem.objects.create(order=self.o1, status=1)\n+\n+        # Create some OrderItems for the second order with heterogeneous\n+        # status_id values\n+        self.oi4 = OrderItem.objects.create(order=self.o2, status=1)\n+        self.oi5 = OrderItem.objects.create(order=self.o2, status=2)\n+        self.oi6 = OrderItem.objects.create(order=self.o2, status=3)\n+\n+        # Create some OrderItems for the second order with heterogeneous\n+        # status_id values\n+        self.oi7 = OrderItem.objects.create(order=self.o3, status=2)\n+        self.oi8 = OrderItem.objects.create(order=self.o3, status=3)\n+        self.oi9 = OrderItem.objects.create(order=self.o3, status=4)\n+\n+    def test_exclude_plain(self):\n+        \"\"\"\n+        This should exclude Orders which have some items with status 1\n+\n+        \"\"\"\n+        self.assertQuerysetEqual(\n+            Order.objects.exclude(items__status=1),\n+            ['<Order: 3>'])\n+\n+    def test_exclude_plain_distinct(self):\n+        \"\"\"\n+        This should exclude Orders which have some items with status 1\n+\n+        \"\"\"\n+        self.assertQuerysetEqual(\n+            Order.objects.exclude(items__status=1).distinct(),\n+            ['<Order: 3>'])\n+\n+    def test_exclude_with_q_object_distinct(self):\n+        \"\"\"\n+        This should exclude Orders which have some items with status 1\n+\n+        \"\"\"\n+        self.assertQuerysetEqual(\n+            Order.objects.exclude(Q(items__status=1)).distinct(),\n+            ['<Order: 3>'])\n+\n+    def test_exclude_with_q_object_no_distinct(self):\n+        \"\"\"\n+        This should exclude Orders which have some items with status 1\n+\n+        \"\"\"\n+        self.assertQuerysetEqual(\n+            Order.objects.exclude(Q(items__status=1)),\n+            ['<Order: 3>'])\n+\n+    def test_exclude_with_q_is_equal_to_plain_exclude(self):\n+        \"\"\"\n+        Using exclude(condition) and exclude(Q(condition)) should\n+        yield the same QuerySet\n+\n+        \"\"\"\n+        self.assertEqual(\n+            list(Order.objects.exclude(items__status=1).distinct()),\n+            list(Order.objects.exclude(Q(items__status=1)).distinct()))\n+\n+    def test_exclude_with_q_is_equal_to_plain_exclude_variation(self):\n+        \"\"\"\n+        Using exclude(condition) and exclude(Q(condition)) should\n+        yield the same QuerySet\n+\n+        \"\"\"\n+        self.assertEqual(\n+            list(Order.objects.exclude(items__status=1)),\n+            list(Order.objects.exclude(Q(items__status=1)).distinct()))\n+\n+    @unittest.expectedFailure\n+    def test_only_orders_with_all_items_having_status_1(self):\n+        \"\"\"\n+        This should only return orders having ALL items set to status 1, or\n+        those items not having any orders at all. The correct way to write\n+        this query in SQL seems to be using two nested subqueries.\n+        \"\"\"\n+        self.assertQuerysetEqual(\n+            Order.objects.exclude(~Q(items__status=1)).distinct(),\n+            ['<Order: 1>'])\n+\n class NullInExcludeTest(TestCase):\n     def setUp(self):\n         NullableName.objects.create(name='i1')\n@@ -2326,6 +2421,14 @@ def test_col_not_in_list_containing_null(self):\n             NullableName.objects.exclude(name__in=[None]),\n             ['i1'], attrgetter('name'))\n \n+    def test_double_exclude(self):\n+        self.assertEqual(\n+            list(NullableName.objects.filter(~~Q(name='i1'))),\n+            list(NullableName.objects.filter(Q(name='i1'))))\n+        self.assertNotIn(\n+            'IS NOT NULL',\n+            str(NullableName.objects.filter(~~Q(name='i1')).query))\n+\n class EmptyStringsAsNullTest(TestCase):\n     \"\"\"\n     Test that filtering on non-null character fields works as expected.\n@@ -2433,8 +2536,12 @@ def test_empty_nodes(self):\n \n class NullJoinPromotionOrTest(TestCase):\n     def setUp(self):\n-        d = ModelD.objects.create(name='foo')\n-        ModelA.objects.create(name='bar', d=d)\n+        self.d1 = ModelD.objects.create(name='foo')\n+        d2 = ModelD.objects.create(name='bar')\n+        self.a1 = ModelA.objects.create(name='a1', d=self.d1)\n+        c = ModelC.objects.create(name='c')\n+        b = ModelB.objects.create(name='b', c=c)\n+        self.a2 = ModelA.objects.create(name='a2', b=b, d=d2)\n \n     def test_ticket_17886(self):\n         # The first Q-object is generating the match, the rest of the filters\n@@ -2448,12 +2555,38 @@ def test_ticket_17886(self):\n             Q(b__c__name='foo')\n         )\n         qset = ModelA.objects.filter(q_obj)\n-        self.assertEqual(len(qset), 1)\n+        self.assertEqual(list(qset), [self.a1])\n         # We generate one INNER JOIN to D. The join is direct and not nullable\n         # so we can use INNER JOIN for it. However, we can NOT use INNER JOIN\n         # for the b->c join, as a->b is nullable.\n         self.assertEqual(str(qset.query).count('INNER JOIN'), 1)\n \n+    def test_isnull_filter_promotion(self):\n+        qs = ModelA.objects.filter(Q(b__name__isnull=True))\n+        self.assertEqual(str(qs.query).count('LEFT OUTER'), 1)\n+        self.assertEqual(list(qs), [self.a1])\n+\n+        qs = ModelA.objects.filter(~Q(b__name__isnull=True))\n+        self.assertEqual(str(qs.query).count('INNER JOIN'), 1)\n+        self.assertEqual(list(qs), [self.a2])\n+\n+        qs = ModelA.objects.filter(~~Q(b__name__isnull=True))\n+        self.assertEqual(str(qs.query).count('LEFT OUTER'), 1)\n+        self.assertEqual(list(qs), [self.a1])\n+\n+        qs = ModelA.objects.filter(Q(b__name__isnull=False))\n+        self.assertEqual(str(qs.query).count('INNER JOIN'), 1)\n+        self.assertEqual(list(qs), [self.a2])\n+\n+        qs = ModelA.objects.filter(~Q(b__name__isnull=False))\n+        self.assertEqual(str(qs.query).count('LEFT OUTER'), 1)\n+        self.assertEqual(list(qs), [self.a1])\n+\n+        qs = ModelA.objects.filter(~~Q(b__name__isnull=False))\n+        self.assertEqual(str(qs.query).count('INNER JOIN'), 1)\n+        self.assertEqual(list(qs), [self.a2])\n+\n+\n class ReverseJoinTrimmingTest(TestCase):\n     def test_reverse_trimming(self):\n         # Check that we don't accidentally trim reverse joins - we can't know"
        }
    ],
    "stats": {
        "total": 732,
        "additions": 513,
        "deletions": 219
    }
}