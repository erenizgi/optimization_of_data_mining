{
    "author": "manfre",
    "message": "Fixed #18927 -- Fixed bulk_create tests when no has_bulk_insert",
    "sha": "32ac067a6ddca465cd94fc7ee35bfe54a675979b",
    "files": [
        {
            "sha": "5d61242b9b553088f988e96fbe0a8c55f5183766",
            "filename": "tests/regressiontests/bulk_create/tests.py",
            "status": "modified",
            "additions": 43,
            "deletions": 3,
            "changes": 46,
            "blob_url": "https://github.com/django/django/blob/32ac067a6ddca465cd94fc7ee35bfe54a675979b/tests%2Fregressiontests%2Fbulk_create%2Ftests.py",
            "raw_url": "https://github.com/django/django/raw/32ac067a6ddca465cd94fc7ee35bfe54a675979b/tests%2Fregressiontests%2Fbulk_create%2Ftests.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/tests%2Fregressiontests%2Fbulk_create%2Ftests.py?ref=32ac067a6ddca465cd94fc7ee35bfe54a675979b",
            "patch": "@@ -3,7 +3,7 @@\n from operator import attrgetter\n \n from django.db import connection\n-from django.test import TestCase, skipIfDBFeature\n+from django.test import TestCase, skipIfDBFeature, skipUnlessDBFeature\n from django.test.utils import override_settings\n \n from .models import Country, Restaurant, Pizzeria, State, TwoFields\n@@ -29,6 +29,7 @@ def test_simple(self):\n         self.assertEqual(created, [])\n         self.assertEqual(Country.objects.count(), 4)\n \n+    @skipUnlessDBFeature('has_bulk_insert')\n     def test_efficiency(self):\n         with self.assertNumQueries(1):\n             Country.objects.bulk_create(self.data)\n@@ -50,6 +51,16 @@ def test_inheritance(self):\n         ], attrgetter(\"name\"))\n \n     def test_non_auto_increment_pk(self):\n+        State.objects.bulk_create([\n+            State(two_letter_code=s)\n+            for s in [\"IL\", \"NY\", \"CA\", \"ME\"]\n+        ])\n+        self.assertQuerysetEqual(State.objects.order_by(\"two_letter_code\"), [\n+            \"CA\", \"IL\", \"ME\", \"NY\",\n+        ], attrgetter(\"two_letter_code\"))\n+\n+    @skipUnlessDBFeature('has_bulk_insert')\n+    def test_non_auto_increment_pk_efficiency(self):\n         with self.assertNumQueries(1):\n             State.objects.bulk_create([\n                 State(two_letter_code=s)\n@@ -77,13 +88,21 @@ def test_large_batch(self):\n             TwoFields.objects.bulk_create([\n                    TwoFields(f1=i, f2=i+1) for i in range(0, 1001)\n                 ])\n-            self.assertTrue(len(connection.queries) < 10)\n         self.assertEqual(TwoFields.objects.count(), 1001)\n         self.assertEqual(\n             TwoFields.objects.filter(f1__gte=450, f1__lte=550).count(),\n             101)\n         self.assertEqual(TwoFields.objects.filter(f2__gte=901).count(), 101)\n \n+    @skipUnlessDBFeature('has_bulk_insert')\n+    def test_large_batch_efficiency(self):\n+        with override_settings(DEBUG=True):\n+            connection.queries = []\n+            TwoFields.objects.bulk_create([\n+                   TwoFields(f1=i, f2=i+1) for i in range(0, 1001)\n+                ])\n+            self.assertTrue(len(connection.queries) < 10)\n+\n     def test_large_batch_mixed(self):\n         \"\"\"\n         Test inserting a large batch with objects having primary key set\n@@ -94,15 +113,36 @@ def test_large_batch_mixed(self):\n             TwoFields.objects.bulk_create([\n                 TwoFields(id=i if i % 2 == 0 else None, f1=i, f2=i+1)\n                 for i in range(100000, 101000)])\n-            self.assertTrue(len(connection.queries) < 10)\n         self.assertEqual(TwoFields.objects.count(), 1000)\n         # We can't assume much about the ID's created, except that the above\n         # created IDs must exist.\n         id_range = range(100000, 101000, 2)\n         self.assertEqual(TwoFields.objects.filter(id__in=id_range).count(), 500)\n         self.assertEqual(TwoFields.objects.exclude(id__in=id_range).count(), 500)\n \n+    @skipUnlessDBFeature('has_bulk_insert')\n+    def test_large_batch_mixed_efficiency(self):\n+        \"\"\"\n+        Test inserting a large batch with objects having primary key set\n+        mixed together with objects without PK set.\n+        \"\"\"\n+        with override_settings(DEBUG=True):\n+            connection.queries = []\n+            TwoFields.objects.bulk_create([\n+                TwoFields(id=i if i % 2 == 0 else None, f1=i, f2=i+1)\n+                for i in range(100000, 101000)])\n+            self.assertTrue(len(connection.queries) < 10)\n+\n     def test_explicit_batch_size(self):\n+        objs = [TwoFields(f1=i, f2=i) for i in range(0, 4)]\n+        TwoFields.objects.bulk_create(objs, 2)\n+        self.assertEqual(TwoFields.objects.count(), len(objs))\n+        TwoFields.objects.all().delete()\n+        TwoFields.objects.bulk_create(objs, len(objs))\n+        self.assertEqual(TwoFields.objects.count(), len(objs))\n+\n+    @skipUnlessDBFeature('has_bulk_insert')\n+    def test_explicit_batch_size_efficiency(self):\n         objs = [TwoFields(f1=i, f2=i) for i in range(0, 100)]\n         with self.assertNumQueries(2):\n             TwoFields.objects.bulk_create(objs, 50)"
        }
    ],
    "stats": {
        "total": 46,
        "additions": 43,
        "deletions": 3
    }
}