{
    "author": "adrianholovaty",
    "message": "Made a small optimization to the template lexer. There's no need to calculate the len of VARIABLE_TAG_START, et al, each time we create a token.\n\ngit-svn-id: http://code.djangoproject.com/svn/django/trunk@17399 bcc190cf-cafb-0310-a4f2-bffc1f526a37",
    "sha": "234b7e372000381657250fe133cbcfa90ffbb2a9",
    "files": [
        {
            "sha": "94723238531f605e894836bbf9438ecf5a3e976d",
            "filename": "django/template/base.py",
            "status": "modified",
            "additions": 7,
            "deletions": 11,
            "changes": 18,
            "blob_url": "https://github.com/django/django/blob/234b7e372000381657250fe133cbcfa90ffbb2a9/django%2Ftemplate%2Fbase.py",
            "raw_url": "https://github.com/django/django/raw/234b7e372000381657250fe133cbcfa90ffbb2a9/django%2Ftemplate%2Fbase.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Ftemplate%2Fbase.py?ref=234b7e372000381657250fe133cbcfa90ffbb2a9",
            "patch": "@@ -204,22 +204,18 @@ def create_token(self, token_string, in_tag):\n         otherwise it should be treated as a literal string.\n         \"\"\"\n         if in_tag:\n+            # The [2:-2] ranges below strip off *_TAG_START and *_TAG_END.\n+            # We could do len(BLOCK_TAG_START) to be more \"correct\", but we've\n+            # hard-coded the 2s here for performance. And it's not like\n+            # the TAG_START values are going to change anytime, anyway.\n             if token_string.startswith(VARIABLE_TAG_START):\n-                token = Token(TOKEN_VAR,\n-                              token_string[\n-                                len(VARIABLE_TAG_START):-len(VARIABLE_TAG_END)\n-                              ].strip())\n+                token = Token(TOKEN_VAR, token_string[2:-2].strip())\n             elif token_string.startswith(BLOCK_TAG_START):\n-                token = Token(TOKEN_BLOCK,\n-                              token_string[\n-                                len(BLOCK_TAG_START):-len(BLOCK_TAG_END)\n-                              ].strip())\n+                token = Token(TOKEN_BLOCK, token_string[2:-2].strip())\n             elif token_string.startswith(COMMENT_TAG_START):\n                 content = ''\n                 if token_string.find(TRANSLATOR_COMMENT_MARK):\n-                    content = token_string[\n-                                len(COMMENT_TAG_START):-len(COMMENT_TAG_END)\n-                              ].strip()\n+                    content = token_string[2:-2].strip()\n                 token = Token(TOKEN_COMMENT, content)\n         else:\n             token = Token(TOKEN_TEXT, token_string)"
        }
    ],
    "stats": {
        "total": 18,
        "additions": 7,
        "deletions": 11
    }
}