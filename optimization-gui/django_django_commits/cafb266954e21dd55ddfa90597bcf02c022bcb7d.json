{
    "author": "akaariai",
    "message": "Fixed #17144 -- MySQL again groups by PK only\n\nThanks to Christian Oudard for the report and tests.",
    "sha": "cafb266954e21dd55ddfa90597bcf02c022bcb7d",
    "files": [
        {
            "sha": "f0a1611e9c4730a1fc69bddb886dc6a992345f97",
            "filename": "django/db/models/sql/compiler.py",
            "status": "modified",
            "additions": 35,
            "deletions": 31,
            "changes": 66,
            "blob_url": "https://github.com/django/django/blob/cafb266954e21dd55ddfa90597bcf02c022bcb7d/django%2Fdb%2Fmodels%2Fsql%2Fcompiler.py",
            "raw_url": "https://github.com/django/django/raw/cafb266954e21dd55ddfa90597bcf02c022bcb7d/django%2Fdb%2Fmodels%2Fsql%2Fcompiler.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fdb%2Fmodels%2Fsql%2Fcompiler.py?ref=cafb266954e21dd55ddfa90597bcf02c022bcb7d",
            "patch": "@@ -103,21 +103,12 @@ def as_sql(self, with_limits=True, with_col_aliases=False):\n             result.append('WHERE %s' % where)\n             params.extend(w_params)\n \n-        grouping, gb_params = self.get_grouping()\n+        grouping, gb_params = self.get_grouping(ordering_group_by)\n         if grouping:\n             if distinct_fields:\n                 raise NotImplementedError(\n                     \"annotate() + distinct(fields) not implemented.\")\n-            if ordering:\n-                # If the backend can't group by PK (i.e., any database\n-                # other than MySQL), then any fields mentioned in the\n-                # ordering clause needs to be in the group by clause.\n-                if not self.connection.features.allows_group_by_pk:\n-                    for col, col_params in ordering_group_by:\n-                        if col not in grouping:\n-                            grouping.append(str(col))\n-                            gb_params.extend(col_params)\n-            else:\n+            if not ordering:\n                 ordering = self.connection.ops.force_no_ordering()\n             result.append('GROUP BY %s' % ', '.join(grouping))\n             params.extend(gb_params)\n@@ -378,7 +369,7 @@ def get_ordering(self):\n                 else:\n                     order = asc\n                 result.append('%s %s' % (field, order))\n-                group_by.append((field, []))\n+                group_by.append((str(field), []))\n                 continue\n             col, order = get_order_dir(field, asc)\n             if col in self.query.aggregate_select:\n@@ -538,39 +529,52 @@ def get_from_clause(self):\n                 first = False\n         return result, []\n \n-    def get_grouping(self):\n+    def get_grouping(self, ordering_group_by):\n         \"\"\"\n         Returns a tuple representing the SQL elements in the \"group by\" clause.\n         \"\"\"\n         qn = self.quote_name_unless_alias\n         result, params = [], []\n         if self.query.group_by is not None:\n-            if (len(self.query.model._meta.fields) == len(self.query.select) and\n-                self.connection.features.allows_group_by_pk):\n+            select_cols = self.query.select + self.query.related_select_cols\n+            # Just the column, not the fields.\n+            select_cols = [s[0] for s in select_cols]\n+            if (len(self.query.model._meta.fields) == len(self.query.select)\n+                    and self.connection.features.allows_group_by_pk):\n                 self.query.group_by = [\n                     (self.query.model._meta.db_table, self.query.model._meta.pk.column)\n                 ]\n-\n-            group_by = self.query.group_by or []\n-\n-            extra_selects = []\n-            for extra_select, extra_params in six.itervalues(self.query.extra_select):\n-                extra_selects.append(extra_select)\n-                params.extend(extra_params)\n-            select_cols = [s.col for s in self.query.select]\n-            related_select_cols = [s.col for s in self.query.related_select_cols]\n-            cols = (group_by + select_cols + related_select_cols + extra_selects)\n+                select_cols = []\n             seen = set()\n+            cols = self.query.group_by + select_cols\n             for col in cols:\n-                if col in seen:\n-                    continue\n-                seen.add(col)\n                 if isinstance(col, (list, tuple)):\n-                    result.append('%s.%s' % (qn(col[0]), qn(col[1])))\n+                    sql = '%s.%s' % (qn(col[0]), qn(col[1]))\n                 elif hasattr(col, 'as_sql'):\n-                    result.append(col.as_sql(qn, self.connection))\n+                    sql = col.as_sql(qn, self.connection)\n                 else:\n-                    result.append('(%s)' % str(col))\n+                    sql = '(%s)' % str(col)\n+                if sql not in seen:\n+                    result.append(sql)\n+                    seen.add(sql)\n+\n+            # Still, we need to add all stuff in ordering (except if the backend can\n+            # group by just by PK).\n+            if ordering_group_by and not self.connection.features.allows_group_by_pk:\n+                for order, order_params in ordering_group_by:\n+                    # Even if we have seen the same SQL string, it might have\n+                    # different params, so, we add same SQL in \"has params\" case.\n+                    if order not in seen or params:\n+                        result.append(order)\n+                        params.extend(order_params)\n+                        seen.add(order)\n+\n+            # Unconditionally add the extra_select items.\n+            for extra_select, extra_params in self.query.extra_select.values():\n+                sql = '(%s)' % str(extra_select)\n+                result.append(sql)\n+                params.extend(extra_params)\n+\n         return result, params\n \n     def fill_related_selections(self, opts=None, root_alias=None, cur_depth=1,"
        },
        {
            "sha": "9b3cd41e41ecb4a13012fc12dbf86bcaf95dab97",
            "filename": "tests/regressiontests/aggregation_regress/tests.py",
            "status": "modified",
            "additions": 90,
            "deletions": 1,
            "changes": 91,
            "blob_url": "https://github.com/django/django/blob/cafb266954e21dd55ddfa90597bcf02c022bcb7d/tests%2Fregressiontests%2Faggregation_regress%2Ftests.py",
            "raw_url": "https://github.com/django/django/raw/cafb266954e21dd55ddfa90597bcf02c022bcb7d/tests%2Fregressiontests%2Faggregation_regress%2Ftests.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/tests%2Fregressiontests%2Faggregation_regress%2Ftests.py?ref=cafb266954e21dd55ddfa90597bcf02c022bcb7d",
            "patch": "@@ -470,7 +470,7 @@ def test_more_more(self):\n         # Regression for #15709 - Ensure each group_by field only exists once\n         # per query\n         qs = Book.objects.values('publisher').annotate(max_pages=Max('pages')).order_by()\n-        grouping, gb_params = qs.query.get_compiler(qs.db).get_grouping()\n+        grouping, gb_params = qs.query.get_compiler(qs.db).get_grouping([])\n         self.assertEqual(len(grouping), 1)\n \n     def test_duplicate_alias(self):\n@@ -889,3 +889,92 @@ def test_annotate_joins(self):\n         self.assertIs(qs.query.alias_map['aggregation_regress_book'].join_type, None)\n         # Check that the query executes without problems.\n         self.assertEqual(len(qs.exclude(publisher=-1)), 6)\n+\n+    @skipUnlessDBFeature(\"allows_group_by_pk\")\n+    def test_aggregate_duplicate_columns(self):\n+        # Regression test for #17144\n+\n+        results = Author.objects.annotate(num_contacts=Count('book_contact_set'))\n+\n+        # There should only be one GROUP BY clause, for the `id` column.\n+        # `name` and `age` should not be grouped on.\n+        grouping, gb_params = results.query.get_compiler(using='default').get_grouping([])\n+        self.assertEqual(len(grouping), 1)\n+        assert 'id' in grouping[0]\n+        assert 'name' not in grouping[0]\n+        assert 'age' not in grouping[0]\n+\n+        # The query group_by property should also only show the `id`.\n+        self.assertEqual(results.query.group_by, [('aggregation_regress_author', 'id')])\n+\n+        # Ensure that we get correct results.\n+        self.assertEqual(\n+            [(a.name, a.num_contacts) for a in results.order_by('name')],\n+            [\n+                ('Adrian Holovaty', 1),\n+                ('Brad Dayley', 1),\n+                ('Jacob Kaplan-Moss', 0),\n+                ('James Bennett', 1),\n+                ('Jeffrey Forcier', 1),\n+                ('Paul Bissex', 0),\n+                ('Peter Norvig', 2),\n+                ('Stuart Russell', 0),\n+                ('Wesley J. Chun', 0),\n+            ]\n+        )\n+\n+    @skipUnlessDBFeature(\"allows_group_by_pk\")\n+    def test_aggregate_duplicate_columns_only(self):\n+        # Works with only() too.\n+        results = Author.objects.only('id', 'name').annotate(num_contacts=Count('book_contact_set'))\n+        grouping, gb_params = results.query.get_compiler(using='default').get_grouping([])\n+        self.assertEqual(len(grouping), 1)\n+        assert 'id' in grouping[0]\n+        assert 'name' not in grouping[0]\n+        assert 'age' not in grouping[0]\n+\n+        # The query group_by property should also only show the `id`.\n+        self.assertEqual(results.query.group_by, [('aggregation_regress_author', 'id')])\n+\n+        # Ensure that we get correct results.\n+        self.assertEqual(\n+            [(a.name, a.num_contacts) for a in results.order_by('name')],\n+            [\n+                ('Adrian Holovaty', 1),\n+                ('Brad Dayley', 1),\n+                ('Jacob Kaplan-Moss', 0),\n+                ('James Bennett', 1),\n+                ('Jeffrey Forcier', 1),\n+                ('Paul Bissex', 0),\n+                ('Peter Norvig', 2),\n+                ('Stuart Russell', 0),\n+                ('Wesley J. Chun', 0),\n+            ]\n+        )\n+\n+    @skipUnlessDBFeature(\"allows_group_by_pk\")\n+    def test_aggregate_duplicate_columns_select_related(self):\n+        # And select_related()\n+        results = Book.objects.select_related('contact').annotate(\n+            num_authors=Count('authors'))\n+        grouping, gb_params = results.query.get_compiler(using='default').get_grouping([])\n+        self.assertEqual(len(grouping), 1)\n+        assert 'id' in grouping[0]\n+        assert 'name' not in grouping[0]\n+        assert 'contact' not in grouping[0]\n+\n+        # The query group_by property should also only show the `id`.\n+        self.assertEqual(results.query.group_by, [('aggregation_regress_book', 'id')])\n+\n+        # Ensure that we get correct results.\n+        self.assertEqual(\n+            [(b.name, b.num_authors) for b in results.order_by('name')],\n+            [\n+                ('Artificial Intelligence: A Modern Approach', 2),\n+                ('Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp', 1),\n+                ('Practical Django Projects', 1),\n+                ('Python Web Development with Django', 3),\n+                ('Sams Teach Yourself Django in 24 Hours', 1),\n+                ('The Definitive Guide to Django: Web Development Done Right', 2)\n+            ]\n+        )"
        }
    ],
    "stats": {
        "total": 157,
        "additions": 125,
        "deletions": 32
    }
}