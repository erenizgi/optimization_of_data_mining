{
    "author": "aaugustin",
    "message": "Fixed #17728 -- When filtering an annotation, ensured the values used in the filter are properly converted to their database representation. This bug was particularly visible with timezone-aware DateTimeFields. Thanks gg for the report and Carl for the review.\n\n\ngit-svn-id: http://code.djangoproject.com/svn/django/trunk@17576 bcc190cf-cafb-0310-a4f2-bffc1f526a37",
    "sha": "8b5361619818a8e16562d054d7dc8ddf61147384",
    "files": [
        {
            "sha": "b41314a686e69446c6ee0bcc550ac7751ebe4671",
            "filename": "django/db/models/sql/aggregates.py",
            "status": "modified",
            "additions": 4,
            "deletions": 11,
            "changes": 15,
            "blob_url": "https://github.com/django/django/blob/8b5361619818a8e16562d054d7dc8ddf61147384/django%2Fdb%2Fmodels%2Fsql%2Faggregates.py",
            "raw_url": "https://github.com/django/django/raw/8b5361619818a8e16562d054d7dc8ddf61147384/django%2Fdb%2Fmodels%2Fsql%2Faggregates.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fdb%2Fmodels%2Fsql%2Faggregates.py?ref=8b5361619818a8e16562d054d7dc8ddf61147384",
            "patch": "@@ -2,18 +2,11 @@\n Classes to represent the default SQL aggregate functions\n \"\"\"\n \n-class AggregateField(object):\n-    \"\"\"An internal field mockup used to identify aggregates in the\n-    data-conversion parts of the database backend.\n-    \"\"\"\n-    def __init__(self, internal_type):\n-        self.internal_type = internal_type\n-\n-    def get_internal_type(self):\n-        return self.internal_type\n+from django.db.models.fields import IntegerField, FloatField\n \n-ordinal_aggregate_field = AggregateField('IntegerField')\n-computed_aggregate_field = AggregateField('FloatField')\n+# Fake fields used to identify aggregate types in data-conversion operations.\n+ordinal_aggregate_field = IntegerField()\n+computed_aggregate_field = FloatField()\n \n class Aggregate(object):\n     \"\"\""
        },
        {
            "sha": "2bd705dd608023ee9004078e350791d9114481eb",
            "filename": "django/db/models/sql/where.py",
            "status": "modified",
            "additions": 24,
            "deletions": 22,
            "changes": 46,
            "blob_url": "https://github.com/django/django/blob/8b5361619818a8e16562d054d7dc8ddf61147384/django%2Fdb%2Fmodels%2Fsql%2Fwhere.py",
            "raw_url": "https://github.com/django/django/raw/8b5361619818a8e16562d054d7dc8ddf61147384/django%2Fdb%2Fmodels%2Fsql%2Fwhere.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fdb%2Fmodels%2Fsql%2Fwhere.py?ref=8b5361619818a8e16562d054d7dc8ddf61147384",
            "patch": "@@ -10,6 +10,7 @@\n from django.utils import tree\n from django.db.models.fields import Field\n from django.db.models.sql.datastructures import EmptyResultSet, FullResultSet\n+from django.db.models.sql.aggregates import Aggregate\n \n # Connection types\n AND = 'AND'\n@@ -30,9 +31,8 @@ class WhereNode(tree.Node):\n     the correct SQL).\n \n     The children in this tree are usually either Q-like objects or lists of\n-    [table_alias, field_name, db_type, lookup_type, value_annotation,\n-    params]. However, a child could also be any class with as_sql() and\n-    relabel_aliases() methods.\n+    [table_alias, field_name, db_type, lookup_type, value_annotation, params].\n+    However, a child could also be any class with as_sql() and relabel_aliases() methods.\n     \"\"\"\n     default = AND\n \n@@ -54,25 +54,22 @@ def add(self, data, connector):\n             # emptiness and transform any non-empty values correctly.\n             value = list(value)\n \n-        # The \"annotation\" parameter is used to pass auxilliary information\n+        # The \"value_annotation\" parameter is used to pass auxilliary information\n         # about the value(s) to the query construction. Specifically, datetime\n         # and empty values need special handling. Other types could be used\n         # here in the future (using Python types is suggested for consistency).\n         if isinstance(value, datetime.datetime):\n-            annotation = datetime.datetime\n+            value_annotation = datetime.datetime\n         elif hasattr(value, 'value_annotation'):\n-            annotation = value.value_annotation\n+            value_annotation = value.value_annotation\n         else:\n-            annotation = bool(value)\n+            value_annotation = bool(value)\n \n         if hasattr(obj, \"prepare\"):\n             value = obj.prepare(lookup_type, value)\n-            super(WhereNode, self).add((obj, lookup_type, annotation, value),\n-                connector)\n-            return\n \n-        super(WhereNode, self).add((obj, lookup_type, annotation, value),\n-                connector)\n+        super(WhereNode, self).add(\n+                (obj, lookup_type, value_annotation, value), connector)\n \n     def as_sql(self, qn, connection):\n         \"\"\"\n@@ -132,29 +129,34 @@ def as_sql(self, qn, connection):\n \n     def make_atom(self, child, qn, connection):\n         \"\"\"\n-        Turn a tuple (table_alias, column_name, db_type, lookup_type,\n-        value_annot, params) into valid SQL.\n+        Turn a tuple (Constraint(table_alias, column_name, db_type),\n+        lookup_type, value_annotation, params) into valid SQL.\n+\n+        The first item of the tuple may also be an Aggregate.\n \n         Returns the string for the SQL fragment and the parameters to use for\n         it.\n         \"\"\"\n-        lvalue, lookup_type, value_annot, params_or_value = child\n-        if hasattr(lvalue, 'process'):\n+        lvalue, lookup_type, value_annotation, params_or_value = child\n+        if isinstance(lvalue, Constraint):\n             try:\n                 lvalue, params = lvalue.process(lookup_type, params_or_value, connection)\n             except EmptyShortCircuit:\n                 raise EmptyResultSet\n+        elif isinstance(lvalue, Aggregate):\n+            params = lvalue.field.get_db_prep_lookup(lookup_type, params_or_value, connection)\n         else:\n-            params = Field().get_db_prep_lookup(lookup_type, params_or_value,\n-                connection=connection, prepared=True)\n+            raise TypeError(\"'make_atom' expects a Constraint or an Aggregate \"\n+                            \"as the first item of its 'child' argument.\")\n+\n         if isinstance(lvalue, tuple):\n             # A direct database column lookup.\n             field_sql = self.sql_for_columns(lvalue, qn, connection)\n         else:\n             # A smart object with an as_sql() method.\n             field_sql = lvalue.as_sql(qn, connection)\n \n-        if value_annot is datetime.datetime:\n+        if value_annotation is datetime.datetime:\n             cast_sql = connection.ops.datetime_cast_sql()\n         else:\n             cast_sql = '%s'\n@@ -168,7 +170,7 @@ def make_atom(self, child, qn, connection):\n         if (len(params) == 1 and params[0] == '' and lookup_type == 'exact'\n             and connection.features.interprets_empty_strings_as_nulls):\n             lookup_type = 'isnull'\n-            value_annot = True\n+            value_annotation = True\n \n         if lookup_type in connection.operators:\n             format = \"%s %%s %%s\" % (connection.ops.lookup_cast(lookup_type),)\n@@ -177,7 +179,7 @@ def make_atom(self, child, qn, connection):\n                               extra), params)\n \n         if lookup_type == 'in':\n-            if not value_annot:\n+            if not value_annotation:\n                 raise EmptyResultSet\n             if extra:\n                 return ('%s IN %s' % (field_sql, extra), params)\n@@ -206,7 +208,7 @@ def make_atom(self, child, qn, connection):\n                     params)\n         elif lookup_type == 'isnull':\n             return ('%s IS %sNULL' % (field_sql,\n-                (not value_annot and 'NOT ' or '')), ())\n+                (not value_annotation and 'NOT ' or '')), ())\n         elif lookup_type == 'search':\n             return (connection.ops.fulltext_search_sql(field_sql), params)\n         elif lookup_type in ('regex', 'iregex'):"
        },
        {
            "sha": "f0cc79275d13c2341cf8b35de1506b6ae2ea4847",
            "filename": "tests/modeltests/timezones/models.py",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/django/django/blob/8b5361619818a8e16562d054d7dc8ddf61147384/tests%2Fmodeltests%2Ftimezones%2Fmodels.py",
            "raw_url": "https://github.com/django/django/raw/8b5361619818a8e16562d054d7dc8ddf61147384/tests%2Fmodeltests%2Ftimezones%2Fmodels.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/tests%2Fmodeltests%2Ftimezones%2Fmodels.py?ref=8b5361619818a8e16562d054d7dc8ddf61147384",
            "patch": "@@ -6,6 +6,13 @@ class Event(models.Model):\n class MaybeEvent(models.Model):\n     dt = models.DateTimeField(blank=True, null=True)\n \n+class Session(models.Model):\n+    name = models.CharField(max_length=20)\n+\n+class SessionEvent(models.Model):\n+    dt = models.DateTimeField()\n+    session = models.ForeignKey(Session, related_name='events')\n+\n class Timestamp(models.Model):\n     created = models.DateTimeField(auto_now_add=True)\n     updated = models.DateTimeField(auto_now=True)"
        },
        {
            "sha": "818405971c7e07d8d9c4e7355afe4c567ef96736",
            "filename": "tests/modeltests/timezones/tests.py",
            "status": "modified",
            "additions": 45,
            "deletions": 1,
            "changes": 46,
            "blob_url": "https://github.com/django/django/blob/8b5361619818a8e16562d054d7dc8ddf61147384/tests%2Fmodeltests%2Ftimezones%2Ftests.py",
            "raw_url": "https://github.com/django/django/raw/8b5361619818a8e16562d054d7dc8ddf61147384/tests%2Fmodeltests%2Ftimezones%2Ftests.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/tests%2Fmodeltests%2Ftimezones%2Ftests.py?ref=8b5361619818a8e16562d054d7dc8ddf61147384",
            "patch": "@@ -25,7 +25,7 @@\n from django.utils.unittest import skipIf, skipUnless\n \n from .forms import EventForm, EventSplitForm, EventModelForm\n-from .models import Event, MaybeEvent, Timestamp\n+from .models import Event, MaybeEvent, Session, SessionEvent, Timestamp\n \n \n # These tests use the EAT (Eastern Africa Time) and ICT (Indochina Time)\n@@ -231,6 +231,28 @@ def test_query_aggregation(self):\n             'dt__max': datetime.datetime(2011, 9, 1, 23, 20, 20),\n         })\n \n+    def test_query_annotation(self):\n+        # Only min and max make sense for datetimes.\n+        morning = Session.objects.create(name='morning')\n+        afternoon = Session.objects.create(name='afternoon')\n+        SessionEvent.objects.create(dt=datetime.datetime(2011, 9, 1, 23, 20, 20), session=afternoon)\n+        SessionEvent.objects.create(dt=datetime.datetime(2011, 9, 1, 13, 20, 30), session=afternoon)\n+        SessionEvent.objects.create(dt=datetime.datetime(2011, 9, 1, 3, 20, 40), session=morning)\n+        morning_min_dt = datetime.datetime(2011, 9, 1, 3, 20, 40)\n+        afternoon_min_dt = datetime.datetime(2011, 9, 1, 13, 20, 30)\n+        self.assertQuerysetEqual(\n+                Session.objects.annotate(dt=Min('events__dt')).order_by('dt'),\n+                [morning_min_dt, afternoon_min_dt],\n+                transform=lambda d: d.dt)\n+        self.assertQuerysetEqual(\n+                Session.objects.annotate(dt=Min('events__dt')).filter(dt__lt=afternoon_min_dt),\n+                [morning_min_dt],\n+                transform=lambda d: d.dt)\n+        self.assertQuerysetEqual(\n+                Session.objects.annotate(dt=Min('events__dt')).filter(dt__gte=afternoon_min_dt),\n+                [afternoon_min_dt],\n+                transform=lambda d: d.dt)\n+\n     def test_query_dates(self):\n         Event.objects.create(dt=datetime.datetime(2011, 1, 1, 1, 30, 0))\n         Event.objects.create(dt=datetime.datetime(2011, 1, 1, 4, 30, 0))\n@@ -412,6 +434,28 @@ def test_query_aggregation(self):\n             'dt__max': datetime.datetime(2011, 9, 1, 23, 20, 20, tzinfo=EAT),\n         })\n \n+    def test_query_annotation(self):\n+        # Only min and max make sense for datetimes.\n+        morning = Session.objects.create(name='morning')\n+        afternoon = Session.objects.create(name='afternoon')\n+        SessionEvent.objects.create(dt=datetime.datetime(2011, 9, 1, 23, 20, 20, tzinfo=EAT), session=afternoon)\n+        SessionEvent.objects.create(dt=datetime.datetime(2011, 9, 1, 13, 20, 30, tzinfo=EAT), session=afternoon)\n+        SessionEvent.objects.create(dt=datetime.datetime(2011, 9, 1, 3, 20, 40, tzinfo=EAT), session=morning)\n+        morning_min_dt = datetime.datetime(2011, 9, 1, 3, 20, 40, tzinfo=EAT)\n+        afternoon_min_dt = datetime.datetime(2011, 9, 1, 13, 20, 30, tzinfo=EAT)\n+        self.assertQuerysetEqual(\n+                Session.objects.annotate(dt=Min('events__dt')).order_by('dt'),\n+                [morning_min_dt, afternoon_min_dt],\n+                transform=lambda d: d.dt)\n+        self.assertQuerysetEqual(\n+                Session.objects.annotate(dt=Min('events__dt')).filter(dt__lt=afternoon_min_dt),\n+                [morning_min_dt],\n+                transform=lambda d: d.dt)\n+        self.assertQuerysetEqual(\n+                Session.objects.annotate(dt=Min('events__dt')).filter(dt__gte=afternoon_min_dt),\n+                [afternoon_min_dt],\n+                transform=lambda d: d.dt)\n+\n     def test_query_dates(self):\n         # Same comment as in test_query_date_related_filters.\n         Event.objects.create(dt=datetime.datetime(2011, 1, 1, 1, 30, 0, tzinfo=EAT))"
        }
    ],
    "stats": {
        "total": 114,
        "additions": 80,
        "deletions": 34
    }
}