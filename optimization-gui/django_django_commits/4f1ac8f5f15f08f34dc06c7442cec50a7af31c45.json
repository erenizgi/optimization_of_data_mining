{
    "author": "jezdez",
    "message": "Minor bugfixing of the staticfiles app following upstream development in django-staticfiles.\n\n- Create the files to ignore during the tests dynamically (.hidden and backup~)\n- Refactored the post_processing method of the CachedFilesMixin storage mixin to be less time consuming.\n- Refactored handling of fragments in the post_process method.\n\ngit-svn-id: http://code.djangoproject.com/svn/django/trunk@17519 bcc190cf-cafb-0310-a4f2-bffc1f526a37",
    "sha": "4f1ac8f5f15f08f34dc06c7442cec50a7af31c45",
    "files": [
        {
            "sha": "2155e37ea6c42f41fe68ce8778d71452f32b5c6d",
            "filename": "django/contrib/staticfiles/management/commands/collectstatic.py",
            "status": "modified",
            "additions": 70,
            "deletions": 44,
            "changes": 114,
            "blob_url": "https://github.com/django/django/blob/4f1ac8f5f15f08f34dc06c7442cec50a7af31c45/django%2Fcontrib%2Fstaticfiles%2Fmanagement%2Fcommands%2Fcollectstatic.py",
            "raw_url": "https://github.com/django/django/raw/4f1ac8f5f15f08f34dc06c7442cec50a7af31c45/django%2Fcontrib%2Fstaticfiles%2Fmanagement%2Fcommands%2Fcollectstatic.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fcontrib%2Fstaticfiles%2Fmanagement%2Fcommands%2Fcollectstatic.py?ref=4f1ac8f5f15f08f34dc06c7442cec50a7af31c45",
            "patch": "@@ -7,13 +7,14 @@\n from django.core.files.storage import FileSystemStorage\n from django.core.management.base import CommandError, NoArgsCommand\n from django.utils.encoding import smart_str, smart_unicode\n+from django.utils.datastructures import SortedDict\n \n from django.contrib.staticfiles import finders, storage\n \n \n class Command(NoArgsCommand):\n     \"\"\"\n-    Command that allows to copy or symlink media files from different\n+    Command that allows to copy or symlink static files from different\n     locations to the settings.STATIC_ROOT.\n     \"\"\"\n     option_list = NoArgsCommand.option_list + (\n@@ -50,6 +51,7 @@ def __init__(self, *args, **kwargs):\n         self.copied_files = []\n         self.symlinked_files = []\n         self.unmodified_files = []\n+        self.post_processed_files = []\n         self.storage = storage.staticfiles_storage\n         try:\n             self.storage.path('')\n@@ -61,25 +63,74 @@ def __init__(self, *args, **kwargs):\n         if hasattr(os, 'stat_float_times'):\n             os.stat_float_times(False)\n \n-    def handle_noargs(self, **options):\n+    def set_options(self, **options):\n+        \"\"\"\n+        Set instance variables based on an options dict\n+        \"\"\"\n+        self.interactive = options['interactive']\n+        self.verbosity = int(options.get('verbosity', 1))\n+        self.symlink = options['link']\n         self.clear = options['clear']\n         self.dry_run = options['dry_run']\n         ignore_patterns = options['ignore_patterns']\n         if options['use_default_ignore_patterns']:\n             ignore_patterns += ['CVS', '.*', '*~']\n         self.ignore_patterns = list(set(ignore_patterns))\n-        self.interactive = options['interactive']\n-        self.symlink = options['link']\n-        self.verbosity = int(options.get('verbosity', 1))\n         self.post_process = options['post_process']\n \n+    def collect(self):\n+        \"\"\"\n+        Perform the bulk of the work of collectstatic.\n+\n+        Split off from handle_noargs() to facilitate testing.\n+        \"\"\"\n         if self.symlink:\n             if sys.platform == 'win32':\n                 raise CommandError(\"Symlinking is not supported by this \"\n                                    \"platform (%s).\" % sys.platform)\n             if not self.local:\n                 raise CommandError(\"Can't symlink to a remote destination.\")\n \n+        if self.clear:\n+            self.clear_dir('')\n+\n+        if self.symlink:\n+            handler = self.link_file\n+        else:\n+            handler = self.copy_file\n+\n+        found_files = SortedDict()\n+        for finder in finders.get_finders():\n+            for path, storage in finder.list(self.ignore_patterns):\n+                # Prefix the relative path if the source storage contains it\n+                if getattr(storage, 'prefix', None):\n+                    prefixed_path = os.path.join(storage.prefix, path)\n+                else:\n+                    prefixed_path = path\n+                found_files[prefixed_path] = storage.open(path)\n+                handler(path, prefixed_path, storage)\n+\n+        # Here we check if the storage backend has a post_process\n+        # method and pass it the list of modified files.\n+        if self.post_process and hasattr(self.storage, 'post_process'):\n+            processor = self.storage.post_process(found_files,\n+                                                  dry_run=self.dry_run)\n+            for original_path, processed_path, processed in processor:\n+                if processed:\n+                    self.log(u\"Post-processed '%s' as '%s\" %\n+                             (original_path, processed_path), level=1)\n+                    self.post_processed_files.append(original_path)\n+                else:\n+                    self.log(u\"Skipped post-processing '%s'\" % original_path)\n+\n+        return {\n+            'modified': self.copied_files + self.symlinked_files,\n+            'unmodified': self.unmodified_files,\n+            'post_processed': self.post_processed_files,\n+        }\n+\n+    def handle_noargs(self, **options):\n+        self.set_options(**options)\n         # Warn before doing anything more.\n         if (isinstance(self.storage, FileSystemStorage) and\n                 self.storage.location):\n@@ -107,49 +158,25 @@ def handle_noargs(self, **options):\n             if confirm != 'yes':\n                 raise CommandError(\"Collecting static files cancelled.\")\n \n-        if self.clear:\n-            self.clear_dir('')\n-\n-        handler = {\n-            True: self.link_file,\n-            False: self.copy_file,\n-        }[self.symlink]\n-\n-        found_files = []\n-        for finder in finders.get_finders():\n-            for path, storage in finder.list(self.ignore_patterns):\n-                # Prefix the relative path if the source storage contains it\n-                if getattr(storage, 'prefix', None):\n-                    prefixed_path = os.path.join(storage.prefix, path)\n-                else:\n-                    prefixed_path = path\n-                found_files.append(prefixed_path)\n-                handler(path, prefixed_path, storage)\n-\n-        # Here we check if the storage backend has a post_process\n-        # method and pass it the list of modified files.\n-        if self.post_process and hasattr(self.storage, 'post_process'):\n-            post_processed = self.storage.post_process(found_files, **options)\n-            for path in post_processed:\n-                self.log(u\"Post-processed '%s'\" % path, level=1)\n-        else:\n-            post_processed = []\n-\n-        modified_files = self.copied_files + self.symlinked_files\n-        actual_count = len(modified_files)\n-        unmodified_count = len(self.unmodified_files)\n+        collected = self.collect()\n+        modified_count = len(collected['modified'])\n+        unmodified_count = len(collected['unmodified'])\n+        post_processed_count = len(collected['post_processed'])\n \n         if self.verbosity >= 1:\n-            template = (\"\\n%(actual_count)s %(identifier)s %(action)s\"\n-                        \"%(destination)s%(unmodified)s.\\n\")\n+            template = (\"\\n%(modified_count)s %(identifier)s %(action)s\"\n+                        \"%(destination)s%(unmodified)s%(post_processed)s.\\n\")\n             summary = template % {\n-                'actual_count': actual_count,\n-                'identifier': 'static file' + (actual_count > 1 and 's' or ''),\n+                'modified_count': modified_count,\n+                'identifier': 'static file' + (modified_count != 1 and 's' or ''),\n                 'action': self.symlink and 'symlinked' or 'copied',\n                 'destination': (destination_path and \" to '%s'\"\n                                 % destination_path or ''),\n-                'unmodified': (self.unmodified_files and ', %s unmodified'\n+                'unmodified': (collected['unmodified'] and ', %s unmodified'\n                                % unmodified_count or ''),\n+                'post_processed': (collected['post_processed'] and\n+                                   ', %s post-processed'\n+                                   % post_processed_count or ''),\n             }\n             self.stdout.write(smart_str(summary))\n \n@@ -180,21 +207,20 @@ def clear_dir(self, path):\n             self.clear_dir(os.path.join(path, d))\n \n     def delete_file(self, path, prefixed_path, source_storage):\n-        # Whether we are in symlink mode\n         # Checks if the target file should be deleted if it already exists\n         if self.storage.exists(prefixed_path):\n             try:\n                 # When was the target file modified last time?\n                 target_last_modified = \\\n                     self.storage.modified_time(prefixed_path)\n-            except (OSError, NotImplementedError):\n+            except (OSError, NotImplementedError, AttributeError):\n                 # The storage doesn't support ``modified_time`` or failed\n                 pass\n             else:\n                 try:\n                     # When was the source file modified last time?\n                     source_last_modified = source_storage.modified_time(path)\n-                except (OSError, NotImplementedError):\n+                except (OSError, NotImplementedError, AttributeError):\n                     pass\n                 else:\n                     # The full path of the target file"
        },
        {
            "sha": "b0f28d4063cf42bffbaecfd2939003417f42e255",
            "filename": "django/contrib/staticfiles/storage.py",
            "status": "modified",
            "additions": 70,
            "deletions": 31,
            "changes": 101,
            "blob_url": "https://github.com/django/django/blob/4f1ac8f5f15f08f34dc06c7442cec50a7af31c45/django%2Fcontrib%2Fstaticfiles%2Fstorage.py",
            "raw_url": "https://github.com/django/django/raw/4f1ac8f5f15f08f34dc06c7442cec50a7af31c45/django%2Fcontrib%2Fstaticfiles%2Fstorage.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/django%2Fcontrib%2Fstaticfiles%2Fstorage.py?ref=4f1ac8f5f15f08f34dc06c7442cec50a7af31c45",
            "patch": "@@ -4,18 +4,18 @@\n import posixpath\n import re\n from urllib import unquote\n-from urlparse import urlsplit, urlunsplit\n+from urlparse import urlsplit, urlunsplit, urldefrag\n \n from django.conf import settings\n from django.core.cache import (get_cache, InvalidCacheBackendError,\n                                cache as default_cache)\n from django.core.exceptions import ImproperlyConfigured\n from django.core.files.base import ContentFile\n from django.core.files.storage import FileSystemStorage, get_storage_class\n+from django.utils.datastructures import SortedDict\n from django.utils.encoding import force_unicode, smart_str\n from django.utils.functional import LazyObject\n from django.utils.importlib import import_module\n-from django.utils.datastructures import SortedDict\n \n from django.contrib.staticfiles.utils import check_settings, matches_patterns\n \n@@ -75,7 +75,7 @@ def hashed_name(self, name, content=None):\n             try:\n                 content = self.open(clean_name)\n             except IOError:\n-                # Handle directory paths\n+                # Handle directory paths and fragments\n                 return name\n         path, filename = os.path.split(clean_name)\n         root, ext = os.path.splitext(filename)\n@@ -102,16 +102,31 @@ def url(self, name, force=False):\n         Returns the real URL in DEBUG mode.\n         \"\"\"\n         if settings.DEBUG and not force:\n-            hashed_name = name\n+            hashed_name, fragment = name, ''\n         else:\n+            clean_name, fragment = urldefrag(name)\n             cache_key = self.cache_key(name)\n             hashed_name = self.cache.get(cache_key)\n             if hashed_name is None:\n-                hashed_name = self.hashed_name(name).replace('\\\\', '/')\n+                hashed_name = self.hashed_name(clean_name).replace('\\\\', '/')\n                 # set the cache if there was a miss\n                 # (e.g. if cache server goes down)\n                 self.cache.set(cache_key, hashed_name)\n-        return unquote(super(CachedFilesMixin, self).url(hashed_name))\n+\n+        final_url = super(CachedFilesMixin, self).url(hashed_name)\n+\n+        # Special casing for a @font-face hack, like url(myfont.eot?#iefix\")\n+        # http://www.fontspring.com/blog/the-new-bulletproof-font-face-syntax\n+        query_fragment = '?#' in name  # [sic!]\n+        if fragment or query_fragment:\n+            urlparts = list(urlsplit(final_url))\n+            if fragment and not urlparts[4]:\n+                urlparts[4] = fragment\n+            if query_fragment and not urlparts[3]:\n+                urlparts[2] += '?'\n+            final_url = urlunsplit(urlparts)\n+\n+        return unquote(final_url)\n \n     def url_converter(self, name):\n         \"\"\"\n@@ -124,8 +139,9 @@ def converter(matchobj):\n             of the storage.\n             \"\"\"\n             matched, url = matchobj.groups()\n-            # Completely ignore http(s) prefixed URLs\n-            if url.startswith(('#', 'http', 'https', 'data:')):\n+            # Completely ignore http(s) prefixed URLs,\n+            # fragments and data-uri URLs\n+            if url.startswith(('#', 'http:', 'https:', 'data:')):\n                 return matched\n             name_parts = name.split(os.sep)\n             # Using posix normpath here to remove duplicates\n@@ -146,57 +162,80 @@ def converter(matchobj):\n                     start, end = 1, sub_level - 1\n             joined_result = '/'.join(name_parts[:-start] + url_parts[end:])\n             hashed_url = self.url(unquote(joined_result), force=True)\n+\n             # Return the hashed and normalized version to the file\n             return 'url(\"%s\")' % unquote(hashed_url)\n         return converter\n \n     def post_process(self, paths, dry_run=False, **options):\n         \"\"\"\n         Post process the given list of files (called from collectstatic).\n+\n+        Processing is actually two separate operations:\n+\n+        1. renaming files to include a hash of their content for cache-busting,\n+           and copying those files to the target storage.\n+        2. adjusting files which contain references to other files so they\n+           refer to the cache-busting filenames.\n+\n+        If either of these are performed on a file, then that file is considered\n+        post-processed.\n         \"\"\"\n-        processed_files = []\n         # don't even dare to process the files if we're in dry run mode\n         if dry_run:\n-            return processed_files\n+            return\n \n         # delete cache of all handled paths\n         self.cache.delete_many([self.cache_key(path) for path in paths])\n \n-        # only try processing the files we have patterns for\n+        # build a list of adjustable files\n         matches = lambda path: matches_patterns(path, self._patterns.keys())\n-        processing_paths = [path for path in paths if matches(path)]\n+        adjustable_paths = [path for path in paths if matches(path)]\n \n         # then sort the files by the directory level\n         path_level = lambda name: len(name.split(os.sep))\n-        for name in sorted(paths, key=path_level, reverse=True):\n+        for name in sorted(paths.keys(), key=path_level, reverse=True):\n+\n+            # use the original, local file, not the copied-but-unprocessed\n+            # file, which might be somewhere far away, like S3\n+            with paths[name] as original_file:\n+\n+                # generate the hash with the original content, even for\n+                # adjustable files.\n+                hashed_name = self.hashed_name(name, original_file)\n \n-            # first get a hashed name for the given file\n-            hashed_name = self.hashed_name(name)\n+                # then get the original's file content..\n+                if hasattr(original_file, 'seek'):\n+                    original_file.seek(0)\n \n-            with self.open(name) as original_file:\n-                # then get the original's file content\n-                content = original_file.read()\n+                hashed_file_exists = self.exists(hashed_name)\n+                processed = False\n \n-                # to apply each replacement pattern on the content\n-                if name in processing_paths:\n+                # ..to apply each replacement pattern to the content\n+                if name in adjustable_paths:\n+                    content = original_file.read()\n                     converter = self.url_converter(name)\n                     for patterns in self._patterns.values():\n                         for pattern in patterns:\n                             content = pattern.sub(converter, content)\n-\n-                # then save the processed result\n-                if self.exists(hashed_name):\n-                    self.delete(hashed_name)\n-\n-                content_file = ContentFile(smart_str(content))\n-                saved_name = self._save(hashed_name, content_file)\n-                hashed_name = force_unicode(saved_name.replace('\\\\', '/'))\n-                processed_files.append(hashed_name)\n+                    if hashed_file_exists:\n+                        self.delete(hashed_name)\n+                    # then save the processed result\n+                    content_file = ContentFile(smart_str(content))\n+                    saved_name = self._save(hashed_name, content_file)\n+                    hashed_name = force_unicode(saved_name.replace('\\\\', '/'))\n+                    processed = True\n+                else:\n+                    # or handle the case in which neither processing nor\n+                    # a change to the original file happened\n+                    if not hashed_file_exists:\n+                        processed = True\n+                        saved_name = self._save(hashed_name, original_file)\n+                        hashed_name = force_unicode(saved_name.replace('\\\\', '/'))\n \n                 # and then set the cache accordingly\n                 self.cache.set(self.cache_key(name), hashed_name)\n-\n-        return processed_files\n+                yield name, hashed_name, processed\n \n \n class CachedStaticFilesStorage(CachedFilesMixin, StaticFilesStorage):"
        },
        {
            "sha": "cef6c23575aa0c0d3190fd54c1250b166689740f",
            "filename": "tests/regressiontests/staticfiles_tests/apps/test/static/test/.hidden",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/django/django/blob/2df1847c9b59b183bb3331fb19a7f76c72358edf/tests%2Fregressiontests%2Fstaticfiles_tests%2Fapps%2Ftest%2Fstatic%2Ftest%2F.hidden",
            "raw_url": "https://github.com/django/django/raw/2df1847c9b59b183bb3331fb19a7f76c72358edf/tests%2Fregressiontests%2Fstaticfiles_tests%2Fapps%2Ftest%2Fstatic%2Ftest%2F.hidden",
            "contents_url": "https://api.github.com/repos/django/django/contents/tests%2Fregressiontests%2Fstaticfiles_tests%2Fapps%2Ftest%2Fstatic%2Ftest%2F.hidden?ref=2df1847c9b59b183bb3331fb19a7f76c72358edf",
            "patch": "@@ -1 +0,0 @@\n-This file should be ignored."
        },
        {
            "sha": "cef6c23575aa0c0d3190fd54c1250b166689740f",
            "filename": "tests/regressiontests/staticfiles_tests/apps/test/static/test/backup~",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/django/django/blob/2df1847c9b59b183bb3331fb19a7f76c72358edf/tests%2Fregressiontests%2Fstaticfiles_tests%2Fapps%2Ftest%2Fstatic%2Ftest%2Fbackup%7E",
            "raw_url": "https://github.com/django/django/raw/2df1847c9b59b183bb3331fb19a7f76c72358edf/tests%2Fregressiontests%2Fstaticfiles_tests%2Fapps%2Ftest%2Fstatic%2Ftest%2Fbackup%7E",
            "contents_url": "https://api.github.com/repos/django/django/contents/tests%2Fregressiontests%2Fstaticfiles_tests%2Fapps%2Ftest%2Fstatic%2Ftest%2Fbackup%7E?ref=2df1847c9b59b183bb3331fb19a7f76c72358edf",
            "patch": "@@ -1 +0,0 @@\n-This file should be ignored."
        },
        {
            "sha": "680027b63c1ec2530a586f894700faab11a01855",
            "filename": "tests/regressiontests/staticfiles_tests/tests.py",
            "status": "modified",
            "additions": 49,
            "deletions": 10,
            "changes": 59,
            "blob_url": "https://github.com/django/django/blob/4f1ac8f5f15f08f34dc06c7442cec50a7af31c45/tests%2Fregressiontests%2Fstaticfiles_tests%2Ftests.py",
            "raw_url": "https://github.com/django/django/raw/4f1ac8f5f15f08f34dc06c7442cec50a7af31c45/tests%2Fregressiontests%2Fstaticfiles_tests%2Ftests.py",
            "contents_url": "https://api.github.com/repos/django/django/contents/tests%2Fregressiontests%2Fstaticfiles_tests%2Ftests.py?ref=4f1ac8f5f15f08f34dc06c7442cec50a7af31c45",
            "patch": "@@ -39,6 +39,7 @@\n         'django.contrib.staticfiles.finders.DefaultStorageFinder',\n     ),\n }\n+from django.contrib.staticfiles.management.commands.collectstatic import Command as CollectstaticCommand\n \n \n class BaseStaticFilesTestCase(object):\n@@ -52,13 +53,26 @@ def setUp(self):\n         default_storage._wrapped = empty\n         storage.staticfiles_storage._wrapped = empty\n \n+        testfiles_path = os.path.join(TEST_ROOT, 'apps', 'test', 'static', 'test')\n         # To make sure SVN doesn't hangs itself with the non-ASCII characters\n         # during checkout, we actually create one file dynamically.\n-        _nonascii_filepath = os.path.join(\n-            TEST_ROOT, 'apps', 'test', 'static', 'test', u'fi\\u015fier.txt')\n-        with codecs.open(_nonascii_filepath, 'w', 'utf-8') as f:\n+        self._nonascii_filepath = os.path.join(testfiles_path, u'fi\\u015fier.txt')\n+        with codecs.open(self._nonascii_filepath, 'w', 'utf-8') as f:\n             f.write(u\"fi\\u015fier in the app dir\")\n-        self.addCleanup(os.unlink, _nonascii_filepath)\n+        # And also create the stupid hidden file to dwarf the setup.py's\n+        # package data handling.\n+        self._hidden_filepath = os.path.join(testfiles_path, '.hidden')\n+        with codecs.open(self._hidden_filepath, 'w', 'utf-8') as f:\n+            f.write(\"should be ignored\")\n+        self._backup_filepath = os.path.join(\n+            TEST_ROOT, 'project', 'documents', 'test', 'backup~')\n+        with codecs.open(self._backup_filepath, 'w', 'utf-8') as f:\n+            f.write(\"should be ignored\")\n+\n+    def tearDown(self):\n+        os.unlink(self._nonascii_filepath)\n+        os.unlink(self._hidden_filepath)\n+        os.unlink(self._backup_filepath)\n \n     def assertFileContains(self, filepath, text):\n         self.assertIn(text, self._get_file(smart_unicode(filepath)),\n@@ -93,7 +107,7 @@ class BaseCollectionTestCase(BaseStaticFilesTestCase):\n     Tests shared by all file finding features (collectstatic,\n     findstatic, and static serve view).\n \n-    This relies on the asserts defined in UtilityAssertsTestCase, but\n+    This relies on the asserts defined in BaseStaticFilesTestCase, but\n     is separated because some test cases need those asserts without\n     all these tests.\n     \"\"\"\n@@ -300,7 +314,7 @@ def test_template_tag_return(self):\n                                 \"does/not/exist.png\",\n                                 \"/static/does/not/exist.png\")\n         self.assertStaticRenders(\"test/file.txt\",\n-                                 \"/static/test/file.dad0999e4f8f.txt\")\n+                                 \"/static/test/file.ea5bccaf16d5.txt\")\n         self.assertStaticRenders(\"cached/styles.css\",\n                                  \"/static/cached/styles.93b1147e8552.css\")\n \n@@ -362,12 +376,12 @@ def test_template_tag_relative(self):\n         self.assertEqual(relpath, \"cached/relative.2217ea7273c2.css\")\n         with storage.staticfiles_storage.open(relpath) as relfile:\n             content = relfile.read()\n+            self.assertIn(\"/static/cached/styles.93b1147e8552.css\", content)\n             self.assertNotIn(\"../cached/styles.css\", content)\n             self.assertNotIn('@import \"styles.css\"', content)\n+            self.assertNotIn('url(img/relative.png)', content)\n+            self.assertIn('url(\"/static/cached/img/relative.acae32e4532b.png\")', content)\n             self.assertIn(\"/static/cached/styles.93b1147e8552.css\", content)\n-            self.assertNotIn(\"url(img/relative.png)\", content)\n-            self.assertIn(\"/static/cached/img/relative.acae32e4532b.png\", content)\n-            self.assertIn(\"/static/cached/absolute.cc80cb5e2eb1.css#eggs\", content)\n \n     def test_template_tag_deep_relative(self):\n         relpath = self.cached_file_path(\"cached/css/window.css\")\n@@ -398,13 +412,38 @@ def test_cache_invalidation(self):\n         cached_name = storage.staticfiles_storage.cache.get(cache_key)\n         self.assertEqual(cached_name, hashed_name)\n \n+    def test_post_processing(self):\n+        \"\"\"Test that post_processing behaves correctly.\n+\n+        Files that are alterable should always be post-processed; files that\n+        aren't should be skipped.\n+\n+        collectstatic has already been called once in setUp() for this testcase,\n+        therefore we check by verifying behavior on a second run.\n+        \"\"\"\n+        collectstatic_args = {\n+            'interactive': False,\n+            'verbosity': '0',\n+            'link': False,\n+            'clear': False,\n+            'dry_run': False,\n+            'post_process': True,\n+            'use_default_ignore_patterns': True,\n+            'ignore_patterns': ['*.ignoreme'],\n+        }\n+\n+        collectstatic_cmd = CollectstaticCommand()\n+        collectstatic_cmd.set_options(**collectstatic_args)\n+        stats = collectstatic_cmd.collect()\n+        self.assertTrue(u'cached/css/window.css' in stats['post_processed'])\n+        self.assertTrue(u'cached/css/img/window.png' in stats['unmodified'])\n+\n # we set DEBUG to False here since the template tag wouldn't work otherwise\n TestCollectionCachedStorage = override_settings(**dict(TEST_SETTINGS,\n     STATICFILES_STORAGE='django.contrib.staticfiles.storage.CachedStaticFilesStorage',\n     DEBUG=False,\n ))(TestCollectionCachedStorage)\n \n-\n if sys.platform != 'win32':\n \n     class TestCollectionLinks(CollectionTestCase, TestDefaults):"
        }
    ],
    "stats": {
        "total": 276,
        "additions": 189,
        "deletions": 87
    }
}